Main Function with logger : Logger(dir=output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7, use-tf=False, writer=None)
Arguments : -------------------------------
FLOP_ratio       : 0.7
FLOP_tolerant    : 0.05
FLOP_weight      : 2.0
ablation_num_select : None
batch_size       : 256
cutout_length    : -1
data_path        : /data//cifar.python
dataset          : cifar10
eval_frequency   : 1
gumbel_tau_max   : 5.0
gumbel_tau_min   : 0.1
model_config     : ./configs/archs/CIFAR-ResNet20.config
optim_config     : ./configs/search-opts/CIFARX.config
print_freq       : 100
print_freq_eval  : 200
procedure        : search-v2
rand_seed        : 5
resume           : None
save_dir         : ./output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7
split_path       : ./.latent-data/splits/cifar10-0.5.pth
workers          : 6
Python  Version  : 3.7.4 (default, Aug 13 2019, 20:35:49)  [GCC 7.3.0]
Pillow  Version  : 6.2.0
PyTorch Version  : 1.3.1
cuDNN   Version  : 7603
CUDA available   : True
CUDA GPU numbers : 3
CUDA_VISIBLE_DEVICES : 0,1,2
./configs/archs/CIFAR-ResNet20.config
Configure(dataset='cifar', arch='resnet', depth=20, module='ResNetBasicblock', super_type='basic', zero_init_residual=False, class_num=10, search_mode='shape')
./configs/search-opts/CIFARX.config
Configure(scheduler='cos', eta_min=0.0, epochs=600, warmup=0, optim='SGD', LR=0.1, decay=0.0005, momentum=0.9, nesterov=True, criterion='Softmax', arch_LR=0.001, arch_decay=0.001, class_num=10, FLOP=40.813194)
Model Information : SearchShapeCifarResNet : Depth : 20 , Layers for each block : 3
stage=0 ::: depth-block-choices=(1, 2, 3) for 3 blocks.
stage=0, ilayer=00/03, block=001, iC= 16, oC= 16, stride=1
stage=0, ilayer=01/03, block=002, iC= 16, oC= 16, stride=1
stage=0, ilayer=02/03, block=003, iC= 16, oC= 16, stride=1
stage=1 ::: depth-block-choices=(1, 2, 3) for 3 blocks.
stage=1, ilayer=00/03, block=004, iC= 16, oC= 32, stride=2
stage=1, ilayer=01/03, block=005, iC= 32, oC= 32, stride=1
stage=1, ilayer=02/03, block=006, iC= 32, oC= 32, stride=1
stage=2 ::: depth-block-choices=(1, 2, 3) for 3 blocks.
stage=2, ilayer=00/03, block=007, iC= 32, oC= 64, stride=2
stage=2, ilayer=01/03, block=008, iC= 64, oC= 64, stride=1
stage=2, ilayer=02/03, block=009, iC= 64, oC= 64, stride=1
MAX_FLOP = 40.813194 M
Params   = 0.279089 M
train_data : Dataset CIFAR10
    Number of datapoints: 50000
    Root location: /data//cifar.python
    Split: Train
    StandardTransform
Transform: Compose(
               RandomHorizontalFlip(p=0.5)
               RandomCrop(size=(32, 32), padding=4)
               ToTensor()
               Normalize(mean=[0.4913725490196078, 0.4823529411764706, 0.4466666666666667], std=[0.24705882352941178, 0.24352941176470588, 0.2615686274509804])
           )
search-data: SearchDataset(name=cifar10, train=25000, valid=25000, version=V1)
search_train_loader : 25000 samples
search_valid_loader : 25000 samples
base-optimizer : SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.1
    momentum: 0.9
    nesterov: True
    weight_decay: 0.0005
)
arch-optimizer : Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.5, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.001

Parameter Group 1
    amsgrad: False
    betas: (0.5, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.001
)
scheduler      : CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=0, iter=0.00, type=cosine, T-max=600, eta-min=0.0)
criterion      : CrossEntropyLoss()
=> do not find the last-info file : output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth or resume : None

***[2020-01-29 05:41:03]*** start epoch=000/600 Time Left: [00:00:00], LR=[0.100000 ~ 0.100000], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=0, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=5.0, FLOP=40.81
[Search] : epoch=000/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:41:09] [epoch=000/600][000/098] Time 6.63 (6.63) Data 0.37 (0.37) Base-Loss 2.302 (2.302)  Prec@1 12.89 (12.89) Prec@5 52.34 (52.34) Acls-loss 2.306 (2.306) FLOP-Loss -2.384 (-2.384) Arch-Loss -2.461 (-2.461)
**TRAIN** [2020-01-29 05:41:36] [epoch=000/600][097/098] Time 0.41 (0.34) Data 0.00 (0.00) Base-Loss 1.873 (2.060)  Prec@1 25.00 (21.22) Prec@5 81.55 (75.16) Acls-loss 1.957 (2.055) FLOP-Loss 0.000 (-0.098) Arch-Loss 1.957 (1.860)
 **TRAIN** Prec@1 21.22 Prec@5 75.16 Error@1 78.78 Error@5 24.84 Base-Loss:2.060, Arch-Loss=1.860
***[2020-01-29 05:41:36]*** TRAIN [epoch=000/600] base-loss = 2.059667, arch-loss = 1.860328, accuracy-1 = 21.22, accuracy-5 = 75.16
[epoch=000/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 16, 16, 16, 12, 14, 25, 22, 28, 32, 22, 9, 57, 44, 57, 25, 57, 25]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 26.634234)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.330 0.334 0.337  ||  -0.0150 -0.0031 0.0054  || discrepancy=0.00 || select=2/3
001/003-th : 0.331 0.333 0.337  ||  -0.0067 -0.0003 0.0107  || discrepancy=0.00 || select=2/3
002/003-th : 0.336 0.324 0.340  ||  -0.0051 -0.0423 0.0070  || discrepancy=0.00 || select=2/3
-----------------------------------------------
000/019-th : 0.124 0.124 0.126 0.121 0.125 0.128 0.126 0.126  ||  -0.008 -0.003 0.007 -0.030 0.004 0.029 0.009 0.011    || dis=0.00 || select=5/8
001/019-th : 0.124 0.126 0.124 0.124 0.126 0.124 0.125 0.127  ||  -0.002 0.017 0.000 -0.002 0.012 -0.001 0.005 0.019    || dis=0.00 || select=7/8
002/019-th : 0.125 0.123 0.122 0.125 0.127 0.125 0.126 0.128  ||  -0.009 -0.023 -0.031 -0.010 0.007 -0.004 -0.001 0.016  || dis=0.00 || select=7/8
003/019-th : 0.124 0.123 0.126 0.125 0.124 0.126 0.126 0.127  ||  -0.016 -0.021 -0.002 -0.009 -0.013 0.003 -0.000 0.006  || dis=0.00 || select=7/8
004/019-th : 0.124 0.125 0.125 0.127 0.123 0.125 0.125 0.127  ||  -0.011 -0.003 -0.004 0.011 -0.014 -0.001 -0.003 0.012  || dis=0.00 || select=7/8
005/019-th : 0.124 0.125 0.124 0.123 0.127 0.127 0.124 0.126  ||  -0.007 -0.000 -0.003 -0.016 0.016 0.022 -0.004 0.012  || dis=0.00 || select=5/8
006/019-th : 0.123 0.125 0.124 0.126 0.126 0.125 0.126 0.125  ||  -0.012 0.003 0.000 0.016 0.015 0.005 0.017 0.007      || dis=0.00 || select=6/8
007/019-th : 0.126 0.125 0.125 0.124 0.125 0.126 0.125 0.123  ||  0.006 0.004 0.002 -0.009 0.001 0.009 0.001 -0.012     || dis=0.00 || select=5/8
008/019-th : 0.124 0.125 0.124 0.123 0.127 0.126 0.125 0.126  ||  -0.010 0.002 -0.007 -0.014 0.012 0.008 -0.004 0.004   || dis=0.00 || select=4/8
009/019-th : 0.124 0.125 0.125 0.123 0.124 0.125 0.128 0.127  ||  -0.009 0.001 0.006 -0.010 -0.008 0.002 0.025 0.016    || dis=0.00 || select=6/8
010/019-th : 0.122 0.124 0.125 0.124 0.126 0.126 0.126 0.127  ||  -0.018 -0.003 0.005 -0.006 0.013 0.015 0.010 0.019    || dis=0.00 || select=7/8
011/019-th : 0.127 0.124 0.124 0.124 0.127 0.125 0.124 0.126  ||  0.010 -0.013 -0.010 -0.011 0.010 -0.003 -0.013 0.007  || dis=0.00 || select=4/8
012/019-th : 0.127 0.124 0.123 0.126 0.126 0.124 0.125 0.125  ||  0.021 -0.006 -0.015 0.013 0.013 -0.003 0.003 0.004    || dis=0.00 || select=0/8
013/019-th : 0.125 0.125 0.122 0.125 0.126 0.124 0.126 0.126  ||  0.002 0.004 -0.021 -0.002 0.011 -0.012 0.012 0.006    || dis=0.00 || select=6/8
014/019-th : 0.124 0.123 0.125 0.125 0.128 0.126 0.123 0.126  ||  -0.007 -0.019 0.002 -0.000 0.020 0.007 -0.013 0.010   || dis=0.00 || select=4/8
015/019-th : 0.124 0.124 0.125 0.123 0.127 0.125 0.127 0.125  ||  -0.012 -0.013 -0.001 -0.018 0.011 0.001 0.015 0.002   || dis=0.00 || select=6/8
016/019-th : 0.125 0.126 0.122 0.123 0.126 0.126 0.126 0.125  ||  0.006 0.017 -0.015 -0.006 0.017 0.017 0.011 0.007     || dis=0.00 || select=1/8
017/019-th : 0.125 0.123 0.125 0.124 0.127 0.123 0.127 0.126  ||  0.007 -0.006 0.006 0.002 0.020 -0.007 0.022 0.017     || dis=0.00 || select=6/8
018/019-th : 0.124 0.127 0.123 0.123 0.125 0.127 0.125 0.126  ||  -0.011 0.017 -0.015 -0.016 0.002 0.016 0.001 0.005    || dis=0.00 || select=1/8
[epoch=000/600] FLOP : 26.63 MB, ratio : 0.6526, Expected-ratio : 0.7000, Discrepancy : 0.001
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:41:36] [epoch=000/600][000/098] Time 0.34 (0.34) Data 0.27 (0.27) Loss 2.254 (2.254)  Prec@1 22.27 (22.27) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:41:42] [epoch=000/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.997 (2.171)  Prec@1 29.17 (21.83) Prec@5 80.95 (76.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 21.83 Prec@5 76.80 Error@1 78.17 Error@5 23.20 Loss:2.171
***[2020-01-29 05:41:42]*** VALID [epoch=000/600] loss = 2.170594, accuracy@1 = 21.83, accuracy@5 = 76.80 | Best-Valid-Acc@1=-1.00, Error@1=101.00
Currently, the best validation accuracy found at 000-epoch :: acc@1=21.83, acc@5=76.80, error@1=78.17, error@5=23.20, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:41:42]*** start epoch=001/600 Time Left: [06:33:24], LR=[0.099999 ~ 0.099999], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=1, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.999966416006195, FLOP=40.81
[Search] : epoch=001/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:41:43] [epoch=001/600][000/098] Time 0.73 (0.73) Data 0.35 (0.35) Base-Loss 1.966 (1.966)  Prec@1 26.56 (26.56) Prec@5 80.86 (80.86) Acls-loss 1.878 (1.878) FLOP-Loss 0.000 (0.000) Arch-Loss 1.878 (1.878)
**TRAIN** [2020-01-29 05:42:07] [epoch=001/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.665 (1.865)  Prec@1 33.33 (28.71) Prec@5 91.67 (84.35) Acls-loss 1.814 (1.863) FLOP-Loss 0.000 (-0.024) Arch-Loss 1.814 (1.814)
 **TRAIN** Prec@1 28.71 Prec@5 84.35 Error@1 71.29 Error@5 15.65 Base-Loss:1.865, Arch-Loss=1.814
***[2020-01-29 05:42:07]*** TRAIN [epoch=001/600] base-loss = 1.864777, arch-loss = 1.813816, accuracy-1 = 28.71, accuracy-5 = 84.35
[epoch=001/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 16, 12, 16, 12, 14, 25, 22, 28, 32, 22, 9, 57, 44, 57, 44, 57, 51]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.62931)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.330 0.332 0.338  ||  -0.0165 -0.0111 0.0070  || discrepancy=0.01 || select=2/3
001/003-th : 0.332 0.330 0.339  ||  -0.0081 -0.0146 0.0124  || discrepancy=0.01 || select=2/3
002/003-th : 0.338 0.319 0.343  ||  -0.0074 -0.0648 0.0096  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.123 0.123 0.125 0.121 0.126 0.128 0.126 0.127  ||  -0.012 -0.009 0.004 -0.031 0.011 0.029 0.014 0.016    || dis=0.00 || select=5/8
001/019-th : 0.123 0.126 0.124 0.124 0.127 0.124 0.125 0.127  ||  -0.006 0.013 -0.003 -0.004 0.020 0.001 0.007 0.022    || dis=0.00 || select=7/8
002/019-th : 0.124 0.122 0.122 0.124 0.127 0.126 0.126 0.128  ||  -0.011 -0.027 -0.030 -0.011 0.011 -0.000 -0.000 0.017  || dis=0.00 || select=7/8
003/019-th : 0.124 0.123 0.125 0.125 0.124 0.127 0.126 0.127  ||  -0.018 -0.024 -0.004 -0.007 -0.010 0.007 0.002 0.007  || dis=0.00 || select=5/8
004/019-th : 0.124 0.125 0.124 0.126 0.124 0.125 0.125 0.127  ||  -0.012 -0.003 -0.007 0.008 -0.010 0.002 -0.001 0.013  || dis=0.00 || select=7/8
005/019-th : 0.123 0.124 0.124 0.123 0.126 0.128 0.125 0.126  ||  -0.011 -0.004 -0.004 -0.011 0.014 0.026 -0.001 0.014  || dis=0.00 || select=5/8
006/019-th : 0.123 0.124 0.124 0.126 0.126 0.125 0.127 0.125  ||  -0.014 0.001 -0.002 0.014 0.013 0.006 0.019 0.009     || dis=0.00 || select=6/8
007/019-th : 0.125 0.125 0.125 0.124 0.125 0.127 0.126 0.124  ||  0.001 0.001 0.000 -0.011 0.004 0.014 0.005 -0.009     || dis=0.00 || select=5/8
008/019-th : 0.124 0.125 0.124 0.122 0.127 0.127 0.125 0.126  ||  -0.013 -0.001 -0.010 -0.022 0.017 0.013 -0.002 0.007  || dis=0.00 || select=4/8
009/019-th : 0.123 0.124 0.125 0.124 0.123 0.125 0.128 0.127  ||  -0.012 -0.002 0.005 -0.007 -0.010 0.005 0.027 0.018   || dis=0.00 || select=6/8
010/019-th : 0.122 0.124 0.125 0.123 0.126 0.127 0.126 0.127  ||  -0.021 -0.005 0.003 -0.008 0.016 0.018 0.013 0.020    || dis=0.00 || select=7/8
011/019-th : 0.126 0.124 0.124 0.124 0.127 0.126 0.124 0.127  ||  0.007 -0.014 -0.013 -0.014 0.011 0.001 -0.011 0.010   || dis=0.00 || select=4/8
012/019-th : 0.127 0.124 0.122 0.126 0.126 0.124 0.125 0.125  ||  0.019 -0.008 -0.017 0.010 0.015 -0.001 0.004 0.006    || dis=0.00 || select=0/8
013/019-th : 0.125 0.125 0.122 0.124 0.127 0.124 0.127 0.126  ||  -0.004 0.003 -0.023 -0.012 0.015 -0.007 0.016 0.009   || dis=0.00 || select=6/8
014/019-th : 0.123 0.122 0.125 0.125 0.127 0.126 0.124 0.127  ||  -0.013 -0.024 -0.001 0.002 0.020 0.012 -0.008 0.016   || dis=0.00 || select=4/8
015/019-th : 0.123 0.123 0.125 0.123 0.126 0.126 0.127 0.126  ||  -0.014 -0.016 -0.005 -0.017 0.010 0.004 0.017 0.005   || dis=0.00 || select=6/8
016/019-th : 0.124 0.126 0.122 0.123 0.128 0.127 0.126 0.125  ||  0.001 0.014 -0.020 -0.008 0.028 0.020 0.014 0.011     || dis=0.00 || select=4/8
017/019-th : 0.125 0.123 0.124 0.125 0.127 0.124 0.127 0.126  ||  0.005 -0.009 0.002 0.006 0.020 -0.003 0.023 0.019     || dis=0.00 || select=6/8
018/019-th : 0.123 0.127 0.123 0.123 0.124 0.127 0.126 0.127  ||  -0.017 0.014 -0.019 -0.014 -0.009 0.017 0.005 0.012   || dis=0.00 || select=5/8
[epoch=001/600] FLOP : 27.63 MB, ratio : 0.6770, Expected-ratio : 0.7000, Discrepancy : 0.001
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:42:07] [epoch=001/600][000/098] Time 0.34 (0.34) Data 0.27 (0.27) Loss 2.117 (2.117)  Prec@1 24.61 (24.61) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:42:13] [epoch=001/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.078 (2.029)  Prec@1 25.60 (25.68) Prec@5 77.98 (81.87) Size=[168, 3, 32, 32]
 **VALID** Prec@1 25.68 Prec@5 81.87 Error@1 74.32 Error@5 18.13 Loss:2.029
***[2020-01-29 05:42:13]*** VALID [epoch=001/600] loss = 2.028578, accuracy@1 = 25.68, accuracy@5 = 81.87 | Best-Valid-Acc@1=21.83, Error@1=78.17
Currently, the best validation accuracy found at 001-epoch :: acc@1=25.68, acc@5=81.87, error@1=74.32, error@5=18.13, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:42:13]*** start epoch=002/600 Time Left: [05:53:14], LR=[0.099997 ~ 0.099997], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=2, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.999865664945505, FLOP=40.81
[Search] : epoch=002/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:42:14] [epoch=002/600][000/098] Time 0.71 (0.71) Data 0.42 (0.42) Base-Loss 1.787 (1.787)  Prec@1 33.98 (33.98) Prec@5 85.55 (85.55) Acls-loss 1.711 (1.711) FLOP-Loss 0.000 (0.000) Arch-Loss 1.711 (1.711)
**TRAIN** [2020-01-29 05:42:40] [epoch=002/600][097/098] Time 0.23 (0.27) Data 0.00 (0.00) Base-Loss 1.809 (1.758)  Prec@1 27.38 (33.04) Prec@5 82.14 (87.28) Acls-loss 1.786 (1.749) FLOP-Loss 0.000 (0.000) Arch-Loss 1.786 (1.749)
 **TRAIN** Prec@1 33.04 Prec@5 87.28 Error@1 66.96 Error@5 12.72 Base-Loss:1.758, Arch-Loss=1.749
***[2020-01-29 05:42:40]*** TRAIN [epoch=002/600] base-loss = 1.758355, arch-loss = 1.749088, accuracy-1 = 33.04, accuracy-5 = 87.28
[epoch=002/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 16, 12, 16, 12, 14, 25, 22, 28, 32, 22, 9, 57, 44, 57, 44, 57, 51]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 26.33907)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.331 0.330 0.339  ||  -0.0165 -0.0206 0.0072  || discrepancy=0.01 || select=2/3
001/003-th : 0.333 0.328 0.340  ||  -0.0085 -0.0232 0.0128  || discrepancy=0.01 || select=2/3
002/003-th : 0.339 0.315 0.346  ||  -0.0088 -0.0823 0.0114  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.122 0.122 0.125 0.122 0.127 0.129 0.127 0.127  ||  -0.019 -0.018 0.002 -0.022 0.018 0.033 0.018 0.023    || dis=0.00 || select=5/8
001/019-th : 0.123 0.125 0.124 0.124 0.127 0.125 0.125 0.127  ||  -0.008 0.009 -0.003 -0.001 0.024 0.004 0.008 0.024    || dis=0.00 || select=4/8
002/019-th : 0.124 0.122 0.122 0.125 0.127 0.126 0.126 0.128  ||  -0.011 -0.027 -0.030 -0.009 0.012 -0.000 0.001 0.017  || dis=0.00 || select=7/8
003/019-th : 0.124 0.123 0.125 0.125 0.124 0.127 0.126 0.127  ||  -0.018 -0.023 -0.005 -0.007 -0.011 0.009 0.003 0.006  || dis=0.00 || select=5/8
004/019-th : 0.124 0.125 0.124 0.126 0.124 0.125 0.125 0.127  ||  -0.013 -0.004 -0.006 0.005 -0.007 0.001 -0.000 0.014  || dis=0.00 || select=7/8
005/019-th : 0.123 0.124 0.125 0.123 0.126 0.128 0.125 0.127  ||  -0.011 -0.005 -0.001 -0.013 0.009 0.025 -0.000 0.015  || dis=0.00 || select=5/8
006/019-th : 0.123 0.124 0.124 0.126 0.126 0.125 0.127 0.125  ||  -0.014 0.001 -0.002 0.011 0.012 0.007 0.020 0.009     || dis=0.00 || select=6/8
007/019-th : 0.124 0.125 0.124 0.124 0.126 0.127 0.126 0.124  ||  -0.003 -0.001 -0.008 -0.008 0.013 0.015 0.010 -0.006  || dis=0.00 || select=5/8
008/019-th : 0.123 0.125 0.124 0.123 0.127 0.127 0.125 0.126  ||  -0.016 -0.002 -0.010 -0.016 0.016 0.015 -0.001 0.008  || dis=0.00 || select=4/8
009/019-th : 0.123 0.124 0.125 0.124 0.124 0.125 0.128 0.127  ||  -0.013 -0.003 0.003 -0.007 -0.006 0.006 0.028 0.019   || dis=0.00 || select=6/8
010/019-th : 0.122 0.123 0.125 0.124 0.127 0.127 0.126 0.127  ||  -0.023 -0.007 0.003 -0.005 0.019 0.018 0.014 0.021    || dis=0.00 || select=7/8
011/019-th : 0.126 0.124 0.123 0.124 0.127 0.126 0.124 0.127  ||  0.005 -0.014 -0.017 -0.014 0.015 0.003 -0.007 0.011   || dis=0.00 || select=4/8
012/019-th : 0.127 0.124 0.122 0.126 0.127 0.124 0.125 0.125  ||  0.017 -0.008 -0.017 0.009 0.016 -0.001 0.005 0.007    || dis=0.00 || select=0/8
013/019-th : 0.124 0.125 0.122 0.123 0.126 0.125 0.128 0.127  ||  -0.007 -0.002 -0.026 -0.017 0.003 -0.001 0.021 0.013  || dis=0.00 || select=6/8
014/019-th : 0.123 0.121 0.124 0.125 0.128 0.128 0.125 0.127  ||  -0.019 -0.029 -0.007 -0.002 0.025 0.021 -0.002 0.018  || dis=0.00 || select=4/8
015/019-th : 0.123 0.123 0.124 0.122 0.128 0.126 0.128 0.126  ||  -0.017 -0.017 -0.008 -0.024 0.019 0.005 0.019 0.007   || dis=0.00 || select=6/8
016/019-th : 0.124 0.126 0.121 0.123 0.128 0.127 0.126 0.126  ||  -0.004 0.013 -0.028 -0.004 0.032 0.026 0.014 0.014    || dis=0.00 || select=4/8
017/019-th : 0.124 0.123 0.124 0.125 0.126 0.124 0.127 0.127  ||  0.003 -0.010 -0.001 0.006 0.018 -0.003 0.025 0.020    || dis=0.00 || select=6/8
018/019-th : 0.122 0.126 0.123 0.124 0.124 0.128 0.126 0.127  ||  -0.024 0.008 -0.018 -0.005 -0.005 0.025 0.007 0.016   || dis=0.00 || select=5/8
[epoch=002/600] FLOP : 26.34 MB, ratio : 0.6454, Expected-ratio : 0.7000, Discrepancy : 0.001
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:42:40] [epoch=002/600][000/098] Time 0.38 (0.38) Data 0.31 (0.31) Loss 2.020 (2.020)  Prec@1 21.09 (21.09) Prec@5 76.17 (76.17) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:42:46] [epoch=002/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.114 (1.969)  Prec@1 29.76 (27.79) Prec@5 76.19 (82.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 27.79 Prec@5 82.72 Error@1 72.21 Error@5 17.28 Loss:1.969
***[2020-01-29 05:42:46]*** VALID [epoch=002/600] loss = 1.969463, accuracy@1 = 27.79, accuracy@5 = 82.72 | Best-Valid-Acc@1=25.68, Error@1=74.32
Currently, the best validation accuracy found at 002-epoch :: acc@1=27.79, acc@5=82.72, error@1=72.21, error@5=17.28, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:42:46]*** start epoch=003/600 Time Left: [05:42:47], LR=[0.099994 ~ 0.099994], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=3, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.9996977495800685, FLOP=40.81
[Search] : epoch=003/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:42:47] [epoch=003/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 1.842 (1.842)  Prec@1 32.42 (32.42) Prec@5 86.33 (86.33) Acls-loss 1.699 (1.699) FLOP-Loss -2.393 (-2.393) Arch-Loss -3.087 (-3.087)
**TRAIN** [2020-01-29 05:43:10] [epoch=003/600][097/098] Time 0.26 (0.25) Data 0.00 (0.00) Base-Loss 1.766 (1.698)  Prec@1 31.55 (35.63) Prec@5 86.90 (88.39) Acls-loss 1.700 (1.693) FLOP-Loss 0.000 (0.025) Arch-Loss 1.700 (1.742)
 **TRAIN** Prec@1 35.63 Prec@5 88.39 Error@1 64.37 Error@5 11.61 Base-Loss:1.698, Arch-Loss=1.742
***[2020-01-29 05:43:10]*** TRAIN [epoch=003/600] base-loss = 1.698410, arch-loss = 1.742017, accuracy-1 = 35.63, accuracy-5 = 88.39
[epoch=003/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 16, 12, 16, 12, 14, 25, 22, 28, 32, 32, 9, 57, 44, 44, 44, 57, 51]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 26.624766)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.334 0.325 0.341  ||  -0.0141 -0.0418 0.0052  || discrepancy=0.01 || select=2/3
001/003-th : 0.335 0.324 0.341  ||  -0.0061 -0.0415 0.0108  || discrepancy=0.01 || select=2/3
002/003-th : 0.339 0.316 0.345  ||  -0.0072 -0.0765 0.0098  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.122 0.122 0.124 0.122 0.128 0.128 0.127 0.127  ||  -0.019 -0.023 -0.001 -0.023 0.026 0.031 0.020 0.024   || dis=0.00 || select=5/8
001/019-th : 0.123 0.125 0.124 0.125 0.127 0.125 0.125 0.127  ||  -0.009 0.009 -0.004 0.004 0.024 0.006 0.008 0.023     || dis=0.00 || select=4/8
002/019-th : 0.125 0.122 0.122 0.125 0.127 0.125 0.126 0.128  ||  -0.009 -0.026 -0.027 -0.005 0.013 -0.004 -0.001 0.016  || dis=0.00 || select=7/8
003/019-th : 0.124 0.123 0.125 0.125 0.124 0.126 0.126 0.126  ||  -0.016 -0.020 -0.003 -0.003 -0.013 0.005 0.000 0.005  || dis=0.00 || select=5/8
004/019-th : 0.123 0.125 0.125 0.126 0.124 0.125 0.125 0.126  ||  -0.013 -0.002 -0.003 0.007 -0.005 0.002 0.000 0.011   || dis=0.00 || select=7/8
005/019-th : 0.123 0.124 0.125 0.124 0.125 0.127 0.124 0.126  ||  -0.010 -0.003 0.002 -0.007 0.006 0.021 -0.003 0.014   || dis=0.00 || select=5/8
006/019-th : 0.123 0.125 0.124 0.126 0.125 0.125 0.127 0.125  ||  -0.012 0.003 0.000 0.012 0.007 0.005 0.017 0.006      || dis=0.00 || select=6/8
007/019-th : 0.124 0.124 0.124 0.125 0.127 0.127 0.126 0.124  ||  -0.006 -0.004 -0.006 0.000 0.017 0.018 0.013 -0.007   || dis=0.00 || select=5/8
008/019-th : 0.123 0.125 0.124 0.124 0.127 0.127 0.125 0.126  ||  -0.017 -0.001 -0.011 -0.011 0.017 0.017 -0.000 0.007  || dis=0.00 || select=4/8
009/019-th : 0.123 0.124 0.125 0.124 0.124 0.125 0.128 0.127  ||  -0.012 -0.002 0.002 -0.002 -0.004 0.004 0.026 0.018   || dis=0.00 || select=6/8
010/019-th : 0.122 0.123 0.125 0.124 0.127 0.127 0.126 0.127  ||  -0.023 -0.007 0.005 -0.000 0.019 0.018 0.012 0.019    || dis=0.00 || select=7/8
011/019-th : 0.126 0.124 0.123 0.125 0.126 0.125 0.124 0.127  ||  0.006 -0.011 -0.017 -0.006 0.009 0.001 -0.009 0.010   || dis=0.00 || select=7/8
012/019-th : 0.127 0.124 0.123 0.126 0.126 0.124 0.125 0.125  ||  0.018 -0.006 -0.014 0.007 0.013 -0.003 0.003 0.006    || dis=0.00 || select=0/8
013/019-th : 0.124 0.125 0.122 0.124 0.125 0.125 0.128 0.127  ||  -0.011 0.000 -0.029 -0.011 -0.006 -0.001 0.025 0.015  || dis=0.00 || select=6/8
014/019-th : 0.121 0.121 0.124 0.125 0.130 0.128 0.125 0.127  ||  -0.025 -0.032 -0.006 0.003 0.040 0.025 0.004 0.017    || dis=0.00 || select=4/8
015/019-th : 0.123 0.123 0.124 0.122 0.129 0.126 0.127 0.126  ||  -0.017 -0.019 -0.006 -0.025 0.029 0.008 0.017 0.007   || dis=0.00 || select=4/8
016/019-th : 0.123 0.125 0.120 0.124 0.129 0.128 0.126 0.125  ||  -0.005 0.008 -0.030 0.001 0.040 0.031 0.015 0.013     || dis=0.00 || select=4/8
017/019-th : 0.124 0.123 0.124 0.126 0.126 0.124 0.127 0.127  ||  0.003 -0.010 -0.000 0.013 0.012 -0.005 0.023 0.020    || dis=0.00 || select=6/8
018/019-th : 0.122 0.126 0.122 0.124 0.124 0.129 0.125 0.127  ||  -0.025 0.011 -0.022 -0.006 -0.005 0.030 0.004 0.016   || dis=0.00 || select=5/8
[epoch=003/600] FLOP : 26.62 MB, ratio : 0.6524, Expected-ratio : 0.7000, Discrepancy : 0.001
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:43:11] [epoch=003/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.121 (2.121)  Prec@1 25.78 (25.78) Prec@5 79.30 (79.30) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:43:16] [epoch=003/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.937 (1.992)  Prec@1 28.57 (29.48) Prec@5 85.12 (82.49) Size=[168, 3, 32, 32]
 **VALID** Prec@1 29.48 Prec@5 82.49 Error@1 70.52 Error@5 17.51 Loss:1.992
***[2020-01-29 05:43:17]*** VALID [epoch=003/600] loss = 1.992212, accuracy@1 = 29.48, accuracy@5 = 82.49 | Best-Valid-Acc@1=27.79, Error@1=72.21
Currently, the best validation accuracy found at 003-epoch :: acc@1=29.48, acc@5=82.49, error@1=70.52, error@5=17.51, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:43:17]*** start epoch=004/600 Time Left: [05:33:00], LR=[0.099989 ~ 0.099989], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=4, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.999462674513372, FLOP=40.81
[Search] : epoch=004/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:43:17] [epoch=004/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 1.702 (1.702)  Prec@1 33.20 (33.20) Prec@5 88.67 (88.67) Acls-loss 1.728 (1.728) FLOP-Loss 0.000 (0.000) Arch-Loss 1.728 (1.728)
**TRAIN** [2020-01-29 05:43:41] [epoch=004/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 1.569 (1.639)  Prec@1 38.10 (38.18) Prec@5 90.48 (89.62) Acls-loss 1.522 (1.646) FLOP-Loss 0.000 (-0.049) Arch-Loss 1.522 (1.548)
 **TRAIN** Prec@1 38.18 Prec@5 89.62 Error@1 61.82 Error@5 10.38 Base-Loss:1.639, Arch-Loss=1.548
***[2020-01-29 05:43:41]*** TRAIN [epoch=004/600] base-loss = 1.638897, arch-loss = 1.548344, accuracy-1 = 38.18, accuracy-5 = 89.62
[epoch=004/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 16, 12, 16, 12, 14, 25, 25, 28, 25, 32, 22, 57, 44, 44, 44, 57, 51]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.34291)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.335 0.320 0.345  ||  -0.0197 -0.0638 0.0113  || discrepancy=0.01 || select=2/3
001/003-th : 0.334 0.322 0.344  ||  -0.0115 -0.0489 0.0164  || discrepancy=0.01 || select=2/3
002/003-th : 0.339 0.312 0.349  ||  -0.0124 -0.0940 0.0155  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.120 0.120 0.123 0.121 0.129 0.130 0.128 0.128  ||  -0.032 -0.035 -0.008 -0.022 0.038 0.049 0.028 0.033   || dis=0.00 || select=5/8
001/019-th : 0.122 0.124 0.123 0.123 0.128 0.126 0.126 0.128  ||  -0.015 -0.002 -0.009 -0.006 0.035 0.014 0.014 0.031   || dis=0.00 || select=4/8
002/019-th : 0.124 0.121 0.122 0.125 0.128 0.126 0.126 0.128  ||  -0.016 -0.033 -0.030 -0.006 0.020 0.003 0.006 0.020   || dis=0.00 || select=7/8
003/019-th : 0.123 0.122 0.125 0.124 0.125 0.127 0.127 0.127  ||  -0.021 -0.026 -0.007 -0.011 -0.007 0.011 0.007 0.010  || dis=0.00 || select=5/8
004/019-th : 0.123 0.124 0.124 0.124 0.126 0.126 0.126 0.127  ||  -0.019 -0.007 -0.008 -0.007 0.005 0.009 0.005 0.017   || dis=0.00 || select=7/8
005/019-th : 0.122 0.124 0.124 0.123 0.126 0.128 0.125 0.127  ||  -0.018 -0.009 -0.006 -0.017 0.014 0.028 0.003 0.022   || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.125 0.126 0.126 0.127 0.126  ||  -0.017 -0.002 -0.004 0.004 0.011 0.010 0.022 0.012    || dis=0.00 || select=6/8
007/019-th : 0.122 0.123 0.123 0.124 0.128 0.128 0.128 0.125  ||  -0.017 -0.016 -0.013 -0.003 0.025 0.026 0.024 0.003   || dis=0.00 || select=5/8
008/019-th : 0.122 0.124 0.123 0.123 0.127 0.128 0.126 0.127  ||  -0.027 -0.005 -0.015 -0.015 0.015 0.022 0.008 0.015   || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.124 0.123 0.125 0.126 0.128 0.128  ||  -0.018 -0.010 -0.001 -0.011 0.003 0.012 0.030 0.024   || dis=0.00 || select=6/8
010/019-th : 0.121 0.123 0.125 0.124 0.127 0.127 0.126 0.127  ||  -0.030 -0.012 0.002 -0.002 0.022 0.024 0.017 0.024    || dis=0.00 || select=5/8
011/019-th : 0.125 0.123 0.123 0.123 0.127 0.126 0.125 0.127  ||  -0.001 -0.018 -0.021 -0.020 0.015 0.007 -0.000 0.016  || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.123 0.125 0.127 0.125 0.126 0.126  ||  0.012 -0.011 -0.017 0.002 0.015 0.001 0.008 0.011     || dis=0.00 || select=4/8
013/019-th : 0.122 0.124 0.120 0.123 0.127 0.126 0.130 0.129  ||  -0.026 -0.012 -0.038 -0.018 0.014 0.007 0.036 0.028   || dis=0.00 || select=6/8
014/019-th : 0.120 0.120 0.123 0.124 0.131 0.129 0.126 0.128  ||  -0.038 -0.039 -0.012 -0.007 0.052 0.037 0.014 0.025   || dis=0.00 || select=4/8
015/019-th : 0.122 0.122 0.123 0.122 0.130 0.127 0.128 0.127  ||  -0.026 -0.026 -0.015 -0.021 0.039 0.014 0.026 0.014   || dis=0.00 || select=4/8
016/019-th : 0.122 0.124 0.119 0.126 0.129 0.128 0.126 0.126  ||  -0.014 0.003 -0.035 0.017 0.043 0.034 0.021 0.018     || dis=0.00 || select=4/8
017/019-th : 0.123 0.122 0.123 0.126 0.127 0.124 0.128 0.127  ||  -0.008 -0.015 -0.009 0.014 0.020 0.002 0.031 0.026    || dis=0.00 || select=6/8
018/019-th : 0.120 0.125 0.122 0.126 0.126 0.128 0.125 0.127  ||  -0.034 0.005 -0.021 0.011 0.010 0.029 0.004 0.021     || dis=0.00 || select=5/8
[epoch=004/600] FLOP : 27.34 MB, ratio : 0.6700, Expected-ratio : 0.7000, Discrepancy : 0.002
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:43:41] [epoch=004/600][000/098] Time 0.36 (0.36) Data 0.29 (0.29) Loss 1.801 (1.801)  Prec@1 34.77 (34.77) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:43:47] [epoch=004/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.224 (1.950)  Prec@1 26.19 (30.59) Prec@5 71.43 (83.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.59 Prec@5 83.40 Error@1 69.41 Error@5 16.60 Loss:1.950
***[2020-01-29 05:43:47]*** VALID [epoch=004/600] loss = 1.950361, accuracy@1 = 30.59, accuracy@5 = 83.40 | Best-Valid-Acc@1=29.48, Error@1=70.52
Currently, the best validation accuracy found at 004-epoch :: acc@1=30.59, acc@5=83.40, error@1=69.41, error@5=16.60, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:43:47]*** start epoch=005/600 Time Left: [05:26:48], LR=[0.099983 ~ 0.099983], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=5, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.999160446190115, FLOP=40.81
[Search] : epoch=005/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:43:48] [epoch=005/600][000/098] Time 0.65 (0.65) Data 0.38 (0.38) Base-Loss 1.598 (1.598)  Prec@1 39.45 (39.45) Prec@5 89.06 (89.06) Acls-loss 1.664 (1.664) FLOP-Loss 0.000 (0.000) Arch-Loss 1.664 (1.664)
**TRAIN** [2020-01-29 05:44:13] [epoch=005/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 1.624 (1.601)  Prec@1 35.12 (39.76) Prec@5 89.88 (90.36) Acls-loss 1.525 (1.607) FLOP-Loss 0.000 (0.001) Arch-Loss 1.525 (1.608)
 **TRAIN** Prec@1 39.76 Prec@5 90.36 Error@1 60.24 Error@5 9.64 Base-Loss:1.601, Arch-Loss=1.608
***[2020-01-29 05:44:13]*** TRAIN [epoch=005/600] base-loss = 1.601129, arch-loss = 1.607915, accuracy-1 = 39.76, accuracy-5 = 90.36
[epoch=005/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 11, 16, 16, 12, 14, 22, 25, 28, 32, 22, 32, 57, 44, 44, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.433344)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.335 0.319 0.346  ||  -0.0204 -0.0684 0.0123  || discrepancy=0.01 || select=2/3
001/003-th : 0.333 0.323 0.344  ||  -0.0126 -0.0444 0.0175  || discrepancy=0.01 || select=2/3
002/003-th : 0.339 0.311 0.350  ||  -0.0145 -0.1015 0.0180  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.120 0.118 0.123 0.120 0.130 0.131 0.128 0.130  ||  -0.038 -0.048 -0.013 -0.036 0.047 0.055 0.034 0.044   || dis=0.00 || select=5/8
001/019-th : 0.122 0.123 0.123 0.124 0.129 0.126 0.126 0.128  ||  -0.018 -0.004 -0.009 -0.000 0.037 0.014 0.014 0.033   || dis=0.00 || select=4/8
002/019-th : 0.123 0.121 0.121 0.125 0.129 0.126 0.126 0.128  ||  -0.020 -0.036 -0.034 -0.002 0.027 0.007 0.008 0.023   || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.125 0.125 0.125 0.127 0.127 0.127  ||  -0.022 -0.028 -0.009 -0.008 -0.008 0.012 0.009 0.012  || dis=0.00 || select=7/8
004/019-th : 0.123 0.124 0.124 0.124 0.126 0.127 0.126 0.127  ||  -0.020 -0.010 -0.011 -0.005 0.005 0.012 0.007 0.018   || dis=0.00 || select=7/8
005/019-th : 0.122 0.123 0.124 0.124 0.126 0.128 0.125 0.127  ||  -0.018 -0.010 -0.007 -0.009 0.011 0.028 0.004 0.022   || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.125 0.126 0.126 0.127 0.126  ||  -0.018 -0.004 -0.005 0.004 0.009 0.009 0.022 0.012    || dis=0.00 || select=6/8
007/019-th : 0.122 0.122 0.123 0.124 0.128 0.128 0.128 0.125  ||  -0.023 -0.020 -0.014 -0.002 0.029 0.029 0.028 0.007   || dis=0.00 || select=4/8
008/019-th : 0.121 0.124 0.123 0.124 0.126 0.128 0.126 0.127  ||  -0.031 -0.007 -0.015 -0.008 0.011 0.026 0.008 0.019   || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.124 0.123 0.125 0.126 0.129 0.128  ||  -0.019 -0.011 -0.002 -0.015 0.005 0.010 0.032 0.026   || dis=0.00 || select=6/8
010/019-th : 0.120 0.123 0.124 0.124 0.127 0.127 0.126 0.127  ||  -0.031 -0.013 0.001 0.001 0.023 0.024 0.018 0.025     || dis=0.00 || select=7/8
011/019-th : 0.125 0.123 0.123 0.124 0.127 0.126 0.125 0.127  ||  -0.002 -0.020 -0.020 -0.007 0.019 0.007 -0.001 0.017  || dis=0.00 || select=4/8
012/019-th : 0.126 0.123 0.123 0.125 0.126 0.125 0.126 0.126  ||  0.010 -0.012 -0.016 0.003 0.012 0.003 0.009 0.012     || dis=0.00 || select=7/8
013/019-th : 0.120 0.123 0.120 0.123 0.126 0.127 0.131 0.130  ||  -0.038 -0.020 -0.041 -0.020 0.010 0.013 0.044 0.040   || dis=0.00 || select=6/8
014/019-th : 0.119 0.119 0.122 0.123 0.132 0.130 0.127 0.128  ||  -0.043 -0.047 -0.015 -0.009 0.063 0.043 0.019 0.028   || dis=0.00 || select=4/8
015/019-th : 0.121 0.121 0.123 0.123 0.131 0.127 0.128 0.127  ||  -0.030 -0.033 -0.017 -0.016 0.051 0.016 0.030 0.017   || dis=0.00 || select=4/8
016/019-th : 0.121 0.124 0.120 0.125 0.129 0.128 0.127 0.126  ||  -0.021 -0.000 -0.031 0.012 0.044 0.035 0.026 0.020    || dis=0.00 || select=4/8
017/019-th : 0.122 0.121 0.122 0.125 0.128 0.125 0.128 0.127  ||  -0.013 -0.020 -0.012 0.013 0.036 0.006 0.032 0.029    || dis=0.00 || select=4/8
018/019-th : 0.120 0.125 0.123 0.125 0.126 0.128 0.126 0.128  ||  -0.040 -0.001 -0.016 0.004 0.011 0.025 0.007 0.029    || dis=0.00 || select=7/8
[epoch=005/600] FLOP : 27.43 MB, ratio : 0.6722, Expected-ratio : 0.7000, Discrepancy : 0.002
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:44:13] [epoch=005/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 1.885 (1.885)  Prec@1 34.77 (34.77) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:44:19] [epoch=005/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.903 (2.057)  Prec@1 36.90 (29.17) Prec@5 81.55 (82.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 29.17 Prec@5 82.32 Error@1 70.83 Error@5 17.68 Loss:2.057
***[2020-01-29 05:44:19]*** VALID [epoch=005/600] loss = 2.056864, accuracy@1 = 29.17, accuracy@5 = 82.32 | Best-Valid-Acc@1=30.59, Error@1=69.41
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:44:19]*** start epoch=006/600 Time Left: [05:24:43], LR=[0.099975 ~ 0.099975], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=6, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.998791072896043, FLOP=40.81
[Search] : epoch=006/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:44:20] [epoch=006/600][000/098] Time 0.75 (0.75) Data 0.37 (0.37) Base-Loss 1.611 (1.611)  Prec@1 38.28 (38.28) Prec@5 91.41 (91.41) Acls-loss 1.544 (1.544) FLOP-Loss 0.000 (0.000) Arch-Loss 1.544 (1.544)
**TRAIN** [2020-01-29 05:44:45] [epoch=006/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.588 (1.567)  Prec@1 36.90 (41.56) Prec@5 88.69 (90.74) Acls-loss 1.688 (1.563) FLOP-Loss 2.403 (0.017) Arch-Loss 6.494 (1.596)
 **TRAIN** Prec@1 41.56 Prec@5 90.74 Error@1 58.44 Error@5 9.26 Base-Loss:1.567, Arch-Loss=1.596
***[2020-01-29 05:44:45]*** TRAIN [epoch=006/600] base-loss = 1.567308, arch-loss = 1.596482, accuracy-1 = 41.56, accuracy-5 = 90.74
[epoch=006/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 11, 12, 16, 12, 14, 28, 25, 28, 32, 32, 32, 64, 44, 44, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.758144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.336 0.317 0.347  ||  -0.0199 -0.0782 0.0121  || discrepancy=0.01 || select=2/3
001/003-th : 0.331 0.328 0.341  ||  -0.0119 -0.0200 0.0165  || discrepancy=0.01 || select=2/3
002/003-th : 0.338 0.311 0.350  ||  -0.0162 -0.0983 0.0198  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.119 0.117 0.122 0.119 0.132 0.132 0.129 0.131  ||  -0.046 -0.056 -0.018 -0.046 0.057 0.060 0.038 0.054   || dis=0.00 || select=5/8
001/019-th : 0.122 0.123 0.122 0.124 0.129 0.126 0.126 0.128  ||  -0.018 -0.008 -0.012 -0.003 0.039 0.018 0.015 0.034   || dis=0.00 || select=4/8
002/019-th : 0.123 0.121 0.121 0.126 0.129 0.126 0.126 0.128  ||  -0.021 -0.035 -0.033 0.002 0.027 0.008 0.007 0.023    || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.124 0.125 0.125 0.127 0.127 0.127  ||  -0.023 -0.028 -0.011 -0.001 -0.006 0.012 0.009 0.012  || dis=0.00 || select=5/8
004/019-th : 0.122 0.124 0.124 0.125 0.125 0.126 0.126 0.127  ||  -0.020 -0.008 -0.007 0.004 0.003 0.010 0.007 0.015    || dis=0.00 || select=7/8
005/019-th : 0.122 0.123 0.124 0.124 0.126 0.128 0.125 0.127  ||  -0.018 -0.012 -0.004 -0.007 0.012 0.028 0.002 0.021   || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.125 0.125 0.126 0.127 0.126  ||  -0.017 -0.003 -0.004 0.005 0.008 0.009 0.021 0.012    || dis=0.00 || select=6/8
007/019-th : 0.121 0.122 0.123 0.125 0.128 0.128 0.128 0.126  ||  -0.027 -0.023 -0.015 0.001 0.031 0.028 0.031 0.011    || dis=0.00 || select=6/8
008/019-th : 0.121 0.124 0.123 0.123 0.127 0.128 0.126 0.127  ||  -0.033 -0.008 -0.015 -0.012 0.013 0.025 0.010 0.020   || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.124 0.123 0.125 0.126 0.129 0.128  ||  -0.017 -0.011 -0.004 -0.012 0.001 0.011 0.032 0.025   || dis=0.00 || select=6/8
010/019-th : 0.120 0.123 0.125 0.124 0.127 0.127 0.127 0.127  ||  -0.031 -0.014 0.004 -0.001 0.019 0.024 0.018 0.025    || dis=0.00 || select=7/8
011/019-th : 0.125 0.123 0.123 0.124 0.127 0.126 0.125 0.127  ||  -0.003 -0.020 -0.021 -0.009 0.016 0.007 -0.000 0.018  || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.123 0.126 0.126 0.125 0.126 0.126  ||  0.011 -0.011 -0.015 0.009 0.009 0.001 0.007 0.011     || dis=0.00 || select=7/8
013/019-th : 0.120 0.122 0.120 0.124 0.126 0.127 0.131 0.131  ||  -0.041 -0.025 -0.043 -0.011 0.005 0.015 0.045 0.046   || dis=0.00 || select=7/8
014/019-th : 0.118 0.118 0.122 0.122 0.133 0.130 0.127 0.128  ||  -0.048 -0.050 -0.015 -0.015 0.071 0.048 0.024 0.029   || dis=0.00 || select=4/8
015/019-th : 0.121 0.120 0.122 0.123 0.132 0.127 0.129 0.127  ||  -0.031 -0.038 -0.021 -0.014 0.054 0.017 0.034 0.020   || dis=0.00 || select=4/8
016/019-th : 0.120 0.123 0.119 0.127 0.131 0.128 0.127 0.126  ||  -0.027 -0.006 -0.038 0.031 0.059 0.040 0.026 0.022    || dis=0.00 || select=4/8
017/019-th : 0.122 0.121 0.122 0.125 0.129 0.125 0.128 0.128  ||  -0.017 -0.024 -0.013 0.007 0.044 0.011 0.034 0.030    || dis=0.00 || select=4/8
018/019-th : 0.119 0.125 0.123 0.125 0.126 0.127 0.125 0.129  ||  -0.044 -0.000 -0.010 0.006 0.014 0.018 0.004 0.034    || dis=0.00 || select=7/8
[epoch=006/600] FLOP : 28.76 MB, ratio : 0.7046, Expected-ratio : 0.7000, Discrepancy : 0.002
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:44:45] [epoch=006/600][000/098] Time 0.36 (0.36) Data 0.29 (0.29) Loss 2.358 (2.358)  Prec@1 25.39 (25.39) Prec@5 76.56 (76.56) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:44:51] [epoch=006/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.460 (2.121)  Prec@1 19.05 (29.17) Prec@5 74.40 (80.92) Size=[168, 3, 32, 32]
 **VALID** Prec@1 29.17 Prec@5 80.92 Error@1 70.83 Error@5 19.08 Loss:2.121
***[2020-01-29 05:44:51]*** VALID [epoch=006/600] loss = 2.121197, accuracy@1 = 29.17, accuracy@5 = 80.92 | Best-Valid-Acc@1=30.59, Error@1=69.41
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:44:51]*** start epoch=007/600 Time Left: [05:22:23], LR=[0.099966 ~ 0.099966], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=7, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.998354564757707, FLOP=40.81
[Search] : epoch=007/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:44:52] [epoch=007/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 1.545 (1.545)  Prec@1 39.84 (39.84) Prec@5 91.02 (91.02) Acls-loss 1.583 (1.583) FLOP-Loss 2.402 (2.402) Arch-Loss 6.388 (6.388)
**TRAIN** [2020-01-29 05:45:16] [epoch=007/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.485 (1.533)  Prec@1 39.88 (43.14) Prec@5 92.26 (91.49) Acls-loss 1.562 (1.542) FLOP-Loss 0.000 (0.025) Arch-Loss 1.562 (1.591)
 **TRAIN** Prec@1 43.14 Prec@5 91.49 Error@1 56.86 Error@5 8.51 Base-Loss:1.533, Arch-Loss=1.591
***[2020-01-29 05:45:16]*** TRAIN [epoch=007/600] base-loss = 1.533012, arch-loss = 1.591367, accuracy-1 = 43.14, accuracy-5 = 91.49
[epoch=007/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 11, 16, 16, 12, 14, 28, 25, 28, 32, 32, 9, 64, 44, 44, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.218816)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.339 0.313 0.349  ||  -0.0181 -0.0969 0.0109  || discrepancy=0.01 || select=2/3
001/003-th : 0.333 0.326 0.341  ||  -0.0099 -0.0318 0.0147  || discrepancy=0.01 || select=2/3
002/003-th : 0.340 0.309 0.352  ||  -0.0154 -0.1099 0.0194  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.118 0.117 0.121 0.118 0.131 0.132 0.131 0.131  ||  -0.050 -0.059 -0.024 -0.055 0.052 0.061 0.051 0.056   || dis=0.00 || select=5/8
001/019-th : 0.122 0.123 0.122 0.123 0.129 0.127 0.126 0.129  ||  -0.017 -0.012 -0.014 -0.008 0.037 0.021 0.016 0.036   || dis=0.00 || select=4/8
002/019-th : 0.123 0.121 0.121 0.126 0.128 0.126 0.126 0.128  ||  -0.020 -0.035 -0.031 0.006 0.023 0.009 0.007 0.022    || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.124 0.126 0.124 0.127 0.127 0.127  ||  -0.022 -0.027 -0.009 0.002 -0.012 0.011 0.009 0.011   || dis=0.00 || select=7/8
004/019-th : 0.123 0.124 0.124 0.125 0.125 0.126 0.126 0.127  ||  -0.019 -0.007 -0.004 0.003 0.003 0.010 0.006 0.013    || dis=0.00 || select=7/8
005/019-th : 0.122 0.123 0.124 0.124 0.126 0.128 0.125 0.127  ||  -0.018 -0.010 -0.003 -0.005 0.010 0.025 0.002 0.020   || dis=0.00 || select=5/8
006/019-th : 0.123 0.124 0.124 0.125 0.125 0.125 0.127 0.126  ||  -0.015 -0.002 -0.001 0.004 0.007 0.007 0.018 0.010    || dis=0.00 || select=6/8
007/019-th : 0.121 0.122 0.123 0.123 0.129 0.128 0.129 0.126  ||  -0.030 -0.024 -0.016 -0.017 0.032 0.029 0.034 0.015   || dis=0.00 || select=6/8
008/019-th : 0.121 0.123 0.123 0.125 0.127 0.128 0.126 0.127  ||  -0.035 -0.013 -0.016 0.001 0.014 0.027 0.012 0.021    || dis=0.00 || select=5/8
009/019-th : 0.123 0.123 0.124 0.123 0.125 0.126 0.129 0.128  ||  -0.016 -0.010 -0.006 -0.012 -0.000 0.012 0.032 0.024  || dis=0.00 || select=6/8
010/019-th : 0.120 0.123 0.125 0.125 0.127 0.127 0.126 0.127  ||  -0.031 -0.013 0.005 0.002 0.018 0.023 0.017 0.024     || dis=0.00 || select=7/8
011/019-th : 0.125 0.123 0.123 0.125 0.127 0.126 0.125 0.127  ||  -0.002 -0.020 -0.019 -0.005 0.013 0.004 0.001 0.018   || dis=0.00 || select=7/8
012/019-th : 0.126 0.124 0.123 0.126 0.125 0.125 0.125 0.126  ||  0.013 -0.008 -0.012 0.009 0.005 -0.000 0.005 0.009    || dis=0.00 || select=0/8
013/019-th : 0.120 0.122 0.119 0.124 0.126 0.127 0.131 0.131  ||  -0.044 -0.025 -0.046 -0.011 0.005 0.016 0.046 0.049   || dis=0.00 || select=7/8
014/019-th : 0.118 0.118 0.123 0.122 0.134 0.130 0.127 0.128  ||  -0.052 -0.051 -0.013 -0.021 0.077 0.047 0.025 0.032   || dis=0.00 || select=4/8
015/019-th : 0.120 0.120 0.122 0.122 0.132 0.127 0.129 0.127  ||  -0.034 -0.037 -0.024 -0.018 0.057 0.021 0.036 0.020   || dis=0.00 || select=4/8
016/019-th : 0.120 0.122 0.119 0.128 0.131 0.129 0.126 0.126  ||  -0.029 -0.007 -0.037 0.036 0.060 0.045 0.024 0.022    || dis=0.00 || select=4/8
017/019-th : 0.122 0.121 0.122 0.124 0.130 0.126 0.128 0.128  ||  -0.016 -0.023 -0.020 0.003 0.046 0.014 0.033 0.030    || dis=0.00 || select=4/8
018/019-th : 0.118 0.124 0.123 0.126 0.127 0.127 0.125 0.129  ||  -0.050 -0.001 -0.013 0.015 0.021 0.019 0.001 0.037    || dis=0.00 || select=7/8
[epoch=007/600] FLOP : 27.22 MB, ratio : 0.6669, Expected-ratio : 0.7000, Discrepancy : 0.002
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:45:16] [epoch=007/600][000/098] Time 0.37 (0.37) Data 0.30 (0.30) Loss 1.851 (1.851)  Prec@1 27.34 (27.34) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:45:22] [epoch=007/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.106 (2.119)  Prec@1 26.79 (29.98) Prec@5 74.40 (81.82) Size=[168, 3, 32, 32]
 **VALID** Prec@1 29.98 Prec@5 81.82 Error@1 70.02 Error@5 18.18 Loss:2.119
***[2020-01-29 05:45:22]*** VALID [epoch=007/600] loss = 2.119152, accuracy@1 = 29.98, accuracy@5 = 81.82 | Best-Valid-Acc@1=30.59, Error@1=69.41
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:45:22]*** start epoch=008/600 Time Left: [05:20:36], LR=[0.099956 ~ 0.099956], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=8, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.997850933742203, FLOP=40.81
[Search] : epoch=008/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:45:23] [epoch=008/600][000/098] Time 0.67 (0.67) Data 0.36 (0.36) Base-Loss 1.499 (1.499)  Prec@1 44.14 (44.14) Prec@5 89.84 (89.84) Acls-loss 1.524 (1.524) FLOP-Loss 0.000 (0.000) Arch-Loss 1.524 (1.524)
**TRAIN** [2020-01-29 05:45:48] [epoch=008/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.548 (1.493)  Prec@1 39.29 (44.80) Prec@5 92.26 (91.94) Acls-loss 1.480 (1.492) FLOP-Loss -2.405 (-0.016) Arch-Loss -3.330 (1.460)
 **TRAIN** Prec@1 44.80 Prec@5 91.94 Error@1 55.20 Error@5 8.06 Base-Loss:1.493, Arch-Loss=1.460
***[2020-01-29 05:45:48]*** TRAIN [epoch=008/600] base-loss = 1.492973, arch-loss = 1.459794, accuracy-1 = 44.80, accuracy-5 = 91.94
[epoch=008/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 11, 11, 14, 12, 12, 14, 28, 25, 28, 32, 32, 32, 64, 44, 44, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.194944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.341 0.307 0.352  ||  -0.0200 -0.1230 0.0133  || discrepancy=0.01 || select=2/3
001/003-th : 0.334 0.323 0.343  ||  -0.0112 -0.0437 0.0163  || discrepancy=0.01 || select=2/3
002/003-th : 0.343 0.299 0.358  ||  -0.0192 -0.1572 0.0245  || discrepancy=0.01 || select=2/3
-----------------------------------------------
000/019-th : 0.118 0.116 0.121 0.117 0.131 0.133 0.132 0.132  ||  -0.054 -0.067 -0.028 -0.064 0.052 0.066 0.058 0.061   || dis=0.00 || select=5/8
001/019-th : 0.122 0.122 0.122 0.122 0.129 0.127 0.127 0.129  ||  -0.019 -0.018 -0.020 -0.015 0.040 0.026 0.020 0.040   || dis=0.00 || select=4/8
002/019-th : 0.122 0.121 0.121 0.126 0.129 0.127 0.127 0.128  ||  -0.024 -0.038 -0.032 0.005 0.027 0.011 0.011 0.024    || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.124 0.125 0.125 0.127 0.127 0.127  ||  -0.024 -0.029 -0.009 -0.001 -0.005 0.011 0.012 0.012  || dis=0.00 || select=6/8
004/019-th : 0.122 0.124 0.124 0.125 0.126 0.127 0.126 0.126  ||  -0.022 -0.010 -0.005 0.003 0.008 0.015 0.009 0.013    || dis=0.00 || select=5/8
005/019-th : 0.122 0.123 0.124 0.123 0.127 0.128 0.125 0.127  ||  -0.022 -0.011 -0.004 -0.012 0.017 0.027 0.006 0.021   || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.125 0.126 0.126 0.127 0.126  ||  -0.017 -0.004 -0.003 0.003 0.010 0.009 0.019 0.012    || dis=0.00 || select=6/8
007/019-th : 0.120 0.121 0.122 0.121 0.130 0.129 0.130 0.127  ||  -0.039 -0.031 -0.019 -0.030 0.040 0.036 0.042 0.022   || dis=0.00 || select=6/8
008/019-th : 0.120 0.123 0.122 0.126 0.127 0.129 0.127 0.128  ||  -0.040 -0.017 -0.021 0.007 0.019 0.031 0.015 0.025    || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.124 0.122 0.126 0.127 0.129 0.128  ||  -0.018 -0.013 -0.008 -0.022 0.009 0.015 0.033 0.026   || dis=0.00 || select=6/8
010/019-th : 0.120 0.122 0.125 0.125 0.127 0.127 0.126 0.127  ||  -0.036 -0.015 0.004 0.010 0.023 0.024 0.019 0.026     || dis=0.00 || select=7/8
011/019-th : 0.125 0.122 0.122 0.124 0.127 0.126 0.126 0.128  ||  -0.005 -0.024 -0.024 -0.008 0.014 0.007 0.007 0.020   || dis=0.00 || select=7/8
012/019-th : 0.126 0.124 0.123 0.126 0.125 0.125 0.126 0.126  ||  0.010 -0.009 -0.014 0.009 0.005 0.001 0.007 0.010     || dis=0.00 || select=7/8
013/019-th : 0.119 0.122 0.119 0.124 0.125 0.128 0.131 0.132  ||  -0.050 -0.029 -0.047 -0.008 -0.004 0.021 0.049 0.055  || dis=0.00 || select=7/8
014/019-th : 0.116 0.117 0.121 0.121 0.136 0.131 0.128 0.129  ||  -0.063 -0.056 -0.021 -0.022 0.092 0.053 0.033 0.039   || dis=0.01 || select=4/8
015/019-th : 0.120 0.120 0.121 0.122 0.132 0.128 0.130 0.128  ||  -0.042 -0.042 -0.027 -0.019 0.054 0.025 0.042 0.026   || dis=0.00 || select=4/8
016/019-th : 0.118 0.121 0.118 0.128 0.133 0.130 0.126 0.126  ||  -0.040 -0.016 -0.038 0.044 0.077 0.057 0.028 0.024    || dis=0.00 || select=4/8
017/019-th : 0.121 0.120 0.120 0.124 0.131 0.127 0.129 0.128  ||  -0.022 -0.028 -0.033 0.000 0.059 0.022 0.039 0.034    || dis=0.00 || select=4/8
018/019-th : 0.117 0.123 0.122 0.125 0.129 0.127 0.126 0.131  ||  -0.062 -0.010 -0.018 0.002 0.034 0.021 0.013 0.047    || dis=0.00 || select=7/8
[epoch=008/600] FLOP : 28.19 MB, ratio : 0.6908, Expected-ratio : 0.7000, Discrepancy : 0.003
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:45:49] [epoch=008/600][000/098] Time 0.36 (0.36) Data 0.29 (0.29) Loss 1.595 (1.595)  Prec@1 38.67 (38.67) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:45:55] [epoch=008/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.130 (2.160)  Prec@1 31.55 (30.24) Prec@5 79.17 (81.68) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.24 Prec@5 81.68 Error@1 69.76 Error@5 18.32 Loss:2.160
***[2020-01-29 05:45:55]*** VALID [epoch=008/600] loss = 2.160050, accuracy@1 = 30.24, accuracy@5 = 81.68 | Best-Valid-Acc@1=30.59, Error@1=69.41
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:45:55]*** start epoch=009/600 Time Left: [05:19:57], LR=[0.099944 ~ 0.099944], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=9, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.9972801936568265, FLOP=40.81
[Search] : epoch=009/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:45:55] [epoch=009/600][000/098] Time 0.64 (0.64) Data 0.38 (0.38) Base-Loss 1.531 (1.531)  Prec@1 40.23 (40.23) Prec@5 89.84 (89.84) Acls-loss 1.652 (1.652) FLOP-Loss 0.000 (0.000) Arch-Loss 1.652 (1.652)
**TRAIN** [2020-01-29 05:46:20] [epoch=009/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.388 (1.456)  Prec@1 51.79 (46.42) Prec@5 92.86 (92.58) Acls-loss 1.512 (1.462) FLOP-Loss 0.000 (0.000) Arch-Loss 1.512 (1.463)
 **TRAIN** Prec@1 46.42 Prec@5 92.58 Error@1 53.58 Error@5 7.42 Base-Loss:1.456, Arch-Loss=1.463
***[2020-01-29 05:46:20]*** TRAIN [epoch=009/600] base-loss = 1.455941, arch-loss = 1.462534, accuracy-1 = 46.42, accuracy-5 = 92.58
[epoch=009/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 11, 14, 12, 12, 14, 22, 25, 28, 22, 32, 32, 64, 44, 44, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.449472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.343 0.301 0.356  ||  -0.0220 -0.1538 0.0162  || discrepancy=0.01 || select=2/3
001/003-th : 0.336 0.316 0.348  ||  -0.0138 -0.0765 0.0195  || discrepancy=0.01 || select=2/3
002/003-th : 0.344 0.295 0.362  ||  -0.0231 -0.1766 0.0290  || discrepancy=0.02 || select=2/3
-----------------------------------------------
000/019-th : 0.117 0.115 0.120 0.117 0.131 0.134 0.133 0.133  ||  -0.062 -0.078 -0.036 -0.065 0.056 0.075 0.069 0.068   || dis=0.00 || select=5/8
001/019-th : 0.121 0.121 0.121 0.122 0.130 0.128 0.127 0.130  ||  -0.023 -0.023 -0.025 -0.017 0.045 0.027 0.024 0.045   || dis=0.00 || select=7/8
002/019-th : 0.122 0.120 0.121 0.126 0.129 0.127 0.127 0.128  ||  -0.029 -0.039 -0.032 0.008 0.028 0.015 0.014 0.026    || dis=0.00 || select=4/8
003/019-th : 0.122 0.122 0.125 0.125 0.125 0.127 0.127 0.127  ||  -0.026 -0.031 -0.007 -0.005 -0.001 0.013 0.015 0.013  || dis=0.00 || select=6/8
004/019-th : 0.122 0.123 0.124 0.125 0.126 0.127 0.126 0.127  ||  -0.024 -0.013 -0.006 0.004 0.013 0.018 0.011 0.014    || dis=0.00 || select=5/8
005/019-th : 0.122 0.123 0.124 0.124 0.126 0.128 0.126 0.128  ||  -0.024 -0.013 -0.005 -0.004 0.008 0.029 0.008 0.023   || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.125 0.126 0.126 0.127 0.126  ||  -0.019 -0.007 -0.005 -0.000 0.012 0.011 0.021 0.014   || dis=0.00 || select=6/8
007/019-th : 0.119 0.120 0.122 0.121 0.130 0.130 0.130 0.128  ||  -0.044 -0.037 -0.023 -0.030 0.045 0.040 0.045 0.030   || dis=0.00 || select=4/8
008/019-th : 0.119 0.122 0.121 0.126 0.128 0.129 0.127 0.128  ||  -0.047 -0.020 -0.026 0.011 0.027 0.038 0.020 0.029    || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.123 0.122 0.126 0.127 0.129 0.128  ||  -0.020 -0.016 -0.012 -0.020 0.007 0.018 0.036 0.028   || dis=0.00 || select=6/8
010/019-th : 0.119 0.122 0.124 0.125 0.129 0.128 0.127 0.127  ||  -0.038 -0.018 -0.002 0.008 0.036 0.028 0.020 0.028    || dis=0.00 || select=4/8
011/019-th : 0.124 0.122 0.122 0.124 0.127 0.127 0.127 0.128  ||  -0.008 -0.029 -0.027 -0.011 0.013 0.014 0.012 0.024   || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.123 0.126 0.126 0.125 0.126 0.126  ||  0.008 -0.013 -0.016 0.009 0.007 0.003 0.010 0.013     || dis=0.00 || select=7/8
013/019-th : 0.118 0.121 0.118 0.124 0.124 0.129 0.132 0.134  ||  -0.059 -0.036 -0.055 -0.010 -0.011 0.029 0.055 0.066  || dis=0.00 || select=7/8
014/019-th : 0.116 0.116 0.121 0.121 0.136 0.131 0.129 0.130  ||  -0.070 -0.064 -0.025 -0.022 0.089 0.058 0.042 0.045   || dis=0.01 || select=4/8
015/019-th : 0.119 0.119 0.120 0.122 0.132 0.129 0.131 0.129  ||  -0.049 -0.046 -0.037 -0.022 0.059 0.033 0.047 0.033   || dis=0.00 || select=4/8
016/019-th : 0.117 0.120 0.118 0.128 0.135 0.130 0.127 0.126  ||  -0.049 -0.021 -0.041 0.042 0.093 0.060 0.034 0.027    || dis=0.01 || select=4/8
017/019-th : 0.120 0.120 0.119 0.123 0.130 0.128 0.130 0.129  ||  -0.030 -0.030 -0.041 -0.005 0.048 0.028 0.046 0.041   || dis=0.00 || select=4/8
018/019-th : 0.115 0.122 0.120 0.126 0.131 0.129 0.126 0.131  ||  -0.079 -0.014 -0.031 0.016 0.050 0.036 0.018 0.051    || dis=0.00 || select=7/8
[epoch=009/600] FLOP : 27.45 MB, ratio : 0.6726, Expected-ratio : 0.7000, Discrepancy : 0.003
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:46:20] [epoch=009/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.783 (1.783)  Prec@1 36.33 (36.33) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:46:26] [epoch=009/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.225 (2.068)  Prec@1 30.95 (32.24) Prec@5 72.02 (82.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.24 Prec@5 82.79 Error@1 67.76 Error@5 17.21 Loss:2.068
***[2020-01-29 05:46:26]*** VALID [epoch=009/600] loss = 2.068311, accuracy@1 = 32.24, accuracy@5 = 82.79 | Best-Valid-Acc@1=30.59, Error@1=69.41
Currently, the best validation accuracy found at 009-epoch :: acc@1=32.24, acc@5=82.79, error@1=67.76, error@5=17.21, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:46:26]*** start epoch=010/600 Time Left: [05:18:19], LR=[0.099931 ~ 0.099931], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=10, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.996642360148706, FLOP=40.81
[Search] : epoch=010/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:46:27] [epoch=010/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 1.461 (1.461)  Prec@1 48.44 (48.44) Prec@5 94.14 (94.14) Acls-loss 1.492 (1.492) FLOP-Loss 0.000 (0.000) Arch-Loss 1.492 (1.492)
**TRAIN** [2020-01-29 05:46:51] [epoch=010/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.482 (1.405)  Prec@1 44.64 (48.48) Prec@5 91.07 (93.18) Acls-loss 1.228 (1.417) FLOP-Loss 0.000 (-0.148) Arch-Loss 1.228 (1.120)
 **TRAIN** Prec@1 48.48 Prec@5 93.18 Error@1 51.52 Error@5 6.82 Base-Loss:1.405, Arch-Loss=1.120
***[2020-01-29 05:46:51]*** TRAIN [epoch=010/600] base-loss = 1.405194, arch-loss = 1.120128, accuracy-1 = 48.48, accuracy-5 = 93.18
[epoch=010/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 11, 14, 12, 12, 14, 28, 22, 28, 22, 32, 28, 64, 44, 57, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.632768)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.341 0.295 0.364  ||  -0.0353 -0.1821 0.0303  || discrepancy=0.02 || select=2/3
001/003-th : 0.335 0.309 0.356  ||  -0.0278 -0.1102 0.0341  || discrepancy=0.02 || select=2/3
002/003-th : 0.340 0.291 0.369  ||  -0.0377 -0.1940 0.0442  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.115 0.113 0.119 0.115 0.131 0.136 0.136 0.136  ||  -0.082 -0.096 -0.046 -0.083 0.051 0.093 0.088 0.088   || dis=0.00 || select=5/8
001/019-th : 0.120 0.120 0.119 0.121 0.131 0.130 0.129 0.132  ||  -0.038 -0.038 -0.040 -0.028 0.051 0.043 0.039 0.060   || dis=0.00 || select=7/8
002/019-th : 0.119 0.118 0.120 0.125 0.130 0.129 0.129 0.130  ||  -0.045 -0.054 -0.044 -0.002 0.040 0.033 0.029 0.039   || dis=0.00 || select=4/8
003/019-th : 0.121 0.120 0.123 0.124 0.127 0.128 0.129 0.129  ||  -0.039 -0.045 -0.018 -0.015 0.010 0.023 0.028 0.027   || dis=0.00 || select=6/8
004/019-th : 0.120 0.121 0.122 0.123 0.128 0.128 0.128 0.128  ||  -0.037 -0.029 -0.019 -0.015 0.028 0.030 0.027 0.028   || dis=0.00 || select=5/8
005/019-th : 0.120 0.121 0.123 0.122 0.128 0.130 0.127 0.129  ||  -0.040 -0.029 -0.015 -0.018 0.024 0.042 0.022 0.038   || dis=0.00 || select=5/8
006/019-th : 0.121 0.122 0.122 0.123 0.127 0.128 0.129 0.128  ||  -0.033 -0.020 -0.019 -0.016 0.023 0.025 0.035 0.029   || dis=0.00 || select=6/8
007/019-th : 0.117 0.118 0.120 0.117 0.132 0.132 0.133 0.131  ||  -0.060 -0.057 -0.041 -0.065 0.061 0.059 0.062 0.049   || dis=0.00 || select=6/8
008/019-th : 0.116 0.119 0.119 0.124 0.132 0.131 0.129 0.130  ||  -0.066 -0.039 -0.043 0.000 0.061 0.058 0.037 0.044    || dis=0.00 || select=4/8
009/019-th : 0.120 0.121 0.121 0.121 0.127 0.128 0.131 0.130  ||  -0.036 -0.031 -0.026 -0.029 0.023 0.031 0.051 0.043   || dis=0.00 || select=6/8
010/019-th : 0.118 0.120 0.122 0.123 0.130 0.129 0.128 0.129  ||  -0.052 -0.031 -0.016 -0.009 0.048 0.039 0.034 0.041   || dis=0.00 || select=4/8
011/019-th : 0.122 0.119 0.120 0.123 0.128 0.129 0.129 0.130  ||  -0.024 -0.049 -0.038 -0.013 0.027 0.031 0.030 0.037   || dis=0.00 || select=7/8
012/019-th : 0.124 0.121 0.121 0.125 0.128 0.127 0.128 0.128  ||  -0.006 -0.029 -0.029 0.001 0.025 0.017 0.026 0.025    || dis=0.00 || select=6/8
013/019-th : 0.116 0.119 0.116 0.123 0.126 0.130 0.135 0.136  ||  -0.077 -0.052 -0.072 -0.014 0.005 0.036 0.074 0.084   || dis=0.00 || select=7/8
014/019-th : 0.113 0.114 0.118 0.121 0.137 0.134 0.132 0.132  ||  -0.092 -0.083 -0.044 -0.024 0.102 0.079 0.062 0.062   || dis=0.00 || select=4/8
015/019-th : 0.116 0.117 0.118 0.121 0.132 0.131 0.133 0.131  ||  -0.070 -0.067 -0.055 -0.028 0.059 0.054 0.066 0.053   || dis=0.00 || select=6/8
016/019-th : 0.114 0.118 0.115 0.127 0.135 0.133 0.129 0.128  ||  -0.072 -0.034 -0.059 0.036 0.100 0.080 0.055 0.041    || dis=0.00 || select=4/8
017/019-th : 0.118 0.118 0.117 0.121 0.133 0.129 0.132 0.132  ||  -0.049 -0.050 -0.059 -0.022 0.073 0.042 0.062 0.061   || dis=0.00 || select=4/8
018/019-th : 0.113 0.120 0.119 0.125 0.130 0.131 0.129 0.134  ||  -0.096 -0.032 -0.048 0.003 0.044 0.048 0.034 0.075    || dis=0.00 || select=7/8
[epoch=010/600] FLOP : 27.63 MB, ratio : 0.6771, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:46:52] [epoch=010/600][000/098] Time 0.39 (0.39) Data 0.32 (0.32) Loss 1.808 (1.808)  Prec@1 31.25 (31.25) Prec@5 84.38 (84.38) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:46:58] [epoch=010/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.011 (2.209)  Prec@1 31.55 (30.14) Prec@5 79.17 (79.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.14 Prec@5 79.62 Error@1 69.86 Error@5 20.38 Loss:2.209
***[2020-01-29 05:46:58]*** VALID [epoch=010/600] loss = 2.209147, accuracy@1 = 30.14, accuracy@5 = 79.62 | Best-Valid-Acc@1=32.24, Error@1=67.76
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:46:58]*** start epoch=011/600 Time Left: [05:17:00], LR=[0.099917 ~ 0.099917], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=11, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.9959374507043695, FLOP=40.81
[Search] : epoch=011/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:46:58] [epoch=011/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 1.345 (1.345)  Prec@1 52.34 (52.34) Prec@5 94.53 (94.53) Acls-loss 1.380 (1.380) FLOP-Loss 0.000 (0.000) Arch-Loss 1.380 (1.380)
**TRAIN** [2020-01-29 05:47:23] [epoch=011/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.420 (1.365)  Prec@1 46.43 (50.26) Prec@5 91.07 (93.34) Acls-loss 1.351 (1.384) FLOP-Loss 0.000 (0.025) Arch-Loss 1.351 (1.434)
 **TRAIN** Prec@1 50.26 Prec@5 93.34 Error@1 49.74 Error@5 6.66 Base-Loss:1.365, Arch-Loss=1.434
***[2020-01-29 05:47:23]*** TRAIN [epoch=011/600] base-loss = 1.365312, arch-loss = 1.434049, accuracy-1 = 50.26, accuracy-5 = 93.34
[epoch=011/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 14, 12, 12, 14, 22, 25, 28, 25, 32, 22, 64, 44, 57, 44, 44, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.581568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.342 0.294 0.364  ||  -0.0335 -0.1869 0.0290  || discrepancy=0.02 || select=2/3
001/003-th : 0.338 0.304 0.359  ||  -0.0265 -0.1334 0.0335  || discrepancy=0.02 || select=2/3
002/003-th : 0.341 0.289 0.370  ||  -0.0376 -0.2013 0.0447  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.114 0.111 0.120 0.115 0.129 0.136 0.137 0.136  ||  -0.086 -0.109 -0.037 -0.074 0.039 0.093 0.098 0.091   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.120 0.121 0.130 0.129 0.129 0.132  ||  -0.035 -0.040 -0.039 -0.022 0.043 0.039 0.039 0.060   || dis=0.00 || select=7/8
002/019-th : 0.119 0.118 0.120 0.125 0.131 0.129 0.128 0.130  ||  -0.048 -0.055 -0.039 0.003 0.045 0.035 0.028 0.039    || dis=0.00 || select=4/8
003/019-th : 0.121 0.120 0.123 0.124 0.126 0.128 0.129 0.129  ||  -0.038 -0.045 -0.017 -0.008 0.007 0.020 0.028 0.026   || dis=0.00 || select=6/8
004/019-th : 0.120 0.121 0.122 0.123 0.128 0.128 0.128 0.128  ||  -0.037 -0.027 -0.021 -0.014 0.026 0.028 0.026 0.028   || dis=0.00 || select=5/8
005/019-th : 0.120 0.122 0.123 0.123 0.126 0.130 0.127 0.129  ||  -0.039 -0.025 -0.012 -0.014 0.014 0.043 0.018 0.037   || dis=0.00 || select=5/8
006/019-th : 0.121 0.122 0.123 0.123 0.127 0.127 0.129 0.128  ||  -0.032 -0.019 -0.017 -0.011 0.022 0.020 0.032 0.028   || dis=0.00 || select=6/8
007/019-th : 0.117 0.117 0.119 0.115 0.135 0.133 0.133 0.131  ||  -0.061 -0.063 -0.047 -0.080 0.076 0.066 0.062 0.053   || dis=0.00 || select=4/8
008/019-th : 0.116 0.119 0.118 0.125 0.132 0.132 0.129 0.129  ||  -0.068 -0.043 -0.049 0.012 0.062 0.064 0.040 0.043    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.121 0.121 0.128 0.129 0.131 0.130  ||  -0.036 -0.031 -0.026 -0.032 0.024 0.032 0.049 0.043   || dis=0.00 || select=6/8
010/019-th : 0.118 0.120 0.122 0.125 0.129 0.129 0.128 0.129  ||  -0.053 -0.032 -0.018 0.006 0.042 0.042 0.034 0.040    || dis=0.00 || select=5/8
011/019-th : 0.122 0.119 0.120 0.125 0.127 0.129 0.129 0.130  ||  -0.024 -0.049 -0.037 -0.003 0.014 0.028 0.031 0.038   || dis=0.00 || select=7/8
012/019-th : 0.124 0.121 0.121 0.125 0.128 0.126 0.128 0.128  ||  -0.005 -0.028 -0.028 0.002 0.026 0.011 0.024 0.025    || dis=0.00 || select=4/8
013/019-th : 0.115 0.118 0.116 0.122 0.126 0.130 0.136 0.136  ||  -0.081 -0.056 -0.078 -0.023 0.005 0.041 0.081 0.087   || dis=0.00 || select=7/8
014/019-th : 0.112 0.113 0.118 0.120 0.138 0.134 0.133 0.132  ||  -0.099 -0.088 -0.043 -0.028 0.110 0.081 0.071 0.063   || dis=0.00 || select=4/8
015/019-th : 0.115 0.116 0.117 0.121 0.133 0.133 0.134 0.132  ||  -0.075 -0.071 -0.064 -0.027 0.066 0.064 0.071 0.056   || dis=0.00 || select=6/8
016/019-th : 0.113 0.118 0.115 0.127 0.137 0.132 0.130 0.128  ||  -0.077 -0.036 -0.063 0.037 0.111 0.078 0.057 0.043    || dis=0.01 || select=4/8
017/019-th : 0.118 0.118 0.116 0.122 0.132 0.129 0.132 0.132  ||  -0.051 -0.049 -0.064 -0.021 0.066 0.040 0.062 0.064   || dis=0.00 || select=4/8
018/019-th : 0.112 0.120 0.119 0.123 0.130 0.131 0.129 0.135  ||  -0.103 -0.033 -0.043 -0.011 0.046 0.048 0.036 0.081   || dis=0.00 || select=7/8
[epoch=011/600] FLOP : 27.58 MB, ratio : 0.6758, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:47:23] [epoch=011/600][000/098] Time 0.39 (0.39) Data 0.32 (0.32) Loss 2.273 (2.273)  Prec@1 34.38 (34.38) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:47:29] [epoch=011/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.009 (2.283)  Prec@1 32.74 (31.01) Prec@5 84.52 (79.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 31.01 Prec@5 79.84 Error@1 68.99 Error@5 20.16 Loss:2.283
***[2020-01-29 05:47:29]*** VALID [epoch=011/600] loss = 2.282584, accuracy@1 = 31.01, accuracy@5 = 79.84 | Best-Valid-Acc@1=32.24, Error@1=67.76
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:47:29]*** start epoch=012/600 Time Left: [05:15:53], LR=[0.099901 ~ 0.099901], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=12, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.995165484649266, FLOP=40.81
[Search] : epoch=012/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:47:30] [epoch=012/600][000/098] Time 0.78 (0.78) Data 0.39 (0.39) Base-Loss 1.328 (1.328)  Prec@1 53.12 (53.12) Prec@5 91.02 (91.02) Acls-loss 1.334 (1.334) FLOP-Loss 0.000 (0.000) Arch-Loss 1.334 (1.334)
**TRAIN** [2020-01-29 05:47:55] [epoch=012/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.323 (1.326)  Prec@1 55.36 (52.39) Prec@5 93.45 (93.77) Acls-loss 1.340 (1.337) FLOP-Loss -2.413 (0.157) Arch-Loss -3.486 (1.651)
 **TRAIN** Prec@1 52.39 Prec@5 93.77 Error@1 47.61 Error@5 6.23 Base-Loss:1.326, Arch-Loss=1.651
***[2020-01-29 05:47:55]*** TRAIN [epoch=012/600] base-loss = 1.326244, arch-loss = 1.651253, accuracy-1 = 52.39, accuracy-5 = 93.77
[epoch=012/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 11, 14, 12, 12, 14, 22, 22, 28, 25, 32, 22, 64, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.23744)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.346 0.297 0.358  ||  -0.0190 -0.1728 0.0147  || discrepancy=0.01 || select=2/3
001/003-th : 0.342 0.306 0.353  ||  -0.0126 -0.1233 0.0197  || discrepancy=0.01 || select=2/3
002/003-th : 0.346 0.288 0.366  ||  -0.0250 -0.2058 0.0327  || discrepancy=0.02 || select=2/3
-----------------------------------------------
000/019-th : 0.115 0.112 0.121 0.117 0.127 0.136 0.136 0.135  ||  -0.079 -0.105 -0.028 -0.062 0.020 0.091 0.090 0.085   || dis=0.00 || select=5/8
001/019-th : 0.122 0.121 0.121 0.122 0.128 0.128 0.128 0.130  ||  -0.021 -0.028 -0.027 -0.018 0.029 0.025 0.028 0.047   || dis=0.00 || select=7/8
002/019-th : 0.120 0.119 0.122 0.127 0.129 0.128 0.127 0.128  ||  -0.039 -0.044 -0.025 0.016 0.036 0.024 0.018 0.028    || dis=0.00 || select=4/8
003/019-th : 0.122 0.121 0.125 0.126 0.124 0.127 0.127 0.127  ||  -0.025 -0.033 -0.002 0.004 -0.008 0.010 0.015 0.013   || dis=0.00 || select=6/8
004/019-th : 0.121 0.123 0.124 0.125 0.127 0.127 0.126 0.126  ||  -0.026 -0.015 -0.003 0.003 0.016 0.018 0.013 0.014    || dis=0.00 || select=5/8
005/019-th : 0.121 0.123 0.125 0.126 0.124 0.128 0.125 0.128  ||  -0.027 -0.012 0.003 0.009 -0.003 0.026 0.004 0.023    || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.125 0.126 0.125 0.127 0.126  ||  -0.019 -0.006 -0.001 0.003 0.011 0.006 0.018 0.014    || dis=0.00 || select=6/8
007/019-th : 0.119 0.119 0.120 0.116 0.133 0.132 0.131 0.131  ||  -0.050 -0.051 -0.038 -0.076 0.062 0.053 0.051 0.045   || dis=0.00 || select=4/8
008/019-th : 0.117 0.120 0.119 0.127 0.132 0.131 0.127 0.128  ||  -0.057 -0.035 -0.036 0.023 0.062 0.054 0.028 0.032    || dis=0.00 || select=4/8
009/019-th : 0.121 0.122 0.123 0.123 0.127 0.127 0.129 0.128  ||  -0.026 -0.018 -0.015 -0.007 0.019 0.022 0.035 0.030   || dis=0.00 || select=6/8
010/019-th : 0.119 0.122 0.124 0.126 0.128 0.128 0.126 0.127  ||  -0.042 -0.019 -0.003 0.020 0.028 0.034 0.020 0.027    || dis=0.00 || select=5/8
011/019-th : 0.123 0.121 0.121 0.128 0.125 0.127 0.127 0.128  ||  -0.012 -0.035 -0.027 0.023 -0.001 0.017 0.017 0.024   || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.123 0.126 0.127 0.124 0.126 0.126  ||  0.010 -0.014 -0.011 0.013 0.018 -0.006 0.011 0.010    || dis=0.00 || select=4/8
013/019-th : 0.117 0.119 0.116 0.124 0.125 0.129 0.135 0.135  ||  -0.069 -0.049 -0.074 -0.010 -0.001 0.028 0.073 0.079  || dis=0.00 || select=7/8
014/019-th : 0.112 0.114 0.120 0.123 0.136 0.133 0.131 0.130  ||  -0.096 -0.082 -0.031 -0.005 0.099 0.077 0.063 0.055   || dis=0.00 || select=4/8
015/019-th : 0.116 0.117 0.118 0.123 0.132 0.131 0.132 0.130  ||  -0.066 -0.058 -0.056 -0.015 0.061 0.050 0.061 0.046   || dis=0.00 || select=6/8
016/019-th : 0.114 0.119 0.117 0.130 0.136 0.130 0.128 0.126  ||  -0.073 -0.025 -0.046 0.058 0.105 0.065 0.048 0.031    || dis=0.01 || select=4/8
017/019-th : 0.119 0.120 0.119 0.123 0.129 0.127 0.131 0.132  ||  -0.043 -0.035 -0.042 -0.010 0.037 0.023 0.049 0.056   || dis=0.00 || select=7/8
018/019-th : 0.113 0.121 0.121 0.125 0.133 0.128 0.127 0.134  ||  -0.096 -0.028 -0.030 0.006 0.065 0.029 0.020 0.074    || dis=0.00 || select=7/8
[epoch=012/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.003
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:47:55] [epoch=012/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.581 (2.581)  Prec@1 29.30 (29.30) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:48:01] [epoch=012/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.860 (2.252)  Prec@1 23.81 (30.72) Prec@5 82.14 (80.61) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.72 Prec@5 80.61 Error@1 69.28 Error@5 19.39 Loss:2.252
***[2020-01-29 05:48:01]*** VALID [epoch=012/600] loss = 2.251685, accuracy@1 = 30.72, accuracy@5 = 80.61 | Best-Valid-Acc@1=32.24, Error@1=67.76
[GPU-Memory-Usage on cuda:0 is 517996544 bytes, 517996.54 KB, 518.00 MB, 0.52 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:48:01]*** start epoch=013/600 Time Left: [05:14:52], LR=[0.099884 ~ 0.099884], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=13, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.994326483147233, FLOP=40.81
[Search] : epoch=013/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:48:02] [epoch=013/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 1.423 (1.423)  Prec@1 54.30 (54.30) Prec@5 92.58 (92.58) Acls-loss 1.357 (1.357) FLOP-Loss 0.000 (0.000) Arch-Loss 1.357 (1.357)
**TRAIN** [2020-01-29 05:48:26] [epoch=013/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.361 (1.299)  Prec@1 49.40 (52.87) Prec@5 98.21 (94.28) Acls-loss 1.296 (1.308) FLOP-Loss 0.000 (0.050) Arch-Loss 1.296 (1.407)
 **TRAIN** Prec@1 52.87 Prec@5 94.28 Error@1 47.13 Error@5 5.72 Base-Loss:1.299, Arch-Loss=1.407
***[2020-01-29 05:48:26]*** TRAIN [epoch=013/600] base-loss = 1.298974, arch-loss = 1.407167, accuracy-1 = 52.87, accuracy-5 = 94.28
[epoch=013/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 11, 14, 12, 12, 14, 22, 22, 28, 25, 32, 19, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.348 0.293 0.359  ||  -0.0169 -0.1882 0.0134  || discrepancy=0.01 || select=2/3
001/003-th : 0.345 0.300 0.355  ||  -0.0102 -0.1508 0.0182  || discrepancy=0.01 || select=2/3
002/003-th : 0.347 0.283 0.370  ||  -0.0271 -0.2334 0.0360  || discrepancy=0.02 || select=2/3
-----------------------------------------------
000/019-th : 0.114 0.112 0.120 0.117 0.129 0.137 0.136 0.135  ||  -0.087 -0.104 -0.034 -0.063 0.039 0.098 0.091 0.087   || dis=0.00 || select=5/8
001/019-th : 0.122 0.121 0.120 0.122 0.127 0.128 0.128 0.131  ||  -0.020 -0.026 -0.036 -0.018 0.019 0.028 0.029 0.047   || dis=0.00 || select=7/8
002/019-th : 0.120 0.120 0.122 0.127 0.128 0.127 0.127 0.128  ||  -0.038 -0.041 -0.022 0.019 0.029 0.020 0.017 0.027    || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.126 0.126 0.124 0.126 0.127 0.127  ||  -0.023 -0.031 0.002 0.008 -0.012 0.006 0.012 0.011    || dis=0.00 || select=6/8
004/019-th : 0.122 0.123 0.124 0.125 0.127 0.127 0.126 0.126  ||  -0.025 -0.012 -0.005 0.001 0.015 0.017 0.012 0.013    || dis=0.00 || select=5/8
005/019-th : 0.121 0.123 0.125 0.126 0.125 0.128 0.125 0.127  ||  -0.026 -0.013 0.002 0.010 0.004 0.026 0.005 0.021     || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.125 0.125 0.125 0.125 0.127 0.126  ||  -0.018 -0.004 -0.000 0.005 0.007 0.004 0.018 0.013    || dis=0.00 || select=6/8
007/019-th : 0.119 0.119 0.120 0.115 0.133 0.132 0.132 0.132  ||  -0.050 -0.050 -0.045 -0.088 0.058 0.052 0.052 0.050   || dis=0.00 || select=4/8
008/019-th : 0.117 0.119 0.120 0.127 0.132 0.131 0.128 0.128  ||  -0.060 -0.040 -0.035 0.022 0.063 0.055 0.032 0.034    || dis=0.00 || select=4/8
009/019-th : 0.121 0.122 0.123 0.123 0.126 0.127 0.129 0.128  ||  -0.027 -0.018 -0.014 -0.008 0.016 0.022 0.036 0.031   || dis=0.00 || select=6/8
010/019-th : 0.119 0.122 0.124 0.128 0.126 0.128 0.126 0.127  ||  -0.042 -0.019 0.001 0.029 0.017 0.031 0.019 0.026     || dis=0.00 || select=5/8
011/019-th : 0.123 0.121 0.122 0.127 0.124 0.127 0.128 0.128  ||  -0.013 -0.035 -0.026 0.018 -0.011 0.017 0.020 0.025   || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.123 0.126 0.126 0.124 0.126 0.126  ||  0.011 -0.010 -0.010 0.013 0.008 -0.007 0.007 0.008    || dis=0.00 || select=3/8
013/019-th : 0.117 0.119 0.116 0.121 0.126 0.129 0.136 0.136  ||  -0.071 -0.054 -0.079 -0.031 0.004 0.031 0.083 0.082   || dis=0.00 || select=6/8
014/019-th : 0.111 0.112 0.120 0.123 0.138 0.134 0.132 0.130  ||  -0.100 -0.095 -0.025 -0.004 0.115 0.084 0.068 0.055   || dis=0.00 || select=4/8
015/019-th : 0.117 0.117 0.118 0.121 0.132 0.131 0.134 0.131  ||  -0.068 -0.064 -0.059 -0.030 0.059 0.049 0.070 0.051   || dis=0.00 || select=6/8
016/019-th : 0.113 0.119 0.118 0.130 0.135 0.131 0.128 0.127  ||  -0.083 -0.027 -0.035 0.060 0.100 0.066 0.048 0.034    || dis=0.00 || select=4/8
017/019-th : 0.119 0.120 0.120 0.123 0.127 0.128 0.131 0.132  ||  -0.049 -0.037 -0.040 -0.012 0.023 0.025 0.053 0.061   || dis=0.00 || select=7/8
018/019-th : 0.112 0.121 0.120 0.125 0.131 0.128 0.128 0.136  ||  -0.108 -0.031 -0.035 0.004 0.053 0.024 0.026 0.090    || dis=0.01 || select=7/8
[epoch=013/600] FLOP : 27.62 MB, ratio : 0.6768, Expected-ratio : 0.7000, Discrepancy : 0.003
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:48:26] [epoch=013/600][000/098] Time 0.36 (0.36) Data 0.29 (0.29) Loss 2.069 (2.069)  Prec@1 39.06 (39.06) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:48:32] [epoch=013/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.761 (2.183)  Prec@1 35.12 (32.94) Prec@5 86.90 (82.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.94 Prec@5 82.06 Error@1 67.06 Error@5 17.94 Loss:2.183
***[2020-01-29 05:48:32]*** VALID [epoch=013/600] loss = 2.183268, accuracy@1 = 32.94, accuracy@5 = 82.06 | Best-Valid-Acc@1=32.24, Error@1=67.76
Currently, the best validation accuracy found at 013-epoch :: acc@1=32.94, acc@5=82.06, error@1=67.06, error@5=17.94, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 532676608 bytes, 532676.61 KB, 532.68 MB, 0.53 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:48:32]*** start epoch=014/600 Time Left: [05:13:53], LR=[0.099866 ~ 0.099866], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=14, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.993420469199922, FLOP=40.81
[Search] : epoch=014/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:48:33] [epoch=014/600][000/098] Time 0.65 (0.65) Data 0.38 (0.38) Base-Loss 1.364 (1.364)  Prec@1 51.56 (51.56) Prec@5 93.36 (93.36) Acls-loss 1.271 (1.271) FLOP-Loss 0.000 (0.000) Arch-Loss 1.271 (1.271)
**TRAIN** [2020-01-29 05:48:57] [epoch=014/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.235 (1.279)  Prec@1 53.57 (53.88) Prec@5 94.64 (94.30) Acls-loss 1.236 (1.291) FLOP-Loss 0.000 (0.025) Arch-Loss 1.236 (1.341)
 **TRAIN** Prec@1 53.88 Prec@5 94.30 Error@1 46.12 Error@5 5.70 Base-Loss:1.279, Arch-Loss=1.341
***[2020-01-29 05:48:57]*** TRAIN [epoch=014/600] base-loss = 1.279247, arch-loss = 1.340981, accuracy-1 = 53.88, accuracy-5 = 94.30
[epoch=014/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 14, 11, 12, 14, 22, 25, 28, 19, 32, 19, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 26.993728)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.349 0.293 0.359  ||  -0.0156 -0.1914 0.0125  || discrepancy=0.01 || select=2/3
001/003-th : 0.348 0.295 0.357  ||  -0.0089 -0.1716 0.0177  || discrepancy=0.01 || select=2/3
002/003-th : 0.348 0.280 0.372  ||  -0.0281 -0.2477 0.0379  || discrepancy=0.02 || select=2/3
-----------------------------------------------
000/019-th : 0.113 0.111 0.120 0.118 0.128 0.137 0.137 0.136  ||  -0.092 -0.116 -0.035 -0.053 0.030 0.100 0.102 0.091   || dis=0.00 || select=6/8
001/019-th : 0.122 0.122 0.120 0.122 0.127 0.128 0.129 0.131  ||  -0.020 -0.025 -0.039 -0.018 0.017 0.027 0.031 0.047   || dis=0.00 || select=7/8
002/019-th : 0.120 0.120 0.122 0.126 0.128 0.128 0.127 0.128  ||  -0.039 -0.040 -0.020 0.011 0.028 0.023 0.019 0.026    || dis=0.00 || select=4/8
003/019-th : 0.122 0.122 0.126 0.126 0.125 0.126 0.127 0.127  ||  -0.024 -0.030 0.005 0.007 -0.004 0.006 0.012 0.010    || dis=0.00 || select=6/8
004/019-th : 0.122 0.123 0.124 0.125 0.127 0.127 0.126 0.126  ||  -0.024 -0.014 -0.002 -0.001 0.019 0.016 0.013 0.012   || dis=0.00 || select=4/8
005/019-th : 0.121 0.123 0.125 0.126 0.125 0.127 0.126 0.127  ||  -0.027 -0.012 0.000 0.014 0.003 0.023 0.008 0.019     || dis=0.00 || select=5/8
006/019-th : 0.122 0.124 0.124 0.126 0.126 0.124 0.127 0.126  ||  -0.019 -0.005 -0.001 0.010 0.013 -0.001 0.019 0.013   || dis=0.00 || select=6/8
007/019-th : 0.119 0.119 0.118 0.115 0.132 0.132 0.132 0.132  ||  -0.048 -0.051 -0.057 -0.082 0.055 0.052 0.055 0.052   || dis=0.00 || select=4/8
008/019-th : 0.116 0.118 0.119 0.128 0.131 0.132 0.128 0.128  ||  -0.061 -0.046 -0.040 0.033 0.058 0.064 0.034 0.034    || dis=0.00 || select=5/8
009/019-th : 0.121 0.122 0.122 0.123 0.128 0.127 0.129 0.128  ||  -0.025 -0.022 -0.016 -0.013 0.026 0.021 0.036 0.032   || dis=0.00 || select=6/8
010/019-th : 0.118 0.121 0.124 0.128 0.127 0.128 0.126 0.127  ||  -0.044 -0.024 0.002 0.037 0.029 0.037 0.019 0.024     || dis=0.00 || select=3/8
011/019-th : 0.123 0.121 0.122 0.126 0.123 0.127 0.128 0.129  ||  -0.017 -0.032 -0.022 0.009 -0.016 0.015 0.023 0.027   || dis=0.00 || select=7/8
012/019-th : 0.126 0.124 0.123 0.126 0.126 0.124 0.125 0.126  ||  0.013 -0.008 -0.011 0.014 0.008 -0.009 0.006 0.007    || dis=0.00 || select=3/8
013/019-th : 0.117 0.118 0.115 0.121 0.126 0.130 0.137 0.137  ||  -0.072 -0.060 -0.087 -0.038 0.005 0.035 0.089 0.086   || dis=0.00 || select=6/8
014/019-th : 0.110 0.112 0.120 0.123 0.139 0.134 0.133 0.130  ||  -0.111 -0.098 -0.028 -0.001 0.121 0.085 0.077 0.059   || dis=0.01 || select=4/8
015/019-th : 0.116 0.116 0.117 0.121 0.131 0.131 0.134 0.132  ||  -0.070 -0.069 -0.061 -0.028 0.049 0.047 0.074 0.057   || dis=0.00 || select=6/8
016/019-th : 0.111 0.118 0.118 0.132 0.135 0.130 0.129 0.127  ||  -0.092 -0.032 -0.031 0.077 0.101 0.063 0.051 0.036    || dis=0.00 || select=4/8
017/019-th : 0.119 0.120 0.120 0.122 0.127 0.128 0.132 0.134  ||  -0.052 -0.041 -0.042 -0.026 0.016 0.023 0.057 0.069   || dis=0.00 || select=7/8
018/019-th : 0.111 0.120 0.121 0.125 0.131 0.127 0.127 0.137  ||  -0.113 -0.033 -0.026 0.002 0.053 0.023 0.016 0.098    || dis=0.01 || select=7/8
[epoch=014/600] FLOP : 26.99 MB, ratio : 0.6614, Expected-ratio : 0.7000, Discrepancy : 0.003
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:48:58] [epoch=014/600][000/098] Time 0.37 (0.37) Data 0.30 (0.30) Loss 2.012 (2.012)  Prec@1 39.06 (39.06) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:49:04] [epoch=014/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.965 (2.205)  Prec@1 34.52 (34.42) Prec@5 82.74 (82.36) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.42 Prec@5 82.36 Error@1 65.58 Error@5 17.64 Loss:2.205
***[2020-01-29 05:49:04]*** VALID [epoch=014/600] loss = 2.204882, accuracy@1 = 34.42, accuracy@5 = 82.36 | Best-Valid-Acc@1=32.94, Error@1=67.06
Currently, the best validation accuracy found at 014-epoch :: acc@1=34.42, acc@5=82.36, error@1=65.58, error@5=17.64, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 532676608 bytes, 532676.61 KB, 532.68 MB, 0.53 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:49:04]*** start epoch=015/600 Time Left: [05:12:55], LR=[0.099846 ~ 0.099846], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=15, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.992447467646164, FLOP=40.81
[Search] : epoch=015/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:49:05] [epoch=015/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 1.273 (1.273)  Prec@1 57.03 (57.03) Prec@5 95.70 (95.70) Acls-loss 1.245 (1.245) FLOP-Loss 0.000 (0.000) Arch-Loss 1.245 (1.245)
**TRAIN** [2020-01-29 05:49:28] [epoch=015/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 1.434 (1.255)  Prec@1 54.76 (55.03) Prec@5 89.88 (94.44) Acls-loss 1.122 (1.269) FLOP-Loss -2.420 (-0.016) Arch-Loss -3.718 (1.237)
 **TRAIN** Prec@1 55.03 Prec@5 94.44 Error@1 44.97 Error@5 5.56 Base-Loss:1.255, Arch-Loss=1.237
***[2020-01-29 05:49:29]*** TRAIN [epoch=015/600] base-loss = 1.255059, arch-loss = 1.236849, accuracy-1 = 55.03, accuracy-5 = 94.44
[epoch=015/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 14, 11, 12, 14, 28, 25, 28, 19, 32, 9, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 26.48288)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.350 0.287 0.363  ||  -0.0191 -0.2176 0.0171  || discrepancy=0.01 || select=2/3
001/003-th : 0.349 0.289 0.361  ||  -0.0121 -0.2007 0.0219  || discrepancy=0.01 || select=2/3
002/003-th : 0.348 0.276 0.375  ||  -0.0325 -0.2632 0.0432  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.112 0.110 0.121 0.117 0.128 0.138 0.139 0.137  ||  -0.104 -0.124 -0.028 -0.057 0.031 0.107 0.111 0.097   || dis=0.00 || select=6/8
001/019-th : 0.121 0.121 0.120 0.122 0.126 0.129 0.129 0.131  ||  -0.026 -0.027 -0.041 -0.022 0.012 0.033 0.035 0.052   || dis=0.00 || select=7/8
002/019-th : 0.119 0.119 0.122 0.126 0.129 0.128 0.127 0.128  ||  -0.043 -0.044 -0.022 0.012 0.035 0.028 0.021 0.029    || dis=0.00 || select=4/8
003/019-th : 0.122 0.121 0.126 0.126 0.125 0.126 0.127 0.127  ||  -0.026 -0.034 0.004 0.007 -0.006 0.008 0.015 0.013    || dis=0.00 || select=6/8
004/019-th : 0.121 0.122 0.124 0.124 0.128 0.127 0.127 0.127  ||  -0.028 -0.019 -0.006 -0.004 0.027 0.018 0.017 0.015   || dis=0.00 || select=4/8
005/019-th : 0.121 0.123 0.124 0.126 0.125 0.128 0.126 0.127  ||  -0.030 -0.016 -0.006 0.016 0.006 0.025 0.012 0.022    || dis=0.00 || select=5/8
006/019-th : 0.122 0.123 0.124 0.125 0.127 0.125 0.128 0.127  ||  -0.024 -0.009 -0.006 0.000 0.020 0.003 0.024 0.017    || dis=0.00 || select=6/8
007/019-th : 0.119 0.119 0.116 0.115 0.133 0.132 0.133 0.133  ||  -0.051 -0.053 -0.073 -0.085 0.059 0.054 0.062 0.057   || dis=0.00 || select=6/8
008/019-th : 0.115 0.117 0.119 0.127 0.132 0.133 0.128 0.129  ||  -0.069 -0.055 -0.038 0.029 0.064 0.072 0.038 0.040    || dis=0.00 || select=5/8
009/019-th : 0.121 0.121 0.122 0.123 0.127 0.128 0.129 0.129  ||  -0.031 -0.027 -0.018 -0.013 0.021 0.025 0.040 0.038   || dis=0.00 || select=6/8
010/019-th : 0.118 0.120 0.123 0.129 0.128 0.129 0.126 0.127  ||  -0.047 -0.031 -0.004 0.047 0.037 0.045 0.018 0.027    || dis=0.00 || select=3/8
011/019-th : 0.122 0.121 0.120 0.126 0.125 0.128 0.129 0.129  ||  -0.026 -0.035 -0.038 0.006 -0.001 0.022 0.031 0.034   || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.124 0.126 0.126 0.124 0.126 0.126  ||  0.010 -0.011 -0.008 0.006 0.009 -0.009 0.009 0.010    || dis=0.00 || select=0/8
013/019-th : 0.116 0.118 0.114 0.119 0.125 0.131 0.139 0.138  ||  -0.078 -0.064 -0.102 -0.058 -0.003 0.042 0.102 0.096  || dis=0.00 || select=6/8
014/019-th : 0.109 0.110 0.118 0.121 0.142 0.135 0.134 0.131  ||  -0.122 -0.108 -0.036 -0.010 0.146 0.093 0.087 0.065   || dis=0.01 || select=4/8
015/019-th : 0.115 0.115 0.116 0.122 0.131 0.133 0.135 0.133  ||  -0.079 -0.081 -0.069 -0.020 0.047 0.062 0.082 0.064   || dis=0.00 || select=6/8
016/019-th : 0.110 0.118 0.118 0.131 0.134 0.131 0.130 0.128  ||  -0.107 -0.036 -0.034 0.072 0.093 0.065 0.060 0.048    || dis=0.00 || select=4/8
017/019-th : 0.118 0.119 0.117 0.124 0.126 0.129 0.133 0.135  ||  -0.058 -0.050 -0.061 -0.007 0.009 0.034 0.062 0.079   || dis=0.00 || select=7/8
018/019-th : 0.110 0.118 0.121 0.125 0.131 0.128 0.128 0.139  ||  -0.122 -0.050 -0.031 0.008 0.048 0.031 0.026 0.109    || dis=0.01 || select=7/8
[epoch=015/600] FLOP : 26.48 MB, ratio : 0.6489, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:49:29] [epoch=015/600][000/098] Time 0.37 (0.37) Data 0.30 (0.30) Loss 2.328 (2.328)  Prec@1 19.92 (19.92) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:49:35] [epoch=015/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.241 (2.456)  Prec@1 30.95 (30.22) Prec@5 77.38 (78.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.22 Prec@5 78.16 Error@1 69.78 Error@5 21.84 Loss:2.456
***[2020-01-29 05:49:35]*** VALID [epoch=015/600] loss = 2.456066, accuracy@1 = 30.22, accuracy@5 = 78.16 | Best-Valid-Acc@1=34.42, Error@1=65.58
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:49:35]*** start epoch=016/600 Time Left: [05:11:38], LR=[0.099825 ~ 0.099825], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=16, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.991407505161286, FLOP=40.81
[Search] : epoch=016/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:49:35] [epoch=016/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 1.294 (1.294)  Prec@1 51.95 (51.95) Prec@5 94.53 (94.53) Acls-loss 1.231 (1.231) FLOP-Loss -2.421 (-2.421) Arch-Loss -3.611 (-3.611)
**TRAIN** [2020-01-29 05:49:59] [epoch=016/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 1.216 (1.218)  Prec@1 52.38 (55.99) Prec@5 97.62 (94.82) Acls-loss 1.220 (1.238) FLOP-Loss 0.000 (0.050) Arch-Loss 1.220 (1.338)
 **TRAIN** Prec@1 55.99 Prec@5 94.82 Error@1 44.01 Error@5 5.18 Base-Loss:1.218, Arch-Loss=1.338
***[2020-01-29 05:49:59]*** TRAIN [epoch=016/600] base-loss = 1.218112, arch-loss = 1.337932, accuracy-1 = 55.99, accuracy-5 = 94.82
[epoch=016/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 11, 14, 11, 12, 14, 28, 25, 32, 25, 32, 19, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.450368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.352 0.284 0.363  ||  -0.0161 -0.2304 0.0149  || discrepancy=0.01 || select=2/3
001/003-th : 0.351 0.286 0.362  ||  -0.0099 -0.2147 0.0204  || discrepancy=0.01 || select=2/3
002/003-th : 0.349 0.273 0.377  ||  -0.0326 -0.2773 0.0442  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.111 0.109 0.120 0.118 0.128 0.139 0.138 0.136  ||  -0.109 -0.124 -0.032 -0.046 0.033 0.114 0.110 0.098   || dis=0.00 || select=5/8
001/019-th : 0.122 0.122 0.119 0.122 0.126 0.129 0.129 0.131  ||  -0.025 -0.024 -0.044 -0.024 0.011 0.035 0.034 0.050   || dis=0.00 || select=7/8
002/019-th : 0.119 0.120 0.122 0.127 0.129 0.128 0.127 0.128  ||  -0.043 -0.042 -0.020 0.017 0.034 0.025 0.019 0.028    || dis=0.00 || select=4/8
003/019-th : 0.122 0.122 0.126 0.126 0.124 0.126 0.127 0.127  ||  -0.023 -0.030 0.003 0.010 -0.007 0.005 0.012 0.010    || dis=0.00 || select=6/8
004/019-th : 0.121 0.123 0.124 0.125 0.127 0.127 0.127 0.126  ||  -0.026 -0.014 -0.004 0.001 0.021 0.015 0.016 0.011    || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.126 0.126 0.128 0.126 0.127  ||  -0.026 -0.020 -0.006 0.013 0.011 0.029 0.009 0.021    || dis=0.00 || select=5/8
006/019-th : 0.122 0.123 0.124 0.125 0.128 0.125 0.128 0.127  ||  -0.024 -0.009 -0.007 0.001 0.023 -0.000 0.026 0.016   || dis=0.00 || select=6/8
007/019-th : 0.120 0.119 0.116 0.115 0.131 0.132 0.134 0.133  ||  -0.048 -0.055 -0.081 -0.089 0.046 0.053 0.064 0.061   || dis=0.00 || select=6/8
008/019-th : 0.115 0.117 0.118 0.128 0.131 0.134 0.129 0.129  ||  -0.071 -0.056 -0.043 0.037 0.057 0.079 0.041 0.040    || dis=0.00 || select=5/8
009/019-th : 0.121 0.121 0.122 0.122 0.126 0.128 0.129 0.130  ||  -0.029 -0.028 -0.019 -0.017 0.010 0.028 0.038 0.039   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.123 0.129 0.128 0.130 0.126 0.127  ||  -0.046 -0.029 -0.003 0.046 0.031 0.047 0.017 0.025    || dis=0.00 || select=5/8
011/019-th : 0.122 0.121 0.120 0.124 0.125 0.128 0.130 0.130  ||  -0.025 -0.032 -0.041 -0.012 0.000 0.020 0.034 0.034   || dis=0.00 || select=7/8
012/019-th : 0.126 0.123 0.124 0.127 0.126 0.124 0.125 0.126  ||  0.010 -0.010 -0.006 0.019 0.009 -0.008 0.005 0.008    || dis=0.00 || select=3/8
013/019-th : 0.117 0.118 0.113 0.118 0.125 0.130 0.140 0.139  ||  -0.076 -0.066 -0.104 -0.065 -0.007 0.036 0.105 0.100  || dis=0.00 || select=6/8
014/019-th : 0.109 0.109 0.118 0.121 0.141 0.135 0.135 0.132  ||  -0.123 -0.115 -0.037 -0.017 0.141 0.091 0.094 0.069   || dis=0.01 || select=4/8
015/019-th : 0.115 0.115 0.116 0.121 0.131 0.133 0.135 0.133  ||  -0.078 -0.081 -0.070 -0.033 0.050 0.062 0.081 0.066   || dis=0.00 || select=6/8
016/019-th : 0.108 0.117 0.118 0.131 0.137 0.131 0.129 0.128  ||  -0.118 -0.042 -0.032 0.075 0.115 0.071 0.058 0.052    || dis=0.01 || select=4/8
017/019-th : 0.118 0.119 0.117 0.123 0.126 0.130 0.133 0.135  ||  -0.057 -0.049 -0.067 -0.014 0.009 0.039 0.063 0.078   || dis=0.00 || select=7/8
018/019-th : 0.110 0.118 0.120 0.125 0.130 0.128 0.129 0.140  ||  -0.125 -0.057 -0.038 0.006 0.042 0.029 0.037 0.115    || dis=0.01 || select=7/8
[epoch=016/600] FLOP : 28.45 MB, ratio : 0.6971, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:50:00] [epoch=016/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 1.895 (1.895)  Prec@1 33.59 (33.59) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:50:06] [epoch=016/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.026 (2.210)  Prec@1 28.57 (33.14) Prec@5 84.52 (81.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.14 Prec@5 81.38 Error@1 66.86 Error@5 18.62 Loss:2.210
***[2020-01-29 05:50:06]*** VALID [epoch=016/600] loss = 2.209937, accuracy@1 = 33.14, accuracy@5 = 81.38 | Best-Valid-Acc@1=34.42, Error@1=65.58
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:50:06]*** start epoch=017/600 Time Left: [05:10:43], LR=[0.099802 ~ 0.099802], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=17, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.990300610256385, FLOP=40.81
[Search] : epoch=017/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:50:07] [epoch=017/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 1.367 (1.367)  Prec@1 49.22 (49.22) Prec@5 92.58 (92.58) Acls-loss 1.277 (1.277) FLOP-Loss 0.000 (0.000) Arch-Loss 1.277 (1.277)
**TRAIN** [2020-01-29 05:50:31] [epoch=017/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.214 (1.196)  Prec@1 55.95 (57.08) Prec@5 97.02 (95.01) Acls-loss 1.175 (1.218) FLOP-Loss 0.000 (-0.050) Arch-Loss 1.175 (1.118)
 **TRAIN** Prec@1 57.08 Prec@5 95.01 Error@1 42.92 Error@5 4.99 Base-Loss:1.196, Arch-Loss=1.118
***[2020-01-29 05:50:31]*** TRAIN [epoch=017/600] base-loss = 1.196228, arch-loss = 1.118382, accuracy-1 = 57.08, accuracy-5 = 95.01
[epoch=017/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 12, 16, 11, 14, 11, 12, 14, 28, 25, 32, 25, 28, 22, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.364544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.352 0.279 0.368  ||  -0.0219 -0.2547 0.0216  || discrepancy=0.02 || select=2/3
001/003-th : 0.352 0.281 0.367  ||  -0.0153 -0.2407 0.0268  || discrepancy=0.02 || select=2/3
002/003-th : 0.349 0.267 0.383  ||  -0.0406 -0.3070 0.0534  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.109 0.108 0.118 0.119 0.129 0.140 0.139 0.137  ||  -0.122 -0.132 -0.045 -0.038 0.042 0.124 0.121 0.105   || dis=0.00 || select=5/8
001/019-th : 0.121 0.121 0.119 0.121 0.126 0.130 0.130 0.132  ||  -0.031 -0.030 -0.049 -0.029 0.008 0.038 0.041 0.057   || dis=0.00 || select=7/8
002/019-th : 0.119 0.119 0.121 0.126 0.130 0.128 0.128 0.129  ||  -0.050 -0.049 -0.027 0.011 0.041 0.030 0.027 0.034    || dis=0.00 || select=4/8
003/019-th : 0.122 0.121 0.125 0.126 0.125 0.126 0.128 0.127  ||  -0.028 -0.034 -0.003 0.006 -0.004 0.009 0.018 0.016   || dis=0.00 || select=6/8
004/019-th : 0.120 0.122 0.123 0.124 0.129 0.127 0.127 0.127  ||  -0.034 -0.020 -0.009 -0.002 0.031 0.022 0.022 0.016   || dis=0.00 || select=4/8
005/019-th : 0.121 0.121 0.123 0.125 0.126 0.129 0.127 0.128  ||  -0.031 -0.028 -0.014 0.005 0.015 0.034 0.016 0.027    || dis=0.00 || select=5/8
006/019-th : 0.120 0.123 0.123 0.124 0.129 0.125 0.129 0.127  ||  -0.033 -0.016 -0.009 -0.007 0.032 0.007 0.033 0.023   || dis=0.00 || select=6/8
007/019-th : 0.119 0.118 0.115 0.113 0.133 0.133 0.135 0.135  ||  -0.055 -0.062 -0.088 -0.105 0.061 0.056 0.072 0.070   || dis=0.00 || select=6/8
008/019-th : 0.114 0.116 0.118 0.126 0.132 0.135 0.130 0.130  ||  -0.082 -0.067 -0.049 0.021 0.067 0.090 0.051 0.050    || dis=0.00 || select=5/8
009/019-th : 0.120 0.120 0.121 0.122 0.128 0.129 0.130 0.130  ||  -0.035 -0.034 -0.032 -0.017 0.028 0.032 0.045 0.045   || dis=0.00 || select=7/8
010/019-th : 0.117 0.119 0.122 0.130 0.128 0.130 0.126 0.127  ||  -0.052 -0.036 -0.009 0.048 0.037 0.048 0.023 0.030    || dis=0.00 || select=5/8
011/019-th : 0.121 0.120 0.119 0.123 0.126 0.129 0.131 0.131  ||  -0.034 -0.041 -0.049 -0.018 0.009 0.026 0.043 0.043   || dis=0.00 || select=6/8
012/019-th : 0.125 0.123 0.123 0.126 0.127 0.124 0.126 0.126  ||  0.003 -0.015 -0.010 0.008 0.018 -0.001 0.009 0.014    || dis=0.00 || select=4/8
013/019-th : 0.116 0.117 0.112 0.117 0.126 0.131 0.141 0.141  ||  -0.084 -0.077 -0.113 -0.074 0.002 0.042 0.113 0.112   || dis=0.00 || select=6/8
014/019-th : 0.107 0.108 0.117 0.120 0.142 0.135 0.138 0.134  ||  -0.135 -0.132 -0.053 -0.028 0.146 0.097 0.114 0.083   || dis=0.00 || select=4/8
015/019-th : 0.115 0.114 0.114 0.117 0.132 0.134 0.138 0.136  ||  -0.083 -0.090 -0.090 -0.066 0.055 0.067 0.095 0.080   || dis=0.00 || select=6/8
016/019-th : 0.107 0.115 0.117 0.132 0.136 0.132 0.130 0.130  ||  -0.127 -0.055 -0.039 0.076 0.109 0.079 0.066 0.062    || dis=0.00 || select=4/8
017/019-th : 0.117 0.118 0.116 0.122 0.125 0.131 0.134 0.137  ||  -0.065 -0.057 -0.072 -0.026 0.004 0.047 0.071 0.089   || dis=0.00 || select=7/8
018/019-th : 0.108 0.115 0.120 0.125 0.130 0.130 0.131 0.142  ||  -0.145 -0.075 -0.040 0.004 0.041 0.043 0.052 0.129    || dis=0.01 || select=7/8
[epoch=017/600] FLOP : 28.36 MB, ratio : 0.6950, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:50:31] [epoch=017/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 2.787 (2.787)  Prec@1 22.27 (22.27) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:50:37] [epoch=017/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.146 (2.431)  Prec@1 25.60 (30.43) Prec@5 75.00 (77.96) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.43 Prec@5 77.96 Error@1 69.57 Error@5 22.04 Loss:2.431
***[2020-01-29 05:50:38]*** VALID [epoch=017/600] loss = 2.430900, accuracy@1 = 30.43, accuracy@5 = 77.96 | Best-Valid-Acc@1=34.42, Error@1=65.58
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:50:38]*** start epoch=018/600 Time Left: [05:09:53], LR=[0.099778 ~ 0.099778], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=18, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.989126813277546, FLOP=40.81
[Search] : epoch=018/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:50:38] [epoch=018/600][000/098] Time 0.76 (0.76) Data 0.38 (0.38) Base-Loss 1.131 (1.131)  Prec@1 62.89 (62.89) Prec@5 96.48 (96.48) Acls-loss 1.119 (1.119) FLOP-Loss 0.000 (0.000) Arch-Loss 1.119 (1.119)
**TRAIN** [2020-01-29 05:51:02] [epoch=018/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.907 (1.203)  Prec@1 67.26 (56.91) Prec@5 99.40 (94.99) Acls-loss 1.082 (1.201) FLOP-Loss 0.000 (0.050) Arch-Loss 1.082 (1.300)
 **TRAIN** Prec@1 56.91 Prec@5 94.99 Error@1 43.09 Error@5 5.01 Base-Loss:1.203, Arch-Loss=1.300
***[2020-01-29 05:51:02]*** TRAIN [epoch=018/600] base-loss = 1.202659, arch-loss = 1.300247, accuracy-1 = 56.91, accuracy-5 = 94.99
[epoch=018/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 14, 11, 12, 14, 32, 25, 32, 19, 28, 22, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.355072)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.354 0.280 0.367  ||  -0.0180 -0.2529 0.0182  || discrepancy=0.01 || select=2/3
001/003-th : 0.354 0.279 0.367  ||  -0.0119 -0.2501 0.0240  || discrepancy=0.01 || select=2/3
002/003-th : 0.352 0.262 0.386  ||  -0.0397 -0.3320 0.0540  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.109 0.108 0.119 0.119 0.129 0.139 0.140 0.136  ||  -0.120 -0.136 -0.035 -0.037 0.048 0.118 0.123 0.100   || dis=0.00 || select=6/8
001/019-th : 0.121 0.121 0.120 0.122 0.125 0.129 0.130 0.132  ||  -0.030 -0.029 -0.040 -0.023 0.003 0.037 0.040 0.053   || dis=0.00 || select=7/8
002/019-th : 0.119 0.119 0.122 0.126 0.130 0.128 0.128 0.128  ||  -0.049 -0.047 -0.023 0.013 0.045 0.030 0.025 0.031    || dis=0.00 || select=4/8
003/019-th : 0.122 0.121 0.125 0.126 0.125 0.126 0.127 0.127  ||  -0.025 -0.032 -0.003 0.009 -0.005 0.006 0.017 0.013   || dis=0.00 || select=6/8
004/019-th : 0.121 0.123 0.124 0.125 0.128 0.127 0.127 0.126  ||  -0.031 -0.017 -0.004 -0.000 0.026 0.017 0.018 0.013   || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.123 0.126 0.126 0.128 0.126 0.128  ||  -0.027 -0.023 -0.013 0.014 0.008 0.027 0.013 0.024    || dis=0.00 || select=5/8
006/019-th : 0.121 0.123 0.124 0.124 0.128 0.125 0.128 0.127  ||  -0.031 -0.013 -0.005 -0.002 0.029 0.004 0.030 0.020   || dis=0.00 || select=6/8
007/019-th : 0.119 0.119 0.115 0.113 0.132 0.132 0.135 0.136  ||  -0.053 -0.059 -0.091 -0.105 0.045 0.049 0.070 0.075   || dis=0.00 || select=7/8
008/019-th : 0.113 0.115 0.117 0.128 0.133 0.135 0.129 0.129  ||  -0.083 -0.067 -0.055 0.040 0.074 0.089 0.049 0.048    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.121 0.122 0.128 0.128 0.130 0.130  ||  -0.034 -0.029 -0.031 -0.022 0.024 0.029 0.042 0.044   || dis=0.00 || select=7/8
010/019-th : 0.117 0.119 0.123 0.129 0.128 0.129 0.126 0.127  ||  -0.052 -0.035 -0.009 0.046 0.039 0.043 0.022 0.030    || dis=0.00 || select=3/8
011/019-th : 0.121 0.121 0.120 0.122 0.126 0.128 0.131 0.131  ||  -0.033 -0.038 -0.047 -0.031 0.009 0.025 0.045 0.042   || dis=0.00 || select=6/8
012/019-th : 0.125 0.123 0.123 0.125 0.128 0.124 0.125 0.126  ||  0.005 -0.011 -0.009 0.004 0.028 -0.008 0.006 0.012    || dis=0.00 || select=4/8
013/019-th : 0.116 0.116 0.112 0.116 0.125 0.131 0.142 0.141  ||  -0.081 -0.079 -0.118 -0.084 -0.007 0.042 0.117 0.115  || dis=0.00 || select=6/8
014/019-th : 0.106 0.107 0.116 0.119 0.144 0.135 0.138 0.134  ||  -0.142 -0.137 -0.054 -0.030 0.163 0.094 0.120 0.086   || dis=0.01 || select=4/8
015/019-th : 0.116 0.115 0.114 0.118 0.129 0.134 0.138 0.136  ||  -0.081 -0.088 -0.091 -0.065 0.031 0.065 0.097 0.081   || dis=0.00 || select=6/8
016/019-th : 0.107 0.115 0.118 0.132 0.137 0.132 0.130 0.130  ||  -0.133 -0.060 -0.036 0.079 0.114 0.080 0.066 0.064    || dis=0.01 || select=4/8
017/019-th : 0.118 0.119 0.116 0.120 0.124 0.131 0.135 0.137  ||  -0.063 -0.054 -0.073 -0.038 -0.007 0.047 0.074 0.087  || dis=0.00 || select=7/8
018/019-th : 0.108 0.115 0.119 0.125 0.130 0.129 0.132 0.142  ||  -0.146 -0.079 -0.045 0.003 0.040 0.038 0.058 0.134    || dis=0.01 || select=7/8
[epoch=018/600] FLOP : 28.36 MB, ratio : 0.6948, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:51:02] [epoch=018/600][000/098] Time 0.36 (0.36) Data 0.29 (0.29) Loss 2.610 (2.610)  Prec@1 22.66 (22.66) Prec@5 66.02 (66.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:51:08] [epoch=018/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.531 (2.191)  Prec@1 44.05 (32.57) Prec@5 94.64 (81.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.57 Prec@5 81.20 Error@1 67.43 Error@5 18.80 Loss:2.191
***[2020-01-29 05:51:08]*** VALID [epoch=018/600] loss = 2.191023, accuracy@1 = 32.57, accuracy@5 = 81.20 | Best-Valid-Acc@1=34.42, Error@1=65.58
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:51:08]*** start epoch=019/600 Time Left: [05:08:45], LR=[0.099753 ~ 0.099753], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=19, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.987886146405005, FLOP=40.81
[Search] : epoch=019/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:51:09] [epoch=019/600][000/098] Time 0.64 (0.64) Data 0.38 (0.38) Base-Loss 1.178 (1.178)  Prec@1 58.59 (58.59) Prec@5 94.53 (94.53) Acls-loss 1.190 (1.190) FLOP-Loss 0.000 (0.000) Arch-Loss 1.190 (1.190)
**TRAIN** [2020-01-29 05:51:34] [epoch=019/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.187 (1.180)  Prec@1 54.17 (57.77) Prec@5 96.43 (95.19) Acls-loss 1.261 (1.201) FLOP-Loss 0.000 (0.025) Arch-Loss 1.261 (1.251)
 **TRAIN** Prec@1 57.77 Prec@5 95.19 Error@1 42.23 Error@5 4.81 Base-Loss:1.180, Arch-Loss=1.251
***[2020-01-29 05:51:34]*** TRAIN [epoch=019/600] base-loss = 1.179598, arch-loss = 1.250517, accuracy-1 = 57.77, accuracy-5 = 95.19
[epoch=019/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 14, 11, 12, 11, 32, 25, 32, 22, 28, 22, 64, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.21824)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.354 0.280 0.366  ||  -0.0167 -0.2492 0.0174  || discrepancy=0.01 || select=2/3
001/003-th : 0.357 0.272 0.370  ||  -0.0112 -0.2825 0.0247  || discrepancy=0.01 || select=2/3
002/003-th : 0.351 0.261 0.388  ||  -0.0415 -0.3394 0.0566  || discrepancy=0.04 || select=2/3
-----------------------------------------------
000/019-th : 0.109 0.107 0.119 0.119 0.130 0.140 0.141 0.136  ||  -0.125 -0.143 -0.039 -0.034 0.053 0.124 0.132 0.100   || dis=0.00 || select=6/8
001/019-th : 0.121 0.121 0.120 0.122 0.125 0.130 0.130 0.132  ||  -0.030 -0.031 -0.038 -0.023 -0.000 0.038 0.041 0.054  || dis=0.00 || select=7/8
002/019-th : 0.118 0.119 0.122 0.126 0.131 0.129 0.128 0.128  ||  -0.050 -0.047 -0.023 0.011 0.048 0.035 0.024 0.030    || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.125 0.126 0.125 0.126 0.127 0.127  ||  -0.023 -0.030 -0.004 0.008 -0.003 0.004 0.015 0.012   || dis=0.00 || select=6/8
004/019-th : 0.121 0.123 0.124 0.125 0.128 0.126 0.127 0.126  ||  -0.032 -0.017 -0.002 0.003 0.023 0.014 0.019 0.014    || dis=0.00 || select=4/8
005/019-th : 0.122 0.122 0.123 0.126 0.126 0.128 0.126 0.128  ||  -0.026 -0.023 -0.013 0.010 0.009 0.025 0.014 0.022    || dis=0.00 || select=5/8
006/019-th : 0.121 0.123 0.124 0.124 0.128 0.125 0.128 0.127  ||  -0.031 -0.011 -0.007 -0.001 0.030 0.001 0.029 0.019   || dis=0.00 || select=4/8
007/019-th : 0.119 0.118 0.115 0.114 0.131 0.132 0.135 0.136  ||  -0.056 -0.060 -0.086 -0.096 0.038 0.050 0.071 0.076   || dis=0.00 || select=7/8
008/019-th : 0.113 0.114 0.117 0.129 0.132 0.135 0.130 0.130  ||  -0.086 -0.077 -0.057 0.042 0.065 0.092 0.055 0.053    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.120 0.123 0.127 0.127 0.130 0.131  ||  -0.034 -0.027 -0.035 -0.012 0.019 0.020 0.042 0.046   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.123 0.129 0.129 0.128 0.127 0.127  ||  -0.051 -0.033 -0.008 0.041 0.045 0.036 0.023 0.028    || dis=0.00 || select=4/8
011/019-th : 0.121 0.121 0.119 0.123 0.126 0.129 0.131 0.131  ||  -0.032 -0.039 -0.053 -0.014 0.002 0.027 0.044 0.042   || dis=0.00 || select=6/8
012/019-th : 0.125 0.124 0.123 0.125 0.128 0.124 0.125 0.126  ||  0.006 -0.009 -0.012 0.002 0.025 -0.009 0.001 0.014    || dis=0.00 || select=4/8
013/019-th : 0.115 0.116 0.111 0.116 0.127 0.130 0.142 0.142  ||  -0.086 -0.080 -0.122 -0.081 0.009 0.036 0.119 0.120   || dis=0.00 || select=7/8
014/019-th : 0.106 0.106 0.116 0.121 0.142 0.134 0.140 0.135  ||  -0.148 -0.143 -0.058 -0.017 0.149 0.091 0.129 0.092   || dis=0.00 || select=4/8
015/019-th : 0.116 0.115 0.114 0.117 0.129 0.135 0.139 0.136  ||  -0.081 -0.088 -0.095 -0.070 0.025 0.071 0.100 0.081   || dis=0.00 || select=6/8
016/019-th : 0.105 0.115 0.117 0.131 0.139 0.132 0.131 0.130  ||  -0.147 -0.061 -0.041 0.073 0.129 0.083 0.074 0.069    || dis=0.01 || select=4/8
017/019-th : 0.117 0.118 0.116 0.121 0.123 0.132 0.135 0.137  ||  -0.064 -0.057 -0.077 -0.030 -0.016 0.054 0.074 0.090  || dis=0.00 || select=7/8
018/019-th : 0.107 0.114 0.119 0.124 0.129 0.130 0.133 0.144  ||  -0.157 -0.092 -0.047 -0.004 0.038 0.040 0.068 0.148   || dis=0.01 || select=7/8
[epoch=019/600] FLOP : 28.22 MB, ratio : 0.6914, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:51:35] [epoch=019/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.921 (1.921)  Prec@1 33.98 (33.98) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:51:41] [epoch=019/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.490 (2.117)  Prec@1 32.74 (34.66) Prec@5 85.12 (82.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.66 Prec@5 82.99 Error@1 65.34 Error@5 17.01 Loss:2.117
***[2020-01-29 05:51:41]*** VALID [epoch=019/600] loss = 2.116795, accuracy@1 = 34.66, accuracy@5 = 82.99 | Best-Valid-Acc@1=34.42, Error@1=65.58
Currently, the best validation accuracy found at 019-epoch :: acc@1=34.66, acc@5=82.99, error@1=65.34, error@5=17.01, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:51:41]*** start epoch=020/600 Time Left: [05:08:31], LR=[0.099726 ~ 0.099726], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=20, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.98657864365227, FLOP=40.81
[Search] : epoch=020/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:51:41] [epoch=020/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 1.170 (1.170)  Prec@1 57.03 (57.03) Prec@5 97.66 (97.66) Acls-loss 1.214 (1.214) FLOP-Loss 0.000 (0.000) Arch-Loss 1.214 (1.214)
**TRAIN** [2020-01-29 05:52:07] [epoch=020/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.127 (1.167)  Prec@1 63.69 (58.21) Prec@5 94.64 (95.33) Acls-loss 1.093 (1.195) FLOP-Loss 0.000 (0.099) Arch-Loss 1.093 (1.394)
 **TRAIN** Prec@1 58.21 Prec@5 95.33 Error@1 41.79 Error@5 4.67 Base-Loss:1.167, Arch-Loss=1.394
***[2020-01-29 05:52:07]*** TRAIN [epoch=020/600] base-loss = 1.166784, arch-loss = 1.393591, accuracy-1 = 58.21, accuracy-5 = 95.33
[epoch=020/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 9, 11, 12, 11, 32, 25, 32, 22, 32, 22, 64, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.609984)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.359 0.276 0.365  ||  -0.0084 -0.2691 0.0102  || discrepancy=0.01 || select=2/3
001/003-th : 0.361 0.270 0.369  ||  -0.0029 -0.2944 0.0174  || discrepancy=0.01 || select=2/3
002/003-th : 0.354 0.260 0.387  ||  -0.0366 -0.3463 0.0526  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.108 0.106 0.118 0.120 0.131 0.140 0.141 0.135  ||  -0.130 -0.145 -0.040 -0.027 0.067 0.131 0.138 0.094   || dis=0.00 || select=6/8
001/019-th : 0.122 0.121 0.121 0.123 0.124 0.128 0.129 0.131  ||  -0.025 -0.026 -0.027 -0.010 -0.005 0.030 0.033 0.047  || dis=0.00 || select=7/8
002/019-th : 0.119 0.120 0.123 0.126 0.130 0.128 0.127 0.127  ||  -0.046 -0.038 -0.012 0.014 0.044 0.029 0.018 0.023    || dis=0.00 || select=4/8
003/019-th : 0.124 0.123 0.126 0.127 0.124 0.125 0.126 0.126  ||  -0.014 -0.022 0.002 0.012 -0.010 -0.001 0.009 0.002   || dis=0.00 || select=3/8
004/019-th : 0.122 0.124 0.125 0.126 0.127 0.125 0.126 0.125  ||  -0.025 -0.008 0.005 0.010 0.020 0.005 0.011 0.006     || dis=0.00 || select=4/8
005/019-th : 0.123 0.123 0.124 0.125 0.124 0.127 0.126 0.127  ||  -0.016 -0.015 -0.005 0.004 -0.005 0.018 0.005 0.016   || dis=0.00 || select=5/8
006/019-th : 0.121 0.124 0.125 0.126 0.128 0.124 0.127 0.126  ||  -0.028 -0.007 0.002 0.012 0.025 -0.006 0.023 0.014    || dis=0.00 || select=4/8
007/019-th : 0.120 0.118 0.117 0.116 0.129 0.131 0.135 0.135  ||  -0.049 -0.062 -0.075 -0.084 0.028 0.037 0.070 0.072   || dis=0.00 || select=7/8
008/019-th : 0.114 0.115 0.117 0.128 0.132 0.135 0.130 0.129  ||  -0.083 -0.068 -0.050 0.037 0.065 0.088 0.052 0.046    || dis=0.00 || select=5/8
009/019-th : 0.122 0.122 0.121 0.124 0.127 0.126 0.129 0.130  ||  -0.025 -0.021 -0.032 -0.003 0.016 0.011 0.035 0.039   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.124 0.128 0.130 0.128 0.126 0.126  ||  -0.044 -0.029 -0.001 0.036 0.048 0.031 0.018 0.020    || dis=0.00 || select=4/8
011/019-th : 0.122 0.121 0.119 0.125 0.126 0.128 0.130 0.130  ||  -0.027 -0.035 -0.045 -0.001 0.010 0.021 0.035 0.037   || dis=0.00 || select=7/8
012/019-th : 0.126 0.125 0.124 0.125 0.127 0.122 0.124 0.126  ||  0.013 -0.002 -0.006 0.005 0.015 -0.019 -0.006 0.011   || dis=0.00 || select=4/8
013/019-th : 0.116 0.117 0.112 0.116 0.126 0.131 0.141 0.142  ||  -0.079 -0.078 -0.121 -0.084 0.001 0.036 0.115 0.118   || dis=0.00 || select=7/8
014/019-th : 0.106 0.106 0.117 0.123 0.141 0.134 0.139 0.134  ||  -0.149 -0.142 -0.051 0.005 0.136 0.090 0.128 0.086    || dis=0.00 || select=4/8
015/019-th : 0.116 0.115 0.115 0.117 0.128 0.135 0.138 0.135  ||  -0.075 -0.085 -0.086 -0.069 0.018 0.069 0.095 0.076   || dis=0.00 || select=6/8
016/019-th : 0.105 0.116 0.117 0.129 0.140 0.132 0.131 0.130  ||  -0.148 -0.053 -0.039 0.055 0.135 0.075 0.073 0.067    || dis=0.01 || select=4/8
017/019-th : 0.118 0.119 0.116 0.122 0.124 0.131 0.133 0.136  ||  -0.057 -0.049 -0.074 -0.023 -0.010 0.048 0.062 0.085  || dis=0.00 || select=7/8
018/019-th : 0.107 0.114 0.120 0.123 0.128 0.129 0.133 0.144  ||  -0.157 -0.088 -0.035 -0.010 0.029 0.037 0.068 0.147   || dis=0.01 || select=7/8
[epoch=020/600] FLOP : 27.61 MB, ratio : 0.6765, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:52:07] [epoch=020/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.783 (1.783)  Prec@1 37.89 (37.89) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:52:13] [epoch=020/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.537 (2.189)  Prec@1 22.02 (33.34) Prec@5 76.79 (80.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.34 Prec@5 80.89 Error@1 66.66 Error@5 19.11 Loss:2.189
***[2020-01-29 05:52:13]*** VALID [epoch=020/600] loss = 2.188814, accuracy@1 = 33.34, accuracy@5 = 80.89 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:52:13]*** start epoch=021/600 Time Left: [05:08:17], LR=[0.099698 ~ 0.099698], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=21, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.985204340865191, FLOP=40.81
[Search] : epoch=021/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:52:14] [epoch=021/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 1.226 (1.226)  Prec@1 56.64 (56.64) Prec@5 96.09 (96.09) Acls-loss 1.136 (1.136) FLOP-Loss 0.000 (0.000) Arch-Loss 1.136 (1.136)
**TRAIN** [2020-01-29 05:52:40] [epoch=021/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 1.561 (1.173)  Prec@1 42.26 (57.96) Prec@5 88.69 (95.30) Acls-loss 1.262 (1.184) FLOP-Loss 0.000 (0.050) Arch-Loss 1.262 (1.284)
 **TRAIN** Prec@1 57.96 Prec@5 95.30 Error@1 42.04 Error@5 4.70 Base-Loss:1.173, Arch-Loss=1.284
***[2020-01-29 05:52:40]*** TRAIN [epoch=021/600] base-loss = 1.172708, arch-loss = 1.283572, accuracy-1 = 57.96, accuracy-5 = 95.30
[epoch=021/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 9, 11, 12, 11, 32, 25, 32, 22, 32, 22, 64, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.694848)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.361 0.275 0.364  ||  -0.0032 -0.2768 0.0059  || discrepancy=0.00 || select=2/3
001/003-th : 0.366 0.264 0.370  ||  0.0022 -0.3217 0.0138  || discrepancy=0.00 || select=2/3
002/003-th : 0.357 0.253 0.389  ||  -0.0341 -0.3783 0.0521  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.108 0.105 0.119 0.119 0.133 0.139 0.142 0.136  ||  -0.133 -0.157 -0.035 -0.031 0.078 0.124 0.142 0.099   || dis=0.00 || select=6/8
001/019-th : 0.122 0.122 0.122 0.123 0.123 0.129 0.129 0.130  ||  -0.021 -0.025 -0.021 -0.010 -0.016 0.030 0.031 0.043  || dis=0.00 || select=7/8
002/019-th : 0.119 0.120 0.124 0.127 0.130 0.127 0.126 0.127  ||  -0.043 -0.035 -0.008 0.018 0.039 0.023 0.013 0.022    || dis=0.00 || select=4/8
003/019-th : 0.124 0.123 0.126 0.127 0.124 0.125 0.126 0.125  ||  -0.010 -0.020 0.007 0.013 -0.009 -0.004 0.004 -0.001  || dis=0.00 || select=3/8
004/019-th : 0.122 0.124 0.126 0.126 0.126 0.125 0.126 0.125  ||  -0.022 -0.004 0.011 0.010 0.013 0.001 0.007 0.003     || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.125 0.125 0.124 0.127 0.125 0.126  ||  -0.009 -0.010 0.003 -0.001 -0.010 0.014 -0.000 0.010  || dis=0.00 || select=5/8
006/019-th : 0.121 0.123 0.125 0.125 0.128 0.123 0.127 0.126  ||  -0.027 -0.007 0.008 0.008 0.031 -0.010 0.021 0.014    || dis=0.00 || select=4/8
007/019-th : 0.120 0.119 0.117 0.117 0.128 0.130 0.134 0.135  ||  -0.048 -0.056 -0.069 -0.073 0.017 0.035 0.063 0.071   || dis=0.00 || select=7/8
008/019-th : 0.114 0.116 0.117 0.129 0.132 0.134 0.130 0.129  ||  -0.081 -0.065 -0.053 0.044 0.067 0.082 0.049 0.045    || dis=0.00 || select=5/8
009/019-th : 0.122 0.122 0.121 0.125 0.126 0.126 0.129 0.130  ||  -0.021 -0.019 -0.032 -0.001 0.007 0.006 0.032 0.039   || dis=0.00 || select=7/8
010/019-th : 0.119 0.120 0.123 0.130 0.130 0.127 0.126 0.126  ||  -0.041 -0.027 -0.006 0.048 0.051 0.026 0.016 0.017    || dis=0.00 || select=4/8
011/019-th : 0.122 0.121 0.119 0.125 0.127 0.127 0.129 0.130  ||  -0.024 -0.034 -0.049 0.000 0.018 0.020 0.031 0.036    || dis=0.00 || select=7/8
012/019-th : 0.126 0.125 0.125 0.125 0.127 0.122 0.124 0.126  ||  0.013 0.001 -0.002 0.003 0.016 -0.020 -0.011 0.010    || dis=0.00 || select=4/8
013/019-th : 0.114 0.116 0.111 0.119 0.126 0.130 0.142 0.142  ||  -0.098 -0.080 -0.121 -0.056 0.004 0.039 0.123 0.124   || dis=0.00 || select=7/8
014/019-th : 0.105 0.106 0.117 0.124 0.140 0.135 0.140 0.134  ||  -0.159 -0.148 -0.046 0.012 0.132 0.101 0.133 0.087    || dis=0.00 || select=6/8
015/019-th : 0.117 0.116 0.114 0.118 0.127 0.133 0.138 0.136  ||  -0.073 -0.082 -0.094 -0.060 0.015 0.060 0.096 0.077   || dis=0.00 || select=6/8
016/019-th : 0.105 0.115 0.118 0.129 0.139 0.133 0.132 0.130  ||  -0.153 -0.056 -0.035 0.052 0.127 0.085 0.080 0.062    || dis=0.01 || select=4/8
017/019-th : 0.119 0.120 0.116 0.123 0.122 0.130 0.133 0.136  ||  -0.050 -0.046 -0.073 -0.016 -0.022 0.039 0.057 0.085  || dis=0.00 || select=7/8
018/019-th : 0.106 0.114 0.120 0.124 0.127 0.129 0.134 0.146  ||  -0.163 -0.086 -0.039 -0.010 0.020 0.030 0.071 0.158   || dis=0.01 || select=7/8
[epoch=021/600] FLOP : 28.69 MB, ratio : 0.7031, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:52:40] [epoch=021/600][000/098] Time 0.34 (0.34) Data 0.26 (0.26) Loss 2.706 (2.706)  Prec@1 25.39 (25.39) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:52:46] [epoch=021/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.965 (2.491)  Prec@1 38.10 (30.77) Prec@5 80.95 (79.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 30.77 Prec@5 79.14 Error@1 69.23 Error@5 20.86 Loss:2.491
***[2020-01-29 05:52:46]*** VALID [epoch=021/600] loss = 2.490894, accuracy@1 = 30.77, accuracy@5 = 79.14 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:52:46]*** start epoch=022/600 Time Left: [05:08:13], LR=[0.099669 ~ 0.099669], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=22, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.983763275720971, FLOP=40.81
[Search] : epoch=022/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:52:47] [epoch=022/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 1.159 (1.159)  Prec@1 61.33 (61.33) Prec@5 95.31 (95.31) Acls-loss 1.330 (1.330) FLOP-Loss 2.421 (2.421) Arch-Loss 6.171 (6.171)
**TRAIN** [2020-01-29 05:53:12] [epoch=022/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.113 (1.180)  Prec@1 58.33 (57.62) Prec@5 95.83 (95.28) Acls-loss 1.194 (1.192) FLOP-Loss 0.000 (0.050) Arch-Loss 1.194 (1.292)
 **TRAIN** Prec@1 57.62 Prec@5 95.28 Error@1 42.38 Error@5 4.72 Base-Loss:1.180, Arch-Loss=1.292
***[2020-01-29 05:53:12]*** TRAIN [epoch=022/600] base-loss = 1.179623, arch-loss = 1.291614, accuracy-1 = 57.62, accuracy-5 = 95.28
[epoch=022/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 9, 11, 16, 11, 32, 25, 32, 22, 32, 22, 57, 44, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.15488)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.363 0.274 0.363  ||  0.0006 -0.2792 0.0028  || discrepancy=0.00 || select=2/3
001/003-th : 0.368 0.261 0.370  ||  0.0062 -0.3366 0.0109  || discrepancy=0.00 || select=2/3
002/003-th : 0.359 0.248 0.393  ||  -0.0352 -0.4056 0.0550  || discrepancy=0.03 || select=2/3
-----------------------------------------------
000/019-th : 0.107 0.104 0.118 0.119 0.134 0.139 0.143 0.136  ||  -0.142 -0.162 -0.044 -0.030 0.087 0.128 0.151 0.103   || dis=0.00 || select=6/8
001/019-th : 0.122 0.122 0.123 0.123 0.124 0.128 0.128 0.130  ||  -0.019 -0.019 -0.018 -0.013 -0.010 0.023 0.027 0.041  || dis=0.00 || select=7/8
002/019-th : 0.119 0.121 0.124 0.127 0.129 0.127 0.126 0.127  ||  -0.043 -0.029 -0.006 0.017 0.033 0.023 0.009 0.020    || dis=0.00 || select=4/8
003/019-th : 0.125 0.124 0.126 0.127 0.124 0.124 0.125 0.125  ||  -0.006 -0.015 0.007 0.015 -0.012 -0.008 0.001 -0.003  || dis=0.00 || select=3/8
004/019-th : 0.122 0.124 0.126 0.126 0.127 0.125 0.125 0.125  ||  -0.020 -0.003 0.012 0.012 0.018 0.003 0.005 -0.001    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.126 0.125 0.124 0.126 0.125 0.126  ||  -0.006 -0.008 0.006 -0.000 -0.012 0.007 -0.002 0.009  || dis=0.00 || select=7/8
006/019-th : 0.121 0.124 0.126 0.126 0.128 0.123 0.127 0.126  ||  -0.029 -0.003 0.011 0.014 0.029 -0.011 0.020 0.011    || dis=0.00 || select=4/8
007/019-th : 0.120 0.119 0.117 0.118 0.128 0.130 0.134 0.135  ||  -0.047 -0.057 -0.070 -0.064 0.020 0.035 0.063 0.070   || dis=0.00 || select=7/8
008/019-th : 0.114 0.116 0.117 0.129 0.132 0.134 0.129 0.128  ||  -0.081 -0.061 -0.053 0.043 0.071 0.086 0.048 0.040    || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.121 0.124 0.124 0.127 0.129 0.130  ||  -0.020 -0.015 -0.035 -0.006 -0.004 0.013 0.030 0.038  || dis=0.00 || select=7/8
010/019-th : 0.119 0.121 0.123 0.130 0.130 0.126 0.126 0.126  ||  -0.040 -0.025 -0.003 0.049 0.050 0.017 0.015 0.016    || dis=0.00 || select=4/8
011/019-th : 0.123 0.121 0.118 0.125 0.129 0.127 0.129 0.130  ||  -0.019 -0.035 -0.058 0.001 0.029 0.017 0.029 0.036    || dis=0.00 || select=7/8
012/019-th : 0.126 0.125 0.125 0.126 0.127 0.122 0.123 0.125  ||  0.013 0.003 0.003 0.007 0.020 -0.022 -0.011 0.005     || dis=0.00 || select=4/8
013/019-th : 0.110 0.115 0.111 0.120 0.128 0.131 0.143 0.142  ||  -0.126 -0.082 -0.115 -0.037 0.027 0.049 0.133 0.128   || dis=0.00 || select=6/8
014/019-th : 0.104 0.105 0.116 0.127 0.141 0.135 0.140 0.133  ||  -0.163 -0.154 -0.053 0.038 0.141 0.099 0.138 0.086    || dis=0.00 || select=4/8
015/019-th : 0.117 0.116 0.113 0.119 0.128 0.133 0.139 0.136  ||  -0.072 -0.083 -0.101 -0.052 0.016 0.060 0.099 0.078   || dis=0.00 || select=6/8
016/019-th : 0.103 0.115 0.118 0.130 0.140 0.132 0.132 0.130  ||  -0.163 -0.060 -0.033 0.066 0.140 0.081 0.084 0.062    || dis=0.01 || select=4/8
017/019-th : 0.120 0.119 0.116 0.123 0.124 0.130 0.132 0.136  ||  -0.045 -0.046 -0.076 -0.021 -0.007 0.035 0.057 0.083  || dis=0.00 || select=7/8
018/019-th : 0.105 0.113 0.120 0.122 0.129 0.130 0.134 0.148  ||  -0.174 -0.097 -0.039 -0.023 0.034 0.041 0.072 0.170   || dis=0.01 || select=7/8
[epoch=022/600] FLOP : 28.15 MB, ratio : 0.6898, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:53:13] [epoch=022/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.621 (2.621)  Prec@1 23.05 (23.05) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:53:19] [epoch=022/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.119 (2.393)  Prec@1 35.12 (28.39) Prec@5 76.19 (78.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 28.39 Prec@5 78.13 Error@1 71.61 Error@5 21.87 Loss:2.393
***[2020-01-29 05:53:19]*** VALID [epoch=022/600] loss = 2.393251, accuracy@1 = 28.39, accuracy@5 = 78.13 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:53:19]*** start epoch=023/600 Time Left: [05:07:49], LR=[0.099638 ~ 0.099638], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=23, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.982255487727142, FLOP=40.81
[Search] : epoch=023/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:53:19] [epoch=023/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 1.063 (1.063)  Prec@1 61.72 (61.72) Prec@5 95.70 (95.70) Acls-loss 1.300 (1.300) FLOP-Loss 0.000 (0.000) Arch-Loss 1.300 (1.300)
**TRAIN** [2020-01-29 05:53:45] [epoch=023/600][097/098] Time 0.28 (0.27) Data 0.00 (0.00) Base-Loss 1.116 (1.162)  Prec@1 57.74 (58.49) Prec@5 97.02 (95.34) Acls-loss 1.252 (1.179) FLOP-Loss 0.000 (0.000) Arch-Loss 1.252 (1.179)
 **TRAIN** Prec@1 58.49 Prec@5 95.34 Error@1 41.51 Error@5 4.66 Base-Loss:1.162, Arch-Loss=1.179
***[2020-01-29 05:53:45]*** TRAIN [epoch=023/600] base-loss = 1.161840, arch-loss = 1.179389, accuracy-1 = 58.49, accuracy-5 = 95.34
[epoch=023/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 16, 11, 32, 25, 32, 22, 22, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.970816)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.274 0.364  ||  -0.0012 -0.2772 0.0052  || discrepancy=0.00 || select=2/3
001/003-th : 0.369 0.258 0.373  ||  0.0042 -0.3526 0.0141  || discrepancy=0.00 || select=2/3
002/003-th : 0.359 0.244 0.398  ||  -0.0410 -0.4281 0.0623  || discrepancy=0.04 || select=2/3
-----------------------------------------------
000/019-th : 0.105 0.104 0.117 0.120 0.135 0.139 0.144 0.137  ||  -0.158 -0.165 -0.051 -0.023 0.093 0.127 0.163 0.110   || dis=0.00 || select=6/8
001/019-th : 0.122 0.122 0.122 0.124 0.124 0.128 0.129 0.130  ||  -0.022 -0.023 -0.018 -0.009 -0.009 0.026 0.033 0.041  || dis=0.00 || select=7/8
002/019-th : 0.119 0.120 0.124 0.127 0.129 0.128 0.126 0.127  ||  -0.046 -0.033 -0.007 0.024 0.038 0.026 0.010 0.022    || dis=0.00 || select=4/8
003/019-th : 0.124 0.123 0.126 0.126 0.125 0.125 0.125 0.125  ||  -0.009 -0.015 0.006 0.005 -0.002 -0.005 0.001 -0.001  || dis=0.00 || select=2/8
004/019-th : 0.122 0.124 0.126 0.125 0.127 0.125 0.126 0.124  ||  -0.024 -0.004 0.014 0.006 0.022 0.003 0.011 -0.001    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.126 0.124 0.124 0.126 0.125 0.127  ||  -0.009 -0.008 0.004 -0.013 -0.010 0.009 0.002 0.011   || dis=0.00 || select=7/8
006/019-th : 0.120 0.123 0.126 0.127 0.128 0.123 0.127 0.126  ||  -0.033 -0.007 0.010 0.020 0.028 -0.007 0.024 0.012    || dis=0.00 || select=4/8
007/019-th : 0.120 0.118 0.117 0.117 0.128 0.130 0.134 0.136  ||  -0.050 -0.062 -0.073 -0.069 0.018 0.036 0.067 0.076   || dis=0.00 || select=7/8
008/019-th : 0.113 0.115 0.117 0.128 0.134 0.135 0.130 0.129  ||  -0.086 -0.065 -0.056 0.039 0.081 0.089 0.052 0.042    || dis=0.00 || select=5/8
009/019-th : 0.122 0.123 0.120 0.124 0.125 0.128 0.129 0.130  ||  -0.023 -0.019 -0.044 -0.009 -0.002 0.021 0.031 0.043  || dis=0.00 || select=7/8
010/019-th : 0.119 0.120 0.123 0.128 0.129 0.127 0.127 0.126  ||  -0.041 -0.029 -0.009 0.031 0.043 0.025 0.026 0.015    || dis=0.00 || select=4/8
011/019-th : 0.122 0.119 0.116 0.124 0.132 0.128 0.129 0.130  ||  -0.020 -0.047 -0.071 -0.007 0.060 0.025 0.035 0.040   || dis=0.00 || select=4/8
012/019-th : 0.126 0.124 0.124 0.126 0.128 0.123 0.124 0.125  ||  0.011 -0.003 -0.002 0.013 0.024 -0.014 -0.008 0.007   || dis=0.00 || select=4/8
013/019-th : 0.107 0.114 0.111 0.123 0.127 0.132 0.144 0.142  ||  -0.151 -0.084 -0.116 -0.011 0.020 0.058 0.146 0.134   || dis=0.00 || select=6/8
014/019-th : 0.103 0.103 0.115 0.127 0.140 0.135 0.141 0.134  ||  -0.170 -0.166 -0.057 0.041 0.137 0.101 0.145 0.095    || dis=0.00 || select=6/8
015/019-th : 0.116 0.115 0.113 0.119 0.126 0.135 0.139 0.136  ||  -0.078 -0.088 -0.104 -0.054 0.004 0.073 0.103 0.083   || dis=0.00 || select=6/8
016/019-th : 0.102 0.113 0.117 0.129 0.143 0.133 0.133 0.130  ||  -0.174 -0.070 -0.039 0.062 0.159 0.088 0.089 0.068    || dis=0.01 || select=4/8
017/019-th : 0.119 0.119 0.116 0.122 0.125 0.130 0.133 0.136  ||  -0.047 -0.054 -0.079 -0.029 -0.003 0.041 0.062 0.086  || dis=0.00 || select=7/8
018/019-th : 0.104 0.114 0.119 0.121 0.127 0.129 0.137 0.149  ||  -0.186 -0.094 -0.044 -0.031 0.019 0.036 0.094 0.177   || dis=0.01 || select=7/8
[epoch=023/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.004
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:53:46] [epoch=023/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.349 (2.349)  Prec@1 21.48 (21.48) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:53:51] [epoch=023/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.726 (2.288)  Prec@1 19.64 (32.50) Prec@5 80.95 (80.90) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.50 Prec@5 80.90 Error@1 67.50 Error@5 19.10 Loss:2.288
***[2020-01-29 05:53:52]*** VALID [epoch=023/600] loss = 2.288460, accuracy@1 = 32.50, accuracy@5 = 80.90 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:53:52]*** start epoch=024/600 Time Left: [05:07:38], LR=[0.099606 ~ 0.099606], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=24, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.980681018220471, FLOP=40.81
[Search] : epoch=024/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:53:52] [epoch=024/600][000/098] Time 0.76 (0.76) Data 0.35 (0.35) Base-Loss 1.139 (1.139)  Prec@1 54.30 (54.30) Prec@5 96.09 (96.09) Acls-loss 1.142 (1.142) FLOP-Loss 0.000 (0.000) Arch-Loss 1.142 (1.142)
**TRAIN** [2020-01-29 05:54:18] [epoch=024/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 1.197 (1.144)  Prec@1 58.33 (59.10) Prec@5 95.83 (95.44) Acls-loss 1.152 (1.163) FLOP-Loss 0.000 (0.025) Arch-Loss 1.152 (1.213)
 **TRAIN** Prec@1 59.10 Prec@5 95.44 Error@1 40.90 Error@5 4.56 Base-Loss:1.144, Arch-Loss=1.213
***[2020-01-29 05:54:18]*** TRAIN [epoch=024/600] base-loss = 1.144410, arch-loss = 1.212762, accuracy-1 = 59.10, accuracy-5 = 95.44
[epoch=024/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 8, 16, 9, 32, 25, 32, 22, 22, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.015936)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.363 0.272 0.365  ||  0.0001 -0.2864 0.0048  || discrepancy=0.00 || select=2/3
001/003-th : 0.370 0.256 0.374  ||  0.0051 -0.3646 0.0144  || discrepancy=0.00 || select=2/3
002/003-th : 0.359 0.240 0.401  ||  -0.0439 -0.4456 0.0668  || discrepancy=0.04 || select=2/3
-----------------------------------------------
000/019-th : 0.104 0.104 0.116 0.120 0.135 0.139 0.146 0.137  ||  -0.163 -0.168 -0.057 -0.023 0.093 0.127 0.174 0.112   || dis=0.01 || select=6/8
001/019-th : 0.122 0.121 0.122 0.124 0.123 0.128 0.129 0.130  ||  -0.021 -0.026 -0.020 -0.005 -0.012 0.028 0.034 0.042  || dis=0.00 || select=7/8
002/019-th : 0.118 0.120 0.123 0.128 0.129 0.128 0.126 0.127  ||  -0.049 -0.032 -0.008 0.027 0.037 0.026 0.013 0.022    || dis=0.00 || select=4/8
003/019-th : 0.125 0.124 0.126 0.126 0.125 0.125 0.125 0.125  ||  -0.006 -0.014 0.006 0.003 -0.005 -0.007 0.000 -0.002  || dis=0.00 || select=2/8
004/019-th : 0.122 0.124 0.127 0.125 0.127 0.125 0.126 0.124  ||  -0.025 -0.006 0.018 0.005 0.018 0.007 0.013 -0.002    || dis=0.00 || select=2/8
005/019-th : 0.124 0.124 0.125 0.124 0.125 0.126 0.125 0.127  ||  -0.007 -0.009 -0.001 -0.013 -0.001 0.006 0.001 0.012  || dis=0.00 || select=7/8
006/019-th : 0.120 0.124 0.125 0.128 0.126 0.124 0.127 0.126  ||  -0.037 -0.006 0.008 0.028 0.013 -0.000 0.024 0.013    || dis=0.00 || select=3/8
007/019-th : 0.120 0.117 0.116 0.117 0.129 0.131 0.135 0.136  ||  -0.048 -0.073 -0.078 -0.069 0.024 0.045 0.070 0.079   || dis=0.00 || select=7/8
008/019-th : 0.113 0.115 0.116 0.128 0.133 0.136 0.130 0.129  ||  -0.089 -0.066 -0.058 0.039 0.078 0.095 0.053 0.042    || dis=0.00 || select=5/8
009/019-th : 0.122 0.122 0.119 0.125 0.124 0.127 0.129 0.131  ||  -0.022 -0.020 -0.046 0.000 -0.005 0.018 0.032 0.044   || dis=0.00 || select=7/8
010/019-th : 0.119 0.120 0.122 0.126 0.129 0.128 0.128 0.127  ||  -0.041 -0.031 -0.018 0.017 0.036 0.033 0.028 0.018    || dis=0.00 || select=4/8
011/019-th : 0.123 0.118 0.116 0.123 0.132 0.129 0.130 0.130  ||  -0.018 -0.053 -0.076 -0.016 0.052 0.032 0.038 0.042   || dis=0.00 || select=4/8
012/019-th : 0.126 0.124 0.124 0.126 0.127 0.123 0.124 0.126  ||  0.009 -0.001 -0.003 0.014 0.022 -0.017 -0.007 0.008   || dis=0.00 || select=4/8
013/019-th : 0.105 0.114 0.111 0.123 0.126 0.133 0.144 0.143  ||  -0.172 -0.086 -0.113 -0.009 0.018 0.071 0.152 0.144   || dis=0.00 || select=6/8
014/019-th : 0.102 0.102 0.115 0.129 0.139 0.135 0.143 0.135  ||  -0.179 -0.176 -0.061 0.052 0.131 0.101 0.156 0.102    || dis=0.00 || select=6/8
015/019-th : 0.116 0.114 0.113 0.118 0.127 0.136 0.141 0.137  ||  -0.079 -0.099 -0.108 -0.064 0.015 0.077 0.114 0.085   || dis=0.00 || select=6/8
016/019-th : 0.101 0.112 0.116 0.130 0.142 0.132 0.134 0.131  ||  -0.182 -0.080 -0.046 0.064 0.156 0.084 0.100 0.076    || dis=0.01 || select=4/8
017/019-th : 0.120 0.118 0.116 0.120 0.124 0.131 0.134 0.137  ||  -0.045 -0.056 -0.081 -0.044 -0.009 0.046 0.064 0.090  || dis=0.00 || select=7/8
018/019-th : 0.103 0.114 0.119 0.120 0.128 0.129 0.136 0.151  ||  -0.190 -0.093 -0.047 -0.036 0.025 0.036 0.084 0.190   || dis=0.01 || select=7/8
[epoch=024/600] FLOP : 27.02 MB, ratio : 0.6619, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:54:18] [epoch=024/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.773 (1.773)  Prec@1 32.81 (32.81) Prec@5 81.25 (81.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:54:24] [epoch=024/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.312 (2.110)  Prec@1 31.55 (33.98) Prec@5 77.38 (82.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.98 Prec@5 82.17 Error@1 66.02 Error@5 17.83 Loss:2.110
***[2020-01-29 05:54:25]*** VALID [epoch=024/600] loss = 2.110387, accuracy@1 = 33.98, accuracy@5 = 82.17 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:54:25]*** start epoch=025/600 Time Left: [05:07:28], LR=[0.099572 ~ 0.099572], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=25, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.979039910365835, FLOP=40.81
[Search] : epoch=025/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:54:25] [epoch=025/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 1.168 (1.168)  Prec@1 61.33 (61.33) Prec@5 94.92 (94.92) Acls-loss 1.113 (1.113) FLOP-Loss 0.000 (0.000) Arch-Loss 1.113 (1.113)
**TRAIN** [2020-01-29 05:54:51] [epoch=025/600][097/098] Time 0.27 (0.27) Data 0.00 (0.00) Base-Loss 1.241 (1.134)  Prec@1 54.17 (59.79) Prec@5 95.24 (95.56) Acls-loss 1.123 (1.138) FLOP-Loss -2.426 (0.034) Arch-Loss -3.730 (1.206)
 **TRAIN** Prec@1 59.79 Prec@5 95.56 Error@1 40.21 Error@5 4.44 Base-Loss:1.134, Arch-Loss=1.206
***[2020-01-29 05:54:51]*** TRAIN [epoch=025/600] base-loss = 1.134055, arch-loss = 1.205556, accuracy-1 = 59.79, accuracy-5 = 95.56
[epoch=025/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 16, 14, 32, 25, 32, 22, 22, 19, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.656768)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.364 0.271 0.365  ||  0.0025 -0.2928 0.0033  || discrepancy=0.00 || select=2/3
001/003-th : 0.372 0.255 0.374  ||  0.0077 -0.3712 0.0128  || discrepancy=0.00 || select=2/3
002/003-th : 0.358 0.239 0.403  ||  -0.0472 -0.4532 0.0712  || discrepancy=0.05 || select=2/3
-----------------------------------------------
000/019-th : 0.103 0.104 0.115 0.119 0.136 0.139 0.147 0.137  ||  -0.171 -0.165 -0.068 -0.026 0.101 0.128 0.179 0.114   || dis=0.01 || select=6/8
001/019-th : 0.122 0.121 0.122 0.123 0.124 0.129 0.129 0.130  ||  -0.021 -0.028 -0.021 -0.010 -0.008 0.031 0.035 0.041  || dis=0.00 || select=7/8
002/019-th : 0.119 0.121 0.124 0.127 0.129 0.128 0.126 0.127  ||  -0.048 -0.031 -0.006 0.021 0.032 0.024 0.012 0.022    || dis=0.00 || select=4/8
003/019-th : 0.125 0.124 0.127 0.126 0.124 0.124 0.125 0.125  ||  -0.004 -0.012 0.012 0.005 -0.007 -0.013 -0.003 -0.002  || dis=0.00 || select=2/8
004/019-th : 0.122 0.124 0.126 0.125 0.127 0.125 0.126 0.124  ||  -0.023 -0.005 0.013 0.005 0.023 0.005 0.012 -0.003    || dis=0.00 || select=4/8
005/019-th : 0.125 0.125 0.125 0.123 0.125 0.125 0.125 0.127  ||  -0.005 -0.005 -0.002 -0.015 -0.003 0.001 -0.001 0.012  || dis=0.00 || select=7/8
006/019-th : 0.120 0.124 0.125 0.127 0.127 0.124 0.127 0.126  ||  -0.036 -0.006 0.009 0.021 0.020 0.002 0.025 0.010     || dis=0.00 || select=6/8
007/019-th : 0.119 0.116 0.116 0.117 0.129 0.131 0.135 0.136  ||  -0.051 -0.074 -0.075 -0.066 0.031 0.045 0.074 0.078   || dis=0.00 || select=7/8
008/019-th : 0.112 0.116 0.117 0.128 0.134 0.135 0.129 0.129  ||  -0.093 -0.062 -0.056 0.034 0.079 0.092 0.047 0.047    || dis=0.00 || select=5/8
009/019-th : 0.123 0.122 0.119 0.124 0.124 0.127 0.129 0.131  ||  -0.021 -0.021 -0.047 -0.009 -0.005 0.018 0.033 0.044  || dis=0.00 || select=7/8
010/019-th : 0.120 0.120 0.122 0.126 0.129 0.128 0.128 0.127  ||  -0.040 -0.032 -0.022 0.015 0.040 0.029 0.028 0.019    || dis=0.00 || select=4/8
011/019-th : 0.122 0.118 0.116 0.121 0.131 0.130 0.131 0.131  ||  -0.020 -0.055 -0.077 -0.032 0.051 0.036 0.044 0.044   || dis=0.00 || select=4/8
012/019-th : 0.126 0.125 0.124 0.127 0.127 0.122 0.124 0.125  ||  0.009 0.002 -0.001 0.022 0.015 -0.022 -0.008 0.007    || dis=0.00 || select=3/8
013/019-th : 0.103 0.114 0.111 0.124 0.125 0.134 0.145 0.144  ||  -0.182 -0.085 -0.108 -0.005 0.007 0.073 0.155 0.148   || dis=0.00 || select=6/8
014/019-th : 0.101 0.102 0.115 0.130 0.138 0.136 0.142 0.136  ||  -0.188 -0.176 -0.061 0.060 0.126 0.107 0.153 0.107    || dis=0.00 || select=6/8
015/019-th : 0.116 0.115 0.113 0.115 0.123 0.137 0.143 0.138  ||  -0.079 -0.094 -0.109 -0.090 -0.022 0.081 0.126 0.089  || dis=0.00 || select=6/8
016/019-th : 0.100 0.111 0.117 0.129 0.142 0.133 0.135 0.132  ||  -0.192 -0.088 -0.043 0.058 0.156 0.091 0.106 0.080    || dis=0.01 || select=4/8
017/019-th : 0.120 0.119 0.116 0.120 0.124 0.131 0.133 0.137  ||  -0.042 -0.055 -0.078 -0.043 -0.008 0.042 0.062 0.088  || dis=0.00 || select=7/8
018/019-th : 0.102 0.114 0.118 0.122 0.127 0.128 0.136 0.152  ||  -0.203 -0.088 -0.052 -0.021 0.020 0.029 0.090 0.196   || dis=0.02 || select=7/8
[epoch=025/600] FLOP : 28.66 MB, ratio : 0.7021, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:54:52] [epoch=025/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.254 (2.254)  Prec@1 30.08 (30.08) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:54:58] [epoch=025/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.530 (2.324)  Prec@1 29.17 (33.46) Prec@5 78.57 (82.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.46 Prec@5 82.21 Error@1 66.54 Error@5 17.79 Loss:2.324
***[2020-01-29 05:54:58]*** VALID [epoch=025/600] loss = 2.323800, accuracy@1 = 33.46, accuracy@5 = 82.21 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:54:58]*** start epoch=026/600 Time Left: [05:07:21], LR=[0.099537 ~ 0.099537], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=26, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.977332209155037, FLOP=40.81
[Search] : epoch=026/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:54:59] [epoch=026/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 1.021 (1.021)  Prec@1 64.84 (64.84) Prec@5 97.27 (97.27) Acls-loss 1.148 (1.148) FLOP-Loss 2.427 (2.427) Arch-Loss 6.003 (6.003)
**TRAIN** [2020-01-29 05:55:25] [epoch=026/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 1.008 (1.131)  Prec@1 66.07 (59.71) Prec@5 95.24 (95.64) Acls-loss 1.161 (1.134) FLOP-Loss 0.000 (0.025) Arch-Loss 1.161 (1.184)
 **TRAIN** Prec@1 59.71 Prec@5 95.64 Error@1 40.29 Error@5 4.36 Base-Loss:1.131, Arch-Loss=1.184
***[2020-01-29 05:55:25]*** TRAIN [epoch=026/600] base-loss = 1.130981, arch-loss = 1.184068, accuracy-1 = 59.71, accuracy-5 = 95.64
[epoch=026/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 9, 11, 11, 14, 32, 22, 32, 22, 22, 19, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.1136)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.365 0.269 0.366  ||  0.0026 -0.3011 0.0039  || discrepancy=0.00 || select=2/3
001/003-th : 0.374 0.250 0.376  ||  0.0076 -0.3959 0.0142  || discrepancy=0.00 || select=2/3
002/003-th : 0.357 0.240 0.403  ||  -0.0487 -0.4457 0.0732  || discrepancy=0.05 || select=2/3
-----------------------------------------------
000/019-th : 0.102 0.104 0.114 0.120 0.137 0.139 0.147 0.137  ||  -0.182 -0.166 -0.070 -0.021 0.111 0.129 0.187 0.115   || dis=0.01 || select=6/8
001/019-th : 0.122 0.121 0.122 0.123 0.124 0.128 0.129 0.130  ||  -0.021 -0.030 -0.018 -0.010 -0.004 0.031 0.034 0.041  || dis=0.00 || select=7/8
002/019-th : 0.118 0.121 0.124 0.127 0.129 0.128 0.126 0.127  ||  -0.050 -0.032 -0.006 0.024 0.037 0.028 0.011 0.022    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.127 0.125 0.124 0.125 0.125  ||  -0.008 -0.011 0.009 0.014 -0.004 -0.009 -0.004 -0.002  || dis=0.00 || select=3/8
004/019-th : 0.121 0.124 0.125 0.125 0.129 0.126 0.126 0.124  ||  -0.025 -0.008 0.006 0.003 0.033 0.008 0.014 -0.002    || dis=0.00 || select=4/8
005/019-th : 0.125 0.124 0.125 0.122 0.127 0.126 0.125 0.127  ||  -0.004 -0.009 -0.003 -0.024 0.012 0.003 0.000 0.012   || dis=0.00 || select=4/8
006/019-th : 0.119 0.123 0.125 0.127 0.128 0.124 0.128 0.126  ||  -0.042 -0.009 0.011 0.027 0.028 0.001 0.029 0.011     || dis=0.00 || select=6/8
007/019-th : 0.118 0.116 0.117 0.118 0.128 0.131 0.136 0.136  ||  -0.057 -0.075 -0.072 -0.060 0.019 0.044 0.077 0.082   || dis=0.00 || select=7/8
008/019-th : 0.112 0.115 0.116 0.126 0.136 0.136 0.130 0.129  ||  -0.098 -0.067 -0.062 0.023 0.100 0.099 0.052 0.049    || dis=0.00 || select=4/8
009/019-th : 0.122 0.122 0.119 0.124 0.125 0.127 0.130 0.131  ||  -0.024 -0.022 -0.051 -0.007 -0.000 0.016 0.038 0.046  || dis=0.00 || select=7/8
010/019-th : 0.119 0.120 0.121 0.127 0.129 0.129 0.128 0.127  ||  -0.043 -0.032 -0.023 0.020 0.035 0.034 0.027 0.021    || dis=0.00 || select=4/8
011/019-th : 0.122 0.118 0.116 0.120 0.132 0.130 0.131 0.131  ||  -0.023 -0.059 -0.070 -0.036 0.056 0.041 0.044 0.044   || dis=0.00 || select=4/8
012/019-th : 0.126 0.124 0.124 0.128 0.126 0.122 0.124 0.125  ||  0.008 -0.001 -0.005 0.026 0.014 -0.017 -0.006 0.007   || dis=0.00 || select=3/8
013/019-th : 0.103 0.114 0.110 0.123 0.125 0.135 0.146 0.144  ||  -0.184 -0.087 -0.120 -0.006 0.007 0.082 0.159 0.149   || dis=0.00 || select=6/8
014/019-th : 0.100 0.102 0.115 0.131 0.136 0.137 0.143 0.136  ||  -0.196 -0.182 -0.057 0.067 0.105 0.118 0.158 0.108    || dis=0.01 || select=6/8
015/019-th : 0.116 0.115 0.113 0.115 0.123 0.136 0.143 0.138  ||  -0.082 -0.094 -0.111 -0.091 -0.021 0.078 0.129 0.093  || dis=0.00 || select=6/8
016/019-th : 0.100 0.111 0.117 0.129 0.141 0.133 0.136 0.132  ||  -0.195 -0.090 -0.042 0.057 0.148 0.089 0.111 0.081    || dis=0.00 || select=4/8
017/019-th : 0.120 0.118 0.116 0.122 0.124 0.131 0.133 0.137  ||  -0.042 -0.056 -0.080 -0.028 -0.009 0.042 0.060 0.089  || dis=0.00 || select=7/8
018/019-th : 0.101 0.114 0.119 0.122 0.128 0.128 0.136 0.151  ||  -0.204 -0.088 -0.042 -0.017 0.027 0.029 0.085 0.194   || dis=0.01 || select=7/8
[epoch=026/600] FLOP : 27.11 MB, ratio : 0.6643, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:55:25] [epoch=026/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.222 (3.222)  Prec@1 30.08 (30.08) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:55:31] [epoch=026/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.869 (2.490)  Prec@1 46.43 (32.41) Prec@5 84.52 (82.11) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.41 Prec@5 82.11 Error@1 67.59 Error@5 17.89 Loss:2.490
***[2020-01-29 05:55:31]*** VALID [epoch=026/600] loss = 2.490490, accuracy@1 = 32.41, accuracy@5 = 82.11 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:55:31]*** start epoch=027/600 Time Left: [05:07:13], LR=[0.099501 ~ 0.099501], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=27, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.975557961405566, FLOP=40.81
[Search] : epoch=027/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:55:32] [epoch=027/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 1.133 (1.133)  Prec@1 59.38 (59.38) Prec@5 95.70 (95.70) Acls-loss 1.128 (1.128) FLOP-Loss 0.000 (0.000) Arch-Loss 1.128 (1.128)
**TRAIN** [2020-01-29 05:55:58] [epoch=027/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 1.105 (1.117)  Prec@1 64.88 (60.32) Prec@5 95.83 (95.73) Acls-loss 1.100 (1.142) FLOP-Loss 2.430 (0.042) Arch-Loss 5.959 (1.225)
 **TRAIN** Prec@1 60.32 Prec@5 95.73 Error@1 39.68 Error@5 4.27 Base-Loss:1.117, Arch-Loss=1.225
***[2020-01-29 05:55:58]*** TRAIN [epoch=027/600] base-loss = 1.117166, arch-loss = 1.224639, accuracy-1 = 60.32, accuracy-5 = 95.73
[epoch=027/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 16, 14, 32, 25, 32, 22, 22, 19, 57, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 23.190656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.365 0.270 0.365  ||  0.0041 -0.3002 0.0030  || discrepancy=0.00 || select=0/3
001/003-th : 0.376 0.247 0.377  ||  0.0098 -0.4086 0.0130  || discrepancy=0.00 || select=2/3
002/003-th : 0.358 0.237 0.406  ||  -0.0502 -0.4619 0.0758  || discrepancy=0.05 || select=2/3
-----------------------------------------------
000/019-th : 0.101 0.104 0.114 0.121 0.135 0.140 0.148 0.138  ||  -0.188 -0.166 -0.068 -0.015 0.096 0.136 0.188 0.117   || dis=0.01 || select=6/8
001/019-th : 0.122 0.121 0.122 0.124 0.124 0.128 0.129 0.130  ||  -0.022 -0.026 -0.019 -0.006 -0.009 0.028 0.034 0.040  || dis=0.00 || select=7/8
002/019-th : 0.118 0.121 0.124 0.128 0.129 0.128 0.126 0.127  ||  -0.050 -0.029 -0.004 0.028 0.034 0.028 0.010 0.021    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.127 0.126 0.125 0.124 0.125 0.125  ||  -0.007 -0.007 0.010 0.008 -0.005 -0.008 -0.005 -0.003  || dis=0.00 || select=2/8
004/019-th : 0.121 0.124 0.126 0.124 0.129 0.126 0.126 0.124  ||  -0.026 -0.007 0.012 -0.000 0.034 0.009 0.012 -0.002   || dis=0.00 || select=4/8
005/019-th : 0.125 0.124 0.125 0.122 0.126 0.126 0.125 0.127  ||  -0.001 -0.008 -0.004 -0.029 0.008 0.003 -0.000 0.011  || dis=0.00 || select=7/8
006/019-th : 0.119 0.123 0.126 0.128 0.127 0.123 0.128 0.126  ||  -0.042 -0.007 0.012 0.028 0.023 -0.006 0.029 0.011    || dis=0.00 || select=6/8
007/019-th : 0.118 0.116 0.117 0.118 0.127 0.131 0.136 0.137  ||  -0.057 -0.082 -0.073 -0.058 0.016 0.047 0.079 0.086   || dis=0.00 || select=7/8
008/019-th : 0.111 0.115 0.117 0.125 0.136 0.137 0.129 0.129  ||  -0.103 -0.065 -0.054 0.018 0.097 0.103 0.049 0.049    || dis=0.00 || select=5/8
009/019-th : 0.122 0.122 0.118 0.124 0.125 0.127 0.130 0.131  ||  -0.025 -0.021 -0.056 -0.010 -0.003 0.019 0.038 0.048  || dis=0.00 || select=7/8
010/019-th : 0.119 0.120 0.121 0.127 0.130 0.128 0.127 0.127  ||  -0.042 -0.031 -0.027 0.020 0.045 0.031 0.025 0.020    || dis=0.00 || select=4/8
011/019-th : 0.122 0.118 0.117 0.120 0.132 0.130 0.131 0.131  ||  -0.026 -0.057 -0.065 -0.044 0.052 0.041 0.046 0.044   || dis=0.00 || select=4/8
012/019-th : 0.126 0.125 0.124 0.127 0.125 0.123 0.124 0.125  ||  0.009 0.002 -0.003 0.016 0.004 -0.016 -0.005 0.005    || dis=0.00 || select=3/8
013/019-th : 0.103 0.114 0.111 0.122 0.124 0.135 0.146 0.145  ||  -0.186 -0.090 -0.110 -0.018 -0.004 0.079 0.163 0.153  || dis=0.00 || select=6/8
014/019-th : 0.100 0.101 0.116 0.130 0.135 0.139 0.143 0.136  ||  -0.201 -0.189 -0.052 0.065 0.098 0.127 0.161 0.110    || dis=0.00 || select=6/8
015/019-th : 0.116 0.115 0.112 0.113 0.123 0.138 0.144 0.139  ||  -0.080 -0.094 -0.117 -0.107 -0.027 0.087 0.131 0.095  || dis=0.00 || select=6/8
016/019-th : 0.100 0.111 0.117 0.128 0.142 0.132 0.137 0.132  ||  -0.200 -0.094 -0.038 0.050 0.153 0.082 0.116 0.083    || dis=0.00 || select=4/8
017/019-th : 0.120 0.118 0.116 0.121 0.125 0.130 0.133 0.137  ||  -0.039 -0.055 -0.076 -0.035 0.001 0.035 0.058 0.089   || dis=0.00 || select=7/8
018/019-th : 0.101 0.113 0.119 0.122 0.128 0.127 0.137 0.153  ||  -0.209 -0.098 -0.047 -0.018 0.029 0.020 0.097 0.203   || dis=0.02 || select=7/8
[epoch=027/600] FLOP : 23.19 MB, ratio : 0.5682, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:55:58] [epoch=027/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.929 (1.929)  Prec@1 42.19 (42.19) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:56:05] [epoch=027/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.970 (2.486)  Prec@1 39.29 (32.10) Prec@5 86.90 (79.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.10 Prec@5 79.78 Error@1 67.90 Error@5 20.22 Loss:2.486
***[2020-01-29 05:56:05]*** VALID [epoch=027/600] loss = 2.486144, accuracy@1 = 32.10, accuracy@5 = 79.78 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:56:05]*** start epoch=028/600 Time Left: [05:07:10], LR=[0.099464 ~ 0.099464], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=28, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.973717215759321, FLOP=40.81
[Search] : epoch=028/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:56:05] [epoch=028/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 0.990 (0.990)  Prec@1 66.41 (66.41) Prec@5 98.83 (98.83) Acls-loss 0.999 (0.999) FLOP-Loss -2.429 (-2.429) Arch-Loss -3.860 (-3.860)
**TRAIN** [2020-01-29 05:56:32] [epoch=028/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 1.067 (1.123)  Prec@1 59.52 (59.84) Prec@5 97.02 (95.76) Acls-loss 1.082 (1.138) FLOP-Loss 0.000 (-0.025) Arch-Loss 1.082 (1.089)
 **TRAIN** Prec@1 59.84 Prec@5 95.76 Error@1 40.16 Error@5 4.24 Base-Loss:1.123, Arch-Loss=1.089
***[2020-01-29 05:56:32]*** TRAIN [epoch=028/600] base-loss = 1.122557, arch-loss = 1.088520, accuracy-1 = 59.84, accuracy-5 = 95.76
[epoch=028/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 9, 11, 11, 11, 32, 25, 32, 22, 28, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.768064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.364 0.272 0.365  ||  0.0021 -0.2901 0.0052  || discrepancy=0.00 || select=2/3
001/003-th : 0.374 0.247 0.378  ||  0.0066 -0.4083 0.0167  || discrepancy=0.00 || select=2/3
002/003-th : 0.356 0.236 0.408  ||  -0.0552 -0.4673 0.0815  || discrepancy=0.05 || select=2/3
-----------------------------------------------
000/019-th : 0.101 0.104 0.114 0.121 0.134 0.141 0.148 0.138  ||  -0.196 -0.165 -0.074 -0.011 0.092 0.143 0.189 0.122   || dis=0.01 || select=6/8
001/019-th : 0.122 0.121 0.122 0.123 0.124 0.129 0.129 0.130  ||  -0.024 -0.030 -0.021 -0.013 -0.005 0.033 0.036 0.044  || dis=0.00 || select=7/8
002/019-th : 0.117 0.121 0.124 0.127 0.129 0.129 0.126 0.127  ||  -0.056 -0.031 -0.006 0.025 0.037 0.035 0.014 0.023    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.126 0.125 0.125 0.125 0.125  ||  -0.009 -0.008 0.003 0.004 0.001 -0.005 -0.003 -0.001  || dis=0.00 || select=3/8
004/019-th : 0.121 0.123 0.125 0.125 0.129 0.126 0.127 0.125  ||  -0.030 -0.010 0.007 0.002 0.034 0.009 0.017 0.001     || dis=0.00 || select=4/8
005/019-th : 0.125 0.124 0.125 0.121 0.127 0.126 0.126 0.127  ||  -0.004 -0.009 -0.005 -0.033 0.015 0.003 0.003 0.013   || dis=0.00 || select=4/8
006/019-th : 0.118 0.123 0.125 0.128 0.129 0.124 0.128 0.126  ||  -0.046 -0.012 0.006 0.028 0.039 -0.004 0.032 0.014    || dis=0.00 || select=4/8
007/019-th : 0.118 0.115 0.116 0.118 0.129 0.132 0.136 0.137  ||  -0.063 -0.085 -0.077 -0.061 0.029 0.053 0.080 0.091   || dis=0.00 || select=7/8
008/019-th : 0.110 0.115 0.117 0.125 0.137 0.137 0.130 0.130  ||  -0.109 -0.070 -0.054 0.014 0.105 0.106 0.056 0.052    || dis=0.00 || select=5/8
009/019-th : 0.122 0.122 0.118 0.123 0.125 0.128 0.130 0.132  ||  -0.028 -0.024 -0.059 -0.016 0.003 0.022 0.040 0.052   || dis=0.00 || select=7/8
010/019-th : 0.119 0.120 0.120 0.126 0.130 0.129 0.128 0.128  ||  -0.047 -0.034 -0.039 0.016 0.044 0.036 0.029 0.028    || dis=0.00 || select=4/8
011/019-th : 0.122 0.118 0.117 0.119 0.130 0.130 0.132 0.132  ||  -0.030 -0.062 -0.069 -0.047 0.037 0.041 0.056 0.050   || dis=0.00 || select=6/8
012/019-th : 0.126 0.124 0.124 0.126 0.126 0.124 0.125 0.126  ||  0.007 -0.003 -0.010 0.007 0.013 -0.009 -0.001 0.007   || dis=0.00 || select=4/8
013/019-th : 0.103 0.113 0.111 0.122 0.122 0.136 0.147 0.146  ||  -0.191 -0.096 -0.111 -0.018 -0.016 0.085 0.165 0.160  || dis=0.00 || select=6/8
014/019-th : 0.099 0.101 0.116 0.130 0.133 0.140 0.145 0.137  ||  -0.213 -0.191 -0.055 0.061 0.088 0.135 0.170 0.115    || dis=0.00 || select=6/8
015/019-th : 0.115 0.114 0.112 0.113 0.125 0.137 0.144 0.139  ||  -0.089 -0.100 -0.113 -0.105 -0.008 0.086 0.134 0.101  || dis=0.00 || select=6/8
016/019-th : 0.099 0.110 0.117 0.128 0.143 0.133 0.137 0.133  ||  -0.206 -0.103 -0.040 0.049 0.164 0.087 0.119 0.087    || dis=0.01 || select=4/8
017/019-th : 0.120 0.118 0.115 0.121 0.127 0.129 0.133 0.137  ||  -0.041 -0.059 -0.084 -0.036 0.012 0.032 0.061 0.093   || dis=0.00 || select=7/8
018/019-th : 0.101 0.112 0.118 0.124 0.126 0.128 0.137 0.154  ||  -0.214 -0.105 -0.054 -0.007 0.015 0.026 0.097 0.214   || dis=0.02 || select=7/8
[epoch=028/600] FLOP : 27.77 MB, ratio : 0.6804, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:56:32] [epoch=028/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.816 (2.816)  Prec@1 20.70 (20.70) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:56:38] [epoch=028/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.679 (2.209)  Prec@1 44.64 (34.26) Prec@5 87.50 (82.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.26 Prec@5 82.32 Error@1 65.74 Error@5 17.68 Loss:2.209
***[2020-01-29 05:56:38]*** VALID [epoch=028/600] loss = 2.209079, accuracy@1 = 34.26, accuracy@5 = 82.32 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:56:38]*** start epoch=029/600 Time Left: [05:06:58], LR=[0.099425 ~ 0.099425], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=29, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.971810022681274, FLOP=40.81
[Search] : epoch=029/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:56:39] [epoch=029/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 1.127 (1.127)  Prec@1 60.55 (60.55) Prec@5 94.92 (94.92) Acls-loss 1.144 (1.144) FLOP-Loss 0.000 (0.000) Arch-Loss 1.144 (1.144)
**TRAIN** [2020-01-29 05:57:04] [epoch=029/600][097/098] Time 0.28 (0.27) Data 0.00 (0.00) Base-Loss 1.016 (1.101)  Prec@1 60.71 (60.52) Prec@5 98.21 (95.89) Acls-loss 0.999 (1.122) FLOP-Loss 0.000 (0.000) Arch-Loss 0.999 (1.122)
 **TRAIN** Prec@1 60.52 Prec@5 95.89 Error@1 39.48 Error@5 4.11 Base-Loss:1.101, Arch-Loss=1.122
***[2020-01-29 05:57:04]*** TRAIN [epoch=029/600] base-loss = 1.101226, arch-loss = 1.121835, accuracy-1 = 60.52, accuracy-5 = 95.89
[epoch=029/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 11, 11, 11, 11, 32, 25, 32, 22, 28, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.173568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.274 0.364  ||  0.0011 -0.2773 0.0064  || discrepancy=0.00 || select=2/3
001/003-th : 0.373 0.248 0.378  ||  0.0054 -0.4033 0.0184  || discrepancy=0.01 || select=2/3
002/003-th : 0.356 0.234 0.411  ||  -0.0585 -0.4792 0.0856  || discrepancy=0.05 || select=2/3
-----------------------------------------------
000/019-th : 0.100 0.104 0.113 0.120 0.134 0.141 0.149 0.139  ||  -0.202 -0.163 -0.082 -0.020 0.090 0.141 0.193 0.127   || dis=0.01 || select=6/8
001/019-th : 0.121 0.121 0.122 0.123 0.124 0.129 0.130 0.130  ||  -0.026 -0.033 -0.025 -0.012 -0.006 0.036 0.039 0.046  || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.124 0.127 0.129 0.129 0.126 0.128  ||  -0.059 -0.032 -0.007 0.021 0.037 0.035 0.017 0.025    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.008 0.002 0.001 0.002 -0.003 -0.001 0.000   || dis=0.00 || select=4/8
004/019-th : 0.120 0.123 0.125 0.124 0.130 0.126 0.127 0.125  ||  -0.033 -0.012 0.004 -0.002 0.047 0.013 0.017 0.003    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.125 0.120 0.128 0.126 0.126 0.127  ||  -0.006 -0.009 -0.006 -0.041 0.018 0.002 0.006 0.015   || dis=0.00 || select=4/8
006/019-th : 0.118 0.122 0.125 0.128 0.129 0.124 0.128 0.126  ||  -0.049 -0.014 0.009 0.029 0.037 0.001 0.034 0.014     || dis=0.00 || select=4/8
007/019-th : 0.117 0.114 0.115 0.119 0.130 0.132 0.136 0.138  ||  -0.069 -0.090 -0.082 -0.053 0.035 0.053 0.085 0.096   || dis=0.00 || select=7/8
008/019-th : 0.110 0.114 0.116 0.123 0.138 0.138 0.131 0.130  ||  -0.114 -0.076 -0.061 0.002 0.112 0.115 0.061 0.056    || dis=0.00 || select=5/8
009/019-th : 0.121 0.122 0.118 0.122 0.126 0.128 0.131 0.132  ||  -0.030 -0.027 -0.063 -0.023 0.003 0.023 0.043 0.055   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.119 0.126 0.130 0.129 0.129 0.128  ||  -0.049 -0.033 -0.042 0.010 0.045 0.037 0.032 0.029    || dis=0.00 || select=4/8
011/019-th : 0.121 0.118 0.116 0.120 0.128 0.131 0.133 0.132  ||  -0.035 -0.060 -0.073 -0.045 0.025 0.047 0.058 0.054   || dis=0.00 || select=6/8
012/019-th : 0.125 0.124 0.123 0.126 0.128 0.123 0.125 0.126  ||  0.004 -0.003 -0.017 0.011 0.027 -0.010 0.001 0.009    || dis=0.00 || select=4/8
013/019-th : 0.102 0.113 0.110 0.121 0.123 0.136 0.148 0.147  ||  -0.194 -0.100 -0.123 -0.026 -0.014 0.091 0.172 0.165  || dis=0.00 || select=6/8
014/019-th : 0.098 0.101 0.114 0.128 0.133 0.141 0.146 0.138  ||  -0.219 -0.195 -0.067 0.046 0.083 0.142 0.178 0.124    || dis=0.01 || select=6/8
015/019-th : 0.114 0.113 0.112 0.113 0.126 0.137 0.144 0.140  ||  -0.094 -0.106 -0.115 -0.102 0.003 0.089 0.137 0.107   || dis=0.00 || select=6/8
016/019-th : 0.098 0.109 0.117 0.128 0.143 0.134 0.138 0.133  ||  -0.213 -0.107 -0.044 0.050 0.163 0.092 0.123 0.091    || dis=0.00 || select=4/8
017/019-th : 0.120 0.118 0.115 0.120 0.126 0.130 0.133 0.137  ||  -0.042 -0.060 -0.081 -0.046 0.007 0.038 0.064 0.093   || dis=0.00 || select=7/8
018/019-th : 0.100 0.112 0.118 0.122 0.127 0.128 0.139 0.155  ||  -0.218 -0.111 -0.055 -0.020 0.016 0.025 0.106 0.220   || dis=0.02 || select=7/8
[epoch=029/600] FLOP : 28.17 MB, ratio : 0.6903, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:57:04] [epoch=029/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.166 (2.166)  Prec@1 35.16 (35.16) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:57:10] [epoch=029/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.581 (2.135)  Prec@1 37.50 (34.16) Prec@5 93.45 (82.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.16 Prec@5 82.32 Error@1 65.84 Error@5 17.68 Loss:2.135
***[2020-01-29 05:57:10]*** VALID [epoch=029/600] loss = 2.134634, accuracy@1 = 34.16, accuracy@5 = 82.32 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:57:10]*** start epoch=030/600 Time Left: [05:06:30], LR=[0.099384 ~ 0.099384], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=30, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.969836434458087, FLOP=40.81
[Search] : epoch=030/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:57:11] [epoch=030/600][000/098] Time 0.78 (0.78) Data 0.35 (0.35) Base-Loss 1.056 (1.056)  Prec@1 63.67 (63.67) Prec@5 96.48 (96.48) Acls-loss 1.054 (1.054) FLOP-Loss 0.000 (0.000) Arch-Loss 1.054 (1.054)
**TRAIN** [2020-01-29 05:57:37] [epoch=030/600][097/098] Time 0.28 (0.27) Data 0.00 (0.00) Base-Loss 1.083 (1.114)  Prec@1 60.71 (60.52) Prec@5 95.83 (95.78) Acls-loss 1.141 (1.117) FLOP-Loss 0.000 (0.050) Arch-Loss 1.141 (1.217)
 **TRAIN** Prec@1 60.52 Prec@5 95.78 Error@1 39.48 Error@5 4.22 Base-Loss:1.114, Arch-Loss=1.217
***[2020-01-29 05:57:37]*** TRAIN [epoch=030/600] base-loss = 1.114177, arch-loss = 1.217151, accuracy-1 = 60.52, accuracy-5 = 95.78
[epoch=030/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 11, 32, 25, 32, 22, 28, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.565312)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.276 0.362  ||  0.0035 -0.2695 0.0043  || discrepancy=0.00 || select=2/3
001/003-th : 0.375 0.246 0.379  ||  0.0078 -0.4148 0.0168  || discrepancy=0.00 || select=2/3
002/003-th : 0.356 0.232 0.412  ||  -0.0587 -0.4853 0.0866  || discrepancy=0.06 || select=2/3
-----------------------------------------------
000/019-th : 0.100 0.104 0.112 0.119 0.134 0.143 0.149 0.139  ||  -0.202 -0.167 -0.087 -0.026 0.090 0.153 0.193 0.129   || dis=0.01 || select=6/8
001/019-th : 0.122 0.121 0.122 0.123 0.124 0.129 0.130 0.130  ||  -0.026 -0.033 -0.022 -0.013 -0.006 0.036 0.038 0.044  || dis=0.00 || select=7/8
002/019-th : 0.117 0.121 0.124 0.127 0.129 0.129 0.126 0.127  ||  -0.058 -0.029 -0.006 0.020 0.034 0.033 0.015 0.024    || dis=0.00 || select=4/8
003/019-th : 0.124 0.125 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.010 -0.006 0.004 -0.002 0.001 -0.003 -0.003 -0.001  || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.125 0.125 0.130 0.126 0.127 0.125  ||  -0.033 -0.012 0.007 0.001 0.044 0.011 0.017 0.003     || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.125 0.121 0.128 0.125 0.126 0.127  ||  -0.006 -0.007 -0.002 -0.035 0.022 0.002 0.003 0.013   || dis=0.00 || select=4/8
006/019-th : 0.118 0.123 0.125 0.127 0.129 0.124 0.128 0.126  ||  -0.048 -0.013 0.010 0.027 0.035 -0.003 0.034 0.013    || dis=0.00 || select=4/8
007/019-th : 0.117 0.115 0.114 0.118 0.131 0.131 0.136 0.138  ||  -0.069 -0.087 -0.089 -0.055 0.046 0.050 0.085 0.097   || dis=0.00 || select=7/8
008/019-th : 0.110 0.114 0.116 0.124 0.138 0.138 0.131 0.130  ||  -0.115 -0.078 -0.055 0.006 0.113 0.113 0.060 0.056    || dis=0.00 || select=5/8
009/019-th : 0.121 0.122 0.118 0.123 0.125 0.128 0.131 0.133  ||  -0.030 -0.025 -0.061 -0.021 -0.002 0.019 0.043 0.057  || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.120 0.127 0.130 0.129 0.128 0.127  ||  -0.050 -0.034 -0.038 0.021 0.049 0.037 0.032 0.025    || dis=0.00 || select=4/8
011/019-th : 0.121 0.118 0.116 0.120 0.128 0.131 0.132 0.132  ||  -0.033 -0.058 -0.074 -0.041 0.020 0.048 0.054 0.054   || dis=0.00 || select=6/8
012/019-th : 0.125 0.124 0.123 0.125 0.128 0.124 0.125 0.126  ||  0.006 -0.003 -0.014 0.002 0.026 -0.009 -0.000 0.008   || dis=0.00 || select=4/8
013/019-th : 0.102 0.112 0.110 0.121 0.123 0.137 0.148 0.147  ||  -0.198 -0.103 -0.124 -0.029 -0.011 0.096 0.174 0.169  || dis=0.00 || select=6/8
014/019-th : 0.098 0.100 0.115 0.128 0.134 0.141 0.146 0.138  ||  -0.221 -0.199 -0.063 0.050 0.092 0.144 0.182 0.119    || dis=0.01 || select=6/8
015/019-th : 0.115 0.113 0.112 0.113 0.125 0.137 0.144 0.140  ||  -0.093 -0.107 -0.112 -0.107 -0.005 0.088 0.137 0.109  || dis=0.00 || select=6/8
016/019-th : 0.098 0.109 0.116 0.129 0.144 0.133 0.137 0.133  ||  -0.217 -0.109 -0.045 0.061 0.173 0.094 0.122 0.089    || dis=0.01 || select=4/8
017/019-th : 0.121 0.119 0.116 0.120 0.124 0.129 0.134 0.138  ||  -0.038 -0.058 -0.077 -0.049 -0.014 0.030 0.065 0.094  || dis=0.00 || select=7/8
018/019-th : 0.100 0.111 0.117 0.121 0.127 0.128 0.139 0.156  ||  -0.215 -0.119 -0.061 -0.026 0.023 0.029 0.108 0.224   || dis=0.02 || select=7/8
[epoch=030/600] FLOP : 27.57 MB, ratio : 0.6754, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:57:37] [epoch=030/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.584 (2.584)  Prec@1 35.16 (35.16) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:57:43] [epoch=030/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.403 (2.410)  Prec@1 33.93 (32.02) Prec@5 83.33 (80.47) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.02 Prec@5 80.47 Error@1 67.98 Error@5 19.53 Loss:2.410
***[2020-01-29 05:57:43]*** VALID [epoch=030/600] loss = 2.409523, accuracy@1 = 32.02, accuracy@5 = 80.47 | Best-Valid-Acc@1=34.66, Error@1=65.34
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:57:43]*** start epoch=031/600 Time Left: [05:06:06], LR=[0.099343 ~ 0.099343], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=31, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.967796505196678, FLOP=40.81
[Search] : epoch=031/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:57:44] [epoch=031/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 1.185 (1.185)  Prec@1 57.81 (57.81) Prec@5 95.70 (95.70) Acls-loss 0.964 (0.964) FLOP-Loss 0.000 (0.000) Arch-Loss 0.964 (0.964)
**TRAIN** [2020-01-29 05:58:10] [epoch=031/600][097/098] Time 0.24 (0.28) Data 0.00 (0.00) Base-Loss 1.075 (1.098)  Prec@1 60.71 (60.64) Prec@5 94.64 (95.94) Acls-loss 1.138 (1.113) FLOP-Loss 0.000 (0.000) Arch-Loss 1.138 (1.113)
 **TRAIN** Prec@1 60.64 Prec@5 95.94 Error@1 39.36 Error@5 4.06 Base-Loss:1.098, Arch-Loss=1.113
***[2020-01-29 05:58:10]*** TRAIN [epoch=031/600] base-loss = 1.098487, arch-loss = 1.113348, accuracy-1 = 60.64, accuracy-5 = 95.94
[epoch=031/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 11, 32, 25, 32, 22, 32, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.970816)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.275 0.363  ||  0.0033 -0.2704 0.0049  || discrepancy=0.00 || select=2/3
001/003-th : 0.376 0.243 0.381  ||  0.0063 -0.4293 0.0193  || discrepancy=0.01 || select=2/3
002/003-th : 0.354 0.233 0.414  ||  -0.0641 -0.4834 0.0925  || discrepancy=0.06 || select=2/3
-----------------------------------------------
000/019-th : 0.099 0.103 0.112 0.120 0.134 0.143 0.149 0.140  ||  -0.209 -0.170 -0.090 -0.022 0.089 0.153 0.198 0.133   || dis=0.01 || select=6/8
001/019-th : 0.121 0.120 0.122 0.124 0.124 0.129 0.130 0.130  ||  -0.029 -0.034 -0.021 -0.007 -0.003 0.037 0.039 0.045  || dis=0.00 || select=7/8
002/019-th : 0.117 0.121 0.124 0.127 0.129 0.129 0.127 0.127  ||  -0.059 -0.031 -0.005 0.017 0.037 0.033 0.017 0.024    || dis=0.00 || select=4/8
003/019-th : 0.124 0.125 0.126 0.125 0.126 0.125 0.125 0.125  ||  -0.012 -0.006 0.005 -0.005 0.004 -0.000 -0.001 -0.001  || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.125 0.124 0.130 0.126 0.127 0.125  ||  -0.035 -0.013 0.004 -0.002 0.041 0.014 0.019 0.004    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.124 0.121 0.127 0.126 0.126 0.127  ||  -0.008 -0.009 -0.006 -0.030 0.018 0.003 0.007 0.015   || dis=0.00 || select=4/8
006/019-th : 0.118 0.122 0.125 0.127 0.129 0.124 0.129 0.126  ||  -0.050 -0.014 0.008 0.020 0.040 0.000 0.035 0.015     || dis=0.00 || select=4/8
007/019-th : 0.116 0.114 0.113 0.118 0.131 0.132 0.137 0.138  ||  -0.074 -0.091 -0.097 -0.058 0.047 0.052 0.092 0.102   || dis=0.00 || select=7/8
008/019-th : 0.110 0.114 0.116 0.123 0.137 0.138 0.131 0.131  ||  -0.116 -0.081 -0.063 -0.001 0.109 0.116 0.064 0.060   || dis=0.00 || select=5/8
009/019-th : 0.121 0.122 0.117 0.123 0.125 0.127 0.131 0.133  ||  -0.034 -0.026 -0.064 -0.018 0.002 0.018 0.048 0.059   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.119 0.126 0.131 0.129 0.128 0.128  ||  -0.051 -0.036 -0.042 0.015 0.048 0.040 0.032 0.028    || dis=0.00 || select=4/8
011/019-th : 0.121 0.119 0.116 0.119 0.126 0.132 0.133 0.133  ||  -0.034 -0.057 -0.081 -0.050 0.007 0.049 0.057 0.060   || dis=0.00 || select=7/8
012/019-th : 0.125 0.124 0.123 0.124 0.128 0.124 0.125 0.126  ||  0.003 -0.005 -0.017 -0.003 0.024 -0.008 0.005 0.011   || dis=0.00 || select=4/8
013/019-th : 0.101 0.111 0.109 0.120 0.124 0.137 0.149 0.148  ||  -0.205 -0.108 -0.129 -0.031 -0.000 0.098 0.179 0.175  || dis=0.00 || select=6/8
014/019-th : 0.097 0.099 0.114 0.127 0.136 0.142 0.147 0.138  ||  -0.228 -0.206 -0.070 0.043 0.111 0.156 0.189 0.121    || dis=0.01 || select=6/8
015/019-th : 0.114 0.112 0.113 0.113 0.126 0.138 0.145 0.140  ||  -0.100 -0.117 -0.109 -0.110 0.001 0.098 0.144 0.112   || dis=0.00 || select=6/8
016/019-th : 0.097 0.108 0.116 0.129 0.143 0.135 0.138 0.134  ||  -0.228 -0.114 -0.047 0.058 0.163 0.103 0.127 0.096    || dis=0.00 || select=4/8
017/019-th : 0.121 0.118 0.115 0.121 0.123 0.130 0.134 0.138  ||  -0.038 -0.062 -0.085 -0.035 -0.021 0.035 0.070 0.093  || dis=0.00 || select=7/8
018/019-th : 0.099 0.109 0.117 0.122 0.129 0.128 0.140 0.156  ||  -0.226 -0.128 -0.061 -0.015 0.035 0.032 0.117 0.226   || dis=0.02 || select=7/8
[epoch=031/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:58:11] [epoch=031/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.382 (1.382)  Prec@1 48.44 (48.44) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:58:16] [epoch=031/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.200 (2.164)  Prec@1 26.19 (35.75) Prec@5 79.17 (83.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.75 Prec@5 83.70 Error@1 64.25 Error@5 16.30 Loss:2.164
***[2020-01-29 05:58:17]*** VALID [epoch=031/600] loss = 2.163946, accuracy@1 = 35.75, accuracy@5 = 83.70 | Best-Valid-Acc@1=34.66, Error@1=65.34
Currently, the best validation accuracy found at 031-epoch :: acc@1=35.75, acc@5=83.70, error@1=64.25, error@5=16.30, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:58:17]*** start epoch=032/600 Time Left: [05:05:54], LR=[0.099300 ~ 0.099300], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=32, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.965690290822737, FLOP=40.81
[Search] : epoch=032/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:58:17] [epoch=032/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 1.020 (1.020)  Prec@1 63.67 (63.67) Prec@5 97.66 (97.66) Acls-loss 1.046 (1.046) FLOP-Loss 0.000 (0.000) Arch-Loss 1.046 (1.046)
**TRAIN** [2020-01-29 05:58:44] [epoch=032/600][097/098] Time 0.28 (0.28) Data 0.00 (0.00) Base-Loss 1.025 (1.095)  Prec@1 60.71 (61.34) Prec@5 97.02 (96.04) Acls-loss 1.122 (1.117) FLOP-Loss 2.440 (0.042) Arch-Loss 6.002 (1.201)
 **TRAIN** Prec@1 61.34 Prec@5 96.04 Error@1 38.66 Error@5 3.96 Base-Loss:1.095, Arch-Loss=1.201
***[2020-01-29 05:58:44]*** TRAIN [epoch=032/600] base-loss = 1.094699, arch-loss = 1.200910, accuracy-1 = 61.34, accuracy-5 = 96.04
[epoch=032/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 14, 32, 25, 32, 25, 32, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.80128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.360 0.281 0.359  ||  0.0047 -0.2443 0.0034  || discrepancy=0.00 || select=0/3
001/003-th : 0.375 0.245 0.380  ||  0.0074 -0.4195 0.0185  || discrepancy=0.01 || select=2/3
002/003-th : 0.354 0.231 0.415  ||  -0.0654 -0.4891 0.0945  || discrepancy=0.06 || select=2/3
-----------------------------------------------
000/019-th : 0.099 0.103 0.111 0.120 0.131 0.144 0.150 0.141  ||  -0.213 -0.170 -0.097 -0.024 0.068 0.159 0.201 0.139   || dis=0.01 || select=6/8
001/019-th : 0.121 0.121 0.122 0.123 0.124 0.129 0.129 0.130  ||  -0.028 -0.031 -0.020 -0.010 -0.007 0.038 0.038 0.044  || dis=0.00 || select=7/8
002/019-th : 0.117 0.121 0.124 0.126 0.130 0.129 0.126 0.127  ||  -0.058 -0.031 -0.003 0.015 0.041 0.033 0.015 0.023    || dis=0.00 || select=4/8
003/019-th : 0.124 0.125 0.126 0.125 0.126 0.125 0.125 0.125  ||  -0.011 -0.005 0.007 -0.001 0.003 -0.001 -0.002 -0.002  || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.125 0.125 0.129 0.126 0.127 0.125  ||  -0.036 -0.014 0.001 0.006 0.039 0.013 0.020 0.005     || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.125 0.121 0.128 0.125 0.126 0.127  ||  -0.008 -0.009 -0.002 -0.030 0.019 -0.001 0.004 0.016  || dis=0.00 || select=4/8
006/019-th : 0.118 0.123 0.125 0.127 0.128 0.124 0.129 0.126  ||  -0.050 -0.012 0.009 0.021 0.031 -0.002 0.034 0.014    || dis=0.00 || select=6/8
007/019-th : 0.116 0.114 0.113 0.118 0.130 0.133 0.138 0.139  ||  -0.076 -0.095 -0.102 -0.064 0.034 0.059 0.094 0.108   || dis=0.00 || select=7/8
008/019-th : 0.109 0.113 0.116 0.123 0.138 0.139 0.131 0.131  ||  -0.118 -0.084 -0.059 -0.006 0.110 0.119 0.062 0.063   || dis=0.00 || select=5/8
009/019-th : 0.121 0.122 0.117 0.124 0.124 0.128 0.131 0.133  ||  -0.035 -0.025 -0.066 -0.010 -0.007 0.021 0.048 0.059  || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.119 0.127 0.130 0.130 0.128 0.128  ||  -0.051 -0.036 -0.043 0.019 0.040 0.042 0.031 0.029    || dis=0.00 || select=5/8
011/019-th : 0.121 0.118 0.116 0.121 0.126 0.131 0.133 0.134  ||  -0.040 -0.058 -0.079 -0.032 0.003 0.044 0.060 0.063   || dis=0.00 || select=7/8
012/019-th : 0.125 0.124 0.123 0.126 0.127 0.124 0.125 0.126  ||  -0.000 -0.004 -0.013 0.010 0.020 -0.008 0.004 0.011   || dis=0.00 || select=4/8
013/019-th : 0.101 0.112 0.108 0.119 0.125 0.137 0.149 0.149  ||  -0.204 -0.107 -0.139 -0.048 0.007 0.098 0.181 0.180   || dis=0.00 || select=6/8
014/019-th : 0.096 0.099 0.114 0.127 0.134 0.144 0.148 0.138  ||  -0.235 -0.212 -0.071 0.042 0.094 0.170 0.193 0.124    || dis=0.00 || select=6/8
015/019-th : 0.112 0.112 0.111 0.113 0.126 0.140 0.145 0.140  ||  -0.111 -0.115 -0.118 -0.101 0.009 0.108 0.149 0.114   || dis=0.00 || select=6/8
016/019-th : 0.097 0.108 0.116 0.129 0.142 0.136 0.138 0.134  ||  -0.231 -0.119 -0.048 0.055 0.154 0.115 0.127 0.097    || dis=0.00 || select=4/8
017/019-th : 0.121 0.117 0.116 0.120 0.125 0.130 0.134 0.137  ||  -0.036 -0.066 -0.079 -0.044 -0.005 0.036 0.069 0.092  || dis=0.00 || select=7/8
018/019-th : 0.099 0.109 0.118 0.121 0.129 0.128 0.140 0.157  ||  -0.232 -0.132 -0.056 -0.024 0.038 0.029 0.116 0.235   || dis=0.02 || select=7/8
[epoch=032/600] FLOP : 24.80 MB, ratio : 0.6077, Expected-ratio : 0.7000, Discrepancy : 0.005
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:58:45] [epoch=032/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.241 (2.241)  Prec@1 30.86 (30.86) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:58:51] [epoch=032/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.662 (2.326)  Prec@1 44.05 (35.30) Prec@5 80.36 (82.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.30 Prec@5 82.72 Error@1 64.70 Error@5 17.28 Loss:2.326
***[2020-01-29 05:58:51]*** VALID [epoch=032/600] loss = 2.326366, accuracy@1 = 35.30, accuracy@5 = 82.72 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:58:51]*** start epoch=033/600 Time Left: [05:05:52], LR=[0.099255 ~ 0.099255], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=33, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.963517849079196, FLOP=40.81
[Search] : epoch=033/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:58:51] [epoch=033/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 1.070 (1.070)  Prec@1 66.41 (66.41) Prec@5 97.66 (97.66) Acls-loss 1.035 (1.035) FLOP-Loss -2.439 (-2.439) Arch-Loss -3.844 (-3.844)
**TRAIN** [2020-01-29 05:59:18] [epoch=033/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 1.189 (1.085)  Prec@1 52.98 (61.17) Prec@5 97.02 (96.09) Acls-loss 1.338 (1.100) FLOP-Loss 2.442 (-0.008) Arch-Loss 6.222 (1.084)
 **TRAIN** Prec@1 61.17 Prec@5 96.09 Error@1 38.83 Error@5 3.91 Base-Loss:1.085, Arch-Loss=1.084
***[2020-01-29 05:59:18]*** TRAIN [epoch=033/600] base-loss = 1.085040, arch-loss = 1.083717, accuracy-1 = 61.17, accuracy-5 = 96.09
[epoch=033/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 14, 32, 25, 32, 22, 32, 22, 64, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.67744)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.358 0.283 0.358  ||  0.0041 -0.2317 0.0040  || discrepancy=0.00 || select=0/3
001/003-th : 0.377 0.240 0.382  ||  0.0068 -0.4449 0.0201  || discrepancy=0.01 || select=2/3
002/003-th : 0.353 0.231 0.416  ||  -0.0685 -0.4916 0.0981  || discrepancy=0.06 || select=2/3
-----------------------------------------------
000/019-th : 0.099 0.102 0.111 0.119 0.133 0.144 0.151 0.141  ||  -0.218 -0.179 -0.100 -0.028 0.084 0.159 0.206 0.144   || dis=0.01 || select=6/8
001/019-th : 0.121 0.121 0.122 0.123 0.124 0.130 0.129 0.130  ||  -0.030 -0.033 -0.021 -0.009 -0.004 0.040 0.039 0.045  || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.124 0.127 0.130 0.129 0.126 0.127  ||  -0.060 -0.032 -0.006 0.018 0.041 0.035 0.016 0.025    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.006 0.008 0.001 -0.000 -0.002 -0.002 -0.001  || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.125 0.130 0.126 0.127 0.125  ||  -0.038 -0.015 -0.001 0.006 0.041 0.011 0.021 0.007    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.125 0.121 0.128 0.125 0.126 0.127  ||  -0.009 -0.010 -0.003 -0.030 0.021 -0.000 0.005 0.018  || dis=0.00 || select=4/8
006/019-th : 0.118 0.123 0.125 0.127 0.128 0.124 0.129 0.126  ||  -0.052 -0.012 0.006 0.020 0.033 -0.001 0.034 0.016    || dis=0.00 || select=6/8
007/019-th : 0.115 0.113 0.113 0.117 0.130 0.133 0.138 0.140  ||  -0.081 -0.102 -0.097 -0.068 0.041 0.060 0.099 0.112   || dis=0.00 || select=7/8
008/019-th : 0.109 0.112 0.116 0.124 0.138 0.139 0.131 0.131  ||  -0.122 -0.090 -0.059 0.005 0.112 0.119 0.065 0.066    || dis=0.00 || select=5/8
009/019-th : 0.120 0.122 0.116 0.124 0.125 0.128 0.132 0.133  ||  -0.039 -0.028 -0.073 -0.011 0.002 0.025 0.052 0.062   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.119 0.126 0.131 0.130 0.128 0.128  ||  -0.052 -0.036 -0.042 0.010 0.050 0.041 0.030 0.030    || dis=0.00 || select=4/8
011/019-th : 0.121 0.118 0.117 0.120 0.126 0.131 0.134 0.134  ||  -0.040 -0.063 -0.074 -0.046 0.004 0.042 0.062 0.068   || dis=0.00 || select=7/8
012/019-th : 0.124 0.124 0.123 0.125 0.128 0.124 0.126 0.126  ||  -0.003 -0.007 -0.015 0.002 0.028 -0.007 0.007 0.013   || dis=0.00 || select=4/8
013/019-th : 0.101 0.110 0.108 0.118 0.126 0.138 0.149 0.149  ||  -0.209 -0.117 -0.139 -0.047 0.015 0.105 0.182 0.186   || dis=0.00 || select=7/8
014/019-th : 0.096 0.098 0.114 0.127 0.133 0.145 0.148 0.139  ||  -0.242 -0.214 -0.071 0.037 0.088 0.174 0.196 0.130    || dis=0.00 || select=6/8
015/019-th : 0.112 0.111 0.111 0.113 0.125 0.140 0.146 0.141  ||  -0.113 -0.119 -0.118 -0.102 -0.003 0.111 0.153 0.118  || dis=0.01 || select=6/8
016/019-th : 0.096 0.107 0.116 0.129 0.143 0.137 0.138 0.134  ||  -0.239 -0.123 -0.046 0.059 0.162 0.118 0.129 0.099    || dis=0.00 || select=4/8
017/019-th : 0.121 0.117 0.116 0.122 0.124 0.130 0.134 0.137  ||  -0.036 -0.071 -0.079 -0.029 -0.009 0.042 0.070 0.091  || dis=0.00 || select=7/8
018/019-th : 0.098 0.108 0.117 0.122 0.131 0.128 0.139 0.157  ||  -0.239 -0.136 -0.060 -0.018 0.057 0.033 0.117 0.238   || dis=0.02 || select=7/8
[epoch=033/600] FLOP : 24.68 MB, ratio : 0.6046, Expected-ratio : 0.7000, Discrepancy : 0.006
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:59:19] [epoch=033/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.045 (2.045)  Prec@1 38.67 (38.67) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:59:25] [epoch=033/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.957 (2.305)  Prec@1 29.17 (32.76) Prec@5 83.93 (80.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.76 Prec@5 80.70 Error@1 67.24 Error@5 19.30 Loss:2.305
***[2020-01-29 05:59:25]*** VALID [epoch=033/600] loss = 2.304893, accuracy@1 = 32.76, accuracy@5 = 80.70 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:59:25]*** start epoch=034/600 Time Left: [05:05:52], LR=[0.099210 ~ 0.099210], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=34, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.961279239524642, FLOP=40.81
[Search] : epoch=034/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:59:26] [epoch=034/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 1.061 (1.061)  Prec@1 62.89 (62.89) Prec@5 96.88 (96.88) Acls-loss 1.047 (1.047) FLOP-Loss -2.442 (-2.442) Arch-Loss -3.836 (-3.836)
**TRAIN** [2020-01-29 05:59:52] [epoch=034/600][097/098] Time 0.28 (0.28) Data 0.00 (0.00) Base-Loss 1.185 (1.071)  Prec@1 58.93 (62.00) Prec@5 97.02 (96.30) Acls-loss 1.065 (1.090) FLOP-Loss 2.444 (-0.008) Arch-Loss 5.953 (1.074)
 **TRAIN** Prec@1 62.00 Prec@5 96.30 Error@1 38.00 Error@5 3.70 Base-Loss:1.071, Arch-Loss=1.074
***[2020-01-29 05:59:52]*** TRAIN [epoch=034/600] base-loss = 1.071181, arch-loss = 1.074082, accuracy-1 = 62.00, accuracy-5 = 96.30
[epoch=034/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 14, 32, 25, 32, 22, 32, 22, 64, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.991552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.358 0.284 0.358  ||  0.0038 -0.2261 0.0046  || discrepancy=0.00 || select=2/3
001/003-th : 0.379 0.237 0.385  ||  0.0055 -0.4644 0.0222  || discrepancy=0.01 || select=2/3
002/003-th : 0.352 0.229 0.418  ||  -0.0708 -0.5003 0.1013  || discrepancy=0.07 || select=2/3
-----------------------------------------------
000/019-th : 0.098 0.101 0.111 0.119 0.134 0.144 0.151 0.142  ||  -0.223 -0.188 -0.102 -0.032 0.090 0.163 0.213 0.149   || dis=0.01 || select=6/8
001/019-th : 0.121 0.120 0.122 0.123 0.124 0.130 0.130 0.130  ||  -0.032 -0.033 -0.021 -0.008 0.000 0.040 0.040 0.045   || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.123 0.127 0.129 0.129 0.127 0.128  ||  -0.061 -0.034 -0.011 0.020 0.039 0.038 0.018 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.007 0.007 -0.001 0.001 -0.002 -0.001 -0.000  || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.039 -0.015 -0.003 0.001 0.038 0.012 0.024 0.008    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.124 0.122 0.128 0.125 0.126 0.127  ||  -0.010 -0.011 -0.005 -0.026 0.024 0.002 0.005 0.018   || dis=0.00 || select=4/8
006/019-th : 0.118 0.123 0.125 0.126 0.129 0.124 0.129 0.126  ||  -0.053 -0.013 0.006 0.015 0.033 -0.002 0.037 0.017    || dis=0.00 || select=6/8
007/019-th : 0.115 0.112 0.113 0.117 0.131 0.133 0.139 0.140  ||  -0.086 -0.106 -0.104 -0.061 0.049 0.064 0.105 0.115   || dis=0.00 || select=7/8
008/019-th : 0.108 0.112 0.116 0.124 0.138 0.139 0.131 0.132  ||  -0.125 -0.094 -0.061 0.005 0.118 0.123 0.065 0.068    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.116 0.123 0.126 0.129 0.132 0.133  ||  -0.040 -0.033 -0.076 -0.019 0.006 0.031 0.054 0.065   || dis=0.00 || select=7/8
010/019-th : 0.118 0.120 0.119 0.126 0.131 0.129 0.128 0.128  ||  -0.055 -0.039 -0.044 0.016 0.054 0.040 0.033 0.033    || dis=0.00 || select=4/8
011/019-th : 0.120 0.117 0.117 0.119 0.125 0.133 0.134 0.135  ||  -0.046 -0.069 -0.071 -0.054 -0.001 0.055 0.068 0.071  || dis=0.00 || select=7/8
012/019-th : 0.124 0.123 0.123 0.126 0.128 0.124 0.126 0.126  ||  -0.005 -0.009 -0.016 0.013 0.029 -0.007 0.009 0.014   || dis=0.00 || select=4/8
013/019-th : 0.101 0.109 0.107 0.119 0.125 0.138 0.150 0.150  ||  -0.210 -0.127 -0.145 -0.039 0.007 0.108 0.188 0.190   || dis=0.00 || select=7/8
014/019-th : 0.095 0.098 0.114 0.127 0.134 0.144 0.149 0.140  ||  -0.250 -0.218 -0.071 0.040 0.098 0.166 0.198 0.138    || dis=0.01 || select=6/8
015/019-th : 0.111 0.111 0.111 0.112 0.126 0.141 0.146 0.141  ||  -0.117 -0.121 -0.125 -0.108 0.006 0.117 0.156 0.122   || dis=0.01 || select=6/8
016/019-th : 0.095 0.107 0.115 0.129 0.143 0.138 0.138 0.134  ||  -0.246 -0.130 -0.052 0.062 0.167 0.130 0.132 0.102    || dis=0.00 || select=4/8
017/019-th : 0.121 0.117 0.115 0.121 0.124 0.131 0.134 0.137  ||  -0.037 -0.070 -0.082 -0.032 -0.010 0.043 0.071 0.092  || dis=0.00 || select=7/8
018/019-th : 0.097 0.107 0.117 0.122 0.130 0.128 0.140 0.158  ||  -0.245 -0.143 -0.059 -0.014 0.051 0.035 0.121 0.243   || dis=0.02 || select=7/8
[epoch=034/600] FLOP : 28.99 MB, ratio : 0.7103, Expected-ratio : 0.7000, Discrepancy : 0.006
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 05:59:53] [epoch=034/600][000/098] Time 0.35 (0.35) Data 0.28 (0.28) Loss 2.453 (2.453)  Prec@1 34.77 (34.77) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 05:59:59] [epoch=034/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.508 (2.426)  Prec@1 52.98 (31.83) Prec@5 94.05 (80.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 31.83 Prec@5 80.17 Error@1 68.17 Error@5 19.83 Loss:2.426
***[2020-01-29 05:59:59]*** VALID [epoch=034/600] loss = 2.426365, accuracy@1 = 31.83, accuracy@5 = 80.17 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 05:59:59]*** start epoch=035/600 Time Left: [05:05:41], LR=[0.099163 ~ 0.099163], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=35, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.958974523531689, FLOP=40.81
[Search] : epoch=035/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 05:59:59] [epoch=035/600][000/098] Time 0.75 (0.75) Data 0.37 (0.37) Base-Loss 1.110 (1.110)  Prec@1 59.38 (59.38) Prec@5 94.53 (94.53) Acls-loss 1.057 (1.057) FLOP-Loss 2.444 (2.444) Arch-Loss 5.945 (5.945)
**TRAIN** [2020-01-29 06:00:26] [epoch=035/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 1.090 (1.082)  Prec@1 57.74 (61.79) Prec@5 96.43 (96.04) Acls-loss 1.075 (1.100) FLOP-Loss -2.444 (0.009) Arch-Loss -3.814 (1.118)
 **TRAIN** Prec@1 61.79 Prec@5 96.04 Error@1 38.21 Error@5 3.96 Base-Loss:1.082, Arch-Loss=1.118
***[2020-01-29 06:00:26]*** TRAIN [epoch=035/600] base-loss = 1.082103, arch-loss = 1.117741, accuracy-1 = 61.79, accuracy-5 = 96.04
[epoch=035/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 14, 32, 25, 32, 22, 32, 22, 64, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.991552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.357 0.285 0.358  ||  0.0041 -0.2222 0.0045  || discrepancy=0.00 || select=2/3
001/003-th : 0.379 0.235 0.386  ||  0.0056 -0.4739 0.0227  || discrepancy=0.01 || select=2/3
002/003-th : 0.351 0.229 0.420  ||  -0.0734 -0.5030 0.1043  || discrepancy=0.07 || select=2/3
-----------------------------------------------
000/019-th : 0.097 0.101 0.110 0.119 0.136 0.144 0.151 0.142  ||  -0.230 -0.192 -0.101 -0.026 0.109 0.164 0.215 0.150   || dis=0.01 || select=6/8
001/019-th : 0.121 0.120 0.122 0.124 0.124 0.130 0.130 0.130  ||  -0.032 -0.034 -0.022 -0.007 -0.001 0.041 0.040 0.046  || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.123 0.127 0.130 0.129 0.127 0.128  ||  -0.061 -0.035 -0.012 0.023 0.041 0.039 0.018 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.009 0.008 -0.004 -0.001 0.000 -0.001 0.000  || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.038 -0.015 -0.005 -0.001 0.038 0.008 0.025 0.008   || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.124 0.122 0.128 0.125 0.126 0.127  ||  -0.011 -0.011 -0.005 -0.026 0.025 -0.001 0.005 0.019  || dis=0.00 || select=4/8
006/019-th : 0.118 0.123 0.125 0.126 0.128 0.125 0.129 0.126  ||  -0.054 -0.014 0.006 0.015 0.033 0.003 0.037 0.016     || dis=0.00 || select=6/8
007/019-th : 0.114 0.112 0.113 0.117 0.132 0.133 0.138 0.141  ||  -0.091 -0.108 -0.101 -0.063 0.054 0.067 0.104 0.119   || dis=0.00 || select=7/8
008/019-th : 0.108 0.112 0.116 0.124 0.138 0.140 0.131 0.132  ||  -0.131 -0.097 -0.058 0.013 0.113 0.128 0.068 0.068    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.116 0.122 0.125 0.129 0.132 0.134  ||  -0.041 -0.034 -0.075 -0.028 0.001 0.032 0.056 0.067   || dis=0.00 || select=7/8
010/019-th : 0.117 0.119 0.119 0.126 0.133 0.129 0.128 0.128  ||  -0.057 -0.044 -0.040 0.017 0.066 0.041 0.033 0.033    || dis=0.00 || select=4/8
011/019-th : 0.119 0.117 0.117 0.119 0.125 0.133 0.135 0.135  ||  -0.049 -0.073 -0.070 -0.050 -0.004 0.058 0.072 0.072  || dis=0.00 || select=7/8
012/019-th : 0.124 0.123 0.123 0.127 0.129 0.123 0.125 0.126  ||  -0.007 -0.012 -0.014 0.021 0.033 -0.008 0.008 0.016   || dis=0.00 || select=4/8
013/019-th : 0.100 0.109 0.108 0.119 0.125 0.138 0.150 0.151  ||  -0.213 -0.133 -0.142 -0.041 0.011 0.106 0.190 0.194   || dis=0.00 || select=7/8
014/019-th : 0.094 0.098 0.113 0.127 0.135 0.144 0.149 0.140  ||  -0.255 -0.222 -0.071 0.040 0.107 0.167 0.201 0.140    || dis=0.01 || select=6/8
015/019-th : 0.111 0.111 0.110 0.111 0.128 0.141 0.147 0.142  ||  -0.122 -0.120 -0.126 -0.115 0.021 0.119 0.158 0.124   || dis=0.01 || select=6/8
016/019-th : 0.095 0.106 0.115 0.129 0.143 0.139 0.139 0.135  ||  -0.249 -0.133 -0.058 0.057 0.162 0.136 0.132 0.106    || dis=0.00 || select=4/8
017/019-th : 0.121 0.117 0.115 0.120 0.125 0.131 0.134 0.137  ||  -0.037 -0.070 -0.081 -0.044 -0.001 0.046 0.071 0.092  || dis=0.00 || select=7/8
018/019-th : 0.097 0.107 0.117 0.122 0.129 0.129 0.141 0.158  ||  -0.250 -0.144 -0.062 -0.015 0.038 0.039 0.130 0.245   || dis=0.02 || select=7/8
[epoch=035/600] FLOP : 28.99 MB, ratio : 0.7103, Expected-ratio : 0.7000, Discrepancy : 0.006
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:00:27] [epoch=035/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.611 (2.611)  Prec@1 21.88 (21.88) Prec@5 61.72 (61.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:00:33] [epoch=035/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.499 (2.316)  Prec@1 37.50 (35.33) Prec@5 78.57 (82.96) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.33 Prec@5 82.96 Error@1 64.67 Error@5 17.04 Loss:2.316
***[2020-01-29 06:00:33]*** VALID [epoch=035/600] loss = 2.315527, accuracy@1 = 35.33, accuracy@5 = 82.96 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:00:33]*** start epoch=036/600 Time Left: [05:05:35], LR=[0.099114 ~ 0.099114], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=36, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.956603764285288, FLOP=40.81
[Search] : epoch=036/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:00:34] [epoch=036/600][000/098] Time 0.77 (0.77) Data 0.36 (0.36) Base-Loss 1.126 (1.126)  Prec@1 59.38 (59.38) Prec@5 94.53 (94.53) Acls-loss 1.146 (1.146) FLOP-Loss 2.445 (2.445) Arch-Loss 6.037 (6.037)
**TRAIN** [2020-01-29 06:01:00] [epoch=036/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 1.078 (1.064)  Prec@1 63.69 (62.35) Prec@5 96.43 (96.14) Acls-loss 1.050 (1.080) FLOP-Loss 2.447 (0.042) Arch-Loss 5.943 (1.164)
 **TRAIN** Prec@1 62.35 Prec@5 96.14 Error@1 37.65 Error@5 3.86 Base-Loss:1.064, Arch-Loss=1.164
***[2020-01-29 06:01:00]*** TRAIN [epoch=036/600] base-loss = 1.064039, arch-loss = 1.163762, accuracy-1 = 62.35, accuracy-5 = 96.14
[epoch=036/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 8, 11, 16, 14, 32, 25, 32, 22, 32, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.520704)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.358 0.285 0.357  ||  0.0047 -0.2231 0.0042  || discrepancy=0.00 || select=0/3
001/003-th : 0.379 0.236 0.385  ||  0.0061 -0.4695 0.0226  || discrepancy=0.01 || select=2/3
002/003-th : 0.350 0.229 0.420  ||  -0.0756 -0.4994 0.1067  || discrepancy=0.07 || select=2/3
-----------------------------------------------
000/019-th : 0.097 0.101 0.110 0.119 0.137 0.144 0.151 0.142  ||  -0.232 -0.194 -0.100 -0.028 0.117 0.163 0.213 0.153   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.122 0.124 0.125 0.130 0.129 0.130  ||  -0.032 -0.034 -0.021 -0.007 0.001 0.041 0.040 0.046   || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.123 0.127 0.129 0.129 0.127 0.128  ||  -0.062 -0.035 -0.013 0.022 0.040 0.040 0.018 0.026    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.009 0.007 -0.003 0.002 0.000 -0.001 0.000   || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.039 -0.015 -0.006 0.001 0.038 0.007 0.026 0.008    || dis=0.00 || select=4/8
005/019-th : 0.124 0.124 0.124 0.123 0.127 0.125 0.126 0.128  ||  -0.012 -0.010 -0.005 -0.021 0.013 0.002 0.005 0.020   || dis=0.00 || select=7/8
006/019-th : 0.118 0.123 0.125 0.127 0.128 0.125 0.129 0.126  ||  -0.053 -0.013 0.004 0.018 0.029 0.003 0.035 0.016     || dis=0.00 || select=6/8
007/019-th : 0.113 0.112 0.112 0.118 0.132 0.134 0.138 0.141  ||  -0.098 -0.106 -0.104 -0.057 0.059 0.069 0.104 0.122   || dis=0.00 || select=7/8
008/019-th : 0.108 0.112 0.116 0.124 0.136 0.140 0.132 0.132  ||  -0.133 -0.098 -0.055 0.009 0.104 0.131 0.069 0.070    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.116 0.122 0.125 0.130 0.132 0.134  ||  -0.044 -0.034 -0.079 -0.022 0.003 0.037 0.056 0.068   || dis=0.00 || select=7/8
010/019-th : 0.117 0.119 0.119 0.127 0.132 0.129 0.129 0.128  ||  -0.058 -0.044 -0.043 0.020 0.060 0.041 0.036 0.034    || dis=0.00 || select=4/8
011/019-th : 0.119 0.116 0.117 0.119 0.126 0.133 0.134 0.135  ||  -0.051 -0.075 -0.070 -0.049 0.009 0.059 0.071 0.074   || dis=0.00 || select=7/8
012/019-th : 0.124 0.123 0.122 0.126 0.129 0.124 0.125 0.127  ||  -0.006 -0.010 -0.017 0.013 0.032 -0.006 0.007 0.016   || dis=0.00 || select=4/8
013/019-th : 0.100 0.108 0.107 0.118 0.127 0.138 0.151 0.151  ||  -0.219 -0.134 -0.148 -0.045 0.022 0.108 0.197 0.197   || dis=0.00 || select=6/8
014/019-th : 0.094 0.097 0.113 0.127 0.136 0.144 0.149 0.140  ||  -0.258 -0.226 -0.074 0.043 0.112 0.172 0.203 0.142    || dis=0.01 || select=6/8
015/019-th : 0.110 0.110 0.110 0.113 0.126 0.141 0.147 0.142  ||  -0.125 -0.125 -0.125 -0.100 0.006 0.122 0.160 0.126   || dis=0.01 || select=6/8
016/019-th : 0.095 0.106 0.115 0.128 0.142 0.139 0.139 0.136  ||  -0.250 -0.138 -0.058 0.050 0.153 0.136 0.133 0.111    || dis=0.00 || select=4/8
017/019-th : 0.121 0.117 0.116 0.119 0.124 0.131 0.135 0.138  ||  -0.037 -0.069 -0.077 -0.055 -0.009 0.043 0.071 0.094  || dis=0.00 || select=7/8
018/019-th : 0.096 0.107 0.116 0.121 0.129 0.130 0.142 0.158  ||  -0.253 -0.149 -0.062 -0.024 0.043 0.048 0.135 0.246   || dis=0.02 || select=7/8
[epoch=036/600] FLOP : 24.52 MB, ratio : 0.6008, Expected-ratio : 0.7000, Discrepancy : 0.006
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:01:00] [epoch=036/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.577 (1.577)  Prec@1 45.70 (45.70) Prec@5 91.41 (91.41) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:01:06] [epoch=036/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.446 (2.180)  Prec@1 24.40 (34.94) Prec@5 70.24 (82.27) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.94 Prec@5 82.27 Error@1 65.06 Error@5 17.73 Loss:2.180
***[2020-01-29 06:01:06]*** VALID [epoch=036/600] loss = 2.179722, accuracy@1 = 34.94, accuracy@5 = 82.27 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:01:06]*** start epoch=037/600 Time Left: [05:05:17], LR=[0.099065 ~ 0.099065], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=37, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.9541670267810005, FLOP=40.81
[Search] : epoch=037/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:01:07] [epoch=037/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.999 (0.999)  Prec@1 64.84 (64.84) Prec@5 97.27 (97.27) Acls-loss 1.122 (1.122) FLOP-Loss -2.446 (-2.446) Arch-Loss -3.770 (-3.770)
**TRAIN** [2020-01-29 06:01:33] [epoch=037/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.956 (1.053)  Prec@1 64.29 (63.24) Prec@5 98.21 (96.48) Acls-loss 1.132 (1.064) FLOP-Loss -2.448 (0.009) Arch-Loss -3.764 (1.082)
 **TRAIN** Prec@1 63.24 Prec@5 96.48 Error@1 36.76 Error@5 3.52 Base-Loss:1.053, Arch-Loss=1.082
***[2020-01-29 06:01:33]*** TRAIN [epoch=037/600] base-loss = 1.052846, arch-loss = 1.081908, accuracy-1 = 63.24, accuracy-5 = 96.48
[epoch=037/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 16, 14, 32, 25, 32, 22, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.21952)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.359 0.282 0.359  ||  0.0047 -0.2391 0.0046  || discrepancy=0.00 || select=0/3
001/003-th : 0.380 0.234 0.387  ||  0.0057 -0.4790 0.0236  || discrepancy=0.01 || select=2/3
002/003-th : 0.350 0.228 0.422  ||  -0.0781 -0.5049 0.1098  || discrepancy=0.07 || select=2/3
-----------------------------------------------
000/019-th : 0.096 0.100 0.110 0.119 0.139 0.144 0.151 0.142  ||  -0.239 -0.201 -0.099 -0.026 0.133 0.165 0.218 0.154   || dis=0.01 || select=6/8
001/019-th : 0.121 0.120 0.122 0.123 0.124 0.130 0.130 0.130  ||  -0.032 -0.035 -0.024 -0.008 0.000 0.044 0.040 0.046   || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.123 0.127 0.130 0.129 0.127 0.128  ||  -0.063 -0.035 -0.014 0.024 0.042 0.040 0.019 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.011 0.007 0.001 0.002 0.000 0.000 0.000     || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.040 -0.015 -0.004 -0.000 0.038 0.007 0.026 0.008   || dis=0.00 || select=4/8
005/019-th : 0.123 0.124 0.125 0.123 0.127 0.125 0.126 0.128  ||  -0.015 -0.012 -0.001 -0.017 0.012 0.003 0.007 0.021   || dis=0.00 || select=7/8
006/019-th : 0.118 0.123 0.125 0.126 0.128 0.125 0.129 0.127  ||  -0.054 -0.014 0.003 0.013 0.028 0.004 0.036 0.017     || dis=0.00 || select=6/8
007/019-th : 0.113 0.112 0.112 0.117 0.132 0.134 0.138 0.141  ||  -0.099 -0.107 -0.109 -0.059 0.061 0.071 0.105 0.125   || dis=0.00 || select=7/8
008/019-th : 0.107 0.111 0.116 0.125 0.137 0.140 0.132 0.132  ||  -0.140 -0.104 -0.054 0.020 0.112 0.134 0.071 0.074    || dis=0.00 || select=5/8
009/019-th : 0.119 0.121 0.116 0.123 0.125 0.129 0.132 0.134  ||  -0.046 -0.037 -0.077 -0.020 0.000 0.034 0.056 0.072   || dis=0.00 || select=7/8
010/019-th : 0.117 0.118 0.119 0.126 0.134 0.129 0.129 0.128  ||  -0.062 -0.047 -0.041 0.016 0.076 0.040 0.037 0.035    || dis=0.01 || select=4/8
011/019-th : 0.119 0.116 0.117 0.119 0.127 0.133 0.135 0.135  ||  -0.053 -0.079 -0.070 -0.049 0.011 0.060 0.074 0.076   || dis=0.00 || select=7/8
012/019-th : 0.124 0.123 0.122 0.126 0.129 0.124 0.125 0.127  ||  -0.007 -0.011 -0.017 0.013 0.034 -0.008 0.007 0.018   || dis=0.00 || select=4/8
013/019-th : 0.099 0.108 0.106 0.119 0.125 0.139 0.152 0.152  ||  -0.221 -0.140 -0.156 -0.039 0.009 0.110 0.201 0.203   || dis=0.00 || select=7/8
014/019-th : 0.093 0.096 0.113 0.127 0.137 0.145 0.149 0.140  ||  -0.263 -0.234 -0.072 0.043 0.121 0.176 0.207 0.143    || dis=0.00 || select=6/8
015/019-th : 0.110 0.110 0.110 0.113 0.125 0.142 0.147 0.142  ||  -0.127 -0.131 -0.131 -0.098 0.004 0.127 0.165 0.129   || dis=0.01 || select=6/8
016/019-th : 0.094 0.105 0.114 0.128 0.141 0.141 0.140 0.137  ||  -0.255 -0.144 -0.063 0.052 0.144 0.145 0.137 0.115    || dis=0.00 || select=5/8
017/019-th : 0.121 0.117 0.116 0.118 0.126 0.131 0.134 0.137  ||  -0.038 -0.069 -0.073 -0.058 0.003 0.043 0.071 0.093   || dis=0.00 || select=7/8
018/019-th : 0.096 0.106 0.117 0.120 0.129 0.131 0.142 0.159  ||  -0.260 -0.154 -0.059 -0.033 0.042 0.059 0.139 0.249   || dis=0.02 || select=7/8
[epoch=037/600] FLOP : 25.22 MB, ratio : 0.6179, Expected-ratio : 0.7000, Discrepancy : 0.006
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:01:34] [epoch=037/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.053 (3.053)  Prec@1 23.05 (23.05) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:01:40] [epoch=037/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.878 (2.661)  Prec@1 46.43 (32.10) Prec@5 86.90 (80.41) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.10 Prec@5 80.41 Error@1 67.90 Error@5 19.59 Loss:2.661
***[2020-01-29 06:01:40]*** VALID [epoch=037/600] loss = 2.660637, accuracy@1 = 32.10, accuracy@5 = 80.41 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:01:40]*** start epoch=038/600 Time Left: [05:04:57], LR=[0.099014 ~ 0.099014], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=38, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.951664377823219, FLOP=40.81
[Search] : epoch=038/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:01:40] [epoch=038/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.038 (1.038)  Prec@1 63.28 (63.28) Prec@5 95.31 (95.31) Acls-loss 1.135 (1.135) FLOP-Loss -2.448 (-2.448) Arch-Loss -3.761 (-3.761)
**TRAIN** [2020-01-29 06:02:08] [epoch=038/600][097/098] Time 0.29 (0.29) Data 0.00 (0.00) Base-Loss 1.012 (1.051)  Prec@1 59.52 (62.62) Prec@5 97.62 (96.44) Acls-loss 1.206 (1.074) FLOP-Loss -2.450 (0.009) Arch-Loss -3.693 (1.092)
 **TRAIN** Prec@1 62.62 Prec@5 96.44 Error@1 37.38 Error@5 3.56 Base-Loss:1.051, Arch-Loss=1.092
***[2020-01-29 06:02:08]*** TRAIN [epoch=038/600] base-loss = 1.050750, arch-loss = 1.091838, accuracy-1 = 62.62, accuracy-5 = 96.44
[epoch=038/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 16, 14, 32, 25, 32, 22, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 30.685632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.360 0.280 0.360  ||  0.0045 -0.2471 0.0052  || discrepancy=0.00 || select=2/3
001/003-th : 0.380 0.232 0.388  ||  0.0049 -0.4864 0.0250  || discrepancy=0.01 || select=2/3
002/003-th : 0.349 0.227 0.424  ||  -0.0814 -0.5116 0.1137  || discrepancy=0.08 || select=2/3
-----------------------------------------------
000/019-th : 0.095 0.099 0.110 0.120 0.138 0.144 0.151 0.142  ||  -0.247 -0.202 -0.101 -0.011 0.130 0.173 0.219 0.156   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.122 0.124 0.125 0.130 0.129 0.130  ||  -0.035 -0.036 -0.023 -0.005 0.002 0.046 0.040 0.047   || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.123 0.127 0.130 0.129 0.127 0.128  ||  -0.064 -0.036 -0.014 0.022 0.044 0.040 0.021 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.012 -0.010 0.005 0.001 0.001 -0.000 0.001 0.001    || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.041 -0.016 -0.006 -0.001 0.038 0.008 0.027 0.010   || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.125 0.122 0.127 0.126 0.126 0.128  ||  -0.020 -0.014 0.000 -0.021 0.020 0.011 0.009 0.023    || dis=0.00 || select=7/8
006/019-th : 0.118 0.123 0.125 0.125 0.128 0.125 0.129 0.127  ||  -0.055 -0.016 0.002 0.008 0.030 0.007 0.036 0.019     || dis=0.00 || select=6/8
007/019-th : 0.113 0.112 0.111 0.118 0.133 0.133 0.139 0.142  ||  -0.100 -0.110 -0.116 -0.057 0.069 0.065 0.109 0.129   || dis=0.00 || select=7/8
008/019-th : 0.106 0.110 0.116 0.126 0.137 0.141 0.132 0.132  ||  -0.143 -0.109 -0.059 0.027 0.111 0.139 0.076 0.076    || dis=0.00 || select=5/8
009/019-th : 0.120 0.121 0.116 0.122 0.124 0.130 0.133 0.135  ||  -0.047 -0.039 -0.081 -0.031 -0.009 0.036 0.061 0.075  || dis=0.00 || select=7/8
010/019-th : 0.116 0.118 0.119 0.125 0.135 0.129 0.129 0.129  ||  -0.065 -0.047 -0.041 0.006 0.083 0.038 0.042 0.037    || dis=0.01 || select=4/8
011/019-th : 0.118 0.115 0.117 0.119 0.127 0.133 0.136 0.136  ||  -0.056 -0.084 -0.072 -0.052 0.013 0.060 0.079 0.081   || dis=0.00 || select=7/8
012/019-th : 0.123 0.123 0.123 0.126 0.129 0.123 0.126 0.127  ||  -0.009 -0.014 -0.014 0.010 0.034 -0.009 0.009 0.020   || dis=0.00 || select=4/8
013/019-th : 0.099 0.107 0.106 0.119 0.126 0.138 0.152 0.153  ||  -0.224 -0.149 -0.159 -0.042 0.018 0.110 0.207 0.207   || dis=0.00 || select=7/8
014/019-th : 0.093 0.096 0.112 0.126 0.138 0.144 0.150 0.141  ||  -0.267 -0.239 -0.077 0.040 0.128 0.174 0.213 0.147    || dis=0.01 || select=6/8
015/019-th : 0.110 0.109 0.109 0.113 0.126 0.142 0.148 0.143  ||  -0.128 -0.136 -0.135 -0.097 0.008 0.127 0.167 0.133   || dis=0.01 || select=6/8
016/019-th : 0.094 0.105 0.114 0.128 0.140 0.142 0.140 0.137  ||  -0.261 -0.150 -0.063 0.051 0.138 0.151 0.140 0.119    || dis=0.00 || select=5/8
017/019-th : 0.121 0.117 0.116 0.118 0.126 0.131 0.135 0.138  ||  -0.039 -0.068 -0.077 -0.062 0.003 0.044 0.072 0.094   || dis=0.00 || select=7/8
018/019-th : 0.095 0.106 0.116 0.120 0.131 0.131 0.142 0.159  ||  -0.265 -0.155 -0.061 -0.033 0.056 0.057 0.140 0.253   || dis=0.02 || select=7/8
[epoch=038/600] FLOP : 30.69 MB, ratio : 0.7519, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:02:08] [epoch=038/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.953 (2.953)  Prec@1 33.98 (33.98) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:02:14] [epoch=038/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.626 (2.298)  Prec@1 39.29 (34.20) Prec@5 88.69 (82.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.20 Prec@5 82.78 Error@1 65.80 Error@5 17.22 Loss:2.298
***[2020-01-29 06:02:14]*** VALID [epoch=038/600] loss = 2.297862, accuracy@1 = 34.20, accuracy@5 = 82.78 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:02:14]*** start epoch=039/600 Time Left: [05:04:54], LR=[0.098961 ~ 0.098961], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=39, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.9490958860233265, FLOP=40.81
[Search] : epoch=039/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:02:15] [epoch=039/600][000/098] Time 0.68 (0.68) Data 0.35 (0.35) Base-Loss 0.987 (0.987)  Prec@1 69.92 (69.92) Prec@5 96.88 (96.88) Acls-loss 0.946 (0.946) FLOP-Loss 2.450 (2.450) Arch-Loss 5.846 (5.846)
**TRAIN** [2020-01-29 06:02:43] [epoch=039/600][097/098] Time 0.26 (0.30) Data 0.00 (0.00) Base-Loss 1.133 (1.052)  Prec@1 63.69 (63.05) Prec@5 95.83 (96.30) Acls-loss 1.168 (1.063) FLOP-Loss 2.451 (0.042) Arch-Loss 6.071 (1.147)
 **TRAIN** Prec@1 63.05 Prec@5 96.30 Error@1 36.95 Error@5 3.70 Base-Loss:1.052, Arch-Loss=1.147
***[2020-01-29 06:02:43]*** TRAIN [epoch=039/600] base-loss = 1.051724, arch-loss = 1.146543, accuracy-1 = 63.05, accuracy-5 = 96.30
[epoch=039/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 8, 11, 11, 14, 32, 25, 32, 22, 32, 22, 57, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.900992)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.276 0.362  ||  0.0053 -0.2682 0.0049  || discrepancy=0.00 || select=0/3
001/003-th : 0.380 0.232 0.388  ||  0.0055 -0.4894 0.0248  || discrepancy=0.01 || select=2/3
002/003-th : 0.348 0.227 0.425  ||  -0.0832 -0.5101 0.1157  || discrepancy=0.08 || select=2/3
-----------------------------------------------
000/019-th : 0.094 0.099 0.110 0.120 0.140 0.144 0.151 0.142  ||  -0.250 -0.200 -0.102 -0.011 0.144 0.175 0.217 0.155   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.122 0.124 0.125 0.130 0.129 0.130  ||  -0.035 -0.035 -0.022 -0.004 0.004 0.046 0.039 0.046   || dis=0.00 || select=7/8
002/019-th : 0.117 0.120 0.123 0.127 0.130 0.130 0.127 0.128  ||  -0.065 -0.036 -0.014 0.020 0.043 0.042 0.022 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.011 -0.009 0.006 0.002 -0.001 0.001 0.000 -0.000   || dis=0.00 || select=2/8
004/019-th : 0.120 0.123 0.124 0.124 0.130 0.126 0.128 0.126  ||  -0.041 -0.015 -0.007 -0.004 0.041 0.009 0.025 0.010   || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.125 0.122 0.128 0.126 0.126 0.128  ||  -0.021 -0.014 0.003 -0.021 0.023 0.009 0.009 0.022    || dis=0.00 || select=4/8
006/019-th : 0.118 0.122 0.124 0.124 0.129 0.126 0.129 0.127  ||  -0.054 -0.017 -0.000 -0.001 0.035 0.009 0.038 0.018   || dis=0.00 || select=6/8
007/019-th : 0.113 0.112 0.110 0.118 0.133 0.133 0.139 0.142  ||  -0.101 -0.110 -0.122 -0.052 0.064 0.064 0.111 0.131   || dis=0.00 || select=7/8
008/019-th : 0.106 0.110 0.116 0.125 0.136 0.141 0.133 0.133  ||  -0.145 -0.112 -0.054 0.022 0.103 0.139 0.077 0.077    || dis=0.00 || select=5/8
009/019-th : 0.120 0.120 0.115 0.122 0.125 0.130 0.133 0.135  ||  -0.046 -0.040 -0.083 -0.024 -0.004 0.035 0.061 0.075  || dis=0.00 || select=7/8
010/019-th : 0.116 0.118 0.119 0.125 0.135 0.129 0.129 0.129  ||  -0.068 -0.047 -0.041 0.005 0.086 0.041 0.043 0.037    || dis=0.01 || select=4/8
011/019-th : 0.118 0.115 0.116 0.119 0.126 0.133 0.136 0.136  ||  -0.056 -0.083 -0.074 -0.050 0.007 0.058 0.081 0.082   || dis=0.00 || select=7/8
012/019-th : 0.124 0.123 0.123 0.125 0.129 0.123 0.126 0.127  ||  -0.009 -0.014 -0.016 0.006 0.035 -0.009 0.008 0.021   || dis=0.00 || select=4/8
013/019-th : 0.099 0.106 0.105 0.118 0.127 0.138 0.153 0.153  ||  -0.222 -0.153 -0.165 -0.051 0.023 0.110 0.211 0.210   || dis=0.00 || select=6/8
014/019-th : 0.093 0.095 0.112 0.128 0.136 0.145 0.150 0.141  ||  -0.268 -0.242 -0.079 0.051 0.114 0.174 0.214 0.149    || dis=0.01 || select=6/8
015/019-th : 0.110 0.109 0.109 0.113 0.126 0.142 0.148 0.143  ||  -0.131 -0.140 -0.135 -0.100 0.005 0.127 0.172 0.137   || dis=0.01 || select=6/8
016/019-th : 0.094 0.104 0.114 0.129 0.140 0.141 0.140 0.137  ||  -0.263 -0.155 -0.064 0.056 0.143 0.148 0.142 0.121    || dis=0.00 || select=5/8
017/019-th : 0.121 0.117 0.116 0.118 0.125 0.131 0.135 0.138  ||  -0.037 -0.068 -0.076 -0.063 -0.006 0.041 0.074 0.094  || dis=0.00 || select=7/8
018/019-th : 0.095 0.106 0.116 0.119 0.130 0.132 0.142 0.160  ||  -0.265 -0.157 -0.062 -0.037 0.046 0.066 0.138 0.255   || dis=0.02 || select=7/8
[epoch=039/600] FLOP : 24.90 MB, ratio : 0.6101, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:02:44] [epoch=039/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.232 (2.232)  Prec@1 33.98 (33.98) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:02:50] [epoch=039/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 4.234 (2.411)  Prec@1 27.98 (34.13) Prec@5 79.17 (82.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.13 Prec@5 82.20 Error@1 65.87 Error@5 17.80 Loss:2.411
***[2020-01-29 06:02:50]*** VALID [epoch=039/600] loss = 2.411380, accuracy@1 = 34.13, accuracy@5 = 82.20 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:02:50]*** start epoch=040/600 Time Left: [05:05:03], LR=[0.098907 ~ 0.098907], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=40, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.946461621797824, FLOP=40.81
[Search] : epoch=040/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:02:51] [epoch=040/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.994 (0.994)  Prec@1 64.84 (64.84) Prec@5 96.88 (96.88) Acls-loss 1.068 (1.068) FLOP-Loss -2.451 (-2.451) Arch-Loss -3.834 (-3.834)
**TRAIN** [2020-01-29 06:03:17] [epoch=040/600][097/098] Time 0.27 (0.27) Data 0.00 (0.00) Base-Loss 0.969 (1.033)  Prec@1 65.48 (63.46) Prec@5 98.21 (96.64) Acls-loss 0.987 (1.038) FLOP-Loss 0.000 (-0.025) Arch-Loss 0.987 (0.988)
 **TRAIN** Prec@1 63.46 Prec@5 96.64 Error@1 36.54 Error@5 3.36 Base-Loss:1.033, Arch-Loss=0.988
***[2020-01-29 06:03:17]*** TRAIN [epoch=040/600] base-loss = 1.033110, arch-loss = 0.987888, accuracy-1 = 63.46, accuracy-5 = 96.64
[epoch=040/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 8, 11, 11, 14, 32, 25, 32, 22, 32, 22, 57, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.293504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.363 0.273 0.364  ||  0.0038 -0.2811 0.0068  || discrepancy=0.00 || select=2/3
001/003-th : 0.382 0.227 0.391  ||  0.0037 -0.5180 0.0275  || discrepancy=0.01 || select=2/3
002/003-th : 0.347 0.224 0.428  ||  -0.0877 -0.5252 0.1211  || discrepancy=0.08 || select=2/3
-----------------------------------------------
000/019-th : 0.094 0.099 0.109 0.118 0.140 0.146 0.151 0.142  ||  -0.252 -0.200 -0.108 -0.025 0.144 0.183 0.219 0.159   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.121 0.123 0.125 0.131 0.129 0.130  ||  -0.036 -0.037 -0.024 -0.008 0.007 0.049 0.040 0.048   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.122 0.127 0.130 0.130 0.127 0.128  ||  -0.067 -0.039 -0.016 0.020 0.048 0.046 0.023 0.028    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.125 0.125 0.125  ||  -0.013 -0.010 0.004 -0.000 -0.001 0.002 0.002 0.002   || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.123 0.124 0.130 0.126 0.128 0.126  ||  -0.044 -0.017 -0.010 -0.005 0.040 0.012 0.028 0.013   || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.125 0.123 0.128 0.126 0.126 0.128  ||  -0.024 -0.017 0.001 -0.018 0.029 0.011 0.011 0.025    || dis=0.00 || select=4/8
006/019-th : 0.117 0.122 0.124 0.125 0.129 0.126 0.130 0.127  ||  -0.058 -0.019 -0.003 0.001 0.036 0.013 0.041 0.021    || dis=0.00 || select=6/8
007/019-th : 0.112 0.111 0.110 0.118 0.134 0.133 0.140 0.143  ||  -0.106 -0.114 -0.126 -0.051 0.073 0.067 0.114 0.136   || dis=0.00 || select=7/8
008/019-th : 0.105 0.109 0.116 0.125 0.137 0.142 0.133 0.133  ||  -0.151 -0.115 -0.059 0.022 0.110 0.143 0.081 0.081    || dis=0.00 || select=5/8
009/019-th : 0.119 0.119 0.115 0.121 0.125 0.130 0.134 0.136  ||  -0.051 -0.047 -0.085 -0.031 0.001 0.039 0.066 0.080   || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.135 0.130 0.129 0.129  ||  -0.072 -0.049 -0.046 0.012 0.088 0.050 0.043 0.037    || dis=0.01 || select=4/8
011/019-th : 0.118 0.115 0.116 0.119 0.126 0.134 0.136 0.137  ||  -0.062 -0.086 -0.080 -0.055 0.007 0.066 0.085 0.087   || dis=0.00 || select=7/8
012/019-th : 0.123 0.123 0.122 0.125 0.129 0.124 0.126 0.128  ||  -0.011 -0.017 -0.018 0.006 0.032 -0.007 0.012 0.023   || dis=0.00 || select=4/8
013/019-th : 0.099 0.106 0.105 0.117 0.127 0.139 0.154 0.154  ||  -0.225 -0.158 -0.169 -0.061 0.027 0.111 0.217 0.215   || dis=0.00 || select=6/8
014/019-th : 0.092 0.095 0.111 0.129 0.138 0.144 0.151 0.141  ||  -0.275 -0.248 -0.083 0.060 0.127 0.173 0.218 0.153    || dis=0.01 || select=6/8
015/019-th : 0.109 0.108 0.109 0.112 0.126 0.142 0.149 0.144  ||  -0.134 -0.149 -0.134 -0.109 0.008 0.130 0.176 0.143   || dis=0.01 || select=6/8
016/019-th : 0.093 0.104 0.114 0.129 0.139 0.142 0.141 0.138  ||  -0.269 -0.161 -0.068 0.057 0.133 0.155 0.144 0.128    || dis=0.00 || select=5/8
017/019-th : 0.121 0.117 0.116 0.117 0.124 0.131 0.135 0.138  ||  -0.039 -0.069 -0.079 -0.068 -0.009 0.045 0.076 0.095  || dis=0.00 || select=7/8
018/019-th : 0.094 0.104 0.115 0.119 0.131 0.133 0.143 0.161  ||  -0.269 -0.168 -0.073 -0.041 0.058 0.071 0.144 0.263   || dis=0.02 || select=7/8
[epoch=040/600] FLOP : 28.29 MB, ratio : 0.6932, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:03:17] [epoch=040/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 4.226 (4.226)  Prec@1 27.34 (27.34) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:03:23] [epoch=040/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.914 (2.274)  Prec@1 23.81 (34.11) Prec@5 66.67 (81.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.11 Prec@5 81.32 Error@1 65.89 Error@5 18.68 Loss:2.274
***[2020-01-29 06:03:23]*** VALID [epoch=040/600] loss = 2.273741, accuracy@1 = 34.11, accuracy@5 = 81.32 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:03:23]*** start epoch=041/600 Time Left: [05:04:39], LR=[0.098852 ~ 0.098852], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=41, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.943761657366396, FLOP=40.81
[Search] : epoch=041/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:03:24] [epoch=041/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.960 (0.960)  Prec@1 66.80 (66.80) Prec@5 97.27 (97.27) Acls-loss 0.946 (0.946) FLOP-Loss 0.000 (0.000) Arch-Loss 0.946 (0.946)
**TRAIN** [2020-01-29 06:03:50] [epoch=041/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.114 (1.035)  Prec@1 61.31 (63.75) Prec@5 94.64 (96.52) Acls-loss 0.975 (1.057) FLOP-Loss -2.454 (0.034) Arch-Loss -3.932 (1.125)
 **TRAIN** Prec@1 63.75 Prec@5 96.52 Error@1 36.25 Error@5 3.48 Base-Loss:1.035, Arch-Loss=1.125
***[2020-01-29 06:03:50]*** TRAIN [epoch=041/600] base-loss = 1.035287, arch-loss = 1.125153, accuracy-1 = 63.75, accuracy-5 = 96.52
[epoch=041/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 8, 11, 16, 14, 32, 25, 32, 22, 32, 22, 57, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 29.445504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.365 0.269 0.366  ||  0.0050 -0.3024 0.0062  || discrepancy=0.00 || select=2/3
001/003-th : 0.382 0.226 0.391  ||  0.0045 -0.5204 0.0272  || discrepancy=0.01 || select=2/3
002/003-th : 0.346 0.226 0.428  ||  -0.0893 -0.5167 0.1227  || discrepancy=0.08 || select=2/3
-----------------------------------------------
000/019-th : 0.094 0.099 0.109 0.118 0.139 0.147 0.152 0.143  ||  -0.252 -0.201 -0.112 -0.033 0.131 0.189 0.223 0.159   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.121 0.123 0.125 0.130 0.129 0.130  ||  -0.035 -0.036 -0.024 -0.008 0.008 0.048 0.039 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.122 0.127 0.130 0.130 0.127 0.128  ||  -0.066 -0.038 -0.016 0.025 0.047 0.044 0.022 0.027    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.126 0.125 0.125  ||  -0.013 -0.009 0.004 0.001 0.002 0.003 0.001 0.001     || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.123 0.125 0.130 0.126 0.128 0.126  ||  -0.043 -0.015 -0.012 0.001 0.039 0.012 0.026 0.012    || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.125 0.123 0.128 0.126 0.126 0.128  ||  -0.023 -0.016 0.001 -0.017 0.024 0.009 0.011 0.024    || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.124 0.124 0.129 0.126 0.130 0.127  ||  -0.059 -0.019 -0.003 -0.006 0.036 0.016 0.043 0.020   || dis=0.00 || select=6/8
007/019-th : 0.112 0.111 0.110 0.118 0.132 0.134 0.140 0.143  ||  -0.108 -0.114 -0.125 -0.054 0.061 0.071 0.114 0.137   || dis=0.00 || select=7/8
008/019-th : 0.105 0.109 0.116 0.125 0.137 0.142 0.133 0.133  ||  -0.155 -0.114 -0.055 0.020 0.110 0.144 0.079 0.083    || dis=0.00 || select=5/8
009/019-th : 0.119 0.119 0.115 0.121 0.126 0.130 0.134 0.136  ||  -0.051 -0.048 -0.084 -0.036 0.008 0.040 0.067 0.081   || dis=0.00 || select=7/8
010/019-th : 0.116 0.118 0.119 0.124 0.135 0.130 0.129 0.128  ||  -0.070 -0.049 -0.042 0.004 0.084 0.051 0.044 0.036    || dis=0.01 || select=4/8
011/019-th : 0.117 0.115 0.115 0.120 0.126 0.134 0.136 0.137  ||  -0.064 -0.087 -0.087 -0.045 0.011 0.072 0.084 0.089   || dis=0.00 || select=7/8
012/019-th : 0.123 0.122 0.122 0.126 0.128 0.124 0.126 0.128  ||  -0.011 -0.018 -0.021 0.007 0.029 -0.004 0.012 0.024   || dis=0.00 || select=4/8
013/019-th : 0.099 0.106 0.104 0.117 0.128 0.139 0.154 0.154  ||  -0.228 -0.158 -0.180 -0.061 0.030 0.117 0.220 0.217   || dis=0.00 || select=6/8
014/019-th : 0.091 0.094 0.111 0.130 0.137 0.144 0.151 0.141  ||  -0.281 -0.249 -0.084 0.068 0.124 0.171 0.221 0.155    || dis=0.01 || select=6/8
015/019-th : 0.109 0.107 0.109 0.111 0.126 0.143 0.150 0.145  ||  -0.138 -0.151 -0.137 -0.120 0.011 0.138 0.181 0.146   || dis=0.01 || select=6/8
016/019-th : 0.092 0.104 0.114 0.129 0.139 0.142 0.141 0.139  ||  -0.275 -0.162 -0.068 0.054 0.134 0.155 0.148 0.130    || dis=0.00 || select=5/8
017/019-th : 0.121 0.118 0.117 0.116 0.124 0.131 0.135 0.138  ||  -0.038 -0.065 -0.074 -0.075 -0.009 0.043 0.076 0.093  || dis=0.00 || select=7/8
018/019-th : 0.094 0.104 0.115 0.120 0.131 0.133 0.142 0.160  ||  -0.269 -0.169 -0.072 -0.030 0.062 0.076 0.142 0.259   || dis=0.02 || select=7/8
[epoch=041/600] FLOP : 29.45 MB, ratio : 0.7215, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:03:50] [epoch=041/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.670 (1.670)  Prec@1 45.31 (45.31) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:03:56] [epoch=041/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.419 (2.295)  Prec@1 35.71 (33.32) Prec@5 79.76 (81.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.32 Prec@5 81.43 Error@1 66.68 Error@5 18.57 Loss:2.295
***[2020-01-29 06:03:56]*** VALID [epoch=041/600] loss = 2.295176, accuracy@1 = 33.32, accuracy@5 = 81.43 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:03:56]*** start epoch=042/600 Time Left: [05:04:13], LR=[0.098796 ~ 0.098796], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=42, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.940996066749931, FLOP=40.81
[Search] : epoch=042/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:03:57] [epoch=042/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 1.104 (1.104)  Prec@1 65.23 (65.23) Prec@5 94.53 (94.53) Acls-loss 1.023 (1.023) FLOP-Loss 2.454 (2.454) Arch-Loss 5.932 (5.932)
**TRAIN** [2020-01-29 06:04:24] [epoch=042/600][097/098] Time 0.37 (0.28) Data 0.00 (0.00) Base-Loss 1.070 (1.061)  Prec@1 60.12 (62.71) Prec@5 99.40 (96.46) Acls-loss 0.974 (1.072) FLOP-Loss -2.455 (0.059) Arch-Loss -3.935 (1.190)
 **TRAIN** Prec@1 62.71 Prec@5 96.46 Error@1 37.29 Error@5 3.54 Base-Loss:1.061, Arch-Loss=1.190
***[2020-01-29 06:04:24]*** TRAIN [epoch=042/600] base-loss = 1.061301, arch-loss = 1.190260, accuracy-1 = 62.71, accuracy-5 = 96.46
[epoch=042/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 8, 11, 16, 14, 32, 25, 32, 22, 32, 22, 57, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 23.979392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.367 0.267 0.366  ||  0.0061 -0.3107 0.0055  || discrepancy=0.00 || select=0/3
001/003-th : 0.384 0.223 0.393  ||  0.0051 -0.5412 0.0275  || discrepancy=0.01 || select=2/3
002/003-th : 0.346 0.226 0.428  ||  -0.0891 -0.5147 0.1228  || discrepancy=0.08 || select=2/3
-----------------------------------------------
000/019-th : 0.094 0.100 0.109 0.117 0.139 0.147 0.152 0.142  ||  -0.254 -0.200 -0.108 -0.036 0.131 0.191 0.222 0.159   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.122 0.124 0.126 0.130 0.129 0.130  ||  -0.035 -0.036 -0.021 -0.004 0.013 0.047 0.037 0.046   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.122 0.128 0.130 0.130 0.127 0.128  ||  -0.065 -0.038 -0.015 0.028 0.045 0.043 0.021 0.027    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.126 0.126 0.125 0.125  ||  -0.012 -0.009 0.006 0.002 0.005 0.003 -0.001 -0.001   || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.043 -0.015 -0.009 0.003 0.036 0.009 0.024 0.013    || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.124 0.124 0.127 0.126 0.126 0.128  ||  -0.022 -0.016 -0.003 -0.008 0.019 0.011 0.012 0.023   || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.124 0.123 0.130 0.127 0.130 0.127  ||  -0.058 -0.019 -0.005 -0.009 0.039 0.016 0.044 0.019   || dis=0.00 || select=6/8
007/019-th : 0.111 0.111 0.110 0.118 0.134 0.134 0.140 0.143  ||  -0.112 -0.118 -0.121 -0.053 0.071 0.076 0.115 0.139   || dis=0.00 || select=7/8
008/019-th : 0.105 0.109 0.116 0.125 0.137 0.141 0.133 0.133  ||  -0.158 -0.117 -0.052 0.020 0.114 0.144 0.081 0.084    || dis=0.00 || select=5/8
009/019-th : 0.119 0.119 0.115 0.122 0.126 0.130 0.134 0.136  ||  -0.052 -0.049 -0.085 -0.026 0.009 0.038 0.066 0.081   || dis=0.00 || select=7/8
010/019-th : 0.116 0.118 0.119 0.123 0.136 0.131 0.130 0.128  ||  -0.069 -0.047 -0.045 -0.006 0.089 0.051 0.046 0.033   || dis=0.01 || select=4/8
011/019-th : 0.118 0.115 0.115 0.119 0.126 0.135 0.136 0.137  ||  -0.063 -0.088 -0.088 -0.055 0.007 0.076 0.085 0.089   || dis=0.00 || select=7/8
012/019-th : 0.124 0.122 0.122 0.125 0.128 0.124 0.127 0.128  ||  -0.010 -0.020 -0.021 0.004 0.024 -0.003 0.015 0.023   || dis=0.00 || select=4/8
013/019-th : 0.096 0.104 0.104 0.118 0.130 0.140 0.155 0.153  ||  -0.248 -0.172 -0.170 -0.044 0.055 0.131 0.227 0.221   || dis=0.00 || select=6/8
014/019-th : 0.091 0.094 0.110 0.129 0.140 0.144 0.151 0.142  ||  -0.287 -0.251 -0.089 0.065 0.145 0.174 0.224 0.159    || dis=0.01 || select=6/8
015/019-th : 0.108 0.107 0.109 0.109 0.127 0.144 0.150 0.145  ||  -0.141 -0.154 -0.139 -0.137 0.018 0.143 0.186 0.149   || dis=0.01 || select=6/8
016/019-th : 0.092 0.104 0.114 0.128 0.139 0.142 0.142 0.139  ||  -0.280 -0.160 -0.068 0.049 0.134 0.153 0.152 0.130    || dis=0.00 || select=5/8
017/019-th : 0.121 0.118 0.116 0.116 0.125 0.131 0.135 0.138  ||  -0.038 -0.063 -0.076 -0.075 -0.001 0.040 0.077 0.092  || dis=0.00 || select=7/8
018/019-th : 0.095 0.104 0.115 0.119 0.132 0.133 0.143 0.160  ||  -0.266 -0.173 -0.069 -0.033 0.066 0.075 0.145 0.257   || dis=0.02 || select=7/8
[epoch=042/600] FLOP : 23.98 MB, ratio : 0.5875, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:04:24] [epoch=042/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.198 (3.198)  Prec@1 19.14 (19.14) Prec@5 73.83 (73.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:04:30] [epoch=042/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.259 (2.429)  Prec@1 27.38 (33.00) Prec@5 70.24 (80.45) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.00 Prec@5 80.45 Error@1 67.00 Error@5 19.55 Loss:2.429
***[2020-01-29 06:04:30]*** VALID [epoch=042/600] loss = 2.429019, accuracy@1 = 33.00, accuracy@5 = 80.45 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:04:30]*** start epoch=043/600 Time Left: [05:03:57], LR=[0.098738 ~ 0.098738], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=43, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.938164925768493, FLOP=40.81
[Search] : epoch=043/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:04:31] [epoch=043/600][000/098] Time 0.79 (0.79) Data 0.37 (0.37) Base-Loss 0.983 (0.983)  Prec@1 65.23 (65.23) Prec@5 94.53 (94.53) Acls-loss 1.099 (1.099) FLOP-Loss -2.455 (-2.455) Arch-Loss -3.812 (-3.812)
**TRAIN** [2020-01-29 06:04:58] [epoch=043/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 1.007 (1.045)  Prec@1 61.31 (62.90) Prec@5 95.83 (96.28) Acls-loss 1.034 (1.063) FLOP-Loss 2.457 (0.042) Arch-Loss 5.949 (1.147)
 **TRAIN** Prec@1 62.90 Prec@5 96.28 Error@1 37.10 Error@5 3.72 Base-Loss:1.045, Arch-Loss=1.147
***[2020-01-29 06:04:58]*** TRAIN [epoch=043/600] base-loss = 1.044575, arch-loss = 1.147216, accuracy-1 = 62.90, accuracy-5 = 96.28
[epoch=043/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 8, 11, 16, 14, 32, 25, 32, 22, 32, 32, 57, 57, 57, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.5184)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.369 0.262 0.369  ||  0.0065 -0.3343 0.0058  || discrepancy=0.00 || select=0/3
001/003-th : 0.386 0.219 0.395  ||  0.0052 -0.5603 0.0281  || discrepancy=0.01 || select=2/3
002/003-th : 0.345 0.226 0.429  ||  -0.0911 -0.5171 0.1253  || discrepancy=0.08 || select=2/3
-----------------------------------------------
000/019-th : 0.094 0.099 0.109 0.117 0.141 0.147 0.152 0.143  ||  -0.260 -0.205 -0.107 -0.036 0.149 0.190 0.224 0.162   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.122 0.124 0.126 0.130 0.129 0.130  ||  -0.034 -0.036 -0.022 -0.003 0.012 0.046 0.036 0.045   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.122 0.128 0.130 0.130 0.127 0.127  ||  -0.065 -0.038 -0.016 0.033 0.044 0.042 0.020 0.026    || dis=0.00 || select=4/8
003/019-th : 0.123 0.124 0.126 0.125 0.126 0.126 0.125 0.125  ||  -0.012 -0.008 0.009 0.004 0.007 0.005 -0.003 -0.002   || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.124 0.125 0.129 0.126 0.128 0.126  ||  -0.042 -0.013 -0.009 0.002 0.038 0.009 0.023 0.012    || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.124 0.124 0.127 0.126 0.126 0.128  ||  -0.022 -0.014 -0.005 -0.009 0.018 0.012 0.011 0.022   || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.124 0.123 0.129 0.127 0.130 0.127  ||  -0.059 -0.019 -0.005 -0.009 0.038 0.018 0.043 0.020   || dis=0.00 || select=6/8
007/019-th : 0.111 0.110 0.110 0.118 0.134 0.134 0.139 0.143  ||  -0.116 -0.120 -0.122 -0.054 0.079 0.079 0.116 0.141   || dis=0.00 || select=7/8
008/019-th : 0.104 0.109 0.115 0.125 0.139 0.141 0.133 0.133  ||  -0.160 -0.119 -0.059 0.024 0.124 0.145 0.083 0.086    || dis=0.00 || select=5/8
009/019-th : 0.118 0.119 0.114 0.122 0.126 0.131 0.134 0.136  ||  -0.056 -0.051 -0.088 -0.026 0.007 0.044 0.068 0.085   || dis=0.00 || select=7/8
010/019-th : 0.116 0.118 0.118 0.123 0.135 0.131 0.130 0.129  ||  -0.069 -0.048 -0.048 -0.008 0.080 0.053 0.044 0.036   || dis=0.00 || select=4/8
011/019-th : 0.117 0.114 0.115 0.119 0.127 0.135 0.136 0.137  ||  -0.069 -0.089 -0.085 -0.049 0.014 0.076 0.086 0.091   || dis=0.00 || select=7/8
012/019-th : 0.123 0.122 0.122 0.125 0.127 0.125 0.127 0.128  ||  -0.012 -0.022 -0.023 0.004 0.017 0.003 0.016 0.024    || dis=0.00 || select=7/8
013/019-th : 0.094 0.103 0.104 0.118 0.132 0.141 0.155 0.154  ||  -0.264 -0.180 -0.170 -0.041 0.075 0.137 0.234 0.228   || dis=0.00 || select=6/8
014/019-th : 0.090 0.094 0.110 0.129 0.139 0.144 0.152 0.142  ||  -0.292 -0.251 -0.095 0.066 0.138 0.174 0.226 0.162    || dis=0.01 || select=6/8
015/019-th : 0.108 0.106 0.108 0.108 0.129 0.145 0.151 0.145  ||  -0.145 -0.160 -0.139 -0.145 0.032 0.152 0.190 0.151   || dis=0.01 || select=6/8
016/019-th : 0.091 0.103 0.113 0.128 0.141 0.142 0.142 0.139  ||  -0.286 -0.163 -0.070 0.048 0.148 0.154 0.156 0.133    || dis=0.00 || select=6/8
017/019-th : 0.121 0.117 0.116 0.118 0.125 0.130 0.135 0.137  ||  -0.037 -0.067 -0.077 -0.056 0.000 0.037 0.077 0.093   || dis=0.00 || select=7/8
018/019-th : 0.094 0.104 0.115 0.119 0.131 0.133 0.144 0.160  ||  -0.271 -0.172 -0.071 -0.039 0.062 0.072 0.152 0.260   || dis=0.02 || select=7/8
[epoch=043/600] FLOP : 25.52 MB, ratio : 0.6252, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:04:58] [epoch=043/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.265 (3.265)  Prec@1 27.34 (27.34) Prec@5 75.39 (75.39) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:05:04] [epoch=043/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.606 (2.542)  Prec@1 27.38 (31.60) Prec@5 77.98 (79.68) Size=[168, 3, 32, 32]
 **VALID** Prec@1 31.60 Prec@5 79.68 Error@1 68.40 Error@5 20.32 Loss:2.542
***[2020-01-29 06:05:04]*** VALID [epoch=043/600] loss = 2.541735, accuracy@1 = 31.60, accuracy@5 = 79.68 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:05:04]*** start epoch=044/600 Time Left: [05:03:40], LR=[0.098679 ~ 0.098679], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=44, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.935268312039243, FLOP=40.81
[Search] : epoch=044/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:05:05] [epoch=044/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.884 (0.884)  Prec@1 67.19 (67.19) Prec@5 98.05 (98.05) Acls-loss 1.104 (1.104) FLOP-Loss -2.456 (-2.456) Arch-Loss -3.809 (-3.809)
**TRAIN** [2020-01-29 06:05:31] [epoch=044/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.013 (1.014)  Prec@1 66.07 (64.29) Prec@5 95.24 (96.74) Acls-loss 1.029 (1.032) FLOP-Loss 2.459 (-0.008) Arch-Loss 5.947 (1.016)
 **TRAIN** Prec@1 64.29 Prec@5 96.74 Error@1 35.71 Error@5 3.26 Base-Loss:1.014, Arch-Loss=1.016
***[2020-01-29 06:05:31]*** TRAIN [epoch=044/600] base-loss = 1.014452, arch-loss = 1.015538, accuracy-1 = 64.29, accuracy-5 = 96.74
[epoch=044/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 8, 11, 16, 14, 32, 25, 32, 22, 32, 32, 57, 57, 57, 57, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 30.984512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.370 0.259 0.370  ||  0.0063 -0.3507 0.0066  || discrepancy=0.00 || select=2/3
001/003-th : 0.387 0.217 0.396  ||  0.0045 -0.5728 0.0296  || discrepancy=0.01 || select=2/3
002/003-th : 0.345 0.225 0.430  ||  -0.0937 -0.5214 0.1284  || discrepancy=0.09 || select=2/3
-----------------------------------------------
000/019-th : 0.093 0.098 0.109 0.117 0.140 0.147 0.152 0.143  ||  -0.265 -0.211 -0.107 -0.039 0.145 0.196 0.228 0.166   || dis=0.01 || select=6/8
001/019-th : 0.120 0.120 0.122 0.124 0.125 0.130 0.129 0.130  ||  -0.034 -0.037 -0.021 -0.001 0.008 0.046 0.037 0.046   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.122 0.129 0.130 0.129 0.127 0.127  ||  -0.067 -0.039 -0.016 0.036 0.046 0.042 0.021 0.026    || dis=0.00 || select=4/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.126 0.125 0.125  ||  -0.012 -0.009 0.009 0.005 0.007 0.004 -0.002 -0.002   || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.123 0.125 0.129 0.126 0.128 0.126  ||  -0.044 -0.015 -0.010 0.005 0.035 0.012 0.023 0.013    || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.124 0.124 0.127 0.127 0.126 0.128  ||  -0.023 -0.015 -0.006 -0.011 0.016 0.014 0.012 0.024   || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.124 0.123 0.129 0.127 0.130 0.127  ||  -0.061 -0.021 -0.007 -0.012 0.036 0.023 0.047 0.021   || dis=0.00 || select=6/8
007/019-th : 0.111 0.110 0.110 0.117 0.132 0.135 0.140 0.144  ||  -0.118 -0.121 -0.120 -0.063 0.062 0.083 0.119 0.144   || dis=0.00 || select=7/8
008/019-th : 0.104 0.109 0.116 0.125 0.136 0.143 0.134 0.134  ||  -0.162 -0.123 -0.061 0.016 0.103 0.151 0.085 0.090    || dis=0.01 || select=5/8
009/019-th : 0.118 0.119 0.114 0.122 0.125 0.131 0.134 0.137  ||  -0.057 -0.054 -0.091 -0.025 -0.001 0.048 0.069 0.087  || dis=0.00 || select=7/8
010/019-th : 0.116 0.118 0.118 0.124 0.134 0.131 0.130 0.129  ||  -0.071 -0.050 -0.049 -0.006 0.073 0.055 0.045 0.038   || dis=0.00 || select=4/8
011/019-th : 0.116 0.114 0.114 0.119 0.127 0.135 0.137 0.137  ||  -0.071 -0.092 -0.090 -0.048 0.018 0.074 0.093 0.094   || dis=0.00 || select=7/8
012/019-th : 0.123 0.122 0.122 0.125 0.127 0.125 0.127 0.128  ||  -0.013 -0.023 -0.024 -0.000 0.020 0.005 0.017 0.025   || dis=0.00 || select=7/8
013/019-th : 0.093 0.102 0.103 0.118 0.132 0.142 0.156 0.155  ||  -0.275 -0.182 -0.177 -0.041 0.075 0.144 0.241 0.234   || dis=0.00 || select=6/8
014/019-th : 0.090 0.093 0.110 0.129 0.140 0.144 0.152 0.142  ||  -0.296 -0.256 -0.097 0.064 0.151 0.175 0.230 0.165    || dis=0.01 || select=6/8
015/019-th : 0.107 0.106 0.108 0.110 0.128 0.144 0.151 0.146  ||  -0.150 -0.166 -0.140 -0.128 0.027 0.148 0.193 0.156   || dis=0.01 || select=6/8
016/019-th : 0.091 0.103 0.113 0.128 0.142 0.142 0.143 0.139  ||  -0.293 -0.168 -0.073 0.051 0.160 0.157 0.161 0.135    || dis=0.00 || select=6/8
017/019-th : 0.120 0.117 0.116 0.119 0.125 0.130 0.135 0.137  ||  -0.040 -0.068 -0.076 -0.047 0.002 0.037 0.078 0.094   || dis=0.00 || select=7/8
018/019-th : 0.094 0.104 0.115 0.119 0.130 0.132 0.144 0.161  ||  -0.278 -0.171 -0.069 -0.035 0.053 0.069 0.155 0.263   || dis=0.02 || select=7/8
[epoch=044/600] FLOP : 30.98 MB, ratio : 0.7592, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:05:32] [epoch=044/600][000/098] Time 0.40 (0.40) Data 0.30 (0.30) Loss 2.135 (2.135)  Prec@1 27.73 (27.73) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:05:38] [epoch=044/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.932 (2.523)  Prec@1 34.52 (33.32) Prec@5 83.33 (80.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.32 Prec@5 80.21 Error@1 66.68 Error@5 19.79 Loss:2.523
***[2020-01-29 06:05:38]*** VALID [epoch=044/600] loss = 2.523172, accuracy@1 = 33.32, accuracy@5 = 80.21 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:05:38]*** start epoch=045/600 Time Left: [05:03:18], LR=[0.098618 ~ 0.098618], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=45, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.932306304974308, FLOP=40.81
[Search] : epoch=045/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:05:39] [epoch=045/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 1.078 (1.078)  Prec@1 62.11 (62.11) Prec@5 96.09 (96.09) Acls-loss 1.070 (1.070) FLOP-Loss 2.458 (2.458) Arch-Loss 5.987 (5.987)
**TRAIN** [2020-01-29 06:06:04] [epoch=045/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.119 (1.013)  Prec@1 58.33 (64.31) Prec@5 95.24 (96.57) Acls-loss 1.078 (1.033) FLOP-Loss 0.000 (0.000) Arch-Loss 1.078 (1.033)
 **TRAIN** Prec@1 64.31 Prec@5 96.57 Error@1 35.69 Error@5 3.43 Base-Loss:1.013, Arch-Loss=1.033
***[2020-01-29 06:06:04]*** TRAIN [epoch=045/600] base-loss = 1.013475, arch-loss = 1.033198, accuracy-1 = 64.31, accuracy-5 = 96.57
[epoch=045/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 8, 11, 16, 14, 32, 25, 32, 22, 28, 22, 57, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.49792)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.370 0.260 0.370  ||  0.0059 -0.3468 0.0072  || discrepancy=0.00 || select=2/3
001/003-th : 0.388 0.214 0.398  ||  0.0035 -0.5903 0.0313  || discrepancy=0.01 || select=2/3
002/003-th : 0.344 0.223 0.432  ||  -0.0959 -0.5282 0.1311  || discrepancy=0.09 || select=2/3
-----------------------------------------------
000/019-th : 0.093 0.098 0.110 0.117 0.137 0.149 0.153 0.144  ||  -0.272 -0.213 -0.103 -0.042 0.119 0.202 0.230 0.171   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.124 0.126 0.130 0.129 0.130  ||  -0.035 -0.040 -0.021 0.002 0.011 0.048 0.037 0.047    || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.122 0.129 0.130 0.130 0.127 0.127  ||  -0.068 -0.040 -0.014 0.036 0.044 0.044 0.021 0.027    || dis=0.00 || select=4/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.126 0.125 0.125  ||  -0.013 -0.010 0.007 0.005 0.007 0.007 -0.001 -0.001   || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.123 0.125 0.130 0.126 0.128 0.126  ||  -0.045 -0.017 -0.012 0.001 0.039 0.014 0.024 0.014    || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.124 0.123 0.127 0.127 0.127 0.128  ||  -0.024 -0.016 -0.006 -0.017 0.017 0.014 0.013 0.024   || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.123 0.123 0.129 0.128 0.131 0.127  ||  -0.064 -0.022 -0.009 -0.015 0.038 0.023 0.049 0.023   || dis=0.00 || select=6/8
007/019-th : 0.110 0.110 0.110 0.116 0.133 0.136 0.141 0.144  ||  -0.123 -0.124 -0.123 -0.070 0.064 0.089 0.123 0.147   || dis=0.00 || select=7/8
008/019-th : 0.104 0.108 0.115 0.125 0.135 0.143 0.134 0.135  ||  -0.164 -0.129 -0.064 0.019 0.098 0.153 0.091 0.092    || dis=0.01 || select=5/8
009/019-th : 0.118 0.118 0.114 0.122 0.125 0.131 0.134 0.137  ||  -0.060 -0.058 -0.091 -0.023 -0.000 0.049 0.072 0.091  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.133 0.132 0.130 0.129  ||  -0.072 -0.052 -0.052 0.008 0.072 0.060 0.046 0.038    || dis=0.00 || select=4/8
011/019-th : 0.116 0.114 0.114 0.120 0.127 0.135 0.138 0.137  ||  -0.077 -0.094 -0.095 -0.040 0.015 0.080 0.098 0.096   || dis=0.00 || select=6/8
012/019-th : 0.123 0.122 0.122 0.125 0.128 0.126 0.127 0.128  ||  -0.014 -0.025 -0.025 0.001 0.027 0.007 0.018 0.026    || dis=0.00 || select=4/8
013/019-th : 0.092 0.101 0.103 0.117 0.132 0.142 0.157 0.156  ||  -0.282 -0.191 -0.172 -0.048 0.074 0.149 0.245 0.240   || dis=0.00 || select=6/8
014/019-th : 0.089 0.093 0.109 0.128 0.142 0.144 0.152 0.143  ||  -0.301 -0.260 -0.103 0.059 0.168 0.178 0.234 0.170    || dis=0.01 || select=6/8
015/019-th : 0.106 0.105 0.108 0.111 0.127 0.145 0.151 0.147  ||  -0.157 -0.174 -0.143 -0.114 0.021 0.151 0.196 0.163   || dis=0.00 || select=6/8
016/019-th : 0.090 0.102 0.112 0.127 0.144 0.143 0.143 0.139  ||  -0.298 -0.172 -0.076 0.042 0.169 0.163 0.163 0.139    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.116 0.119 0.126 0.130 0.135 0.138  ||  -0.042 -0.067 -0.078 -0.050 0.005 0.037 0.078 0.095   || dis=0.00 || select=7/8
018/019-th : 0.094 0.104 0.115 0.118 0.129 0.134 0.145 0.161  ||  -0.279 -0.173 -0.072 -0.043 0.042 0.080 0.157 0.266   || dis=0.02 || select=7/8
[epoch=045/600] FLOP : 28.50 MB, ratio : 0.6983, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:06:04] [epoch=045/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.962 (1.962)  Prec@1 40.23 (40.23) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:06:10] [epoch=045/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.014 (2.290)  Prec@1 40.48 (34.25) Prec@5 89.29 (81.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.25 Prec@5 81.89 Error@1 65.75 Error@5 18.11 Loss:2.290
***[2020-01-29 06:06:10]*** VALID [epoch=045/600] loss = 2.290388, accuracy@1 = 34.25, accuracy@5 = 81.89 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:06:10]*** start epoch=046/600 Time Left: [05:02:40], LR=[0.098557 ~ 0.098557], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=46, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.929278985778608, FLOP=40.81
[Search] : epoch=046/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:06:11] [epoch=046/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 0.985 (0.985)  Prec@1 66.41 (66.41) Prec@5 97.27 (97.27) Acls-loss 0.995 (0.995) FLOP-Loss 0.000 (0.000) Arch-Loss 0.995 (0.995)
**TRAIN** [2020-01-29 06:06:36] [epoch=046/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.053 (1.017)  Prec@1 63.69 (64.19) Prec@5 95.24 (96.62) Acls-loss 1.054 (1.023) FLOP-Loss -2.461 (0.034) Arch-Loss -3.868 (1.091)
 **TRAIN** Prec@1 64.19 Prec@5 96.62 Error@1 35.81 Error@5 3.38 Base-Loss:1.017, Arch-Loss=1.091
***[2020-01-29 06:06:36]*** TRAIN [epoch=046/600] base-loss = 1.016892, arch-loss = 1.091396, accuracy-1 = 64.19, accuracy-5 = 96.62
[epoch=046/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 8, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.004224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.369 0.261 0.369  ||  0.0071 -0.3388 0.0062  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.211 0.400  ||  0.0039 -0.6064 0.0316  || discrepancy=0.01 || select=2/3
002/003-th : 0.344 0.223 0.433  ||  -0.0972 -0.5294 0.1328  || discrepancy=0.09 || select=2/3
-----------------------------------------------
000/019-th : 0.092 0.098 0.109 0.117 0.139 0.148 0.153 0.144  ||  -0.276 -0.214 -0.104 -0.040 0.132 0.198 0.232 0.173   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.122 0.124 0.125 0.130 0.129 0.130  ||  -0.034 -0.040 -0.020 0.000 0.010 0.047 0.037 0.046    || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.122 0.129 0.130 0.130 0.127 0.128  ||  -0.068 -0.040 -0.014 0.035 0.043 0.044 0.021 0.027    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.126 0.125 0.125  ||  -0.013 -0.009 0.009 0.007 0.007 0.008 -0.002 -0.002   || dis=0.00 || select=2/8
004/019-th : 0.119 0.123 0.123 0.125 0.129 0.126 0.128 0.126  ||  -0.044 -0.017 -0.012 0.002 0.038 0.014 0.025 0.013    || dis=0.00 || select=4/8
005/019-th : 0.122 0.123 0.124 0.123 0.127 0.127 0.126 0.128  ||  -0.024 -0.017 -0.007 -0.013 0.019 0.016 0.013 0.024   || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.124 0.123 0.129 0.128 0.131 0.127  ||  -0.063 -0.021 -0.007 -0.016 0.037 0.025 0.048 0.021   || dis=0.00 || select=6/8
007/019-th : 0.110 0.110 0.110 0.117 0.131 0.137 0.141 0.145  ||  -0.123 -0.125 -0.123 -0.064 0.048 0.091 0.123 0.148   || dis=0.00 || select=7/8
008/019-th : 0.104 0.108 0.115 0.125 0.135 0.144 0.135 0.135  ||  -0.164 -0.131 -0.064 0.015 0.093 0.156 0.092 0.093    || dis=0.01 || select=5/8
009/019-th : 0.118 0.118 0.114 0.122 0.125 0.131 0.135 0.137  ||  -0.060 -0.059 -0.090 -0.024 -0.002 0.049 0.073 0.092  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.132 0.132 0.130 0.129  ||  -0.074 -0.051 -0.051 0.007 0.058 0.062 0.046 0.038    || dis=0.00 || select=5/8
011/019-th : 0.116 0.113 0.113 0.120 0.128 0.135 0.138 0.137  ||  -0.077 -0.097 -0.098 -0.041 0.023 0.080 0.102 0.097   || dis=0.00 || select=6/8
012/019-th : 0.123 0.122 0.121 0.126 0.127 0.126 0.127 0.128  ||  -0.016 -0.025 -0.027 0.008 0.022 0.010 0.018 0.027    || dis=0.00 || select=7/8
013/019-th : 0.092 0.100 0.104 0.117 0.130 0.142 0.157 0.157  ||  -0.284 -0.200 -0.166 -0.049 0.062 0.147 0.246 0.248   || dis=0.00 || select=7/8
014/019-th : 0.089 0.093 0.109 0.127 0.142 0.144 0.152 0.143  ||  -0.303 -0.261 -0.101 0.052 0.166 0.174 0.234 0.173    || dis=0.01 || select=6/8
015/019-th : 0.106 0.104 0.108 0.112 0.128 0.144 0.152 0.147  ||  -0.158 -0.181 -0.144 -0.109 0.025 0.148 0.200 0.167   || dis=0.01 || select=6/8
016/019-th : 0.090 0.102 0.112 0.127 0.144 0.143 0.143 0.140  ||  -0.302 -0.177 -0.077 0.046 0.172 0.165 0.165 0.142    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.116 0.119 0.126 0.130 0.135 0.137  ||  -0.041 -0.069 -0.078 -0.049 0.009 0.040 0.077 0.095   || dis=0.00 || select=7/8
018/019-th : 0.093 0.104 0.115 0.119 0.128 0.134 0.145 0.161  ||  -0.280 -0.174 -0.070 -0.035 0.039 0.083 0.159 0.263   || dis=0.02 || select=7/8
[epoch=046/600] FLOP : 25.00 MB, ratio : 0.6127, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:06:36] [epoch=046/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.088 (3.088)  Prec@1 30.86 (30.86) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:06:42] [epoch=046/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.750 (2.359)  Prec@1 42.26 (33.53) Prec@5 85.12 (82.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.53 Prec@5 82.10 Error@1 66.47 Error@5 17.90 Loss:2.359
***[2020-01-29 06:06:42]*** VALID [epoch=046/600] loss = 2.358687, accuracy@1 = 33.53, accuracy@5 = 82.10 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:06:42]*** start epoch=047/600 Time Left: [05:01:58], LR=[0.098494 ~ 0.098494], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=47, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.92618643744763, FLOP=40.81
[Search] : epoch=047/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:06:43] [epoch=047/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 1.131 (1.131)  Prec@1 60.16 (60.16) Prec@5 96.48 (96.48) Acls-loss 0.814 (0.814) FLOP-Loss -2.461 (-2.461) Arch-Loss -4.109 (-4.109)
**TRAIN** [2020-01-29 06:07:08] [epoch=047/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.014 (1.009)  Prec@1 68.45 (64.98) Prec@5 94.64 (96.76) Acls-loss 1.316 (1.025) FLOP-Loss -2.463 (0.009) Arch-Loss -3.610 (1.043)
 **TRAIN** Prec@1 64.98 Prec@5 96.76 Error@1 35.02 Error@5 3.24 Base-Loss:1.009, Arch-Loss=1.043
***[2020-01-29 06:07:08]*** TRAIN [epoch=047/600] base-loss = 1.009108, arch-loss = 1.043306, accuracy-1 = 64.98, accuracy-5 = 96.76
[epoch=047/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 32.485568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.371 0.258 0.371  ||  0.0067 -0.3568 0.0071  || discrepancy=0.00 || select=2/3
001/003-th : 0.390 0.207 0.403  ||  0.0025 -0.6302 0.0339  || discrepancy=0.01 || select=2/3
002/003-th : 0.344 0.222 0.434  ||  -0.0992 -0.5350 0.1354  || discrepancy=0.09 || select=2/3
-----------------------------------------------
000/019-th : 0.092 0.098 0.110 0.117 0.138 0.149 0.154 0.144  ||  -0.281 -0.217 -0.101 -0.040 0.126 0.202 0.236 0.174   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.122 0.124 0.126 0.130 0.129 0.130  ||  -0.035 -0.041 -0.021 -0.002 0.011 0.047 0.037 0.048   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.122 0.128 0.130 0.130 0.127 0.128  ||  -0.068 -0.041 -0.015 0.033 0.043 0.044 0.022 0.027    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.126 0.125 0.125  ||  -0.014 -0.009 0.007 0.007 0.005 0.009 -0.001 -0.001   || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.129 0.127 0.128 0.127  ||  -0.045 -0.018 -0.012 0.001 0.037 0.016 0.025 0.015    || dis=0.00 || select=4/8
005/019-th : 0.122 0.122 0.124 0.123 0.127 0.127 0.127 0.128  ||  -0.026 -0.020 -0.005 -0.017 0.019 0.018 0.014 0.027   || dis=0.00 || select=7/8
006/019-th : 0.117 0.122 0.124 0.122 0.130 0.128 0.131 0.127  ||  -0.065 -0.023 -0.008 -0.019 0.042 0.026 0.051 0.022   || dis=0.00 || select=6/8
007/019-th : 0.110 0.110 0.110 0.116 0.131 0.137 0.141 0.145  ||  -0.125 -0.128 -0.130 -0.069 0.047 0.095 0.126 0.152   || dis=0.00 || select=7/8
008/019-th : 0.104 0.108 0.115 0.125 0.134 0.144 0.135 0.135  ||  -0.168 -0.132 -0.066 0.018 0.090 0.162 0.093 0.094    || dis=0.01 || select=5/8
009/019-th : 0.118 0.118 0.114 0.122 0.124 0.132 0.135 0.137  ||  -0.061 -0.061 -0.091 -0.028 -0.006 0.050 0.077 0.093  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.130 0.132 0.131 0.130  ||  -0.077 -0.051 -0.050 0.005 0.047 0.062 0.050 0.041    || dis=0.00 || select=5/8
011/019-th : 0.115 0.113 0.113 0.119 0.127 0.135 0.139 0.138  ||  -0.079 -0.098 -0.096 -0.047 0.017 0.077 0.105 0.100   || dis=0.00 || select=6/8
012/019-th : 0.122 0.121 0.121 0.126 0.128 0.126 0.127 0.128  ||  -0.019 -0.028 -0.031 0.010 0.027 0.010 0.021 0.030    || dis=0.00 || select=7/8
013/019-th : 0.092 0.100 0.103 0.116 0.131 0.143 0.157 0.158  ||  -0.290 -0.204 -0.172 -0.055 0.063 0.154 0.250 0.255   || dis=0.00 || select=7/8
014/019-th : 0.088 0.092 0.109 0.127 0.143 0.144 0.153 0.144  ||  -0.311 -0.265 -0.103 0.052 0.170 0.180 0.240 0.176    || dis=0.01 || select=6/8
015/019-th : 0.105 0.104 0.107 0.111 0.127 0.146 0.152 0.148  ||  -0.168 -0.181 -0.149 -0.113 0.021 0.159 0.203 0.172   || dis=0.00 || select=6/8
016/019-th : 0.089 0.101 0.112 0.126 0.144 0.144 0.144 0.140  ||  -0.308 -0.180 -0.081 0.037 0.175 0.171 0.170 0.145    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.115 0.119 0.126 0.131 0.135 0.138  ||  -0.043 -0.070 -0.081 -0.046 0.010 0.044 0.078 0.096   || dis=0.00 || select=7/8
018/019-th : 0.093 0.104 0.115 0.119 0.128 0.135 0.145 0.161  ||  -0.285 -0.174 -0.074 -0.034 0.036 0.092 0.159 0.266   || dis=0.02 || select=7/8
[epoch=047/600] FLOP : 32.49 MB, ratio : 0.7960, Expected-ratio : 0.7000, Discrepancy : 0.007
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:07:09] [epoch=047/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.921 (1.921)  Prec@1 40.23 (40.23) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:07:15] [epoch=047/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.219 (2.398)  Prec@1 25.60 (32.54) Prec@5 76.79 (79.93) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.54 Prec@5 79.93 Error@1 67.46 Error@5 20.07 Loss:2.398
***[2020-01-29 06:07:15]*** VALID [epoch=047/600] loss = 2.397602, accuracy@1 = 32.54, accuracy@5 = 79.93 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:07:15]*** start epoch=048/600 Time Left: [05:01:20], LR=[0.098429 ~ 0.098429], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=48, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.923028744765146, FLOP=40.81
[Search] : epoch=048/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:07:16] [epoch=048/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 1.073 (1.073)  Prec@1 62.89 (62.89) Prec@5 94.53 (94.53) Acls-loss 1.021 (1.021) FLOP-Loss 2.463 (2.463) Arch-Loss 5.948 (5.948)
**TRAIN** [2020-01-29 06:07:40] [epoch=048/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.140 (0.993)  Prec@1 54.76 (65.27) Prec@5 95.24 (96.75) Acls-loss 1.029 (1.014) FLOP-Loss -2.464 (0.009) Arch-Loss -3.899 (1.031)
 **TRAIN** Prec@1 65.27 Prec@5 96.75 Error@1 34.73 Error@5 3.25 Base-Loss:0.993, Arch-Loss=1.031
***[2020-01-29 06:07:40]*** TRAIN [epoch=048/600] base-loss = 0.992888, arch-loss = 1.031464, accuracy-1 = 65.27, accuracy-5 = 96.75
[epoch=048/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 32.485568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.371 0.258 0.371  ||  0.0065 -0.3544 0.0076  || discrepancy=0.00 || select=2/3
001/003-th : 0.391 0.204 0.405  ||  0.0017 -0.6478 0.0355  || discrepancy=0.01 || select=2/3
002/003-th : 0.342 0.223 0.435  ||  -0.1012 -0.5303 0.1375  || discrepancy=0.09 || select=2/3
-----------------------------------------------
000/019-th : 0.091 0.097 0.110 0.116 0.137 0.149 0.154 0.145  ||  -0.285 -0.220 -0.102 -0.042 0.123 0.201 0.239 0.178   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.122 0.124 0.126 0.130 0.129 0.130  ||  -0.037 -0.042 -0.022 -0.004 0.016 0.049 0.038 0.049   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.122 0.128 0.130 0.130 0.127 0.128  ||  -0.069 -0.041 -0.014 0.031 0.044 0.044 0.022 0.028    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.125 0.126 0.125 0.125  ||  -0.013 -0.010 0.006 0.006 0.002 0.010 -0.001 -0.001   || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.130 0.127 0.128 0.127  ||  -0.046 -0.020 -0.013 0.002 0.040 0.017 0.027 0.015    || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.123 0.127 0.127 0.127 0.128  ||  -0.028 -0.019 -0.006 -0.018 0.016 0.018 0.015 0.028   || dis=0.00 || select=7/8
006/019-th : 0.117 0.121 0.124 0.122 0.130 0.128 0.131 0.127  ||  -0.066 -0.026 -0.008 -0.018 0.042 0.025 0.053 0.024   || dis=0.00 || select=6/8
007/019-th : 0.110 0.109 0.109 0.116 0.131 0.137 0.142 0.146  ||  -0.126 -0.134 -0.131 -0.070 0.046 0.097 0.128 0.156   || dis=0.00 || select=7/8
008/019-th : 0.103 0.108 0.114 0.126 0.134 0.144 0.136 0.135  ||  -0.174 -0.132 -0.072 0.025 0.090 0.162 0.101 0.095    || dis=0.01 || select=5/8
009/019-th : 0.117 0.117 0.114 0.123 0.124 0.132 0.135 0.137  ||  -0.065 -0.063 -0.091 -0.020 -0.005 0.052 0.079 0.095  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.131 0.133 0.131 0.130  ||  -0.076 -0.053 -0.054 0.004 0.050 0.067 0.049 0.041    || dis=0.00 || select=5/8
011/019-th : 0.115 0.113 0.113 0.119 0.129 0.135 0.139 0.138  ||  -0.081 -0.098 -0.103 -0.050 0.032 0.078 0.105 0.102   || dis=0.00 || select=6/8
012/019-th : 0.122 0.121 0.121 0.126 0.129 0.126 0.127 0.129  ||  -0.020 -0.031 -0.034 0.007 0.030 0.012 0.020 0.033    || dis=0.00 || select=7/8
013/019-th : 0.091 0.099 0.103 0.116 0.130 0.144 0.158 0.159  ||  -0.296 -0.213 -0.173 -0.053 0.056 0.161 0.254 0.260   || dis=0.00 || select=7/8
014/019-th : 0.088 0.092 0.108 0.126 0.142 0.145 0.154 0.144  ||  -0.314 -0.269 -0.107 0.048 0.166 0.187 0.243 0.178    || dis=0.01 || select=6/8
015/019-th : 0.104 0.103 0.107 0.111 0.128 0.146 0.153 0.148  ||  -0.174 -0.189 -0.151 -0.111 0.033 0.165 0.209 0.175   || dis=0.01 || select=6/8
016/019-th : 0.089 0.101 0.111 0.126 0.144 0.144 0.144 0.141  ||  -0.313 -0.184 -0.087 0.038 0.176 0.175 0.174 0.149    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.115 0.119 0.125 0.131 0.136 0.138  ||  -0.043 -0.070 -0.082 -0.046 -0.004 0.046 0.080 0.097  || dis=0.00 || select=7/8
018/019-th : 0.093 0.104 0.115 0.119 0.129 0.135 0.144 0.161  ||  -0.285 -0.175 -0.068 -0.038 0.044 0.093 0.156 0.266   || dis=0.02 || select=7/8
[epoch=048/600] FLOP : 32.49 MB, ratio : 0.7960, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:07:41] [epoch=048/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.658 (2.658)  Prec@1 16.41 (16.41) Prec@5 74.22 (74.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:07:47] [epoch=048/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.488 (2.623)  Prec@1 33.93 (35.11) Prec@5 86.31 (82.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.11 Prec@5 82.31 Error@1 64.89 Error@5 17.69 Loss:2.623
***[2020-01-29 06:07:47]*** VALID [epoch=048/600] loss = 2.622798, accuracy@1 = 35.11, accuracy@5 = 82.31 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:07:47]*** start epoch=049/600 Time Left: [05:00:38], LR=[0.098363 ~ 0.098363], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=49, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.919805994300898, FLOP=40.81
[Search] : epoch=049/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:07:47] [epoch=049/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.931 (0.931)  Prec@1 67.19 (67.19) Prec@5 97.27 (97.27) Acls-loss 1.078 (1.078) FLOP-Loss 2.465 (2.465) Arch-Loss 6.008 (6.008)
**TRAIN** [2020-01-29 06:08:12] [epoch=049/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.904 (1.011)  Prec@1 66.67 (64.74) Prec@5 95.83 (96.64) Acls-loss 1.120 (1.013) FLOP-Loss -2.465 (0.059) Arch-Loss -3.810 (1.132)
 **TRAIN** Prec@1 64.74 Prec@5 96.64 Error@1 35.26 Error@5 3.36 Base-Loss:1.011, Arch-Loss=1.132
***[2020-01-29 06:08:12]*** TRAIN [epoch=049/600] base-loss = 1.011316, arch-loss = 1.131542, accuracy-1 = 64.74, accuracy-5 = 96.64
[epoch=049/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 12, 11, 16, 14, 32, 25, 32, 25, 28, 22, 64, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.686656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.371 0.258 0.371  ||  0.0074 -0.3535 0.0070  || discrepancy=0.00 || select=0/3
001/003-th : 0.392 0.203 0.405  ||  0.0023 -0.6556 0.0355  || discrepancy=0.01 || select=2/3
002/003-th : 0.342 0.223 0.435  ||  -0.1024 -0.5316 0.1390  || discrepancy=0.09 || select=2/3
-----------------------------------------------
000/019-th : 0.091 0.097 0.109 0.117 0.137 0.149 0.154 0.145  ||  -0.287 -0.222 -0.105 -0.034 0.121 0.202 0.238 0.180   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.040 -0.019 -0.009 0.015 0.048 0.037 0.048   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.127  ||  -0.068 -0.040 -0.013 0.033 0.046 0.044 0.021 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.126 0.125 0.126 0.125 0.125  ||  -0.012 -0.012 0.006 0.009 0.002 0.009 -0.001 -0.002   || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.129 0.127 0.128 0.127  ||  -0.045 -0.018 -0.012 0.001 0.034 0.015 0.026 0.015    || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.123 0.127 0.127 0.127 0.128  ||  -0.028 -0.020 -0.003 -0.014 0.017 0.019 0.014 0.027   || dis=0.00 || select=7/8
006/019-th : 0.117 0.121 0.124 0.122 0.130 0.128 0.131 0.128  ||  -0.067 -0.026 -0.007 -0.021 0.042 0.025 0.052 0.025   || dis=0.00 || select=6/8
007/019-th : 0.110 0.109 0.109 0.117 0.131 0.137 0.142 0.146  ||  -0.125 -0.137 -0.134 -0.063 0.048 0.095 0.130 0.156   || dis=0.00 || select=7/8
008/019-th : 0.103 0.107 0.114 0.128 0.134 0.144 0.136 0.134  ||  -0.177 -0.134 -0.073 0.043 0.093 0.162 0.104 0.093    || dis=0.01 || select=5/8
009/019-th : 0.117 0.117 0.113 0.123 0.125 0.132 0.136 0.137  ||  -0.066 -0.064 -0.096 -0.015 -0.001 0.053 0.081 0.095  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.131 0.133 0.130 0.129  ||  -0.076 -0.053 -0.052 0.005 0.055 0.065 0.048 0.040    || dis=0.00 || select=5/8
011/019-th : 0.115 0.113 0.113 0.120 0.127 0.135 0.139 0.138  ||  -0.084 -0.098 -0.098 -0.043 0.018 0.079 0.105 0.103   || dis=0.00 || select=6/8
012/019-th : 0.122 0.121 0.120 0.125 0.129 0.126 0.127 0.129  ||  -0.019 -0.031 -0.036 0.003 0.033 0.013 0.022 0.032    || dis=0.00 || select=4/8
013/019-th : 0.091 0.099 0.103 0.117 0.129 0.144 0.158 0.160  ||  -0.300 -0.217 -0.177 -0.049 0.052 0.163 0.254 0.266   || dis=0.00 || select=7/8
014/019-th : 0.088 0.092 0.108 0.127 0.143 0.145 0.154 0.144  ||  -0.316 -0.274 -0.110 0.053 0.169 0.188 0.247 0.178    || dis=0.01 || select=6/8
015/019-th : 0.104 0.102 0.107 0.111 0.128 0.146 0.153 0.148  ||  -0.178 -0.193 -0.152 -0.107 0.033 0.164 0.213 0.179   || dis=0.01 || select=6/8
016/019-th : 0.088 0.101 0.111 0.126 0.146 0.144 0.144 0.141  ||  -0.317 -0.185 -0.091 0.040 0.188 0.175 0.175 0.151    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.116 0.119 0.123 0.131 0.136 0.138  ||  -0.044 -0.069 -0.079 -0.052 -0.019 0.043 0.081 0.099  || dis=0.00 || select=7/8
018/019-th : 0.092 0.103 0.115 0.119 0.131 0.136 0.143 0.161  ||  -0.294 -0.176 -0.068 -0.036 0.064 0.098 0.152 0.269   || dis=0.02 || select=7/8
[epoch=049/600] FLOP : 24.69 MB, ratio : 0.6049, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:08:13] [epoch=049/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.945 (2.945)  Prec@1 13.28 (13.28) Prec@5 59.77 (59.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:08:19] [epoch=049/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.710 (2.473)  Prec@1 31.55 (34.98) Prec@5 74.40 (81.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.98 Prec@5 81.78 Error@1 65.02 Error@5 18.22 Loss:2.473
***[2020-01-29 06:08:19]*** VALID [epoch=049/600] loss = 2.472985, accuracy@1 = 34.98, accuracy@5 = 81.78 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:08:19]*** start epoch=050/600 Time Left: [04:59:59], LR=[0.098296 ~ 0.098296], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=50, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.916518274408217, FLOP=40.81
[Search] : epoch=050/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:08:19] [epoch=050/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.026 (1.026)  Prec@1 65.62 (65.62) Prec@5 96.88 (96.88) Acls-loss 1.019 (1.019) FLOP-Loss -2.465 (-2.465) Arch-Loss -3.912 (-3.912)
**TRAIN** [2020-01-29 06:08:44] [epoch=050/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.998 (0.980)  Prec@1 68.45 (65.96) Prec@5 97.02 (96.71) Acls-loss 1.031 (1.007) FLOP-Loss -2.467 (0.009) Arch-Loss -3.902 (1.025)
 **TRAIN** Prec@1 65.96 Prec@5 96.71 Error@1 34.04 Error@5 3.29 Base-Loss:0.980, Arch-Loss=1.025
***[2020-01-29 06:08:44]*** TRAIN [epoch=050/600] base-loss = 0.979930, arch-loss = 1.024667, accuracy-1 = 65.96, accuracy-5 = 96.71
[epoch=050/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 44, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.156416)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.370 0.260 0.370  ||  0.0071 -0.3480 0.0076  || discrepancy=0.00 || select=2/3
001/003-th : 0.393 0.201 0.407  ||  0.0018 -0.6699 0.0368  || discrepancy=0.01 || select=2/3
002/003-th : 0.341 0.221 0.438  ||  -0.1058 -0.5405 0.1431  || discrepancy=0.10 || select=2/3
-----------------------------------------------
000/019-th : 0.091 0.097 0.109 0.117 0.136 0.149 0.155 0.146  ||  -0.291 -0.223 -0.108 -0.035 0.116 0.203 0.241 0.183   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.037 -0.040 -0.019 -0.012 0.013 0.049 0.038 0.048   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.122 0.128 0.130 0.130 0.127 0.128  ||  -0.070 -0.041 -0.014 0.034 0.045 0.045 0.022 0.027    || dis=0.00 || select=4/8
003/019-th : 0.123 0.123 0.126 0.126 0.125 0.126 0.125 0.125  ||  -0.013 -0.013 0.005 0.010 0.002 0.011 0.000 -0.001    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.130 0.126 0.128 0.127  ||  -0.047 -0.018 -0.010 0.001 0.039 0.014 0.026 0.015    || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.122 0.127 0.128 0.127 0.128  ||  -0.028 -0.019 -0.006 -0.019 0.015 0.024 0.015 0.027   || dis=0.00 || select=7/8
006/019-th : 0.116 0.121 0.124 0.122 0.130 0.128 0.132 0.128  ||  -0.068 -0.028 -0.009 -0.022 0.039 0.026 0.054 0.026   || dis=0.00 || select=6/8
007/019-th : 0.110 0.108 0.109 0.118 0.130 0.137 0.142 0.146  ||  -0.127 -0.142 -0.137 -0.056 0.045 0.099 0.133 0.159   || dis=0.00 || select=7/8
008/019-th : 0.102 0.107 0.114 0.128 0.133 0.145 0.137 0.135  ||  -0.180 -0.138 -0.077 0.041 0.085 0.166 0.108 0.097    || dis=0.01 || select=5/8
009/019-th : 0.117 0.117 0.113 0.123 0.125 0.132 0.136 0.138  ||  -0.068 -0.065 -0.101 -0.015 -0.001 0.055 0.081 0.098  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.124 0.132 0.133 0.131 0.130  ||  -0.077 -0.054 -0.053 0.001 0.056 0.065 0.050 0.041    || dis=0.00 || select=5/8
011/019-th : 0.114 0.113 0.113 0.119 0.129 0.135 0.139 0.139  ||  -0.087 -0.102 -0.099 -0.049 0.037 0.082 0.106 0.106   || dis=0.00 || select=6/8
012/019-th : 0.122 0.121 0.120 0.125 0.129 0.127 0.128 0.129  ||  -0.021 -0.031 -0.039 0.004 0.030 0.014 0.025 0.033    || dis=0.00 || select=7/8
013/019-th : 0.090 0.099 0.103 0.117 0.127 0.145 0.158 0.160  ||  -0.306 -0.218 -0.178 -0.048 0.039 0.170 0.256 0.269   || dis=0.00 || select=7/8
014/019-th : 0.088 0.091 0.107 0.127 0.143 0.145 0.154 0.144  ||  -0.319 -0.276 -0.115 0.056 0.170 0.190 0.250 0.180    || dis=0.01 || select=6/8
015/019-th : 0.104 0.101 0.106 0.110 0.129 0.147 0.154 0.149  ||  -0.179 -0.200 -0.156 -0.121 0.040 0.169 0.220 0.182   || dis=0.01 || select=6/8
016/019-th : 0.088 0.100 0.110 0.125 0.147 0.144 0.144 0.141  ||  -0.322 -0.189 -0.090 0.029 0.198 0.178 0.176 0.155    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.116 0.119 0.124 0.131 0.136 0.138  ||  -0.045 -0.072 -0.080 -0.049 -0.011 0.043 0.084 0.099  || dis=0.00 || select=7/8
018/019-th : 0.091 0.103 0.114 0.118 0.133 0.136 0.143 0.162  ||  -0.298 -0.181 -0.074 -0.042 0.079 0.104 0.153 0.274   || dis=0.02 || select=7/8
[epoch=050/600] FLOP : 31.16 MB, ratio : 0.7634, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:08:45] [epoch=050/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.215 (2.215)  Prec@1 33.20 (33.20) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:08:51] [epoch=050/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.075 (2.351)  Prec@1 40.48 (35.02) Prec@5 86.31 (82.81) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.02 Prec@5 82.81 Error@1 64.98 Error@5 17.19 Loss:2.351
***[2020-01-29 06:08:51]*** VALID [epoch=050/600] loss = 2.351496, accuracy@1 = 35.02, accuracy@5 = 82.81 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:08:51]*** start epoch=051/600 Time Left: [04:59:19], LR=[0.098228 ~ 0.098228], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=51, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.913165675221605, FLOP=40.81
[Search] : epoch=051/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:08:51] [epoch=051/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.933 (0.933)  Prec@1 66.80 (66.80) Prec@5 96.88 (96.88) Acls-loss 0.971 (0.971) FLOP-Loss 2.467 (2.467) Arch-Loss 5.905 (5.905)
**TRAIN** [2020-01-29 06:09:16] [epoch=051/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.096 (0.976)  Prec@1 57.14 (65.92) Prec@5 95.83 (96.99) Acls-loss 1.104 (1.007) FLOP-Loss 2.469 (0.042) Arch-Loss 6.041 (1.091)
 **TRAIN** Prec@1 65.92 Prec@5 96.99 Error@1 34.08 Error@5 3.01 Base-Loss:0.976, Arch-Loss=1.091
***[2020-01-29 06:09:16]*** TRAIN [epoch=051/600] base-loss = 0.975604, arch-loss = 1.091177, accuracy-1 = 65.92, accuracy-5 = 96.99
[epoch=051/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 44, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.879296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.370 0.260 0.370  ||  0.0077 -0.3429 0.0072  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.204 0.405  ||  0.0018 -0.6477 0.0370  || discrepancy=0.01 || select=2/3
002/003-th : 0.341 0.221 0.439  ||  -0.1077 -0.5407 0.1453  || discrepancy=0.10 || select=2/3
-----------------------------------------------
000/019-th : 0.090 0.097 0.109 0.118 0.136 0.149 0.154 0.146  ||  -0.297 -0.220 -0.108 -0.031 0.110 0.204 0.240 0.185   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.037 -0.040 -0.019 -0.009 0.010 0.049 0.038 0.048   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.127  ||  -0.070 -0.040 -0.013 0.034 0.046 0.045 0.022 0.026    || dis=0.00 || select=4/8
003/019-th : 0.123 0.123 0.125 0.126 0.125 0.126 0.125 0.125  ||  -0.012 -0.013 0.004 0.009 0.003 0.011 -0.001 -0.001   || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.124 0.130 0.127 0.128 0.126  ||  -0.048 -0.017 -0.013 -0.002 0.043 0.015 0.026 0.015   || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.122 0.126 0.128 0.127 0.128  ||  -0.029 -0.020 -0.010 -0.021 0.012 0.025 0.017 0.028   || dis=0.00 || select=7/8
006/019-th : 0.116 0.121 0.124 0.122 0.129 0.128 0.132 0.128  ||  -0.068 -0.028 -0.008 -0.022 0.036 0.025 0.054 0.027   || dis=0.00 || select=6/8
007/019-th : 0.109 0.107 0.108 0.118 0.132 0.137 0.142 0.146  ||  -0.128 -0.146 -0.145 -0.050 0.061 0.099 0.135 0.161   || dis=0.00 || select=7/8
008/019-th : 0.102 0.106 0.113 0.128 0.134 0.145 0.137 0.135  ||  -0.183 -0.142 -0.078 0.046 0.090 0.167 0.111 0.098    || dis=0.01 || select=5/8
009/019-th : 0.117 0.117 0.113 0.122 0.125 0.132 0.136 0.138  ||  -0.069 -0.068 -0.099 -0.021 -0.000 0.057 0.082 0.100  || dis=0.00 || select=7/8
010/019-th : 0.115 0.118 0.118 0.125 0.131 0.132 0.131 0.130  ||  -0.077 -0.056 -0.054 0.001 0.054 0.063 0.052 0.043    || dis=0.00 || select=5/8
011/019-th : 0.114 0.113 0.113 0.119 0.128 0.135 0.139 0.139  ||  -0.088 -0.102 -0.097 -0.046 0.029 0.080 0.107 0.107   || dis=0.00 || select=6/8
012/019-th : 0.122 0.121 0.120 0.125 0.128 0.127 0.128 0.129  ||  -0.021 -0.031 -0.040 -0.002 0.026 0.017 0.025 0.033   || dis=0.00 || select=7/8
013/019-th : 0.090 0.098 0.102 0.117 0.127 0.145 0.160 0.161  ||  -0.306 -0.224 -0.183 -0.051 0.034 0.168 0.263 0.273   || dis=0.00 || select=7/8
014/019-th : 0.087 0.092 0.107 0.127 0.141 0.146 0.155 0.145  ||  -0.322 -0.273 -0.122 0.051 0.160 0.191 0.254 0.182    || dis=0.01 || select=6/8
015/019-th : 0.103 0.101 0.106 0.110 0.128 0.148 0.155 0.149  ||  -0.182 -0.207 -0.158 -0.123 0.032 0.179 0.222 0.186   || dis=0.01 || select=6/8
016/019-th : 0.087 0.100 0.110 0.124 0.147 0.145 0.144 0.142  ||  -0.325 -0.191 -0.092 0.025 0.197 0.182 0.177 0.158    || dis=0.00 || select=4/8
017/019-th : 0.120 0.117 0.116 0.119 0.123 0.131 0.136 0.138  ||  -0.046 -0.071 -0.079 -0.053 -0.015 0.045 0.084 0.100  || dis=0.00 || select=7/8
018/019-th : 0.091 0.102 0.114 0.119 0.133 0.137 0.143 0.162  ||  -0.303 -0.183 -0.075 -0.034 0.079 0.107 0.155 0.275   || dis=0.02 || select=7/8
[epoch=051/600] FLOP : 24.88 MB, ratio : 0.6096, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:09:17] [epoch=051/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.786 (2.786)  Prec@1 33.59 (33.59) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:09:23] [epoch=051/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.669 (2.352)  Prec@1 52.38 (35.14) Prec@5 92.86 (82.12) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.14 Prec@5 82.12 Error@1 64.86 Error@5 17.88 Loss:2.352
***[2020-01-29 06:09:23]*** VALID [epoch=051/600] loss = 2.352266, accuracy@1 = 35.14, accuracy@5 = 82.12 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:09:23]*** start epoch=052/600 Time Left: [04:58:39], LR=[0.098158 ~ 0.098158], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=52, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.909748288654263, FLOP=40.81
[Search] : epoch=052/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:09:24] [epoch=052/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.990 (0.990)  Prec@1 66.80 (66.80) Prec@5 96.48 (96.48) Acls-loss 1.031 (1.031) FLOP-Loss -2.468 (-2.468) Arch-Loss -3.906 (-3.906)
**TRAIN** [2020-01-29 06:09:48] [epoch=052/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.037 (0.980)  Prec@1 61.90 (65.93) Prec@5 97.02 (96.83) Acls-loss 0.925 (0.993) FLOP-Loss 2.471 (-0.008) Arch-Loss 5.866 (0.976)
 **TRAIN** Prec@1 65.93 Prec@5 96.83 Error@1 34.07 Error@5 3.17 Base-Loss:0.980, Arch-Loss=0.976
***[2020-01-29 06:09:48]*** TRAIN [epoch=052/600] base-loss = 0.979862, arch-loss = 0.976232, accuracy-1 = 65.93, accuracy-5 = 96.83
[epoch=052/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.421376)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.370 0.259 0.370  ||  0.0077 -0.3493 0.0076  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.205 0.405  ||  0.0008 -0.6394 0.0383  || discrepancy=0.02 || select=2/3
002/003-th : 0.339 0.222 0.439  ||  -0.1106 -0.5354 0.1482  || discrepancy=0.10 || select=2/3
-----------------------------------------------
000/019-th : 0.090 0.097 0.109 0.118 0.135 0.150 0.154 0.147  ||  -0.302 -0.223 -0.110 -0.032 0.109 0.212 0.239 0.190   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.037 -0.042 -0.020 -0.011 0.011 0.051 0.039 0.048   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.122 0.128 0.130 0.130 0.127 0.127  ||  -0.070 -0.042 -0.014 0.034 0.047 0.045 0.023 0.027    || dis=0.00 || select=4/8
003/019-th : 0.123 0.123 0.125 0.125 0.126 0.127 0.125 0.125  ||  -0.013 -0.013 0.003 0.002 0.005 0.012 0.001 -0.000    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.124 0.130 0.127 0.128 0.127  ||  -0.049 -0.018 -0.012 -0.002 0.040 0.017 0.027 0.015   || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.122 0.127 0.128 0.127 0.129  ||  -0.031 -0.020 -0.008 -0.024 0.014 0.025 0.019 0.029   || dis=0.00 || select=7/8
006/019-th : 0.116 0.121 0.124 0.122 0.129 0.128 0.132 0.128  ||  -0.069 -0.030 -0.009 -0.024 0.037 0.029 0.055 0.028   || dis=0.00 || select=6/8
007/019-th : 0.109 0.107 0.107 0.119 0.132 0.138 0.142 0.146  ||  -0.132 -0.147 -0.153 -0.046 0.065 0.104 0.137 0.163   || dis=0.00 || select=7/8
008/019-th : 0.101 0.106 0.112 0.127 0.136 0.145 0.137 0.135  ||  -0.187 -0.144 -0.085 0.041 0.105 0.172 0.114 0.100    || dis=0.01 || select=5/8
009/019-th : 0.116 0.117 0.113 0.123 0.124 0.133 0.136 0.138  ||  -0.071 -0.070 -0.103 -0.015 -0.005 0.060 0.084 0.102  || dis=0.00 || select=7/8
010/019-th : 0.115 0.117 0.117 0.125 0.131 0.133 0.132 0.130  ||  -0.081 -0.059 -0.057 0.006 0.050 0.063 0.057 0.045    || dis=0.00 || select=5/8
011/019-th : 0.114 0.112 0.114 0.117 0.129 0.135 0.139 0.139  ||  -0.090 -0.105 -0.090 -0.064 0.034 0.079 0.110 0.109   || dis=0.00 || select=6/8
012/019-th : 0.122 0.121 0.120 0.124 0.128 0.127 0.128 0.129  ||  -0.023 -0.032 -0.039 -0.003 0.027 0.016 0.028 0.034   || dis=0.00 || select=7/8
013/019-th : 0.090 0.098 0.101 0.116 0.127 0.145 0.160 0.162  ||  -0.307 -0.227 -0.191 -0.059 0.036 0.166 0.268 0.279   || dis=0.00 || select=7/8
014/019-th : 0.087 0.091 0.106 0.127 0.142 0.147 0.156 0.145  ||  -0.327 -0.275 -0.132 0.050 0.162 0.200 0.257 0.185    || dis=0.01 || select=6/8
015/019-th : 0.103 0.100 0.106 0.109 0.127 0.150 0.156 0.149  ||  -0.189 -0.211 -0.158 -0.127 0.028 0.188 0.229 0.188   || dis=0.01 || select=6/8
016/019-th : 0.087 0.100 0.110 0.125 0.144 0.146 0.145 0.143  ||  -0.330 -0.194 -0.095 0.027 0.174 0.189 0.179 0.162    || dis=0.00 || select=5/8
017/019-th : 0.120 0.117 0.116 0.119 0.122 0.132 0.137 0.139  ||  -0.046 -0.072 -0.081 -0.053 -0.030 0.049 0.086 0.101  || dis=0.00 || select=7/8
018/019-th : 0.090 0.102 0.114 0.119 0.134 0.136 0.143 0.162  ||  -0.305 -0.188 -0.076 -0.026 0.092 0.105 0.152 0.278   || dis=0.02 || select=7/8
[epoch=052/600] FLOP : 25.42 MB, ratio : 0.6229, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:09:49] [epoch=052/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.171 (2.171)  Prec@1 48.05 (48.05) Prec@5 94.53 (94.53) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:09:55] [epoch=052/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.056 (2.397)  Prec@1 22.62 (35.06) Prec@5 69.64 (83.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.06 Prec@5 83.04 Error@1 64.94 Error@5 16.96 Loss:2.397
***[2020-01-29 06:09:55]*** VALID [epoch=052/600] loss = 2.397316, accuracy@1 = 35.06, accuracy@5 = 83.04 | Best-Valid-Acc@1=35.75, Error@1=64.25
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:09:55]*** start epoch=053/600 Time Left: [04:57:59], LR=[0.098087 ~ 0.098087], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=53, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.906266208395568, FLOP=40.81
[Search] : epoch=053/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:09:55] [epoch=053/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.813 (0.813)  Prec@1 71.48 (71.48) Prec@5 98.05 (98.05) Acls-loss 1.006 (1.006) FLOP-Loss -2.470 (-2.470) Arch-Loss -3.935 (-3.935)
**TRAIN** [2020-01-29 06:10:21] [epoch=053/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.977 (0.970)  Prec@1 64.29 (66.02) Prec@5 96.43 (96.94) Acls-loss 1.175 (0.991) FLOP-Loss 0.000 (0.026) Arch-Loss 1.175 (1.042)
 **TRAIN** Prec@1 66.02 Prec@5 96.94 Error@1 33.98 Error@5 3.06 Base-Loss:0.970, Arch-Loss=1.042
***[2020-01-29 06:10:21]*** TRAIN [epoch=053/600] base-loss = 0.970271, arch-loss = 1.042434, accuracy-1 = 66.02, accuracy-5 = 96.94
[epoch=053/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 12, 11, 16, 14, 32, 25, 32, 25, 32, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.03008)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.371 0.258 0.371  ||  0.0085 -0.3549 0.0072  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.206 0.404  ||  0.0014 -0.6382 0.0381  || discrepancy=0.01 || select=2/3
002/003-th : 0.338 0.222 0.439  ||  -0.1118 -0.5322 0.1496  || discrepancy=0.10 || select=2/3
-----------------------------------------------
000/019-th : 0.090 0.097 0.108 0.118 0.136 0.151 0.154 0.147  ||  -0.304 -0.226 -0.120 -0.026 0.111 0.222 0.240 0.191   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.040 -0.019 -0.010 0.010 0.048 0.038 0.048   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.127  ||  -0.069 -0.041 -0.013 0.033 0.045 0.046 0.022 0.026    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.125 0.125 0.126 0.125 0.125  ||  -0.012 -0.012 0.005 0.002 0.003 0.011 0.001 -0.001    || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.124 0.130 0.127 0.128 0.126  ||  -0.048 -0.017 -0.012 -0.002 0.041 0.016 0.028 0.014   || dis=0.00 || select=4/8
005/019-th : 0.121 0.122 0.124 0.123 0.128 0.128 0.127 0.128  ||  -0.033 -0.022 -0.009 -0.018 0.022 0.023 0.019 0.029   || dis=0.00 || select=7/8
006/019-th : 0.116 0.121 0.124 0.122 0.130 0.128 0.132 0.128  ||  -0.070 -0.030 -0.008 -0.021 0.040 0.029 0.055 0.028   || dis=0.00 || select=6/8
007/019-th : 0.109 0.107 0.107 0.118 0.133 0.138 0.143 0.146  ||  -0.132 -0.149 -0.152 -0.049 0.067 0.104 0.138 0.165   || dis=0.00 || select=7/8
008/019-th : 0.101 0.105 0.112 0.126 0.139 0.145 0.137 0.135  ||  -0.193 -0.147 -0.084 0.033 0.128 0.170 0.118 0.103    || dis=0.01 || select=5/8
009/019-th : 0.116 0.117 0.113 0.122 0.125 0.133 0.136 0.138  ||  -0.071 -0.070 -0.103 -0.023 -0.002 0.061 0.085 0.102  || dis=0.00 || select=7/8
010/019-th : 0.115 0.117 0.117 0.126 0.132 0.132 0.131 0.130  ||  -0.081 -0.060 -0.060 0.014 0.058 0.062 0.056 0.045    || dis=0.00 || select=5/8
011/019-th : 0.114 0.112 0.114 0.117 0.129 0.135 0.139 0.139  ||  -0.089 -0.108 -0.088 -0.062 0.034 0.081 0.108 0.110   || dis=0.00 || select=7/8
012/019-th : 0.122 0.121 0.120 0.125 0.128 0.127 0.128 0.129  ||  -0.024 -0.032 -0.038 0.002 0.023 0.017 0.029 0.033    || dis=0.00 || select=7/8
013/019-th : 0.090 0.098 0.101 0.116 0.128 0.145 0.160 0.162  ||  -0.312 -0.227 -0.193 -0.057 0.046 0.166 0.269 0.281   || dis=0.00 || select=7/8
014/019-th : 0.087 0.091 0.105 0.127 0.142 0.147 0.156 0.145  ||  -0.329 -0.278 -0.135 0.050 0.166 0.200 0.260 0.188    || dis=0.01 || select=6/8
015/019-th : 0.102 0.100 0.105 0.109 0.128 0.150 0.156 0.150  ||  -0.193 -0.216 -0.165 -0.124 0.033 0.190 0.232 0.194   || dis=0.01 || select=6/8
016/019-th : 0.087 0.099 0.110 0.124 0.145 0.147 0.145 0.142  ||  -0.332 -0.197 -0.093 0.026 0.179 0.192 0.180 0.161    || dis=0.00 || select=5/8
017/019-th : 0.120 0.117 0.116 0.119 0.121 0.131 0.137 0.139  ||  -0.045 -0.072 -0.077 -0.055 -0.035 0.045 0.086 0.101  || dis=0.00 || select=7/8
018/019-th : 0.090 0.102 0.114 0.119 0.133 0.136 0.143 0.162  ||  -0.306 -0.188 -0.073 -0.028 0.081 0.104 0.154 0.279   || dis=0.02 || select=7/8
[epoch=053/600] FLOP : 27.03 MB, ratio : 0.6623, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:10:21] [epoch=053/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.763 (1.763)  Prec@1 45.31 (45.31) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:10:27] [epoch=053/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.003 (2.280)  Prec@1 38.10 (36.41) Prec@5 90.48 (82.92) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.41 Prec@5 82.92 Error@1 63.59 Error@5 17.08 Loss:2.280
***[2020-01-29 06:10:27]*** VALID [epoch=053/600] loss = 2.280387, accuracy@1 = 36.41, accuracy@5 = 82.92 | Best-Valid-Acc@1=35.75, Error@1=64.25
Currently, the best validation accuracy found at 053-epoch :: acc@1=36.41, acc@5=82.92, error@1=63.59, error@5=17.08, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:10:27]*** start epoch=054/600 Time Left: [04:57:23], LR=[0.098015 ~ 0.098015], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=54, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.90271952990851, FLOP=40.81
[Search] : epoch=054/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:10:28] [epoch=054/600][000/098] Time 0.77 (0.77) Data 0.35 (0.35) Base-Loss 0.921 (0.921)  Prec@1 69.53 (69.53) Prec@5 97.27 (97.27) Acls-loss 1.142 (1.142) FLOP-Loss 0.000 (0.000) Arch-Loss 1.142 (1.142)
**TRAIN** [2020-01-29 06:10:53] [epoch=054/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 1.018 (0.970)  Prec@1 64.88 (66.16) Prec@5 95.24 (96.98) Acls-loss 1.016 (1.000) FLOP-Loss 2.473 (0.017) Arch-Loss 5.961 (1.033)
 **TRAIN** Prec@1 66.16 Prec@5 96.98 Error@1 33.84 Error@5 3.02 Base-Loss:0.970, Arch-Loss=1.033
***[2020-01-29 06:10:53]*** TRAIN [epoch=054/600] base-loss = 0.970251, arch-loss = 1.033399, accuracy-1 = 66.16, accuracy-5 = 96.98
[epoch=054/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 11, 16, 14, 32, 25, 32, 25, 32, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.946688)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.373 0.254 0.373  ||  0.0085 -0.3748 0.0078  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.204 0.405  ||  0.0008 -0.6458 0.0393  || discrepancy=0.02 || select=2/3
002/003-th : 0.337 0.222 0.440  ||  -0.1143 -0.5310 0.1523  || discrepancy=0.10 || select=2/3
-----------------------------------------------
000/019-th : 0.089 0.096 0.108 0.118 0.135 0.152 0.154 0.147  ||  -0.305 -0.228 -0.116 -0.026 0.110 0.224 0.240 0.191   || dis=0.00 || select=6/8
001/019-th : 0.120 0.120 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.039 -0.017 -0.011 0.013 0.048 0.037 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.129 0.130 0.130 0.127 0.127  ||  -0.070 -0.042 -0.013 0.036 0.047 0.046 0.022 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.126 0.125 0.125  ||  -0.012 -0.011 0.005 0.003 0.002 0.010 0.001 -0.002    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.130 0.127 0.128 0.126  ||  -0.048 -0.018 -0.013 -0.000 0.039 0.016 0.029 0.013   || dis=0.00 || select=4/8
005/019-th : 0.120 0.122 0.124 0.123 0.128 0.128 0.127 0.129  ||  -0.037 -0.024 -0.008 -0.013 0.027 0.023 0.021 0.031   || dis=0.00 || select=7/8
006/019-th : 0.116 0.121 0.124 0.122 0.130 0.128 0.132 0.128  ||  -0.071 -0.032 -0.008 -0.022 0.044 0.029 0.056 0.028   || dis=0.00 || select=6/8
007/019-th : 0.109 0.107 0.107 0.117 0.132 0.138 0.143 0.147  ||  -0.134 -0.151 -0.151 -0.056 0.064 0.105 0.140 0.167   || dis=0.00 || select=7/8
008/019-th : 0.100 0.105 0.112 0.127 0.139 0.145 0.137 0.135  ||  -0.197 -0.146 -0.087 0.038 0.135 0.171 0.119 0.104    || dis=0.01 || select=5/8
009/019-th : 0.116 0.116 0.113 0.122 0.124 0.133 0.136 0.139  ||  -0.073 -0.071 -0.103 -0.024 -0.009 0.062 0.087 0.105  || dis=0.00 || select=7/8
010/019-th : 0.114 0.117 0.117 0.127 0.132 0.132 0.131 0.130  ||  -0.083 -0.060 -0.063 0.021 0.057 0.064 0.057 0.046    || dis=0.00 || select=5/8
011/019-th : 0.114 0.112 0.114 0.117 0.129 0.135 0.139 0.140  ||  -0.088 -0.111 -0.090 -0.062 0.037 0.082 0.107 0.112   || dis=0.00 || select=7/8
012/019-th : 0.122 0.120 0.119 0.126 0.128 0.127 0.129 0.129  ||  -0.025 -0.034 -0.043 0.007 0.028 0.020 0.030 0.034    || dis=0.00 || select=7/8
013/019-th : 0.090 0.097 0.101 0.115 0.126 0.145 0.162 0.164  ||  -0.314 -0.233 -0.195 -0.067 0.022 0.164 0.276 0.289   || dis=0.00 || select=7/8
014/019-th : 0.086 0.091 0.105 0.127 0.143 0.147 0.156 0.146  ||  -0.334 -0.282 -0.137 0.056 0.171 0.200 0.262 0.191    || dis=0.01 || select=6/8
015/019-th : 0.102 0.100 0.105 0.109 0.126 0.150 0.157 0.151  ||  -0.199 -0.218 -0.169 -0.123 0.020 0.194 0.239 0.198   || dis=0.01 || select=6/8
016/019-th : 0.086 0.099 0.110 0.124 0.146 0.147 0.145 0.143  ||  -0.338 -0.203 -0.093 0.023 0.186 0.198 0.184 0.164    || dis=0.00 || select=5/8
017/019-th : 0.120 0.117 0.117 0.119 0.121 0.132 0.137 0.139  ||  -0.046 -0.075 -0.073 -0.055 -0.041 0.048 0.086 0.102  || dis=0.00 || select=7/8
018/019-th : 0.090 0.102 0.114 0.119 0.132 0.137 0.144 0.163  ||  -0.309 -0.187 -0.075 -0.032 0.068 0.108 0.156 0.281   || dis=0.02 || select=7/8
[epoch=054/600] FLOP : 25.95 MB, ratio : 0.6357, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:10:53] [epoch=054/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.654 (2.654)  Prec@1 33.20 (33.20) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:10:59] [epoch=054/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.355 (2.401)  Prec@1 29.76 (34.24) Prec@5 78.57 (81.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.24 Prec@5 81.72 Error@1 65.76 Error@5 18.28 Loss:2.401
***[2020-01-29 06:11:00]*** VALID [epoch=054/600] loss = 2.401323, accuracy@1 = 34.24, accuracy@5 = 81.72 | Best-Valid-Acc@1=36.41, Error@1=63.59
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:11:00]*** start epoch=055/600 Time Left: [04:56:47], LR=[0.097941 ~ 0.097941], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=55, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.899108350427073, FLOP=40.81
[Search] : epoch=055/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:11:00] [epoch=055/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.869 (0.869)  Prec@1 69.92 (69.92) Prec@5 98.44 (98.44) Acls-loss 0.949 (0.949) FLOP-Loss -2.472 (-2.472) Arch-Loss -3.996 (-3.996)
**TRAIN** [2020-01-29 06:11:26] [epoch=055/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.030 (0.972)  Prec@1 61.90 (66.62) Prec@5 98.21 (96.80) Acls-loss 0.910 (0.984) FLOP-Loss -2.473 (0.009) Arch-Loss -4.037 (1.002)
 **TRAIN** Prec@1 66.62 Prec@5 96.80 Error@1 33.38 Error@5 3.20 Base-Loss:0.972, Arch-Loss=1.002
***[2020-01-29 06:11:26]*** TRAIN [epoch=055/600] base-loss = 0.971555, arch-loss = 1.002172, accuracy-1 = 66.62, accuracy-5 = 96.80
[epoch=055/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 12, 11, 16, 14, 32, 25, 32, 25, 32, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.071616)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.373 0.253 0.373  ||  0.0085 -0.3795 0.0081  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.204 0.406  ||  -0.0001 -0.6464 0.0407  || discrepancy=0.02 || select=2/3
002/003-th : 0.336 0.223 0.440  ||  -0.1159 -0.5253 0.1539  || discrepancy=0.10 || select=2/3
-----------------------------------------------
000/019-th : 0.089 0.097 0.109 0.117 0.135 0.152 0.155 0.147  ||  -0.311 -0.227 -0.110 -0.038 0.110 0.224 0.243 0.193   || dis=0.00 || select=6/8
001/019-th : 0.120 0.120 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.038 -0.039 -0.019 -0.013 0.014 0.049 0.037 0.048   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.129 0.130 0.130 0.127 0.128  ||  -0.071 -0.043 -0.013 0.035 0.043 0.047 0.022 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.127 0.125 0.125  ||  -0.012 -0.011 0.002 0.000 0.002 0.011 0.002 -0.002    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.130 0.127 0.128 0.126  ||  -0.048 -0.018 -0.015 -0.001 0.039 0.016 0.030 0.014   || dis=0.00 || select=4/8
005/019-th : 0.120 0.122 0.124 0.123 0.128 0.128 0.127 0.129  ||  -0.038 -0.025 -0.009 -0.013 0.031 0.024 0.021 0.033   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.123 0.122 0.130 0.129 0.132 0.128  ||  -0.072 -0.034 -0.008 -0.023 0.045 0.032 0.057 0.029   || dis=0.00 || select=6/8
007/019-th : 0.109 0.106 0.107 0.117 0.131 0.139 0.143 0.148  ||  -0.134 -0.156 -0.148 -0.062 0.053 0.109 0.141 0.170   || dis=0.01 || select=7/8
008/019-th : 0.100 0.105 0.111 0.127 0.140 0.144 0.137 0.135  ||  -0.201 -0.144 -0.091 0.042 0.138 0.168 0.121 0.105    || dis=0.00 || select=5/8
009/019-th : 0.116 0.116 0.113 0.121 0.125 0.133 0.136 0.139  ||  -0.075 -0.071 -0.105 -0.029 0.001 0.062 0.087 0.107   || dis=0.00 || select=7/8
010/019-th : 0.114 0.117 0.117 0.127 0.130 0.133 0.132 0.130  ||  -0.084 -0.063 -0.062 0.025 0.046 0.067 0.059 0.047    || dis=0.00 || select=5/8
011/019-th : 0.114 0.112 0.114 0.116 0.130 0.135 0.140 0.140  ||  -0.089 -0.112 -0.095 -0.071 0.037 0.082 0.111 0.114   || dis=0.00 || select=7/8
012/019-th : 0.121 0.121 0.119 0.126 0.129 0.127 0.129 0.129  ||  -0.027 -0.034 -0.046 0.007 0.031 0.018 0.033 0.036    || dis=0.00 || select=7/8
013/019-th : 0.090 0.097 0.101 0.114 0.126 0.145 0.162 0.165  ||  -0.314 -0.238 -0.197 -0.076 0.024 0.163 0.278 0.295   || dis=0.00 || select=7/8
014/019-th : 0.086 0.090 0.105 0.127 0.143 0.148 0.157 0.146  ||  -0.337 -0.290 -0.138 0.052 0.172 0.206 0.267 0.193    || dis=0.01 || select=6/8
015/019-th : 0.101 0.098 0.104 0.110 0.129 0.150 0.157 0.151  ||  -0.203 -0.229 -0.171 -0.120 0.041 0.196 0.243 0.202   || dis=0.01 || select=6/8
016/019-th : 0.086 0.099 0.110 0.123 0.146 0.148 0.146 0.143  ||  -0.344 -0.203 -0.097 0.021 0.187 0.202 0.187 0.167    || dis=0.00 || select=5/8
017/019-th : 0.120 0.116 0.117 0.119 0.121 0.131 0.137 0.139  ||  -0.046 -0.076 -0.073 -0.053 -0.038 0.046 0.085 0.104  || dis=0.00 || select=7/8
018/019-th : 0.090 0.102 0.115 0.120 0.130 0.137 0.144 0.162  ||  -0.311 -0.185 -0.067 -0.024 0.056 0.106 0.155 0.279   || dis=0.02 || select=7/8
[epoch=055/600] FLOP : 26.07 MB, ratio : 0.6388, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:11:26] [epoch=055/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.021 (2.021)  Prec@1 41.41 (41.41) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:11:32] [epoch=055/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.922 (2.314)  Prec@1 32.74 (35.56) Prec@5 77.38 (81.97) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.56 Prec@5 81.97 Error@1 64.44 Error@5 18.03 Loss:2.314
***[2020-01-29 06:11:32]*** VALID [epoch=055/600] loss = 2.313774, accuracy@1 = 35.56, accuracy@5 = 81.97 | Best-Valid-Acc@1=36.41, Error@1=63.59
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:11:32]*** start epoch=056/600 Time Left: [04:56:16], LR=[0.097866 ~ 0.097866], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=56, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.895432768953564, FLOP=40.81
[Search] : epoch=056/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:11:33] [epoch=056/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 1.037 (1.037)  Prec@1 61.33 (61.33) Prec@5 96.88 (96.88) Acls-loss 1.014 (1.014) FLOP-Loss -2.474 (-2.474) Arch-Loss -3.934 (-3.934)
**TRAIN** [2020-01-29 06:11:58] [epoch=056/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.008 (0.956)  Prec@1 65.48 (66.62) Prec@5 97.02 (96.99) Acls-loss 1.156 (0.991) FLOP-Loss 2.475 (0.042) Arch-Loss 6.106 (1.076)
 **TRAIN** Prec@1 66.62 Prec@5 96.99 Error@1 33.38 Error@5 3.01 Base-Loss:0.956, Arch-Loss=1.076
***[2020-01-29 06:11:58]*** TRAIN [epoch=056/600] base-loss = 0.955626, arch-loss = 1.075821, accuracy-1 = 66.62, accuracy-5 = 96.99
[epoch=056/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.546304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.374 0.253 0.374  ||  0.0088 -0.3827 0.0082  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.205 0.406  ||  0.0000 -0.6420 0.0410  || discrepancy=0.02 || select=2/3
002/003-th : 0.336 0.222 0.442  ||  -0.1169 -0.5331 0.1556  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.089 0.097 0.109 0.116 0.135 0.152 0.155 0.148  ||  -0.313 -0.228 -0.109 -0.046 0.102 0.226 0.243 0.197   || dis=0.00 || select=6/8
001/019-th : 0.120 0.120 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.037 -0.039 -0.021 -0.010 0.012 0.050 0.037 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.129 0.130 0.130 0.127 0.127  ||  -0.071 -0.042 -0.013 0.036 0.043 0.047 0.022 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.126 0.125 0.125  ||  -0.011 -0.011 0.003 -0.000 0.000 0.010 0.002 -0.002   || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.129 0.127 0.128 0.126  ||  -0.048 -0.018 -0.014 0.000 0.034 0.017 0.029 0.014    || dis=0.00 || select=4/8
005/019-th : 0.120 0.121 0.124 0.123 0.128 0.127 0.127 0.129  ||  -0.037 -0.026 -0.006 -0.015 0.029 0.021 0.021 0.032   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.123 0.122 0.130 0.128 0.132 0.128  ||  -0.072 -0.035 -0.010 -0.019 0.040 0.031 0.058 0.030   || dis=0.00 || select=6/8
007/019-th : 0.109 0.106 0.107 0.116 0.131 0.139 0.144 0.148  ||  -0.134 -0.157 -0.151 -0.071 0.049 0.106 0.142 0.174   || dis=0.00 || select=7/8
008/019-th : 0.099 0.105 0.111 0.128 0.140 0.144 0.137 0.135  ||  -0.206 -0.148 -0.095 0.053 0.144 0.172 0.122 0.108    || dis=0.00 || select=5/8
009/019-th : 0.116 0.116 0.112 0.122 0.125 0.133 0.137 0.139  ||  -0.075 -0.072 -0.107 -0.029 0.001 0.060 0.088 0.108   || dis=0.00 || select=7/8
010/019-th : 0.114 0.117 0.116 0.126 0.131 0.134 0.132 0.130  ||  -0.086 -0.063 -0.064 0.018 0.052 0.073 0.060 0.046    || dis=0.00 || select=5/8
011/019-th : 0.114 0.112 0.113 0.116 0.130 0.135 0.140 0.140  ||  -0.091 -0.111 -0.097 -0.072 0.043 0.083 0.114 0.114   || dis=0.00 || select=6/8
012/019-th : 0.121 0.120 0.119 0.126 0.128 0.127 0.129 0.129  ||  -0.028 -0.034 -0.045 0.013 0.028 0.017 0.034 0.035    || dis=0.00 || select=7/8
013/019-th : 0.090 0.096 0.100 0.113 0.127 0.145 0.163 0.165  ||  -0.314 -0.245 -0.201 -0.080 0.037 0.168 0.280 0.297   || dis=0.00 || select=7/8
014/019-th : 0.086 0.090 0.104 0.127 0.141 0.149 0.157 0.146  ||  -0.340 -0.292 -0.142 0.055 0.162 0.211 0.267 0.196    || dis=0.01 || select=6/8
015/019-th : 0.101 0.098 0.104 0.111 0.127 0.150 0.158 0.152  ||  -0.205 -0.236 -0.171 -0.104 0.026 0.191 0.246 0.207   || dis=0.01 || select=6/8
016/019-th : 0.085 0.098 0.110 0.124 0.145 0.149 0.146 0.143  ||  -0.351 -0.205 -0.095 0.022 0.178 0.207 0.191 0.167    || dis=0.00 || select=5/8
017/019-th : 0.120 0.116 0.116 0.119 0.123 0.131 0.136 0.139  ||  -0.047 -0.076 -0.074 -0.054 -0.019 0.048 0.084 0.104  || dis=0.00 || select=7/8
018/019-th : 0.089 0.102 0.114 0.119 0.131 0.137 0.144 0.163  ||  -0.318 -0.186 -0.072 -0.028 0.063 0.110 0.157 0.283   || dis=0.02 || select=7/8
[epoch=056/600] FLOP : 25.55 MB, ratio : 0.6259, Expected-ratio : 0.7000, Discrepancy : 0.008
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:11:58] [epoch=056/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.895 (1.895)  Prec@1 37.50 (37.50) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:12:04] [epoch=056/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.706 (2.099)  Prec@1 44.64 (37.55) Prec@5 84.52 (83.49) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.55 Prec@5 83.49 Error@1 62.45 Error@5 16.51 Loss:2.099
***[2020-01-29 06:12:04]*** VALID [epoch=056/600] loss = 2.098867, accuracy@1 = 37.55, accuracy@5 = 83.49 | Best-Valid-Acc@1=36.41, Error@1=63.59
Currently, the best validation accuracy found at 056-epoch :: acc@1=37.55, acc@5=83.49, error@1=62.45, error@5=16.51, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:12:04]*** start epoch=057/600 Time Left: [04:55:36], LR=[0.097790 ~ 0.097790], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=57, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.891692886255909, FLOP=40.81
[Search] : epoch=057/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:12:05] [epoch=057/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.007 (1.007)  Prec@1 66.02 (66.02) Prec@5 96.09 (96.09) Acls-loss 0.981 (0.981) FLOP-Loss -2.475 (-2.475) Arch-Loss -3.969 (-3.969)
**TRAIN** [2020-01-29 06:12:30] [epoch=057/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.250 (0.942)  Prec@1 60.71 (67.49) Prec@5 92.86 (97.12) Acls-loss 1.002 (0.960) FLOP-Loss -2.476 (0.009) Arch-Loss -3.949 (0.978)
 **TRAIN** Prec@1 67.49 Prec@5 97.12 Error@1 32.51 Error@5 2.88 Base-Loss:0.942, Arch-Loss=0.978
***[2020-01-29 06:12:30]*** TRAIN [epoch=057/600] base-loss = 0.941700, arch-loss = 0.978239, accuracy-1 = 67.49, accuracy-5 = 97.12
[epoch=057/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.546304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.374 0.252 0.374  ||  0.0090 -0.3885 0.0084  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.205 0.406  ||  -0.0007 -0.6439 0.0422  || discrepancy=0.02 || select=2/3
002/003-th : 0.336 0.222 0.442  ||  -0.1184 -0.5306 0.1573  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.089 0.097 0.108 0.116 0.135 0.153 0.155 0.148  ||  -0.316 -0.229 -0.113 -0.049 0.106 0.228 0.245 0.199   || dis=0.00 || select=6/8
001/019-th : 0.120 0.120 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.038 -0.039 -0.020 -0.013 0.013 0.049 0.038 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.129 0.129 0.130 0.127 0.128  ||  -0.071 -0.042 -0.011 0.035 0.041 0.046 0.022 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.126 0.125 0.125  ||  -0.011 -0.011 0.003 -0.001 0.001 0.009 0.002 -0.002   || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.125 0.129 0.127 0.129 0.126  ||  -0.047 -0.018 -0.015 0.000 0.033 0.016 0.030 0.014    || dis=0.00 || select=4/8
005/019-th : 0.120 0.122 0.124 0.123 0.128 0.127 0.127 0.129  ||  -0.039 -0.025 -0.006 -0.015 0.029 0.021 0.022 0.034   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.124 0.122 0.130 0.128 0.132 0.128  ||  -0.073 -0.036 -0.008 -0.021 0.043 0.027 0.059 0.031   || dis=0.00 || select=6/8
007/019-th : 0.109 0.106 0.107 0.117 0.130 0.139 0.143 0.149  ||  -0.134 -0.164 -0.148 -0.066 0.046 0.109 0.141 0.177   || dis=0.01 || select=7/8
008/019-th : 0.099 0.105 0.111 0.128 0.139 0.145 0.138 0.136  ||  -0.209 -0.149 -0.097 0.048 0.133 0.174 0.125 0.110    || dis=0.01 || select=5/8
009/019-th : 0.116 0.116 0.112 0.122 0.124 0.133 0.137 0.140  ||  -0.076 -0.073 -0.108 -0.026 -0.012 0.063 0.089 0.109  || dis=0.00 || select=7/8
010/019-th : 0.114 0.117 0.117 0.127 0.130 0.133 0.132 0.130  ||  -0.089 -0.063 -0.064 0.023 0.048 0.072 0.062 0.048    || dis=0.00 || select=5/8
011/019-th : 0.113 0.111 0.112 0.116 0.132 0.135 0.140 0.140  ||  -0.093 -0.112 -0.103 -0.071 0.054 0.080 0.118 0.116   || dis=0.00 || select=6/8
012/019-th : 0.121 0.121 0.119 0.126 0.128 0.127 0.129 0.129  ||  -0.029 -0.033 -0.046 0.009 0.028 0.017 0.033 0.037    || dis=0.00 || select=7/8
013/019-th : 0.090 0.096 0.100 0.113 0.126 0.146 0.163 0.166  ||  -0.314 -0.247 -0.211 -0.088 0.025 0.173 0.284 0.302   || dis=0.00 || select=7/8
014/019-th : 0.085 0.090 0.104 0.127 0.143 0.148 0.158 0.146  ||  -0.350 -0.292 -0.143 0.054 0.174 0.211 0.272 0.199    || dis=0.01 || select=6/8
015/019-th : 0.100 0.097 0.104 0.111 0.127 0.149 0.158 0.153  ||  -0.211 -0.237 -0.172 -0.103 0.025 0.189 0.247 0.213   || dis=0.01 || select=6/8
016/019-th : 0.084 0.098 0.110 0.124 0.146 0.149 0.146 0.143  ||  -0.359 -0.206 -0.097 0.025 0.187 0.213 0.192 0.169    || dis=0.00 || select=5/8
017/019-th : 0.119 0.116 0.116 0.118 0.123 0.132 0.137 0.139  ||  -0.047 -0.076 -0.078 -0.056 -0.017 0.049 0.087 0.104  || dis=0.00 || select=7/8
018/019-th : 0.089 0.102 0.114 0.119 0.133 0.136 0.144 0.163  ||  -0.318 -0.184 -0.073 -0.033 0.080 0.106 0.157 0.283   || dis=0.02 || select=7/8
[epoch=057/600] FLOP : 25.55 MB, ratio : 0.6259, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:12:30] [epoch=057/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.006 (3.006)  Prec@1 32.42 (32.42) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:12:36] [epoch=057/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.949 (2.215)  Prec@1 32.14 (37.18) Prec@5 82.74 (84.87) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.18 Prec@5 84.87 Error@1 62.82 Error@5 15.13 Loss:2.215
***[2020-01-29 06:12:36]*** VALID [epoch=057/600] loss = 2.214593, accuracy@1 = 37.18, accuracy@5 = 84.87 | Best-Valid-Acc@1=37.55, Error@1=62.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:12:36]*** start epoch=058/600 Time Left: [04:54:58], LR=[0.097712 ~ 0.097712], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=58, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.887888804864878, FLOP=40.81
[Search] : epoch=058/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:12:37] [epoch=058/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.995 (0.995)  Prec@1 66.41 (66.41) Prec@5 98.05 (98.05) Acls-loss 0.979 (0.979) FLOP-Loss -2.476 (-2.476) Arch-Loss -3.972 (-3.972)
**TRAIN** [2020-01-29 06:13:02] [epoch=058/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.901 (0.971)  Prec@1 66.67 (65.98) Prec@5 97.02 (96.95) Acls-loss 1.132 (0.989) FLOP-Loss 2.478 (0.042) Arch-Loss 6.087 (1.074)
 **TRAIN** Prec@1 65.98 Prec@5 96.95 Error@1 34.02 Error@5 3.05 Base-Loss:0.971, Arch-Loss=1.074
***[2020-01-29 06:13:02]*** TRAIN [epoch=058/600] base-loss = 0.971002, arch-loss = 1.073550, accuracy-1 = 65.98, accuracy-5 = 96.95
[epoch=058/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 12, 11, 16, 14, 32, 25, 32, 25, 28, 32, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.546304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.375 0.251 0.375  ||  0.0092 -0.3935 0.0086  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.206 0.406  ||  -0.0007 -0.6371 0.0425  || discrepancy=0.02 || select=2/3
002/003-th : 0.335 0.222 0.444  ||  -0.1211 -0.5335 0.1604  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.088 0.096 0.108 0.115 0.136 0.153 0.155 0.148  ||  -0.317 -0.231 -0.115 -0.050 0.116 0.232 0.245 0.200   || dis=0.00 || select=6/8
001/019-th : 0.120 0.120 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.039 -0.018 -0.010 0.015 0.048 0.036 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.129 0.129 0.130 0.127 0.127  ||  -0.071 -0.042 -0.010 0.037 0.040 0.045 0.022 0.026    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.126 0.125 0.125  ||  -0.010 -0.011 0.001 0.000 -0.001 0.008 0.002 -0.002   || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.125 0.129 0.127 0.129 0.126  ||  -0.047 -0.018 -0.015 0.003 0.030 0.016 0.030 0.013    || dis=0.00 || select=4/8
005/019-th : 0.120 0.122 0.124 0.122 0.128 0.127 0.127 0.129  ||  -0.038 -0.026 -0.006 -0.019 0.027 0.022 0.022 0.033   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.124 0.122 0.130 0.128 0.132 0.129  ||  -0.074 -0.037 -0.009 -0.020 0.040 0.027 0.059 0.031   || dis=0.00 || select=6/8
007/019-th : 0.109 0.106 0.107 0.116 0.129 0.140 0.144 0.149  ||  -0.136 -0.165 -0.152 -0.069 0.038 0.117 0.142 0.179   || dis=0.01 || select=7/8
008/019-th : 0.098 0.104 0.110 0.128 0.140 0.145 0.138 0.136  ||  -0.212 -0.153 -0.098 0.055 0.140 0.178 0.126 0.111    || dis=0.00 || select=5/8
009/019-th : 0.116 0.116 0.112 0.121 0.124 0.133 0.137 0.140  ||  -0.076 -0.075 -0.107 -0.030 -0.009 0.064 0.092 0.109  || dis=0.00 || select=7/8
010/019-th : 0.113 0.117 0.117 0.127 0.129 0.134 0.132 0.131  ||  -0.091 -0.063 -0.064 0.025 0.041 0.075 0.061 0.050    || dis=0.00 || select=5/8
011/019-th : 0.113 0.111 0.113 0.117 0.130 0.135 0.140 0.140  ||  -0.096 -0.113 -0.101 -0.063 0.043 0.079 0.119 0.118   || dis=0.00 || select=6/8
012/019-th : 0.121 0.120 0.119 0.126 0.128 0.127 0.129 0.129  ||  -0.029 -0.034 -0.046 0.012 0.030 0.018 0.033 0.036    || dis=0.00 || select=7/8
013/019-th : 0.090 0.095 0.100 0.113 0.124 0.147 0.165 0.168  ||  -0.315 -0.257 -0.212 -0.089 0.006 0.175 0.290 0.309   || dis=0.00 || select=7/8
014/019-th : 0.084 0.089 0.104 0.126 0.144 0.149 0.157 0.147  ||  -0.354 -0.297 -0.144 0.052 0.183 0.217 0.272 0.202    || dis=0.01 || select=6/8
015/019-th : 0.100 0.096 0.104 0.112 0.127 0.149 0.159 0.153  ||  -0.213 -0.246 -0.175 -0.098 0.032 0.188 0.254 0.216   || dis=0.01 || select=6/8
016/019-th : 0.084 0.098 0.110 0.123 0.145 0.151 0.146 0.143  ||  -0.364 -0.208 -0.096 0.021 0.187 0.222 0.193 0.170    || dis=0.01 || select=5/8
017/019-th : 0.119 0.116 0.116 0.118 0.123 0.132 0.137 0.139  ||  -0.048 -0.075 -0.079 -0.057 -0.017 0.051 0.087 0.104  || dis=0.00 || select=7/8
018/019-th : 0.089 0.102 0.114 0.118 0.132 0.137 0.145 0.163  ||  -0.323 -0.189 -0.076 -0.036 0.073 0.107 0.167 0.286   || dis=0.02 || select=7/8
[epoch=058/600] FLOP : 25.55 MB, ratio : 0.6259, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:13:02] [epoch=058/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 4.159 (4.159)  Prec@1 33.20 (33.20) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:13:08] [epoch=058/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.717 (2.166)  Prec@1 32.74 (38.55) Prec@5 85.12 (84.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.55 Prec@5 84.43 Error@1 61.45 Error@5 15.57 Loss:2.166
***[2020-01-29 06:13:08]*** VALID [epoch=058/600] loss = 2.166208, accuracy@1 = 38.55, accuracy@5 = 84.43 | Best-Valid-Acc@1=37.55, Error@1=62.45
Currently, the best validation accuracy found at 058-epoch :: acc@1=38.55, acc@5=84.43, error@1=61.45, error@5=15.57, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:13:08]*** start epoch=059/600 Time Left: [04:54:18], LR=[0.097633 ~ 0.097633], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=59, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.884020629071286, FLOP=40.81
[Search] : epoch=059/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:13:09] [epoch=059/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 1.069 (1.069)  Prec@1 59.77 (59.77) Prec@5 96.88 (96.88) Acls-loss 1.018 (1.018) FLOP-Loss -2.477 (-2.477) Arch-Loss -3.936 (-3.936)
**TRAIN** [2020-01-29 06:13:34] [epoch=059/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.944 (0.943)  Prec@1 66.07 (67.56) Prec@5 97.62 (97.18) Acls-loss 0.971 (0.968) FLOP-Loss -2.478 (0.009) Arch-Loss -3.984 (0.986)
 **TRAIN** Prec@1 67.56 Prec@5 97.18 Error@1 32.44 Error@5 2.82 Base-Loss:0.943, Arch-Loss=0.986
***[2020-01-29 06:13:34]*** TRAIN [epoch=059/600] base-loss = 0.943014, arch-loss = 0.985837, accuracy-1 = 67.56, accuracy-5 = 97.18
[epoch=059/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 14, 16, 14, 32, 25, 32, 25, 28, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.3584)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.377 0.247 0.377  ||  0.0091 -0.4140 0.0093  || discrepancy=0.00 || select=2/3
001/003-th : 0.389 0.205 0.406  ||  -0.0007 -0.6390 0.0430  || discrepancy=0.02 || select=2/3
002/003-th : 0.334 0.222 0.444  ||  -0.1219 -0.5319 0.1613  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.088 0.096 0.108 0.115 0.139 0.152 0.155 0.148  ||  -0.320 -0.232 -0.116 -0.051 0.136 0.227 0.247 0.201   || dis=0.00 || select=6/8
001/019-th : 0.120 0.120 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.039 -0.018 -0.008 0.016 0.047 0.036 0.046   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.127  ||  -0.071 -0.042 -0.010 0.033 0.044 0.044 0.021 0.026    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.126 0.125 0.125 0.126 0.125 0.125  ||  -0.010 -0.010 0.003 -0.001 -0.002 0.008 0.002 -0.002  || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.125 0.128 0.127 0.129 0.126  ||  -0.047 -0.018 -0.017 0.006 0.029 0.018 0.031 0.012    || dis=0.00 || select=6/8
005/019-th : 0.120 0.122 0.124 0.122 0.128 0.128 0.127 0.129  ||  -0.038 -0.026 -0.007 -0.019 0.028 0.023 0.021 0.033   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.123 0.122 0.130 0.128 0.132 0.129  ||  -0.075 -0.038 -0.011 -0.020 0.041 0.030 0.060 0.033   || dis=0.00 || select=6/8
007/019-th : 0.108 0.105 0.108 0.117 0.128 0.141 0.144 0.149  ||  -0.141 -0.168 -0.147 -0.061 0.030 0.121 0.142 0.182   || dis=0.01 || select=7/8
008/019-th : 0.098 0.104 0.110 0.129 0.142 0.145 0.137 0.136  ||  -0.215 -0.158 -0.096 0.060 0.159 0.176 0.126 0.113    || dis=0.00 || select=5/8
009/019-th : 0.116 0.116 0.112 0.122 0.124 0.133 0.137 0.140  ||  -0.075 -0.077 -0.110 -0.026 -0.011 0.062 0.094 0.110  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.116 0.128 0.129 0.134 0.132 0.131  ||  -0.093 -0.065 -0.064 0.027 0.042 0.077 0.059 0.052    || dis=0.00 || select=5/8
011/019-th : 0.113 0.111 0.113 0.118 0.129 0.134 0.141 0.140  ||  -0.097 -0.116 -0.099 -0.051 0.036 0.075 0.122 0.119   || dis=0.00 || select=6/8
012/019-th : 0.121 0.120 0.119 0.126 0.130 0.127 0.129 0.129  ||  -0.030 -0.035 -0.048 0.010 0.041 0.019 0.033 0.037    || dis=0.00 || select=4/8
013/019-th : 0.089 0.095 0.100 0.112 0.125 0.146 0.165 0.169  ||  -0.319 -0.262 -0.212 -0.097 0.015 0.171 0.293 0.315   || dis=0.00 || select=7/8
014/019-th : 0.084 0.089 0.103 0.127 0.144 0.149 0.157 0.147  ||  -0.355 -0.300 -0.150 0.057 0.184 0.217 0.273 0.204    || dis=0.01 || select=6/8
015/019-th : 0.099 0.096 0.102 0.110 0.131 0.149 0.159 0.153  ||  -0.216 -0.251 -0.183 -0.110 0.059 0.192 0.259 0.220   || dis=0.01 || select=6/8
016/019-th : 0.084 0.098 0.109 0.124 0.145 0.151 0.147 0.143  ||  -0.367 -0.211 -0.100 0.026 0.181 0.221 0.198 0.171    || dis=0.00 || select=5/8
017/019-th : 0.119 0.116 0.116 0.118 0.123 0.132 0.137 0.139  ||  -0.048 -0.074 -0.078 -0.060 -0.021 0.050 0.088 0.104  || dis=0.00 || select=7/8
018/019-th : 0.089 0.102 0.114 0.119 0.133 0.137 0.144 0.163  ||  -0.324 -0.189 -0.077 -0.032 0.081 0.107 0.163 0.285   || dis=0.02 || select=7/8
[epoch=059/600] FLOP : 31.36 MB, ratio : 0.7683, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:13:34] [epoch=059/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.724 (3.724)  Prec@1 21.88 (21.88) Prec@5 71.48 (71.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:13:40] [epoch=059/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.688 (2.582)  Prec@1 39.29 (33.06) Prec@5 88.69 (79.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.06 Prec@5 79.16 Error@1 66.94 Error@5 20.84 Loss:2.582
***[2020-01-29 06:13:40]*** VALID [epoch=059/600] loss = 2.582055, accuracy@1 = 33.06, accuracy@5 = 79.16 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:13:40]*** start epoch=060/600 Time Left: [04:53:41], LR=[0.097553 ~ 0.097553], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=60, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.880088464923126, FLOP=40.81
[Search] : epoch=060/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:13:41] [epoch=060/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.882 (0.882)  Prec@1 67.97 (67.97) Prec@5 98.83 (98.83) Acls-loss 0.953 (0.953) FLOP-Loss 2.478 (2.478) Arch-Loss 5.909 (5.909)
**TRAIN** [2020-01-29 06:14:06] [epoch=060/600][097/098] Time 0.32 (0.26) Data 0.00 (0.00) Base-Loss 0.836 (0.949)  Prec@1 70.24 (66.86) Prec@5 99.40 (97.12) Acls-loss 0.988 (0.970) FLOP-Loss -2.479 (0.009) Arch-Loss -3.969 (0.988)
 **TRAIN** Prec@1 66.86 Prec@5 97.12 Error@1 33.14 Error@5 2.88 Base-Loss:0.949, Arch-Loss=0.988
***[2020-01-29 06:14:06]*** TRAIN [epoch=060/600] base-loss = 0.949466, arch-loss = 0.988007, accuracy-1 = 66.86, accuracy-5 = 97.12
[epoch=060/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 12, 14, 16, 14, 32, 25, 32, 25, 28, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.608256)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.377 0.246 0.377  ||  0.0091 -0.4190 0.0097  || discrepancy=0.00 || select=2/3
001/003-th : 0.388 0.205 0.407  ||  -0.0015 -0.6398 0.0443  || discrepancy=0.02 || select=2/3
002/003-th : 0.334 0.222 0.444  ||  -0.1236 -0.5298 0.1632  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.087 0.096 0.108 0.115 0.139 0.152 0.155 0.148  ||  -0.327 -0.234 -0.116 -0.050 0.142 0.227 0.249 0.205   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.127 0.130 0.129 0.130  ||  -0.038 -0.041 -0.020 -0.009 0.019 0.049 0.038 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.128  ||  -0.072 -0.042 -0.011 0.031 0.044 0.044 0.023 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.126 0.126 0.125  ||  -0.010 -0.010 0.002 -0.003 -0.003 0.008 0.003 -0.002  || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.125 0.128 0.127 0.129 0.126  ||  -0.047 -0.019 -0.016 0.001 0.023 0.019 0.032 0.013    || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.124 0.123 0.128 0.128 0.128 0.129  ||  -0.041 -0.026 -0.003 -0.017 0.026 0.023 0.023 0.034   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.123 0.122 0.130 0.128 0.133 0.129  ||  -0.075 -0.039 -0.013 -0.022 0.040 0.030 0.062 0.034   || dis=0.00 || select=6/8
007/019-th : 0.108 0.105 0.107 0.116 0.129 0.140 0.144 0.150  ||  -0.142 -0.170 -0.149 -0.067 0.037 0.119 0.144 0.184   || dis=0.01 || select=7/8
008/019-th : 0.097 0.103 0.110 0.129 0.144 0.144 0.138 0.136  ||  -0.221 -0.161 -0.094 0.061 0.174 0.176 0.129 0.114    || dis=0.00 || select=5/8
009/019-th : 0.116 0.115 0.112 0.123 0.124 0.133 0.137 0.140  ||  -0.076 -0.080 -0.114 -0.015 -0.012 0.062 0.095 0.112  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.116 0.127 0.131 0.134 0.132 0.131  ||  -0.094 -0.067 -0.070 0.026 0.054 0.080 0.061 0.053    || dis=0.00 || select=5/8
011/019-th : 0.113 0.111 0.113 0.120 0.129 0.134 0.141 0.140  ||  -0.099 -0.119 -0.100 -0.038 0.035 0.071 0.124 0.120   || dis=0.00 || select=6/8
012/019-th : 0.121 0.120 0.119 0.125 0.130 0.127 0.129 0.129  ||  -0.032 -0.036 -0.048 0.007 0.046 0.021 0.034 0.038    || dis=0.00 || select=4/8
013/019-th : 0.089 0.094 0.100 0.111 0.124 0.145 0.166 0.169  ||  -0.321 -0.267 -0.213 -0.103 0.009 0.167 0.301 0.319   || dis=0.00 || select=7/8
014/019-th : 0.084 0.089 0.103 0.127 0.143 0.149 0.158 0.147  ||  -0.355 -0.301 -0.154 0.056 0.177 0.220 0.275 0.205    || dis=0.01 || select=6/8
015/019-th : 0.099 0.096 0.102 0.110 0.130 0.149 0.160 0.154  ||  -0.220 -0.253 -0.192 -0.115 0.053 0.194 0.265 0.225   || dis=0.01 || select=6/8
016/019-th : 0.083 0.098 0.109 0.124 0.143 0.151 0.148 0.144  ||  -0.373 -0.210 -0.102 0.026 0.168 0.220 0.203 0.173    || dis=0.00 || select=5/8
017/019-th : 0.119 0.116 0.116 0.118 0.123 0.132 0.137 0.139  ||  -0.048 -0.075 -0.080 -0.061 -0.019 0.052 0.090 0.104  || dis=0.00 || select=7/8
018/019-th : 0.089 0.102 0.114 0.119 0.133 0.137 0.144 0.163  ||  -0.326 -0.188 -0.072 -0.028 0.078 0.108 0.162 0.285   || dis=0.02 || select=7/8
[epoch=060/600] FLOP : 31.61 MB, ratio : 0.7745, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:14:07] [epoch=060/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.930 (1.930)  Prec@1 30.47 (30.47) Prec@5 79.30 (79.30) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:14:13] [epoch=060/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.905 (2.167)  Prec@1 44.05 (37.97) Prec@5 89.29 (84.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.97 Prec@5 84.66 Error@1 62.03 Error@5 15.34 Loss:2.167
***[2020-01-29 06:14:13]*** VALID [epoch=060/600] loss = 2.166965, accuracy@1 = 37.97, accuracy@5 = 84.66 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:14:13]*** start epoch=061/600 Time Left: [04:53:05], LR=[0.097471 ~ 0.097471], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=61, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.8760924202226645, FLOP=40.81
[Search] : epoch=061/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:14:14] [epoch=061/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.973 (0.973)  Prec@1 64.84 (64.84) Prec@5 96.48 (96.48) Acls-loss 0.939 (0.939) FLOP-Loss 2.479 (2.479) Arch-Loss 5.898 (5.898)
**TRAIN** [2020-01-29 06:14:38] [epoch=061/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.992 (0.945)  Prec@1 70.83 (66.86) Prec@5 96.43 (97.10) Acls-loss 1.014 (0.959) FLOP-Loss 2.481 (0.042) Arch-Loss 5.975 (1.044)
 **TRAIN** Prec@1 66.86 Prec@5 97.10 Error@1 33.14 Error@5 2.90 Base-Loss:0.945, Arch-Loss=1.044
***[2020-01-29 06:14:38]*** TRAIN [epoch=061/600] base-loss = 0.945081, arch-loss = 1.043867, accuracy-1 = 66.86, accuracy-5 = 97.10
[epoch=061/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 14, 16, 14, 32, 25, 32, 25, 28, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.307136)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.377 0.246 0.377  ||  0.0096 -0.4200 0.0095  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.205 0.407  ||  -0.0011 -0.6413 0.0444  || discrepancy=0.02 || select=2/3
002/003-th : 0.333 0.223 0.445  ||  -0.1252 -0.5265 0.1650  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.087 0.096 0.107 0.115 0.139 0.152 0.156 0.149  ||  -0.330 -0.235 -0.120 -0.054 0.138 0.230 0.252 0.207   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.041 -0.017 -0.011 0.017 0.048 0.038 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.128  ||  -0.072 -0.042 -0.010 0.031 0.045 0.044 0.022 0.027    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.125 0.125 0.125 0.126 0.125 0.125  ||  -0.010 -0.010 0.003 0.002 -0.003 0.008 0.003 -0.003   || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.125 0.128 0.127 0.129 0.127  ||  -0.048 -0.019 -0.015 -0.001 0.022 0.019 0.033 0.013   || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.124 0.122 0.128 0.128 0.128 0.129  ||  -0.041 -0.028 -0.003 -0.020 0.028 0.024 0.024 0.034   || dis=0.00 || select=7/8
006/019-th : 0.116 0.120 0.123 0.122 0.130 0.128 0.133 0.129  ||  -0.075 -0.041 -0.012 -0.023 0.039 0.029 0.061 0.035   || dis=0.00 || select=6/8
007/019-th : 0.108 0.105 0.107 0.116 0.129 0.141 0.144 0.150  ||  -0.143 -0.171 -0.153 -0.068 0.035 0.123 0.145 0.186   || dis=0.01 || select=7/8
008/019-th : 0.097 0.103 0.110 0.128 0.142 0.145 0.138 0.136  ||  -0.225 -0.161 -0.097 0.058 0.162 0.176 0.133 0.117    || dis=0.00 || select=5/8
009/019-th : 0.116 0.115 0.111 0.123 0.124 0.133 0.137 0.140  ||  -0.075 -0.081 -0.116 -0.018 -0.012 0.063 0.095 0.113  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.116 0.128 0.131 0.134 0.132 0.131  ||  -0.095 -0.068 -0.068 0.028 0.056 0.080 0.063 0.052    || dis=0.00 || select=5/8
011/019-th : 0.113 0.110 0.113 0.121 0.129 0.133 0.141 0.141  ||  -0.100 -0.124 -0.094 -0.029 0.039 0.067 0.124 0.122   || dis=0.00 || select=6/8
012/019-th : 0.120 0.120 0.119 0.126 0.131 0.127 0.129 0.129  ||  -0.033 -0.037 -0.047 0.013 0.052 0.020 0.034 0.038    || dis=0.00 || select=4/8
013/019-th : 0.089 0.094 0.099 0.111 0.123 0.145 0.167 0.170  ||  -0.324 -0.267 -0.215 -0.102 0.002 0.166 0.303 0.323   || dis=0.00 || select=7/8
014/019-th : 0.084 0.089 0.103 0.127 0.143 0.150 0.158 0.148  ||  -0.358 -0.303 -0.153 0.055 0.173 0.223 0.275 0.207    || dis=0.01 || select=6/8
015/019-th : 0.099 0.095 0.101 0.109 0.130 0.150 0.161 0.155  ||  -0.222 -0.257 -0.197 -0.125 0.055 0.198 0.266 0.232   || dis=0.01 || select=6/8
016/019-th : 0.083 0.097 0.109 0.124 0.145 0.151 0.148 0.144  ||  -0.379 -0.217 -0.104 0.028 0.185 0.225 0.206 0.176    || dis=0.00 || select=5/8
017/019-th : 0.119 0.116 0.116 0.118 0.124 0.132 0.137 0.139  ||  -0.051 -0.074 -0.080 -0.056 -0.011 0.055 0.088 0.104  || dis=0.00 || select=7/8
018/019-th : 0.089 0.101 0.114 0.120 0.132 0.136 0.144 0.163  ||  -0.326 -0.191 -0.074 -0.021 0.077 0.107 0.163 0.285   || dis=0.02 || select=7/8
[epoch=061/600] FLOP : 24.31 MB, ratio : 0.5956, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:14:39] [epoch=061/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 3.169 (3.169)  Prec@1 29.30 (29.30) Prec@5 74.22 (74.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:14:45] [epoch=061/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.005 (2.248)  Prec@1 23.81 (35.19) Prec@5 58.93 (81.87) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.19 Prec@5 81.87 Error@1 64.81 Error@5 18.13 Loss:2.248
***[2020-01-29 06:14:45]*** VALID [epoch=061/600] loss = 2.247987, accuracy@1 = 35.19, accuracy@5 = 81.87 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:14:45]*** start epoch=062/600 Time Left: [04:52:29], LR=[0.097388 ~ 0.097388], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=62, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.872032604523485, FLOP=40.81
[Search] : epoch=062/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:14:46] [epoch=062/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.876 (0.876)  Prec@1 71.48 (71.48) Prec@5 98.05 (98.05) Acls-loss 0.958 (0.958) FLOP-Loss -2.480 (-2.480) Arch-Loss -4.002 (-4.002)
**TRAIN** [2020-01-29 06:15:10] [epoch=062/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.840 (0.954)  Prec@1 70.24 (67.09) Prec@5 97.62 (96.94) Acls-loss 0.977 (0.968) FLOP-Loss -2.481 (0.009) Arch-Loss -3.985 (0.986)
 **TRAIN** Prec@1 67.09 Prec@5 96.94 Error@1 32.91 Error@5 3.06 Base-Loss:0.954, Arch-Loss=0.986
***[2020-01-29 06:15:10]*** TRAIN [epoch=062/600] base-loss = 0.953777, arch-loss = 0.985570, accuracy-1 = 67.09, accuracy-5 = 96.94
[epoch=062/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 12, 14, 16, 14, 32, 25, 32, 25, 28, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.3584)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.379 0.242 0.379  ||  0.0098 -0.4374 0.0100  || discrepancy=0.00 || select=2/3
001/003-th : 0.388 0.205 0.407  ||  -0.0014 -0.6404 0.0452  || discrepancy=0.02 || select=2/3
002/003-th : 0.332 0.223 0.445  ||  -0.1269 -0.5248 0.1668  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.086 0.095 0.107 0.114 0.140 0.152 0.155 0.149  ||  -0.335 -0.241 -0.116 -0.054 0.151 0.230 0.253 0.211   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.038 -0.042 -0.017 -0.011 0.017 0.048 0.039 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.128 0.130 0.130 0.127 0.128  ||  -0.073 -0.043 -0.010 0.029 0.044 0.042 0.023 0.028    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.125 0.126 0.125 0.126 0.125 0.125  ||  -0.010 -0.010 0.001 0.004 -0.002 0.008 0.002 -0.003   || dis=0.00 || select=5/8
004/019-th : 0.119 0.123 0.123 0.125 0.128 0.127 0.129 0.127  ||  -0.048 -0.019 -0.015 -0.001 0.022 0.018 0.033 0.014   || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.124 0.123 0.129 0.127 0.127 0.129  ||  -0.041 -0.029 -0.004 -0.017 0.032 0.022 0.022 0.035   || dis=0.00 || select=7/8
006/019-th : 0.115 0.120 0.123 0.122 0.130 0.129 0.133 0.129  ||  -0.077 -0.042 -0.013 -0.023 0.038 0.033 0.063 0.036   || dis=0.00 || select=6/8
007/019-th : 0.108 0.105 0.106 0.116 0.130 0.141 0.144 0.150  ||  -0.144 -0.173 -0.157 -0.070 0.041 0.126 0.148 0.187   || dis=0.01 || select=7/8
008/019-th : 0.096 0.103 0.110 0.128 0.142 0.145 0.139 0.137  ||  -0.229 -0.166 -0.095 0.058 0.158 0.180 0.135 0.120    || dis=0.00 || select=5/8
009/019-th : 0.116 0.115 0.111 0.123 0.123 0.134 0.138 0.140  ||  -0.077 -0.083 -0.117 -0.020 -0.015 0.069 0.097 0.114  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.116 0.128 0.130 0.134 0.132 0.131  ||  -0.096 -0.070 -0.064 0.030 0.046 0.079 0.063 0.054    || dis=0.00 || select=5/8
011/019-th : 0.113 0.110 0.113 0.121 0.130 0.133 0.141 0.141  ||  -0.100 -0.126 -0.098 -0.029 0.043 0.065 0.126 0.124   || dis=0.00 || select=6/8
012/019-th : 0.120 0.120 0.118 0.125 0.131 0.127 0.129 0.129  ||  -0.034 -0.039 -0.050 0.009 0.054 0.021 0.035 0.040    || dis=0.00 || select=4/8
013/019-th : 0.089 0.094 0.099 0.110 0.124 0.146 0.168 0.171  ||  -0.327 -0.274 -0.214 -0.110 0.009 0.168 0.309 0.327   || dis=0.00 || select=7/8
014/019-th : 0.084 0.089 0.103 0.126 0.141 0.151 0.158 0.148  ||  -0.361 -0.305 -0.157 0.050 0.164 0.227 0.277 0.212    || dis=0.01 || select=6/8
015/019-th : 0.098 0.095 0.101 0.108 0.130 0.151 0.161 0.156  ||  -0.225 -0.263 -0.201 -0.130 0.054 0.204 0.267 0.238   || dis=0.01 || select=6/8
016/019-th : 0.082 0.097 0.109 0.124 0.145 0.151 0.148 0.144  ||  -0.385 -0.220 -0.103 0.030 0.185 0.227 0.208 0.179    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.125 0.132 0.137 0.138  ||  -0.054 -0.075 -0.076 -0.061 0.001 0.058 0.090 0.103   || dis=0.00 || select=7/8
018/019-th : 0.088 0.102 0.114 0.120 0.133 0.136 0.144 0.163  ||  -0.330 -0.188 -0.071 -0.024 0.079 0.105 0.163 0.286   || dis=0.02 || select=7/8
[epoch=062/600] FLOP : 31.36 MB, ratio : 0.7683, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:15:11] [epoch=062/600][000/098] Time 0.35 (0.35) Data 0.28 (0.28) Loss 1.669 (1.669)  Prec@1 43.36 (43.36) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:15:17] [epoch=062/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.799 (2.073)  Prec@1 36.90 (38.54) Prec@5 83.93 (83.73) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.54 Prec@5 83.73 Error@1 61.46 Error@5 16.27 Loss:2.073
***[2020-01-29 06:15:17]*** VALID [epoch=062/600] loss = 2.072689, accuracy@1 = 38.54, accuracy@5 = 83.73 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:15:17]*** start epoch=063/600 Time Left: [04:51:53], LR=[0.097304 ~ 0.097304], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=63, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.867909129127486, FLOP=40.81
[Search] : epoch=063/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:15:18] [epoch=063/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.841 (0.841)  Prec@1 68.36 (68.36) Prec@5 98.44 (98.44) Acls-loss 0.962 (0.962) FLOP-Loss 2.482 (2.482) Arch-Loss 5.926 (5.926)
**TRAIN** [2020-01-29 06:15:43] [epoch=063/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.013 (0.934)  Prec@1 66.67 (67.48) Prec@5 97.62 (97.25) Acls-loss 0.994 (0.956) FLOP-Loss 2.483 (0.042) Arch-Loss 5.961 (1.041)
 **TRAIN** Prec@1 67.48 Prec@5 97.25 Error@1 32.52 Error@5 2.75 Base-Loss:0.934, Arch-Loss=1.041
***[2020-01-29 06:15:43]*** TRAIN [epoch=063/600] base-loss = 0.933682, arch-loss = 1.040647, accuracy-1 = 67.48, accuracy-5 = 97.25
[epoch=063/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 9, 14, 11, 14, 32, 25, 32, 25, 28, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.432064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.378 0.245 0.378  ||  0.0102 -0.4245 0.0098  || discrepancy=0.00 || select=0/3
001/003-th : 0.388 0.206 0.406  ||  -0.0011 -0.6338 0.0452  || discrepancy=0.02 || select=2/3
002/003-th : 0.331 0.223 0.446  ||  -0.1288 -0.5235 0.1689  || discrepancy=0.11 || select=2/3
-----------------------------------------------
000/019-th : 0.086 0.095 0.107 0.116 0.140 0.152 0.155 0.149  ||  -0.338 -0.239 -0.117 -0.043 0.145 0.228 0.250 0.211   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.037 -0.041 -0.018 -0.011 0.015 0.047 0.038 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.123 0.128 0.129 0.130 0.127 0.128  ||  -0.072 -0.043 -0.008 0.028 0.040 0.042 0.023 0.028    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.126 0.125 0.126 0.125 0.125  ||  -0.010 -0.010 0.001 0.008 -0.000 0.008 0.001 -0.003   || dis=0.00 || select=3/8
004/019-th : 0.119 0.123 0.123 0.125 0.128 0.127 0.129 0.127  ||  -0.048 -0.019 -0.015 0.001 0.021 0.018 0.032 0.014    || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.125 0.123 0.129 0.127 0.127 0.129  ||  -0.043 -0.029 0.000 -0.013 0.035 0.023 0.022 0.034    || dis=0.00 || select=4/8
006/019-th : 0.115 0.119 0.123 0.122 0.129 0.129 0.133 0.129  ||  -0.078 -0.043 -0.012 -0.023 0.037 0.032 0.064 0.036   || dis=0.00 || select=6/8
007/019-th : 0.108 0.104 0.106 0.116 0.130 0.141 0.144 0.150  ||  -0.144 -0.175 -0.160 -0.067 0.042 0.127 0.149 0.188   || dis=0.01 || select=7/8
008/019-th : 0.096 0.103 0.109 0.128 0.144 0.145 0.139 0.137  ||  -0.234 -0.166 -0.102 0.055 0.172 0.178 0.139 0.123    || dis=0.00 || select=5/8
009/019-th : 0.116 0.115 0.111 0.123 0.123 0.134 0.138 0.140  ||  -0.077 -0.086 -0.116 -0.019 -0.015 0.070 0.098 0.115  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.117 0.128 0.129 0.134 0.133 0.131  ||  -0.097 -0.071 -0.062 0.032 0.038 0.073 0.065 0.056    || dis=0.00 || select=5/8
011/019-th : 0.113 0.110 0.112 0.120 0.130 0.133 0.141 0.141  ||  -0.100 -0.126 -0.101 -0.038 0.044 0.066 0.127 0.126   || dis=0.00 || select=6/8
012/019-th : 0.120 0.120 0.119 0.126 0.130 0.127 0.129 0.130  ||  -0.034 -0.039 -0.047 0.009 0.047 0.021 0.033 0.040    || dis=0.00 || select=4/8
013/019-th : 0.089 0.092 0.100 0.110 0.125 0.145 0.168 0.171  ||  -0.328 -0.286 -0.210 -0.113 0.021 0.167 0.313 0.330   || dis=0.00 || select=7/8
014/019-th : 0.083 0.088 0.102 0.125 0.143 0.152 0.159 0.148  ||  -0.367 -0.309 -0.161 0.041 0.174 0.236 0.284 0.213    || dis=0.01 || select=6/8
015/019-th : 0.098 0.094 0.100 0.109 0.129 0.152 0.161 0.157  ||  -0.228 -0.269 -0.209 -0.126 0.048 0.209 0.268 0.245   || dis=0.00 || select=6/8
016/019-th : 0.082 0.097 0.108 0.124 0.145 0.151 0.149 0.145  ||  -0.391 -0.218 -0.107 0.028 0.182 0.224 0.212 0.183    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.117 0.126 0.132 0.137 0.138  ||  -0.054 -0.075 -0.074 -0.060 0.007 0.058 0.090 0.103   || dis=0.00 || select=7/8
018/019-th : 0.088 0.101 0.113 0.121 0.133 0.136 0.144 0.163  ||  -0.328 -0.194 -0.078 -0.014 0.079 0.105 0.163 0.287   || dis=0.02 || select=7/8
[epoch=063/600] FLOP : 24.43 MB, ratio : 0.5986, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:15:43] [epoch=063/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.306 (3.306)  Prec@1 37.89 (37.89) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:15:49] [epoch=063/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.006 (2.142)  Prec@1 32.74 (37.53) Prec@5 89.29 (82.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.53 Prec@5 82.72 Error@1 62.47 Error@5 17.28 Loss:2.142
***[2020-01-29 06:15:49]*** VALID [epoch=063/600] loss = 2.142415, accuracy@1 = 37.53, accuracy@5 = 82.72 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:15:49]*** start epoch=064/600 Time Left: [04:51:16], LR=[0.097219 ~ 0.097219], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=64, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.863722107081829, FLOP=40.81
[Search] : epoch=064/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:15:50] [epoch=064/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.952 (0.952)  Prec@1 68.36 (68.36) Prec@5 95.31 (95.31) Acls-loss 0.863 (0.863) FLOP-Loss -2.483 (-2.483) Arch-Loss -4.102 (-4.102)
**TRAIN** [2020-01-29 06:16:15] [epoch=064/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.876 (0.945)  Prec@1 70.83 (67.38) Prec@5 97.62 (96.97) Acls-loss 1.020 (0.979) FLOP-Loss -2.483 (0.009) Arch-Loss -3.947 (0.997)
 **TRAIN** Prec@1 67.38 Prec@5 96.97 Error@1 32.62 Error@5 3.03 Base-Loss:0.945, Arch-Loss=0.997
***[2020-01-29 06:16:15]*** TRAIN [epoch=064/600] base-loss = 0.944837, arch-loss = 0.996993, accuracy-1 = 67.38, accuracy-5 = 96.97
[epoch=064/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 9, 14, 16, 14, 32, 22, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.552896)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.378 0.245 0.378  ||  0.0104 -0.4236 0.0098  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.203 0.408  ||  -0.0019 -0.6512 0.0467  || discrepancy=0.02 || select=2/3
002/003-th : 0.330 0.223 0.446  ||  -0.1304 -0.5227 0.1707  || discrepancy=0.12 || select=2/3
-----------------------------------------------
000/019-th : 0.086 0.095 0.107 0.116 0.141 0.152 0.155 0.149  ||  -0.341 -0.241 -0.120 -0.041 0.154 0.233 0.250 0.213   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.130 0.129 0.130  ||  -0.038 -0.041 -0.019 -0.010 0.018 0.048 0.038 0.046   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.072 -0.043 -0.006 0.030 0.038 0.042 0.022 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.124 0.125 0.126 0.125 0.126 0.125 0.125  ||  -0.011 -0.010 0.002 0.011 0.001 0.008 0.001 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.123 0.123 0.125 0.128 0.127 0.129 0.127  ||  -0.049 -0.018 -0.016 0.002 0.025 0.018 0.032 0.014    || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.124 0.123 0.129 0.127 0.127 0.129  ||  -0.044 -0.028 0.000 -0.011 0.034 0.023 0.022 0.035    || dis=0.00 || select=7/8
006/019-th : 0.115 0.119 0.123 0.122 0.130 0.128 0.133 0.129  ||  -0.077 -0.043 -0.012 -0.022 0.039 0.030 0.063 0.036   || dis=0.00 || select=6/8
007/019-th : 0.108 0.104 0.106 0.117 0.128 0.142 0.145 0.151  ||  -0.146 -0.178 -0.158 -0.061 0.026 0.128 0.149 0.192   || dis=0.01 || select=7/8
008/019-th : 0.095 0.102 0.109 0.127 0.145 0.145 0.139 0.137  ||  -0.238 -0.171 -0.100 0.052 0.185 0.179 0.142 0.125    || dis=0.00 || select=4/8
009/019-th : 0.116 0.114 0.111 0.123 0.123 0.134 0.138 0.140  ||  -0.078 -0.088 -0.119 -0.019 -0.013 0.069 0.102 0.116  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.116 0.128 0.129 0.134 0.133 0.131  ||  -0.097 -0.070 -0.066 0.029 0.039 0.073 0.067 0.055    || dis=0.00 || select=5/8
011/019-th : 0.113 0.109 0.113 0.120 0.130 0.133 0.141 0.141  ||  -0.099 -0.132 -0.098 -0.035 0.044 0.065 0.127 0.127   || dis=0.00 || select=7/8
012/019-th : 0.120 0.120 0.119 0.126 0.130 0.127 0.129 0.130  ||  -0.035 -0.040 -0.047 0.015 0.043 0.022 0.034 0.041    || dis=0.00 || select=4/8
013/019-th : 0.088 0.091 0.099 0.110 0.128 0.145 0.168 0.171  ||  -0.333 -0.297 -0.211 -0.104 0.044 0.169 0.314 0.334   || dis=0.00 || select=7/8
014/019-th : 0.083 0.088 0.102 0.125 0.143 0.152 0.159 0.149  ||  -0.368 -0.310 -0.164 0.038 0.179 0.235 0.285 0.216    || dis=0.01 || select=6/8
015/019-th : 0.098 0.093 0.100 0.109 0.129 0.152 0.161 0.158  ||  -0.232 -0.277 -0.209 -0.124 0.051 0.208 0.270 0.252   || dis=0.00 || select=6/8
016/019-th : 0.081 0.097 0.109 0.123 0.146 0.151 0.149 0.145  ||  -0.399 -0.220 -0.103 0.022 0.192 0.227 0.213 0.185    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.117 0.125 0.132 0.137 0.138  ||  -0.055 -0.075 -0.076 -0.062 0.004 0.059 0.091 0.103   || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.113 0.121 0.132 0.137 0.144 0.164  ||  -0.328 -0.200 -0.079 -0.011 0.078 0.109 0.164 0.289   || dis=0.02 || select=7/8
[epoch=064/600] FLOP : 24.55 MB, ratio : 0.6016, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:16:15] [epoch=064/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.618 (1.618)  Prec@1 48.05 (48.05) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:16:21] [epoch=064/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.763 (2.112)  Prec@1 41.67 (37.37) Prec@5 83.33 (83.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.37 Prec@5 83.18 Error@1 62.63 Error@5 16.82 Loss:2.112
***[2020-01-29 06:16:21]*** VALID [epoch=064/600] loss = 2.112401, accuracy@1 = 37.37, accuracy@5 = 83.18 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:16:21]*** start epoch=065/600 Time Left: [04:50:40], LR=[0.097132 ~ 0.097132], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=65, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.859471653175837, FLOP=40.81
[Search] : epoch=065/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:16:22] [epoch=065/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.958 (0.958)  Prec@1 68.36 (68.36) Prec@5 95.31 (95.31) Acls-loss 0.939 (0.939) FLOP-Loss -2.484 (-2.484) Arch-Loss -4.028 (-4.028)
**TRAIN** [2020-01-29 06:16:47] [epoch=065/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.054 (0.941)  Prec@1 64.88 (67.64) Prec@5 94.64 (97.14) Acls-loss 0.747 (0.964) FLOP-Loss -2.485 (0.009) Arch-Loss -4.223 (0.982)
 **TRAIN** Prec@1 67.64 Prec@5 97.14 Error@1 32.36 Error@5 2.86 Base-Loss:0.941, Arch-Loss=0.982
***[2020-01-29 06:16:47]*** TRAIN [epoch=065/600] base-loss = 0.941071, arch-loss = 0.982187, accuracy-1 = 67.64, accuracy-5 = 97.14
[epoch=065/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 9, 14, 16, 14, 32, 22, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.01024)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.378 0.243 0.378  ||  0.0102 -0.4310 0.0105  || discrepancy=0.00 || select=2/3
001/003-th : 0.389 0.201 0.410  ||  -0.0027 -0.6623 0.0482  || discrepancy=0.02 || select=2/3
002/003-th : 0.330 0.222 0.448  ||  -0.1333 -0.5270 0.1741  || discrepancy=0.12 || select=2/3
-----------------------------------------------
000/019-th : 0.085 0.095 0.107 0.116 0.140 0.152 0.155 0.150  ||  -0.345 -0.243 -0.121 -0.039 0.153 0.235 0.252 0.215   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.126 0.131 0.129 0.130  ||  -0.039 -0.041 -0.018 -0.012 0.016 0.049 0.039 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.073 -0.044 -0.006 0.031 0.038 0.043 0.023 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.123 0.125 0.126 0.126 0.126 0.125 0.125  ||  -0.011 -0.012 0.001 0.010 0.004 0.008 0.002 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.125 0.129 0.127 0.129 0.127  ||  -0.051 -0.019 -0.018 0.004 0.030 0.019 0.033 0.015    || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.124 0.123 0.128 0.127 0.128 0.129  ||  -0.045 -0.028 -0.004 -0.012 0.029 0.023 0.024 0.036   || dis=0.00 || select=7/8
006/019-th : 0.115 0.119 0.123 0.122 0.130 0.129 0.133 0.129  ||  -0.078 -0.046 -0.012 -0.021 0.043 0.033 0.064 0.037   || dis=0.00 || select=6/8
007/019-th : 0.107 0.104 0.106 0.116 0.129 0.142 0.145 0.151  ||  -0.148 -0.178 -0.161 -0.070 0.033 0.130 0.150 0.194   || dis=0.01 || select=7/8
008/019-th : 0.095 0.102 0.109 0.128 0.145 0.144 0.140 0.137  ||  -0.238 -0.175 -0.102 0.054 0.184 0.178 0.144 0.127    || dis=0.00 || select=4/8
009/019-th : 0.116 0.114 0.110 0.123 0.124 0.134 0.138 0.140  ||  -0.078 -0.090 -0.123 -0.016 -0.008 0.073 0.101 0.117  || dis=0.00 || select=7/8
010/019-th : 0.113 0.116 0.116 0.127 0.129 0.134 0.133 0.132  ||  -0.100 -0.071 -0.066 0.020 0.038 0.075 0.070 0.057    || dis=0.00 || select=5/8
011/019-th : 0.112 0.109 0.113 0.119 0.130 0.133 0.142 0.142  ||  -0.103 -0.132 -0.099 -0.046 0.040 0.069 0.129 0.131   || dis=0.00 || select=7/8
012/019-th : 0.120 0.119 0.118 0.126 0.130 0.127 0.129 0.130  ||  -0.037 -0.042 -0.051 0.012 0.048 0.024 0.037 0.041    || dis=0.00 || select=4/8
013/019-th : 0.087 0.091 0.099 0.110 0.127 0.146 0.168 0.172  ||  -0.338 -0.300 -0.216 -0.104 0.040 0.175 0.316 0.339   || dis=0.00 || select=7/8
014/019-th : 0.082 0.087 0.101 0.125 0.143 0.152 0.160 0.149  ||  -0.374 -0.314 -0.168 0.042 0.180 0.239 0.288 0.219    || dis=0.01 || select=6/8
015/019-th : 0.097 0.092 0.100 0.108 0.129 0.152 0.162 0.159  ||  -0.235 -0.285 -0.212 -0.127 0.050 0.213 0.274 0.258   || dis=0.00 || select=6/8
016/019-th : 0.080 0.096 0.108 0.123 0.145 0.151 0.149 0.146  ||  -0.405 -0.223 -0.107 0.021 0.188 0.229 0.214 0.192    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.115 0.117 0.125 0.133 0.137 0.139  ||  -0.056 -0.074 -0.079 -0.066 0.000 0.060 0.091 0.105   || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.113 0.121 0.132 0.136 0.145 0.164  ||  -0.330 -0.202 -0.081 -0.016 0.076 0.107 0.171 0.290   || dis=0.02 || select=7/8
[epoch=065/600] FLOP : 31.01 MB, ratio : 0.7598, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:16:47] [epoch=065/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.536 (2.536)  Prec@1 30.08 (30.08) Prec@5 78.91 (78.91) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:16:54] [epoch=065/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.324 (2.273)  Prec@1 33.33 (35.85) Prec@5 75.60 (82.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.85 Prec@5 82.30 Error@1 64.15 Error@5 17.70 Loss:2.273
***[2020-01-29 06:16:54]*** VALID [epoch=065/600] loss = 2.272885, accuracy@1 = 35.85, accuracy@5 = 82.30 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:16:54]*** start epoch=066/600 Time Left: [04:50:05], LR=[0.097044 ~ 0.097044], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=66, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.855157883937853, FLOP=40.81
[Search] : epoch=066/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:16:54] [epoch=066/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.970 (0.970)  Prec@1 65.62 (65.62) Prec@5 96.48 (96.48) Acls-loss 0.976 (0.976) FLOP-Loss 2.485 (2.485) Arch-Loss 5.946 (5.946)
**TRAIN** [2020-01-29 06:17:19] [epoch=066/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.042 (0.917)  Prec@1 65.48 (68.41) Prec@5 96.43 (97.32) Acls-loss 0.836 (0.957) FLOP-Loss 2.487 (0.042) Arch-Loss 5.809 (1.042)
 **TRAIN** Prec@1 68.41 Prec@5 97.32 Error@1 31.59 Error@5 2.68 Base-Loss:0.917, Arch-Loss=1.042
***[2020-01-29 06:17:19]*** TRAIN [epoch=066/600] base-loss = 0.916720, arch-loss = 1.041750, accuracy-1 = 68.41, accuracy-5 = 97.32
[epoch=066/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 9, 14, 16, 14, 32, 22, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.552896)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.378 0.245 0.378  ||  0.0108 -0.4237 0.0102  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.200 0.410  ||  -0.0027 -0.6688 0.0487  || discrepancy=0.02 || select=2/3
002/003-th : 0.329 0.223 0.449  ||  -0.1346 -0.5252 0.1756  || discrepancy=0.12 || select=2/3
-----------------------------------------------
000/019-th : 0.085 0.094 0.107 0.117 0.139 0.152 0.155 0.150  ||  -0.348 -0.246 -0.116 -0.032 0.141 0.231 0.252 0.216   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.122 0.126 0.130 0.129 0.130  ||  -0.038 -0.041 -0.017 -0.015 0.016 0.048 0.039 0.047   || dis=0.00 || select=5/8
002/019-th : 0.116 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.073 -0.043 -0.005 0.032 0.038 0.042 0.023 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.123 0.125 0.126 0.126 0.126 0.125 0.125  ||  -0.011 -0.012 0.002 0.009 0.006 0.009 0.003 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.125 0.128 0.127 0.129 0.127  ||  -0.051 -0.019 -0.017 0.002 0.026 0.021 0.034 0.014    || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.124 0.123 0.128 0.128 0.128 0.129  ||  -0.047 -0.032 -0.004 -0.010 0.030 0.028 0.026 0.037   || dis=0.00 || select=7/8
006/019-th : 0.115 0.119 0.123 0.122 0.130 0.129 0.133 0.129  ||  -0.079 -0.047 -0.012 -0.018 0.044 0.035 0.064 0.036   || dis=0.00 || select=6/8
007/019-th : 0.107 0.104 0.106 0.117 0.128 0.142 0.145 0.151  ||  -0.148 -0.181 -0.161 -0.066 0.025 0.132 0.151 0.195   || dis=0.01 || select=7/8
008/019-th : 0.095 0.101 0.109 0.128 0.145 0.145 0.140 0.137  ||  -0.240 -0.177 -0.102 0.055 0.183 0.180 0.144 0.127    || dis=0.00 || select=4/8
009/019-th : 0.116 0.114 0.110 0.123 0.124 0.134 0.138 0.141  ||  -0.078 -0.092 -0.123 -0.013 -0.009 0.071 0.102 0.118  || dis=0.00 || select=7/8
010/019-th : 0.112 0.116 0.116 0.128 0.129 0.134 0.133 0.132  ||  -0.101 -0.072 -0.066 0.028 0.041 0.075 0.069 0.058    || dis=0.00 || select=5/8
011/019-th : 0.112 0.109 0.112 0.119 0.131 0.133 0.141 0.142  ||  -0.104 -0.134 -0.101 -0.048 0.051 0.069 0.128 0.133   || dis=0.00 || select=7/8
012/019-th : 0.120 0.119 0.118 0.125 0.130 0.128 0.129 0.130  ||  -0.038 -0.042 -0.052 0.008 0.047 0.026 0.039 0.041    || dis=0.00 || select=4/8
013/019-th : 0.087 0.091 0.098 0.110 0.127 0.146 0.168 0.173  ||  -0.339 -0.301 -0.219 -0.107 0.036 0.176 0.315 0.344   || dis=0.00 || select=7/8
014/019-th : 0.082 0.087 0.102 0.124 0.143 0.152 0.160 0.149  ||  -0.376 -0.318 -0.163 0.038 0.179 0.239 0.289 0.220    || dis=0.01 || select=6/8
015/019-th : 0.097 0.092 0.100 0.108 0.130 0.151 0.163 0.160  ||  -0.235 -0.291 -0.212 -0.133 0.057 0.207 0.280 0.261   || dis=0.00 || select=6/8
016/019-th : 0.080 0.096 0.109 0.123 0.145 0.152 0.149 0.146  ||  -0.409 -0.225 -0.103 0.018 0.184 0.230 0.215 0.194    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.115 0.118 0.125 0.132 0.137 0.139  ||  -0.056 -0.073 -0.078 -0.061 0.005 0.056 0.091 0.105   || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.113 0.120 0.133 0.136 0.146 0.164  ||  -0.330 -0.204 -0.081 -0.021 0.080 0.106 0.172 0.292   || dis=0.02 || select=7/8
[epoch=066/600] FLOP : 24.55 MB, ratio : 0.6016, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:17:20] [epoch=066/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.389 (2.389)  Prec@1 22.27 (22.27) Prec@5 68.75 (68.75) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:17:26] [epoch=066/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.080 (2.172)  Prec@1 32.74 (35.64) Prec@5 79.17 (81.63) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.64 Prec@5 81.63 Error@1 64.36 Error@5 18.37 Loss:2.172
***[2020-01-29 06:17:26]*** VALID [epoch=066/600] loss = 2.172259, accuracy@1 = 35.64, accuracy@5 = 81.63 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:17:26]*** start epoch=067/600 Time Left: [04:49:29], LR=[0.096955 ~ 0.096955], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=67, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.850780917632037, FLOP=40.81
[Search] : epoch=067/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:17:27] [epoch=067/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.897 (0.897)  Prec@1 68.36 (68.36) Prec@5 97.27 (97.27) Acls-loss 0.807 (0.807) FLOP-Loss -2.486 (-2.486) Arch-Loss -4.166 (-4.166)
**TRAIN** [2020-01-29 06:17:52] [epoch=067/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.988 (0.947)  Prec@1 65.48 (67.40) Prec@5 96.43 (96.96) Acls-loss 1.022 (0.966) FLOP-Loss -2.487 (0.009) Arch-Loss -3.951 (0.984)
 **TRAIN** Prec@1 67.40 Prec@5 96.96 Error@1 32.60 Error@5 3.04 Base-Loss:0.947, Arch-Loss=0.984
***[2020-01-29 06:17:52]*** TRAIN [epoch=067/600] base-loss = 0.947031, arch-loss = 0.983544, accuracy-1 = 67.40, accuracy-5 = 96.96
[epoch=067/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 9, 14, 16, 14, 32, 25, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.865216)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.379 0.243 0.378  ||  0.0111 -0.4341 0.0103  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.200 0.410  ||  -0.0029 -0.6697 0.0494  || discrepancy=0.02 || select=2/3
002/003-th : 0.328 0.222 0.449  ||  -0.1362 -0.5271 0.1775  || discrepancy=0.12 || select=2/3
-----------------------------------------------
000/019-th : 0.084 0.094 0.108 0.116 0.141 0.152 0.155 0.150  ||  -0.355 -0.251 -0.112 -0.034 0.162 0.237 0.254 0.218   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.127 0.130 0.129 0.130  ||  -0.038 -0.041 -0.018 -0.014 0.018 0.047 0.039 0.047   || dis=0.00 || select=5/8
002/019-th : 0.115 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.073 -0.043 -0.004 0.032 0.036 0.043 0.023 0.026    || dis=0.00 || select=5/8
003/019-th : 0.124 0.123 0.125 0.126 0.125 0.126 0.125 0.125  ||  -0.011 -0.013 0.004 0.010 0.003 0.007 0.003 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.125 0.128 0.127 0.129 0.127  ||  -0.051 -0.019 -0.015 -0.001 0.026 0.021 0.035 0.014   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.124 0.123 0.129 0.128 0.128 0.129  ||  -0.047 -0.033 -0.007 -0.012 0.036 0.027 0.027 0.038   || dis=0.00 || select=7/8
006/019-th : 0.115 0.119 0.123 0.122 0.130 0.129 0.133 0.129  ||  -0.080 -0.047 -0.013 -0.017 0.045 0.035 0.065 0.037   || dis=0.00 || select=6/8
007/019-th : 0.107 0.104 0.106 0.117 0.127 0.142 0.145 0.151  ||  -0.151 -0.183 -0.161 -0.058 0.022 0.133 0.153 0.195   || dis=0.01 || select=7/8
008/019-th : 0.095 0.101 0.109 0.128 0.143 0.145 0.140 0.138  ||  -0.246 -0.178 -0.101 0.054 0.167 0.183 0.146 0.132    || dis=0.00 || select=5/8
009/019-th : 0.115 0.114 0.110 0.123 0.124 0.134 0.139 0.141  ||  -0.079 -0.093 -0.127 -0.012 -0.010 0.073 0.104 0.120  || dis=0.00 || select=7/8
010/019-th : 0.112 0.116 0.116 0.128 0.129 0.134 0.133 0.132  ||  -0.102 -0.072 -0.067 0.028 0.040 0.077 0.070 0.058    || dis=0.00 || select=5/8
011/019-th : 0.112 0.109 0.112 0.119 0.131 0.134 0.141 0.142  ||  -0.106 -0.134 -0.104 -0.045 0.053 0.075 0.128 0.134   || dis=0.00 || select=7/8
012/019-th : 0.120 0.119 0.118 0.125 0.131 0.128 0.130 0.129  ||  -0.038 -0.045 -0.051 0.007 0.048 0.031 0.040 0.040    || dis=0.00 || select=4/8
013/019-th : 0.087 0.090 0.098 0.110 0.128 0.146 0.168 0.173  ||  -0.341 -0.305 -0.218 -0.108 0.043 0.178 0.315 0.346   || dis=0.00 || select=7/8
014/019-th : 0.082 0.087 0.101 0.124 0.144 0.152 0.160 0.150  ||  -0.378 -0.320 -0.168 0.033 0.183 0.237 0.292 0.223    || dis=0.01 || select=6/8
015/019-th : 0.096 0.092 0.099 0.107 0.131 0.152 0.163 0.160  ||  -0.244 -0.291 -0.217 -0.136 0.065 0.212 0.285 0.265   || dis=0.00 || select=6/8
016/019-th : 0.080 0.096 0.108 0.122 0.146 0.152 0.150 0.147  ||  -0.411 -0.227 -0.107 0.012 0.190 0.231 0.219 0.196    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.117 0.126 0.132 0.137 0.139  ||  -0.056 -0.073 -0.077 -0.064 0.009 0.055 0.090 0.106   || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.113 0.120 0.132 0.137 0.146 0.165  ||  -0.336 -0.203 -0.080 -0.024 0.075 0.107 0.174 0.294   || dis=0.02 || select=7/8
[epoch=067/600] FLOP : 24.87 MB, ratio : 0.6092, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:17:52] [epoch=067/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.970 (1.970)  Prec@1 35.94 (35.94) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:17:58] [epoch=067/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.310 (2.284)  Prec@1 29.17 (35.72) Prec@5 79.17 (82.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.72 Prec@5 82.21 Error@1 64.28 Error@5 17.79 Loss:2.284
***[2020-01-29 06:17:58]*** VALID [epoch=067/600] loss = 2.284034, accuracy@1 = 35.72, accuracy@5 = 82.21 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:17:59]*** start epoch=068/600 Time Left: [04:48:56], LR=[0.096864 ~ 0.096864], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=68, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.846340874255135, FLOP=40.81
[Search] : epoch=068/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:17:59] [epoch=068/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.861 (0.861)  Prec@1 67.97 (67.97) Prec@5 98.83 (98.83) Acls-loss 0.940 (0.940) FLOP-Loss -2.487 (-2.487) Arch-Loss -4.034 (-4.034)
**TRAIN** [2020-01-29 06:18:24] [epoch=068/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.113 (0.930)  Prec@1 67.26 (67.83) Prec@5 94.05 (97.26) Acls-loss 1.028 (0.952) FLOP-Loss -2.489 (0.009) Arch-Loss -3.950 (0.970)
 **TRAIN** Prec@1 67.83 Prec@5 97.26 Error@1 32.17 Error@5 2.74 Base-Loss:0.930, Arch-Loss=0.970
***[2020-01-29 06:18:24]*** TRAIN [epoch=068/600] base-loss = 0.930208, arch-loss = 0.970143, accuracy-1 = 67.83, accuracy-5 = 97.26
[epoch=068/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 9, 14, 16, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 32.0464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.378 0.243 0.379  ||  0.0106 -0.4322 0.0112  || discrepancy=0.00 || select=2/3
001/003-th : 0.390 0.198 0.412  ||  -0.0038 -0.6842 0.0510  || discrepancy=0.02 || select=2/3
002/003-th : 0.327 0.222 0.450  ||  -0.1389 -0.5257 0.1803  || discrepancy=0.12 || select=2/3
-----------------------------------------------
000/019-th : 0.084 0.094 0.107 0.116 0.141 0.153 0.155 0.150  ||  -0.361 -0.252 -0.116 -0.037 0.159 0.239 0.256 0.223   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.122 0.127 0.130 0.129 0.130  ||  -0.039 -0.042 -0.017 -0.016 0.020 0.047 0.039 0.047   || dis=0.00 || select=5/8
002/019-th : 0.115 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.074 -0.044 -0.006 0.028 0.035 0.044 0.025 0.028    || dis=0.00 || select=5/8
003/019-th : 0.124 0.123 0.125 0.126 0.125 0.126 0.125 0.125  ||  -0.012 -0.013 0.003 0.009 0.004 0.008 0.003 -0.002    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.128 0.127 0.130 0.127  ||  -0.052 -0.022 -0.016 -0.004 0.028 0.021 0.037 0.015   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.123 0.129 0.128 0.128 0.130  ||  -0.049 -0.036 -0.010 -0.008 0.036 0.025 0.029 0.040   || dis=0.00 || select=7/8
006/019-th : 0.115 0.118 0.123 0.122 0.130 0.129 0.133 0.129  ||  -0.082 -0.049 -0.014 -0.017 0.043 0.038 0.067 0.038   || dis=0.00 || select=6/8
007/019-th : 0.107 0.104 0.106 0.119 0.124 0.143 0.146 0.152  ||  -0.157 -0.182 -0.162 -0.049 -0.008 0.138 0.158 0.198  || dis=0.01 || select=7/8
008/019-th : 0.095 0.101 0.110 0.128 0.141 0.146 0.141 0.139  ||  -0.248 -0.180 -0.099 0.053 0.146 0.182 0.147 0.136    || dis=0.01 || select=5/8
009/019-th : 0.115 0.113 0.110 0.122 0.124 0.135 0.139 0.141  ||  -0.081 -0.096 -0.128 -0.020 -0.004 0.075 0.106 0.122  || dis=0.00 || select=7/8
010/019-th : 0.112 0.115 0.117 0.127 0.129 0.134 0.134 0.132  ||  -0.104 -0.073 -0.063 0.019 0.041 0.078 0.072 0.058    || dis=0.00 || select=5/8
011/019-th : 0.111 0.109 0.112 0.119 0.131 0.134 0.141 0.142  ||  -0.109 -0.135 -0.107 -0.038 0.057 0.079 0.128 0.135   || dis=0.00 || select=7/8
012/019-th : 0.120 0.119 0.118 0.125 0.130 0.129 0.130 0.130  ||  -0.039 -0.047 -0.053 0.004 0.042 0.037 0.042 0.041    || dis=0.00 || select=6/8
013/019-th : 0.087 0.090 0.098 0.109 0.128 0.147 0.168 0.174  ||  -0.344 -0.310 -0.219 -0.118 0.048 0.183 0.318 0.350   || dis=0.01 || select=7/8
014/019-th : 0.082 0.087 0.101 0.124 0.143 0.151 0.161 0.150  ||  -0.381 -0.323 -0.168 0.033 0.179 0.233 0.296 0.227    || dis=0.01 || select=6/8
015/019-th : 0.094 0.092 0.099 0.108 0.130 0.152 0.164 0.161  ||  -0.269 -0.288 -0.216 -0.122 0.061 0.215 0.294 0.273   || dis=0.00 || select=6/8
016/019-th : 0.080 0.096 0.108 0.121 0.144 0.152 0.151 0.147  ||  -0.413 -0.230 -0.108 0.004 0.178 0.232 0.223 0.199    || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.117 0.125 0.132 0.137 0.139  ||  -0.058 -0.072 -0.078 -0.064 0.004 0.056 0.091 0.107   || dis=0.00 || select=7/8
018/019-th : 0.087 0.100 0.113 0.120 0.132 0.137 0.146 0.165  ||  -0.337 -0.206 -0.085 -0.022 0.078 0.112 0.177 0.295   || dis=0.02 || select=7/8
[epoch=068/600] FLOP : 32.05 MB, ratio : 0.7852, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:18:24] [epoch=068/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.907 (1.907)  Prec@1 42.58 (42.58) Prec@5 91.41 (91.41) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:18:30] [epoch=068/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.709 (2.317)  Prec@1 38.10 (36.84) Prec@5 88.10 (82.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.84 Prec@5 82.65 Error@1 63.16 Error@5 17.35 Loss:2.317
***[2020-01-29 06:18:30]*** VALID [epoch=068/600] loss = 2.316901, accuracy@1 = 36.84, accuracy@5 = 82.65 | Best-Valid-Acc@1=38.55, Error@1=61.45
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:18:31]*** start epoch=069/600 Time Left: [04:48:20], LR=[0.096772 ~ 0.096772], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=69, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.841837875533176, FLOP=40.81
[Search] : epoch=069/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:18:31] [epoch=069/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.894 (0.894)  Prec@1 67.97 (67.97) Prec@5 99.22 (99.22) Acls-loss 0.865 (0.865) FLOP-Loss 2.489 (2.489) Arch-Loss 5.843 (5.843)
**TRAIN** [2020-01-29 06:18:56] [epoch=069/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.957 (0.932)  Prec@1 69.05 (67.33) Prec@5 94.64 (97.08) Acls-loss 0.902 (0.941) FLOP-Loss -2.490 (0.034) Arch-Loss -4.077 (1.010)
 **TRAIN** Prec@1 67.33 Prec@5 97.08 Error@1 32.67 Error@5 2.92 Base-Loss:0.932, Arch-Loss=1.010
***[2020-01-29 06:18:56]*** TRAIN [epoch=069/600] base-loss = 0.932235, arch-loss = 1.010240, accuracy-1 = 67.33, accuracy-5 = 97.08
[epoch=069/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 11, 14, 32, 25, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 30.990784)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.379 0.242 0.379  ||  0.0110 -0.4357 0.0111  || discrepancy=0.00 || select=2/3
001/003-th : 0.390 0.199 0.411  ||  -0.0034 -0.6759 0.0510  || discrepancy=0.02 || select=2/3
002/003-th : 0.327 0.222 0.451  ||  -0.1401 -0.5271 0.1819  || discrepancy=0.12 || select=2/3
-----------------------------------------------
000/019-th : 0.084 0.094 0.107 0.117 0.140 0.153 0.156 0.150  ||  -0.362 -0.252 -0.119 -0.032 0.148 0.239 0.259 0.222   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.122 0.127 0.130 0.129 0.130  ||  -0.039 -0.041 -0.017 -0.016 0.021 0.046 0.039 0.047   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.074 -0.044 -0.004 0.026 0.035 0.044 0.024 0.028    || dis=0.00 || select=5/8
003/019-th : 0.123 0.123 0.125 0.126 0.126 0.126 0.126 0.125  ||  -0.012 -0.013 0.003 0.007 0.006 0.007 0.004 -0.002    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.122 0.125 0.129 0.128 0.130 0.127  ||  -0.051 -0.023 -0.021 -0.001 0.029 0.022 0.038 0.015   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.123 0.130 0.128 0.128 0.129  ||  -0.049 -0.038 -0.009 -0.011 0.041 0.029 0.029 0.039   || dis=0.00 || select=4/8
006/019-th : 0.115 0.118 0.123 0.123 0.130 0.129 0.133 0.129  ||  -0.082 -0.051 -0.014 -0.014 0.047 0.038 0.067 0.039   || dis=0.00 || select=6/8
007/019-th : 0.106 0.103 0.105 0.120 0.124 0.144 0.147 0.152  ||  -0.157 -0.189 -0.168 -0.040 -0.004 0.142 0.164 0.198  || dis=0.01 || select=7/8
008/019-th : 0.094 0.101 0.110 0.129 0.141 0.145 0.140 0.139  ||  -0.252 -0.184 -0.097 0.059 0.149 0.182 0.146 0.140    || dis=0.00 || select=5/8
009/019-th : 0.115 0.113 0.110 0.124 0.125 0.134 0.139 0.141  ||  -0.083 -0.098 -0.128 -0.009 -0.002 0.073 0.108 0.123  || dis=0.00 || select=7/8
010/019-th : 0.112 0.115 0.116 0.127 0.129 0.135 0.134 0.132  ||  -0.105 -0.075 -0.066 0.023 0.041 0.081 0.072 0.058    || dis=0.00 || select=5/8
011/019-th : 0.111 0.108 0.111 0.120 0.132 0.134 0.141 0.142  ||  -0.111 -0.136 -0.110 -0.035 0.065 0.079 0.130 0.135   || dis=0.00 || select=7/8
012/019-th : 0.119 0.119 0.118 0.125 0.131 0.129 0.130 0.130  ||  -0.041 -0.048 -0.053 0.001 0.048 0.039 0.043 0.042    || dis=0.00 || select=4/8
013/019-th : 0.087 0.089 0.098 0.108 0.128 0.147 0.169 0.174  ||  -0.344 -0.316 -0.222 -0.126 0.044 0.184 0.326 0.353   || dis=0.00 || select=7/8
014/019-th : 0.081 0.086 0.101 0.124 0.144 0.152 0.162 0.150  ||  -0.386 -0.328 -0.170 0.035 0.185 0.236 0.300 0.229    || dis=0.01 || select=6/8
015/019-th : 0.093 0.091 0.098 0.108 0.131 0.152 0.165 0.161  ||  -0.271 -0.294 -0.219 -0.121 0.071 0.218 0.296 0.275   || dis=0.00 || select=6/8
016/019-th : 0.080 0.096 0.109 0.121 0.142 0.153 0.152 0.148  ||  -0.417 -0.230 -0.103 -0.002 0.161 0.233 0.226 0.200   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.125 0.132 0.137 0.139  ||  -0.057 -0.072 -0.076 -0.058 0.002 0.053 0.091 0.107   || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.112 0.120 0.132 0.138 0.146 0.164  ||  -0.334 -0.206 -0.089 -0.021 0.076 0.120 0.175 0.293   || dis=0.02 || select=7/8
[epoch=069/600] FLOP : 30.99 MB, ratio : 0.7593, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:18:56] [epoch=069/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.629 (1.629)  Prec@1 42.58 (42.58) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:19:02] [epoch=069/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.346 (2.109)  Prec@1 30.36 (39.62) Prec@5 81.55 (84.82) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.62 Prec@5 84.82 Error@1 60.38 Error@5 15.18 Loss:2.109
***[2020-01-29 06:19:02]*** VALID [epoch=069/600] loss = 2.108993, accuracy@1 = 39.62, accuracy@5 = 84.82 | Best-Valid-Acc@1=38.55, Error@1=61.45
Currently, the best validation accuracy found at 069-epoch :: acc@1=39.62, acc@5=84.82, error@1=60.38, error@5=15.18, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:19:03]*** start epoch=070/600 Time Left: [04:47:42], LR=[0.096679 ~ 0.096679], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=70, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.837272044918144, FLOP=40.81
[Search] : epoch=070/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:19:03] [epoch=070/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.883 (0.883)  Prec@1 67.19 (67.19) Prec@5 96.48 (96.48) Acls-loss 0.961 (0.961) FLOP-Loss 2.490 (2.490) Arch-Loss 5.941 (5.941)
**TRAIN** [2020-01-29 06:19:28] [epoch=070/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 1.092 (0.914)  Prec@1 61.31 (68.22) Prec@5 96.43 (97.44) Acls-loss 0.989 (0.947) FLOP-Loss -2.491 (0.009) Arch-Loss -3.993 (0.965)
 **TRAIN** Prec@1 68.22 Prec@5 97.44 Error@1 31.78 Error@5 2.56 Base-Loss:0.914, Arch-Loss=0.965
***[2020-01-29 06:19:28]*** TRAIN [epoch=070/600] base-loss = 0.914224, arch-loss = 0.965275, accuracy-1 = 68.22, accuracy-5 = 97.44
[epoch=070/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 12, 14, 11, 14, 32, 25, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.709632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.377 0.246 0.377  ||  0.0109 -0.4162 0.0113  || discrepancy=0.00 || select=2/3
001/003-th : 0.389 0.200 0.411  ||  -0.0039 -0.6671 0.0517  || discrepancy=0.02 || select=2/3
002/003-th : 0.326 0.222 0.452  ||  -0.1432 -0.5255 0.1850  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.084 0.094 0.107 0.117 0.138 0.153 0.156 0.151  ||  -0.366 -0.252 -0.119 -0.028 0.131 0.240 0.260 0.225   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.122 0.127 0.130 0.129 0.130  ||  -0.039 -0.041 -0.018 -0.017 0.022 0.046 0.039 0.047   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.075 -0.044 -0.005 0.026 0.036 0.043 0.025 0.028    || dis=0.00 || select=5/8
003/019-th : 0.123 0.123 0.125 0.126 0.125 0.126 0.126 0.125  ||  -0.013 -0.014 0.003 0.008 0.004 0.009 0.005 -0.002    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.122 0.124 0.129 0.128 0.130 0.127  ||  -0.051 -0.024 -0.022 -0.003 0.032 0.022 0.038 0.016   || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.123 0.123 0.130 0.128 0.128 0.130  ||  -0.050 -0.038 -0.012 -0.016 0.041 0.030 0.031 0.040   || dis=0.00 || select=4/8
006/019-th : 0.114 0.118 0.123 0.122 0.131 0.129 0.133 0.129  ||  -0.083 -0.052 -0.013 -0.019 0.050 0.038 0.067 0.040   || dis=0.00 || select=6/8
007/019-th : 0.106 0.103 0.105 0.119 0.123 0.143 0.147 0.153  ||  -0.162 -0.189 -0.168 -0.043 -0.009 0.139 0.167 0.203  || dis=0.01 || select=7/8
008/019-th : 0.093 0.100 0.109 0.129 0.144 0.145 0.141 0.139  ||  -0.259 -0.185 -0.105 0.063 0.171 0.180 0.151 0.142    || dis=0.00 || select=5/8
009/019-th : 0.115 0.113 0.109 0.123 0.126 0.134 0.139 0.141  ||  -0.084 -0.099 -0.131 -0.013 0.012 0.077 0.109 0.123   || dis=0.00 || select=7/8
010/019-th : 0.111 0.115 0.116 0.128 0.131 0.134 0.134 0.132  ||  -0.108 -0.078 -0.066 0.030 0.052 0.080 0.074 0.060    || dis=0.00 || select=5/8
011/019-th : 0.111 0.108 0.111 0.119 0.131 0.135 0.141 0.143  ||  -0.111 -0.138 -0.108 -0.043 0.055 0.081 0.130 0.138   || dis=0.00 || select=7/8
012/019-th : 0.119 0.119 0.118 0.124 0.131 0.130 0.130 0.130  ||  -0.042 -0.048 -0.054 -0.004 0.051 0.041 0.042 0.043   || dis=0.00 || select=4/8
013/019-th : 0.086 0.089 0.098 0.108 0.126 0.148 0.170 0.175  ||  -0.347 -0.320 -0.225 -0.126 0.033 0.191 0.329 0.356   || dis=0.00 || select=7/8
014/019-th : 0.081 0.086 0.101 0.123 0.145 0.152 0.161 0.151  ||  -0.393 -0.330 -0.174 0.031 0.190 0.241 0.301 0.234    || dis=0.01 || select=6/8
015/019-th : 0.093 0.091 0.097 0.108 0.131 0.152 0.165 0.162  ||  -0.272 -0.298 -0.233 -0.125 0.071 0.220 0.300 0.283   || dis=0.00 || select=6/8
016/019-th : 0.079 0.096 0.108 0.120 0.144 0.153 0.151 0.148  ||  -0.423 -0.232 -0.107 -0.004 0.178 0.235 0.226 0.205   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.124 0.132 0.137 0.139  ||  -0.058 -0.073 -0.078 -0.057 -0.004 0.053 0.091 0.108  || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.113 0.120 0.132 0.138 0.146 0.165  ||  -0.339 -0.209 -0.083 -0.023 0.072 0.119 0.177 0.295   || dis=0.02 || select=7/8
[epoch=070/600] FLOP : 31.71 MB, ratio : 0.7769, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:19:29] [epoch=070/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.029 (2.029)  Prec@1 31.25 (31.25) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:19:35] [epoch=070/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.216 (2.084)  Prec@1 38.69 (37.63) Prec@5 85.12 (84.01) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.63 Prec@5 84.01 Error@1 62.37 Error@5 15.99 Loss:2.084
***[2020-01-29 06:19:35]*** VALID [epoch=070/600] loss = 2.084156, accuracy@1 = 37.63, accuracy@5 = 84.01 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:19:35]*** start epoch=071/600 Time Left: [04:47:08], LR=[0.096585 ~ 0.096585], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=71, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.832643507584595, FLOP=40.81
[Search] : epoch=071/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:19:35] [epoch=071/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 1.084 (1.084)  Prec@1 66.02 (66.02) Prec@5 95.31 (95.31) Acls-loss 0.949 (0.949) FLOP-Loss 2.492 (2.492) Arch-Loss 5.932 (5.932)
**TRAIN** [2020-01-29 06:20:00] [epoch=071/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.865 (0.936)  Prec@1 72.62 (67.56) Prec@5 98.81 (97.13) Acls-loss 0.927 (0.949) FLOP-Loss -2.492 (0.060) Arch-Loss -4.056 (1.069)
 **TRAIN** Prec@1 67.56 Prec@5 97.13 Error@1 32.44 Error@5 2.87 Base-Loss:0.936, Arch-Loss=1.069
***[2020-01-29 06:20:00]*** TRAIN [epoch=071/600] base-loss = 0.935893, arch-loss = 1.068889, accuracy-1 = 67.56, accuracy-5 = 97.13
[epoch=071/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 12, 14, 11, 14, 32, 25, 32, 25, 32, 22, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.82368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.380 0.241 0.379  ||  0.0116 -0.4426 0.0113  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.199 0.411  ||  -0.0031 -0.6752 0.0516  || discrepancy=0.02 || select=2/3
002/003-th : 0.325 0.222 0.453  ||  -0.1446 -0.5276 0.1868  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.083 0.094 0.107 0.117 0.137 0.154 0.157 0.151  ||  -0.373 -0.252 -0.116 -0.026 0.129 0.248 0.262 0.225   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.122 0.127 0.130 0.129 0.130  ||  -0.038 -0.041 -0.016 -0.016 0.019 0.045 0.039 0.046   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.124 0.127 0.129 0.130 0.127 0.128  ||  -0.075 -0.042 -0.004 0.024 0.037 0.043 0.024 0.027    || dis=0.00 || select=5/8
003/019-th : 0.124 0.123 0.126 0.126 0.125 0.126 0.126 0.125  ||  -0.012 -0.014 0.004 0.008 0.002 0.008 0.006 -0.003    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.124 0.129 0.128 0.130 0.127  ||  -0.050 -0.025 -0.019 -0.006 0.032 0.025 0.038 0.015   || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.123 0.123 0.130 0.128 0.128 0.130  ||  -0.050 -0.037 -0.013 -0.014 0.042 0.028 0.030 0.040   || dis=0.00 || select=4/8
006/019-th : 0.114 0.118 0.123 0.122 0.130 0.129 0.133 0.130  ||  -0.084 -0.053 -0.014 -0.020 0.047 0.037 0.068 0.041   || dis=0.00 || select=6/8
007/019-th : 0.105 0.103 0.105 0.120 0.124 0.143 0.147 0.152  ||  -0.166 -0.192 -0.165 -0.037 -0.004 0.141 0.169 0.204  || dis=0.01 || select=7/8
008/019-th : 0.093 0.100 0.109 0.129 0.142 0.145 0.141 0.140  ||  -0.264 -0.187 -0.103 0.064 0.162 0.182 0.155 0.144    || dis=0.00 || select=5/8
009/019-th : 0.114 0.113 0.109 0.124 0.126 0.134 0.139 0.141  ||  -0.084 -0.101 -0.130 -0.005 0.009 0.075 0.107 0.124   || dis=0.00 || select=7/8
010/019-th : 0.112 0.115 0.117 0.128 0.130 0.134 0.134 0.132  ||  -0.105 -0.079 -0.062 0.034 0.046 0.076 0.074 0.058    || dis=0.00 || select=5/8
011/019-th : 0.111 0.108 0.112 0.120 0.131 0.135 0.141 0.142  ||  -0.111 -0.139 -0.107 -0.033 0.054 0.080 0.129 0.137   || dis=0.00 || select=7/8
012/019-th : 0.119 0.119 0.118 0.124 0.130 0.130 0.130 0.130  ||  -0.042 -0.048 -0.053 -0.006 0.045 0.043 0.043 0.042   || dis=0.00 || select=4/8
013/019-th : 0.086 0.089 0.098 0.107 0.127 0.147 0.171 0.175  ||  -0.351 -0.321 -0.223 -0.134 0.038 0.186 0.332 0.361   || dis=0.00 || select=7/8
014/019-th : 0.080 0.086 0.101 0.123 0.147 0.151 0.161 0.151  ||  -0.395 -0.331 -0.172 0.029 0.207 0.233 0.300 0.237    || dis=0.01 || select=6/8
015/019-th : 0.093 0.091 0.097 0.108 0.130 0.152 0.166 0.163  ||  -0.275 -0.299 -0.232 -0.127 0.057 0.215 0.304 0.288   || dis=0.00 || select=6/8
016/019-th : 0.079 0.095 0.109 0.120 0.144 0.153 0.151 0.148  ||  -0.427 -0.234 -0.105 -0.002 0.180 0.238 0.226 0.205   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.124 0.132 0.137 0.139  ||  -0.057 -0.073 -0.076 -0.054 -0.004 0.052 0.090 0.107  || dis=0.00 || select=7/8
018/019-th : 0.087 0.100 0.112 0.120 0.131 0.138 0.147 0.165  ||  -0.344 -0.207 -0.090 -0.018 0.065 0.118 0.181 0.297   || dis=0.02 || select=7/8
[epoch=071/600] FLOP : 25.82 MB, ratio : 0.6327, Expected-ratio : 0.7000, Discrepancy : 0.009
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:20:01] [epoch=071/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.859 (1.859)  Prec@1 39.45 (39.45) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:20:07] [epoch=071/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.613 (2.234)  Prec@1 45.83 (38.68) Prec@5 87.50 (83.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.68 Prec@5 83.14 Error@1 61.32 Error@5 16.86 Loss:2.234
***[2020-01-29 06:20:07]*** VALID [epoch=071/600] loss = 2.233802, accuracy@1 = 38.68, accuracy@5 = 83.14 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:20:07]*** start epoch=072/600 Time Left: [04:46:31], LR=[0.096489 ~ 0.096489], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=72, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.827952390426216, FLOP=40.81
[Search] : epoch=072/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:20:07] [epoch=072/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.965 (0.965)  Prec@1 65.62 (65.62) Prec@5 96.88 (96.88) Acls-loss 1.012 (1.012) FLOP-Loss -2.492 (-2.492) Arch-Loss -3.972 (-3.972)
**TRAIN** [2020-01-29 06:20:32] [epoch=072/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.746 (0.926)  Prec@1 75.60 (67.80) Prec@5 98.21 (97.30) Acls-loss 1.089 (0.949) FLOP-Loss 0.000 (0.026) Arch-Loss 1.089 (1.000)
 **TRAIN** Prec@1 67.80 Prec@5 97.30 Error@1 32.20 Error@5 2.70 Base-Loss:0.926, Arch-Loss=1.000
***[2020-01-29 06:20:32]*** TRAIN [epoch=072/600] base-loss = 0.926035, arch-loss = 1.000066, accuracy-1 = 67.80, accuracy-5 = 97.30
[epoch=072/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 12, 14, 16, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.54752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.382 0.236 0.382  ||  0.0120 -0.4686 0.0116  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.197 0.412  ||  -0.0034 -0.6845 0.0524  || discrepancy=0.02 || select=2/3
002/003-th : 0.325 0.221 0.454  ||  -0.1464 -0.5309 0.1890  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.083 0.094 0.108 0.117 0.136 0.155 0.156 0.151  ||  -0.376 -0.251 -0.114 -0.029 0.124 0.253 0.260 0.226   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.127 0.130 0.129 0.130  ||  -0.038 -0.041 -0.016 -0.014 0.019 0.044 0.039 0.046   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.124 0.127 0.129 0.130 0.127 0.128  ||  -0.076 -0.041 -0.003 0.022 0.039 0.043 0.024 0.027    || dis=0.00 || select=5/8
003/019-th : 0.123 0.123 0.125 0.126 0.125 0.126 0.126 0.125  ||  -0.012 -0.013 0.004 0.007 0.002 0.008 0.006 -0.003    || dis=0.00 || select=5/8
004/019-th : 0.119 0.122 0.123 0.124 0.129 0.128 0.130 0.127  ||  -0.051 -0.025 -0.019 -0.006 0.029 0.022 0.038 0.016   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.123 0.129 0.128 0.128 0.130  ||  -0.049 -0.036 -0.015 -0.017 0.038 0.030 0.030 0.039   || dis=0.00 || select=7/8
006/019-th : 0.115 0.118 0.122 0.122 0.130 0.129 0.133 0.130  ||  -0.083 -0.055 -0.017 -0.019 0.046 0.039 0.068 0.043   || dis=0.00 || select=6/8
007/019-th : 0.105 0.102 0.105 0.121 0.125 0.142 0.147 0.152  ||  -0.171 -0.197 -0.163 -0.025 0.011 0.136 0.172 0.206   || dis=0.01 || select=7/8
008/019-th : 0.093 0.100 0.109 0.129 0.142 0.146 0.141 0.140  ||  -0.266 -0.192 -0.102 0.066 0.158 0.186 0.154 0.147    || dis=0.00 || select=5/8
009/019-th : 0.114 0.112 0.109 0.125 0.126 0.134 0.139 0.141  ||  -0.087 -0.103 -0.129 0.001 0.008 0.074 0.108 0.127    || dis=0.00 || select=7/8
010/019-th : 0.112 0.115 0.117 0.127 0.130 0.134 0.134 0.132  ||  -0.106 -0.081 -0.057 0.024 0.044 0.078 0.073 0.060    || dis=0.00 || select=5/8
011/019-th : 0.111 0.108 0.112 0.120 0.130 0.135 0.141 0.143  ||  -0.112 -0.139 -0.107 -0.031 0.046 0.079 0.129 0.140   || dis=0.00 || select=7/8
012/019-th : 0.120 0.119 0.118 0.123 0.130 0.130 0.130 0.130  ||  -0.042 -0.048 -0.054 -0.011 0.042 0.039 0.045 0.043   || dis=0.00 || select=6/8
013/019-th : 0.086 0.088 0.096 0.107 0.127 0.149 0.171 0.176  ||  -0.355 -0.328 -0.236 -0.135 0.041 0.197 0.339 0.365   || dis=0.00 || select=7/8
014/019-th : 0.080 0.086 0.100 0.123 0.145 0.152 0.162 0.152  ||  -0.397 -0.334 -0.176 0.030 0.192 0.240 0.303 0.239    || dis=0.01 || select=6/8
015/019-th : 0.093 0.090 0.097 0.107 0.130 0.151 0.167 0.165  ||  -0.278 -0.309 -0.232 -0.131 0.056 0.211 0.310 0.295   || dis=0.00 || select=6/8
016/019-th : 0.079 0.095 0.109 0.120 0.143 0.154 0.152 0.149  ||  -0.430 -0.236 -0.105 -0.009 0.172 0.242 0.229 0.208   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.124 0.131 0.137 0.139  ||  -0.057 -0.073 -0.075 -0.055 -0.006 0.049 0.090 0.109  || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.111 0.120 0.132 0.138 0.147 0.166  ||  -0.348 -0.209 -0.095 -0.020 0.075 0.116 0.183 0.303   || dis=0.02 || select=7/8
[epoch=072/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:20:32] [epoch=072/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.564 (2.564)  Prec@1 46.09 (46.09) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:20:38] [epoch=072/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.907 (2.347)  Prec@1 36.90 (35.92) Prec@5 85.12 (81.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.92 Prec@5 81.43 Error@1 64.08 Error@5 18.57 Loss:2.347
***[2020-01-29 06:20:38]*** VALID [epoch=072/600] loss = 2.346902, accuracy@1 = 35.92, accuracy@5 = 81.43 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:20:38]*** start epoch=073/600 Time Left: [04:45:50], LR=[0.096392 ~ 0.096392], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=73, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.823198822052354, FLOP=40.81
[Search] : epoch=073/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:20:39] [epoch=073/600][000/098] Time 0.73 (0.73) Data 0.35 (0.35) Base-Loss 1.019 (1.019)  Prec@1 64.84 (64.84) Prec@5 98.05 (98.05) Acls-loss 0.944 (0.944) FLOP-Loss 0.000 (0.000) Arch-Loss 0.944 (0.944)
**TRAIN** [2020-01-29 06:21:03] [epoch=073/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.998 (0.931)  Prec@1 66.67 (67.86) Prec@5 97.62 (97.22) Acls-loss 1.064 (0.938) FLOP-Loss 0.000 (0.026) Arch-Loss 1.064 (0.989)
 **TRAIN** Prec@1 67.86 Prec@5 97.22 Error@1 32.14 Error@5 2.78 Base-Loss:0.931, Arch-Loss=0.989
***[2020-01-29 06:21:03]*** TRAIN [epoch=073/600] base-loss = 0.930747, arch-loss = 0.989172, accuracy-1 = 67.86, accuracy-5 = 97.22
[epoch=073/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 16, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.54752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.383 0.233 0.383  ||  0.0122 -0.4841 0.0121  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.196 0.413  ||  -0.0037 -0.6926 0.0534  || discrepancy=0.02 || select=2/3
002/003-th : 0.324 0.222 0.454  ||  -0.1475 -0.5278 0.1903  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.082 0.093 0.107 0.118 0.138 0.154 0.157 0.151  ||  -0.378 -0.255 -0.116 -0.021 0.134 0.246 0.263 0.227   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.127 0.130 0.129 0.130  ||  -0.038 -0.041 -0.015 -0.013 0.021 0.044 0.039 0.045   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.124 0.127 0.129 0.130 0.127 0.128  ||  -0.075 -0.042 -0.005 0.022 0.036 0.044 0.025 0.027    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.125 0.126 0.126 0.125  ||  -0.013 -0.012 0.004 0.008 0.002 0.007 0.005 -0.002    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.128 0.127 0.130 0.127  ||  -0.050 -0.025 -0.017 -0.007 0.026 0.020 0.039 0.016   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.122 0.129 0.129 0.129 0.130  ||  -0.049 -0.035 -0.016 -0.024 0.037 0.031 0.031 0.039   || dis=0.00 || select=7/8
006/019-th : 0.115 0.118 0.123 0.122 0.130 0.129 0.133 0.130  ||  -0.084 -0.055 -0.016 -0.022 0.040 0.037 0.067 0.045   || dis=0.00 || select=6/8
007/019-th : 0.104 0.102 0.106 0.121 0.125 0.142 0.147 0.152  ||  -0.174 -0.197 -0.160 -0.024 0.010 0.139 0.172 0.206   || dis=0.01 || select=7/8
008/019-th : 0.093 0.099 0.109 0.129 0.142 0.146 0.141 0.141  ||  -0.268 -0.196 -0.106 0.060 0.162 0.190 0.156 0.150    || dis=0.00 || select=5/8
009/019-th : 0.114 0.112 0.110 0.123 0.125 0.134 0.139 0.142  ||  -0.087 -0.104 -0.127 -0.011 0.003 0.075 0.108 0.129   || dis=0.00 || select=7/8
010/019-th : 0.112 0.114 0.117 0.126 0.130 0.134 0.134 0.132  ||  -0.107 -0.082 -0.056 0.016 0.047 0.078 0.075 0.060    || dis=0.00 || select=5/8
011/019-th : 0.111 0.108 0.112 0.120 0.130 0.135 0.141 0.143  ||  -0.115 -0.141 -0.102 -0.037 0.047 0.080 0.129 0.142   || dis=0.00 || select=7/8
012/019-th : 0.119 0.119 0.118 0.124 0.129 0.130 0.131 0.130  ||  -0.044 -0.049 -0.054 -0.004 0.035 0.040 0.047 0.044   || dis=0.00 || select=6/8
013/019-th : 0.086 0.087 0.096 0.107 0.125 0.150 0.172 0.177  ||  -0.356 -0.334 -0.241 -0.134 0.025 0.204 0.344 0.369   || dis=0.01 || select=7/8
014/019-th : 0.081 0.086 0.100 0.123 0.144 0.152 0.162 0.152  ||  -0.397 -0.333 -0.176 0.028 0.182 0.236 0.304 0.240    || dis=0.01 || select=6/8
015/019-th : 0.093 0.090 0.097 0.107 0.129 0.152 0.167 0.166  ||  -0.280 -0.312 -0.236 -0.134 0.052 0.213 0.309 0.302   || dis=0.00 || select=6/8
016/019-th : 0.078 0.096 0.109 0.119 0.143 0.154 0.152 0.149  ||  -0.434 -0.235 -0.107 -0.011 0.169 0.241 0.231 0.210   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.125 0.131 0.136 0.139  ||  -0.056 -0.074 -0.077 -0.056 -0.001 0.050 0.088 0.110  || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.112 0.119 0.132 0.137 0.148 0.166  ||  -0.343 -0.212 -0.091 -0.027 0.072 0.112 0.186 0.301   || dis=0.02 || select=7/8
[epoch=073/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:21:03] [epoch=073/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.323 (1.323)  Prec@1 55.08 (55.08) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:21:09] [epoch=073/600][097/098] Time 0.12 (0.06) Data 0.00 (0.00) Loss 1.780 (2.254)  Prec@1 47.62 (34.44) Prec@5 87.50 (81.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.44 Prec@5 81.30 Error@1 65.56 Error@5 18.70 Loss:2.254
***[2020-01-29 06:21:09]*** VALID [epoch=073/600] loss = 2.253926, accuracy@1 = 34.44, accuracy@5 = 81.30 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:21:09]*** start epoch=074/600 Time Left: [04:45:08], LR=[0.096294 ~ 0.096294], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=74, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.818382932784488, FLOP=40.81
[Search] : epoch=074/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:21:10] [epoch=074/600][000/098] Time 0.61 (0.61) Data 0.35 (0.35) Base-Loss 0.869 (0.869)  Prec@1 70.31 (70.31) Prec@5 97.27 (97.27) Acls-loss 0.963 (0.963) FLOP-Loss 0.000 (0.000) Arch-Loss 0.963 (0.963)
**TRAIN** [2020-01-29 06:21:34] [epoch=074/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.027 (0.911)  Prec@1 69.05 (68.46) Prec@5 95.24 (97.34) Acls-loss 0.958 (0.938) FLOP-Loss 0.000 (0.026) Arch-Loss 0.958 (0.989)
 **TRAIN** Prec@1 68.46 Prec@5 97.34 Error@1 31.54 Error@5 2.66 Base-Loss:0.911, Arch-Loss=0.989
***[2020-01-29 06:21:34]*** TRAIN [epoch=074/600] base-loss = 0.910987, arch-loss = 0.988581, accuracy-1 = 68.46, accuracy-5 = 97.34
[epoch=074/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 16, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.54752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.384 0.232 0.384  ||  0.0129 -0.4935 0.0119  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.195 0.414  ||  -0.0042 -0.6987 0.0546  || discrepancy=0.02 || select=2/3
002/003-th : 0.323 0.222 0.455  ||  -0.1488 -0.5243 0.1917  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.083 0.093 0.107 0.119 0.136 0.154 0.157 0.151  ||  -0.378 -0.257 -0.115 -0.016 0.124 0.248 0.262 0.227   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.122 0.123 0.127 0.130 0.129 0.130  ||  -0.039 -0.042 -0.015 -0.014 0.023 0.044 0.039 0.045   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.124 0.127 0.129 0.130 0.127 0.128  ||  -0.074 -0.042 -0.006 0.024 0.037 0.044 0.025 0.026    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.126 0.126 0.125  ||  -0.013 -0.011 0.006 0.007 0.006 0.005 0.004 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.128 0.127 0.130 0.127  ||  -0.050 -0.026 -0.016 -0.008 0.027 0.018 0.040 0.016   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.122 0.129 0.129 0.128 0.130  ||  -0.050 -0.035 -0.016 -0.018 0.038 0.031 0.030 0.039   || dis=0.00 || select=7/8
006/019-th : 0.114 0.118 0.123 0.122 0.130 0.129 0.133 0.130  ||  -0.086 -0.057 -0.016 -0.017 0.041 0.039 0.068 0.047   || dis=0.00 || select=6/8
007/019-th : 0.104 0.102 0.106 0.121 0.125 0.142 0.148 0.153  ||  -0.176 -0.198 -0.155 -0.028 0.004 0.137 0.175 0.208   || dis=0.01 || select=7/8
008/019-th : 0.093 0.099 0.109 0.129 0.141 0.147 0.142 0.141  ||  -0.269 -0.199 -0.109 0.062 0.151 0.195 0.156 0.152    || dis=0.01 || select=5/8
009/019-th : 0.114 0.112 0.109 0.124 0.124 0.135 0.139 0.142  ||  -0.087 -0.104 -0.132 -0.010 -0.005 0.076 0.110 0.130  || dis=0.00 || select=7/8
010/019-th : 0.112 0.115 0.118 0.126 0.129 0.134 0.134 0.132  ||  -0.107 -0.080 -0.054 0.014 0.041 0.078 0.073 0.061    || dis=0.00 || select=5/8
011/019-th : 0.110 0.108 0.111 0.120 0.130 0.135 0.141 0.143  ||  -0.118 -0.139 -0.108 -0.034 0.049 0.082 0.130 0.143   || dis=0.00 || select=7/8
012/019-th : 0.119 0.119 0.118 0.125 0.128 0.130 0.131 0.130  ||  -0.045 -0.049 -0.052 0.001 0.024 0.041 0.048 0.044    || dis=0.00 || select=6/8
013/019-th : 0.085 0.087 0.096 0.106 0.126 0.150 0.173 0.177  ||  -0.358 -0.340 -0.244 -0.137 0.033 0.205 0.347 0.373   || dis=0.00 || select=7/8
014/019-th : 0.080 0.086 0.101 0.124 0.142 0.152 0.163 0.153  ||  -0.400 -0.337 -0.175 0.030 0.172 0.236 0.308 0.242    || dis=0.01 || select=6/8
015/019-th : 0.092 0.089 0.096 0.109 0.129 0.151 0.167 0.167  ||  -0.288 -0.316 -0.245 -0.113 0.053 0.210 0.312 0.308   || dis=0.00 || select=6/8
016/019-th : 0.078 0.095 0.108 0.120 0.142 0.155 0.153 0.149  ||  -0.439 -0.235 -0.110 -0.010 0.164 0.246 0.234 0.211   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.116 0.118 0.125 0.131 0.136 0.139  ||  -0.058 -0.075 -0.076 -0.054 0.002 0.051 0.088 0.111   || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.112 0.119 0.132 0.137 0.148 0.165  ||  -0.343 -0.213 -0.087 -0.029 0.074 0.109 0.191 0.298   || dis=0.02 || select=7/8
[epoch=074/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:21:34] [epoch=074/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.526 (1.526)  Prec@1 50.00 (50.00) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:21:40] [epoch=074/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.627 (2.310)  Prec@1 40.48 (36.09) Prec@5 94.64 (82.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.09 Prec@5 82.58 Error@1 63.91 Error@5 17.42 Loss:2.310
***[2020-01-29 06:21:40]*** VALID [epoch=074/600] loss = 2.309635, accuracy@1 = 36.09, accuracy@5 = 82.58 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:21:40]*** start epoch=075/600 Time Left: [04:44:25], LR=[0.096194 ~ 0.096194], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=75, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.813504854652653, FLOP=40.81
[Search] : epoch=075/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:21:41] [epoch=075/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 1.052 (1.052)  Prec@1 64.06 (64.06) Prec@5 97.27 (97.27) Acls-loss 0.896 (0.896) FLOP-Loss 0.000 (0.000) Arch-Loss 0.896 (0.896)
**TRAIN** [2020-01-29 06:22:05] [epoch=075/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.915 (0.919)  Prec@1 71.43 (68.46) Prec@5 97.02 (97.37) Acls-loss 0.928 (0.932) FLOP-Loss 0.000 (0.026) Arch-Loss 0.928 (0.983)
 **TRAIN** Prec@1 68.46 Prec@5 97.37 Error@1 31.54 Error@5 2.63 Base-Loss:0.919, Arch-Loss=0.983
***[2020-01-29 06:22:05]*** TRAIN [epoch=075/600] base-loss = 0.918754, arch-loss = 0.983059, accuracy-1 = 68.46, accuracy-5 = 97.37
[epoch=075/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 16, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.54752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.385 0.230 0.385  ||  0.0130 -0.4998 0.0124  || discrepancy=0.00 || select=0/3
001/003-th : 0.392 0.192 0.416  ||  -0.0043 -0.7151 0.0556  || discrepancy=0.02 || select=2/3
002/003-th : 0.322 0.223 0.455  ||  -0.1505 -0.5189 0.1933  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.082 0.092 0.107 0.118 0.137 0.156 0.157 0.152  ||  -0.387 -0.267 -0.116 -0.017 0.130 0.258 0.267 0.232   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.122 0.128 0.130 0.129 0.130  ||  -0.038 -0.042 -0.013 -0.014 0.028 0.042 0.039 0.044   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.124 0.128 0.129 0.130 0.127 0.128  ||  -0.073 -0.042 -0.006 0.025 0.037 0.044 0.024 0.025    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.125 0.125 0.125  ||  -0.014 -0.010 0.007 0.011 0.007 0.004 0.004 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.128 0.127 0.130 0.127  ||  -0.049 -0.024 -0.018 -0.006 0.026 0.017 0.040 0.015   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.123 0.129 0.129 0.128 0.129  ||  -0.049 -0.035 -0.016 -0.013 0.036 0.033 0.029 0.039   || dis=0.00 || select=7/8
006/019-th : 0.114 0.118 0.123 0.123 0.129 0.130 0.133 0.131  ||  -0.087 -0.057 -0.016 -0.013 0.038 0.039 0.068 0.047   || dis=0.00 || select=6/8
007/019-th : 0.104 0.102 0.106 0.121 0.125 0.142 0.148 0.153  ||  -0.177 -0.197 -0.157 -0.028 0.011 0.134 0.174 0.209   || dis=0.01 || select=7/8
008/019-th : 0.092 0.099 0.108 0.128 0.143 0.147 0.142 0.141  ||  -0.273 -0.201 -0.114 0.058 0.164 0.196 0.159 0.155    || dis=0.00 || select=5/8
009/019-th : 0.114 0.112 0.110 0.125 0.123 0.134 0.140 0.142  ||  -0.089 -0.107 -0.130 -0.001 -0.010 0.073 0.114 0.132  || dis=0.00 || select=7/8
010/019-th : 0.112 0.115 0.118 0.126 0.129 0.134 0.134 0.132  ||  -0.106 -0.080 -0.054 0.011 0.040 0.077 0.074 0.060    || dis=0.00 || select=5/8
011/019-th : 0.110 0.108 0.111 0.120 0.130 0.135 0.141 0.144  ||  -0.121 -0.135 -0.110 -0.037 0.047 0.085 0.128 0.146   || dis=0.00 || select=7/8
012/019-th : 0.119 0.118 0.118 0.125 0.128 0.130 0.131 0.130  ||  -0.046 -0.051 -0.051 -0.000 0.029 0.043 0.048 0.044   || dis=0.00 || select=6/8
013/019-th : 0.085 0.087 0.096 0.106 0.127 0.148 0.173 0.178  ||  -0.364 -0.343 -0.239 -0.139 0.038 0.195 0.351 0.378   || dis=0.01 || select=7/8
014/019-th : 0.080 0.085 0.100 0.123 0.145 0.151 0.163 0.153  ||  -0.401 -0.340 -0.180 0.025 0.195 0.236 0.310 0.244    || dis=0.01 || select=6/8
015/019-th : 0.091 0.089 0.095 0.108 0.130 0.151 0.168 0.167  ||  -0.293 -0.315 -0.249 -0.124 0.057 0.211 0.316 0.313   || dis=0.00 || select=6/8
016/019-th : 0.078 0.096 0.108 0.120 0.139 0.156 0.153 0.150  ||  -0.439 -0.237 -0.115 -0.007 0.141 0.253 0.234 0.213   || dis=0.00 || select=5/8
017/019-th : 0.118 0.116 0.115 0.119 0.126 0.131 0.136 0.140  ||  -0.059 -0.075 -0.078 -0.049 0.007 0.050 0.088 0.112   || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.113 0.120 0.130 0.137 0.148 0.165  ||  -0.339 -0.214 -0.082 -0.022 0.055 0.107 0.189 0.297   || dis=0.02 || select=7/8
[epoch=075/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:22:06] [epoch=075/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.929 (1.929)  Prec@1 42.97 (42.97) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:22:11] [epoch=075/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.379 (2.232)  Prec@1 20.24 (35.10) Prec@5 69.05 (81.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.10 Prec@5 81.32 Error@1 64.90 Error@5 18.68 Loss:2.232
***[2020-01-29 06:22:12]*** VALID [epoch=075/600] loss = 2.232004, accuracy@1 = 35.10, accuracy@5 = 81.32 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:22:12]*** start epoch=076/600 Time Left: [04:43:43], LR=[0.096093 ~ 0.096093], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=76, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.808564721391826, FLOP=40.81
[Search] : epoch=076/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:22:12] [epoch=076/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.090 (1.090)  Prec@1 62.11 (62.11) Prec@5 96.48 (96.48) Acls-loss 0.889 (0.889) FLOP-Loss 0.000 (0.000) Arch-Loss 0.889 (0.889)
**TRAIN** [2020-01-29 06:22:36] [epoch=076/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.812 (0.923)  Prec@1 75.00 (68.36) Prec@5 98.21 (97.26) Acls-loss 0.780 (0.928) FLOP-Loss 0.000 (0.026) Arch-Loss 0.780 (0.979)
 **TRAIN** Prec@1 68.36 Prec@5 97.26 Error@1 31.64 Error@5 2.74 Base-Loss:0.923, Arch-Loss=0.979
***[2020-01-29 06:22:36]*** TRAIN [epoch=076/600] base-loss = 0.923141, arch-loss = 0.978778, accuracy-1 = 68.36, accuracy-5 = 97.26
[epoch=076/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 11, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.54752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.385 0.229 0.385  ||  0.0131 -0.5070 0.0129  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.193 0.416  ||  -0.0045 -0.7131 0.0563  || discrepancy=0.02 || select=2/3
002/003-th : 0.321 0.223 0.455  ||  -0.1524 -0.5158 0.1954  || discrepancy=0.13 || select=2/3
-----------------------------------------------
000/019-th : 0.081 0.092 0.106 0.118 0.138 0.155 0.157 0.152  ||  -0.389 -0.263 -0.123 -0.023 0.135 0.257 0.267 0.235   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.123 0.128 0.129 0.129 0.130  ||  -0.038 -0.041 -0.012 -0.010 0.026 0.041 0.038 0.044   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.124 0.128 0.129 0.130 0.127 0.127  ||  -0.072 -0.042 -0.004 0.027 0.037 0.043 0.023 0.024    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.125 0.125 0.125  ||  -0.014 -0.009 0.006 0.010 0.006 0.004 0.004 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.129 0.127 0.130 0.127  ||  -0.050 -0.025 -0.017 -0.005 0.031 0.017 0.040 0.015   || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.123 0.123 0.130 0.128 0.128 0.129  ||  -0.049 -0.037 -0.015 -0.010 0.044 0.031 0.030 0.037   || dis=0.00 || select=4/8
006/019-th : 0.114 0.118 0.122 0.123 0.129 0.130 0.133 0.131  ||  -0.088 -0.058 -0.018 -0.013 0.034 0.043 0.069 0.047   || dis=0.00 || select=6/8
007/019-th : 0.103 0.102 0.105 0.120 0.126 0.142 0.148 0.153  ||  -0.181 -0.199 -0.161 -0.029 0.020 0.139 0.178 0.211   || dis=0.01 || select=7/8
008/019-th : 0.092 0.099 0.108 0.128 0.141 0.147 0.142 0.142  ||  -0.278 -0.197 -0.118 0.055 0.154 0.196 0.161 0.158    || dis=0.01 || select=5/8
009/019-th : 0.114 0.112 0.110 0.124 0.125 0.134 0.140 0.142  ||  -0.089 -0.110 -0.129 -0.009 -0.001 0.075 0.114 0.133  || dis=0.00 || select=7/8
010/019-th : 0.111 0.114 0.118 0.126 0.131 0.134 0.133 0.132  ||  -0.108 -0.081 -0.054 0.018 0.051 0.077 0.070 0.062    || dis=0.00 || select=5/8
011/019-th : 0.110 0.109 0.111 0.119 0.130 0.135 0.141 0.144  ||  -0.122 -0.132 -0.115 -0.041 0.041 0.083 0.128 0.149   || dis=0.00 || select=7/8
012/019-th : 0.119 0.118 0.118 0.125 0.128 0.130 0.131 0.130  ||  -0.047 -0.051 -0.050 0.006 0.031 0.043 0.048 0.044    || dis=0.00 || select=6/8
013/019-th : 0.085 0.086 0.096 0.106 0.126 0.149 0.173 0.179  ||  -0.367 -0.347 -0.241 -0.141 0.031 0.203 0.351 0.383   || dis=0.01 || select=7/8
014/019-th : 0.080 0.085 0.100 0.122 0.144 0.152 0.163 0.153  ||  -0.403 -0.341 -0.177 0.022 0.186 0.241 0.310 0.244    || dis=0.01 || select=6/8
015/019-th : 0.090 0.088 0.095 0.108 0.131 0.152 0.168 0.168  ||  -0.308 -0.321 -0.253 -0.119 0.076 0.219 0.323 0.319   || dis=0.00 || select=6/8
016/019-th : 0.078 0.095 0.107 0.120 0.141 0.156 0.153 0.150  ||  -0.440 -0.242 -0.122 -0.006 0.152 0.253 0.237 0.216   || dis=0.00 || select=5/8
017/019-th : 0.117 0.116 0.115 0.119 0.127 0.131 0.136 0.139  ||  -0.058 -0.075 -0.080 -0.046 0.020 0.052 0.085 0.111   || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.113 0.122 0.129 0.137 0.149 0.164  ||  -0.340 -0.215 -0.083 -0.009 0.053 0.112 0.194 0.291   || dis=0.02 || select=7/8
[epoch=076/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:22:37] [epoch=076/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.155 (2.155)  Prec@1 35.55 (35.55) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:22:43] [epoch=076/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.157 (2.141)  Prec@1 44.05 (38.75) Prec@5 79.76 (84.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.75 Prec@5 84.62 Error@1 61.25 Error@5 15.38 Loss:2.141
***[2020-01-29 06:22:43]*** VALID [epoch=076/600] loss = 2.140548, accuracy@1 = 38.75, accuracy@5 = 84.62 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:22:43]*** start epoch=077/600 Time Left: [04:43:01], LR=[0.095991 ~ 0.095991], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=77, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.803562668438258, FLOP=40.81
[Search] : epoch=077/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:22:43] [epoch=077/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.822 (0.822)  Prec@1 68.75 (68.75) Prec@5 97.66 (97.66) Acls-loss 0.819 (0.819) FLOP-Loss 0.000 (0.000) Arch-Loss 0.819 (0.819)
**TRAIN** [2020-01-29 06:23:08] [epoch=077/600][097/098] Time 0.29 (0.26) Data 0.00 (0.00) Base-Loss 0.986 (0.904)  Prec@1 65.48 (68.91) Prec@5 97.02 (97.44) Acls-loss 0.937 (0.922) FLOP-Loss 0.000 (0.026) Arch-Loss 0.937 (0.973)
 **TRAIN** Prec@1 68.91 Prec@5 97.44 Error@1 31.09 Error@5 2.56 Base-Loss:0.904, Arch-Loss=0.973
***[2020-01-29 06:23:08]*** TRAIN [epoch=077/600] base-loss = 0.903607, arch-loss = 0.972887, accuracy-1 = 68.91, accuracy-5 = 97.44
[epoch=077/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 11, 14, 32, 25, 32, 25, 32, 28, 64, 57, 57, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.54752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.384 0.232 0.384  ||  0.0137 -0.4907 0.0125  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.192 0.417  ||  -0.0054 -0.7184 0.0579  || discrepancy=0.03 || select=2/3
002/003-th : 0.320 0.223 0.457  ||  -0.1561 -0.5171 0.1994  || discrepancy=0.14 || select=2/3
-----------------------------------------------
000/019-th : 0.082 0.092 0.107 0.117 0.137 0.156 0.157 0.153  ||  -0.390 -0.265 -0.121 -0.026 0.126 0.256 0.268 0.237   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.123 0.128 0.129 0.129 0.130  ||  -0.038 -0.042 -0.012 -0.007 0.027 0.039 0.037 0.043   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.124 0.128 0.129 0.130 0.127 0.127  ||  -0.073 -0.042 -0.002 0.029 0.038 0.042 0.022 0.023    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.126 0.126 0.126 0.125 0.125 0.124  ||  -0.014 -0.009 0.007 0.011 0.007 0.004 0.004 -0.003    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.129 0.127 0.130 0.127  ||  -0.051 -0.025 -0.016 -0.006 0.029 0.017 0.041 0.015   || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.123 0.123 0.131 0.129 0.128 0.129  ||  -0.050 -0.039 -0.013 -0.011 0.049 0.033 0.028 0.038   || dis=0.00 || select=4/8
006/019-th : 0.114 0.117 0.122 0.123 0.129 0.130 0.134 0.131  ||  -0.088 -0.060 -0.018 -0.013 0.033 0.040 0.070 0.048   || dis=0.00 || select=6/8
007/019-th : 0.103 0.101 0.106 0.119 0.127 0.142 0.148 0.153  ||  -0.183 -0.199 -0.158 -0.039 0.024 0.137 0.178 0.213   || dis=0.01 || select=7/8
008/019-th : 0.092 0.099 0.107 0.128 0.141 0.148 0.142 0.142  ||  -0.279 -0.198 -0.124 0.052 0.152 0.202 0.162 0.160    || dis=0.01 || select=5/8
009/019-th : 0.114 0.112 0.109 0.124 0.124 0.134 0.140 0.143  ||  -0.088 -0.112 -0.134 -0.004 -0.005 0.075 0.114 0.134  || dis=0.00 || select=7/8
010/019-th : 0.111 0.114 0.118 0.126 0.130 0.135 0.133 0.132  ||  -0.110 -0.084 -0.054 0.015 0.044 0.082 0.071 0.064    || dis=0.00 || select=5/8
011/019-th : 0.110 0.109 0.110 0.120 0.129 0.135 0.142 0.145  ||  -0.124 -0.133 -0.121 -0.039 0.035 0.084 0.130 0.152   || dis=0.00 || select=7/8
012/019-th : 0.119 0.118 0.119 0.125 0.129 0.130 0.131 0.130  ||  -0.048 -0.052 -0.047 0.004 0.032 0.039 0.047 0.046    || dis=0.00 || select=6/8
013/019-th : 0.084 0.085 0.096 0.106 0.127 0.149 0.174 0.179  ||  -0.372 -0.355 -0.243 -0.140 0.040 0.201 0.359 0.386   || dis=0.01 || select=7/8
014/019-th : 0.080 0.085 0.100 0.122 0.145 0.153 0.163 0.153  ||  -0.404 -0.346 -0.179 0.021 0.190 0.246 0.310 0.246    || dis=0.01 || select=6/8
015/019-th : 0.090 0.088 0.094 0.108 0.131 0.152 0.169 0.169  ||  -0.308 -0.324 -0.260 -0.126 0.072 0.221 0.326 0.324   || dis=0.00 || select=6/8
016/019-th : 0.077 0.094 0.106 0.120 0.142 0.155 0.154 0.151  ||  -0.447 -0.247 -0.128 -0.002 0.160 0.250 0.245 0.221   || dis=0.00 || select=5/8
017/019-th : 0.117 0.115 0.115 0.118 0.128 0.131 0.135 0.139  ||  -0.059 -0.075 -0.080 -0.050 0.024 0.054 0.083 0.113   || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.113 0.121 0.128 0.137 0.150 0.165  ||  -0.343 -0.219 -0.084 -0.017 0.046 0.113 0.200 0.296   || dis=0.02 || select=7/8
[epoch=077/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:23:09] [epoch=077/600][000/098] Time 0.45 (0.45) Data 0.32 (0.32) Loss 1.890 (1.890)  Prec@1 42.19 (42.19) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:23:17] [epoch=077/600][097/098] Time 0.07 (0.09) Data 0.00 (0.00) Loss 1.687 (2.213)  Prec@1 42.86 (38.73) Prec@5 83.93 (83.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.73 Prec@5 83.72 Error@1 61.27 Error@5 16.28 Loss:2.213
***[2020-01-29 06:23:17]*** VALID [epoch=077/600] loss = 2.213299, accuracy@1 = 38.73, accuracy@5 = 83.72 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:23:17]*** start epoch=078/600 Time Left: [04:42:41], LR=[0.095888 ~ 0.095888], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=78, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.798498832925754, FLOP=40.81
[Search] : epoch=078/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:23:18] [epoch=078/600][000/098] Time 0.82 (0.82) Data 0.38 (0.38) Base-Loss 0.888 (0.888)  Prec@1 69.14 (69.14) Prec@5 97.66 (97.66) Acls-loss 0.967 (0.967) FLOP-Loss 0.000 (0.000) Arch-Loss 0.967 (0.967)
**TRAIN** [2020-01-29 06:23:43] [epoch=078/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.855 (0.922)  Prec@1 70.24 (68.04) Prec@5 97.62 (97.39) Acls-loss 0.991 (0.943) FLOP-Loss 0.000 (0.026) Arch-Loss 0.991 (0.994)
 **TRAIN** Prec@1 68.04 Prec@5 97.39 Error@1 31.96 Error@5 2.61 Base-Loss:0.922, Arch-Loss=0.994
***[2020-01-29 06:23:43]*** TRAIN [epoch=078/600] base-loss = 0.921930, arch-loss = 0.994044, accuracy-1 = 68.04, accuracy-5 = 97.39
[epoch=078/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 11, 14, 32, 25, 32, 25, 32, 28, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.263872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.383 0.235 0.382  ||  0.0143 -0.4753 0.0122  || discrepancy=0.00 || select=0/3
001/003-th : 0.392 0.190 0.418  ||  -0.0057 -0.7314 0.0592  || discrepancy=0.03 || select=2/3
002/003-th : 0.319 0.223 0.458  ||  -0.1587 -0.5179 0.2024  || discrepancy=0.14 || select=2/3
-----------------------------------------------
000/019-th : 0.081 0.092 0.107 0.117 0.136 0.157 0.157 0.153  ||  -0.396 -0.264 -0.120 -0.032 0.125 0.265 0.269 0.238   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.123 0.128 0.129 0.129 0.130  ||  -0.038 -0.042 -0.010 -0.008 0.027 0.039 0.037 0.043   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.124 0.129 0.129 0.129 0.127 0.127  ||  -0.073 -0.041 -0.000 0.035 0.036 0.039 0.022 0.022    || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.125 0.127 0.126 0.125 0.125 0.124  ||  -0.014 -0.008 0.003 0.015 0.010 0.003 0.004 -0.004    || dis=0.00 || select=3/8
004/019-th : 0.119 0.122 0.123 0.124 0.129 0.127 0.130 0.127  ||  -0.051 -0.026 -0.018 -0.004 0.030 0.015 0.042 0.016   || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.123 0.124 0.131 0.129 0.128 0.129  ||  -0.051 -0.039 -0.015 -0.006 0.050 0.033 0.027 0.038   || dis=0.00 || select=4/8
006/019-th : 0.114 0.117 0.122 0.124 0.129 0.130 0.134 0.131  ||  -0.088 -0.062 -0.018 -0.006 0.032 0.042 0.069 0.049   || dis=0.00 || select=6/8
007/019-th : 0.103 0.101 0.106 0.119 0.128 0.142 0.148 0.154  ||  -0.184 -0.202 -0.157 -0.037 0.032 0.135 0.177 0.215   || dis=0.01 || select=7/8
008/019-th : 0.092 0.099 0.108 0.127 0.139 0.149 0.143 0.142  ||  -0.282 -0.200 -0.119 0.046 0.138 0.206 0.166 0.160    || dis=0.01 || select=5/8
009/019-th : 0.114 0.111 0.109 0.124 0.124 0.134 0.140 0.143  ||  -0.089 -0.113 -0.134 -0.005 -0.007 0.074 0.118 0.136  || dis=0.00 || select=7/8
010/019-th : 0.111 0.114 0.117 0.127 0.130 0.135 0.133 0.132  ||  -0.112 -0.085 -0.057 0.026 0.045 0.084 0.069 0.065    || dis=0.00 || select=5/8
011/019-th : 0.110 0.109 0.110 0.120 0.128 0.136 0.142 0.145  ||  -0.126 -0.134 -0.126 -0.036 0.032 0.093 0.131 0.154   || dis=0.00 || select=7/8
012/019-th : 0.119 0.118 0.119 0.124 0.129 0.130 0.131 0.131  ||  -0.049 -0.052 -0.048 -0.007 0.037 0.044 0.047 0.046   || dis=0.00 || select=6/8
013/019-th : 0.084 0.085 0.096 0.106 0.125 0.149 0.175 0.181  ||  -0.375 -0.364 -0.241 -0.137 0.029 0.199 0.363 0.394   || dis=0.01 || select=7/8
014/019-th : 0.080 0.084 0.099 0.123 0.144 0.153 0.164 0.153  ||  -0.405 -0.348 -0.191 0.031 0.186 0.247 0.313 0.248    || dis=0.01 || select=6/8
015/019-th : 0.088 0.088 0.093 0.110 0.133 0.150 0.169 0.169  ||  -0.325 -0.322 -0.271 -0.103 0.092 0.210 0.328 0.332   || dis=0.00 || select=7/8
016/019-th : 0.077 0.094 0.106 0.122 0.140 0.155 0.155 0.151  ||  -0.450 -0.249 -0.133 0.008 0.145 0.246 0.251 0.223    || dis=0.00 || select=6/8
017/019-th : 0.118 0.116 0.115 0.119 0.127 0.132 0.135 0.139  ||  -0.058 -0.075 -0.079 -0.050 0.021 0.054 0.082 0.113   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.113 0.121 0.127 0.137 0.150 0.166  ||  -0.343 -0.222 -0.082 -0.014 0.031 0.108 0.201 0.301   || dis=0.02 || select=7/8
[epoch=078/600] FLOP : 27.26 MB, ratio : 0.6680, Expected-ratio : 0.7000, Discrepancy : 0.011
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:23:43] [epoch=078/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.487 (2.487)  Prec@1 17.97 (17.97) Prec@5 73.83 (73.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:23:49] [epoch=078/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.237 (2.288)  Prec@1 41.67 (33.34) Prec@5 92.86 (79.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.34 Prec@5 79.32 Error@1 66.66 Error@5 20.68 Loss:2.288
***[2020-01-29 06:23:49]*** VALID [epoch=078/600] loss = 2.288187, accuracy@1 = 33.34, accuracy@5 = 79.32 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:23:49]*** start epoch=079/600 Time Left: [04:42:06], LR=[0.095783 ~ 0.095783], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=79, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.793373353681925, FLOP=40.81
[Search] : epoch=079/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:23:50] [epoch=079/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 1.070 (1.070)  Prec@1 62.50 (62.50) Prec@5 97.66 (97.66) Acls-loss 0.970 (0.970) FLOP-Loss 0.000 (0.000) Arch-Loss 0.970 (0.970)
**TRAIN** [2020-01-29 06:24:14] [epoch=079/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.920 (0.895)  Prec@1 66.67 (68.93) Prec@5 97.62 (97.42) Acls-loss 0.952 (0.932) FLOP-Loss 0.000 (0.026) Arch-Loss 0.952 (0.984)
 **TRAIN** Prec@1 68.93 Prec@5 97.42 Error@1 31.07 Error@5 2.58 Base-Loss:0.895, Arch-Loss=0.984
***[2020-01-29 06:24:14]*** TRAIN [epoch=079/600] base-loss = 0.895440, arch-loss = 0.983516, accuracy-1 = 68.93, accuracy-5 = 97.42
[epoch=079/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 9, 9, 14, 11, 14, 32, 25, 32, 25, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.261056)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.383 0.234 0.383  ||  0.0145 -0.4784 0.0125  || discrepancy=0.00 || select=0/3
001/003-th : 0.392 0.190 0.419  ||  -0.0065 -0.7320 0.0607  || discrepancy=0.03 || select=2/3
002/003-th : 0.318 0.223 0.459  ||  -0.1617 -0.5179 0.2057  || discrepancy=0.14 || select=2/3
-----------------------------------------------
000/019-th : 0.081 0.092 0.107 0.117 0.136 0.157 0.157 0.153  ||  -0.400 -0.266 -0.118 -0.031 0.119 0.264 0.268 0.242   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.123 0.127 0.129 0.129 0.130  ||  -0.037 -0.043 -0.010 -0.010 0.025 0.041 0.036 0.044   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.125 0.129 0.129 0.129 0.127 0.127  ||  -0.073 -0.041 0.002 0.039 0.037 0.037 0.021 0.021     || dis=0.00 || select=3/8
003/019-th : 0.123 0.124 0.125 0.127 0.126 0.125 0.125 0.124  ||  -0.014 -0.008 0.004 0.015 0.010 0.003 0.004 -0.004    || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.123 0.123 0.130 0.127 0.131 0.127  ||  -0.052 -0.029 -0.019 -0.012 0.037 0.013 0.044 0.019   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.122 0.124 0.130 0.129 0.128 0.129  ||  -0.049 -0.038 -0.020 -0.005 0.045 0.034 0.027 0.037   || dis=0.00 || select=4/8
006/019-th : 0.114 0.117 0.122 0.123 0.129 0.130 0.134 0.131  ||  -0.088 -0.061 -0.023 -0.009 0.036 0.044 0.069 0.049   || dis=0.00 || select=6/8
007/019-th : 0.102 0.101 0.106 0.120 0.129 0.140 0.147 0.154  ||  -0.188 -0.203 -0.156 -0.029 0.041 0.126 0.176 0.220   || dis=0.01 || select=7/8
008/019-th : 0.091 0.099 0.107 0.128 0.139 0.149 0.144 0.143  ||  -0.287 -0.203 -0.126 0.053 0.136 0.208 0.169 0.164    || dis=0.01 || select=5/8
009/019-th : 0.114 0.112 0.109 0.124 0.124 0.135 0.140 0.143  ||  -0.091 -0.111 -0.137 -0.004 -0.006 0.076 0.118 0.136  || dis=0.00 || select=7/8
010/019-th : 0.111 0.114 0.117 0.128 0.131 0.135 0.133 0.133  ||  -0.114 -0.086 -0.057 0.030 0.052 0.082 0.068 0.068    || dis=0.00 || select=5/8
011/019-th : 0.110 0.109 0.110 0.118 0.129 0.136 0.143 0.145  ||  -0.126 -0.134 -0.128 -0.051 0.036 0.092 0.138 0.152   || dis=0.00 || select=7/8
012/019-th : 0.118 0.118 0.119 0.124 0.128 0.130 0.131 0.131  ||  -0.052 -0.054 -0.049 -0.003 0.031 0.045 0.048 0.049   || dis=0.00 || select=7/8
013/019-th : 0.083 0.084 0.095 0.106 0.126 0.149 0.175 0.181  ||  -0.380 -0.368 -0.244 -0.140 0.037 0.203 0.365 0.398   || dis=0.01 || select=7/8
014/019-th : 0.080 0.085 0.098 0.124 0.143 0.153 0.163 0.154  ||  -0.406 -0.344 -0.200 0.035 0.180 0.243 0.312 0.252    || dis=0.01 || select=6/8
015/019-th : 0.087 0.087 0.092 0.110 0.133 0.151 0.169 0.170  ||  -0.331 -0.329 -0.279 -0.097 0.095 0.217 0.333 0.336   || dis=0.00 || select=7/8
016/019-th : 0.077 0.094 0.105 0.122 0.140 0.155 0.155 0.151  ||  -0.452 -0.252 -0.138 0.012 0.150 0.248 0.250 0.226    || dis=0.00 || select=6/8
017/019-th : 0.117 0.115 0.115 0.119 0.127 0.132 0.135 0.139  ||  -0.058 -0.076 -0.077 -0.049 0.022 0.056 0.079 0.113   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.120 0.130 0.137 0.151 0.165  ||  -0.352 -0.222 -0.085 -0.019 0.057 0.111 0.207 0.299   || dis=0.01 || select=7/8
[epoch=079/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.010
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:24:14] [epoch=079/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.376 (3.376)  Prec@1 23.83 (23.83) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:24:20] [epoch=079/600][097/098] Time 0.12 (0.06) Data 0.00 (0.00) Loss 2.601 (2.229)  Prec@1 27.98 (34.78) Prec@5 80.36 (81.23) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.78 Prec@5 81.23 Error@1 65.22 Error@5 18.77 Loss:2.229
***[2020-01-29 06:24:20]*** VALID [epoch=079/600] loss = 2.228896, accuracy@1 = 34.78, accuracy@5 = 81.23 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:24:20]*** start epoch=080/600 Time Left: [04:41:25], LR=[0.095677 ~ 0.095677], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=80, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.788186371224372, FLOP=40.81
[Search] : epoch=080/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:24:21] [epoch=080/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.902 (0.902)  Prec@1 69.53 (69.53) Prec@5 96.88 (96.88) Acls-loss 0.932 (0.932) FLOP-Loss 0.000 (0.000) Arch-Loss 0.932 (0.932)
**TRAIN** [2020-01-29 06:24:45] [epoch=080/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.939 (0.908)  Prec@1 68.45 (68.74) Prec@5 96.43 (97.18) Acls-loss 0.855 (0.938) FLOP-Loss 0.000 (0.026) Arch-Loss 0.855 (0.989)
 **TRAIN** Prec@1 68.74 Prec@5 97.18 Error@1 31.26 Error@5 2.82 Base-Loss:0.908, Arch-Loss=0.989
***[2020-01-29 06:24:45]*** TRAIN [epoch=080/600] base-loss = 0.907931, arch-loss = 0.989483, accuracy-1 = 68.74, accuracy-5 = 97.18
[epoch=080/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 9, 9, 14, 11, 14, 32, 25, 32, 25, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.261056)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.383 0.234 0.382  ||  0.0151 -0.4769 0.0125  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.190 0.419  ||  -0.0067 -0.7318 0.0616  || discrepancy=0.03 || select=2/3
002/003-th : 0.317 0.223 0.460  ||  -0.1645 -0.5154 0.2086  || discrepancy=0.14 || select=2/3
-----------------------------------------------
000/019-th : 0.081 0.092 0.107 0.116 0.136 0.157 0.158 0.154  ||  -0.401 -0.272 -0.120 -0.039 0.122 0.266 0.269 0.248   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.123 0.127 0.129 0.129 0.130  ||  -0.038 -0.043 -0.011 -0.010 0.025 0.042 0.037 0.043   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.125 0.129 0.129 0.129 0.127 0.127  ||  -0.073 -0.040 0.005 0.040 0.034 0.035 0.022 0.020     || dis=0.00 || select=3/8
003/019-th : 0.123 0.124 0.126 0.127 0.126 0.125 0.125 0.124  ||  -0.015 -0.007 0.006 0.021 0.013 0.001 0.004 -0.005    || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.123 0.124 0.129 0.127 0.131 0.127  ||  -0.052 -0.030 -0.019 -0.012 0.035 0.015 0.044 0.019   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.122 0.123 0.130 0.129 0.128 0.129  ||  -0.048 -0.038 -0.023 -0.013 0.043 0.036 0.030 0.036   || dis=0.00 || select=4/8
006/019-th : 0.114 0.117 0.122 0.123 0.129 0.131 0.134 0.131  ||  -0.089 -0.064 -0.022 -0.011 0.039 0.048 0.071 0.049   || dis=0.00 || select=6/8
007/019-th : 0.102 0.101 0.107 0.121 0.129 0.140 0.147 0.154  ||  -0.195 -0.204 -0.146 -0.019 0.046 0.125 0.176 0.220   || dis=0.01 || select=7/8
008/019-th : 0.090 0.098 0.107 0.128 0.140 0.150 0.144 0.143  ||  -0.294 -0.208 -0.125 0.054 0.142 0.216 0.170 0.166    || dis=0.01 || select=5/8
009/019-th : 0.113 0.112 0.109 0.123 0.125 0.134 0.140 0.143  ||  -0.095 -0.109 -0.137 -0.010 0.004 0.076 0.119 0.138   || dis=0.00 || select=7/8
010/019-th : 0.111 0.114 0.117 0.128 0.130 0.135 0.133 0.133  ||  -0.114 -0.086 -0.061 0.029 0.046 0.080 0.070 0.070    || dis=0.00 || select=5/8
011/019-th : 0.109 0.109 0.110 0.119 0.128 0.136 0.144 0.145  ||  -0.131 -0.135 -0.126 -0.048 0.030 0.087 0.145 0.154   || dis=0.00 || select=7/8
012/019-th : 0.118 0.118 0.118 0.126 0.128 0.130 0.130 0.131  ||  -0.053 -0.055 -0.051 0.013 0.028 0.044 0.047 0.051    || dis=0.00 || select=7/8
013/019-th : 0.083 0.084 0.095 0.104 0.127 0.149 0.176 0.182  ||  -0.383 -0.370 -0.246 -0.160 0.046 0.206 0.371 0.403   || dis=0.01 || select=7/8
014/019-th : 0.080 0.084 0.097 0.123 0.144 0.154 0.164 0.154  ||  -0.408 -0.348 -0.205 0.028 0.183 0.251 0.314 0.255    || dis=0.01 || select=6/8
015/019-th : 0.087 0.086 0.091 0.111 0.133 0.153 0.169 0.170  ||  -0.334 -0.344 -0.283 -0.087 0.095 0.231 0.333 0.341   || dis=0.00 || select=7/8
016/019-th : 0.076 0.094 0.105 0.122 0.138 0.155 0.157 0.152  ||  -0.459 -0.254 -0.138 0.005 0.134 0.249 0.259 0.229    || dis=0.00 || select=6/8
017/019-th : 0.118 0.115 0.116 0.119 0.127 0.131 0.135 0.139  ||  -0.057 -0.080 -0.071 -0.047 0.023 0.055 0.080 0.112   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.120 0.128 0.138 0.152 0.165  ||  -0.353 -0.222 -0.081 -0.020 0.043 0.116 0.214 0.296   || dis=0.01 || select=7/8
[epoch=080/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.011
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:24:46] [epoch=080/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.721 (2.721)  Prec@1 22.27 (22.27) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:24:51] [epoch=080/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.078 (2.211)  Prec@1 54.76 (36.82) Prec@5 88.69 (82.90) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.82 Prec@5 82.90 Error@1 63.18 Error@5 17.10 Loss:2.211
***[2020-01-29 06:24:51]*** VALID [epoch=080/600] loss = 2.210702, accuracy@1 = 36.82, accuracy@5 = 82.90 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:24:52]*** start epoch=081/600 Time Left: [04:40:45], LR=[0.095570 ~ 0.095570], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=81, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.782938027756841, FLOP=40.81
[Search] : epoch=081/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:24:52] [epoch=081/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.773 (0.773)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44) Acls-loss 0.852 (0.852) FLOP-Loss 0.000 (0.000) Arch-Loss 0.852 (0.852)
**TRAIN** [2020-01-29 06:25:16] [epoch=081/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.887 (0.900)  Prec@1 72.62 (68.87) Prec@5 96.43 (97.27) Acls-loss 0.953 (0.923) FLOP-Loss 0.000 (0.000) Arch-Loss 0.953 (0.923)
 **TRAIN** Prec@1 68.87 Prec@5 97.27 Error@1 31.13 Error@5 2.73 Base-Loss:0.900, Arch-Loss=0.923
***[2020-01-29 06:25:16]*** TRAIN [epoch=081/600] base-loss = 0.900337, arch-loss = 0.922975, accuracy-1 = 68.87, accuracy-5 = 97.27
[epoch=081/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 16, 14, 32, 25, 32, 25, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.746432)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.238 0.381  ||  0.0142 -0.4539 0.0135  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.189 0.420  ||  -0.0085 -0.7320 0.0642  || discrepancy=0.03 || select=2/3
002/003-th : 0.315 0.223 0.462  ||  -0.1683 -0.5160 0.2128  || discrepancy=0.15 || select=2/3
-----------------------------------------------
000/019-th : 0.080 0.091 0.106 0.116 0.137 0.157 0.158 0.154  ||  -0.406 -0.275 -0.125 -0.034 0.130 0.265 0.274 0.248   || dis=0.00 || select=6/8
001/019-th : 0.119 0.119 0.123 0.122 0.128 0.130 0.129 0.130  ||  -0.039 -0.043 -0.011 -0.015 0.031 0.043 0.039 0.044   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.125 0.129 0.129 0.129 0.127 0.127  ||  -0.074 -0.043 0.006 0.037 0.036 0.039 0.023 0.021     || dis=0.00 || select=5/8
003/019-th : 0.123 0.124 0.125 0.127 0.126 0.125 0.125 0.124  ||  -0.015 -0.007 0.002 0.018 0.013 0.002 0.005 -0.005    || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.122 0.123 0.129 0.127 0.131 0.128  ||  -0.052 -0.032 -0.023 -0.016 0.031 0.017 0.048 0.020   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.121 0.123 0.129 0.129 0.129 0.130  ||  -0.048 -0.040 -0.028 -0.012 0.035 0.033 0.032 0.040   || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.122 0.122 0.130 0.131 0.134 0.131  ||  -0.090 -0.068 -0.021 -0.017 0.047 0.048 0.072 0.051   || dis=0.00 || select=6/8
007/019-th : 0.101 0.100 0.106 0.122 0.129 0.139 0.147 0.154  ||  -0.202 -0.207 -0.149 -0.009 0.049 0.123 0.179 0.226   || dis=0.01 || select=7/8
008/019-th : 0.090 0.098 0.106 0.126 0.142 0.151 0.144 0.144  ||  -0.298 -0.211 -0.129 0.042 0.158 0.220 0.171 0.172    || dis=0.01 || select=5/8
009/019-th : 0.113 0.111 0.108 0.123 0.127 0.134 0.141 0.143  ||  -0.097 -0.113 -0.144 -0.014 0.018 0.076 0.124 0.140   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.117 0.127 0.130 0.135 0.133 0.133  ||  -0.118 -0.086 -0.056 0.020 0.047 0.080 0.070 0.072    || dis=0.00 || select=5/8
011/019-th : 0.109 0.109 0.109 0.118 0.128 0.136 0.145 0.146  ||  -0.131 -0.135 -0.134 -0.058 0.030 0.086 0.151 0.156   || dis=0.00 || select=7/8
012/019-th : 0.117 0.117 0.118 0.126 0.129 0.130 0.131 0.131  ||  -0.058 -0.059 -0.054 0.012 0.037 0.044 0.053 0.054    || dis=0.00 || select=7/8
013/019-th : 0.083 0.083 0.094 0.102 0.127 0.151 0.177 0.183  ||  -0.385 -0.378 -0.251 -0.170 0.048 0.218 0.375 0.409   || dis=0.01 || select=7/8
014/019-th : 0.079 0.084 0.097 0.123 0.144 0.153 0.165 0.155  ||  -0.412 -0.358 -0.208 0.032 0.184 0.248 0.320 0.260    || dis=0.01 || select=6/8
015/019-th : 0.086 0.085 0.091 0.111 0.133 0.152 0.170 0.172  ||  -0.341 -0.352 -0.287 -0.090 0.098 0.231 0.342 0.350   || dis=0.00 || select=7/8
016/019-th : 0.076 0.093 0.106 0.123 0.136 0.157 0.157 0.153  ||  -0.469 -0.261 -0.134 0.016 0.119 0.258 0.260 0.235    || dis=0.00 || select=6/8
017/019-th : 0.117 0.115 0.116 0.119 0.127 0.132 0.135 0.139  ||  -0.059 -0.082 -0.068 -0.043 0.019 0.058 0.081 0.111   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.121 0.128 0.136 0.151 0.165  ||  -0.352 -0.222 -0.078 -0.013 0.045 0.106 0.207 0.299   || dis=0.01 || select=7/8
[epoch=081/600] FLOP : 27.75 MB, ratio : 0.6798, Expected-ratio : 0.7000, Discrepancy : 0.011
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:25:17] [epoch=081/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.057 (2.057)  Prec@1 31.64 (31.64) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:25:23] [epoch=081/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.990 (2.190)  Prec@1 41.67 (37.14) Prec@5 87.50 (82.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.14 Prec@5 82.40 Error@1 62.86 Error@5 17.60 Loss:2.190
***[2020-01-29 06:25:23]*** VALID [epoch=081/600] loss = 2.190420, accuracy@1 = 37.14, accuracy@5 = 82.40 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:25:23]*** start epoch=082/600 Time Left: [04:40:04], LR=[0.095462 ~ 0.095462], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=82, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.777628467165318, FLOP=40.81
[Search] : epoch=082/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:25:23] [epoch=082/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.819 (0.819)  Prec@1 70.70 (70.70) Prec@5 98.83 (98.83) Acls-loss 1.137 (1.137) FLOP-Loss 0.000 (0.000) Arch-Loss 1.137 (1.137)
**TRAIN** [2020-01-29 06:25:47] [epoch=082/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.024 (0.901)  Prec@1 68.45 (68.86) Prec@5 96.43 (97.14) Acls-loss 1.127 (0.929) FLOP-Loss 0.000 (0.051) Arch-Loss 1.127 (1.032)
 **TRAIN** Prec@1 68.86 Prec@5 97.14 Error@1 31.14 Error@5 2.86 Base-Loss:0.901, Arch-Loss=1.032
***[2020-01-29 06:25:48]*** TRAIN [epoch=082/600] base-loss = 0.901479, arch-loss = 1.032051, accuracy-1 = 68.86, accuracy-5 = 97.14
[epoch=082/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 9, 9, 14, 16, 14, 32, 25, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.445376)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.240 0.379  ||  0.0171 -0.4462 0.0110  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.189 0.420  ||  -0.0077 -0.7369 0.0644  || discrepancy=0.03 || select=2/3
002/003-th : 0.314 0.225 0.461  ||  -0.1696 -0.5016 0.2137  || discrepancy=0.15 || select=2/3
-----------------------------------------------
000/019-th : 0.080 0.091 0.106 0.117 0.135 0.158 0.158 0.154  ||  -0.409 -0.275 -0.124 -0.031 0.115 0.270 0.275 0.249   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.123 0.128 0.130 0.129 0.129  ||  -0.038 -0.042 -0.007 -0.013 0.028 0.042 0.036 0.042   || dis=0.00 || select=5/8
002/019-th : 0.115 0.119 0.125 0.130 0.128 0.129 0.127 0.127  ||  -0.073 -0.041 0.006 0.042 0.031 0.040 0.019 0.020     || dis=0.00 || select=3/8
003/019-th : 0.123 0.124 0.125 0.127 0.126 0.125 0.125 0.124  ||  -0.013 -0.004 0.004 0.018 0.013 0.001 0.002 -0.007    || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.123 0.124 0.128 0.126 0.131 0.127  ||  -0.049 -0.030 -0.020 -0.012 0.025 0.011 0.047 0.018   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.121 0.123 0.129 0.129 0.129 0.130  ||  -0.044 -0.039 -0.029 -0.016 0.035 0.035 0.029 0.038   || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.122 0.122 0.131 0.131 0.134 0.130  ||  -0.089 -0.068 -0.018 -0.022 0.050 0.049 0.074 0.047   || dis=0.00 || select=6/8
007/019-th : 0.100 0.100 0.107 0.123 0.128 0.139 0.147 0.155  ||  -0.205 -0.208 -0.142 -0.000 0.039 0.122 0.178 0.226   || dis=0.01 || select=7/8
008/019-th : 0.089 0.097 0.107 0.127 0.142 0.152 0.143 0.143  ||  -0.305 -0.214 -0.123 0.049 0.158 0.228 0.172 0.170    || dis=0.01 || select=5/8
009/019-th : 0.113 0.111 0.107 0.121 0.128 0.134 0.141 0.144  ||  -0.095 -0.112 -0.152 -0.032 0.029 0.072 0.126 0.143   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.118 0.128 0.129 0.133 0.133 0.134  ||  -0.120 -0.086 -0.052 0.033 0.040 0.071 0.072 0.073    || dis=0.00 || select=7/8
011/019-th : 0.109 0.109 0.109 0.119 0.128 0.135 0.145 0.146  ||  -0.133 -0.130 -0.135 -0.049 0.027 0.079 0.151 0.157   || dis=0.00 || select=7/8
012/019-th : 0.117 0.117 0.118 0.126 0.130 0.130 0.131 0.131  ||  -0.059 -0.060 -0.054 0.016 0.042 0.046 0.052 0.054    || dis=0.00 || select=7/8
013/019-th : 0.082 0.083 0.094 0.101 0.129 0.151 0.177 0.183  ||  -0.388 -0.383 -0.255 -0.184 0.061 0.223 0.380 0.414   || dis=0.01 || select=7/8
014/019-th : 0.079 0.084 0.097 0.125 0.144 0.151 0.165 0.155  ||  -0.410 -0.358 -0.207 0.041 0.185 0.233 0.322 0.260    || dis=0.01 || select=6/8
015/019-th : 0.086 0.085 0.090 0.109 0.133 0.152 0.172 0.173  ||  -0.342 -0.356 -0.296 -0.101 0.096 0.227 0.349 0.359   || dis=0.00 || select=7/8
016/019-th : 0.076 0.093 0.106 0.123 0.136 0.156 0.157 0.154  ||  -0.471 -0.264 -0.135 0.018 0.119 0.252 0.263 0.238    || dis=0.00 || select=6/8
017/019-th : 0.118 0.115 0.117 0.120 0.126 0.132 0.135 0.139  ||  -0.057 -0.081 -0.064 -0.037 0.009 0.055 0.079 0.109   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.113 0.120 0.130 0.136 0.149 0.165  ||  -0.344 -0.221 -0.079 -0.017 0.059 0.107 0.198 0.296   || dis=0.02 || select=7/8
[epoch=082/600] FLOP : 27.45 MB, ratio : 0.6725, Expected-ratio : 0.7000, Discrepancy : 0.011
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:25:48] [epoch=082/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.312 (2.312)  Prec@1 35.55 (35.55) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:25:54] [epoch=082/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.744 (2.364)  Prec@1 40.48 (37.58) Prec@5 85.12 (83.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.58 Prec@5 83.99 Error@1 62.42 Error@5 16.01 Loss:2.364
***[2020-01-29 06:25:54]*** VALID [epoch=082/600] loss = 2.363992, accuracy@1 = 37.58, accuracy@5 = 83.99 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:25:54]*** start epoch=083/600 Time Left: [04:39:25], LR=[0.095352 ~ 0.095352], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=83, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.772257835014089, FLOP=40.81
[Search] : epoch=083/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:25:55] [epoch=083/600][000/098] Time 0.64 (0.64) Data 0.38 (0.38) Base-Loss 0.883 (0.883)  Prec@1 66.02 (66.02) Prec@5 99.22 (99.22) Acls-loss 1.016 (1.016) FLOP-Loss 0.000 (0.000) Arch-Loss 1.016 (1.016)
**TRAIN** [2020-01-29 06:26:19] [epoch=083/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.920 (0.906)  Prec@1 69.05 (69.02) Prec@5 98.81 (97.28) Acls-loss 1.051 (0.910) FLOP-Loss 0.000 (0.000) Arch-Loss 1.051 (0.910)
 **TRAIN** Prec@1 69.02 Prec@5 97.28 Error@1 30.98 Error@5 2.72 Base-Loss:0.906, Arch-Loss=0.910
***[2020-01-29 06:26:19]*** TRAIN [epoch=083/600] base-loss = 0.906219, arch-loss = 0.909894, accuracy-1 = 69.02, accuracy-5 = 97.28
[epoch=083/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 9, 9, 14, 16, 14, 32, 25, 32, 32, 32, 28, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.065664)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.380 0.241 0.379  ||  0.0160 -0.4374 0.0125  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.187 0.422  ||  -0.0091 -0.7443 0.0668  || discrepancy=0.03 || select=2/3
002/003-th : 0.312 0.224 0.464  ||  -0.1758 -0.5076 0.2204  || discrepancy=0.15 || select=2/3
-----------------------------------------------
000/019-th : 0.079 0.091 0.107 0.116 0.135 0.157 0.159 0.155  ||  -0.415 -0.278 -0.123 -0.040 0.115 0.268 0.280 0.255   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.123 0.122 0.128 0.130 0.129 0.130  ||  -0.038 -0.044 -0.008 -0.016 0.032 0.042 0.037 0.042   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.125 0.129 0.128 0.129 0.127 0.127  ||  -0.074 -0.043 0.005 0.041 0.033 0.041 0.020 0.021     || dis=0.00 || select=3/8
003/019-th : 0.123 0.124 0.125 0.128 0.126 0.125 0.125 0.124  ||  -0.016 -0.004 0.004 0.022 0.011 0.001 0.003 -0.007    || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.123 0.124 0.128 0.126 0.131 0.128  ||  -0.051 -0.032 -0.020 -0.011 0.025 0.011 0.049 0.020   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.121 0.124 0.129 0.129 0.129 0.130  ||  -0.046 -0.040 -0.033 -0.010 0.032 0.035 0.030 0.041   || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.122 0.122 0.131 0.130 0.134 0.131  ||  -0.091 -0.070 -0.023 -0.019 0.053 0.045 0.077 0.050   || dis=0.00 || select=6/8
007/019-th : 0.100 0.100 0.107 0.124 0.127 0.140 0.148 0.155  ||  -0.212 -0.211 -0.143 0.009 0.031 0.127 0.183 0.229    || dis=0.01 || select=7/8
008/019-th : 0.088 0.096 0.106 0.129 0.143 0.152 0.143 0.143  ||  -0.317 -0.221 -0.130 0.068 0.172 0.237 0.174 0.173    || dis=0.01 || select=5/8
009/019-th : 0.113 0.111 0.107 0.120 0.129 0.134 0.142 0.144  ||  -0.099 -0.116 -0.151 -0.035 0.033 0.073 0.130 0.146   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.118 0.129 0.128 0.134 0.134 0.134  ||  -0.120 -0.089 -0.056 0.038 0.029 0.072 0.074 0.075    || dis=0.00 || select=7/8
011/019-th : 0.109 0.109 0.109 0.119 0.128 0.136 0.145 0.146  ||  -0.136 -0.137 -0.134 -0.040 0.029 0.089 0.150 0.159   || dis=0.00 || select=7/8
012/019-th : 0.117 0.116 0.118 0.126 0.130 0.131 0.131 0.131  ||  -0.062 -0.065 -0.053 0.010 0.041 0.054 0.057 0.055    || dis=0.00 || select=6/8
013/019-th : 0.082 0.082 0.093 0.101 0.127 0.152 0.178 0.184  ||  -0.394 -0.384 -0.260 -0.184 0.050 0.230 0.384 0.419   || dis=0.01 || select=7/8
014/019-th : 0.078 0.083 0.097 0.124 0.145 0.151 0.165 0.156  ||  -0.419 -0.369 -0.209 0.041 0.198 0.236 0.325 0.267    || dis=0.01 || select=6/8
015/019-th : 0.085 0.083 0.089 0.109 0.134 0.153 0.172 0.174  ||  -0.349 -0.369 -0.302 -0.102 0.106 0.235 0.357 0.367   || dis=0.00 || select=7/8
016/019-th : 0.075 0.093 0.105 0.125 0.134 0.157 0.158 0.154  ||  -0.480 -0.267 -0.142 0.030 0.101 0.264 0.266 0.243    || dis=0.00 || select=6/8
017/019-th : 0.117 0.115 0.117 0.121 0.125 0.132 0.135 0.139  ||  -0.058 -0.082 -0.064 -0.032 0.006 0.056 0.078 0.110   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.112 0.121 0.132 0.135 0.150 0.166  ||  -0.357 -0.224 -0.089 -0.009 0.077 0.097 0.201 0.306   || dis=0.02 || select=7/8
[epoch=083/600] FLOP : 28.07 MB, ratio : 0.6877, Expected-ratio : 0.7000, Discrepancy : 0.011
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:26:19] [epoch=083/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.238 (2.238)  Prec@1 41.41 (41.41) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:26:25] [epoch=083/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.627 (2.125)  Prec@1 42.26 (39.22) Prec@5 89.88 (84.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.22 Prec@5 84.28 Error@1 60.78 Error@5 15.72 Loss:2.125
***[2020-01-29 06:26:25]*** VALID [epoch=083/600] loss = 2.124627, accuracy@1 = 39.22, accuracy@5 = 84.28 | Best-Valid-Acc@1=39.62, Error@1=60.38
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:26:25]*** start epoch=084/600 Time Left: [04:38:43], LR=[0.095241 ~ 0.095241], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=84, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.766826278541748, FLOP=40.81
[Search] : epoch=084/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:26:26] [epoch=084/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.940 (0.940)  Prec@1 62.89 (62.89) Prec@5 97.66 (97.66) Acls-loss 0.953 (0.953) FLOP-Loss 0.000 (0.000) Arch-Loss 0.953 (0.953)
**TRAIN** [2020-01-29 06:26:50] [epoch=084/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.801 (0.895)  Prec@1 72.02 (69.04) Prec@5 96.43 (97.36) Acls-loss 0.775 (0.919) FLOP-Loss 0.000 (0.000) Arch-Loss 0.775 (0.919)
 **TRAIN** Prec@1 69.04 Prec@5 97.36 Error@1 30.96 Error@5 2.64 Base-Loss:0.895, Arch-Loss=0.919
***[2020-01-29 06:26:50]*** TRAIN [epoch=084/600] base-loss = 0.894625, arch-loss = 0.919129, accuracy-1 = 69.04, accuracy-5 = 97.36
[epoch=084/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 9, 14, 16, 14, 32, 25, 32, 32, 32, 28, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.55104)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.379 0.242 0.379  ||  0.0149 -0.4327 0.0141  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.189 0.422  ||  -0.0106 -0.7328 0.0689  || discrepancy=0.03 || select=2/3
002/003-th : 0.310 0.224 0.466  ||  -0.1807 -0.5064 0.2256  || discrepancy=0.16 || select=2/3
-----------------------------------------------
000/019-th : 0.079 0.091 0.106 0.116 0.134 0.158 0.160 0.156  ||  -0.420 -0.281 -0.130 -0.036 0.109 0.270 0.285 0.258   || dis=0.00 || select=6/8
001/019-th : 0.119 0.119 0.123 0.122 0.128 0.130 0.129 0.130  ||  -0.039 -0.045 -0.010 -0.014 0.034 0.043 0.038 0.043   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.125 0.129 0.128 0.129 0.127 0.127  ||  -0.077 -0.044 0.005 0.040 0.033 0.042 0.023 0.022     || dis=0.00 || select=5/8
003/019-th : 0.122 0.124 0.125 0.127 0.127 0.125 0.125 0.124  ||  -0.018 -0.005 0.003 0.021 0.018 0.002 0.004 -0.005    || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.123 0.123 0.128 0.127 0.132 0.128  ||  -0.051 -0.036 -0.020 -0.017 0.023 0.011 0.052 0.022   || dis=0.00 || select=6/8
005/019-th : 0.119 0.119 0.121 0.124 0.128 0.129 0.129 0.130  ||  -0.049 -0.044 -0.031 -0.005 0.027 0.032 0.033 0.044   || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.121 0.123 0.132 0.130 0.134 0.131  ||  -0.091 -0.072 -0.026 -0.013 0.060 0.043 0.072 0.054   || dis=0.00 || select=6/8
007/019-th : 0.100 0.099 0.106 0.124 0.127 0.140 0.149 0.156  ||  -0.213 -0.217 -0.147 0.003 0.031 0.124 0.187 0.235    || dis=0.01 || select=7/8
008/019-th : 0.087 0.096 0.105 0.128 0.143 0.152 0.144 0.144  ||  -0.325 -0.227 -0.135 0.066 0.174 0.237 0.178 0.182    || dis=0.01 || select=5/8
009/019-th : 0.113 0.110 0.106 0.119 0.129 0.134 0.143 0.145  ||  -0.101 -0.122 -0.159 -0.045 0.032 0.075 0.136 0.153   || dis=0.00 || select=7/8
010/019-th : 0.110 0.113 0.118 0.127 0.128 0.134 0.134 0.134  ||  -0.120 -0.094 -0.050 0.023 0.027 0.076 0.075 0.077    || dis=0.00 || select=7/8
011/019-th : 0.108 0.109 0.109 0.119 0.127 0.136 0.145 0.147  ||  -0.139 -0.133 -0.135 -0.049 0.018 0.086 0.151 0.165   || dis=0.00 || select=7/8
012/019-th : 0.117 0.116 0.118 0.125 0.130 0.131 0.131 0.131  ||  -0.063 -0.065 -0.051 0.008 0.049 0.050 0.056 0.056    || dis=0.00 || select=6/8
013/019-th : 0.081 0.082 0.093 0.100 0.128 0.151 0.179 0.186  ||  -0.397 -0.394 -0.263 -0.187 0.053 0.219 0.394 0.428   || dis=0.01 || select=7/8
014/019-th : 0.078 0.081 0.097 0.124 0.145 0.153 0.165 0.157  ||  -0.426 -0.383 -0.210 0.038 0.195 0.247 0.326 0.277    || dis=0.01 || select=6/8
015/019-th : 0.084 0.083 0.089 0.110 0.132 0.153 0.175 0.175  ||  -0.359 -0.377 -0.307 -0.091 0.090 0.235 0.370 0.373   || dis=0.00 || select=7/8
016/019-th : 0.074 0.092 0.104 0.123 0.136 0.158 0.158 0.155  ||  -0.492 -0.267 -0.147 0.023 0.117 0.267 0.267 0.251    || dis=0.00 || select=6/8
017/019-th : 0.117 0.114 0.116 0.121 0.126 0.131 0.135 0.139  ||  -0.060 -0.084 -0.067 -0.027 0.011 0.053 0.078 0.114   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.122 0.131 0.134 0.150 0.167  ||  -0.360 -0.225 -0.084 -0.006 0.066 0.089 0.202 0.311   || dis=0.02 || select=7/8
[epoch=084/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.012
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:26:50] [epoch=084/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.790 (1.790)  Prec@1 39.06 (39.06) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:26:56] [epoch=084/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.675 (2.059)  Prec@1 46.43 (39.80) Prec@5 88.10 (84.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.80 Prec@5 84.21 Error@1 60.20 Error@5 15.79 Loss:2.059
***[2020-01-29 06:26:56]*** VALID [epoch=084/600] loss = 2.058889, accuracy@1 = 39.80, accuracy@5 = 84.21 | Best-Valid-Acc@1=39.62, Error@1=60.38
Currently, the best validation accuracy found at 084-epoch :: acc@1=39.80, acc@5=84.21, error@1=60.20, error@5=15.79, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:26:56]*** start epoch=085/600 Time Left: [04:38:05], LR=[0.095129 ~ 0.095129], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=85, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.7613339466571585, FLOP=40.81
[Search] : epoch=085/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:26:57] [epoch=085/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.985 (0.985)  Prec@1 64.84 (64.84) Prec@5 96.48 (96.48) Acls-loss 0.878 (0.878) FLOP-Loss 0.000 (0.000) Arch-Loss 0.878 (0.878)
**TRAIN** [2020-01-29 06:27:21] [epoch=085/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.846 (0.891)  Prec@1 69.64 (69.23) Prec@5 98.21 (97.46) Acls-loss 1.020 (0.917) FLOP-Loss 0.000 (0.026) Arch-Loss 1.020 (0.969)
 **TRAIN** Prec@1 69.23 Prec@5 97.46 Error@1 30.77 Error@5 2.54 Base-Loss:0.891, Arch-Loss=0.969
***[2020-01-29 06:27:21]*** TRAIN [epoch=085/600] base-loss = 0.891040, arch-loss = 0.968890, accuracy-1 = 69.23, accuracy-5 = 97.46
[epoch=085/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 12, 11, 14, 16, 14, 32, 25, 32, 32, 32, 28, 64, 57, 64, 51, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.270144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.380 0.241 0.379  ||  0.0151 -0.4388 0.0147  || discrepancy=0.00 || select=0/3
001/003-th : 0.389 0.188 0.423  ||  -0.0113 -0.7400 0.0707  || discrepancy=0.03 || select=2/3
002/003-th : 0.308 0.225 0.466  ||  -0.1843 -0.4994 0.2292  || discrepancy=0.16 || select=2/3
-----------------------------------------------
000/019-th : 0.079 0.092 0.107 0.117 0.131 0.156 0.161 0.157  ||  -0.420 -0.279 -0.124 -0.034 0.082 0.253 0.287 0.262   || dis=0.00 || select=6/8
001/019-th : 0.119 0.119 0.123 0.123 0.128 0.130 0.129 0.130  ||  -0.040 -0.045 -0.011 -0.011 0.029 0.043 0.038 0.044   || dis=0.00 || select=7/8
002/019-th : 0.115 0.119 0.125 0.129 0.129 0.130 0.127 0.127  ||  -0.077 -0.045 0.007 0.035 0.037 0.042 0.022 0.022     || dis=0.00 || select=5/8
003/019-th : 0.122 0.124 0.125 0.127 0.128 0.125 0.125 0.124  ||  -0.019 -0.004 0.002 0.017 0.025 0.001 0.005 -0.006    || dis=0.00 || select=4/8
004/019-th : 0.119 0.121 0.122 0.123 0.129 0.126 0.132 0.128  ||  -0.051 -0.037 -0.021 -0.013 0.033 0.010 0.052 0.021   || dis=0.00 || select=6/8
005/019-th : 0.119 0.119 0.121 0.125 0.129 0.129 0.129 0.130  ||  -0.050 -0.045 -0.029 -0.001 0.034 0.032 0.032 0.043   || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.121 0.122 0.131 0.130 0.134 0.131  ||  -0.092 -0.072 -0.025 -0.017 0.054 0.044 0.073 0.054   || dis=0.00 || select=6/8
007/019-th : 0.099 0.099 0.106 0.124 0.127 0.140 0.149 0.156  ||  -0.215 -0.220 -0.146 0.005 0.033 0.125 0.189 0.236    || dis=0.01 || select=7/8
008/019-th : 0.086 0.094 0.105 0.128 0.144 0.154 0.144 0.144  ||  -0.332 -0.244 -0.130 0.065 0.184 0.250 0.186 0.184    || dis=0.01 || select=5/8
009/019-th : 0.113 0.111 0.107 0.119 0.128 0.135 0.143 0.146  ||  -0.102 -0.122 -0.157 -0.050 0.022 0.079 0.137 0.154   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.118 0.126 0.129 0.134 0.134 0.135  ||  -0.123 -0.090 -0.051 0.011 0.034 0.076 0.073 0.080    || dis=0.00 || select=7/8
011/019-th : 0.108 0.109 0.109 0.119 0.125 0.136 0.145 0.148  ||  -0.142 -0.133 -0.131 -0.049 0.005 0.090 0.151 0.168   || dis=0.00 || select=7/8
012/019-th : 0.116 0.116 0.119 0.125 0.129 0.131 0.132 0.132  ||  -0.066 -0.066 -0.047 0.006 0.036 0.052 0.058 0.057    || dis=0.00 || select=6/8
013/019-th : 0.081 0.082 0.093 0.099 0.129 0.151 0.180 0.186  ||  -0.404 -0.391 -0.265 -0.198 0.064 0.220 0.398 0.432   || dis=0.01 || select=7/8
014/019-th : 0.078 0.082 0.096 0.124 0.142 0.152 0.167 0.159  ||  -0.431 -0.383 -0.216 0.038 0.175 0.242 0.333 0.285    || dis=0.01 || select=6/8
015/019-th : 0.084 0.082 0.088 0.109 0.132 0.154 0.175 0.176  ||  -0.366 -0.384 -0.310 -0.095 0.091 0.244 0.374 0.381   || dis=0.00 || select=7/8
016/019-th : 0.073 0.092 0.105 0.124 0.135 0.158 0.157 0.156  ||  -0.498 -0.273 -0.142 0.027 0.112 0.271 0.262 0.258    || dis=0.00 || select=5/8
017/019-th : 0.117 0.114 0.117 0.121 0.125 0.132 0.135 0.139  ||  -0.059 -0.087 -0.063 -0.031 0.001 0.059 0.079 0.112   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.112 0.122 0.132 0.134 0.149 0.167  ||  -0.358 -0.220 -0.089 -0.002 0.072 0.088 0.194 0.311   || dis=0.02 || select=7/8
[epoch=085/600] FLOP : 28.27 MB, ratio : 0.6927, Expected-ratio : 0.7000, Discrepancy : 0.012
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:27:21] [epoch=085/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.677 (2.677)  Prec@1 29.30 (29.30) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:27:27] [epoch=085/600][097/098] Time 0.12 (0.07) Data 0.00 (0.00) Loss 2.238 (2.225)  Prec@1 17.86 (38.53) Prec@5 78.57 (84.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.53 Prec@5 84.08 Error@1 61.47 Error@5 15.92 Loss:2.225
***[2020-01-29 06:27:28]*** VALID [epoch=085/600] loss = 2.224875, accuracy@1 = 38.53, accuracy@5 = 84.08 | Best-Valid-Acc@1=39.80, Error@1=60.20
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:27:28]*** start epoch=086/600 Time Left: [04:37:25], LR=[0.095016 ~ 0.095016], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=86, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.755780989935374, FLOP=40.81
[Search] : epoch=086/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:27:28] [epoch=086/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.947 (0.947)  Prec@1 67.19 (67.19) Prec@5 96.88 (96.88) Acls-loss 1.027 (1.027) FLOP-Loss 0.000 (0.000) Arch-Loss 1.027 (1.027)
**TRAIN** [2020-01-29 06:27:52] [epoch=086/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.891 (0.904)  Prec@1 72.62 (68.85) Prec@5 98.21 (97.34) Acls-loss 0.864 (0.922) FLOP-Loss 0.000 (0.103) Arch-Loss 0.864 (1.128)
 **TRAIN** Prec@1 68.85 Prec@5 97.34 Error@1 31.15 Error@5 2.66 Base-Loss:0.904, Arch-Loss=1.128
***[2020-01-29 06:27:52]*** TRAIN [epoch=086/600] base-loss = 0.903901, arch-loss = 1.127735, accuracy-1 = 68.85, accuracy-5 = 97.34
[epoch=086/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 9, 9, 14, 16, 14, 32, 25, 32, 25, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.261056)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.243 0.376  ||  0.0216 -0.4305 0.0088  || discrepancy=0.01 || select=0/3
001/003-th : 0.392 0.187 0.421  ||  -0.0053 -0.7460 0.0659  || discrepancy=0.03 || select=2/3
002/003-th : 0.309 0.227 0.464  ||  -0.1818 -0.4891 0.2267  || discrepancy=0.16 || select=2/3
-----------------------------------------------
000/019-th : 0.079 0.092 0.108 0.117 0.132 0.154 0.161 0.157  ||  -0.420 -0.275 -0.113 -0.030 0.084 0.245 0.283 0.258   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.124 0.124 0.127 0.129 0.128 0.129  ||  -0.034 -0.043 -0.005 -0.003 0.024 0.037 0.033 0.039   || dis=0.00 || select=7/8
002/019-th : 0.116 0.119 0.126 0.129 0.129 0.129 0.126 0.126  ||  -0.070 -0.040 0.014 0.037 0.035 0.035 0.016 0.016     || dis=0.00 || select=3/8
003/019-th : 0.123 0.125 0.126 0.127 0.127 0.124 0.125 0.123  ||  -0.015 0.003 0.011 0.017 0.016 -0.005 -0.000 -0.011   || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.123 0.124 0.129 0.126 0.130 0.127  ||  -0.046 -0.033 -0.012 -0.005 0.035 0.007 0.043 0.015   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.121 0.126 0.128 0.128 0.128 0.130  ||  -0.046 -0.037 -0.031 0.011 0.023 0.026 0.027 0.039    || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.123 0.122 0.131 0.129 0.134 0.131  ||  -0.087 -0.070 -0.017 -0.019 0.048 0.037 0.072 0.050   || dis=0.00 || select=6/8
007/019-th : 0.099 0.099 0.107 0.124 0.128 0.140 0.148 0.155  ||  -0.217 -0.216 -0.139 0.008 0.039 0.128 0.188 0.229    || dis=0.01 || select=7/8
008/019-th : 0.086 0.094 0.106 0.131 0.142 0.154 0.144 0.143  ||  -0.335 -0.245 -0.122 0.088 0.172 0.254 0.185 0.176    || dis=0.01 || select=5/8
009/019-th : 0.113 0.110 0.107 0.119 0.129 0.134 0.143 0.145  ||  -0.100 -0.122 -0.151 -0.050 0.031 0.075 0.134 0.151   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.119 0.128 0.128 0.134 0.133 0.133  ||  -0.119 -0.085 -0.046 0.028 0.030 0.073 0.071 0.070    || dis=0.00 || select=5/8
011/019-th : 0.109 0.110 0.110 0.119 0.125 0.136 0.144 0.147  ||  -0.135 -0.130 -0.126 -0.049 0.000 0.084 0.145 0.165   || dis=0.00 || select=7/8
012/019-th : 0.117 0.117 0.119 0.125 0.130 0.130 0.131 0.131  ||  -0.063 -0.063 -0.040 0.010 0.044 0.048 0.051 0.053    || dis=0.00 || select=7/8
013/019-th : 0.081 0.081 0.093 0.099 0.128 0.151 0.180 0.186  ||  -0.400 -0.398 -0.264 -0.197 0.054 0.225 0.400 0.432   || dis=0.01 || select=7/8
014/019-th : 0.078 0.082 0.097 0.124 0.144 0.151 0.166 0.158  ||  -0.430 -0.380 -0.211 0.037 0.191 0.238 0.329 0.280    || dis=0.01 || select=6/8
015/019-th : 0.083 0.082 0.088 0.108 0.133 0.154 0.175 0.176  ||  -0.369 -0.381 -0.315 -0.103 0.103 0.250 0.374 0.382   || dis=0.00 || select=7/8
016/019-th : 0.073 0.093 0.104 0.125 0.137 0.156 0.157 0.156  ||  -0.496 -0.265 -0.144 0.033 0.127 0.255 0.260 0.254    || dis=0.00 || select=6/8
017/019-th : 0.118 0.115 0.118 0.121 0.123 0.132 0.135 0.139  ||  -0.052 -0.083 -0.056 -0.030 -0.015 0.057 0.076 0.106  || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.113 0.122 0.131 0.132 0.149 0.167  ||  -0.352 -0.212 -0.084 -0.002 0.068 0.073 0.193 0.307   || dis=0.02 || select=7/8
[epoch=086/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.012
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:27:53] [epoch=086/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.397 (2.397)  Prec@1 31.64 (31.64) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:27:59] [epoch=086/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.265 (2.235)  Prec@1 57.74 (38.88) Prec@5 92.26 (83.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.88 Prec@5 83.94 Error@1 61.12 Error@5 16.06 Loss:2.235
***[2020-01-29 06:27:59]*** VALID [epoch=086/600] loss = 2.234964, accuracy@1 = 38.88, accuracy@5 = 83.94 | Best-Valid-Acc@1=39.80, Error@1=60.20
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:27:59]*** start epoch=087/600 Time Left: [04:36:46], LR=[0.094901 ~ 0.094901], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=87, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.750167560613508, FLOP=40.81
[Search] : epoch=087/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:28:00] [epoch=087/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.842 (0.842)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 0.970 (0.970) FLOP-Loss 0.000 (0.000) Arch-Loss 0.970 (0.970)
**TRAIN** [2020-01-29 06:28:24] [epoch=087/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.858 (0.893)  Prec@1 73.21 (69.28) Prec@5 95.83 (97.37) Acls-loss 0.957 (0.912) FLOP-Loss 0.000 (0.026) Arch-Loss 0.957 (0.964)
 **TRAIN** Prec@1 69.28 Prec@5 97.37 Error@1 30.72 Error@5 2.63 Base-Loss:0.893, Arch-Loss=0.964
***[2020-01-29 06:28:24]*** TRAIN [epoch=087/600] base-loss = 0.893373, arch-loss = 0.963804, accuracy-1 = 69.28, accuracy-5 = 97.37
[epoch=087/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 11, 14, 16, 14, 32, 25, 32, 28, 32, 28, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.544448)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.382 0.242 0.377  ||  0.0224 -0.4346 0.0088  || discrepancy=0.01 || select=0/3
001/003-th : 0.392 0.187 0.421  ||  -0.0052 -0.7480 0.0669  || discrepancy=0.03 || select=2/3
002/003-th : 0.307 0.226 0.467  ||  -0.1871 -0.4930 0.2327  || discrepancy=0.16 || select=2/3
-----------------------------------------------
000/019-th : 0.079 0.092 0.108 0.117 0.132 0.156 0.161 0.156  ||  -0.426 -0.273 -0.112 -0.035 0.086 0.255 0.285 0.258   || dis=0.01 || select=6/8
001/019-th : 0.120 0.119 0.124 0.125 0.127 0.129 0.128 0.129  ||  -0.034 -0.045 -0.003 0.005 0.025 0.037 0.032 0.038    || dis=0.00 || select=7/8
002/019-th : 0.116 0.120 0.126 0.129 0.129 0.129 0.126 0.126  ||  -0.069 -0.038 0.014 0.035 0.035 0.034 0.017 0.014     || dis=0.00 || select=4/8
003/019-th : 0.123 0.125 0.126 0.126 0.127 0.124 0.125 0.123  ||  -0.014 0.005 0.012 0.011 0.015 -0.007 0.001 -0.013    || dis=0.00 || select=4/8
004/019-th : 0.119 0.121 0.124 0.125 0.128 0.126 0.131 0.127  ||  -0.046 -0.034 -0.008 -0.001 0.028 0.005 0.044 0.015   || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.121 0.125 0.127 0.128 0.128 0.130  ||  -0.043 -0.034 -0.032 0.002 0.018 0.026 0.024 0.039    || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.123 0.123 0.130 0.129 0.134 0.131  ||  -0.088 -0.070 -0.013 -0.016 0.043 0.033 0.074 0.050   || dis=0.00 || select=6/8
007/019-th : 0.099 0.099 0.107 0.123 0.127 0.141 0.148 0.156  ||  -0.220 -0.216 -0.144 0.001 0.030 0.135 0.187 0.236    || dis=0.01 || select=7/8
008/019-th : 0.085 0.094 0.105 0.132 0.141 0.155 0.145 0.143  ||  -0.343 -0.244 -0.135 0.095 0.166 0.258 0.193 0.178    || dis=0.01 || select=5/8
009/019-th : 0.113 0.110 0.107 0.119 0.128 0.134 0.143 0.146  ||  -0.103 -0.123 -0.151 -0.050 0.023 0.075 0.137 0.155   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.120 0.126 0.128 0.134 0.134 0.134  ||  -0.120 -0.084 -0.036 0.015 0.026 0.070 0.071 0.070    || dis=0.00 || select=6/8
011/019-th : 0.109 0.110 0.109 0.119 0.124 0.136 0.145 0.147  ||  -0.133 -0.127 -0.133 -0.047 -0.008 0.082 0.149 0.165  || dis=0.00 || select=7/8
012/019-th : 0.116 0.117 0.119 0.126 0.129 0.131 0.131 0.131  ||  -0.067 -0.061 -0.043 0.013 0.040 0.051 0.054 0.053    || dis=0.00 || select=6/8
013/019-th : 0.081 0.081 0.092 0.101 0.127 0.150 0.181 0.188  ||  -0.405 -0.398 -0.268 -0.181 0.047 0.213 0.401 0.440   || dis=0.01 || select=7/8
014/019-th : 0.077 0.082 0.096 0.124 0.144 0.152 0.167 0.158  ||  -0.433 -0.380 -0.216 0.038 0.184 0.239 0.336 0.280    || dis=0.01 || select=6/8
015/019-th : 0.082 0.080 0.087 0.108 0.133 0.155 0.176 0.178  ||  -0.380 -0.401 -0.315 -0.106 0.107 0.260 0.383 0.394   || dis=0.00 || select=7/8
016/019-th : 0.073 0.092 0.103 0.125 0.138 0.156 0.157 0.156  ||  -0.501 -0.267 -0.153 0.034 0.137 0.255 0.266 0.257    || dis=0.00 || select=6/8
017/019-th : 0.119 0.115 0.118 0.120 0.123 0.132 0.135 0.139  ||  -0.052 -0.083 -0.057 -0.039 -0.015 0.052 0.077 0.109  || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.121 0.133 0.132 0.149 0.168  ||  -0.357 -0.225 -0.078 -0.012 0.081 0.076 0.195 0.313   || dis=0.02 || select=7/8
[epoch=087/600] FLOP : 27.54 MB, ratio : 0.6749, Expected-ratio : 0.7000, Discrepancy : 0.012
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:28:24] [epoch=087/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 2.530 (2.530)  Prec@1 35.16 (35.16) Prec@5 80.08 (80.08) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:28:30] [epoch=087/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.631 (2.432)  Prec@1 47.62 (34.24) Prec@5 88.69 (80.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.24 Prec@5 80.34 Error@1 65.76 Error@5 19.66 Loss:2.432
***[2020-01-29 06:28:30]*** VALID [epoch=087/600] loss = 2.431786, accuracy@1 = 34.24, accuracy@5 = 80.34 | Best-Valid-Acc@1=39.80, Error@1=60.20
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:28:30]*** start epoch=088/600 Time Left: [04:36:08], LR=[0.094786 ~ 0.094786], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=88, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.744493812586562, FLOP=40.81
[Search] : epoch=088/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:28:31] [epoch=088/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.742 (0.742)  Prec@1 73.44 (73.44) Prec@5 98.05 (98.05) Acls-loss 0.860 (0.860) FLOP-Loss 0.000 (0.000) Arch-Loss 0.860 (0.860)
**TRAIN** [2020-01-29 06:28:56] [epoch=088/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.785 (0.890)  Prec@1 75.00 (69.77) Prec@5 98.21 (97.43) Acls-loss 0.858 (0.916) FLOP-Loss 0.000 (0.026) Arch-Loss 0.858 (0.967)
 **TRAIN** Prec@1 69.77 Prec@5 97.43 Error@1 30.23 Error@5 2.57 Base-Loss:0.890, Arch-Loss=0.967
***[2020-01-29 06:28:56]*** TRAIN [epoch=088/600] base-loss = 0.890025, arch-loss = 0.967178, accuracy-1 = 69.77, accuracy-5 = 97.43
[epoch=088/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 11, 14, 16, 14, 32, 25, 32, 32, 32, 25, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.021952)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.243 0.376  ||  0.0229 -0.4259 0.0088  || discrepancy=0.01 || select=0/3
001/003-th : 0.392 0.187 0.421  ||  -0.0050 -0.7430 0.0677  || discrepancy=0.03 || select=2/3
002/003-th : 0.305 0.227 0.467  ||  -0.1901 -0.4858 0.2357  || discrepancy=0.16 || select=2/3
-----------------------------------------------
000/019-th : 0.078 0.092 0.108 0.117 0.135 0.154 0.160 0.157  ||  -0.434 -0.275 -0.113 -0.032 0.110 0.246 0.283 0.263   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.124 0.125 0.127 0.128 0.128 0.129  ||  -0.033 -0.044 -0.001 0.006 0.025 0.033 0.030 0.038    || dis=0.00 || select=7/8
002/019-th : 0.116 0.120 0.126 0.129 0.129 0.129 0.126 0.126  ||  -0.072 -0.037 0.014 0.034 0.036 0.034 0.017 0.014     || dis=0.00 || select=4/8
003/019-th : 0.123 0.126 0.126 0.126 0.127 0.124 0.125 0.123  ||  -0.015 0.007 0.011 0.013 0.018 -0.006 0.001 -0.013    || dis=0.00 || select=4/8
004/019-th : 0.119 0.121 0.124 0.124 0.129 0.126 0.130 0.127  ||  -0.046 -0.033 -0.007 -0.009 0.030 0.008 0.043 0.015   || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.120 0.126 0.127 0.128 0.128 0.130  ||  -0.043 -0.031 -0.039 0.005 0.018 0.028 0.023 0.039    || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.123 0.123 0.130 0.129 0.134 0.131  ||  -0.089 -0.073 -0.016 -0.014 0.039 0.038 0.072 0.052   || dis=0.00 || select=6/8
007/019-th : 0.099 0.099 0.105 0.122 0.126 0.143 0.149 0.157  ||  -0.221 -0.220 -0.156 -0.007 0.021 0.147 0.188 0.243   || dis=0.01 || select=7/8
008/019-th : 0.084 0.093 0.103 0.132 0.140 0.158 0.146 0.143  ||  -0.353 -0.248 -0.148 0.102 0.160 0.277 0.200 0.181    || dis=0.01 || select=5/8
009/019-th : 0.111 0.111 0.108 0.118 0.128 0.135 0.143 0.146  ||  -0.112 -0.119 -0.144 -0.053 0.027 0.078 0.135 0.158   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.120 0.126 0.129 0.133 0.134 0.134  ||  -0.121 -0.085 -0.034 0.014 0.034 0.064 0.072 0.073    || dis=0.00 || select=7/8
011/019-th : 0.109 0.109 0.110 0.119 0.124 0.135 0.146 0.148  ||  -0.137 -0.131 -0.129 -0.047 -0.004 0.079 0.154 0.168  || dis=0.00 || select=7/8
012/019-th : 0.116 0.117 0.119 0.127 0.129 0.131 0.131 0.131  ||  -0.067 -0.062 -0.043 0.020 0.037 0.057 0.052 0.052    || dis=0.00 || select=5/8
013/019-th : 0.081 0.081 0.092 0.101 0.125 0.148 0.181 0.190  ||  -0.405 -0.397 -0.280 -0.177 0.030 0.204 0.404 0.452   || dis=0.01 || select=7/8
014/019-th : 0.077 0.082 0.097 0.124 0.141 0.153 0.168 0.158  ||  -0.437 -0.382 -0.211 0.039 0.163 0.249 0.337 0.281    || dis=0.01 || select=6/8
015/019-th : 0.081 0.079 0.088 0.107 0.135 0.155 0.176 0.178  ||  -0.391 -0.415 -0.302 -0.110 0.120 0.262 0.388 0.400   || dis=0.00 || select=7/8
016/019-th : 0.073 0.092 0.104 0.123 0.138 0.156 0.158 0.157  ||  -0.507 -0.271 -0.143 0.020 0.139 0.255 0.268 0.261    || dis=0.00 || select=6/8
017/019-th : 0.118 0.115 0.119 0.120 0.121 0.132 0.135 0.139  ||  -0.055 -0.085 -0.050 -0.037 -0.028 0.054 0.081 0.109  || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.121 0.132 0.133 0.148 0.167  ||  -0.353 -0.220 -0.079 -0.012 0.076 0.081 0.191 0.310   || dis=0.02 || select=7/8
[epoch=088/600] FLOP : 28.02 MB, ratio : 0.6866, Expected-ratio : 0.7000, Discrepancy : 0.013
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:28:57] [epoch=088/600][000/098] Time 0.42 (0.42) Data 0.30 (0.30) Loss 4.277 (4.277)  Prec@1 29.69 (29.69) Prec@5 75.39 (75.39) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:29:04] [epoch=088/600][097/098] Time 0.06 (0.08) Data 0.00 (0.00) Loss 3.144 (2.483)  Prec@1 30.95 (34.12) Prec@5 68.45 (79.55) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.12 Prec@5 79.55 Error@1 65.88 Error@5 20.45 Loss:2.483
***[2020-01-29 06:29:04]*** VALID [epoch=088/600] loss = 2.482926, accuracy@1 = 34.12, accuracy@5 = 79.55 | Best-Valid-Acc@1=39.80, Error@1=60.20
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:29:04]*** start epoch=089/600 Time Left: [04:35:43], LR=[0.094669 ~ 0.094669], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=89, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.738759901403202, FLOP=40.81
[Search] : epoch=089/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:29:05] [epoch=089/600][000/098] Time 0.72 (0.72) Data 0.39 (0.39) Base-Loss 0.835 (0.835)  Prec@1 73.44 (73.44) Prec@5 98.05 (98.05) Acls-loss 0.920 (0.920) FLOP-Loss 0.000 (0.000) Arch-Loss 0.920 (0.920)
**TRAIN** [2020-01-29 06:29:29] [epoch=089/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.909 (0.903)  Prec@1 68.45 (68.96) Prec@5 97.02 (97.30) Acls-loss 1.105 (0.926) FLOP-Loss 0.000 (0.000) Arch-Loss 1.105 (0.926)
 **TRAIN** Prec@1 68.96 Prec@5 97.30 Error@1 31.04 Error@5 2.70 Base-Loss:0.903, Arch-Loss=0.926
***[2020-01-29 06:29:29]*** TRAIN [epoch=089/600] base-loss = 0.903486, arch-loss = 0.926392, accuracy-1 = 68.96, accuracy-5 = 97.30
[epoch=089/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 11, 14, 16, 14, 32, 25, 32, 32, 32, 25, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.021952)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.380 0.243 0.377  ||  0.0214 -0.4269 0.0110  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.185 0.424  ||  -0.0079 -0.7591 0.0723  || discrepancy=0.03 || select=2/3
002/003-th : 0.302 0.228 0.469  ||  -0.1968 -0.4782 0.2422  || discrepancy=0.17 || select=2/3
-----------------------------------------------
000/019-th : 0.077 0.091 0.107 0.117 0.137 0.154 0.160 0.157  ||  -0.443 -0.277 -0.114 -0.031 0.127 0.243 0.283 0.268   || dis=0.00 || select=6/8
001/019-th : 0.120 0.118 0.124 0.124 0.128 0.129 0.128 0.129  ||  -0.035 -0.047 -0.003 -0.000 0.029 0.037 0.032 0.041   || dis=0.00 || select=7/8
002/019-th : 0.116 0.120 0.125 0.129 0.129 0.129 0.126 0.126  ||  -0.072 -0.037 0.008 0.034 0.040 0.036 0.016 0.016     || dis=0.00 || select=4/8
003/019-th : 0.123 0.126 0.126 0.126 0.127 0.124 0.125 0.123  ||  -0.017 0.007 0.009 0.006 0.019 -0.005 0.002 -0.011    || dis=0.00 || select=4/8
004/019-th : 0.119 0.121 0.124 0.124 0.128 0.126 0.130 0.127  ||  -0.047 -0.034 -0.010 -0.007 0.028 0.011 0.042 0.018   || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.120 0.126 0.128 0.129 0.128 0.130  ||  -0.048 -0.034 -0.037 0.007 0.028 0.031 0.027 0.039    || dis=0.00 || select=7/8
006/019-th : 0.114 0.116 0.122 0.122 0.131 0.129 0.134 0.132  ||  -0.094 -0.074 -0.020 -0.020 0.046 0.037 0.073 0.059   || dis=0.00 || select=6/8
007/019-th : 0.098 0.099 0.105 0.122 0.125 0.144 0.150 0.157  ||  -0.230 -0.221 -0.160 -0.005 0.016 0.157 0.196 0.245   || dis=0.01 || select=7/8
008/019-th : 0.083 0.093 0.103 0.133 0.140 0.157 0.148 0.144  ||  -0.366 -0.254 -0.148 0.105 0.160 0.271 0.214 0.186    || dis=0.01 || select=5/8
009/019-th : 0.111 0.111 0.108 0.118 0.126 0.136 0.143 0.147  ||  -0.117 -0.120 -0.147 -0.056 0.014 0.086 0.138 0.163   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.119 0.128 0.128 0.133 0.134 0.134  ||  -0.127 -0.088 -0.045 0.028 0.030 0.069 0.075 0.077    || dis=0.00 || select=7/8
011/019-th : 0.109 0.109 0.110 0.119 0.123 0.135 0.146 0.149  ||  -0.136 -0.135 -0.125 -0.049 -0.017 0.075 0.153 0.175  || dis=0.00 || select=7/8
012/019-th : 0.115 0.116 0.118 0.128 0.129 0.132 0.131 0.131  ||  -0.075 -0.069 -0.048 0.028 0.038 0.066 0.053 0.058    || dis=0.00 || select=5/8
013/019-th : 0.078 0.080 0.092 0.101 0.126 0.149 0.182 0.191  ||  -0.433 -0.405 -0.274 -0.177 0.046 0.211 0.412 0.462   || dis=0.01 || select=7/8
014/019-th : 0.077 0.081 0.096 0.124 0.142 0.153 0.168 0.159  ||  -0.441 -0.390 -0.218 0.035 0.174 0.250 0.341 0.289    || dis=0.01 || select=6/8
015/019-th : 0.081 0.077 0.088 0.106 0.136 0.154 0.178 0.181  ||  -0.390 -0.438 -0.300 -0.123 0.130 0.253 0.398 0.416   || dis=0.00 || select=7/8
016/019-th : 0.072 0.091 0.104 0.123 0.137 0.156 0.160 0.157  ||  -0.514 -0.277 -0.149 0.023 0.125 0.256 0.281 0.267    || dis=0.00 || select=6/8
017/019-th : 0.118 0.115 0.118 0.121 0.123 0.132 0.135 0.139  ||  -0.059 -0.082 -0.053 -0.033 -0.017 0.054 0.082 0.108  || dis=0.00 || select=7/8
018/019-th : 0.085 0.098 0.112 0.122 0.133 0.134 0.148 0.167  ||  -0.363 -0.221 -0.086 -0.003 0.082 0.087 0.193 0.313   || dis=0.02 || select=7/8
[epoch=089/600] FLOP : 28.02 MB, ratio : 0.6866, Expected-ratio : 0.7000, Discrepancy : 0.013
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:29:29] [epoch=089/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.724 (2.724)  Prec@1 38.28 (38.28) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:29:35] [epoch=089/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.737 (2.307)  Prec@1 50.60 (37.24) Prec@5 90.48 (81.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.24 Prec@5 81.89 Error@1 62.76 Error@5 18.11 Loss:2.307
***[2020-01-29 06:29:35]*** VALID [epoch=089/600] loss = 2.306504, accuracy@1 = 37.24, accuracy@5 = 81.89 | Best-Valid-Acc@1=39.80, Error@1=60.20
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:29:35]*** start epoch=090/600 Time Left: [04:35:04], LR=[0.094550 ~ 0.094550], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=90, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.732965984261501, FLOP=40.81
[Search] : epoch=090/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:29:36] [epoch=090/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.899 (0.899)  Prec@1 68.75 (68.75) Prec@5 96.48 (96.48) Acls-loss 0.910 (0.910) FLOP-Loss 0.000 (0.000) Arch-Loss 0.910 (0.910)
**TRAIN** [2020-01-29 06:30:00] [epoch=090/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.086 (0.903)  Prec@1 63.10 (68.72) Prec@5 96.43 (97.40) Acls-loss 1.048 (0.924) FLOP-Loss 0.000 (0.000) Arch-Loss 1.048 (0.924)
 **TRAIN** Prec@1 68.72 Prec@5 97.40 Error@1 31.28 Error@5 2.60 Base-Loss:0.903, Arch-Loss=0.924
***[2020-01-29 06:30:00]*** TRAIN [epoch=090/600] base-loss = 0.903116, arch-loss = 0.923841, accuracy-1 = 68.72, accuracy-5 = 97.40
[epoch=090/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 11, 14, 16, 14, 32, 25, 32, 28, 32, 25, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.380928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.240 0.379  ||  0.0184 -0.4425 0.0152  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.185 0.425  ||  -0.0097 -0.7585 0.0752  || discrepancy=0.03 || select=2/3
002/003-th : 0.299 0.230 0.471  ||  -0.2049 -0.4683 0.2499  || discrepancy=0.17 || select=2/3
-----------------------------------------------
000/019-th : 0.077 0.091 0.108 0.115 0.138 0.151 0.162 0.159  ||  -0.445 -0.284 -0.114 -0.048 0.132 0.222 0.294 0.277   || dis=0.00 || select=6/8
001/019-th : 0.119 0.118 0.123 0.125 0.128 0.129 0.128 0.129  ||  -0.039 -0.049 -0.007 0.004 0.032 0.039 0.033 0.043    || dis=0.00 || select=7/8
002/019-th : 0.115 0.120 0.125 0.128 0.130 0.129 0.126 0.126  ||  -0.074 -0.037 0.003 0.033 0.044 0.037 0.017 0.017     || dis=0.00 || select=4/8
003/019-th : 0.122 0.126 0.126 0.125 0.128 0.124 0.125 0.124  ||  -0.020 0.006 0.008 -0.001 0.021 -0.005 0.004 -0.008   || dis=0.00 || select=4/8
004/019-th : 0.119 0.120 0.124 0.124 0.127 0.128 0.130 0.128  ||  -0.051 -0.040 -0.012 -0.007 0.019 0.024 0.042 0.022   || dis=0.00 || select=6/8
005/019-th : 0.118 0.121 0.120 0.125 0.128 0.129 0.129 0.130  ||  -0.053 -0.035 -0.036 -0.001 0.026 0.035 0.031 0.042   || dis=0.00 || select=7/8
006/019-th : 0.113 0.115 0.122 0.121 0.132 0.130 0.135 0.133  ||  -0.098 -0.083 -0.023 -0.025 0.058 0.044 0.078 0.064   || dis=0.00 || select=6/8
007/019-th : 0.097 0.098 0.105 0.122 0.125 0.145 0.151 0.158  ||  -0.235 -0.229 -0.158 -0.012 0.016 0.162 0.205 0.248   || dis=0.01 || select=7/8
008/019-th : 0.083 0.093 0.102 0.131 0.138 0.158 0.150 0.146  ||  -0.371 -0.258 -0.159 0.091 0.144 0.274 0.223 0.199    || dis=0.01 || select=5/8
009/019-th : 0.110 0.110 0.107 0.119 0.127 0.136 0.143 0.147  ||  -0.124 -0.124 -0.150 -0.048 0.022 0.087 0.141 0.168   || dis=0.00 || select=7/8
010/019-th : 0.110 0.113 0.119 0.127 0.127 0.134 0.135 0.135  ||  -0.124 -0.094 -0.049 0.021 0.018 0.071 0.082 0.079    || dis=0.00 || select=6/8
011/019-th : 0.109 0.108 0.110 0.118 0.124 0.135 0.146 0.150  ||  -0.137 -0.144 -0.126 -0.054 -0.010 0.075 0.159 0.180  || dis=0.00 || select=7/8
012/019-th : 0.115 0.116 0.118 0.127 0.129 0.133 0.132 0.132  ||  -0.080 -0.070 -0.051 0.019 0.036 0.067 0.059 0.062    || dis=0.00 || select=5/8
013/019-th : 0.078 0.080 0.091 0.100 0.124 0.151 0.183 0.193  ||  -0.438 -0.408 -0.284 -0.182 0.030 0.228 0.416 0.472   || dis=0.01 || select=7/8
014/019-th : 0.076 0.080 0.095 0.123 0.140 0.153 0.170 0.162  ||  -0.447 -0.397 -0.226 0.026 0.154 0.249 0.352 0.302    || dis=0.01 || select=6/8
015/019-th : 0.080 0.076 0.088 0.103 0.134 0.155 0.180 0.184  ||  -0.396 -0.448 -0.304 -0.144 0.120 0.260 0.411 0.432   || dis=0.00 || select=7/8
016/019-th : 0.071 0.090 0.103 0.125 0.137 0.155 0.161 0.159  ||  -0.523 -0.291 -0.156 0.034 0.127 0.252 0.289 0.277    || dis=0.00 || select=6/8
017/019-th : 0.117 0.115 0.118 0.120 0.123 0.131 0.136 0.139  ||  -0.062 -0.084 -0.052 -0.039 -0.013 0.050 0.088 0.110  || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.113 0.123 0.134 0.133 0.149 0.167  ||  -0.373 -0.224 -0.081 0.009 0.088 0.082 0.196 0.313    || dis=0.02 || select=7/8
[epoch=090/600] FLOP : 27.38 MB, ratio : 0.6709, Expected-ratio : 0.7000, Discrepancy : 0.013
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:30:00] [epoch=090/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.398 (2.398)  Prec@1 28.91 (28.91) Prec@5 71.09 (71.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:30:06] [epoch=090/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.992 (2.480)  Prec@1 33.93 (35.65) Prec@5 75.60 (81.92) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.65 Prec@5 81.92 Error@1 64.35 Error@5 18.08 Loss:2.480
***[2020-01-29 06:30:06]*** VALID [epoch=090/600] loss = 2.480051, accuracy@1 = 35.65, accuracy@5 = 81.92 | Best-Valid-Acc@1=39.80, Error@1=60.20
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:30:06]*** start epoch=091/600 Time Left: [04:34:24], LR=[0.094431 ~ 0.094431], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=91, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.727112220004624, FLOP=40.81
[Search] : epoch=091/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:30:07] [epoch=091/600][000/098] Time 0.74 (0.74) Data 0.36 (0.36) Base-Loss 0.994 (0.994)  Prec@1 68.75 (68.75) Prec@5 96.48 (96.48) Acls-loss 1.040 (1.040) FLOP-Loss 0.000 (0.000) Arch-Loss 1.040 (1.040)
**TRAIN** [2020-01-29 06:30:31] [epoch=091/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.781 (0.903)  Prec@1 73.21 (68.91) Prec@5 97.02 (97.44) Acls-loss 0.903 (0.924) FLOP-Loss 0.000 (0.026) Arch-Loss 0.903 (0.976)
 **TRAIN** Prec@1 68.91 Prec@5 97.44 Error@1 31.09 Error@5 2.56 Base-Loss:0.903, Arch-Loss=0.976
***[2020-01-29 06:30:31]*** TRAIN [epoch=091/600] base-loss = 0.903319, arch-loss = 0.975784, accuracy-1 = 68.91, accuracy-5 = 97.44
[epoch=091/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 11, 14, 16, 14, 32, 25, 32, 28, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.309184)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.238 0.380  ||  0.0189 -0.4519 0.0158  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.183 0.426  ||  -0.0092 -0.7670 0.0763  || discrepancy=0.03 || select=2/3
002/003-th : 0.297 0.230 0.473  ||  -0.2102 -0.4646 0.2554  || discrepancy=0.18 || select=2/3
-----------------------------------------------
000/019-th : 0.076 0.090 0.109 0.115 0.138 0.150 0.162 0.160  ||  -0.463 -0.288 -0.096 -0.044 0.132 0.218 0.293 0.286   || dis=0.00 || select=6/8
001/019-th : 0.119 0.118 0.123 0.124 0.128 0.130 0.128 0.129  ||  -0.040 -0.049 -0.004 -0.001 0.032 0.045 0.031 0.042   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.125 0.128 0.130 0.129 0.126 0.126  ||  -0.074 -0.036 0.007 0.027 0.042 0.036 0.017 0.017     || dis=0.00 || select=4/8
003/019-th : 0.123 0.126 0.126 0.124 0.128 0.124 0.125 0.124  ||  -0.020 0.007 0.012 -0.008 0.022 -0.005 0.002 -0.008   || dis=0.00 || select=4/8
004/019-th : 0.119 0.120 0.124 0.125 0.128 0.127 0.130 0.128  ||  -0.052 -0.040 -0.010 -0.002 0.025 0.018 0.042 0.023   || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.120 0.125 0.127 0.129 0.129 0.130  ||  -0.051 -0.033 -0.037 -0.001 0.018 0.033 0.029 0.043   || dis=0.00 || select=7/8
006/019-th : 0.113 0.114 0.122 0.121 0.132 0.130 0.135 0.133  ||  -0.098 -0.086 -0.022 -0.029 0.060 0.040 0.077 0.068   || dis=0.00 || select=6/8
007/019-th : 0.096 0.096 0.106 0.121 0.127 0.145 0.152 0.157  ||  -0.242 -0.241 -0.151 -0.017 0.031 0.168 0.213 0.248   || dis=0.01 || select=7/8
008/019-th : 0.082 0.093 0.102 0.131 0.138 0.158 0.149 0.147  ||  -0.375 -0.257 -0.159 0.092 0.138 0.275 0.215 0.205    || dis=0.01 || select=5/8
009/019-th : 0.110 0.110 0.108 0.118 0.128 0.136 0.143 0.147  ||  -0.125 -0.123 -0.146 -0.050 0.025 0.087 0.141 0.167   || dis=0.00 || select=7/8
010/019-th : 0.110 0.113 0.119 0.126 0.127 0.134 0.136 0.135  ||  -0.126 -0.095 -0.043 0.011 0.021 0.073 0.086 0.077    || dis=0.00 || select=6/8
011/019-th : 0.109 0.109 0.110 0.118 0.123 0.133 0.147 0.151  ||  -0.136 -0.139 -0.130 -0.060 -0.022 0.060 0.161 0.187  || dis=0.00 || select=7/8
012/019-th : 0.115 0.116 0.118 0.126 0.129 0.132 0.132 0.133  ||  -0.081 -0.066 -0.056 0.010 0.040 0.061 0.058 0.066    || dis=0.00 || select=7/8
013/019-th : 0.078 0.079 0.090 0.100 0.124 0.151 0.183 0.195  ||  -0.440 -0.418 -0.286 -0.186 0.029 0.229 0.419 0.482   || dis=0.01 || select=7/8
014/019-th : 0.076 0.080 0.095 0.123 0.138 0.153 0.171 0.163  ||  -0.451 -0.397 -0.227 0.030 0.141 0.243 0.357 0.307    || dis=0.01 || select=6/8
015/019-th : 0.080 0.075 0.089 0.103 0.134 0.153 0.180 0.186  ||  -0.397 -0.463 -0.294 -0.150 0.119 0.249 0.415 0.445   || dis=0.01 || select=7/8
016/019-th : 0.071 0.090 0.104 0.124 0.135 0.156 0.161 0.160  ||  -0.528 -0.296 -0.146 0.029 0.114 0.257 0.291 0.281    || dis=0.00 || select=6/8
017/019-th : 0.117 0.115 0.119 0.120 0.123 0.131 0.136 0.139  ||  -0.061 -0.083 -0.050 -0.042 -0.012 0.046 0.088 0.110  || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.112 0.123 0.133 0.133 0.148 0.168  ||  -0.372 -0.221 -0.086 0.007 0.085 0.081 0.191 0.318    || dis=0.02 || select=7/8
[epoch=091/600] FLOP : 27.31 MB, ratio : 0.6691, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:30:32] [epoch=091/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.906 (1.906)  Prec@1 50.78 (50.78) Prec@5 92.19 (92.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:30:38] [epoch=091/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 1.785 (2.206)  Prec@1 60.12 (40.30) Prec@5 92.26 (84.55) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.30 Prec@5 84.55 Error@1 59.70 Error@5 15.45 Loss:2.206
***[2020-01-29 06:30:38]*** VALID [epoch=091/600] loss = 2.205877, accuracy@1 = 40.30, accuracy@5 = 84.55 | Best-Valid-Acc@1=39.80, Error@1=60.20
Currently, the best validation accuracy found at 091-epoch :: acc@1=40.30, acc@5=84.55, error@1=59.70, error@5=15.45, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:30:38]*** start epoch=092/600 Time Left: [04:33:47], LR=[0.094310 ~ 0.094310], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=92, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.721198769116476, FLOP=40.81
[Search] : epoch=092/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:30:38] [epoch=092/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.958 (0.958)  Prec@1 69.14 (69.14) Prec@5 95.70 (95.70) Acls-loss 0.818 (0.818) FLOP-Loss 0.000 (0.000) Arch-Loss 0.818 (0.818)
**TRAIN** [2020-01-29 06:31:03] [epoch=092/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.886 (0.898)  Prec@1 69.05 (69.14) Prec@5 98.81 (97.45) Acls-loss 0.965 (0.918) FLOP-Loss 0.000 (0.026) Arch-Loss 0.965 (0.970)
 **TRAIN** Prec@1 69.14 Prec@5 97.45 Error@1 30.86 Error@5 2.55 Base-Loss:0.898, Arch-Loss=0.970
***[2020-01-29 06:31:03]*** TRAIN [epoch=092/600] base-loss = 0.898371, arch-loss = 0.969619, accuracy-1 = 69.14, accuracy-5 = 97.45
[epoch=092/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 11, 14, 16, 14, 32, 25, 32, 28, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.309184)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.239 0.380  ||  0.0189 -0.4492 0.0167  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.184 0.426  ||  -0.0092 -0.7627 0.0775  || discrepancy=0.04 || select=2/3
002/003-th : 0.295 0.230 0.474  ||  -0.2142 -0.4626 0.2598  || discrepancy=0.18 || select=2/3
-----------------------------------------------
000/019-th : 0.075 0.091 0.108 0.115 0.140 0.149 0.161 0.161  ||  -0.470 -0.284 -0.108 -0.049 0.155 0.217 0.293 0.290   || dis=0.00 || select=6/8
001/019-th : 0.119 0.118 0.124 0.123 0.129 0.130 0.128 0.129  ||  -0.039 -0.049 -0.003 -0.005 0.037 0.045 0.030 0.041   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.125 0.128 0.129 0.129 0.127 0.126  ||  -0.072 -0.035 0.006 0.024 0.039 0.034 0.016 0.016     || dis=0.00 || select=4/8
003/019-th : 0.123 0.126 0.126 0.125 0.127 0.124 0.126 0.124  ||  -0.020 0.007 0.005 -0.004 0.018 -0.006 0.004 -0.006   || dis=0.00 || select=4/8
004/019-th : 0.118 0.120 0.123 0.125 0.128 0.127 0.130 0.128  ||  -0.053 -0.039 -0.014 0.002 0.025 0.018 0.044 0.023    || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.120 0.124 0.126 0.130 0.129 0.131  ||  -0.052 -0.033 -0.038 -0.007 0.010 0.039 0.030 0.044   || dis=0.00 || select=7/8
006/019-th : 0.113 0.114 0.122 0.121 0.131 0.130 0.135 0.134  ||  -0.097 -0.086 -0.027 -0.028 0.047 0.037 0.078 0.071   || dis=0.00 || select=6/8
007/019-th : 0.097 0.097 0.106 0.120 0.125 0.144 0.153 0.158  ||  -0.241 -0.240 -0.152 -0.021 0.020 0.161 0.218 0.251   || dis=0.01 || select=7/8
008/019-th : 0.082 0.091 0.103 0.131 0.138 0.158 0.150 0.148  ||  -0.382 -0.273 -0.154 0.092 0.140 0.278 0.225 0.210    || dis=0.01 || select=5/8
009/019-th : 0.110 0.110 0.106 0.119 0.128 0.136 0.143 0.148  ||  -0.125 -0.124 -0.158 -0.044 0.028 0.091 0.139 0.171   || dis=0.01 || select=7/8
010/019-th : 0.110 0.113 0.119 0.125 0.127 0.134 0.136 0.135  ||  -0.124 -0.095 -0.046 0.005 0.019 0.069 0.090 0.078    || dis=0.00 || select=6/8
011/019-th : 0.109 0.108 0.111 0.116 0.123 0.134 0.148 0.152  ||  -0.143 -0.148 -0.116 -0.079 -0.021 0.069 0.167 0.192  || dis=0.00 || select=7/8
012/019-th : 0.114 0.116 0.118 0.125 0.130 0.132 0.131 0.133  ||  -0.083 -0.069 -0.053 0.005 0.045 0.060 0.054 0.070    || dis=0.00 || select=7/8
013/019-th : 0.077 0.079 0.089 0.100 0.123 0.152 0.185 0.196  ||  -0.445 -0.422 -0.299 -0.188 0.021 0.237 0.432 0.489   || dis=0.01 || select=7/8
014/019-th : 0.077 0.080 0.095 0.123 0.137 0.152 0.171 0.164  ||  -0.448 -0.400 -0.231 0.025 0.131 0.240 0.358 0.314    || dis=0.01 || select=6/8
015/019-th : 0.079 0.075 0.089 0.103 0.132 0.153 0.181 0.188  ||  -0.406 -0.467 -0.291 -0.149 0.101 0.251 0.421 0.456   || dis=0.01 || select=7/8
016/019-th : 0.071 0.089 0.102 0.126 0.136 0.156 0.161 0.159  ||  -0.531 -0.297 -0.160 0.043 0.120 0.262 0.295 0.279    || dis=0.00 || select=6/8
017/019-th : 0.117 0.114 0.119 0.121 0.125 0.129 0.136 0.139  ||  -0.064 -0.084 -0.048 -0.025 0.001 0.039 0.089 0.108   || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.112 0.123 0.132 0.135 0.149 0.168  ||  -0.376 -0.218 -0.092 0.004 0.073 0.097 0.199 0.315    || dis=0.02 || select=7/8
[epoch=092/600] FLOP : 27.31 MB, ratio : 0.6691, Expected-ratio : 0.7000, Discrepancy : 0.013
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:31:04] [epoch=092/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.920 (1.920)  Prec@1 42.97 (42.97) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:31:10] [epoch=092/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.881 (2.470)  Prec@1 23.81 (35.79) Prec@5 79.76 (80.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.79 Prec@5 80.40 Error@1 64.21 Error@5 19.60 Loss:2.470
***[2020-01-29 06:31:10]*** VALID [epoch=092/600] loss = 2.469539, accuracy@1 = 35.79, accuracy@5 = 80.40 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:31:10]*** start epoch=093/600 Time Left: [04:33:13], LR=[0.094188 ~ 0.094188], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=93, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.715225793717299, FLOP=40.81
[Search] : epoch=093/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:31:10] [epoch=093/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.797 (0.797)  Prec@1 74.22 (74.22) Prec@5 98.44 (98.44) Acls-loss 0.904 (0.904) FLOP-Loss 0.000 (0.000) Arch-Loss 0.904 (0.904)
**TRAIN** [2020-01-29 06:31:35] [epoch=093/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.092 (0.880)  Prec@1 64.29 (70.03) Prec@5 95.83 (97.47) Acls-loss 0.974 (0.898) FLOP-Loss 0.000 (0.026) Arch-Loss 0.974 (0.950)
 **TRAIN** Prec@1 70.03 Prec@5 97.47 Error@1 29.97 Error@5 2.53 Base-Loss:0.880, Arch-Loss=0.950
***[2020-01-29 06:31:35]*** TRAIN [epoch=093/600] base-loss = 0.879559, arch-loss = 0.950001, accuracy-1 = 70.03, accuracy-5 = 97.47
[epoch=093/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 11, 14, 12, 14, 32, 25, 32, 28, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.309184)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.382 0.237 0.381  ||  0.0205 -0.4557 0.0163  || discrepancy=0.00 || select=0/3
001/003-th : 0.391 0.184 0.426  ||  -0.0082 -0.7623 0.0779  || discrepancy=0.03 || select=2/3
002/003-th : 0.293 0.230 0.477  ||  -0.2218 -0.4619 0.2677  || discrepancy=0.18 || select=2/3
-----------------------------------------------
000/019-th : 0.074 0.090 0.110 0.114 0.141 0.149 0.162 0.160  ||  -0.485 -0.283 -0.091 -0.050 0.159 0.217 0.298 0.288   || dis=0.00 || select=6/8
001/019-th : 0.120 0.118 0.124 0.122 0.129 0.130 0.128 0.129  ||  -0.038 -0.047 -0.003 -0.014 0.038 0.044 0.029 0.041   || dis=0.00 || select=5/8
002/019-th : 0.116 0.120 0.125 0.128 0.129 0.129 0.126 0.126  ||  -0.071 -0.033 0.002 0.028 0.040 0.036 0.015 0.015     || dis=0.00 || select=4/8
003/019-th : 0.123 0.126 0.125 0.124 0.128 0.124 0.125 0.124  ||  -0.018 0.008 0.003 -0.012 0.022 -0.008 0.003 -0.006   || dis=0.00 || select=4/8
004/019-th : 0.118 0.120 0.122 0.124 0.129 0.128 0.131 0.128  ||  -0.055 -0.043 -0.022 -0.005 0.031 0.021 0.046 0.027   || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.120 0.122 0.126 0.131 0.129 0.131  ||  -0.054 -0.032 -0.039 -0.024 0.005 0.049 0.030 0.048   || dis=0.00 || select=5/8
006/019-th : 0.113 0.115 0.122 0.121 0.130 0.130 0.135 0.134  ||  -0.097 -0.083 -0.021 -0.032 0.036 0.037 0.075 0.073   || dis=0.00 || select=6/8
007/019-th : 0.096 0.097 0.105 0.120 0.125 0.145 0.153 0.159  ||  -0.245 -0.241 -0.157 -0.021 0.021 0.166 0.218 0.255   || dis=0.01 || select=7/8
008/019-th : 0.081 0.090 0.102 0.131 0.138 0.159 0.150 0.148  ||  -0.395 -0.280 -0.153 0.095 0.144 0.288 0.230 0.213    || dis=0.01 || select=5/8
009/019-th : 0.110 0.109 0.106 0.120 0.128 0.136 0.143 0.147  ||  -0.123 -0.131 -0.158 -0.032 0.030 0.091 0.141 0.169   || dis=0.00 || select=7/8
010/019-th : 0.110 0.114 0.119 0.125 0.127 0.134 0.136 0.135  ||  -0.124 -0.092 -0.044 0.000 0.021 0.071 0.084 0.079    || dis=0.00 || select=6/8
011/019-th : 0.108 0.108 0.111 0.114 0.123 0.134 0.149 0.151  ||  -0.143 -0.151 -0.116 -0.089 -0.015 0.071 0.175 0.191  || dis=0.00 || select=7/8
012/019-th : 0.114 0.116 0.118 0.124 0.129 0.132 0.132 0.134  ||  -0.084 -0.067 -0.051 0.000 0.037 0.060 0.056 0.071    || dis=0.00 || select=7/8
013/019-th : 0.077 0.079 0.089 0.099 0.122 0.151 0.186 0.198  ||  -0.447 -0.420 -0.302 -0.193 0.019 0.227 0.436 0.498   || dis=0.01 || select=7/8
014/019-th : 0.076 0.079 0.096 0.123 0.137 0.152 0.173 0.164  ||  -0.455 -0.412 -0.225 0.025 0.135 0.237 0.368 0.316    || dis=0.01 || select=6/8
015/019-th : 0.079 0.074 0.088 0.104 0.131 0.155 0.182 0.188  ||  -0.405 -0.481 -0.305 -0.138 0.095 0.264 0.426 0.460   || dis=0.01 || select=7/8
016/019-th : 0.070 0.088 0.102 0.126 0.138 0.157 0.160 0.159  ||  -0.539 -0.306 -0.164 0.051 0.138 0.270 0.291 0.283    || dis=0.00 || select=6/8
017/019-th : 0.117 0.114 0.119 0.122 0.125 0.129 0.136 0.138  ||  -0.062 -0.090 -0.045 -0.017 0.007 0.036 0.087 0.107   || dis=0.00 || select=7/8
018/019-th : 0.083 0.099 0.111 0.122 0.132 0.133 0.151 0.168  ||  -0.383 -0.214 -0.097 -0.000 0.074 0.085 0.212 0.319   || dis=0.02 || select=7/8
[epoch=093/600] FLOP : 27.31 MB, ratio : 0.6691, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:31:35] [epoch=093/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.987 (1.987)  Prec@1 31.25 (31.25) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:31:41] [epoch=093/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.344 (2.276)  Prec@1 23.81 (35.32) Prec@5 78.57 (81.69) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.32 Prec@5 81.69 Error@1 64.68 Error@5 18.31 Loss:2.276
***[2020-01-29 06:31:41]*** VALID [epoch=093/600] loss = 2.276275, accuracy@1 = 35.32, accuracy@5 = 81.69 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:31:41]*** start epoch=094/600 Time Left: [04:32:38], LR=[0.094065 ~ 0.094065], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=94, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.7091934575592305, FLOP=40.81
[Search] : epoch=094/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:31:42] [epoch=094/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.882 (0.882)  Prec@1 71.48 (71.48) Prec@5 97.27 (97.27) Acls-loss 0.857 (0.857) FLOP-Loss 0.000 (0.000) Arch-Loss 0.857 (0.857)
**TRAIN** [2020-01-29 06:32:06] [epoch=094/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.050 (0.885)  Prec@1 66.07 (69.52) Prec@5 95.83 (97.30) Acls-loss 0.905 (0.918) FLOP-Loss 0.000 (0.026) Arch-Loss 0.905 (0.970)
 **TRAIN** Prec@1 69.52 Prec@5 97.30 Error@1 30.48 Error@5 2.70 Base-Loss:0.885, Arch-Loss=0.970
***[2020-01-29 06:32:06]*** TRAIN [epoch=094/600] base-loss = 0.885127, arch-loss = 0.970260, accuracy-1 = 69.52, accuracy-5 = 97.30
[epoch=094/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 11, 14, 16, 16, 32, 25, 32, 28, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.39104)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.383 0.237 0.381  ||  0.0215 -0.4590 0.0164  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.184 0.426  ||  -0.0081 -0.7593 0.0791  || discrepancy=0.04 || select=2/3
002/003-th : 0.290 0.230 0.480  ||  -0.2291 -0.4592 0.2752  || discrepancy=0.19 || select=2/3
-----------------------------------------------
000/019-th : 0.074 0.091 0.109 0.112 0.142 0.151 0.161 0.160  ||  -0.486 -0.276 -0.098 -0.066 0.170 0.233 0.297 0.285   || dis=0.00 || select=6/8
001/019-th : 0.120 0.119 0.124 0.123 0.129 0.129 0.128 0.130  ||  -0.037 -0.045 -0.003 -0.013 0.034 0.037 0.028 0.042   || dis=0.00 || select=7/8
002/019-th : 0.115 0.120 0.125 0.127 0.130 0.129 0.126 0.126  ||  -0.074 -0.033 0.005 0.021 0.047 0.038 0.017 0.015     || dis=0.00 || select=4/8
003/019-th : 0.123 0.127 0.126 0.123 0.128 0.125 0.125 0.125  ||  -0.019 0.012 0.004 -0.022 0.019 -0.002 -0.000 -0.005  || dis=0.00 || select=4/8
004/019-th : 0.118 0.119 0.121 0.124 0.130 0.127 0.131 0.129  ||  -0.055 -0.045 -0.030 -0.005 0.037 0.017 0.049 0.030   || dis=0.00 || select=6/8
005/019-th : 0.119 0.122 0.122 0.121 0.126 0.130 0.129 0.131  ||  -0.055 -0.027 -0.030 -0.031 0.003 0.040 0.031 0.047   || dis=0.00 || select=7/8
006/019-th : 0.113 0.115 0.122 0.122 0.130 0.129 0.135 0.135  ||  -0.099 -0.084 -0.021 -0.023 0.038 0.029 0.074 0.075   || dis=0.00 || select=7/8
007/019-th : 0.096 0.097 0.105 0.120 0.125 0.146 0.153 0.158  ||  -0.250 -0.237 -0.155 -0.023 0.016 0.170 0.221 0.255   || dis=0.01 || select=7/8
008/019-th : 0.080 0.090 0.102 0.132 0.138 0.159 0.151 0.148  ||  -0.396 -0.285 -0.157 0.097 0.143 0.285 0.234 0.217    || dis=0.01 || select=5/8
009/019-th : 0.110 0.108 0.107 0.120 0.126 0.138 0.143 0.148  ||  -0.127 -0.140 -0.149 -0.032 0.010 0.101 0.143 0.175   || dis=0.01 || select=7/8
010/019-th : 0.110 0.113 0.119 0.125 0.128 0.133 0.136 0.135  ||  -0.129 -0.098 -0.044 0.007 0.027 0.068 0.086 0.084    || dis=0.00 || select=6/8
011/019-th : 0.109 0.108 0.110 0.114 0.123 0.135 0.149 0.152  ||  -0.139 -0.147 -0.128 -0.094 -0.016 0.072 0.175 0.195  || dis=0.00 || select=7/8
012/019-th : 0.114 0.116 0.118 0.124 0.132 0.131 0.132 0.133  ||  -0.089 -0.071 -0.049 0.001 0.059 0.055 0.059 0.071    || dis=0.00 || select=7/8
013/019-th : 0.077 0.079 0.088 0.099 0.122 0.150 0.185 0.200  ||  -0.448 -0.420 -0.311 -0.196 0.018 0.224 0.435 0.509   || dis=0.02 || select=7/8
014/019-th : 0.076 0.079 0.094 0.122 0.138 0.154 0.174 0.164  ||  -0.457 -0.418 -0.238 0.019 0.143 0.251 0.377 0.317    || dis=0.01 || select=6/8
015/019-th : 0.079 0.072 0.087 0.103 0.131 0.156 0.182 0.191  ||  -0.407 -0.502 -0.310 -0.141 0.101 0.275 0.427 0.475   || dis=0.01 || select=7/8
016/019-th : 0.069 0.087 0.102 0.127 0.137 0.158 0.160 0.159  ||  -0.551 -0.317 -0.158 0.061 0.138 0.281 0.291 0.288    || dis=0.00 || select=6/8
017/019-th : 0.117 0.114 0.119 0.122 0.125 0.128 0.136 0.138  ||  -0.059 -0.084 -0.047 -0.016 0.008 0.030 0.086 0.104   || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.110 0.122 0.134 0.132 0.152 0.168  ||  -0.375 -0.224 -0.103 -0.002 0.092 0.076 0.217 0.317   || dis=0.02 || select=7/8
[epoch=094/600] FLOP : 28.39 MB, ratio : 0.6956, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:32:07] [epoch=094/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.376 (1.376)  Prec@1 55.47 (55.47) Prec@5 91.41 (91.41) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:32:13] [epoch=094/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.898 (2.147)  Prec@1 26.19 (38.13) Prec@5 80.36 (83.81) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.13 Prec@5 83.81 Error@1 61.87 Error@5 16.19 Loss:2.147
***[2020-01-29 06:32:13]*** VALID [epoch=094/600] loss = 2.146989, accuracy@1 = 38.13, accuracy@5 = 83.81 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:32:13]*** start epoch=095/600 Time Left: [04:32:02], LR=[0.093941 ~ 0.093941], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=95, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.703101926021815, FLOP=40.81
[Search] : epoch=095/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:32:14] [epoch=095/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.825 (0.825)  Prec@1 72.27 (72.27) Prec@5 98.05 (98.05) Acls-loss 0.979 (0.979) FLOP-Loss 0.000 (0.000) Arch-Loss 0.979 (0.979)
**TRAIN** [2020-01-29 06:32:39] [epoch=095/600][097/098] Time 0.29 (0.26) Data 0.00 (0.00) Base-Loss 0.821 (0.894)  Prec@1 72.62 (69.51) Prec@5 98.21 (97.44) Acls-loss 0.855 (0.918) FLOP-Loss 2.528 (0.095) Arch-Loss 5.910 (1.107)
 **TRAIN** Prec@1 69.51 Prec@5 97.44 Error@1 30.49 Error@5 2.56 Base-Loss:0.894, Arch-Loss=1.107
***[2020-01-29 06:32:39]*** TRAIN [epoch=095/600] base-loss = 0.894161, arch-loss = 1.107297, accuracy-1 = 69.51, accuracy-5 = 97.44
[epoch=095/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 11, 6, 14, 16, 16, 32, 25, 32, 28, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.39104)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.387 0.233 0.380  ||  0.0290 -0.4775 0.0107  || discrepancy=0.01 || select=0/3
001/003-th : 0.394 0.181 0.426  ||  -0.0024 -0.7795 0.0759  || discrepancy=0.03 || select=2/3
002/003-th : 0.290 0.231 0.479  ||  -0.2284 -0.4522 0.2748  || discrepancy=0.19 || select=2/3
-----------------------------------------------
000/019-th : 0.074 0.090 0.110 0.114 0.142 0.152 0.160 0.158  ||  -0.486 -0.281 -0.084 -0.054 0.171 0.236 0.292 0.278   || dis=0.00 || select=6/8
001/019-th : 0.121 0.120 0.125 0.123 0.128 0.128 0.127 0.129  ||  -0.029 -0.038 0.004 -0.008 0.029 0.033 0.019 0.034    || dis=0.00 || select=7/8
002/019-th : 0.116 0.121 0.125 0.127 0.130 0.129 0.126 0.125  ||  -0.068 -0.027 0.006 0.024 0.043 0.034 0.012 0.008     || dis=0.00 || select=4/8
003/019-th : 0.123 0.127 0.127 0.123 0.127 0.124 0.124 0.124  ||  -0.014 0.018 0.011 -0.015 0.014 -0.007 -0.005 -0.011  || dis=0.00 || select=1/8
004/019-th : 0.119 0.120 0.123 0.126 0.128 0.126 0.130 0.128  ||  -0.050 -0.040 -0.018 0.012 0.027 0.013 0.042 0.022    || dis=0.00 || select=6/8
005/019-th : 0.119 0.123 0.122 0.122 0.126 0.129 0.128 0.130  ||  -0.048 -0.022 -0.022 -0.026 0.008 0.031 0.022 0.041   || dis=0.00 || select=7/8
006/019-th : 0.114 0.115 0.123 0.122 0.129 0.128 0.134 0.134  ||  -0.091 -0.079 -0.019 -0.022 0.031 0.027 0.069 0.071   || dis=0.00 || select=7/8
007/019-th : 0.095 0.097 0.104 0.120 0.128 0.144 0.154 0.157  ||  -0.252 -0.232 -0.164 -0.018 0.045 0.163 0.225 0.248   || dis=0.00 || select=7/8
008/019-th : 0.080 0.089 0.104 0.130 0.138 0.160 0.151 0.148  ||  -0.399 -0.289 -0.142 0.088 0.141 0.291 0.237 0.212    || dis=0.01 || select=5/8
009/019-th : 0.110 0.109 0.108 0.119 0.126 0.135 0.143 0.149  ||  -0.124 -0.133 -0.139 -0.046 0.010 0.083 0.137 0.179   || dis=0.01 || select=7/8
010/019-th : 0.110 0.113 0.121 0.127 0.128 0.132 0.134 0.134  ||  -0.124 -0.093 -0.031 0.024 0.029 0.063 0.075 0.075    || dis=0.00 || select=6/8
011/019-th : 0.110 0.109 0.110 0.114 0.124 0.133 0.148 0.152  ||  -0.132 -0.139 -0.129 -0.093 -0.008 0.063 0.167 0.193  || dis=0.00 || select=7/8
012/019-th : 0.114 0.116 0.119 0.126 0.130 0.129 0.132 0.133  ||  -0.084 -0.067 -0.044 0.014 0.045 0.039 0.060 0.067    || dis=0.00 || select=7/8
013/019-th : 0.076 0.079 0.087 0.100 0.122 0.149 0.184 0.202  ||  -0.462 -0.412 -0.320 -0.180 0.020 0.218 0.430 0.519   || dis=0.02 || select=7/8
014/019-th : 0.076 0.079 0.095 0.119 0.138 0.154 0.175 0.164  ||  -0.455 -0.420 -0.229 -0.003 0.140 0.251 0.380 0.318   || dis=0.01 || select=6/8
015/019-th : 0.078 0.072 0.086 0.102 0.131 0.157 0.184 0.191  ||  -0.411 -0.503 -0.317 -0.153 0.100 0.282 0.440 0.478   || dis=0.01 || select=7/8
016/019-th : 0.069 0.088 0.102 0.129 0.137 0.157 0.159 0.158  ||  -0.554 -0.309 -0.155 0.078 0.140 0.275 0.289 0.279    || dis=0.00 || select=6/8
017/019-th : 0.117 0.115 0.119 0.126 0.127 0.127 0.134 0.137  ||  -0.060 -0.078 -0.042 0.015 0.021 0.020 0.076 0.097    || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.111 0.123 0.136 0.133 0.149 0.167  ||  -0.373 -0.221 -0.099 0.003 0.110 0.082 0.199 0.312    || dis=0.02 || select=7/8
[epoch=095/600] FLOP : 28.39 MB, ratio : 0.6956, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:32:39] [epoch=095/600][000/098] Time 0.40 (0.40) Data 0.32 (0.32) Loss 2.025 (2.025)  Prec@1 43.75 (43.75) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:32:46] [epoch=095/600][097/098] Time 0.06 (0.08) Data 0.00 (0.00) Loss 1.461 (2.146)  Prec@1 53.57 (39.72) Prec@5 93.45 (84.00) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.72 Prec@5 84.00 Error@1 60.28 Error@5 16.00 Loss:2.146
***[2020-01-29 06:32:46]*** VALID [epoch=095/600] loss = 2.145566, accuracy@1 = 39.72, accuracy@5 = 84.00 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:32:46]*** start epoch=096/600 Time Left: [04:31:35], LR=[0.093815 ~ 0.093815], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=96, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.6969513661074656, FLOP=40.81
[Search] : epoch=096/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:32:47] [epoch=096/600][000/098] Time 0.76 (0.76) Data 0.40 (0.40) Base-Loss 0.739 (0.739)  Prec@1 74.22 (74.22) Prec@5 98.44 (98.44) Acls-loss 0.916 (0.916) FLOP-Loss 0.000 (0.000) Arch-Loss 0.916 (0.916)
**TRAIN** [2020-01-29 06:33:12] [epoch=096/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.794 (0.886)  Prec@1 72.62 (69.60) Prec@5 97.62 (97.50) Acls-loss 0.992 (0.904) FLOP-Loss 0.000 (0.103) Arch-Loss 0.992 (1.111)
 **TRAIN** Prec@1 69.60 Prec@5 97.50 Error@1 30.40 Error@5 2.50 Base-Loss:0.886, Arch-Loss=1.111
***[2020-01-29 06:33:12]*** TRAIN [epoch=096/600] base-loss = 0.885851, arch-loss = 1.110896, accuracy-1 = 69.60, accuracy-5 = 97.50
[epoch=096/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 11, 11, 6, 14, 16, 14, 32, 25, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.464832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.391 0.234 0.375  ||  0.0409 -0.4695 -0.0004  || discrepancy=0.02 || select=0/3
001/003-th : 0.398 0.181 0.421  ||  0.0087 -0.7805 0.0665  || discrepancy=0.02 || select=2/3
002/003-th : 0.292 0.233 0.475  ||  -0.2207 -0.4445 0.2678  || discrepancy=0.18 || select=2/3
-----------------------------------------------
000/019-th : 0.074 0.091 0.111 0.114 0.142 0.151 0.160 0.157  ||  -0.478 -0.274 -0.080 -0.055 0.165 0.230 0.289 0.270   || dis=0.00 || select=6/8
001/019-th : 0.122 0.121 0.127 0.124 0.127 0.127 0.125 0.127  ||  -0.019 -0.028 0.019 -0.001 0.025 0.023 0.009 0.021    || dis=0.00 || select=4/8
002/019-th : 0.118 0.123 0.126 0.128 0.129 0.127 0.125 0.124  ||  -0.056 -0.012 0.015 0.030 0.033 0.020 0.000 -0.004    || dis=0.00 || select=4/8
003/019-th : 0.125 0.129 0.128 0.125 0.126 0.123 0.123 0.122  ||  -0.004 0.028 0.021 -0.003 0.011 -0.019 -0.018 -0.022  || dis=0.00 || select=1/8
004/019-th : 0.120 0.121 0.123 0.128 0.126 0.126 0.129 0.127  ||  -0.038 -0.033 -0.013 0.022 0.011 0.008 0.029 0.015    || dis=0.00 || select=6/8
005/019-th : 0.121 0.124 0.124 0.124 0.125 0.128 0.126 0.129  ||  -0.035 -0.012 -0.009 -0.013 -0.006 0.019 0.009 0.031  || dis=0.00 || select=7/8
006/019-th : 0.115 0.116 0.124 0.123 0.129 0.128 0.133 0.132  ||  -0.082 -0.070 -0.006 -0.014 0.033 0.023 0.060 0.056   || dis=0.00 || select=6/8
007/019-th : 0.096 0.098 0.105 0.123 0.127 0.144 0.152 0.155  ||  -0.244 -0.228 -0.154 0.006 0.034 0.164 0.213 0.236    || dis=0.00 || select=7/8
008/019-th : 0.080 0.090 0.103 0.130 0.140 0.158 0.151 0.146  ||  -0.398 -0.279 -0.145 0.088 0.162 0.282 0.233 0.204    || dis=0.01 || select=5/8
009/019-th : 0.111 0.109 0.109 0.120 0.127 0.134 0.142 0.148  ||  -0.114 -0.130 -0.132 -0.036 0.019 0.073 0.129 0.170   || dis=0.01 || select=7/8
010/019-th : 0.111 0.114 0.123 0.128 0.129 0.131 0.132 0.133  ||  -0.116 -0.088 -0.012 0.026 0.035 0.054 0.064 0.064    || dis=0.00 || select=7/8
011/019-th : 0.112 0.110 0.111 0.114 0.124 0.132 0.147 0.151  ||  -0.116 -0.133 -0.121 -0.100 -0.013 0.049 0.162 0.186  || dis=0.00 || select=7/8
012/019-th : 0.115 0.117 0.119 0.128 0.130 0.128 0.132 0.132  ||  -0.079 -0.058 -0.047 0.030 0.042 0.030 0.057 0.059    || dis=0.00 || select=7/8
013/019-th : 0.074 0.079 0.087 0.101 0.124 0.150 0.183 0.201  ||  -0.476 -0.412 -0.321 -0.164 0.038 0.227 0.427 0.517   || dis=0.02 || select=7/8
014/019-th : 0.077 0.079 0.096 0.120 0.138 0.153 0.173 0.164  ||  -0.447 -0.416 -0.222 0.005 0.140 0.246 0.369 0.314    || dis=0.01 || select=6/8
015/019-th : 0.078 0.071 0.086 0.101 0.130 0.158 0.185 0.191  ||  -0.413 -0.513 -0.317 -0.153 0.095 0.289 0.450 0.480   || dis=0.01 || select=7/8
016/019-th : 0.069 0.088 0.103 0.132 0.136 0.157 0.158 0.157  ||  -0.551 -0.304 -0.145 0.102 0.126 0.270 0.281 0.270    || dis=0.00 || select=6/8
017/019-th : 0.118 0.116 0.119 0.128 0.128 0.125 0.132 0.136  ||  -0.053 -0.065 -0.044 0.028 0.029 0.009 0.063 0.090    || dis=0.00 || select=7/8
018/019-th : 0.085 0.099 0.111 0.123 0.135 0.134 0.149 0.165  ||  -0.364 -0.209 -0.097 0.005 0.098 0.091 0.195 0.298    || dis=0.02 || select=7/8
[epoch=096/600] FLOP : 27.46 MB, ratio : 0.6729, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:33:12] [epoch=096/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.926 (1.926)  Prec@1 42.19 (42.19) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:33:18] [epoch=096/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.523 (2.229)  Prec@1 48.81 (37.72) Prec@5 91.07 (82.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.72 Prec@5 82.30 Error@1 62.28 Error@5 17.70 Loss:2.229
***[2020-01-29 06:33:18]*** VALID [epoch=096/600] loss = 2.228810, accuracy@1 = 37.72, accuracy@5 = 82.30 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:33:18]*** start epoch=097/600 Time Left: [04:31:00], LR=[0.093689 ~ 0.093689], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=97, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.690741946436891, FLOP=40.81
[Search] : epoch=097/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:33:19] [epoch=097/600][000/098] Time 0.74 (0.74) Data 0.36 (0.36) Base-Loss 0.858 (0.858)  Prec@1 71.09 (71.09) Prec@5 97.66 (97.66) Acls-loss 0.876 (0.876) FLOP-Loss 0.000 (0.000) Arch-Loss 0.876 (0.876)
**TRAIN** [2020-01-29 06:33:43] [epoch=097/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.819 (0.870)  Prec@1 70.24 (70.07) Prec@5 98.81 (97.47) Acls-loss 0.966 (0.906) FLOP-Loss 0.000 (0.026) Arch-Loss 0.966 (0.958)
 **TRAIN** Prec@1 70.07 Prec@5 97.47 Error@1 29.93 Error@5 2.53 Base-Loss:0.870, Arch-Loss=0.958
***[2020-01-29 06:33:43]*** TRAIN [epoch=097/600] base-loss = 0.869965, arch-loss = 0.957856, accuracy-1 = 70.07, accuracy-5 = 97.47
[epoch=097/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 9, 6, 14, 16, 14, 32, 25, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.293248)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.390 0.237 0.373  ||  0.0418 -0.4557 -0.0007  || discrepancy=0.02 || select=0/3
001/003-th : 0.398 0.180 0.422  ||  0.0086 -0.7831 0.0684  || discrepancy=0.02 || select=2/3
002/003-th : 0.289 0.235 0.475  ||  -0.2245 -0.4308 0.2712  || discrepancy=0.19 || select=2/3
-----------------------------------------------
000/019-th : 0.074 0.091 0.111 0.115 0.140 0.151 0.161 0.158  ||  -0.479 -0.275 -0.082 -0.048 0.155 0.227 0.290 0.272   || dis=0.00 || select=6/8
001/019-th : 0.122 0.121 0.126 0.124 0.126 0.127 0.126 0.127  ||  -0.017 -0.027 0.015 -0.001 0.016 0.018 0.011 0.022    || dis=0.00 || select=7/8
002/019-th : 0.118 0.123 0.126 0.129 0.128 0.127 0.124 0.124  ||  -0.057 -0.010 0.012 0.035 0.027 0.020 -0.001 -0.002   || dis=0.00 || select=3/8
003/019-th : 0.125 0.129 0.127 0.124 0.127 0.123 0.123 0.122  ||  -0.004 0.029 0.018 -0.005 0.013 -0.013 -0.018 -0.023  || dis=0.00 || select=1/8
004/019-th : 0.120 0.120 0.123 0.127 0.126 0.127 0.129 0.127  ||  -0.039 -0.039 -0.013 0.013 0.011 0.012 0.033 0.019    || dis=0.00 || select=6/8
005/019-th : 0.121 0.122 0.123 0.124 0.126 0.128 0.127 0.129  ||  -0.035 -0.024 -0.013 -0.005 0.005 0.025 0.013 0.031   || dis=0.00 || select=7/8
006/019-th : 0.115 0.116 0.124 0.123 0.128 0.128 0.133 0.133  ||  -0.081 -0.071 -0.010 -0.017 0.024 0.022 0.063 0.059   || dis=0.00 || select=6/8
007/019-th : 0.094 0.098 0.104 0.124 0.129 0.144 0.152 0.155  ||  -0.262 -0.222 -0.161 0.012 0.052 0.167 0.218 0.238    || dis=0.00 || select=7/8
008/019-th : 0.080 0.091 0.104 0.131 0.137 0.159 0.152 0.147  ||  -0.402 -0.277 -0.143 0.088 0.133 0.284 0.239 0.206    || dis=0.01 || select=5/8
009/019-th : 0.111 0.109 0.109 0.119 0.127 0.134 0.142 0.148  ||  -0.112 -0.133 -0.131 -0.048 0.016 0.070 0.132 0.174   || dis=0.01 || select=7/8
010/019-th : 0.110 0.113 0.125 0.127 0.129 0.132 0.132 0.133  ||  -0.121 -0.092 0.002 0.020 0.034 0.058 0.060 0.067     || dis=0.00 || select=7/8
011/019-th : 0.111 0.110 0.112 0.112 0.123 0.131 0.148 0.152  ||  -0.119 -0.135 -0.114 -0.116 -0.016 0.045 0.166 0.195  || dis=0.00 || select=7/8
012/019-th : 0.115 0.117 0.118 0.129 0.130 0.129 0.132 0.132  ||  -0.079 -0.060 -0.054 0.036 0.041 0.034 0.057 0.059    || dis=0.00 || select=7/8
013/019-th : 0.074 0.079 0.086 0.102 0.122 0.151 0.183 0.204  ||  -0.481 -0.412 -0.335 -0.160 0.022 0.233 0.426 0.533   || dis=0.02 || select=7/8
014/019-th : 0.076 0.079 0.096 0.121 0.136 0.154 0.173 0.166  ||  -0.453 -0.412 -0.224 0.006 0.123 0.248 0.365 0.324    || dis=0.01 || select=6/8
015/019-th : 0.078 0.070 0.087 0.101 0.129 0.157 0.186 0.193  ||  -0.414 -0.529 -0.307 -0.157 0.087 0.283 0.456 0.492   || dis=0.01 || select=7/8
016/019-th : 0.069 0.088 0.103 0.133 0.135 0.157 0.158 0.157  ||  -0.548 -0.310 -0.146 0.109 0.123 0.274 0.277 0.270    || dis=0.00 || select=6/8
017/019-th : 0.118 0.116 0.119 0.127 0.127 0.125 0.132 0.136  ||  -0.054 -0.065 -0.040 0.019 0.019 0.008 0.065 0.092    || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.112 0.121 0.135 0.135 0.148 0.164  ||  -0.357 -0.211 -0.084 -0.010 0.097 0.097 0.191 0.294   || dis=0.02 || select=7/8
[epoch=097/600] FLOP : 28.29 MB, ratio : 0.6932, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:33:44] [epoch=097/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.272 (2.272)  Prec@1 29.69 (29.69) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:33:50] [epoch=097/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 3.042 (2.331)  Prec@1 26.19 (35.67) Prec@5 70.83 (81.22) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.67 Prec@5 81.22 Error@1 64.33 Error@5 18.78 Loss:2.331
***[2020-01-29 06:33:50]*** VALID [epoch=097/600] loss = 2.331181, accuracy@1 = 35.67, accuracy@5 = 81.22 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:33:50]*** start epoch=098/600 Time Left: [04:30:23], LR=[0.093561 ~ 0.093561], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=98, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.6844738372444645, FLOP=40.81
[Search] : epoch=098/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:33:50] [epoch=098/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.772 (0.772)  Prec@1 71.48 (71.48) Prec@5 98.05 (98.05) Acls-loss 0.962 (0.962) FLOP-Loss 0.000 (0.000) Arch-Loss 0.962 (0.962)
**TRAIN** [2020-01-29 06:34:15] [epoch=098/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.851 (0.878)  Prec@1 69.64 (69.96) Prec@5 97.02 (97.37) Acls-loss 0.932 (0.903) FLOP-Loss 0.000 (0.000) Arch-Loss 0.932 (0.903)
 **TRAIN** Prec@1 69.96 Prec@5 97.37 Error@1 30.04 Error@5 2.63 Base-Loss:0.878, Arch-Loss=0.903
***[2020-01-29 06:34:15]*** TRAIN [epoch=098/600] base-loss = 0.878423, arch-loss = 0.902598, accuracy-1 = 69.96, accuracy-5 = 97.37
[epoch=098/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 9, 6, 14, 16, 14, 32, 25, 32, 32, 32, 28, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.733888)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.388 0.239 0.374  ||  0.0392 -0.4461 0.0026  || discrepancy=0.01 || select=0/3
001/003-th : 0.396 0.179 0.425  ||  0.0048 -0.7886 0.0741  || discrepancy=0.03 || select=2/3
002/003-th : 0.286 0.238 0.477  ||  -0.2326 -0.4173 0.2786  || discrepancy=0.19 || select=2/3
-----------------------------------------------
000/019-th : 0.074 0.091 0.110 0.115 0.139 0.152 0.161 0.158  ||  -0.488 -0.281 -0.083 -0.044 0.150 0.239 0.296 0.274   || dis=0.00 || select=6/8
001/019-th : 0.122 0.121 0.125 0.124 0.126 0.128 0.126 0.128  ||  -0.019 -0.032 0.004 -0.005 0.016 0.027 0.015 0.025    || dis=0.00 || select=5/8
002/019-th : 0.117 0.123 0.126 0.129 0.128 0.128 0.125 0.125  ||  -0.059 -0.017 0.013 0.037 0.023 0.024 0.002 0.000     || dis=0.00 || select=3/8
003/019-th : 0.124 0.128 0.126 0.124 0.128 0.124 0.123 0.122  ||  -0.004 0.026 0.011 -0.008 0.021 -0.008 -0.016 -0.021  || dis=0.00 || select=1/8
004/019-th : 0.119 0.120 0.123 0.125 0.128 0.127 0.130 0.128  ||  -0.046 -0.043 -0.014 0.004 0.021 0.013 0.042 0.023    || dis=0.00 || select=6/8
005/019-th : 0.120 0.122 0.122 0.124 0.127 0.129 0.127 0.130  ||  -0.039 -0.026 -0.026 -0.004 0.013 0.031 0.015 0.036   || dis=0.00 || select=7/8
006/019-th : 0.115 0.115 0.123 0.121 0.129 0.129 0.134 0.133  ||  -0.084 -0.080 -0.013 -0.031 0.030 0.029 0.069 0.065   || dis=0.00 || select=6/8
007/019-th : 0.092 0.097 0.103 0.123 0.130 0.144 0.154 0.156  ||  -0.279 -0.229 -0.165 0.007 0.067 0.163 0.236 0.247    || dis=0.00 || select=7/8
008/019-th : 0.079 0.090 0.104 0.131 0.137 0.158 0.154 0.148  ||  -0.412 -0.286 -0.144 0.089 0.135 0.279 0.251 0.213    || dis=0.00 || select=5/8
009/019-th : 0.111 0.108 0.109 0.118 0.128 0.134 0.143 0.149  ||  -0.113 -0.141 -0.138 -0.056 0.023 0.070 0.138 0.180   || dis=0.01 || select=7/8
010/019-th : 0.110 0.113 0.124 0.127 0.127 0.133 0.132 0.134  ||  -0.124 -0.098 -0.003 0.023 0.023 0.069 0.062 0.071    || dis=0.00 || select=7/8
011/019-th : 0.111 0.108 0.112 0.111 0.121 0.134 0.149 0.154  ||  -0.122 -0.148 -0.117 -0.120 -0.033 0.067 0.172 0.204  || dis=0.01 || select=7/8
012/019-th : 0.115 0.117 0.117 0.128 0.129 0.130 0.132 0.132  ||  -0.082 -0.064 -0.060 0.031 0.036 0.043 0.063 0.062    || dis=0.00 || select=6/8
013/019-th : 0.072 0.078 0.085 0.100 0.123 0.152 0.183 0.207  ||  -0.497 -0.419 -0.341 -0.177 0.033 0.241 0.429 0.554   || dis=0.02 || select=7/8
014/019-th : 0.076 0.078 0.096 0.121 0.134 0.154 0.174 0.167  ||  -0.458 -0.425 -0.226 0.009 0.114 0.248 0.376 0.332    || dis=0.01 || select=6/8
015/019-th : 0.077 0.068 0.087 0.100 0.128 0.154 0.190 0.196  ||  -0.424 -0.547 -0.299 -0.166 0.085 0.266 0.480 0.509   || dis=0.01 || select=7/8
016/019-th : 0.068 0.088 0.103 0.134 0.136 0.156 0.157 0.158  ||  -0.558 -0.310 -0.152 0.115 0.128 0.268 0.276 0.280    || dis=0.00 || select=7/8
017/019-th : 0.117 0.116 0.119 0.126 0.127 0.126 0.133 0.136  ||  -0.055 -0.072 -0.044 0.018 0.021 0.015 0.070 0.091    || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.113 0.120 0.135 0.136 0.149 0.162  ||  -0.356 -0.211 -0.081 -0.015 0.096 0.105 0.201 0.283   || dis=0.01 || select=7/8
[epoch=098/600] FLOP : 27.73 MB, ratio : 0.6795, Expected-ratio : 0.7000, Discrepancy : 0.014
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:34:15] [epoch=098/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.091 (3.091)  Prec@1 41.02 (41.02) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:34:21] [epoch=098/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.930 (2.231)  Prec@1 36.90 (36.08) Prec@5 79.76 (81.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.08 Prec@5 81.79 Error@1 63.92 Error@5 18.21 Loss:2.231
***[2020-01-29 06:34:21]*** VALID [epoch=098/600] loss = 2.231487, accuracy@1 = 36.08, accuracy@5 = 81.79 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:34:21]*** start epoch=099/600 Time Left: [04:29:46], LR=[0.093432 ~ 0.093432], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=99, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.678147210373568, FLOP=40.81
[Search] : epoch=099/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:34:22] [epoch=099/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.996 (0.996)  Prec@1 66.80 (66.80) Prec@5 96.09 (96.09) Acls-loss 0.923 (0.923) FLOP-Loss 0.000 (0.000) Arch-Loss 0.923 (0.923)
**TRAIN** [2020-01-29 06:34:47] [epoch=099/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.929 (0.888)  Prec@1 69.64 (69.54) Prec@5 95.83 (97.48) Acls-loss 1.074 (0.908) FLOP-Loss 0.000 (-0.078) Arch-Loss 1.074 (0.753)
 **TRAIN** Prec@1 69.54 Prec@5 97.48 Error@1 30.46 Error@5 2.52 Base-Loss:0.888, Arch-Loss=0.753
***[2020-01-29 06:34:47]*** TRAIN [epoch=099/600] base-loss = 0.888068, arch-loss = 0.752531, accuracy-1 = 69.54, accuracy-5 = 97.48
[epoch=099/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 12, 11, 14, 16, 14, 32, 25, 32, 32, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.336256)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.384 0.236 0.381  ||  0.0257 -0.4603 0.0179  || discrepancy=0.00 || select=0/3
001/003-th : 0.390 0.180 0.430  ||  -0.0094 -0.7803 0.0895  || discrepancy=0.04 || select=2/3
002/003-th : 0.280 0.234 0.486  ||  -0.2516 -0.4331 0.2987  || discrepancy=0.21 || select=2/3
-----------------------------------------------
000/019-th : 0.072 0.089 0.109 0.114 0.141 0.152 0.163 0.160  ||  -0.503 -0.298 -0.093 -0.051 0.160 0.242 0.309 0.290   || dis=0.00 || select=6/8
001/019-th : 0.121 0.119 0.123 0.122 0.127 0.130 0.128 0.129  ||  -0.032 -0.042 -0.013 -0.019 0.020 0.043 0.029 0.038   || dis=0.00 || select=5/8
002/019-th : 0.116 0.121 0.124 0.128 0.129 0.129 0.127 0.126  ||  -0.070 -0.029 -0.003 0.026 0.031 0.034 0.015 0.013    || dis=0.00 || select=5/8
003/019-th : 0.123 0.126 0.125 0.122 0.129 0.126 0.125 0.124  ||  -0.019 0.009 0.001 -0.023 0.030 0.006 0.001 -0.006    || dis=0.00 || select=4/8
004/019-th : 0.118 0.118 0.122 0.123 0.129 0.129 0.132 0.130  ||  -0.060 -0.057 -0.025 -0.016 0.029 0.030 0.056 0.036   || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.120 0.122 0.128 0.131 0.129 0.132  ||  -0.057 -0.044 -0.037 -0.022 0.024 0.047 0.033 0.054   || dis=0.00 || select=7/8
006/019-th : 0.114 0.114 0.121 0.120 0.129 0.131 0.136 0.135  ||  -0.093 -0.092 -0.032 -0.042 0.027 0.048 0.081 0.078   || dis=0.00 || select=6/8
007/019-th : 0.090 0.095 0.104 0.121 0.130 0.144 0.157 0.159  ||  -0.301 -0.249 -0.162 -0.006 0.069 0.171 0.255 0.267   || dis=0.00 || select=7/8
008/019-th : 0.078 0.088 0.103 0.128 0.137 0.159 0.157 0.151  ||  -0.426 -0.306 -0.149 0.067 0.137 0.285 0.271 0.232    || dis=0.00 || select=5/8
009/019-th : 0.110 0.106 0.107 0.117 0.128 0.135 0.145 0.152  ||  -0.123 -0.157 -0.155 -0.060 0.028 0.079 0.150 0.197   || dis=0.01 || select=7/8
010/019-th : 0.108 0.111 0.122 0.128 0.127 0.135 0.133 0.135  ||  -0.139 -0.109 -0.019 0.027 0.023 0.084 0.071 0.086    || dis=0.00 || select=7/8
011/019-th : 0.109 0.107 0.109 0.111 0.121 0.136 0.151 0.156  ||  -0.140 -0.160 -0.134 -0.116 -0.035 0.082 0.188 0.221  || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.117 0.128 0.129 0.130 0.134 0.135  ||  -0.094 -0.081 -0.062 0.029 0.035 0.047 0.072 0.078    || dis=0.00 || select=7/8
013/019-th : 0.071 0.077 0.083 0.099 0.121 0.152 0.186 0.212  ||  -0.509 -0.432 -0.358 -0.185 0.015 0.245 0.448 0.581   || dis=0.03 || select=7/8
014/019-th : 0.074 0.077 0.094 0.120 0.133 0.156 0.177 0.169  ||  -0.479 -0.436 -0.240 0.007 0.108 0.269 0.391 0.345    || dis=0.01 || select=6/8
015/019-th : 0.075 0.066 0.085 0.099 0.126 0.157 0.191 0.200  ||  -0.439 -0.567 -0.325 -0.164 0.074 0.292 0.489 0.538   || dis=0.01 || select=7/8
016/019-th : 0.067 0.086 0.102 0.134 0.135 0.157 0.160 0.160  ||  -0.574 -0.324 -0.161 0.118 0.120 0.273 0.291 0.293    || dis=0.00 || select=7/8
017/019-th : 0.116 0.114 0.119 0.124 0.128 0.127 0.135 0.138  ||  -0.068 -0.087 -0.046 -0.005 0.031 0.024 0.082 0.105   || dis=0.00 || select=7/8
018/019-th : 0.085 0.098 0.112 0.120 0.133 0.136 0.150 0.165  ||  -0.365 -0.217 -0.090 -0.016 0.081 0.104 0.207 0.300   || dis=0.02 || select=7/8
[epoch=099/600] FLOP : 28.34 MB, ratio : 0.6943, Expected-ratio : 0.7000, Discrepancy : 0.015
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:34:47] [epoch=099/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.795 (1.795)  Prec@1 40.23 (40.23) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:34:53] [epoch=099/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.865 (2.110)  Prec@1 41.07 (39.80) Prec@5 87.50 (84.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.80 Prec@5 84.65 Error@1 60.20 Error@5 15.35 Loss:2.110
***[2020-01-29 06:34:53]*** VALID [epoch=099/600] loss = 2.109518, accuracy@1 = 39.80, accuracy@5 = 84.65 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:34:53]*** start epoch=100/600 Time Left: [04:29:14], LR=[0.093301 ~ 0.093301], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=100, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.671762239271875, FLOP=40.81
[Search] : epoch=100/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:34:54] [epoch=100/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.785 (0.785)  Prec@1 72.27 (72.27) Prec@5 97.66 (97.66) Acls-loss 0.892 (0.892) FLOP-Loss 0.000 (0.000) Arch-Loss 0.892 (0.892)
**TRAIN** [2020-01-29 06:35:18] [epoch=100/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.874 (0.884)  Prec@1 67.86 (69.39) Prec@5 97.62 (97.50) Acls-loss 0.898 (0.911) FLOP-Loss 0.000 (0.052) Arch-Loss 0.898 (1.015)
 **TRAIN** Prec@1 69.39 Prec@5 97.50 Error@1 30.61 Error@5 2.50 Base-Loss:0.884, Arch-Loss=1.015
***[2020-01-29 06:35:18]*** TRAIN [epoch=100/600] base-loss = 0.884064, arch-loss = 1.015297, accuracy-1 = 69.39, accuracy-5 = 97.50
[epoch=100/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 9, 11, 14, 16, 14, 32, 25, 32, 32, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.961472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.387 0.232 0.381  ||  0.0305 -0.4836 0.0155  || discrepancy=0.01 || select=0/3
001/003-th : 0.391 0.178 0.431  ||  -0.0074 -0.7957 0.0903  || discrepancy=0.04 || select=2/3
002/003-th : 0.278 0.234 0.488  ||  -0.2565 -0.4297 0.3040  || discrepancy=0.21 || select=2/3
-----------------------------------------------
000/019-th : 0.072 0.089 0.108 0.115 0.139 0.153 0.164 0.160  ||  -0.511 -0.293 -0.099 -0.044 0.152 0.243 0.315 0.290   || dis=0.00 || select=6/8
001/019-th : 0.121 0.120 0.124 0.122 0.127 0.129 0.128 0.129  ||  -0.029 -0.035 -0.009 -0.018 0.015 0.036 0.028 0.032   || dis=0.00 || select=5/8
002/019-th : 0.116 0.121 0.126 0.129 0.128 0.128 0.126 0.126  ||  -0.068 -0.026 0.007 0.035 0.024 0.029 0.010 0.009     || dis=0.00 || select=3/8
003/019-th : 0.123 0.127 0.126 0.123 0.128 0.125 0.125 0.124  ||  -0.013 0.012 0.003 -0.020 0.023 0.002 -0.003 -0.010   || dis=0.00 || select=4/8
004/019-th : 0.118 0.119 0.123 0.123 0.129 0.128 0.132 0.129  ||  -0.060 -0.052 -0.017 -0.018 0.033 0.025 0.054 0.033   || dis=0.00 || select=6/8
005/019-th : 0.118 0.119 0.121 0.123 0.128 0.130 0.128 0.132  ||  -0.055 -0.044 -0.035 -0.013 0.027 0.043 0.029 0.053   || dis=0.00 || select=7/8
006/019-th : 0.114 0.114 0.121 0.121 0.129 0.132 0.135 0.135  ||  -0.093 -0.089 -0.036 -0.036 0.031 0.056 0.078 0.074   || dis=0.00 || select=6/8
007/019-th : 0.090 0.094 0.104 0.120 0.130 0.145 0.157 0.159  ||  -0.300 -0.256 -0.155 -0.011 0.066 0.172 0.258 0.268   || dis=0.00 || select=7/8
008/019-th : 0.078 0.088 0.102 0.130 0.135 0.159 0.157 0.152  ||  -0.424 -0.304 -0.158 0.080 0.117 0.281 0.270 0.236    || dis=0.00 || select=5/8
009/019-th : 0.110 0.107 0.107 0.116 0.129 0.135 0.144 0.152  ||  -0.123 -0.157 -0.150 -0.068 0.031 0.079 0.148 0.198   || dis=0.01 || select=7/8
010/019-th : 0.108 0.111 0.122 0.127 0.128 0.134 0.134 0.135  ||  -0.139 -0.111 -0.021 0.023 0.032 0.078 0.073 0.087    || dis=0.00 || select=7/8
011/019-th : 0.108 0.106 0.110 0.112 0.123 0.135 0.150 0.155  ||  -0.144 -0.163 -0.123 -0.108 -0.017 0.080 0.185 0.218  || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.118 0.128 0.129 0.130 0.133 0.135  ||  -0.094 -0.087 -0.055 0.028 0.036 0.044 0.066 0.084    || dis=0.00 || select=7/8
013/019-th : 0.069 0.077 0.084 0.099 0.121 0.149 0.187 0.213  ||  -0.537 -0.431 -0.340 -0.181 0.021 0.230 0.457 0.589   || dis=0.03 || select=7/8
014/019-th : 0.074 0.078 0.093 0.120 0.134 0.155 0.178 0.169  ||  -0.484 -0.431 -0.248 0.001 0.115 0.263 0.399 0.348    || dis=0.01 || select=6/8
015/019-th : 0.075 0.065 0.085 0.098 0.125 0.157 0.192 0.202  ||  -0.439 -0.583 -0.317 -0.174 0.068 0.294 0.496 0.549   || dis=0.01 || select=7/8
016/019-th : 0.067 0.086 0.101 0.134 0.136 0.156 0.160 0.160  ||  -0.576 -0.329 -0.162 0.115 0.135 0.267 0.293 0.295    || dis=0.00 || select=7/8
017/019-th : 0.117 0.113 0.119 0.124 0.127 0.128 0.134 0.138  ||  -0.063 -0.091 -0.047 0.000 0.021 0.030 0.079 0.103    || dis=0.00 || select=7/8
018/019-th : 0.085 0.099 0.111 0.122 0.130 0.137 0.151 0.165  ||  -0.364 -0.212 -0.097 -0.008 0.062 0.115 0.207 0.299   || dis=0.01 || select=7/8
[epoch=100/600] FLOP : 27.96 MB, ratio : 0.6851, Expected-ratio : 0.7000, Discrepancy : 0.016
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:35:19] [epoch=100/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.444 (2.444)  Prec@1 24.22 (24.22) Prec@5 75.78 (75.78) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:35:25] [epoch=100/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.936 (2.053)  Prec@1 27.98 (37.45) Prec@5 78.57 (83.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.45 Prec@5 83.18 Error@1 62.55 Error@5 16.82 Loss:2.053
***[2020-01-29 06:35:25]*** VALID [epoch=100/600] loss = 2.052874, accuracy@1 = 37.45, accuracy@5 = 83.18 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:35:25]*** start epoch=101/600 Time Left: [04:28:37], LR=[0.093170 ~ 0.093170], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=101, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.665319098986591, FLOP=40.81
[Search] : epoch=101/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:35:26] [epoch=101/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.909 (0.909)  Prec@1 69.92 (69.92) Prec@5 96.88 (96.88) Acls-loss 0.853 (0.853) FLOP-Loss 0.000 (0.000) Arch-Loss 0.853 (0.853)
**TRAIN** [2020-01-29 06:35:50] [epoch=101/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.987 (0.883)  Prec@1 68.45 (69.85) Prec@5 95.24 (97.53) Acls-loss 0.915 (0.890) FLOP-Loss 0.000 (0.104) Arch-Loss 0.915 (1.098)
 **TRAIN** Prec@1 69.85 Prec@5 97.53 Error@1 30.15 Error@5 2.47 Base-Loss:0.883, Arch-Loss=1.098
***[2020-01-29 06:35:50]*** TRAIN [epoch=101/600] base-loss = 0.882769, arch-loss = 1.098097, accuracy-1 = 69.85, accuracy-5 = 97.53
[epoch=101/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 9, 6, 14, 16, 14, 32, 25, 32, 32, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.961472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.391 0.232 0.377  ||  0.0419 -0.4816 0.0054  || discrepancy=0.01 || select=0/3
001/003-th : 0.395 0.177 0.428  ||  0.0024 -0.8023 0.0828  || discrepancy=0.03 || select=2/3
002/003-th : 0.279 0.236 0.485  ||  -0.2533 -0.4191 0.3010  || discrepancy=0.21 || select=2/3
-----------------------------------------------
000/019-th : 0.072 0.090 0.109 0.114 0.139 0.154 0.161 0.160  ||  -0.504 -0.284 -0.098 -0.047 0.149 0.253 0.298 0.288   || dis=0.00 || select=6/8
001/019-th : 0.122 0.122 0.125 0.124 0.126 0.128 0.127 0.127  ||  -0.019 -0.024 -0.001 -0.009 0.008 0.023 0.018 0.022   || dis=0.00 || select=5/8
002/019-th : 0.117 0.123 0.127 0.130 0.128 0.127 0.124 0.124  ||  -0.060 -0.014 0.021 0.045 0.026 0.018 0.000 -0.004    || dis=0.00 || select=3/8
003/019-th : 0.125 0.128 0.127 0.124 0.126 0.124 0.123 0.122  ||  -0.004 0.024 0.017 -0.006 0.009 -0.010 -0.013 -0.021  || dis=0.00 || select=1/8
004/019-th : 0.119 0.120 0.124 0.125 0.126 0.128 0.130 0.128  ||  -0.049 -0.040 -0.008 0.001 0.008 0.020 0.038 0.025    || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.121 0.125 0.128 0.129 0.128 0.130  ||  -0.046 -0.039 -0.027 0.003 0.023 0.031 0.026 0.040    || dis=0.00 || select=7/8
006/019-th : 0.115 0.116 0.122 0.120 0.127 0.133 0.134 0.133  ||  -0.082 -0.079 -0.025 -0.041 0.016 0.059 0.070 0.063   || dis=0.00 || select=6/8
007/019-th : 0.090 0.095 0.105 0.121 0.130 0.144 0.156 0.159  ||  -0.300 -0.247 -0.146 -0.008 0.065 0.168 0.247 0.264   || dis=0.00 || select=7/8
008/019-th : 0.078 0.089 0.102 0.132 0.133 0.157 0.157 0.152  ||  -0.425 -0.294 -0.157 0.093 0.101 0.271 0.267 0.236    || dis=0.00 || select=5/8
009/019-th : 0.109 0.107 0.109 0.118 0.128 0.134 0.144 0.151  ||  -0.128 -0.154 -0.135 -0.057 0.027 0.077 0.149 0.193   || dis=0.01 || select=7/8
010/019-th : 0.108 0.112 0.122 0.126 0.129 0.135 0.132 0.135  ||  -0.138 -0.102 -0.018 0.017 0.040 0.082 0.059 0.085    || dis=0.00 || select=7/8
011/019-th : 0.109 0.106 0.113 0.112 0.122 0.134 0.149 0.154  ||  -0.137 -0.160 -0.102 -0.105 -0.021 0.073 0.174 0.211  || dis=0.01 || select=7/8
012/019-th : 0.114 0.116 0.120 0.127 0.127 0.130 0.131 0.135  ||  -0.088 -0.075 -0.035 0.016 0.019 0.041 0.050 0.080    || dis=0.00 || select=7/8
013/019-th : 0.070 0.076 0.085 0.098 0.121 0.148 0.188 0.213  ||  -0.531 -0.443 -0.330 -0.189 0.024 0.224 0.465 0.589   || dis=0.02 || select=7/8
014/019-th : 0.073 0.079 0.093 0.120 0.134 0.155 0.177 0.168  ||  -0.488 -0.412 -0.248 0.004 0.113 0.261 0.395 0.342    || dis=0.01 || select=6/8
015/019-th : 0.075 0.063 0.087 0.098 0.127 0.153 0.193 0.202  ||  -0.438 -0.612 -0.292 -0.169 0.086 0.274 0.507 0.551   || dis=0.01 || select=7/8
016/019-th : 0.068 0.086 0.102 0.134 0.136 0.157 0.158 0.160  ||  -0.569 -0.328 -0.153 0.113 0.129 0.271 0.280 0.294    || dis=0.00 || select=7/8
017/019-th : 0.118 0.114 0.119 0.126 0.124 0.127 0.134 0.137  ||  -0.052 -0.083 -0.043 0.014 -0.005 0.022 0.076 0.093   || dis=0.00 || select=7/8
018/019-th : 0.085 0.100 0.112 0.119 0.131 0.138 0.151 0.163  ||  -0.361 -0.202 -0.088 -0.027 0.068 0.120 0.209 0.288   || dis=0.01 || select=7/8
[epoch=101/600] FLOP : 27.96 MB, ratio : 0.6851, Expected-ratio : 0.7000, Discrepancy : 0.015
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:35:51] [epoch=101/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.177 (2.177)  Prec@1 35.55 (35.55) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:35:57] [epoch=101/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.411 (2.190)  Prec@1 46.43 (37.11) Prec@5 94.64 (82.82) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.11 Prec@5 82.82 Error@1 62.89 Error@5 17.18 Loss:2.190
***[2020-01-29 06:35:57]*** VALID [epoch=101/600] loss = 2.189635, accuracy@1 = 37.11, accuracy@5 = 82.82 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:35:57]*** start epoch=102/600 Time Left: [04:28:03], LR=[0.093037 ~ 0.093037], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=102, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.658817966159662, FLOP=40.81
[Search] : epoch=102/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:35:57] [epoch=102/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.865 (0.865)  Prec@1 67.97 (67.97) Prec@5 97.66 (97.66) Acls-loss 0.752 (0.752) FLOP-Loss 0.000 (0.000) Arch-Loss 0.752 (0.752)
**TRAIN** [2020-01-29 06:36:22] [epoch=102/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.922 (0.881)  Prec@1 66.67 (69.80) Prec@5 100.00 (97.61) Acls-loss 0.739 (0.911) FLOP-Loss 0.000 (0.052) Arch-Loss 0.739 (1.015)
 **TRAIN** Prec@1 69.80 Prec@5 97.61 Error@1 30.20 Error@5 2.39 Base-Loss:0.881, Arch-Loss=1.015
***[2020-01-29 06:36:22]*** TRAIN [epoch=102/600] base-loss = 0.880532, arch-loss = 1.014537, accuracy-1 = 69.80, accuracy-5 = 97.61
[epoch=102/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 9, 8, 14, 16, 12, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.399808)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.393 0.233 0.374  ||  0.0482 -0.4754 0.0003  || discrepancy=0.02 || select=0/3
001/003-th : 0.397 0.177 0.426  ||  0.0075 -0.7996 0.0796  || discrepancy=0.03 || select=2/3
002/003-th : 0.277 0.235 0.487  ||  -0.2576 -0.4213 0.3061  || discrepancy=0.21 || select=2/3
-----------------------------------------------
000/019-th : 0.073 0.090 0.108 0.116 0.139 0.154 0.160 0.160  ||  -0.502 -0.286 -0.101 -0.032 0.149 0.247 0.290 0.288   || dis=0.00 || select=6/8
001/019-th : 0.123 0.122 0.125 0.123 0.126 0.127 0.126 0.127  ||  -0.014 -0.023 0.005 -0.011 0.009 0.020 0.014 0.018    || dis=0.00 || select=5/8
002/019-th : 0.118 0.123 0.128 0.130 0.128 0.126 0.123 0.123  ||  -0.055 -0.008 0.027 0.047 0.031 0.014 -0.008 -0.010   || dis=0.00 || select=3/8
003/019-th : 0.125 0.128 0.128 0.124 0.126 0.123 0.123 0.122  ||  0.002 0.023 0.024 -0.008 0.005 -0.015 -0.017 -0.024   || dis=0.00 || select=2/8
004/019-th : 0.120 0.120 0.125 0.125 0.125 0.128 0.130 0.127  ||  -0.044 -0.038 -0.002 -0.001 0.001 0.023 0.037 0.018   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.120 0.124 0.130 0.128 0.128 0.130  ||  -0.045 -0.035 -0.036 -0.005 0.038 0.029 0.027 0.038   || dis=0.00 || select=7/8
006/019-th : 0.116 0.116 0.121 0.121 0.127 0.133 0.133 0.133  ||  -0.078 -0.074 -0.032 -0.032 0.017 0.062 0.061 0.061   || dis=0.00 || select=5/8
007/019-th : 0.088 0.094 0.106 0.121 0.129 0.144 0.157 0.160  ||  -0.324 -0.257 -0.135 -0.001 0.064 0.167 0.258 0.278   || dis=0.00 || select=7/8
008/019-th : 0.078 0.089 0.102 0.131 0.135 0.156 0.157 0.152  ||  -0.433 -0.291 -0.163 0.093 0.122 0.265 0.268 0.236    || dis=0.00 || select=6/8
009/019-th : 0.110 0.107 0.109 0.118 0.127 0.134 0.145 0.151  ||  -0.126 -0.154 -0.135 -0.054 0.022 0.074 0.152 0.191   || dis=0.01 || select=7/8
010/019-th : 0.109 0.112 0.122 0.125 0.129 0.136 0.133 0.135  ||  -0.133 -0.105 -0.023 0.008 0.041 0.087 0.064 0.081    || dis=0.00 || select=5/8
011/019-th : 0.109 0.106 0.112 0.114 0.124 0.133 0.147 0.154  ||  -0.134 -0.161 -0.107 -0.090 -0.008 0.067 0.166 0.213  || dis=0.01 || select=7/8
012/019-th : 0.115 0.116 0.121 0.127 0.125 0.131 0.131 0.135  ||  -0.084 -0.076 -0.029 0.016 0.004 0.046 0.050 0.077    || dis=0.00 || select=7/8
013/019-th : 0.069 0.075 0.084 0.098 0.121 0.148 0.190 0.214  ||  -0.533 -0.448 -0.337 -0.185 0.024 0.223 0.472 0.594   || dis=0.02 || select=7/8
014/019-th : 0.072 0.080 0.093 0.120 0.133 0.155 0.179 0.169  ||  -0.508 -0.406 -0.251 0.006 0.109 0.263 0.403 0.348    || dis=0.01 || select=6/8
015/019-th : 0.072 0.063 0.088 0.100 0.125 0.154 0.196 0.202  ||  -0.478 -0.613 -0.280 -0.146 0.077 0.281 0.521 0.553   || dis=0.01 || select=7/8
016/019-th : 0.067 0.086 0.101 0.133 0.137 0.155 0.159 0.162  ||  -0.575 -0.332 -0.168 0.109 0.142 0.263 0.286 0.306    || dis=0.00 || select=7/8
017/019-th : 0.119 0.115 0.118 0.124 0.125 0.128 0.135 0.137  ||  -0.048 -0.079 -0.054 -0.007 0.007 0.024 0.079 0.092   || dis=0.00 || select=7/8
018/019-th : 0.084 0.100 0.111 0.120 0.132 0.138 0.151 0.164  ||  -0.370 -0.204 -0.099 -0.017 0.074 0.121 0.212 0.291   || dis=0.01 || select=7/8
[epoch=102/600] FLOP : 27.40 MB, ratio : 0.6713, Expected-ratio : 0.7000, Discrepancy : 0.016
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:36:23] [epoch=102/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.905 (1.905)  Prec@1 37.11 (37.11) Prec@5 78.52 (78.52) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:36:29] [epoch=102/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.739 (2.356)  Prec@1 39.88 (38.82) Prec@5 94.64 (84.36) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.82 Prec@5 84.36 Error@1 61.18 Error@5 15.64 Loss:2.356
***[2020-01-29 06:36:29]*** VALID [epoch=102/600] loss = 2.355615, accuracy@1 = 38.82, accuracy@5 = 84.36 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:36:29]*** start epoch=103/600 Time Left: [04:27:29], LR=[0.092903 ~ 0.092903], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=103, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.65225901902293, FLOP=40.81
[Search] : epoch=103/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:36:29] [epoch=103/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.949 (0.949)  Prec@1 64.84 (64.84) Prec@5 96.88 (96.88) Acls-loss 0.766 (0.766) FLOP-Loss 0.000 (0.000) Arch-Loss 0.766 (0.766)
**TRAIN** [2020-01-29 06:36:53] [epoch=103/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.833 (0.881)  Prec@1 66.07 (69.53) Prec@5 98.81 (97.43) Acls-loss 0.930 (0.896) FLOP-Loss 0.000 (0.000) Arch-Loss 0.930 (0.896)
 **TRAIN** Prec@1 69.53 Prec@5 97.43 Error@1 30.47 Error@5 2.57 Base-Loss:0.881, Arch-Loss=0.896
***[2020-01-29 06:36:54]*** TRAIN [epoch=103/600] base-loss = 0.881035, arch-loss = 0.896073, accuracy-1 = 69.53, accuracy-5 = 97.43
[epoch=103/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 6, 14, 11, 12, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.649664)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.392 0.233 0.375  ||  0.0466 -0.4714 0.0030  || discrepancy=0.02 || select=0/3
001/003-th : 0.394 0.177 0.429  ||  0.0023 -0.7996 0.0868  || discrepancy=0.03 || select=2/3
002/003-th : 0.272 0.233 0.495  ||  -0.2744 -0.4282 0.3235  || discrepancy=0.22 || select=2/3
-----------------------------------------------
000/019-th : 0.072 0.090 0.107 0.116 0.140 0.152 0.161 0.161  ||  -0.504 -0.287 -0.115 -0.034 0.157 0.240 0.296 0.294   || dis=0.00 || select=6/8
001/019-th : 0.123 0.121 0.125 0.124 0.125 0.128 0.127 0.127  ||  -0.017 -0.029 0.003 -0.006 0.005 0.024 0.019 0.020    || dis=0.00 || select=5/8
002/019-th : 0.118 0.123 0.128 0.128 0.129 0.127 0.124 0.124  ||  -0.056 -0.015 0.029 0.029 0.037 0.018 -0.006 -0.006   || dis=0.00 || select=4/8
003/019-th : 0.124 0.128 0.127 0.123 0.127 0.124 0.124 0.123  ||  -0.005 0.020 0.016 -0.018 0.016 -0.005 -0.012 -0.018  || dis=0.00 || select=1/8
004/019-th : 0.119 0.120 0.124 0.124 0.126 0.129 0.130 0.128  ||  -0.046 -0.042 -0.005 -0.006 0.006 0.031 0.037 0.022   || dis=0.00 || select=6/8
005/019-th : 0.118 0.119 0.121 0.124 0.131 0.129 0.128 0.130  ||  -0.054 -0.044 -0.031 -0.003 0.048 0.038 0.029 0.042   || dis=0.00 || select=4/8
006/019-th : 0.115 0.116 0.120 0.122 0.126 0.134 0.134 0.133  ||  -0.084 -0.077 -0.043 -0.022 0.011 0.070 0.068 0.065   || dis=0.00 || select=5/8
007/019-th : 0.088 0.093 0.106 0.120 0.130 0.142 0.158 0.162  ||  -0.323 -0.268 -0.136 -0.011 0.068 0.158 0.263 0.288   || dis=0.00 || select=7/8
008/019-th : 0.077 0.088 0.102 0.131 0.136 0.157 0.157 0.152  ||  -0.441 -0.303 -0.157 0.089 0.131 0.271 0.272 0.239    || dis=0.00 || select=6/8
009/019-th : 0.109 0.107 0.108 0.116 0.127 0.136 0.145 0.152  ||  -0.134 -0.154 -0.141 -0.067 0.021 0.088 0.154 0.199   || dis=0.01 || select=7/8
010/019-th : 0.108 0.112 0.121 0.124 0.130 0.137 0.133 0.135  ||  -0.142 -0.107 -0.024 -0.001 0.045 0.097 0.068 0.085   || dis=0.00 || select=5/8
011/019-th : 0.108 0.106 0.111 0.114 0.126 0.133 0.147 0.155  ||  -0.140 -0.165 -0.114 -0.090 0.009 0.067 0.165 0.221   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.120 0.128 0.125 0.131 0.131 0.136  ||  -0.089 -0.078 -0.043 0.021 -0.000 0.050 0.051 0.085   || dis=0.01 || select=7/8
013/019-th : 0.068 0.075 0.084 0.097 0.121 0.147 0.192 0.216  ||  -0.553 -0.453 -0.336 -0.193 0.030 0.218 0.488 0.608   || dis=0.02 || select=7/8
014/019-th : 0.070 0.079 0.091 0.118 0.135 0.156 0.180 0.171  ||  -0.527 -0.412 -0.268 -0.004 0.124 0.273 0.415 0.362   || dis=0.01 || select=6/8
015/019-th : 0.071 0.061 0.087 0.100 0.125 0.153 0.198 0.205  ||  -0.485 -0.643 -0.286 -0.145 0.082 0.284 0.540 0.573   || dis=0.01 || select=7/8
016/019-th : 0.066 0.085 0.100 0.130 0.138 0.158 0.161 0.163  ||  -0.592 -0.338 -0.178 0.087 0.144 0.281 0.304 0.315    || dis=0.00 || select=7/8
017/019-th : 0.118 0.114 0.119 0.122 0.125 0.129 0.135 0.138  ||  -0.056 -0.087 -0.046 -0.019 0.006 0.038 0.077 0.099   || dis=0.00 || select=7/8
018/019-th : 0.083 0.098 0.110 0.119 0.132 0.138 0.152 0.167  ||  -0.389 -0.217 -0.104 -0.028 0.078 0.119 0.220 0.314   || dis=0.02 || select=7/8
[epoch=103/600] FLOP : 27.65 MB, ratio : 0.6775, Expected-ratio : 0.7000, Discrepancy : 0.017
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:36:54] [epoch=103/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.690 (1.690)  Prec@1 50.39 (50.39) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:37:00] [epoch=103/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.249 (2.276)  Prec@1 29.17 (37.47) Prec@5 76.79 (82.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.47 Prec@5 82.52 Error@1 62.53 Error@5 17.48 Loss:2.276
***[2020-01-29 06:37:00]*** VALID [epoch=103/600] loss = 2.276279, accuracy@1 = 37.47, accuracy@5 = 82.52 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:37:00]*** start epoch=104/600 Time Left: [04:26:52], LR=[0.092768 ~ 0.092768], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=104, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.645642437393241, FLOP=40.81
[Search] : epoch=104/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:37:01] [epoch=104/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.915 (0.915)  Prec@1 70.31 (70.31) Prec@5 96.88 (96.88) Acls-loss 0.905 (0.905) FLOP-Loss 0.000 (0.000) Arch-Loss 0.905 (0.905)
**TRAIN** [2020-01-29 06:37:26] [epoch=104/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 1.196 (0.889)  Prec@1 55.95 (69.32) Prec@5 94.64 (97.33) Acls-loss 0.847 (0.898) FLOP-Loss 0.000 (0.078) Arch-Loss 0.847 (1.054)
 **TRAIN** Prec@1 69.32 Prec@5 97.33 Error@1 30.68 Error@5 2.67 Base-Loss:0.889, Arch-Loss=1.054
***[2020-01-29 06:37:26]*** TRAIN [epoch=104/600] base-loss = 0.888921, arch-loss = 1.053900, accuracy-1 = 69.32, accuracy-5 = 97.33
[epoch=104/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 6, 14, 11, 12, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.649664)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.394 0.235 0.371  ||  0.0554 -0.4598 -0.0050  || discrepancy=0.02 || select=0/3
001/003-th : 0.397 0.174 0.428  ||  0.0089 -0.8150 0.0833  || discrepancy=0.03 || select=2/3
002/003-th : 0.273 0.235 0.492  ||  -0.2694 -0.4185 0.3189  || discrepancy=0.22 || select=2/3
-----------------------------------------------
000/019-th : 0.071 0.090 0.107 0.117 0.141 0.152 0.163 0.160  ||  -0.521 -0.283 -0.114 -0.026 0.163 0.239 0.308 0.290   || dis=0.00 || select=6/8
001/019-th : 0.124 0.122 0.126 0.125 0.124 0.127 0.126 0.127  ||  -0.006 -0.024 0.006 0.001 -0.004 0.014 0.011 0.014    || dis=0.00 || select=5/8
002/019-th : 0.119 0.124 0.129 0.129 0.129 0.125 0.123 0.122  ||  -0.048 -0.004 0.036 0.034 0.039 0.008 -0.015 -0.017   || dis=0.00 || select=4/8
003/019-th : 0.125 0.128 0.128 0.125 0.126 0.124 0.122 0.122  ||  0.003 0.025 0.024 -0.002 0.011 -0.009 -0.023 -0.027   || dis=0.00 || select=1/8
004/019-th : 0.120 0.120 0.125 0.126 0.125 0.128 0.129 0.127  ||  -0.041 -0.038 0.003 0.005 0.002 0.024 0.029 0.017     || dis=0.00 || select=6/8
005/019-th : 0.117 0.119 0.121 0.124 0.131 0.130 0.128 0.130  ||  -0.062 -0.042 -0.025 -0.002 0.049 0.040 0.029 0.044   || dis=0.00 || select=4/8
006/019-th : 0.116 0.116 0.120 0.123 0.126 0.134 0.133 0.133  ||  -0.076 -0.075 -0.038 -0.019 0.012 0.067 0.061 0.059   || dis=0.00 || select=5/8
007/019-th : 0.088 0.094 0.107 0.119 0.132 0.141 0.158 0.161  ||  -0.318 -0.260 -0.131 -0.020 0.080 0.151 0.261 0.279   || dis=0.00 || select=7/8
008/019-th : 0.076 0.089 0.102 0.131 0.138 0.156 0.157 0.151  ||  -0.448 -0.297 -0.159 0.089 0.146 0.269 0.275 0.232    || dis=0.00 || select=6/8
009/019-th : 0.109 0.108 0.110 0.117 0.126 0.134 0.145 0.151  ||  -0.137 -0.143 -0.124 -0.061 0.009 0.077 0.156 0.193   || dis=0.01 || select=7/8
010/019-th : 0.108 0.112 0.122 0.126 0.130 0.135 0.132 0.134  ||  -0.136 -0.105 -0.018 0.017 0.046 0.084 0.061 0.079    || dis=0.00 || select=5/8
011/019-th : 0.108 0.106 0.112 0.114 0.128 0.132 0.147 0.153  ||  -0.137 -0.162 -0.108 -0.086 0.028 0.059 0.165 0.209   || dis=0.01 || select=7/8
012/019-th : 0.114 0.117 0.121 0.126 0.125 0.131 0.131 0.135  ||  -0.087 -0.069 -0.035 0.009 0.001 0.045 0.049 0.081    || dis=0.00 || select=7/8
013/019-th : 0.068 0.075 0.083 0.097 0.119 0.146 0.195 0.217  ||  -0.552 -0.454 -0.344 -0.193 0.015 0.218 0.508 0.611   || dis=0.02 || select=7/8
014/019-th : 0.071 0.079 0.092 0.117 0.137 0.155 0.180 0.170  ||  -0.519 -0.408 -0.262 -0.018 0.138 0.265 0.412 0.358   || dis=0.01 || select=6/8
015/019-th : 0.071 0.061 0.085 0.099 0.125 0.156 0.199 0.204  ||  -0.488 -0.637 -0.306 -0.151 0.084 0.302 0.548 0.572   || dis=0.00 || select=7/8
016/019-th : 0.066 0.085 0.101 0.130 0.137 0.157 0.161 0.163  ||  -0.585 -0.338 -0.168 0.084 0.139 0.272 0.299 0.315    || dis=0.00 || select=7/8
017/019-th : 0.119 0.115 0.120 0.125 0.125 0.128 0.133 0.136  ||  -0.046 -0.081 -0.037 0.000 0.001 0.026 0.068 0.088    || dis=0.00 || select=7/8
018/019-th : 0.084 0.099 0.111 0.120 0.132 0.136 0.150 0.168  ||  -0.372 -0.214 -0.100 -0.019 0.077 0.102 0.203 0.315   || dis=0.02 || select=7/8
[epoch=104/600] FLOP : 27.65 MB, ratio : 0.6775, Expected-ratio : 0.7000, Discrepancy : 0.016
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:37:26] [epoch=104/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 2.717 (2.717)  Prec@1 23.44 (23.44) Prec@5 72.66 (72.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:37:33] [epoch=104/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.117 (2.378)  Prec@1 43.45 (35.93) Prec@5 79.76 (81.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.93 Prec@5 81.14 Error@1 64.07 Error@5 18.86 Loss:2.378
***[2020-01-29 06:37:33]*** VALID [epoch=104/600] loss = 2.378321, accuracy@1 = 35.93, accuracy@5 = 81.14 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:37:33]*** start epoch=105/600 Time Left: [04:26:23], LR=[0.092632 ~ 0.092632], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=105, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.638968402667526, FLOP=40.81
[Search] : epoch=105/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:37:34] [epoch=105/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.793 (0.793)  Prec@1 69.53 (69.53) Prec@5 98.05 (98.05) Acls-loss 0.947 (0.947) FLOP-Loss 0.000 (0.000) Arch-Loss 0.947 (0.947)
**TRAIN** [2020-01-29 06:37:58] [epoch=105/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.919 (0.862)  Prec@1 66.07 (70.24) Prec@5 96.43 (97.49) Acls-loss 0.939 (0.919) FLOP-Loss 0.000 (0.052) Arch-Loss 0.939 (1.023)
 **TRAIN** Prec@1 70.24 Prec@5 97.49 Error@1 29.76 Error@5 2.51 Base-Loss:0.862, Arch-Loss=1.023
***[2020-01-29 06:37:58]*** TRAIN [epoch=105/600] base-loss = 0.861894, arch-loss = 1.022963, accuracy-1 = 70.24, accuracy-5 = 97.49
[epoch=105/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 16, 8, 8, 14, 12, 14, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.24768)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.394 0.237 0.369  ||  0.0585 -0.4515 -0.0071  || discrepancy=0.03 || select=0/3
001/003-th : 0.400 0.171 0.429  ||  0.0121 -0.8373 0.0836  || discrepancy=0.03 || select=2/3
002/003-th : 0.270 0.237 0.493  ||  -0.2767 -0.4050 0.3254  || discrepancy=0.22 || select=2/3
-----------------------------------------------
000/019-th : 0.070 0.090 0.107 0.116 0.141 0.157 0.160 0.159  ||  -0.528 -0.283 -0.107 -0.032 0.168 0.271 0.293 0.287   || dis=0.00 || select=6/8
001/019-th : 0.125 0.122 0.126 0.126 0.123 0.126 0.125 0.126  ||  -0.000 -0.023 0.010 0.010 -0.015 0.008 0.005 0.013    || dis=0.00 || select=7/8
002/019-th : 0.119 0.125 0.130 0.129 0.129 0.125 0.122 0.122  ||  -0.046 0.001 0.040 0.032 0.034 0.006 -0.016 -0.021    || dis=0.00 || select=2/8
003/019-th : 0.126 0.129 0.129 0.124 0.125 0.124 0.122 0.122  ||  0.006 0.029 0.031 -0.006 -0.001 -0.010 -0.026 -0.029  || dis=0.00 || select=2/8
004/019-th : 0.120 0.121 0.125 0.127 0.125 0.127 0.128 0.127  ||  -0.042 -0.034 0.001 0.013 0.001 0.019 0.027 0.017     || dis=0.00 || select=6/8
005/019-th : 0.117 0.119 0.121 0.125 0.129 0.130 0.128 0.130  ||  -0.062 -0.041 -0.026 0.007 0.033 0.045 0.031 0.040    || dis=0.00 || select=5/8
006/019-th : 0.116 0.116 0.119 0.123 0.127 0.133 0.133 0.133  ||  -0.072 -0.071 -0.049 -0.018 0.015 0.061 0.061 0.059   || dis=0.00 || select=6/8
007/019-th : 0.088 0.094 0.107 0.121 0.131 0.140 0.159 0.161  ||  -0.326 -0.253 -0.130 -0.009 0.075 0.143 0.265 0.278   || dis=0.00 || select=7/8
008/019-th : 0.076 0.089 0.101 0.130 0.138 0.156 0.159 0.150  ||  -0.456 -0.294 -0.164 0.087 0.147 0.269 0.286 0.230    || dis=0.00 || select=6/8
009/019-th : 0.108 0.108 0.111 0.118 0.124 0.134 0.145 0.151  ||  -0.139 -0.139 -0.115 -0.058 -0.001 0.071 0.156 0.194  || dis=0.01 || select=7/8
010/019-th : 0.108 0.113 0.122 0.125 0.128 0.137 0.132 0.135  ||  -0.138 -0.093 -0.023 0.007 0.030 0.093 0.058 0.080    || dis=0.00 || select=5/8
011/019-th : 0.108 0.107 0.110 0.115 0.129 0.131 0.147 0.153  ||  -0.136 -0.152 -0.125 -0.077 0.036 0.054 0.165 0.209   || dis=0.01 || select=7/8
012/019-th : 0.114 0.117 0.120 0.126 0.125 0.130 0.131 0.136  ||  -0.088 -0.064 -0.040 0.011 0.003 0.037 0.051 0.081    || dis=0.01 || select=7/8
013/019-th : 0.066 0.072 0.082 0.097 0.121 0.148 0.196 0.217  ||  -0.573 -0.484 -0.353 -0.187 0.037 0.237 0.520 0.621   || dis=0.02 || select=7/8
014/019-th : 0.071 0.078 0.092 0.118 0.135 0.154 0.181 0.171  ||  -0.518 -0.421 -0.254 -0.006 0.126 0.256 0.418 0.361   || dis=0.01 || select=6/8
015/019-th : 0.070 0.060 0.084 0.099 0.126 0.155 0.201 0.205  ||  -0.499 -0.645 -0.311 -0.149 0.094 0.302 0.560 0.578   || dis=0.00 || select=7/8
016/019-th : 0.066 0.085 0.101 0.131 0.137 0.157 0.160 0.163  ||  -0.590 -0.340 -0.170 0.099 0.143 0.277 0.294 0.313    || dis=0.00 || select=7/8
017/019-th : 0.119 0.114 0.121 0.125 0.124 0.129 0.132 0.135  ||  -0.047 -0.087 -0.028 0.009 -0.001 0.040 0.061 0.084   || dis=0.00 || select=7/8
018/019-th : 0.084 0.099 0.110 0.122 0.134 0.133 0.151 0.167  ||  -0.375 -0.211 -0.108 -0.002 0.087 0.080 0.211 0.313   || dis=0.02 || select=7/8
[epoch=105/600] FLOP : 28.25 MB, ratio : 0.6921, Expected-ratio : 0.7000, Discrepancy : 0.016
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:37:58] [epoch=105/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.607 (1.607)  Prec@1 48.83 (48.83) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:38:04] [epoch=105/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.751 (2.155)  Prec@1 38.10 (39.84) Prec@5 86.31 (83.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.84 Prec@5 83.70 Error@1 60.16 Error@5 16.30 Loss:2.155
***[2020-01-29 06:38:05]*** VALID [epoch=105/600] loss = 2.155195, accuracy@1 = 39.84, accuracy@5 = 83.70 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:38:05]*** start epoch=106/600 Time Left: [04:25:48], LR=[0.092495 ~ 0.092495], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=106, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.632237097817817, FLOP=40.81
[Search] : epoch=106/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:38:05] [epoch=106/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.807 (0.807)  Prec@1 73.44 (73.44) Prec@5 96.48 (96.48) Acls-loss 0.948 (0.948) FLOP-Loss 0.000 (0.000) Arch-Loss 0.948 (0.948)
**TRAIN** [2020-01-29 06:38:30] [epoch=106/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.917 (0.868)  Prec@1 67.86 (70.35) Prec@5 95.83 (97.60) Acls-loss 0.827 (0.890) FLOP-Loss 0.000 (0.026) Arch-Loss 0.827 (0.942)
 **TRAIN** Prec@1 70.35 Prec@5 97.60 Error@1 29.65 Error@5 2.40 Base-Loss:0.868, Arch-Loss=0.942
***[2020-01-29 06:38:30]*** TRAIN [epoch=106/600] base-loss = 0.868282, arch-loss = 0.941780, accuracy-1 = 70.35, accuracy-5 = 97.60
[epoch=106/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 8, 8, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.828416)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.394 0.236 0.370  ||  0.0582 -0.4551 -0.0053  || discrepancy=0.02 || select=0/3
001/003-th : 0.399 0.172 0.429  ||  0.0115 -0.8283 0.0858  || discrepancy=0.03 || select=2/3
002/003-th : 0.266 0.237 0.497  ||  -0.2879 -0.4048 0.3368  || discrepancy=0.23 || select=2/3
-----------------------------------------------
000/019-th : 0.070 0.090 0.109 0.116 0.142 0.154 0.160 0.159  ||  -0.531 -0.285 -0.093 -0.025 0.174 0.256 0.292 0.285   || dis=0.00 || select=6/8
001/019-th : 0.124 0.122 0.126 0.127 0.123 0.126 0.125 0.126  ||  -0.005 -0.021 0.013 0.016 -0.015 0.007 0.006 0.013    || dis=0.00 || select=3/8
002/019-th : 0.119 0.125 0.129 0.128 0.129 0.126 0.122 0.122  ||  -0.047 0.000 0.037 0.030 0.033 0.016 -0.017 -0.021    || dis=0.00 || select=2/8
003/019-th : 0.126 0.128 0.129 0.125 0.125 0.123 0.122 0.122  ||  0.007 0.021 0.028 0.002 -0.000 -0.013 -0.023 -0.027   || dis=0.00 || select=2/8
004/019-th : 0.120 0.120 0.124 0.127 0.125 0.127 0.129 0.128  ||  -0.043 -0.037 -0.004 0.012 0.002 0.019 0.031 0.020    || dis=0.00 || select=6/8
005/019-th : 0.117 0.119 0.122 0.125 0.129 0.129 0.128 0.130  ||  -0.063 -0.042 -0.020 0.002 0.035 0.034 0.030 0.044    || dis=0.00 || select=7/8
006/019-th : 0.116 0.116 0.120 0.122 0.126 0.133 0.134 0.133  ||  -0.072 -0.076 -0.044 -0.024 0.010 0.065 0.066 0.058   || dis=0.00 || select=6/8
007/019-th : 0.088 0.093 0.108 0.120 0.131 0.141 0.158 0.162  ||  -0.328 -0.264 -0.121 -0.014 0.072 0.145 0.264 0.284   || dis=0.00 || select=7/8
008/019-th : 0.074 0.088 0.100 0.130 0.139 0.158 0.160 0.152  ||  -0.470 -0.305 -0.175 0.087 0.152 0.281 0.295 0.241    || dis=0.00 || select=6/8
009/019-th : 0.108 0.109 0.111 0.117 0.125 0.133 0.145 0.151  ||  -0.138 -0.137 -0.119 -0.058 0.003 0.069 0.155 0.195   || dis=0.01 || select=7/8
010/019-th : 0.108 0.113 0.121 0.126 0.128 0.137 0.132 0.135  ||  -0.143 -0.093 -0.031 0.013 0.031 0.096 0.063 0.080    || dis=0.00 || select=5/8
011/019-th : 0.109 0.105 0.108 0.116 0.131 0.129 0.148 0.153  ||  -0.134 -0.166 -0.136 -0.067 0.055 0.039 0.176 0.212   || dis=0.01 || select=7/8
012/019-th : 0.114 0.117 0.120 0.125 0.125 0.131 0.131 0.135  ||  -0.089 -0.067 -0.038 0.004 0.005 0.049 0.050 0.081    || dis=0.00 || select=7/8
013/019-th : 0.066 0.072 0.081 0.096 0.121 0.148 0.198 0.219  ||  -0.573 -0.485 -0.359 -0.194 0.033 0.236 0.530 0.628   || dis=0.02 || select=7/8
014/019-th : 0.071 0.078 0.093 0.118 0.134 0.154 0.181 0.172  ||  -0.521 -0.427 -0.250 -0.012 0.117 0.260 0.418 0.370   || dis=0.01 || select=6/8
015/019-th : 0.069 0.060 0.082 0.097 0.128 0.156 0.202 0.208  ||  -0.503 -0.649 -0.335 -0.168 0.113 0.308 0.568 0.596   || dis=0.01 || select=7/8
016/019-th : 0.066 0.084 0.101 0.130 0.136 0.159 0.162 0.163  ||  -0.593 -0.353 -0.169 0.086 0.137 0.292 0.307 0.315    || dis=0.00 || select=7/8
017/019-th : 0.118 0.114 0.121 0.125 0.124 0.130 0.132 0.135  ||  -0.049 -0.088 -0.026 0.006 -0.006 0.044 0.062 0.085   || dis=0.00 || select=7/8
018/019-th : 0.084 0.100 0.111 0.122 0.129 0.134 0.152 0.168  ||  -0.378 -0.205 -0.099 -0.005 0.055 0.092 0.218 0.314   || dis=0.02 || select=7/8
[epoch=106/600] FLOP : 26.83 MB, ratio : 0.6573, Expected-ratio : 0.7000, Discrepancy : 0.017
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:38:30] [epoch=106/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.991 (1.991)  Prec@1 42.19 (42.19) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:38:36] [epoch=106/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.473 (2.048)  Prec@1 43.45 (39.90) Prec@5 90.48 (84.29) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.90 Prec@5 84.29 Error@1 60.10 Error@5 15.71 Loss:2.048
***[2020-01-29 06:38:36]*** VALID [epoch=106/600] loss = 2.047898, accuracy@1 = 39.90, accuracy@5 = 84.29 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:38:36]*** start epoch=107/600 Time Left: [04:25:12], LR=[0.092356 ~ 0.092356], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=107, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.625448707386236, FLOP=40.81
[Search] : epoch=107/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:38:37] [epoch=107/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.626 (0.626)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44) Acls-loss 0.816 (0.816) FLOP-Loss 0.000 (0.000) Arch-Loss 0.816 (0.816)
**TRAIN** [2020-01-29 06:39:01] [epoch=107/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.796 (0.868)  Prec@1 77.38 (70.33) Prec@5 97.62 (97.61) Acls-loss 0.991 (0.900) FLOP-Loss 0.000 (0.026) Arch-Loss 0.991 (0.952)
 **TRAIN** Prec@1 70.33 Prec@5 97.61 Error@1 29.67 Error@5 2.39 Base-Loss:0.868, Arch-Loss=0.952
***[2020-01-29 06:39:01]*** TRAIN [epoch=107/600] base-loss = 0.867545, arch-loss = 0.952286, accuracy-1 = 70.33, accuracy-5 = 97.61
[epoch=107/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 16, 11, 8, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 29.105792)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.395 0.233 0.372  ||  0.0582 -0.4691 -0.0031  || discrepancy=0.02 || select=0/3
001/003-th : 0.397 0.173 0.429  ||  0.0108 -0.8192 0.0880  || discrepancy=0.03 || select=2/3
002/003-th : 0.264 0.236 0.500  ||  -0.2950 -0.4083 0.3447  || discrepancy=0.24 || select=2/3
-----------------------------------------------
000/019-th : 0.071 0.090 0.107 0.118 0.140 0.154 0.159 0.160  ||  -0.517 -0.287 -0.108 -0.011 0.159 0.250 0.282 0.290   || dis=0.00 || select=7/8
001/019-th : 0.124 0.123 0.126 0.126 0.123 0.126 0.126 0.126  ||  -0.006 -0.019 0.012 0.011 -0.018 0.011 0.006 0.013    || dis=0.00 || select=7/8
002/019-th : 0.118 0.124 0.129 0.128 0.129 0.126 0.122 0.122  ||  -0.049 0.000 0.038 0.032 0.041 0.016 -0.017 -0.022    || dis=0.00 || select=4/8
003/019-th : 0.126 0.128 0.128 0.125 0.125 0.124 0.122 0.122  ||  0.008 0.020 0.023 -0.004 0.003 -0.011 -0.022 -0.026   || dis=0.00 || select=2/8
004/019-th : 0.119 0.120 0.124 0.128 0.125 0.128 0.129 0.127  ||  -0.049 -0.036 -0.003 0.027 0.005 0.024 0.032 0.017    || dis=0.00 || select=6/8
005/019-th : 0.117 0.119 0.121 0.125 0.130 0.130 0.129 0.130  ||  -0.066 -0.043 -0.028 0.001 0.040 0.042 0.032 0.045    || dis=0.00 || select=7/8
006/019-th : 0.116 0.115 0.119 0.123 0.127 0.132 0.134 0.133  ||  -0.074 -0.081 -0.047 -0.014 0.016 0.058 0.072 0.060   || dis=0.00 || select=6/8
007/019-th : 0.087 0.092 0.106 0.119 0.132 0.140 0.159 0.164  ||  -0.332 -0.279 -0.132 -0.017 0.087 0.138 0.272 0.298   || dis=0.01 || select=7/8
008/019-th : 0.074 0.087 0.101 0.129 0.140 0.157 0.159 0.154  ||  -0.475 -0.313 -0.169 0.078 0.163 0.273 0.288 0.254    || dis=0.00 || select=6/8
009/019-th : 0.109 0.108 0.111 0.117 0.125 0.134 0.146 0.152  ||  -0.138 -0.143 -0.119 -0.063 0.004 0.070 0.156 0.199   || dis=0.01 || select=7/8
010/019-th : 0.107 0.113 0.120 0.125 0.130 0.137 0.132 0.136  ||  -0.147 -0.096 -0.033 0.005 0.044 0.094 0.063 0.086    || dis=0.00 || select=5/8
011/019-th : 0.108 0.104 0.107 0.117 0.131 0.129 0.149 0.155  ||  -0.140 -0.179 -0.144 -0.057 0.054 0.036 0.185 0.222   || dis=0.01 || select=7/8
012/019-th : 0.114 0.117 0.120 0.126 0.126 0.131 0.131 0.135  ||  -0.092 -0.066 -0.035 0.015 0.013 0.048 0.050 0.078    || dis=0.00 || select=7/8
013/019-th : 0.065 0.071 0.081 0.095 0.121 0.147 0.199 0.220  ||  -0.578 -0.495 -0.358 -0.203 0.041 0.237 0.535 0.639   || dis=0.02 || select=7/8
014/019-th : 0.070 0.075 0.093 0.117 0.133 0.155 0.183 0.174  ||  -0.523 -0.456 -0.246 -0.012 0.114 0.263 0.430 0.380   || dis=0.01 || select=6/8
015/019-th : 0.068 0.059 0.082 0.095 0.128 0.153 0.203 0.211  ||  -0.512 -0.657 -0.332 -0.180 0.119 0.296 0.580 0.614   || dis=0.01 || select=7/8
016/019-th : 0.066 0.082 0.101 0.130 0.136 0.160 0.162 0.164  ||  -0.593 -0.367 -0.165 0.086 0.131 0.299 0.309 0.320    || dis=0.00 || select=7/8
017/019-th : 0.118 0.113 0.122 0.125 0.123 0.130 0.133 0.136  ||  -0.050 -0.095 -0.023 0.008 -0.013 0.043 0.064 0.088   || dis=0.00 || select=7/8
018/019-th : 0.084 0.100 0.110 0.122 0.130 0.136 0.153 0.166  ||  -0.382 -0.198 -0.108 -0.004 0.058 0.102 0.221 0.307   || dis=0.01 || select=7/8
[epoch=107/600] FLOP : 29.11 MB, ratio : 0.7131, Expected-ratio : 0.7000, Discrepancy : 0.017
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:39:02] [epoch=107/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.726 (1.726)  Prec@1 41.02 (41.02) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:39:08] [epoch=107/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.734 (2.288)  Prec@1 51.79 (38.19) Prec@5 90.48 (82.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.19 Prec@5 82.99 Error@1 61.81 Error@5 17.01 Loss:2.288
***[2020-01-29 06:39:08]*** VALID [epoch=107/600] loss = 2.288376, accuracy@1 = 38.19, accuracy@5 = 82.99 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:39:08]*** start epoch=108/600 Time Left: [04:24:38], LR=[0.092216 ~ 0.092216], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=108, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.618603417479937, FLOP=40.81
[Search] : epoch=108/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:39:09] [epoch=108/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.750 (0.750)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83) Acls-loss 0.834 (0.834) FLOP-Loss 2.543 (2.543) Arch-Loss 5.920 (5.920)
**TRAIN** [2020-01-29 06:39:33] [epoch=108/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.831 (0.861)  Prec@1 69.64 (70.52) Prec@5 99.40 (97.63) Acls-loss 1.083 (0.897) FLOP-Loss 0.000 (0.026) Arch-Loss 1.083 (0.949)
 **TRAIN** Prec@1 70.52 Prec@5 97.63 Error@1 29.48 Error@5 2.37 Base-Loss:0.861, Arch-Loss=0.949
***[2020-01-29 06:39:33]*** TRAIN [epoch=108/600] base-loss = 0.860795, arch-loss = 0.948808, accuracy-1 = 70.52, accuracy-5 = 97.63
[epoch=108/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 11, 6, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 57, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.110464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.395 0.232 0.372  ||  0.0587 -0.4731 -0.0018  || discrepancy=0.02 || select=0/3
001/003-th : 0.397 0.172 0.430  ||  0.0106 -0.8241 0.0908  || discrepancy=0.03 || select=2/3
002/003-th : 0.261 0.235 0.504  ||  -0.3048 -0.4085 0.3548  || discrepancy=0.24 || select=2/3
-----------------------------------------------
000/019-th : 0.071 0.090 0.107 0.118 0.141 0.152 0.159 0.162  ||  -0.520 -0.288 -0.115 -0.011 0.165 0.239 0.281 0.299   || dis=0.00 || select=7/8
001/019-th : 0.124 0.122 0.126 0.126 0.123 0.127 0.126 0.126  ||  -0.006 -0.021 0.010 0.009 -0.014 0.017 0.006 0.012    || dis=0.00 || select=5/8
002/019-th : 0.118 0.124 0.129 0.129 0.130 0.127 0.122 0.122  ||  -0.049 -0.003 0.035 0.033 0.041 0.017 -0.018 -0.020   || dis=0.00 || select=4/8
003/019-th : 0.126 0.128 0.127 0.126 0.125 0.124 0.122 0.122  ||  0.008 0.021 0.018 0.005 -0.001 -0.005 -0.022 -0.027   || dis=0.00 || select=1/8
004/019-th : 0.118 0.120 0.125 0.127 0.126 0.128 0.128 0.127  ||  -0.053 -0.036 -0.001 0.019 0.009 0.027 0.030 0.021    || dis=0.00 || select=6/8
005/019-th : 0.117 0.119 0.122 0.124 0.129 0.130 0.129 0.131  ||  -0.065 -0.043 -0.026 -0.009 0.033 0.040 0.032 0.048   || dis=0.00 || select=7/8
006/019-th : 0.116 0.115 0.119 0.124 0.127 0.132 0.136 0.133  ||  -0.078 -0.085 -0.050 -0.011 0.015 0.051 0.081 0.064   || dis=0.00 || select=6/8
007/019-th : 0.087 0.091 0.107 0.120 0.131 0.140 0.160 0.164  ||  -0.335 -0.289 -0.125 -0.015 0.075 0.140 0.277 0.302   || dis=0.00 || select=7/8
008/019-th : 0.073 0.087 0.101 0.129 0.141 0.156 0.159 0.155  ||  -0.494 -0.312 -0.168 0.082 0.170 0.270 0.289 0.263    || dis=0.00 || select=6/8
009/019-th : 0.109 0.108 0.110 0.118 0.125 0.134 0.145 0.153  ||  -0.138 -0.143 -0.127 -0.058 0.000 0.072 0.149 0.207   || dis=0.01 || select=7/8
010/019-th : 0.108 0.113 0.122 0.124 0.129 0.136 0.132 0.136  ||  -0.145 -0.097 -0.022 -0.000 0.035 0.092 0.060 0.088   || dis=0.00 || select=5/8
011/019-th : 0.108 0.104 0.106 0.119 0.131 0.127 0.151 0.155  ||  -0.140 -0.178 -0.157 -0.044 0.053 0.025 0.196 0.223   || dis=0.00 || select=7/8
012/019-th : 0.114 0.117 0.119 0.126 0.126 0.130 0.132 0.136  ||  -0.095 -0.061 -0.048 0.006 0.011 0.040 0.054 0.086    || dis=0.00 || select=7/8
013/019-th : 0.065 0.070 0.081 0.096 0.122 0.149 0.196 0.222  ||  -0.581 -0.508 -0.364 -0.190 0.047 0.248 0.522 0.648   || dis=0.03 || select=7/8
014/019-th : 0.070 0.075 0.091 0.118 0.133 0.155 0.182 0.176  ||  -0.529 -0.461 -0.260 -0.004 0.114 0.269 0.427 0.394   || dis=0.01 || select=6/8
015/019-th : 0.067 0.059 0.082 0.096 0.128 0.154 0.204 0.211  ||  -0.534 -0.661 -0.323 -0.170 0.115 0.304 0.584 0.617   || dis=0.01 || select=7/8
016/019-th : 0.065 0.081 0.101 0.128 0.136 0.162 0.163 0.164  ||  -0.595 -0.376 -0.165 0.074 0.136 0.311 0.314 0.321    || dis=0.00 || select=7/8
017/019-th : 0.118 0.113 0.120 0.126 0.125 0.129 0.134 0.135  ||  -0.050 -0.096 -0.037 0.010 0.002 0.039 0.073 0.086    || dis=0.00 || select=7/8
018/019-th : 0.083 0.101 0.109 0.121 0.130 0.134 0.153 0.169  ||  -0.386 -0.197 -0.117 -0.009 0.063 0.090 0.221 0.322   || dis=0.02 || select=7/8
[epoch=108/600] FLOP : 28.11 MB, ratio : 0.6888, Expected-ratio : 0.7000, Discrepancy : 0.018
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:39:33] [epoch=108/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 1.539 (1.539)  Prec@1 49.22 (49.22) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:39:39] [epoch=108/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.251 (2.307)  Prec@1 57.14 (38.20) Prec@5 96.43 (83.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.20 Prec@5 83.06 Error@1 61.80 Error@5 16.94 Loss:2.307
***[2020-01-29 06:39:39]*** VALID [epoch=108/600] loss = 2.306652, accuracy@1 = 38.20, accuracy@5 = 83.06 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:39:39]*** start epoch=109/600 Time Left: [04:24:01], LR=[0.092076 ~ 0.092076], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=109, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.611701415766, FLOP=40.81
[Search] : epoch=109/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:39:40] [epoch=109/600][000/098] Time 0.77 (0.77) Data 0.35 (0.35) Base-Loss 0.821 (0.821)  Prec@1 69.14 (69.14) Prec@5 98.44 (98.44) Acls-loss 0.875 (0.875) FLOP-Loss 0.000 (0.000) Arch-Loss 0.875 (0.875)
**TRAIN** [2020-01-29 06:40:04] [epoch=109/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.805 (0.858)  Prec@1 73.81 (70.38) Prec@5 96.43 (97.51) Acls-loss 0.977 (0.892) FLOP-Loss 0.000 (0.052) Arch-Loss 0.977 (0.996)
 **TRAIN** Prec@1 70.38 Prec@5 97.51 Error@1 29.62 Error@5 2.49 Base-Loss:0.858, Arch-Loss=0.996
***[2020-01-29 06:40:05]*** TRAIN [epoch=109/600] base-loss = 0.858057, arch-loss = 0.996040, accuracy-1 = 70.38, accuracy-5 = 97.51
[epoch=109/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 6, 12, 16, 14, 32, 28, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.427456)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.398 0.230 0.372  ||  0.0634 -0.4832 -0.0043  || discrepancy=0.03 || select=0/3
001/003-th : 0.398 0.172 0.430  ||  0.0138 -0.8235 0.0900  || discrepancy=0.03 || select=2/3
002/003-th : 0.259 0.236 0.506  ||  -0.3097 -0.4032 0.3599  || discrepancy=0.25 || select=2/3
-----------------------------------------------
000/019-th : 0.071 0.089 0.108 0.118 0.142 0.151 0.159 0.163  ||  -0.523 -0.301 -0.106 -0.015 0.170 0.231 0.284 0.307   || dis=0.00 || select=7/8
001/019-th : 0.125 0.123 0.126 0.127 0.123 0.126 0.125 0.126  ||  -0.002 -0.015 0.011 0.017 -0.014 0.013 0.001 0.007    || dis=0.00 || select=3/8
002/019-th : 0.119 0.124 0.130 0.129 0.128 0.126 0.122 0.122  ||  -0.045 -0.002 0.040 0.039 0.031 0.012 -0.021 -0.024   || dis=0.00 || select=2/8
003/019-th : 0.127 0.128 0.128 0.126 0.124 0.124 0.122 0.121  ||  0.015 0.025 0.022 0.007 -0.011 -0.012 -0.025 -0.032   || dis=0.00 || select=1/8
004/019-th : 0.119 0.121 0.125 0.128 0.125 0.128 0.128 0.127  ||  -0.048 -0.032 0.000 0.022 0.002 0.025 0.024 0.019     || dis=0.00 || select=5/8
005/019-th : 0.118 0.119 0.121 0.125 0.129 0.130 0.128 0.130  ||  -0.058 -0.044 -0.034 0.002 0.033 0.041 0.028 0.043    || dis=0.00 || select=7/8
006/019-th : 0.116 0.115 0.119 0.125 0.127 0.132 0.135 0.133  ||  -0.078 -0.083 -0.050 -0.001 0.017 0.053 0.077 0.061   || dis=0.00 || select=6/8
007/019-th : 0.088 0.091 0.107 0.121 0.129 0.141 0.159 0.165  ||  -0.329 -0.290 -0.124 -0.009 0.056 0.147 0.266 0.305   || dis=0.01 || select=7/8
008/019-th : 0.072 0.087 0.102 0.130 0.143 0.154 0.157 0.155  ||  -0.497 -0.311 -0.159 0.087 0.182 0.259 0.278 0.264    || dis=0.00 || select=6/8
009/019-th : 0.109 0.108 0.108 0.117 0.126 0.134 0.145 0.154  ||  -0.131 -0.147 -0.145 -0.063 0.011 0.074 0.149 0.210   || dis=0.01 || select=7/8
010/019-th : 0.108 0.114 0.123 0.125 0.128 0.134 0.133 0.135  ||  -0.144 -0.091 -0.012 0.000 0.031 0.073 0.069 0.083    || dis=0.00 || select=7/8
011/019-th : 0.108 0.104 0.105 0.120 0.131 0.127 0.151 0.154  ||  -0.138 -0.176 -0.164 -0.036 0.055 0.027 0.194 0.220   || dis=0.00 || select=7/8
012/019-th : 0.114 0.117 0.119 0.124 0.127 0.131 0.132 0.136  ||  -0.094 -0.062 -0.045 -0.008 0.020 0.044 0.053 0.085   || dis=0.00 || select=7/8
013/019-th : 0.065 0.069 0.081 0.097 0.121 0.149 0.194 0.225  ||  -0.573 -0.522 -0.366 -0.182 0.040 0.247 0.512 0.661   || dis=0.03 || select=7/8
014/019-th : 0.070 0.075 0.091 0.117 0.132 0.157 0.181 0.176  ||  -0.528 -0.455 -0.265 -0.014 0.109 0.278 0.425 0.395   || dis=0.01 || select=6/8
015/019-th : 0.066 0.059 0.081 0.096 0.127 0.155 0.204 0.212  ||  -0.545 -0.659 -0.332 -0.164 0.110 0.311 0.587 0.625   || dis=0.01 || select=7/8
016/019-th : 0.066 0.081 0.102 0.129 0.136 0.161 0.163 0.162  ||  -0.592 -0.378 -0.153 0.080 0.137 0.302 0.318 0.311    || dis=0.00 || select=6/8
017/019-th : 0.119 0.113 0.121 0.126 0.124 0.129 0.133 0.135  ||  -0.044 -0.097 -0.027 0.017 -0.004 0.033 0.065 0.083   || dis=0.00 || select=7/8
018/019-th : 0.083 0.100 0.109 0.122 0.130 0.133 0.154 0.169  ||  -0.387 -0.203 -0.113 -0.001 0.060 0.085 0.228 0.321   || dis=0.02 || select=7/8
[epoch=109/600] FLOP : 27.43 MB, ratio : 0.6720, Expected-ratio : 0.7000, Discrepancy : 0.018
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:40:05] [epoch=109/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.930 (1.930)  Prec@1 48.05 (48.05) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:40:11] [epoch=109/600][097/098] Time 0.12 (0.06) Data 0.00 (0.00) Loss 1.699 (2.244)  Prec@1 45.24 (37.97) Prec@5 90.48 (82.69) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.97 Prec@5 82.69 Error@1 62.03 Error@5 17.31 Loss:2.244
***[2020-01-29 06:40:11]*** VALID [epoch=109/600] loss = 2.243734, accuracy@1 = 37.97, accuracy@5 = 82.69 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:40:11]*** start epoch=110/600 Time Left: [04:23:26], LR=[0.091934 ~ 0.091934], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=110, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.604742891466289, FLOP=40.81
[Search] : epoch=110/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:40:11] [epoch=110/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.862 (0.862)  Prec@1 69.14 (69.14) Prec@5 98.83 (98.83) Acls-loss 0.981 (0.981) FLOP-Loss 0.000 (0.000) Arch-Loss 0.981 (0.981)
**TRAIN** [2020-01-29 06:40:36] [epoch=110/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.045 (0.871)  Prec@1 63.10 (70.37) Prec@5 95.24 (97.50) Acls-loss 0.888 (0.899) FLOP-Loss 0.000 (0.000) Arch-Loss 0.888 (0.899)
 **TRAIN** Prec@1 70.37 Prec@5 97.50 Error@1 29.63 Error@5 2.50 Base-Loss:0.871, Arch-Loss=0.899
***[2020-01-29 06:40:36]*** TRAIN [epoch=110/600] base-loss = 0.871202, arch-loss = 0.898641, accuracy-1 = 70.37, accuracy-5 = 97.50
[epoch=110/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 8, 12, 12, 14, 32, 28, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.72544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.398 0.225 0.377  ||  0.0582 -0.5093 0.0043  || discrepancy=0.02 || select=0/3
001/003-th : 0.396 0.171 0.434  ||  0.0076 -0.8319 0.0992  || discrepancy=0.04 || select=2/3
002/003-th : 0.255 0.235 0.510  ||  -0.3217 -0.4043 0.3723  || discrepancy=0.26 || select=2/3
-----------------------------------------------
000/019-th : 0.070 0.089 0.108 0.117 0.142 0.150 0.161 0.163  ||  -0.542 -0.299 -0.104 -0.019 0.169 0.230 0.298 0.311   || dis=0.00 || select=7/8
001/019-th : 0.123 0.122 0.125 0.128 0.124 0.127 0.126 0.126  ||  -0.011 -0.020 0.005 0.028 -0.004 0.017 0.009 0.009    || dis=0.00 || select=3/8
002/019-th : 0.118 0.124 0.129 0.129 0.130 0.127 0.122 0.122  ||  -0.048 -0.006 0.034 0.038 0.042 0.018 -0.018 -0.021   || dis=0.00 || select=4/8
003/019-th : 0.126 0.127 0.128 0.126 0.124 0.124 0.123 0.122  ||  0.010 0.017 0.020 0.007 -0.007 -0.007 -0.018 -0.027   || dis=0.00 || select=2/8
004/019-th : 0.118 0.120 0.123 0.128 0.126 0.129 0.128 0.128  ||  -0.057 -0.039 -0.011 0.023 0.009 0.030 0.028 0.028    || dis=0.00 || select=5/8
005/019-th : 0.117 0.118 0.121 0.124 0.128 0.131 0.130 0.131  ||  -0.061 -0.059 -0.034 -0.006 0.028 0.052 0.041 0.048   || dis=0.00 || select=5/8
006/019-th : 0.115 0.115 0.117 0.124 0.129 0.132 0.136 0.133  ||  -0.084 -0.085 -0.061 -0.007 0.030 0.056 0.084 0.065   || dis=0.00 || select=6/8
007/019-th : 0.086 0.090 0.107 0.121 0.128 0.142 0.160 0.166  ||  -0.343 -0.302 -0.124 -0.003 0.056 0.157 0.273 0.313   || dis=0.01 || select=7/8
008/019-th : 0.073 0.087 0.102 0.129 0.142 0.156 0.157 0.155  ||  -0.494 -0.314 -0.153 0.077 0.172 0.268 0.276 0.264    || dis=0.00 || select=6/8
009/019-th : 0.108 0.106 0.107 0.116 0.126 0.135 0.146 0.155  ||  -0.141 -0.158 -0.149 -0.070 0.012 0.084 0.163 0.218   || dis=0.01 || select=7/8
010/019-th : 0.107 0.112 0.122 0.126 0.129 0.136 0.133 0.136  ||  -0.154 -0.105 -0.022 0.011 0.035 0.087 0.069 0.092    || dis=0.00 || select=7/8
011/019-th : 0.107 0.104 0.105 0.118 0.131 0.129 0.151 0.155  ||  -0.147 -0.175 -0.161 -0.045 0.058 0.040 0.195 0.222   || dis=0.00 || select=7/8
012/019-th : 0.113 0.117 0.118 0.122 0.127 0.132 0.133 0.138  ||  -0.103 -0.068 -0.057 -0.023 0.020 0.052 0.064 0.097   || dis=0.01 || select=7/8
013/019-th : 0.065 0.068 0.080 0.096 0.121 0.150 0.195 0.225  ||  -0.578 -0.530 -0.368 -0.191 0.045 0.260 0.521 0.663   || dis=0.03 || select=7/8
014/019-th : 0.069 0.074 0.089 0.115 0.131 0.159 0.184 0.178  ||  -0.539 -0.469 -0.282 -0.025 0.105 0.296 0.441 0.412   || dis=0.01 || select=6/8
015/019-th : 0.064 0.059 0.081 0.097 0.123 0.156 0.207 0.212  ||  -0.576 -0.649 -0.333 -0.154 0.085 0.321 0.605 0.629   || dis=0.01 || select=7/8
016/019-th : 0.065 0.080 0.101 0.130 0.134 0.159 0.166 0.164  ||  -0.601 -0.390 -0.160 0.089 0.124 0.295 0.333 0.324    || dis=0.00 || select=6/8
017/019-th : 0.117 0.113 0.122 0.124 0.124 0.131 0.134 0.136  ||  -0.058 -0.099 -0.023 -0.003 0.001 0.049 0.071 0.088   || dis=0.00 || select=7/8
018/019-th : 0.082 0.100 0.110 0.124 0.128 0.133 0.155 0.168  ||  -0.397 -0.201 -0.104 0.014 0.043 0.081 0.236 0.319    || dis=0.01 || select=7/8
[epoch=110/600] FLOP : 27.73 MB, ratio : 0.6793, Expected-ratio : 0.7000, Discrepancy : 0.018
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:40:36] [epoch=110/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.340 (2.340)  Prec@1 35.16 (35.16) Prec@5 76.17 (76.17) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:40:42] [epoch=110/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 4.204 (2.439)  Prec@1 23.21 (37.86) Prec@5 60.71 (83.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.86 Prec@5 83.40 Error@1 62.14 Error@5 16.60 Loss:2.439
***[2020-01-29 06:40:42]*** VALID [epoch=110/600] loss = 2.438808, accuracy@1 = 37.86, accuracy@5 = 83.40 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:40:42]*** start epoch=111/600 Time Left: [04:22:49], LR=[0.091790 ~ 0.091790], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=111, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.5977280353522625, FLOP=40.81
[Search] : epoch=111/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:40:43] [epoch=111/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.991 (0.991)  Prec@1 65.23 (65.23) Prec@5 96.09 (96.09) Acls-loss 0.845 (0.845) FLOP-Loss 0.000 (0.000) Arch-Loss 0.845 (0.845)
**TRAIN** [2020-01-29 06:41:07] [epoch=111/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.749 (0.865)  Prec@1 71.43 (70.19) Prec@5 98.21 (97.60) Acls-loss 0.835 (0.885) FLOP-Loss 0.000 (0.000) Arch-Loss 0.835 (0.885)
 **TRAIN** Prec@1 70.19 Prec@5 97.60 Error@1 29.81 Error@5 2.40 Base-Loss:0.865, Arch-Loss=0.885
***[2020-01-29 06:41:07]*** TRAIN [epoch=111/600] base-loss = 0.865390, arch-loss = 0.885484, accuracy-1 = 70.19, accuracy-5 = 97.60
[epoch=111/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 6, 12, 12, 14, 32, 28, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.72544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.395 0.227 0.378  ||  0.0530 -0.4997 0.0106  || discrepancy=0.02 || select=0/3
001/003-th : 0.393 0.170 0.437  ||  0.0023 -0.8363 0.1073  || discrepancy=0.04 || select=2/3
002/003-th : 0.250 0.235 0.514  ||  -0.3346 -0.3967 0.3846  || discrepancy=0.26 || select=2/3
-----------------------------------------------
000/019-th : 0.070 0.088 0.108 0.117 0.142 0.149 0.163 0.163  ||  -0.542 -0.304 -0.101 -0.022 0.168 0.219 0.309 0.312   || dis=0.00 || select=7/8
001/019-th : 0.123 0.122 0.125 0.127 0.125 0.127 0.126 0.126  ||  -0.014 -0.021 0.001 0.023 -0.000 0.018 0.011 0.012    || dis=0.00 || select=3/8
002/019-th : 0.118 0.124 0.128 0.128 0.130 0.127 0.123 0.122  ||  -0.053 -0.004 0.031 0.028 0.040 0.022 -0.015 -0.018   || dis=0.00 || select=4/8
003/019-th : 0.126 0.127 0.126 0.126 0.125 0.124 0.124 0.123  ||  0.005 0.012 0.005 0.007 -0.005 -0.006 -0.010 -0.020   || dis=0.00 || select=1/8
004/019-th : 0.118 0.119 0.122 0.125 0.128 0.131 0.129 0.129  ||  -0.059 -0.045 -0.026 0.001 0.022 0.046 0.035 0.032    || dis=0.00 || select=5/8
005/019-th : 0.117 0.117 0.120 0.124 0.129 0.132 0.131 0.131  ||  -0.065 -0.065 -0.037 -0.009 0.032 0.056 0.047 0.051   || dis=0.00 || select=5/8
006/019-th : 0.114 0.114 0.116 0.125 0.129 0.133 0.136 0.134  ||  -0.094 -0.092 -0.073 0.002 0.031 0.066 0.087 0.074    || dis=0.00 || select=6/8
007/019-th : 0.085 0.089 0.105 0.122 0.129 0.144 0.161 0.166  ||  -0.356 -0.309 -0.141 0.008 0.062 0.173 0.285 0.316    || dis=0.01 || select=7/8
008/019-th : 0.072 0.085 0.102 0.131 0.139 0.157 0.158 0.156  ||  -0.502 -0.332 -0.156 0.094 0.154 0.278 0.287 0.271    || dis=0.00 || select=6/8
009/019-th : 0.108 0.105 0.105 0.115 0.127 0.136 0.147 0.156  ||  -0.144 -0.167 -0.167 -0.075 0.023 0.093 0.170 0.227   || dis=0.01 || select=7/8
010/019-th : 0.106 0.111 0.121 0.125 0.129 0.137 0.134 0.137  ||  -0.159 -0.109 -0.030 0.008 0.034 0.093 0.076 0.097    || dis=0.00 || select=7/8
011/019-th : 0.105 0.103 0.106 0.119 0.131 0.130 0.151 0.156  ||  -0.163 -0.187 -0.157 -0.040 0.059 0.053 0.198 0.231   || dis=0.01 || select=7/8
012/019-th : 0.112 0.115 0.119 0.120 0.130 0.133 0.134 0.138  ||  -0.110 -0.078 -0.051 -0.040 0.037 0.064 0.067 0.102   || dis=0.00 || select=7/8
013/019-th : 0.064 0.066 0.079 0.094 0.118 0.153 0.198 0.227  ||  -0.585 -0.549 -0.378 -0.198 0.027 0.285 0.540 0.680   || dis=0.03 || select=7/8
014/019-th : 0.068 0.073 0.089 0.114 0.129 0.159 0.185 0.182  ||  -0.549 -0.474 -0.286 -0.032 0.091 0.296 0.449 0.431   || dis=0.00 || select=6/8
015/019-th : 0.063 0.059 0.081 0.097 0.123 0.153 0.212 0.214  ||  -0.587 -0.651 -0.336 -0.156 0.090 0.301 0.629 0.638   || dis=0.00 || select=7/8
016/019-th : 0.065 0.080 0.100 0.128 0.135 0.159 0.169 0.165  ||  -0.602 -0.399 -0.171 0.076 0.126 0.291 0.353 0.331    || dis=0.00 || select=6/8
017/019-th : 0.116 0.112 0.121 0.124 0.126 0.130 0.134 0.136  ||  -0.070 -0.101 -0.027 -0.004 0.016 0.046 0.079 0.092   || dis=0.00 || select=7/8
018/019-th : 0.083 0.099 0.110 0.123 0.129 0.134 0.154 0.168  ||  -0.393 -0.210 -0.108 0.009 0.056 0.090 0.229 0.320    || dis=0.01 || select=7/8
[epoch=111/600] FLOP : 27.73 MB, ratio : 0.6793, Expected-ratio : 0.7000, Discrepancy : 0.019
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:41:07] [epoch=111/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.871 (1.871)  Prec@1 40.62 (40.62) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:41:14] [epoch=111/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.126 (2.430)  Prec@1 38.10 (36.41) Prec@5 81.55 (82.23) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.41 Prec@5 82.23 Error@1 63.59 Error@5 17.77 Loss:2.430
***[2020-01-29 06:41:14]*** VALID [epoch=111/600] loss = 2.429579, accuracy@1 = 36.41, accuracy@5 = 82.23 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:41:14]*** start epoch=112/600 Time Left: [04:22:14], LR=[0.091646 ~ 0.091646], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=112, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.590657039739743, FLOP=40.81
[Search] : epoch=112/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:41:14] [epoch=112/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.846 (0.846)  Prec@1 73.83 (73.83) Prec@5 98.44 (98.44) Acls-loss 0.916 (0.916) FLOP-Loss 0.000 (0.000) Arch-Loss 0.916 (0.916)
**TRAIN** [2020-01-29 06:41:38] [epoch=112/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.769 (0.871)  Prec@1 76.19 (70.10) Prec@5 95.83 (97.63) Acls-loss 0.954 (0.901) FLOP-Loss 0.000 (0.000) Arch-Loss 0.954 (0.901)
 **TRAIN** Prec@1 70.10 Prec@5 97.63 Error@1 29.90 Error@5 2.37 Base-Loss:0.871, Arch-Loss=0.901
***[2020-01-29 06:41:38]*** TRAIN [epoch=112/600] base-loss = 0.871420, arch-loss = 0.901032, accuracy-1 = 70.10, accuracy-5 = 97.63
[epoch=112/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 11, 9, 12, 16, 14, 32, 28, 32, 25, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.60416)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.393 0.227 0.380  ||  0.0486 -0.4980 0.0168  || discrepancy=0.01 || select=0/3
001/003-th : 0.390 0.171 0.439  ||  -0.0042 -0.8271 0.1158  || discrepancy=0.05 || select=2/3
002/003-th : 0.246 0.236 0.518  ||  -0.3467 -0.3913 0.3964  || discrepancy=0.27 || select=2/3
-----------------------------------------------
000/019-th : 0.069 0.089 0.108 0.118 0.141 0.147 0.165 0.163  ||  -0.549 -0.299 -0.105 -0.017 0.166 0.208 0.320 0.311   || dis=0.00 || select=6/8
001/019-th : 0.122 0.121 0.124 0.127 0.125 0.127 0.127 0.127  ||  -0.017 -0.028 -0.008 0.022 0.006 0.018 0.017 0.017    || dis=0.00 || select=3/8
002/019-th : 0.117 0.123 0.127 0.128 0.131 0.128 0.123 0.122  ||  -0.057 -0.010 0.021 0.030 0.048 0.029 -0.010 -0.017   || dis=0.00 || select=4/8
003/019-th : 0.125 0.126 0.125 0.126 0.125 0.126 0.125 0.123  ||  -0.001 0.005 -0.004 0.007 -0.002 0.006 0.000 -0.017   || dis=0.00 || select=3/8
004/019-th : 0.117 0.119 0.121 0.123 0.128 0.131 0.130 0.130  ||  -0.064 -0.047 -0.033 -0.015 0.026 0.051 0.041 0.038   || dis=0.00 || select=5/8
005/019-th : 0.117 0.116 0.121 0.124 0.127 0.132 0.132 0.132  ||  -0.063 -0.077 -0.033 -0.009 0.019 0.054 0.054 0.056   || dis=0.00 || select=7/8
006/019-th : 0.113 0.113 0.116 0.124 0.129 0.134 0.136 0.135  ||  -0.098 -0.095 -0.072 -0.004 0.032 0.071 0.088 0.079   || dis=0.00 || select=6/8
007/019-th : 0.084 0.088 0.101 0.123 0.129 0.145 0.163 0.167  ||  -0.360 -0.319 -0.175 0.020 0.066 0.183 0.299 0.324    || dis=0.00 || select=7/8
008/019-th : 0.071 0.085 0.103 0.130 0.136 0.158 0.161 0.156  ||  -0.509 -0.340 -0.141 0.092 0.131 0.284 0.300 0.271    || dis=0.00 || select=6/8
009/019-th : 0.106 0.105 0.105 0.115 0.127 0.137 0.148 0.157  ||  -0.154 -0.168 -0.166 -0.078 0.026 0.095 0.172 0.235   || dis=0.01 || select=7/8
010/019-th : 0.105 0.110 0.119 0.125 0.128 0.138 0.137 0.138  ||  -0.168 -0.121 -0.042 0.002 0.028 0.104 0.099 0.102    || dis=0.00 || select=5/8
011/019-th : 0.103 0.103 0.106 0.118 0.130 0.133 0.150 0.157  ||  -0.184 -0.182 -0.149 -0.047 0.054 0.074 0.192 0.239   || dis=0.01 || select=7/8
012/019-th : 0.111 0.116 0.118 0.120 0.129 0.133 0.135 0.140  ||  -0.120 -0.075 -0.056 -0.044 0.033 0.060 0.075 0.111   || dis=0.01 || select=7/8
013/019-th : 0.062 0.065 0.079 0.092 0.119 0.155 0.200 0.227  ||  -0.612 -0.558 -0.373 -0.216 0.040 0.301 0.560 0.685   || dis=0.03 || select=7/8
014/019-th : 0.066 0.073 0.088 0.113 0.130 0.160 0.187 0.183  ||  -0.574 -0.481 -0.286 -0.042 0.102 0.306 0.464 0.440   || dis=0.00 || select=6/8
015/019-th : 0.062 0.058 0.079 0.096 0.120 0.153 0.213 0.220  ||  -0.601 -0.658 -0.356 -0.156 0.070 0.311 0.641 0.672   || dis=0.01 || select=7/8
016/019-th : 0.065 0.080 0.099 0.128 0.134 0.160 0.168 0.165  ||  -0.602 -0.398 -0.177 0.076 0.124 0.298 0.350 0.332    || dis=0.00 || select=6/8
017/019-th : 0.115 0.112 0.121 0.123 0.126 0.130 0.135 0.137  ||  -0.077 -0.101 -0.028 -0.009 0.010 0.044 0.085 0.099   || dis=0.00 || select=7/8
018/019-th : 0.082 0.099 0.110 0.123 0.129 0.135 0.154 0.168  ||  -0.395 -0.206 -0.102 0.003 0.052 0.097 0.229 0.318    || dis=0.01 || select=7/8
[epoch=112/600] FLOP : 26.60 MB, ratio : 0.6519, Expected-ratio : 0.7000, Discrepancy : 0.019
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:41:39] [epoch=112/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.607 (2.607)  Prec@1 29.69 (29.69) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:41:44] [epoch=112/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.744 (2.416)  Prec@1 38.69 (36.30) Prec@5 80.95 (81.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.30 Prec@5 81.30 Error@1 63.70 Error@5 18.70 Loss:2.416
***[2020-01-29 06:41:45]*** VALID [epoch=112/600] loss = 2.416299, accuracy@1 = 36.30, accuracy@5 = 81.30 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:41:45]*** start epoch=113/600 Time Left: [04:21:36], LR=[0.091501 ~ 0.091501], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=113, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.58353009848365, FLOP=40.81
[Search] : epoch=113/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:41:45] [epoch=113/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.917 (0.917)  Prec@1 67.97 (67.97) Prec@5 96.48 (96.48) Acls-loss 0.972 (0.972) FLOP-Loss 0.000 (0.000) Arch-Loss 0.972 (0.972)
**TRAIN** [2020-01-29 06:42:09] [epoch=113/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.918 (0.873)  Prec@1 73.21 (70.14) Prec@5 95.24 (97.63) Acls-loss 1.117 (0.897) FLOP-Loss 0.000 (0.000) Arch-Loss 1.117 (0.897)
 **TRAIN** Prec@1 70.14 Prec@5 97.63 Error@1 29.86 Error@5 2.37 Base-Loss:0.873, Arch-Loss=0.897
***[2020-01-29 06:42:10]*** TRAIN [epoch=113/600] base-loss = 0.873165, arch-loss = 0.896693, accuracy-1 = 70.14, accuracy-5 = 97.63
[epoch=113/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 11, 12, 12, 16, 14, 32, 28, 32, 28, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.882112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.391 0.224 0.384  ||  0.0429 -0.5123 0.0255  || discrepancy=0.01 || select=0/3
001/003-th : 0.387 0.171 0.442  ||  -0.0097 -0.8276 0.1241  || discrepancy=0.05 || select=2/3
002/003-th : 0.242 0.235 0.524  ||  -0.3620 -0.3906 0.4117  || discrepancy=0.28 || select=2/3
-----------------------------------------------
000/019-th : 0.068 0.088 0.108 0.118 0.142 0.146 0.164 0.165  ||  -0.557 -0.310 -0.103 -0.013 0.175 0.198 0.319 0.324   || dis=0.00 || select=7/8
001/019-th : 0.121 0.121 0.123 0.127 0.125 0.129 0.127 0.127  ||  -0.026 -0.028 -0.016 0.019 0.001 0.034 0.020 0.023    || dis=0.00 || select=5/8
002/019-th : 0.117 0.123 0.126 0.128 0.131 0.128 0.124 0.122  ||  -0.058 -0.014 0.014 0.031 0.051 0.027 -0.002 -0.017   || dis=0.00 || select=4/8
003/019-th : 0.124 0.125 0.124 0.125 0.125 0.126 0.126 0.124  ||  -0.007 0.003 -0.010 0.003 -0.001 0.009 0.005 -0.011   || dis=0.00 || select=5/8
004/019-th : 0.117 0.119 0.121 0.123 0.127 0.131 0.131 0.131  ||  -0.069 -0.047 -0.032 -0.016 0.015 0.049 0.044 0.045   || dis=0.00 || select=5/8
005/019-th : 0.115 0.115 0.122 0.122 0.128 0.132 0.132 0.133  ||  -0.077 -0.081 -0.024 -0.021 0.024 0.060 0.058 0.065   || dis=0.00 || select=7/8
006/019-th : 0.112 0.113 0.117 0.126 0.127 0.133 0.137 0.135  ||  -0.104 -0.095 -0.067 0.007 0.018 0.065 0.093 0.082    || dis=0.00 || select=6/8
007/019-th : 0.084 0.086 0.102 0.121 0.127 0.147 0.163 0.169  ||  -0.360 -0.338 -0.172 0.006 0.052 0.200 0.304 0.337    || dis=0.01 || select=7/8
008/019-th : 0.072 0.082 0.104 0.132 0.134 0.158 0.163 0.156  ||  -0.504 -0.366 -0.135 0.103 0.118 0.283 0.314 0.272    || dis=0.01 || select=6/8
009/019-th : 0.106 0.105 0.105 0.115 0.126 0.138 0.148 0.158  ||  -0.157 -0.172 -0.169 -0.078 0.011 0.102 0.175 0.243   || dis=0.01 || select=7/8
010/019-th : 0.104 0.111 0.119 0.124 0.126 0.136 0.140 0.139  ||  -0.176 -0.115 -0.043 -0.004 0.009 0.091 0.116 0.112   || dis=0.00 || select=6/8
011/019-th : 0.101 0.102 0.106 0.118 0.129 0.134 0.150 0.158  ||  -0.196 -0.189 -0.148 -0.043 0.048 0.080 0.198 0.247   || dis=0.01 || select=7/8
012/019-th : 0.110 0.115 0.117 0.119 0.130 0.134 0.135 0.141  ||  -0.129 -0.080 -0.062 -0.051 0.040 0.069 0.078 0.119   || dis=0.01 || select=7/8
013/019-th : 0.061 0.064 0.078 0.092 0.118 0.154 0.202 0.231  ||  -0.621 -0.579 -0.385 -0.213 0.038 0.302 0.573 0.708   || dis=0.03 || select=7/8
014/019-th : 0.065 0.072 0.089 0.113 0.131 0.158 0.187 0.185  ||  -0.586 -0.490 -0.280 -0.039 0.107 0.299 0.464 0.452   || dis=0.00 || select=6/8
015/019-th : 0.061 0.057 0.078 0.098 0.120 0.154 0.211 0.222  ||  -0.610 -0.681 -0.364 -0.134 0.070 0.324 0.636 0.688   || dis=0.01 || select=7/8
016/019-th : 0.065 0.077 0.098 0.127 0.135 0.162 0.169 0.166  ||  -0.604 -0.423 -0.184 0.071 0.135 0.316 0.355 0.341    || dis=0.00 || select=6/8
017/019-th : 0.114 0.113 0.120 0.124 0.125 0.130 0.136 0.138  ||  -0.085 -0.097 -0.033 -0.001 0.007 0.043 0.087 0.102   || dis=0.00 || select=7/8
018/019-th : 0.083 0.100 0.108 0.122 0.131 0.136 0.153 0.168  ||  -0.392 -0.203 -0.124 -0.003 0.070 0.104 0.224 0.320   || dis=0.02 || select=7/8
[epoch=113/600] FLOP : 27.88 MB, ratio : 0.6832, Expected-ratio : 0.7000, Discrepancy : 0.021
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:42:10] [epoch=113/600][000/098] Time 0.34 (0.34) Data 0.27 (0.27) Loss 1.967 (1.967)  Prec@1 43.75 (43.75) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:42:16] [epoch=113/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.235 (2.109)  Prec@1 36.90 (39.59) Prec@5 81.55 (85.01) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.59 Prec@5 85.01 Error@1 60.41 Error@5 14.99 Loss:2.109
***[2020-01-29 06:42:16]*** VALID [epoch=113/600] loss = 2.108659, accuracy@1 = 39.59, accuracy@5 = 85.01 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:42:16]*** start epoch=114/600 Time Left: [04:21:00], LR=[0.091354 ~ 0.091354], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=114, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.576347406972676, FLOP=40.81
[Search] : epoch=114/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:42:17] [epoch=114/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.803 (0.803)  Prec@1 71.48 (71.48) Prec@5 99.22 (99.22) Acls-loss 0.752 (0.752) FLOP-Loss 0.000 (0.000) Arch-Loss 0.752 (0.752)
**TRAIN** [2020-01-29 06:42:40] [epoch=114/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.744 (0.872)  Prec@1 69.64 (70.10) Prec@5 99.40 (97.58) Acls-loss 0.809 (0.884) FLOP-Loss 0.000 (0.105) Arch-Loss 0.809 (1.094)
 **TRAIN** Prec@1 70.10 Prec@5 97.58 Error@1 29.90 Error@5 2.42 Base-Loss:0.872, Arch-Loss=1.094
***[2020-01-29 06:42:41]*** TRAIN [epoch=114/600] base-loss = 0.871885, arch-loss = 1.094414, accuracy-1 = 70.10, accuracy-5 = 97.58
[epoch=114/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 16, 12, 14, 32, 28, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.526784)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.398 0.223 0.379  ||  0.0592 -0.5174 0.0118  || discrepancy=0.02 || select=0/3
001/003-th : 0.391 0.172 0.436  ||  0.0039 -0.8178 0.1128  || discrepancy=0.04 || select=2/3
002/003-th : 0.243 0.238 0.519  ||  -0.3544 -0.3765 0.4043  || discrepancy=0.28 || select=2/3
-----------------------------------------------
000/019-th : 0.068 0.087 0.111 0.119 0.143 0.146 0.162 0.163  ||  -0.559 -0.312 -0.073 -0.004 0.178 0.200 0.302 0.313   || dis=0.00 || select=7/8
001/019-th : 0.123 0.123 0.124 0.128 0.125 0.126 0.125 0.126  ||  -0.011 -0.013 -0.007 0.026 0.001 0.014 0.006 0.009    || dis=0.00 || select=3/8
002/019-th : 0.119 0.125 0.128 0.130 0.129 0.126 0.122 0.120  ||  -0.043 0.003 0.030 0.047 0.038 0.011 -0.018 -0.033    || dis=0.00 || select=3/8
003/019-th : 0.126 0.127 0.126 0.126 0.125 0.124 0.124 0.122  ||  0.004 0.013 0.009 0.009 -0.004 -0.007 -0.006 -0.023   || dis=0.00 || select=1/8
004/019-th : 0.118 0.121 0.123 0.125 0.127 0.128 0.129 0.129  ||  -0.055 -0.036 -0.016 -0.002 0.019 0.023 0.030 0.033   || dis=0.00 || select=7/8
005/019-th : 0.117 0.117 0.124 0.121 0.127 0.133 0.130 0.131  ||  -0.065 -0.066 -0.009 -0.028 0.020 0.060 0.041 0.050   || dis=0.00 || select=5/8
006/019-th : 0.113 0.114 0.118 0.127 0.129 0.132 0.134 0.133  ||  -0.095 -0.086 -0.057 0.024 0.033 0.060 0.075 0.066    || dis=0.00 || select=6/8
007/019-th : 0.084 0.088 0.103 0.122 0.129 0.145 0.162 0.167  ||  -0.358 -0.322 -0.160 0.006 0.068 0.183 0.294 0.324    || dis=0.01 || select=7/8
008/019-th : 0.072 0.082 0.103 0.134 0.134 0.159 0.164 0.153  ||  -0.506 -0.371 -0.143 0.124 0.121 0.291 0.322 0.256    || dis=0.01 || select=6/8
009/019-th : 0.108 0.106 0.105 0.116 0.128 0.137 0.145 0.157  ||  -0.143 -0.155 -0.172 -0.072 0.027 0.095 0.154 0.232   || dis=0.01 || select=7/8
010/019-th : 0.106 0.112 0.120 0.125 0.125 0.136 0.138 0.138  ||  -0.162 -0.109 -0.035 0.004 0.001 0.084 0.102 0.104    || dis=0.00 || select=7/8
011/019-th : 0.104 0.103 0.107 0.118 0.130 0.132 0.149 0.157  ||  -0.171 -0.182 -0.146 -0.048 0.048 0.069 0.185 0.238   || dis=0.01 || select=7/8
012/019-th : 0.111 0.116 0.119 0.120 0.131 0.131 0.134 0.139  ||  -0.118 -0.075 -0.046 -0.039 0.046 0.048 0.071 0.107   || dis=0.01 || select=7/8
013/019-th : 0.062 0.063 0.078 0.093 0.118 0.154 0.201 0.231  ||  -0.615 -0.590 -0.375 -0.200 0.032 0.304 0.566 0.706   || dis=0.03 || select=7/8
014/019-th : 0.066 0.073 0.089 0.113 0.133 0.159 0.184 0.183  ||  -0.583 -0.483 -0.279 -0.035 0.125 0.301 0.448 0.445   || dis=0.00 || select=6/8
015/019-th : 0.061 0.056 0.075 0.097 0.118 0.158 0.211 0.224  ||  -0.604 -0.689 -0.391 -0.133 0.060 0.350 0.640 0.698   || dis=0.01 || select=7/8
016/019-th : 0.065 0.078 0.098 0.130 0.136 0.161 0.168 0.164  ||  -0.601 -0.412 -0.188 0.091 0.140 0.308 0.350 0.327    || dis=0.00 || select=6/8
017/019-th : 0.115 0.116 0.121 0.125 0.127 0.128 0.133 0.136  ||  -0.078 -0.070 -0.031 0.008 0.022 0.028 0.065 0.087    || dis=0.00 || select=7/8
018/019-th : 0.083 0.099 0.109 0.125 0.132 0.134 0.151 0.167  ||  -0.383 -0.209 -0.116 0.019 0.074 0.093 0.215 0.311    || dis=0.02 || select=7/8
[epoch=114/600] FLOP : 27.53 MB, ratio : 0.6745, Expected-ratio : 0.7000, Discrepancy : 0.020
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:42:41] [epoch=114/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.379 (1.379)  Prec@1 55.47 (55.47) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:42:47] [epoch=114/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.105 (2.036)  Prec@1 46.43 (40.04) Prec@5 85.71 (83.90) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.04 Prec@5 83.90 Error@1 59.96 Error@5 16.10 Loss:2.036
***[2020-01-29 06:42:47]*** VALID [epoch=114/600] loss = 2.035585, accuracy@1 = 40.04, accuracy@5 = 83.90 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:42:47]*** start epoch=115/600 Time Left: [04:20:22], LR=[0.091206 ~ 0.091206], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=115, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.5691091621239375, FLOP=40.81
[Search] : epoch=115/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:42:48] [epoch=115/600][000/098] Time 0.74 (0.74) Data 0.37 (0.37) Base-Loss 0.755 (0.755)  Prec@1 72.66 (72.66) Prec@5 99.61 (99.61) Acls-loss 0.845 (0.845) FLOP-Loss 0.000 (0.000) Arch-Loss 0.845 (0.845)
**TRAIN** [2020-01-29 06:43:12] [epoch=115/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.979 (0.857)  Prec@1 63.10 (70.52) Prec@5 97.62 (97.51) Acls-loss 0.741 (0.887) FLOP-Loss 0.000 (0.000) Arch-Loss 0.741 (0.887)
 **TRAIN** Prec@1 70.52 Prec@5 97.51 Error@1 29.48 Error@5 2.49 Base-Loss:0.857, Arch-Loss=0.887
***[2020-01-29 06:43:12]*** TRAIN [epoch=115/600] base-loss = 0.857344, arch-loss = 0.887114, accuracy-1 = 70.52, accuracy-5 = 97.51
[epoch=115/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 16, 12, 16, 32, 28, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.688576)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.396 0.222 0.382  ||  0.0556 -0.5229 0.0179  || discrepancy=0.01 || select=0/3
001/003-th : 0.390 0.170 0.440  ||  -0.0009 -0.8300 0.1213  || discrepancy=0.05 || select=2/3
002/003-th : 0.240 0.239 0.522  ||  -0.3645 -0.3688 0.4138  || discrepancy=0.28 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.087 0.111 0.119 0.142 0.146 0.162 0.165  ||  -0.576 -0.312 -0.073 -0.002 0.173 0.202 0.306 0.324   || dis=0.00 || select=7/8
001/019-th : 0.123 0.123 0.123 0.128 0.125 0.127 0.125 0.126  ||  -0.015 -0.015 -0.010 0.026 0.002 0.019 0.005 0.014    || dis=0.00 || select=3/8
002/019-th : 0.119 0.124 0.128 0.131 0.128 0.126 0.123 0.121  ||  -0.049 -0.004 0.025 0.052 0.028 0.014 -0.011 -0.027   || dis=0.00 || select=3/8
003/019-th : 0.125 0.126 0.126 0.126 0.125 0.125 0.125 0.122  ||  -0.003 0.011 0.011 0.006 0.003 0.001 -0.002 -0.022    || dis=0.00 || select=1/8
004/019-th : 0.118 0.121 0.121 0.125 0.126 0.129 0.129 0.130  ||  -0.057 -0.033 -0.033 -0.005 0.010 0.029 0.034 0.040   || dis=0.00 || select=7/8
005/019-th : 0.118 0.118 0.122 0.120 0.127 0.133 0.131 0.132  ||  -0.061 -0.061 -0.023 -0.039 0.019 0.060 0.045 0.051   || dis=0.00 || select=5/8
006/019-th : 0.112 0.113 0.118 0.128 0.128 0.133 0.133 0.135  ||  -0.105 -0.098 -0.055 0.027 0.030 0.066 0.068 0.085    || dis=0.00 || select=7/8
007/019-th : 0.083 0.087 0.102 0.122 0.129 0.146 0.164 0.167  ||  -0.372 -0.329 -0.167 0.010 0.070 0.194 0.305 0.328    || dis=0.00 || select=7/8
008/019-th : 0.070 0.082 0.100 0.133 0.134 0.160 0.165 0.156  ||  -0.527 -0.363 -0.166 0.118 0.121 0.299 0.329 0.274    || dis=0.01 || select=6/8
009/019-th : 0.106 0.106 0.103 0.118 0.124 0.138 0.145 0.160  ||  -0.155 -0.155 -0.189 -0.056 -0.005 0.108 0.153 0.252  || dis=0.02 || select=7/8
010/019-th : 0.105 0.110 0.117 0.125 0.130 0.135 0.138 0.140  ||  -0.173 -0.120 -0.057 0.003 0.044 0.081 0.107 0.115    || dis=0.00 || select=7/8
011/019-th : 0.103 0.102 0.107 0.118 0.130 0.134 0.149 0.157  ||  -0.184 -0.189 -0.143 -0.043 0.049 0.083 0.191 0.237   || dis=0.01 || select=7/8
012/019-th : 0.111 0.115 0.119 0.119 0.131 0.131 0.135 0.140  ||  -0.120 -0.085 -0.045 -0.049 0.053 0.046 0.077 0.114   || dis=0.01 || select=7/8
013/019-th : 0.061 0.062 0.077 0.092 0.116 0.156 0.201 0.234  ||  -0.617 -0.600 -0.384 -0.207 0.025 0.316 0.574 0.723   || dis=0.03 || select=7/8
014/019-th : 0.065 0.072 0.088 0.113 0.131 0.160 0.187 0.184  ||  -0.586 -0.494 -0.282 -0.040 0.111 0.310 0.467 0.450   || dis=0.00 || select=6/8
015/019-th : 0.060 0.056 0.075 0.096 0.116 0.157 0.211 0.229  ||  -0.610 -0.682 -0.396 -0.141 0.045 0.345 0.641 0.723   || dis=0.02 || select=7/8
016/019-th : 0.064 0.077 0.098 0.127 0.135 0.164 0.169 0.166  ||  -0.608 -0.424 -0.187 0.076 0.130 0.327 0.357 0.338    || dis=0.00 || select=6/8
017/019-th : 0.115 0.115 0.120 0.125 0.127 0.129 0.133 0.136  ||  -0.081 -0.080 -0.037 0.007 0.022 0.038 0.069 0.092    || dis=0.00 || select=7/8
018/019-th : 0.083 0.098 0.109 0.123 0.132 0.134 0.153 0.168  ||  -0.388 -0.216 -0.111 0.010 0.074 0.089 0.222 0.319    || dis=0.02 || select=7/8
[epoch=115/600] FLOP : 27.69 MB, ratio : 0.6784, Expected-ratio : 0.7000, Discrepancy : 0.021
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:43:12] [epoch=115/600][000/098] Time 0.34 (0.34) Data 0.27 (0.27) Loss 1.278 (1.278)  Prec@1 56.64 (56.64) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:43:18] [epoch=115/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.832 (2.161)  Prec@1 40.48 (39.82) Prec@5 79.17 (84.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.82 Prec@5 84.53 Error@1 60.18 Error@5 15.47 Loss:2.161
***[2020-01-29 06:43:18]*** VALID [epoch=115/600] loss = 2.160728, accuracy@1 = 39.82, accuracy@5 = 84.53 | Best-Valid-Acc@1=40.30, Error@1=59.70
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:43:18]*** start epoch=116/600 Time Left: [04:19:47], LR=[0.091057 ~ 0.091057], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=116, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.561815562377575, FLOP=40.81
[Search] : epoch=116/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:43:19] [epoch=116/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.843 (0.843)  Prec@1 68.75 (68.75) Prec@5 98.05 (98.05) Acls-loss 0.991 (0.991) FLOP-Loss 0.000 (0.000) Arch-Loss 0.991 (0.991)
**TRAIN** [2020-01-29 06:43:43] [epoch=116/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.852 (0.861)  Prec@1 71.43 (70.33) Prec@5 98.21 (97.66) Acls-loss 0.935 (0.883) FLOP-Loss 0.000 (0.000) Arch-Loss 0.935 (0.883)
 **TRAIN** Prec@1 70.33 Prec@5 97.66 Error@1 29.67 Error@5 2.34 Base-Loss:0.861, Arch-Loss=0.883
***[2020-01-29 06:43:43]*** TRAIN [epoch=116/600] base-loss = 0.861387, arch-loss = 0.883276, accuracy-1 = 70.33, accuracy-5 = 97.66
[epoch=116/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 11, 16, 12, 16, 32, 28, 32, 32, 32, 32, 64, 57, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.379776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.394 0.226 0.380  ||  0.0541 -0.5010 0.0199  || discrepancy=0.01 || select=0/3
001/003-th : 0.387 0.169 0.443  ||  -0.0057 -0.8343 0.1295  || discrepancy=0.06 || select=2/3
002/003-th : 0.237 0.237 0.526  ||  -0.3740 -0.3739 0.4245  || discrepancy=0.29 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.086 0.110 0.118 0.142 0.146 0.164 0.167  ||  -0.582 -0.323 -0.080 -0.010 0.171 0.200 0.318 0.338   || dis=0.00 || select=7/8
001/019-th : 0.122 0.122 0.123 0.126 0.126 0.128 0.126 0.127  ||  -0.021 -0.020 -0.013 0.011 0.008 0.030 0.013 0.017    || dis=0.00 || select=5/8
002/019-th : 0.117 0.123 0.127 0.131 0.128 0.128 0.123 0.122  ||  -0.060 -0.010 0.022 0.053 0.030 0.029 -0.007 -0.021   || dis=0.00 || select=3/8
003/019-th : 0.123 0.125 0.124 0.125 0.128 0.126 0.125 0.123  ||  -0.011 -0.002 -0.003 0.004 0.022 0.013 0.003 -0.012   || dis=0.00 || select=4/8
004/019-th : 0.117 0.120 0.121 0.123 0.129 0.130 0.130 0.131  ||  -0.065 -0.044 -0.032 -0.018 0.031 0.038 0.038 0.046   || dis=0.00 || select=7/8
005/019-th : 0.117 0.117 0.122 0.119 0.128 0.133 0.132 0.132  ||  -0.067 -0.064 -0.026 -0.045 0.022 0.064 0.055 0.054   || dis=0.00 || select=5/8
006/019-th : 0.111 0.113 0.117 0.128 0.127 0.133 0.134 0.136  ||  -0.114 -0.097 -0.063 0.030 0.021 0.064 0.075 0.092    || dis=0.00 || select=7/8
007/019-th : 0.082 0.087 0.101 0.121 0.129 0.146 0.164 0.169  ||  -0.384 -0.322 -0.181 0.005 0.070 0.196 0.310 0.341    || dis=0.01 || select=7/8
008/019-th : 0.068 0.082 0.099 0.134 0.135 0.160 0.164 0.157  ||  -0.548 -0.365 -0.176 0.129 0.130 0.304 0.327 0.286    || dis=0.00 || select=6/8
009/019-th : 0.106 0.105 0.101 0.115 0.124 0.140 0.146 0.163  ||  -0.160 -0.168 -0.204 -0.079 -0.006 0.120 0.160 0.274  || dis=0.02 || select=7/8
010/019-th : 0.105 0.110 0.117 0.124 0.131 0.134 0.139 0.140  ||  -0.172 -0.127 -0.063 0.000 0.053 0.072 0.114 0.119    || dis=0.00 || select=7/8
011/019-th : 0.103 0.104 0.106 0.117 0.130 0.134 0.149 0.158  ||  -0.184 -0.176 -0.158 -0.058 0.051 0.085 0.188 0.244   || dis=0.01 || select=7/8
012/019-th : 0.110 0.114 0.119 0.119 0.131 0.131 0.135 0.141  ||  -0.128 -0.090 -0.043 -0.047 0.052 0.049 0.080 0.121   || dis=0.01 || select=7/8
013/019-th : 0.061 0.062 0.076 0.094 0.115 0.155 0.200 0.237  ||  -0.625 -0.604 -0.394 -0.189 0.017 0.315 0.569 0.737   || dis=0.04 || select=7/8
014/019-th : 0.065 0.072 0.088 0.111 0.129 0.161 0.187 0.186  ||  -0.586 -0.489 -0.282 -0.052 0.098 0.316 0.466 0.460   || dis=0.00 || select=6/8
015/019-th : 0.060 0.056 0.074 0.097 0.115 0.158 0.211 0.230  ||  -0.614 -0.676 -0.410 -0.138 0.035 0.356 0.642 0.730   || dis=0.02 || select=7/8
016/019-th : 0.064 0.076 0.097 0.130 0.136 0.161 0.170 0.166  ||  -0.609 -0.437 -0.200 0.094 0.142 0.309 0.364 0.343    || dis=0.00 || select=6/8
017/019-th : 0.114 0.114 0.119 0.126 0.126 0.130 0.133 0.137  ||  -0.088 -0.085 -0.040 0.016 0.015 0.047 0.068 0.098    || dis=0.00 || select=7/8
018/019-th : 0.083 0.097 0.111 0.124 0.131 0.133 0.154 0.168  ||  -0.389 -0.232 -0.097 0.016 0.068 0.083 0.230 0.320    || dis=0.01 || select=7/8
[epoch=116/600] FLOP : 28.38 MB, ratio : 0.6954, Expected-ratio : 0.7000, Discrepancy : 0.022
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:43:43] [epoch=116/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.300 (1.300)  Prec@1 57.42 (57.42) Prec@5 93.75 (93.75) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:43:50] [epoch=116/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.950 (2.112)  Prec@1 38.10 (40.63) Prec@5 83.93 (85.27) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.63 Prec@5 85.27 Error@1 59.37 Error@5 14.73 Loss:2.112
***[2020-01-29 06:43:50]*** VALID [epoch=116/600] loss = 2.111755, accuracy@1 = 40.63, accuracy@5 = 85.27 | Best-Valid-Acc@1=40.30, Error@1=59.70
Currently, the best validation accuracy found at 116-epoch :: acc@1=40.63, acc@5=85.27, error@1=59.37, error@5=14.73, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:43:50]*** start epoch=117/600 Time Left: [04:19:11], LR=[0.090907 ~ 0.090907], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=117, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.554466807691307, FLOP=40.81
[Search] : epoch=117/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:43:50] [epoch=117/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.966 (0.966)  Prec@1 68.36 (68.36) Prec@5 97.27 (97.27) Acls-loss 0.926 (0.926) FLOP-Loss 0.000 (0.000) Arch-Loss 0.926 (0.926)
**TRAIN** [2020-01-29 06:44:14] [epoch=117/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.696 (0.859)  Prec@1 76.19 (70.56) Prec@5 100.00 (97.66) Acls-loss 0.853 (0.888) FLOP-Loss 0.000 (0.132) Arch-Loss 0.853 (1.151)
 **TRAIN** Prec@1 70.56 Prec@5 97.66 Error@1 29.44 Error@5 2.34 Base-Loss:0.859, Arch-Loss=1.151
***[2020-01-29 06:44:14]*** TRAIN [epoch=117/600] base-loss = 0.858798, arch-loss = 1.151035, accuracy-1 = 70.56, accuracy-5 = 97.66
[epoch=117/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 11, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.45248)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.403 0.225 0.372  ||  0.0776 -0.5020 -0.0013  || discrepancy=0.03 || select=0/3
001/003-th : 0.396 0.168 0.436  ||  0.0160 -0.8410 0.1118  || discrepancy=0.04 || select=2/3
002/003-th : 0.239 0.242 0.519  ||  -0.3636 -0.3480 0.4128  || discrepancy=0.28 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.088 0.112 0.121 0.141 0.145 0.160 0.167  ||  -0.581 -0.310 -0.064 0.014 0.163 0.194 0.289 0.332    || dis=0.01 || select=7/8
001/019-th : 0.125 0.125 0.124 0.128 0.124 0.126 0.124 0.125  ||  0.003 -0.001 -0.004 0.023 -0.010 0.011 -0.007 -0.002  || dis=0.00 || select=3/8
002/019-th : 0.120 0.126 0.129 0.132 0.127 0.126 0.122 0.119  ||  -0.038 0.010 0.036 0.060 0.019 0.012 -0.023 -0.044    || dis=0.00 || select=3/8
003/019-th : 0.125 0.128 0.126 0.126 0.125 0.126 0.123 0.120  ||  0.006 0.022 0.010 0.012 0.005 0.010 -0.016 -0.036     || dis=0.00 || select=1/8
004/019-th : 0.120 0.122 0.123 0.122 0.129 0.129 0.128 0.128  ||  -0.042 -0.027 -0.020 -0.024 0.033 0.028 0.020 0.024   || dis=0.00 || select=4/8
005/019-th : 0.119 0.120 0.124 0.122 0.125 0.131 0.128 0.130  ||  -0.048 -0.043 -0.006 -0.024 0.002 0.047 0.026 0.036   || dis=0.00 || select=5/8
006/019-th : 0.114 0.115 0.119 0.130 0.127 0.129 0.131 0.135  ||  -0.092 -0.082 -0.047 0.039 0.023 0.038 0.054 0.078    || dis=0.00 || select=7/8
007/019-th : 0.083 0.087 0.101 0.121 0.131 0.143 0.163 0.169  ||  -0.374 -0.322 -0.177 0.005 0.084 0.171 0.304 0.339    || dis=0.01 || select=7/8
008/019-th : 0.069 0.083 0.100 0.138 0.136 0.155 0.163 0.156  ||  -0.542 -0.357 -0.167 0.149 0.135 0.270 0.318 0.278    || dis=0.01 || select=6/8
009/019-th : 0.108 0.108 0.102 0.116 0.123 0.138 0.144 0.161  ||  -0.140 -0.142 -0.199 -0.068 -0.014 0.104 0.143 0.257  || dis=0.02 || select=7/8
010/019-th : 0.106 0.112 0.117 0.123 0.132 0.134 0.137 0.138  ||  -0.158 -0.104 -0.058 -0.011 0.058 0.072 0.097 0.103   || dis=0.00 || select=7/8
011/019-th : 0.105 0.106 0.106 0.119 0.128 0.134 0.148 0.155  ||  -0.163 -0.155 -0.156 -0.044 0.030 0.076 0.176 0.225   || dis=0.01 || select=7/8
012/019-th : 0.112 0.117 0.121 0.119 0.129 0.130 0.133 0.139  ||  -0.111 -0.068 -0.031 -0.050 0.035 0.037 0.064 0.110   || dis=0.01 || select=7/8
013/019-th : 0.061 0.062 0.076 0.094 0.113 0.157 0.202 0.235  ||  -0.615 -0.598 -0.393 -0.192 0.002 0.324 0.576 0.730   || dis=0.03 || select=7/8
014/019-th : 0.066 0.074 0.088 0.114 0.129 0.160 0.183 0.186  ||  -0.574 -0.461 -0.293 -0.035 0.095 0.305 0.440 0.456   || dis=0.00 || select=7/8
015/019-th : 0.060 0.056 0.073 0.096 0.117 0.160 0.209 0.228  ||  -0.606 -0.682 -0.420 -0.138 0.058 0.368 0.635 0.721   || dis=0.02 || select=7/8
016/019-th : 0.066 0.077 0.099 0.131 0.137 0.157 0.170 0.164  ||  -0.587 -0.427 -0.185 0.100 0.144 0.282 0.359 0.324    || dis=0.01 || select=6/8
017/019-th : 0.116 0.115 0.120 0.128 0.127 0.128 0.130 0.135  ||  -0.066 -0.073 -0.032 0.031 0.024 0.028 0.045 0.079    || dis=0.01 || select=7/8
018/019-th : 0.085 0.099 0.111 0.124 0.129 0.133 0.150 0.168  ||  -0.369 -0.209 -0.098 0.014 0.055 0.086 0.205 0.314    || dis=0.02 || select=7/8
[epoch=117/600] FLOP : 28.45 MB, ratio : 0.6971, Expected-ratio : 0.7000, Discrepancy : 0.023
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:44:15] [epoch=117/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.646 (2.646)  Prec@1 34.77 (34.77) Prec@5 80.08 (80.08) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:44:21] [epoch=117/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.072 (2.329)  Prec@1 42.86 (37.58) Prec@5 88.10 (82.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.58 Prec@5 82.78 Error@1 62.42 Error@5 17.22 Loss:2.329
***[2020-01-29 06:44:21]*** VALID [epoch=117/600] loss = 2.328695, accuracy@1 = 37.58, accuracy@5 = 82.78 | Best-Valid-Acc@1=40.63, Error@1=59.37
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:44:21]*** start epoch=118/600 Time Left: [04:18:34], LR=[0.090756 ~ 0.090756], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=118, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.547063099534958, FLOP=40.81
[Search] : epoch=118/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:44:21] [epoch=118/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.955 (0.955)  Prec@1 68.36 (68.36) Prec@5 97.66 (97.66) Acls-loss 0.911 (0.911) FLOP-Loss 0.000 (0.000) Arch-Loss 0.911 (0.911)
**TRAIN** [2020-01-29 06:44:45] [epoch=118/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.872 (0.857)  Prec@1 66.67 (70.69) Prec@5 98.81 (97.60) Acls-loss 0.698 (0.883) FLOP-Loss 0.000 (0.026) Arch-Loss 0.698 (0.936)
 **TRAIN** Prec@1 70.69 Prec@5 97.60 Error@1 29.31 Error@5 2.40 Base-Loss:0.857, Arch-Loss=0.936
***[2020-01-29 06:44:45]*** TRAIN [epoch=118/600] base-loss = 0.857068, arch-loss = 0.935518, accuracy-1 = 70.69, accuracy-5 = 97.60
[epoch=118/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 11, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.45248)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.401 0.228 0.371  ||  0.0780 -0.4882 -0.0007  || discrepancy=0.03 || select=0/3
001/003-th : 0.395 0.168 0.437  ||  0.0154 -0.8390 0.1152  || discrepancy=0.04 || select=2/3
002/003-th : 0.234 0.240 0.526  ||  -0.3811 -0.3548 0.4308  || discrepancy=0.29 || select=2/3
-----------------------------------------------
000/019-th : 0.068 0.088 0.112 0.120 0.141 0.146 0.158 0.168  ||  -0.569 -0.306 -0.071 0.001 0.160 0.199 0.278 0.336    || dis=0.01 || select=7/8
001/019-th : 0.125 0.124 0.124 0.128 0.124 0.127 0.124 0.125  ||  0.003 -0.006 -0.008 0.024 -0.010 0.014 -0.002 -0.002  || dis=0.00 || select=3/8
002/019-th : 0.120 0.125 0.129 0.132 0.129 0.125 0.122 0.119  ||  -0.036 0.003 0.034 0.059 0.034 0.009 -0.023 -0.044    || dis=0.00 || select=3/8
003/019-th : 0.126 0.128 0.125 0.125 0.125 0.126 0.123 0.122  ||  0.007 0.022 0.003 -0.002 0.002 0.007 -0.016 -0.029    || dis=0.00 || select=1/8
004/019-th : 0.120 0.121 0.123 0.124 0.129 0.128 0.128 0.128  ||  -0.042 -0.031 -0.017 -0.011 0.035 0.024 0.023 0.021   || dis=0.00 || select=4/8
005/019-th : 0.118 0.117 0.125 0.123 0.126 0.132 0.129 0.129  ||  -0.052 -0.063 0.001 -0.015 0.007 0.056 0.036 0.036    || dis=0.00 || select=5/8
006/019-th : 0.114 0.115 0.118 0.128 0.127 0.130 0.132 0.135  ||  -0.090 -0.080 -0.059 0.029 0.018 0.042 0.058 0.080    || dis=0.00 || select=7/8
007/019-th : 0.082 0.088 0.101 0.120 0.130 0.143 0.165 0.171  ||  -0.384 -0.315 -0.179 -0.006 0.074 0.171 0.313 0.348   || dis=0.01 || select=7/8
008/019-th : 0.068 0.083 0.101 0.138 0.136 0.154 0.164 0.157  ||  -0.552 -0.358 -0.163 0.152 0.135 0.265 0.323 0.280    || dis=0.01 || select=6/8
009/019-th : 0.108 0.108 0.103 0.115 0.124 0.137 0.145 0.161  ||  -0.142 -0.144 -0.193 -0.080 -0.005 0.099 0.152 0.257  || dis=0.02 || select=7/8
010/019-th : 0.106 0.113 0.118 0.125 0.130 0.135 0.136 0.137  ||  -0.161 -0.101 -0.053 0.002 0.043 0.082 0.092 0.099    || dis=0.00 || select=7/8
011/019-th : 0.105 0.106 0.107 0.118 0.128 0.131 0.149 0.156  ||  -0.163 -0.156 -0.149 -0.046 0.032 0.058 0.181 0.229   || dis=0.01 || select=7/8
012/019-th : 0.112 0.116 0.121 0.119 0.130 0.130 0.134 0.140  ||  -0.111 -0.075 -0.035 -0.051 0.039 0.037 0.070 0.111   || dis=0.01 || select=7/8
013/019-th : 0.061 0.060 0.076 0.094 0.113 0.157 0.201 0.238  ||  -0.615 -0.629 -0.392 -0.184 -0.001 0.329 0.576 0.749  || dis=0.04 || select=7/8
014/019-th : 0.066 0.073 0.088 0.113 0.128 0.159 0.186 0.187  ||  -0.577 -0.472 -0.288 -0.040 0.083 0.299 0.459 0.464   || dis=0.00 || select=7/8
015/019-th : 0.059 0.056 0.073 0.097 0.118 0.157 0.209 0.232  ||  -0.619 -0.688 -0.420 -0.133 0.067 0.353 0.635 0.742   || dis=0.02 || select=7/8
016/019-th : 0.064 0.077 0.098 0.131 0.137 0.155 0.173 0.166  ||  -0.612 -0.434 -0.184 0.099 0.148 0.268 0.382 0.338    || dis=0.01 || select=6/8
017/019-th : 0.116 0.114 0.120 0.127 0.128 0.129 0.131 0.134  ||  -0.065 -0.083 -0.036 0.024 0.031 0.034 0.051 0.078    || dis=0.00 || select=7/8
018/019-th : 0.083 0.097 0.110 0.124 0.130 0.134 0.152 0.168  ||  -0.385 -0.227 -0.102 0.014 0.061 0.095 0.221 0.321    || dis=0.02 || select=7/8
[epoch=118/600] FLOP : 28.45 MB, ratio : 0.6971, Expected-ratio : 0.7000, Discrepancy : 0.023
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:44:46] [epoch=118/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.325 (2.325)  Prec@1 44.53 (44.53) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:44:52] [epoch=118/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.194 (2.129)  Prec@1 28.57 (37.15) Prec@5 72.62 (82.19) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.15 Prec@5 82.19 Error@1 62.85 Error@5 17.81 Loss:2.129
***[2020-01-29 06:44:52]*** VALID [epoch=118/600] loss = 2.128604, accuracy@1 = 37.15, accuracy@5 = 82.19 | Best-Valid-Acc@1=40.63, Error@1=59.37
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:44:52]*** start epoch=119/600 Time Left: [04:17:58], LR=[0.090604 ~ 0.090604], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=119, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.539604640884925, FLOP=40.81
[Search] : epoch=119/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:44:53] [epoch=119/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.923 (0.923)  Prec@1 66.80 (66.80) Prec@5 95.70 (95.70) Acls-loss 0.891 (0.891) FLOP-Loss 0.000 (0.000) Arch-Loss 0.891 (0.891)
**TRAIN** [2020-01-29 06:45:17] [epoch=119/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.957 (0.861)  Prec@1 65.48 (70.64) Prec@5 95.83 (97.56) Acls-loss 0.956 (0.898) FLOP-Loss 0.000 (0.026) Arch-Loss 0.956 (0.950)
 **TRAIN** Prec@1 70.64 Prec@5 97.56 Error@1 29.36 Error@5 2.44 Base-Loss:0.861, Arch-Loss=0.950
***[2020-01-29 06:45:17]*** TRAIN [epoch=119/600] base-loss = 0.860542, arch-loss = 0.950217, accuracy-1 = 70.64, accuracy-5 = 97.56
[epoch=119/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 6, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.553856)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.401 0.231 0.368  ||  0.0816 -0.4686 -0.0038  || discrepancy=0.03 || select=0/3
001/003-th : 0.394 0.167 0.438  ||  0.0142 -0.8440 0.1199  || discrepancy=0.04 || select=2/3
002/003-th : 0.229 0.241 0.531  ||  -0.3967 -0.3458 0.4449  || discrepancy=0.29 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.087 0.112 0.119 0.141 0.144 0.160 0.170  ||  -0.575 -0.324 -0.070 -0.002 0.166 0.184 0.290 0.351   || dis=0.01 || select=7/8
001/019-th : 0.126 0.124 0.124 0.127 0.123 0.127 0.125 0.125  ||  0.006 -0.009 -0.009 0.013 -0.019 0.020 -0.001 -0.001  || dis=0.00 || select=5/8
002/019-th : 0.120 0.125 0.128 0.131 0.129 0.125 0.122 0.119  ||  -0.038 0.005 0.025 0.054 0.036 0.006 -0.020 -0.042    || dis=0.00 || select=3/8
003/019-th : 0.125 0.128 0.126 0.126 0.125 0.125 0.123 0.122  ||  0.001 0.021 0.010 0.006 0.002 0.000 -0.016 -0.024     || dis=0.00 || select=1/8
004/019-th : 0.119 0.121 0.124 0.123 0.129 0.127 0.129 0.128  ||  -0.047 -0.032 -0.011 -0.015 0.028 0.018 0.031 0.024   || dis=0.00 || select=6/8
005/019-th : 0.117 0.116 0.125 0.124 0.126 0.131 0.131 0.130  ||  -0.065 -0.069 -0.001 -0.007 0.013 0.046 0.048 0.045   || dis=0.00 || select=6/8
006/019-th : 0.114 0.115 0.118 0.128 0.125 0.131 0.133 0.136  ||  -0.090 -0.087 -0.058 0.021 0.004 0.050 0.063 0.086    || dis=0.00 || select=7/8
007/019-th : 0.080 0.089 0.101 0.121 0.130 0.143 0.166 0.170  ||  -0.407 -0.307 -0.174 0.007 0.075 0.170 0.320 0.346    || dis=0.00 || select=7/8
008/019-th : 0.067 0.081 0.099 0.138 0.135 0.156 0.166 0.157  ||  -0.567 -0.373 -0.176 0.159 0.137 0.276 0.339 0.287    || dis=0.01 || select=6/8
009/019-th : 0.106 0.106 0.102 0.116 0.125 0.138 0.144 0.163  ||  -0.156 -0.158 -0.194 -0.072 0.007 0.107 0.149 0.269   || dis=0.02 || select=7/8
010/019-th : 0.106 0.114 0.118 0.125 0.128 0.135 0.137 0.136  ||  -0.164 -0.091 -0.055 0.007 0.030 0.085 0.099 0.092    || dis=0.00 || select=6/8
011/019-th : 0.103 0.108 0.106 0.118 0.128 0.132 0.149 0.156  ||  -0.181 -0.135 -0.153 -0.052 0.030 0.061 0.185 0.232   || dis=0.01 || select=7/8
012/019-th : 0.113 0.116 0.119 0.118 0.130 0.129 0.134 0.140  ||  -0.104 -0.072 -0.049 -0.060 0.038 0.032 0.072 0.115   || dis=0.01 || select=7/8
013/019-th : 0.061 0.060 0.075 0.092 0.114 0.156 0.200 0.241  ||  -0.609 -0.629 -0.403 -0.197 0.011 0.328 0.576 0.760   || dis=0.04 || select=7/8
014/019-th : 0.066 0.074 0.087 0.112 0.128 0.158 0.187 0.189  ||  -0.579 -0.465 -0.297 -0.051 0.082 0.298 0.463 0.473   || dis=0.00 || select=7/8
015/019-th : 0.059 0.054 0.072 0.096 0.120 0.157 0.207 0.235  ||  -0.620 -0.706 -0.422 -0.137 0.083 0.355 0.632 0.756   || dis=0.03 || select=7/8
016/019-th : 0.064 0.077 0.097 0.130 0.137 0.155 0.174 0.166  ||  -0.611 -0.431 -0.196 0.093 0.147 0.273 0.388 0.338    || dis=0.01 || select=6/8
017/019-th : 0.117 0.113 0.121 0.128 0.128 0.128 0.131 0.135  ||  -0.064 -0.099 -0.030 0.028 0.029 0.028 0.055 0.085    || dis=0.00 || select=7/8
018/019-th : 0.082 0.097 0.111 0.125 0.130 0.134 0.152 0.168  ||  -0.397 -0.228 -0.093 0.025 0.063 0.097 0.223 0.317    || dis=0.02 || select=7/8
[epoch=119/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.024
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:45:17] [epoch=119/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.113 (2.113)  Prec@1 42.97 (42.97) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:45:23] [epoch=119/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.030 (2.112)  Prec@1 56.55 (40.96) Prec@5 88.69 (85.91) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.96 Prec@5 85.91 Error@1 59.04 Error@5 14.09 Loss:2.112
***[2020-01-29 06:45:23]*** VALID [epoch=119/600] loss = 2.112204, accuracy@1 = 40.96, accuracy@5 = 85.91 | Best-Valid-Acc@1=40.63, Error@1=59.37
Currently, the best validation accuracy found at 119-epoch :: acc@1=40.96, acc@5=85.91, error@1=59.04, error@5=14.09, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:45:23]*** start epoch=120/600 Time Left: [04:17:21], LR=[0.090451 ~ 0.090451], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=120, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.532091636218621, FLOP=40.81
[Search] : epoch=120/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:45:24] [epoch=120/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.953 (0.953)  Prec@1 67.97 (67.97) Prec@5 96.48 (96.48) Acls-loss 0.871 (0.871) FLOP-Loss 0.000 (0.000) Arch-Loss 0.871 (0.871)
**TRAIN** [2020-01-29 06:45:48] [epoch=120/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.949 (0.856)  Prec@1 69.05 (70.42) Prec@5 97.62 (97.67) Acls-loss 0.925 (0.893) FLOP-Loss 0.000 (0.000) Arch-Loss 0.925 (0.893)
 **TRAIN** Prec@1 70.42 Prec@5 97.67 Error@1 29.58 Error@5 2.33 Base-Loss:0.856, Arch-Loss=0.893
***[2020-01-29 06:45:48]*** TRAIN [epoch=120/600] base-loss = 0.856306, arch-loss = 0.893050, accuracy-1 = 70.42, accuracy-5 = 97.67
[epoch=120/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 6, 11, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.553856)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.400 0.229 0.371  ||  0.0769 -0.4797 0.0040  || discrepancy=0.03 || select=0/3
001/003-th : 0.391 0.163 0.446  ||  0.0036 -0.8680 0.1360  || discrepancy=0.05 || select=2/3
002/003-th : 0.224 0.240 0.537  ||  -0.4139 -0.3447 0.4617  || discrepancy=0.30 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.086 0.111 0.118 0.141 0.145 0.162 0.170  ||  -0.591 -0.329 -0.074 -0.012 0.169 0.196 0.307 0.356   || dis=0.01 || select=7/8
001/019-th : 0.125 0.123 0.122 0.126 0.123 0.129 0.125 0.126  ||  0.000 -0.014 -0.027 0.010 -0.014 0.028 0.004 0.009    || dis=0.00 || select=5/8
002/019-th : 0.120 0.125 0.127 0.131 0.129 0.127 0.122 0.120  ||  -0.040 0.003 0.020 0.048 0.037 0.016 -0.018 -0.041    || dis=0.00 || select=3/8
003/019-th : 0.125 0.127 0.124 0.124 0.126 0.126 0.124 0.124  ||  -0.005 0.016 -0.010 -0.007 0.004 0.008 -0.010 -0.010  || dis=0.00 || select=1/8
004/019-th : 0.118 0.120 0.123 0.123 0.130 0.129 0.129 0.128  ||  -0.057 -0.040 -0.015 -0.014 0.037 0.029 0.037 0.029   || dis=0.00 || select=4/8
005/019-th : 0.117 0.116 0.122 0.124 0.127 0.131 0.131 0.132  ||  -0.063 -0.074 -0.022 -0.004 0.017 0.048 0.050 0.053   || dis=0.00 || select=7/8
006/019-th : 0.113 0.112 0.117 0.128 0.127 0.131 0.134 0.137  ||  -0.097 -0.109 -0.063 0.022 0.020 0.051 0.073 0.095    || dis=0.00 || select=7/8
007/019-th : 0.079 0.087 0.101 0.120 0.131 0.145 0.166 0.171  ||  -0.425 -0.323 -0.170 0.001 0.089 0.187 0.323 0.355    || dis=0.01 || select=7/8
008/019-th : 0.066 0.080 0.099 0.139 0.137 0.156 0.165 0.157  ||  -0.576 -0.383 -0.175 0.168 0.152 0.278 0.334 0.290    || dis=0.01 || select=6/8
009/019-th : 0.106 0.105 0.102 0.115 0.125 0.138 0.145 0.164  ||  -0.156 -0.165 -0.198 -0.079 0.005 0.109 0.157 0.277   || dis=0.02 || select=7/8
010/019-th : 0.103 0.111 0.117 0.126 0.131 0.136 0.140 0.137  ||  -0.188 -0.113 -0.063 0.013 0.053 0.090 0.121 0.101    || dis=0.00 || select=6/8
011/019-th : 0.102 0.106 0.106 0.116 0.128 0.132 0.151 0.158  ||  -0.188 -0.154 -0.150 -0.060 0.035 0.065 0.199 0.242   || dis=0.01 || select=7/8
012/019-th : 0.111 0.116 0.118 0.117 0.129 0.131 0.136 0.142  ||  -0.115 -0.078 -0.062 -0.065 0.032 0.045 0.085 0.126   || dis=0.01 || select=7/8
013/019-th : 0.060 0.059 0.074 0.091 0.112 0.155 0.200 0.247  ||  -0.623 -0.634 -0.411 -0.204 0.002 0.328 0.582 0.793   || dis=0.05 || select=7/8
014/019-th : 0.065 0.074 0.087 0.110 0.126 0.158 0.188 0.192  ||  -0.596 -0.455 -0.303 -0.067 0.073 0.300 0.472 0.493   || dis=0.00 || select=7/8
015/019-th : 0.059 0.054 0.071 0.094 0.118 0.156 0.211 0.237  ||  -0.614 -0.715 -0.430 -0.155 0.078 0.350 0.654 0.773   || dis=0.03 || select=7/8
016/019-th : 0.064 0.076 0.096 0.127 0.138 0.157 0.174 0.169  ||  -0.617 -0.443 -0.203 0.075 0.154 0.286 0.387 0.357    || dis=0.00 || select=6/8
017/019-th : 0.116 0.112 0.119 0.125 0.129 0.129 0.133 0.136  ||  -0.067 -0.103 -0.043 0.001 0.038 0.035 0.068 0.092    || dis=0.00 || select=7/8
018/019-th : 0.081 0.097 0.110 0.126 0.129 0.136 0.153 0.168  ||  -0.409 -0.234 -0.101 0.033 0.060 0.107 0.227 0.322    || dis=0.02 || select=7/8
[epoch=120/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.025
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:45:48] [epoch=120/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.821 (1.821)  Prec@1 46.09 (46.09) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:45:54] [epoch=120/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.980 (2.201)  Prec@1 25.00 (38.28) Prec@5 81.55 (82.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.28 Prec@5 82.79 Error@1 61.72 Error@5 17.21 Loss:2.201
***[2020-01-29 06:45:54]*** VALID [epoch=120/600] loss = 2.200675, accuracy@1 = 38.28, accuracy@5 = 82.79 | Best-Valid-Acc@1=40.96, Error@1=59.04
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:45:54]*** start epoch=121/600 Time Left: [04:16:46], LR=[0.090296 ~ 0.090296], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=121, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.524524291508864, FLOP=40.81
[Search] : epoch=121/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:45:55] [epoch=121/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.829 (0.829)  Prec@1 71.88 (71.88) Prec@5 98.05 (98.05) Acls-loss 0.848 (0.848) FLOP-Loss 0.000 (0.000) Arch-Loss 0.848 (0.848)
**TRAIN** [2020-01-29 06:46:19] [epoch=121/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.844 (0.858)  Prec@1 72.02 (70.37) Prec@5 97.62 (97.56) Acls-loss 0.875 (0.884) FLOP-Loss 0.000 (0.053) Arch-Loss 0.875 (0.990)
 **TRAIN** Prec@1 70.37 Prec@5 97.56 Error@1 29.63 Error@5 2.44 Base-Loss:0.858, Arch-Loss=0.990
***[2020-01-29 06:46:19]*** TRAIN [epoch=121/600] base-loss = 0.857525, arch-loss = 0.989761, accuracy-1 = 70.37, accuracy-5 = 97.56
[epoch=121/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 6, 11, 12, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.553856)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.402 0.230 0.369  ||  0.0841 -0.4755 -0.0012  || discrepancy=0.03 || select=0/3
001/003-th : 0.394 0.160 0.447  ||  0.0097 -0.8918 0.1359  || discrepancy=0.05 || select=2/3
002/003-th : 0.222 0.240 0.538  ||  -0.4195 -0.3380 0.4670  || discrepancy=0.30 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.086 0.111 0.118 0.141 0.144 0.162 0.171  ||  -0.583 -0.329 -0.073 -0.010 0.163 0.187 0.305 0.357   || dis=0.01 || select=7/8
001/019-th : 0.125 0.124 0.123 0.127 0.123 0.127 0.126 0.125  ||  0.000 -0.007 -0.017 0.015 -0.015 0.015 0.007 0.002    || dis=0.00 || select=5/8
002/019-th : 0.121 0.126 0.128 0.130 0.129 0.126 0.121 0.119  ||  -0.033 0.011 0.027 0.041 0.033 0.010 -0.027 -0.045    || dis=0.00 || select=3/8
003/019-th : 0.126 0.128 0.124 0.124 0.126 0.126 0.123 0.124  ||  0.003 0.018 -0.011 -0.011 0.003 0.006 -0.015 -0.012   || dis=0.00 || select=1/8
004/019-th : 0.118 0.121 0.124 0.124 0.129 0.128 0.128 0.127  ||  -0.053 -0.031 -0.004 -0.009 0.036 0.027 0.028 0.018   || dis=0.00 || select=4/8
005/019-th : 0.116 0.116 0.121 0.125 0.130 0.131 0.130 0.131  ||  -0.070 -0.073 -0.024 0.002 0.044 0.053 0.046 0.047    || dis=0.00 || select=5/8
006/019-th : 0.114 0.112 0.118 0.127 0.126 0.132 0.134 0.137  ||  -0.094 -0.105 -0.056 0.016 0.009 0.056 0.069 0.093    || dis=0.00 || select=7/8
007/019-th : 0.079 0.087 0.103 0.118 0.133 0.143 0.166 0.171  ||  -0.426 -0.322 -0.154 -0.018 0.099 0.176 0.324 0.354   || dis=0.01 || select=7/8
008/019-th : 0.066 0.081 0.099 0.138 0.138 0.155 0.165 0.157  ||  -0.579 -0.379 -0.170 0.156 0.158 0.275 0.337 0.288    || dis=0.01 || select=6/8
009/019-th : 0.105 0.106 0.103 0.115 0.126 0.138 0.144 0.162  ||  -0.164 -0.155 -0.185 -0.073 0.015 0.108 0.152 0.268   || dis=0.02 || select=7/8
010/019-th : 0.103 0.111 0.118 0.125 0.131 0.136 0.140 0.135  ||  -0.182 -0.109 -0.047 0.006 0.052 0.090 0.121 0.086    || dis=0.00 || select=6/8
011/019-th : 0.104 0.106 0.104 0.117 0.128 0.131 0.152 0.158  ||  -0.174 -0.154 -0.171 -0.060 0.031 0.060 0.204 0.245   || dis=0.01 || select=7/8
012/019-th : 0.112 0.116 0.115 0.120 0.129 0.130 0.135 0.142  ||  -0.110 -0.074 -0.085 -0.037 0.031 0.039 0.079 0.128   || dis=0.01 || select=7/8
013/019-th : 0.059 0.060 0.073 0.092 0.113 0.154 0.201 0.248  ||  -0.640 -0.622 -0.423 -0.199 0.013 0.320 0.588 0.798   || dis=0.05 || select=7/8
014/019-th : 0.065 0.074 0.087 0.109 0.129 0.155 0.187 0.194  ||  -0.586 -0.455 -0.300 -0.074 0.091 0.277 0.465 0.500   || dis=0.01 || select=7/8
015/019-th : 0.060 0.054 0.071 0.094 0.118 0.153 0.212 0.240  ||  -0.604 -0.715 -0.436 -0.157 0.072 0.333 0.660 0.787   || dis=0.03 || select=7/8
016/019-th : 0.063 0.076 0.096 0.129 0.136 0.157 0.175 0.167  ||  -0.621 -0.437 -0.205 0.088 0.141 0.287 0.395 0.350    || dis=0.01 || select=6/8
017/019-th : 0.117 0.113 0.119 0.124 0.130 0.129 0.132 0.136  ||  -0.063 -0.092 -0.045 -0.005 0.046 0.035 0.057 0.087   || dis=0.00 || select=7/8
018/019-th : 0.081 0.096 0.109 0.126 0.131 0.133 0.153 0.170  ||  -0.405 -0.238 -0.108 0.035 0.071 0.090 0.224 0.331    || dis=0.02 || select=7/8
[epoch=121/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.025
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:46:19] [epoch=121/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.659 (1.659)  Prec@1 48.44 (48.44) Prec@5 94.14 (94.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:46:25] [epoch=121/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 3.925 (2.000)  Prec@1 26.79 (39.39) Prec@5 79.76 (84.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.39 Prec@5 84.34 Error@1 60.61 Error@5 15.66 Loss:2.000
***[2020-01-29 06:46:25]*** VALID [epoch=121/600] loss = 2.000192, accuracy@1 = 39.39, accuracy@5 = 84.34 | Best-Valid-Acc@1=40.96, Error@1=59.04
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:46:25]*** start epoch=122/600 Time Left: [04:16:10], LR=[0.090141 ~ 0.090141], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=122, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.516902814218231, FLOP=40.81
[Search] : epoch=122/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:46:26] [epoch=122/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.890 (0.890)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 1.007 (1.007) FLOP-Loss 0.000 (0.000) Arch-Loss 1.007 (1.007)
**TRAIN** [2020-01-29 06:46:50] [epoch=122/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.823 (0.856)  Prec@1 72.02 (70.85) Prec@5 97.02 (97.66) Acls-loss 0.811 (0.894) FLOP-Loss 0.000 (0.026) Arch-Loss 0.811 (0.947)
 **TRAIN** Prec@1 70.85 Prec@5 97.66 Error@1 29.15 Error@5 2.34 Base-Loss:0.856, Arch-Loss=0.947
***[2020-01-29 06:46:50]*** TRAIN [epoch=122/600] base-loss = 0.856176, arch-loss = 0.946578, accuracy-1 = 70.85, accuracy-5 = 97.66
[epoch=122/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 12, 12, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.862656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.401 0.231 0.367  ||  0.0862 -0.4646 -0.0021  || discrepancy=0.03 || select=0/3
001/003-th : 0.392 0.160 0.447  ||  0.0086 -0.8860 0.1399  || discrepancy=0.05 || select=2/3
002/003-th : 0.217 0.240 0.543  ||  -0.4347 -0.3356 0.4817  || discrepancy=0.30 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.087 0.111 0.117 0.138 0.145 0.164 0.172  ||  -0.584 -0.319 -0.079 -0.026 0.145 0.194 0.316 0.360   || dis=0.01 || select=7/8
001/019-th : 0.125 0.123 0.122 0.128 0.124 0.126 0.126 0.125  ||  0.001 -0.012 -0.025 0.024 -0.006 0.013 0.010 0.002    || dis=0.00 || select=3/8
002/019-th : 0.120 0.125 0.128 0.130 0.130 0.126 0.122 0.119  ||  -0.038 0.000 0.030 0.046 0.041 0.015 -0.022 -0.044    || dis=0.00 || select=3/8
003/019-th : 0.126 0.127 0.123 0.124 0.125 0.127 0.124 0.124  ||  0.002 0.017 -0.019 -0.007 -0.003 0.011 -0.011 -0.011  || dis=0.00 || select=1/8
004/019-th : 0.117 0.121 0.124 0.123 0.129 0.129 0.128 0.128  ||  -0.062 -0.033 -0.004 -0.011 0.035 0.037 0.029 0.024   || dis=0.00 || select=5/8
005/019-th : 0.116 0.115 0.122 0.124 0.128 0.134 0.131 0.130  ||  -0.072 -0.080 -0.023 -0.003 0.024 0.075 0.053 0.046   || dis=0.00 || select=5/8
006/019-th : 0.113 0.113 0.120 0.126 0.126 0.132 0.134 0.137  ||  -0.099 -0.103 -0.043 0.007 0.011 0.054 0.074 0.092    || dis=0.00 || select=7/8
007/019-th : 0.078 0.087 0.103 0.118 0.131 0.143 0.165 0.174  ||  -0.430 -0.322 -0.158 -0.018 0.084 0.177 0.320 0.372   || dis=0.01 || select=7/8
008/019-th : 0.066 0.081 0.098 0.136 0.138 0.156 0.166 0.158  ||  -0.578 -0.376 -0.181 0.145 0.158 0.282 0.340 0.290    || dis=0.01 || select=6/8
009/019-th : 0.106 0.106 0.103 0.116 0.126 0.137 0.145 0.162  ||  -0.158 -0.156 -0.186 -0.066 0.013 0.097 0.154 0.266   || dis=0.02 || select=7/8
010/019-th : 0.102 0.111 0.118 0.123 0.131 0.138 0.140 0.136  ||  -0.192 -0.111 -0.046 -0.005 0.058 0.106 0.119 0.090   || dis=0.00 || select=6/8
011/019-th : 0.104 0.106 0.104 0.117 0.127 0.133 0.151 0.158  ||  -0.171 -0.157 -0.177 -0.059 0.026 0.075 0.198 0.247   || dis=0.01 || select=7/8
012/019-th : 0.112 0.115 0.115 0.119 0.129 0.130 0.135 0.143  ||  -0.111 -0.080 -0.082 -0.047 0.034 0.040 0.078 0.136   || dis=0.01 || select=7/8
013/019-th : 0.058 0.060 0.072 0.090 0.113 0.152 0.202 0.252  ||  -0.651 -0.611 -0.431 -0.211 0.013 0.313 0.594 0.819   || dis=0.05 || select=7/8
014/019-th : 0.065 0.073 0.087 0.109 0.129 0.155 0.187 0.196  ||  -0.595 -0.468 -0.301 -0.077 0.096 0.279 0.465 0.517   || dis=0.01 || select=7/8
015/019-th : 0.059 0.054 0.070 0.093 0.116 0.155 0.212 0.242  ||  -0.618 -0.710 -0.448 -0.164 0.062 0.351 0.667 0.800   || dis=0.03 || select=7/8
016/019-th : 0.063 0.076 0.096 0.128 0.138 0.157 0.175 0.166  ||  -0.625 -0.435 -0.205 0.085 0.156 0.289 0.397 0.343    || dis=0.01 || select=6/8
017/019-th : 0.116 0.114 0.118 0.124 0.130 0.130 0.132 0.135  ||  -0.069 -0.084 -0.052 -0.006 0.042 0.046 0.060 0.084   || dis=0.00 || select=7/8
018/019-th : 0.082 0.096 0.109 0.126 0.131 0.135 0.151 0.170  ||  -0.403 -0.236 -0.114 0.036 0.070 0.100 0.214 0.332    || dis=0.02 || select=7/8
[epoch=122/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.026
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:46:51] [epoch=122/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.620 (1.620)  Prec@1 46.88 (46.88) Prec@5 91.41 (91.41) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:46:57] [epoch=122/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.520 (1.952)  Prec@1 49.40 (42.27) Prec@5 89.29 (86.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.27 Prec@5 86.38 Error@1 57.73 Error@5 13.62 Loss:1.952
***[2020-01-29 06:46:57]*** VALID [epoch=122/600] loss = 1.952098, accuracy@1 = 42.27, accuracy@5 = 86.38 | Best-Valid-Acc@1=40.96, Error@1=59.04
Currently, the best validation accuracy found at 122-epoch :: acc@1=42.27, acc@5=86.38, error@1=57.73, error@5=13.62, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:46:57]*** start epoch=123/600 Time Left: [04:15:36], LR=[0.089984 ~ 0.089984], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=123, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.509227413293372, FLOP=40.81
[Search] : epoch=123/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:46:58] [epoch=123/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.018 (1.018)  Prec@1 65.62 (65.62) Prec@5 96.48 (96.48) Acls-loss 0.947 (0.947) FLOP-Loss 0.000 (0.000) Arch-Loss 0.947 (0.947)
**TRAIN** [2020-01-29 06:47:22] [epoch=123/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.740 (0.861)  Prec@1 76.79 (70.49) Prec@5 97.62 (97.58) Acls-loss 0.779 (0.879) FLOP-Loss 0.000 (0.026) Arch-Loss 0.779 (0.932)
 **TRAIN** Prec@1 70.49 Prec@5 97.58 Error@1 29.51 Error@5 2.42 Base-Loss:0.861, Arch-Loss=0.932
***[2020-01-29 06:47:22]*** TRAIN [epoch=123/600] base-loss = 0.860995, arch-loss = 0.932193, accuracy-1 = 70.49, accuracy-5 = 97.58
[epoch=123/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 12, 12, 12, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.862656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.400 0.236 0.364  ||  0.0900 -0.4397 -0.0061  || discrepancy=0.04 || select=0/3
001/003-th : 0.391 0.159 0.449  ||  0.0076 -0.8904 0.1450  || discrepancy=0.06 || select=2/3
002/003-th : 0.213 0.238 0.549  ||  -0.4504 -0.3364 0.4972  || discrepancy=0.31 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.087 0.109 0.115 0.141 0.148 0.163 0.172  ||  -0.595 -0.317 -0.087 -0.041 0.167 0.212 0.313 0.363   || dis=0.01 || select=7/8
001/019-th : 0.125 0.123 0.121 0.128 0.126 0.127 0.126 0.125  ||  -0.001 -0.015 -0.029 0.024 0.007 0.017 0.014 -0.001   || dis=0.00 || select=3/8
002/019-th : 0.120 0.124 0.129 0.130 0.130 0.126 0.123 0.120  ||  -0.039 -0.008 0.032 0.042 0.040 0.012 -0.015 -0.041   || dis=0.00 || select=3/8
003/019-th : 0.125 0.128 0.123 0.124 0.125 0.128 0.123 0.124  ||  -0.004 0.019 -0.020 -0.006 0.002 0.020 -0.018 -0.006  || dis=0.00 || select=5/8
004/019-th : 0.117 0.121 0.124 0.122 0.130 0.130 0.129 0.127  ||  -0.065 -0.028 -0.007 -0.017 0.045 0.045 0.031 0.017   || dis=0.00 || select=5/8
005/019-th : 0.114 0.115 0.121 0.126 0.129 0.132 0.132 0.131  ||  -0.091 -0.075 -0.024 0.014 0.038 0.060 0.059 0.051    || dis=0.00 || select=5/8
006/019-th : 0.114 0.113 0.119 0.124 0.127 0.132 0.134 0.137  ||  -0.095 -0.097 -0.050 -0.008 0.017 0.058 0.072 0.092   || dis=0.00 || select=7/8
007/019-th : 0.078 0.088 0.102 0.117 0.133 0.142 0.165 0.175  ||  -0.436 -0.314 -0.163 -0.028 0.103 0.169 0.317 0.375   || dis=0.01 || select=7/8
008/019-th : 0.066 0.080 0.098 0.136 0.138 0.157 0.166 0.158  ||  -0.581 -0.386 -0.185 0.145 0.161 0.289 0.344 0.293    || dis=0.01 || select=6/8
009/019-th : 0.105 0.105 0.103 0.115 0.128 0.136 0.145 0.163  ||  -0.163 -0.170 -0.184 -0.070 0.033 0.097 0.156 0.272   || dis=0.02 || select=7/8
010/019-th : 0.103 0.112 0.119 0.121 0.131 0.138 0.141 0.136  ||  -0.189 -0.106 -0.043 -0.028 0.051 0.108 0.124 0.092   || dis=0.00 || select=6/8
011/019-th : 0.105 0.103 0.105 0.117 0.126 0.134 0.151 0.159  ||  -0.161 -0.184 -0.167 -0.053 0.020 0.082 0.198 0.248   || dis=0.01 || select=7/8
012/019-th : 0.112 0.115 0.114 0.121 0.129 0.130 0.135 0.144  ||  -0.112 -0.086 -0.094 -0.034 0.033 0.041 0.078 0.143   || dis=0.01 || select=7/8
013/019-th : 0.057 0.060 0.071 0.090 0.113 0.149 0.205 0.255  ||  -0.658 -0.614 -0.448 -0.213 0.022 0.298 0.614 0.835   || dis=0.05 || select=7/8
014/019-th : 0.064 0.073 0.086 0.106 0.129 0.157 0.187 0.199  ||  -0.601 -0.475 -0.305 -0.095 0.095 0.292 0.468 0.533   || dis=0.01 || select=7/8
015/019-th : 0.058 0.053 0.069 0.094 0.114 0.153 0.213 0.246  ||  -0.630 -0.719 -0.450 -0.149 0.052 0.341 0.674 0.817   || dis=0.03 || select=7/8
016/019-th : 0.063 0.076 0.097 0.127 0.137 0.159 0.175 0.166  ||  -0.631 -0.440 -0.194 0.077 0.150 0.303 0.394 0.346    || dis=0.01 || select=6/8
017/019-th : 0.116 0.114 0.118 0.124 0.129 0.130 0.133 0.136  ||  -0.074 -0.087 -0.049 -0.006 0.036 0.042 0.068 0.088   || dis=0.00 || select=7/8
018/019-th : 0.082 0.097 0.109 0.126 0.131 0.136 0.149 0.170  ||  -0.402 -0.233 -0.115 0.032 0.073 0.107 0.202 0.335    || dis=0.02 || select=7/8
[epoch=123/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.027
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:47:22] [epoch=123/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.284 (2.284)  Prec@1 24.22 (24.22) Prec@5 69.14 (69.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:47:28] [epoch=123/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.587 (2.046)  Prec@1 45.24 (40.91) Prec@5 89.88 (84.56) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.91 Prec@5 84.56 Error@1 59.09 Error@5 15.44 Loss:2.046
***[2020-01-29 06:47:28]*** VALID [epoch=123/600] loss = 2.045577, accuracy@1 = 40.91, accuracy@5 = 84.56 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:47:28]*** start epoch=124/600 Time Left: [04:15:00], LR=[0.089826 ~ 0.089826], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=124, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.501498299159281, FLOP=40.81
[Search] : epoch=124/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:47:29] [epoch=124/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.845 (0.845)  Prec@1 70.31 (70.31) Prec@5 98.05 (98.05) Acls-loss 0.800 (0.800) FLOP-Loss 0.000 (0.000) Arch-Loss 0.800 (0.800)
**TRAIN** [2020-01-29 06:47:53] [epoch=124/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.833 (0.853)  Prec@1 73.81 (70.77) Prec@5 96.43 (97.53) Acls-loss 0.802 (0.883) FLOP-Loss 0.000 (0.027) Arch-Loss 0.802 (0.936)
 **TRAIN** Prec@1 70.77 Prec@5 97.53 Error@1 29.23 Error@5 2.47 Base-Loss:0.853, Arch-Loss=0.936
***[2020-01-29 06:47:53]*** TRAIN [epoch=124/600] base-loss = 0.852859, arch-loss = 0.936226, accuracy-1 = 70.77, accuracy-5 = 97.53
[epoch=124/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 12, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.553856)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.400 0.239 0.361  ||  0.0929 -0.4219 -0.0087  || discrepancy=0.04 || select=0/3
001/003-th : 0.390 0.157 0.453  ||  0.0041 -0.9083 0.1542  || discrepancy=0.06 || select=2/3
002/003-th : 0.208 0.236 0.556  ||  -0.4676 -0.3403 0.5147  || discrepancy=0.32 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.087 0.110 0.115 0.141 0.147 0.163 0.172  ||  -0.606 -0.318 -0.082 -0.036 0.169 0.208 0.312 0.369   || dis=0.01 || select=7/8
001/019-th : 0.125 0.123 0.122 0.126 0.127 0.127 0.126 0.125  ||  -0.000 -0.013 -0.026 0.013 0.015 0.017 0.008 0.000    || dis=0.00 || select=5/8
002/019-th : 0.120 0.123 0.128 0.131 0.130 0.127 0.123 0.119  ||  -0.040 -0.011 0.024 0.050 0.042 0.016 -0.013 -0.042   || dis=0.00 || select=3/8
003/019-th : 0.124 0.127 0.122 0.123 0.126 0.128 0.125 0.125  ||  -0.007 0.015 -0.023 -0.016 0.006 0.019 -0.006 -0.004  || dis=0.00 || select=5/8
004/019-th : 0.116 0.121 0.122 0.124 0.129 0.130 0.131 0.128  ||  -0.070 -0.028 -0.026 -0.007 0.033 0.040 0.045 0.023   || dis=0.00 || select=6/8
005/019-th : 0.113 0.115 0.123 0.127 0.129 0.132 0.132 0.130  ||  -0.097 -0.081 -0.013 0.026 0.037 0.059 0.060 0.048    || dis=0.00 || select=6/8
006/019-th : 0.114 0.113 0.119 0.122 0.127 0.133 0.134 0.138  ||  -0.091 -0.104 -0.047 -0.021 0.014 0.061 0.071 0.097   || dis=0.00 || select=7/8
007/019-th : 0.077 0.087 0.101 0.117 0.135 0.143 0.164 0.176  ||  -0.439 -0.317 -0.177 -0.022 0.114 0.175 0.310 0.381   || dis=0.01 || select=7/8
008/019-th : 0.065 0.079 0.098 0.134 0.141 0.156 0.167 0.160  ||  -0.590 -0.396 -0.186 0.131 0.181 0.281 0.350 0.307    || dis=0.01 || select=6/8
009/019-th : 0.105 0.105 0.103 0.114 0.128 0.136 0.145 0.162  ||  -0.161 -0.162 -0.182 -0.081 0.033 0.097 0.155 0.271   || dis=0.02 || select=7/8
010/019-th : 0.102 0.111 0.119 0.123 0.131 0.137 0.140 0.136  ||  -0.193 -0.108 -0.043 -0.012 0.057 0.100 0.119 0.093   || dis=0.00 || select=6/8
011/019-th : 0.106 0.101 0.105 0.118 0.126 0.136 0.150 0.159  ||  -0.156 -0.198 -0.167 -0.050 0.015 0.094 0.194 0.253   || dis=0.01 || select=7/8
012/019-th : 0.111 0.114 0.114 0.121 0.128 0.131 0.136 0.146  ||  -0.119 -0.093 -0.095 -0.029 0.021 0.048 0.081 0.154   || dis=0.01 || select=7/8
013/019-th : 0.057 0.059 0.070 0.089 0.113 0.151 0.205 0.256  ||  -0.657 -0.633 -0.458 -0.213 0.028 0.312 0.619 0.842   || dis=0.05 || select=7/8
014/019-th : 0.064 0.072 0.086 0.105 0.128 0.157 0.187 0.200  ||  -0.598 -0.478 -0.304 -0.105 0.092 0.295 0.474 0.538   || dis=0.01 || select=7/8
015/019-th : 0.057 0.053 0.068 0.094 0.111 0.154 0.214 0.248  ||  -0.633 -0.724 -0.466 -0.138 0.029 0.353 0.681 0.829   || dis=0.03 || select=7/8
016/019-th : 0.062 0.076 0.096 0.127 0.135 0.161 0.176 0.167  ||  -0.642 -0.440 -0.199 0.080 0.137 0.315 0.402 0.350    || dis=0.01 || select=6/8
017/019-th : 0.116 0.115 0.119 0.123 0.129 0.129 0.134 0.136  ||  -0.075 -0.079 -0.048 -0.014 0.033 0.033 0.073 0.087   || dis=0.00 || select=7/8
018/019-th : 0.081 0.097 0.106 0.126 0.132 0.136 0.150 0.173  ||  -0.404 -0.231 -0.143 0.029 0.075 0.109 0.208 0.346    || dis=0.02 || select=7/8
[epoch=124/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.029
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:47:53] [epoch=124/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.038 (2.038)  Prec@1 28.52 (28.52) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:47:59] [epoch=124/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.650 (2.338)  Prec@1 39.88 (36.22) Prec@5 86.90 (80.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.22 Prec@5 80.84 Error@1 63.78 Error@5 19.16 Loss:2.338
***[2020-01-29 06:47:59]*** VALID [epoch=124/600] loss = 2.337685, accuracy@1 = 36.22, accuracy@5 = 80.84 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:47:59]*** start epoch=125/600 Time Left: [04:14:23], LR=[0.089668 ~ 0.089668], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=125, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.493715683713526, FLOP=40.81
[Search] : epoch=125/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:48:00] [epoch=125/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.826 (0.826)  Prec@1 73.05 (73.05) Prec@5 99.22 (99.22) Acls-loss 0.938 (0.938) FLOP-Loss 0.000 (0.000) Arch-Loss 0.938 (0.938)
**TRAIN** [2020-01-29 06:48:24] [epoch=125/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.909 (0.872)  Prec@1 69.64 (70.11) Prec@5 95.24 (97.57) Acls-loss 0.800 (0.890) FLOP-Loss 0.000 (0.000) Arch-Loss 0.800 (0.890)
 **TRAIN** Prec@1 70.11 Prec@5 97.57 Error@1 29.89 Error@5 2.43 Base-Loss:0.872, Arch-Loss=0.890
***[2020-01-29 06:48:24]*** TRAIN [epoch=125/600] base-loss = 0.872046, arch-loss = 0.890315, accuracy-1 = 70.11, accuracy-5 = 97.57
[epoch=125/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 12, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.558976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.396 0.242 0.362  ||  0.0867 -0.4077 -0.0019  || discrepancy=0.03 || select=0/3
001/003-th : 0.385 0.156 0.458  ||  -0.0059 -0.9092 0.1679  || discrepancy=0.07 || select=2/3
002/003-th : 0.205 0.233 0.562  ||  -0.4795 -0.3509 0.5284  || discrepancy=0.33 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.085 0.110 0.115 0.140 0.147 0.164 0.175  ||  -0.609 -0.337 -0.081 -0.031 0.159 0.207 0.321 0.382   || dis=0.01 || select=7/8
001/019-th : 0.123 0.123 0.122 0.126 0.128 0.127 0.127 0.125  ||  -0.010 -0.016 -0.024 0.011 0.025 0.016 0.015 0.004    || dis=0.00 || select=4/8
002/019-th : 0.119 0.122 0.127 0.131 0.131 0.127 0.124 0.121  ||  -0.047 -0.023 0.017 0.048 0.050 0.017 -0.006 -0.031   || dis=0.00 || select=4/8
003/019-th : 0.124 0.127 0.122 0.122 0.125 0.129 0.126 0.126  ||  -0.014 0.010 -0.026 -0.025 -0.000 0.026 0.004 0.004   || dis=0.00 || select=5/8
004/019-th : 0.116 0.120 0.120 0.124 0.129 0.130 0.132 0.130  ||  -0.076 -0.039 -0.038 -0.009 0.032 0.044 0.052 0.037   || dis=0.00 || select=6/8
005/019-th : 0.112 0.115 0.123 0.125 0.128 0.131 0.134 0.131  ||  -0.105 -0.079 -0.013 0.006 0.031 0.055 0.076 0.054    || dis=0.00 || select=6/8
006/019-th : 0.113 0.112 0.121 0.122 0.127 0.132 0.135 0.139  ||  -0.097 -0.112 -0.034 -0.026 0.014 0.051 0.076 0.107   || dis=0.00 || select=7/8
007/019-th : 0.077 0.085 0.101 0.119 0.133 0.144 0.165 0.175  ||  -0.438 -0.341 -0.175 -0.007 0.101 0.185 0.321 0.380   || dis=0.01 || select=7/8
008/019-th : 0.065 0.079 0.096 0.132 0.141 0.156 0.169 0.162  ||  -0.597 -0.395 -0.199 0.117 0.179 0.284 0.364 0.319    || dis=0.01 || select=6/8
009/019-th : 0.104 0.104 0.104 0.115 0.128 0.137 0.145 0.162  ||  -0.175 -0.171 -0.174 -0.070 0.038 0.101 0.161 0.273   || dis=0.02 || select=7/8
010/019-th : 0.100 0.111 0.118 0.122 0.134 0.136 0.141 0.137  ||  -0.211 -0.114 -0.048 -0.014 0.077 0.093 0.130 0.101   || dis=0.00 || select=6/8
011/019-th : 0.104 0.101 0.102 0.118 0.126 0.138 0.150 0.160  ||  -0.171 -0.198 -0.186 -0.048 0.021 0.114 0.197 0.260   || dis=0.01 || select=7/8
012/019-th : 0.110 0.114 0.114 0.122 0.127 0.132 0.135 0.147  ||  -0.130 -0.095 -0.092 -0.020 0.021 0.053 0.076 0.162   || dis=0.01 || select=7/8
013/019-th : 0.055 0.058 0.070 0.089 0.111 0.152 0.207 0.258  ||  -0.700 -0.635 -0.446 -0.205 0.014 0.324 0.633 0.853   || dis=0.05 || select=7/8
014/019-th : 0.062 0.073 0.084 0.106 0.130 0.155 0.188 0.203  ||  -0.628 -0.463 -0.331 -0.096 0.108 0.287 0.479 0.556   || dis=0.02 || select=7/8
015/019-th : 0.057 0.052 0.066 0.093 0.110 0.156 0.214 0.253  ||  -0.639 -0.730 -0.485 -0.148 0.019 0.372 0.686 0.857   || dis=0.04 || select=7/8
016/019-th : 0.062 0.075 0.096 0.128 0.135 0.159 0.177 0.168  ||  -0.645 -0.454 -0.203 0.089 0.141 0.304 0.410 0.358    || dis=0.01 || select=6/8
017/019-th : 0.116 0.115 0.118 0.121 0.128 0.131 0.134 0.137  ||  -0.074 -0.078 -0.058 -0.028 0.028 0.048 0.075 0.091   || dis=0.00 || select=7/8
018/019-th : 0.081 0.096 0.107 0.123 0.132 0.135 0.150 0.174  ||  -0.409 -0.234 -0.130 0.010 0.080 0.104 0.208 0.358    || dis=0.02 || select=7/8
[epoch=125/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.030
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:48:24] [epoch=125/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.936 (1.936)  Prec@1 37.11 (37.11) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:48:30] [epoch=125/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.282 (2.223)  Prec@1 57.14 (37.60) Prec@5 95.24 (82.23) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.60 Prec@5 82.23 Error@1 62.40 Error@5 17.77 Loss:2.223
***[2020-01-29 06:48:30]*** VALID [epoch=125/600] loss = 2.223190, accuracy@1 = 37.60, accuracy@5 = 82.23 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:48:30]*** start epoch=126/600 Time Left: [04:13:48], LR=[0.089508 ~ 0.089508], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=126, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.485879780320442, FLOP=40.81
[Search] : epoch=126/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:48:31] [epoch=126/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.933 (0.933)  Prec@1 67.19 (67.19) Prec@5 96.48 (96.48) Acls-loss 0.792 (0.792) FLOP-Loss 0.000 (0.000) Arch-Loss 0.792 (0.792)
**TRAIN** [2020-01-29 06:48:55] [epoch=126/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.796 (0.856)  Prec@1 70.83 (70.78) Prec@5 98.81 (97.69) Acls-loss 0.902 (0.869) FLOP-Loss 0.000 (0.000) Arch-Loss 0.902 (0.869)
 **TRAIN** Prec@1 70.78 Prec@5 97.69 Error@1 29.22 Error@5 2.31 Base-Loss:0.856, Arch-Loss=0.869
***[2020-01-29 06:48:55]*** TRAIN [epoch=126/600] base-loss = 0.855712, arch-loss = 0.868791, accuracy-1 = 70.78, accuracy-5 = 97.69
[epoch=126/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 12, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.558976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.394 0.241 0.365  ||  0.0817 -0.4117 0.0057  || discrepancy=0.03 || select=0/3
001/003-th : 0.382 0.155 0.463  ||  -0.0122 -0.9141 0.1787  || discrepancy=0.08 || select=2/3
002/003-th : 0.201 0.230 0.569  ||  -0.4943 -0.3595 0.5445  || discrepancy=0.34 || select=2/3
-----------------------------------------------
000/019-th : 0.064 0.085 0.108 0.113 0.141 0.145 0.167 0.176  ||  -0.615 -0.340 -0.097 -0.047 0.172 0.200 0.339 0.394   || dis=0.01 || select=7/8
001/019-th : 0.123 0.121 0.121 0.126 0.128 0.128 0.127 0.126  ||  -0.015 -0.026 -0.029 0.012 0.029 0.025 0.020 0.009    || dis=0.00 || select=4/8
002/019-th : 0.118 0.122 0.126 0.130 0.132 0.127 0.124 0.121  ||  -0.055 -0.017 0.016 0.044 0.056 0.019 -0.003 -0.032   || dis=0.00 || select=4/8
003/019-th : 0.123 0.126 0.122 0.121 0.126 0.128 0.127 0.127  ||  -0.017 0.005 -0.025 -0.033 0.007 0.020 0.009 0.010    || dis=0.00 || select=5/8
004/019-th : 0.116 0.119 0.122 0.124 0.127 0.131 0.132 0.131  ||  -0.076 -0.053 -0.027 -0.008 0.013 0.044 0.057 0.044   || dis=0.00 || select=6/8
005/019-th : 0.111 0.114 0.121 0.123 0.131 0.133 0.135 0.133  ||  -0.109 -0.089 -0.025 -0.012 0.050 0.064 0.080 0.065   || dis=0.00 || select=6/8
006/019-th : 0.112 0.112 0.121 0.119 0.128 0.131 0.136 0.141  ||  -0.111 -0.113 -0.035 -0.046 0.021 0.047 0.086 0.122   || dis=0.00 || select=7/8
007/019-th : 0.077 0.083 0.101 0.119 0.133 0.143 0.166 0.178  ||  -0.441 -0.365 -0.170 -0.007 0.109 0.175 0.328 0.397   || dis=0.01 || select=7/8
008/019-th : 0.064 0.076 0.096 0.133 0.141 0.158 0.168 0.164  ||  -0.602 -0.429 -0.198 0.124 0.187 0.296 0.361 0.334    || dis=0.00 || select=6/8
009/019-th : 0.103 0.103 0.103 0.113 0.128 0.137 0.148 0.165  ||  -0.183 -0.183 -0.185 -0.088 0.036 0.105 0.178 0.292   || dis=0.02 || select=7/8
010/019-th : 0.100 0.110 0.118 0.122 0.133 0.137 0.141 0.139  ||  -0.212 -0.116 -0.054 -0.018 0.070 0.097 0.128 0.113   || dis=0.00 || select=6/8
011/019-th : 0.103 0.101 0.101 0.118 0.126 0.139 0.151 0.161  ||  -0.180 -0.199 -0.198 -0.043 0.020 0.118 0.204 0.267   || dis=0.01 || select=7/8
012/019-th : 0.108 0.112 0.113 0.123 0.129 0.133 0.135 0.147  ||  -0.140 -0.106 -0.097 -0.017 0.032 0.062 0.080 0.167   || dis=0.01 || select=7/8
013/019-th : 0.054 0.058 0.069 0.090 0.110 0.151 0.210 0.258  ||  -0.705 -0.637 -0.466 -0.194 0.003 0.326 0.653 0.860   || dis=0.05 || select=7/8
014/019-th : 0.061 0.072 0.082 0.104 0.129 0.154 0.192 0.207  ||  -0.648 -0.480 -0.349 -0.105 0.109 0.289 0.509 0.580   || dis=0.01 || select=7/8
015/019-th : 0.056 0.051 0.065 0.092 0.110 0.155 0.211 0.259  ||  -0.645 -0.745 -0.498 -0.148 0.030 0.374 0.680 0.885   || dis=0.05 || select=7/8
016/019-th : 0.061 0.074 0.095 0.128 0.137 0.159 0.178 0.169  ||  -0.654 -0.463 -0.212 0.087 0.153 0.305 0.420 0.365    || dis=0.01 || select=6/8
017/019-th : 0.115 0.114 0.118 0.121 0.128 0.131 0.134 0.138  ||  -0.078 -0.088 -0.054 -0.027 0.024 0.050 0.071 0.103   || dis=0.00 || select=7/8
018/019-th : 0.081 0.096 0.109 0.122 0.131 0.136 0.151 0.174  ||  -0.406 -0.240 -0.114 -0.003 0.072 0.109 0.216 0.353   || dis=0.02 || select=7/8
[epoch=126/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.031
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:48:56] [epoch=126/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.704 (2.704)  Prec@1 44.92 (44.92) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:49:02] [epoch=126/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.732 (2.192)  Prec@1 41.67 (37.47) Prec@5 82.14 (83.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.47 Prec@5 83.28 Error@1 62.53 Error@5 16.72 Loss:2.192
***[2020-01-29 06:49:02]*** VALID [epoch=126/600] loss = 2.192031, accuracy@1 = 37.47, accuracy@5 = 83.28 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:49:02]*** start epoch=127/600 Time Left: [04:13:12], LR=[0.089347 ~ 0.089347], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=127, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.477990803805277, FLOP=40.81
[Search] : epoch=127/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:49:02] [epoch=127/600][000/098] Time 0.72 (0.72) Data 0.34 (0.34) Base-Loss 1.004 (1.004)  Prec@1 66.80 (66.80) Prec@5 96.88 (96.88) Acls-loss 0.756 (0.756) FLOP-Loss 0.000 (0.000) Arch-Loss 0.756 (0.756)
**TRAIN** [2020-01-29 06:49:27] [epoch=127/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.817 (0.840)  Prec@1 74.40 (71.02) Prec@5 98.81 (97.70) Acls-loss 0.850 (0.873) FLOP-Loss 0.000 (0.080) Arch-Loss 0.850 (1.033)
 **TRAIN** Prec@1 71.02 Prec@5 97.70 Error@1 28.98 Error@5 2.30 Base-Loss:0.840, Arch-Loss=1.033
***[2020-01-29 06:49:27]*** TRAIN [epoch=127/600] base-loss = 0.840401, arch-loss = 1.033305, accuracy-1 = 71.02, accuracy-5 = 97.70
[epoch=127/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 6, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.061312)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.399 0.240 0.361  ||  0.0947 -0.4150 -0.0048  || discrepancy=0.04 || select=0/3
001/003-th : 0.387 0.154 0.459  ||  0.0015 -0.9233 0.1704  || discrepancy=0.07 || select=2/3
002/003-th : 0.200 0.234 0.566  ||  -0.4955 -0.3396 0.5438  || discrepancy=0.33 || select=2/3
-----------------------------------------------
000/019-th : 0.064 0.085 0.109 0.113 0.140 0.145 0.167 0.176  ||  -0.619 -0.336 -0.089 -0.053 0.166 0.202 0.340 0.395   || dis=0.01 || select=7/8
001/019-th : 0.125 0.123 0.122 0.128 0.127 0.126 0.125 0.124  ||  0.000 -0.015 -0.018 0.027 0.017 0.011 0.004 -0.004    || dis=0.00 || select=3/8
002/019-th : 0.119 0.124 0.128 0.130 0.132 0.125 0.122 0.118  ||  -0.041 -0.002 0.031 0.047 0.061 0.009 -0.017 -0.051   || dis=0.00 || select=4/8
003/019-th : 0.124 0.127 0.123 0.124 0.126 0.127 0.125 0.124  ||  -0.009 0.016 -0.014 -0.010 0.005 0.013 -0.002 -0.005  || dis=0.00 || select=1/8
004/019-th : 0.117 0.118 0.123 0.124 0.126 0.131 0.132 0.130  ||  -0.065 -0.055 -0.019 -0.005 0.006 0.046 0.052 0.036   || dis=0.00 || select=6/8
005/019-th : 0.113 0.116 0.122 0.126 0.128 0.130 0.134 0.132  ||  -0.095 -0.076 -0.019 0.008 0.024 0.043 0.071 0.054    || dis=0.00 || select=6/8
006/019-th : 0.113 0.112 0.123 0.120 0.128 0.129 0.135 0.141  ||  -0.104 -0.107 -0.012 -0.044 0.025 0.028 0.076 0.117   || dis=0.01 || select=7/8
007/019-th : 0.078 0.084 0.100 0.120 0.133 0.140 0.166 0.178  ||  -0.429 -0.351 -0.179 -0.001 0.106 0.153 0.327 0.392   || dis=0.01 || select=7/8
008/019-th : 0.065 0.076 0.096 0.131 0.142 0.158 0.167 0.164  ||  -0.588 -0.431 -0.203 0.113 0.193 0.299 0.351 0.336    || dis=0.00 || select=6/8
009/019-th : 0.105 0.103 0.104 0.114 0.128 0.137 0.146 0.164  ||  -0.168 -0.187 -0.176 -0.081 0.036 0.099 0.169 0.283   || dis=0.02 || select=7/8
010/019-th : 0.101 0.111 0.120 0.124 0.132 0.136 0.139 0.138  ||  -0.206 -0.114 -0.036 -0.004 0.063 0.093 0.115 0.103   || dis=0.00 || select=6/8
011/019-th : 0.104 0.103 0.102 0.119 0.124 0.139 0.150 0.159  ||  -0.171 -0.182 -0.189 -0.039 0.006 0.117 0.197 0.250   || dis=0.01 || select=7/8
012/019-th : 0.110 0.114 0.115 0.119 0.129 0.132 0.135 0.146  ||  -0.125 -0.088 -0.082 -0.044 0.032 0.054 0.076 0.154   || dis=0.01 || select=7/8
013/019-th : 0.055 0.057 0.069 0.090 0.109 0.152 0.209 0.258  ||  -0.694 -0.649 -0.457 -0.190 -0.002 0.332 0.649 0.857  || dis=0.05 || select=7/8
014/019-th : 0.061 0.071 0.081 0.104 0.128 0.156 0.192 0.207  ||  -0.643 -0.482 -0.350 -0.105 0.100 0.299 0.508 0.582   || dis=0.01 || select=7/8
015/019-th : 0.056 0.051 0.066 0.091 0.110 0.156 0.210 0.259  ||  -0.647 -0.736 -0.479 -0.162 0.029 0.374 0.673 0.881   || dis=0.05 || select=7/8
016/019-th : 0.061 0.074 0.096 0.125 0.137 0.158 0.181 0.169  ||  -0.650 -0.465 -0.202 0.063 0.153 0.296 0.435 0.365    || dis=0.01 || select=6/8
017/019-th : 0.117 0.114 0.121 0.124 0.126 0.130 0.132 0.136  ||  -0.064 -0.086 -0.034 -0.008 0.009 0.045 0.058 0.087   || dis=0.00 || select=7/8
018/019-th : 0.082 0.096 0.108 0.123 0.131 0.137 0.149 0.173  ||  -0.394 -0.241 -0.120 0.010 0.071 0.117 0.203 0.346    || dis=0.02 || select=7/8
[epoch=127/600] FLOP : 28.06 MB, ratio : 0.6876, Expected-ratio : 0.7000, Discrepancy : 0.030
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:49:27] [epoch=127/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.701 (1.701)  Prec@1 40.23 (40.23) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:49:33] [epoch=127/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.276 (2.195)  Prec@1 30.36 (37.16) Prec@5 83.33 (82.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.16 Prec@5 82.54 Error@1 62.84 Error@5 17.46 Loss:2.195
***[2020-01-29 06:49:33]*** VALID [epoch=127/600] loss = 2.194918, accuracy@1 = 37.16, accuracy@5 = 82.54 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:49:33]*** start epoch=128/600 Time Left: [04:12:37], LR=[0.089185 ~ 0.089185], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=128, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.470048970448308, FLOP=40.81
[Search] : epoch=128/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:49:34] [epoch=128/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.958 (0.958)  Prec@1 66.41 (66.41) Prec@5 96.09 (96.09) Acls-loss 0.859 (0.859) FLOP-Loss 0.000 (0.000) Arch-Loss 0.859 (0.859)
**TRAIN** [2020-01-29 06:49:58] [epoch=128/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.735 (0.851)  Prec@1 77.98 (70.73) Prec@5 98.81 (97.60) Acls-loss 0.881 (0.879) FLOP-Loss 0.000 (0.000) Arch-Loss 0.881 (0.879)
 **TRAIN** Prec@1 70.73 Prec@5 97.60 Error@1 29.27 Error@5 2.40 Base-Loss:0.851, Arch-Loss=0.879
***[2020-01-29 06:49:58]*** TRAIN [epoch=128/600] base-loss = 0.850887, arch-loss = 0.878755, accuracy-1 = 70.73, accuracy-5 = 97.60
[epoch=128/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 12, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.323456)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.395 0.239 0.365  ||  0.0856 -0.4156 0.0064  || discrepancy=0.03 || select=0/3
001/003-th : 0.383 0.154 0.463  ||  -0.0084 -0.9178 0.1835  || discrepancy=0.08 || select=2/3
002/003-th : 0.194 0.231 0.575  ||  -0.5197 -0.3442 0.5676  || discrepancy=0.34 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.084 0.110 0.112 0.140 0.147 0.168 0.176  ||  -0.632 -0.344 -0.076 -0.058 0.165 0.212 0.349 0.395   || dis=0.01 || select=7/8
001/019-th : 0.124 0.121 0.123 0.126 0.127 0.127 0.126 0.126  ||  -0.003 -0.034 -0.018 0.013 0.018 0.015 0.011 0.010    || dis=0.00 || select=4/8
002/019-th : 0.118 0.123 0.128 0.132 0.132 0.127 0.122 0.118  ||  -0.047 -0.011 0.028 0.060 0.059 0.022 -0.017 -0.049   || dis=0.00 || select=3/8
003/019-th : 0.123 0.126 0.123 0.124 0.125 0.128 0.126 0.125  ||  -0.018 0.009 -0.014 -0.007 -0.001 0.020 0.010 -0.001  || dis=0.00 || select=5/8
004/019-th : 0.117 0.116 0.122 0.123 0.127 0.133 0.133 0.130  ||  -0.066 -0.072 -0.027 -0.012 0.013 0.060 0.060 0.040   || dis=0.00 || select=6/8
005/019-th : 0.114 0.115 0.121 0.125 0.128 0.130 0.134 0.133  ||  -0.092 -0.080 -0.028 0.000 0.022 0.044 0.074 0.062    || dis=0.00 || select=6/8
006/019-th : 0.112 0.111 0.123 0.119 0.128 0.128 0.138 0.141  ||  -0.110 -0.117 -0.013 -0.047 0.021 0.023 0.101 0.118   || dis=0.00 || select=7/8
007/019-th : 0.077 0.084 0.098 0.120 0.131 0.143 0.167 0.180  ||  -0.439 -0.351 -0.203 0.004 0.088 0.174 0.333 0.408    || dis=0.01 || select=7/8
008/019-th : 0.064 0.077 0.096 0.130 0.141 0.158 0.169 0.166  ||  -0.599 -0.427 -0.205 0.107 0.184 0.296 0.364 0.344    || dis=0.00 || select=6/8
009/019-th : 0.105 0.102 0.101 0.114 0.126 0.138 0.148 0.166  ||  -0.159 -0.196 -0.199 -0.085 0.019 0.113 0.179 0.294   || dis=0.02 || select=7/8
010/019-th : 0.101 0.109 0.119 0.123 0.132 0.135 0.141 0.140  ||  -0.207 -0.128 -0.046 -0.008 0.060 0.084 0.125 0.121   || dis=0.00 || select=6/8
011/019-th : 0.103 0.101 0.102 0.118 0.125 0.140 0.152 0.159  ||  -0.178 -0.195 -0.193 -0.046 0.016 0.127 0.209 0.254   || dis=0.01 || select=7/8
012/019-th : 0.109 0.113 0.115 0.118 0.128 0.133 0.138 0.146  ||  -0.138 -0.098 -0.084 -0.053 0.025 0.063 0.101 0.159   || dis=0.01 || select=7/8
013/019-th : 0.054 0.057 0.069 0.090 0.110 0.149 0.208 0.263  ||  -0.702 -0.648 -0.460 -0.192 0.005 0.315 0.643 0.881   || dis=0.06 || select=7/8
014/019-th : 0.060 0.070 0.081 0.104 0.129 0.155 0.189 0.211  ||  -0.654 -0.503 -0.348 -0.104 0.115 0.297 0.497 0.605   || dis=0.02 || select=7/8
015/019-th : 0.056 0.051 0.067 0.090 0.110 0.153 0.211 0.263  ||  -0.654 -0.740 -0.470 -0.167 0.027 0.357 0.681 0.901   || dis=0.05 || select=7/8
016/019-th : 0.060 0.073 0.095 0.123 0.136 0.162 0.182 0.169  ||  -0.660 -0.467 -0.208 0.050 0.149 0.322 0.439 0.370    || dis=0.01 || select=6/8
017/019-th : 0.116 0.114 0.119 0.124 0.125 0.132 0.133 0.137  ||  -0.073 -0.088 -0.044 -0.007 0.004 0.055 0.066 0.091   || dis=0.00 || select=7/8
018/019-th : 0.081 0.095 0.107 0.123 0.131 0.138 0.152 0.172  ||  -0.403 -0.249 -0.128 0.007 0.074 0.125 0.223 0.345    || dis=0.02 || select=7/8
[epoch=128/600] FLOP : 28.32 MB, ratio : 0.6940, Expected-ratio : 0.7000, Discrepancy : 0.031
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:49:58] [epoch=128/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.917 (1.917)  Prec@1 48.05 (48.05) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:50:04] [epoch=128/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.609 (2.133)  Prec@1 43.45 (40.06) Prec@5 80.95 (83.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.06 Prec@5 83.30 Error@1 59.94 Error@5 16.70 Loss:2.133
***[2020-01-29 06:50:04]*** VALID [epoch=128/600] loss = 2.133310, accuracy@1 = 40.06, accuracy@5 = 83.30 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:50:04]*** start epoch=129/600 Time Left: [04:12:01], LR=[0.089022 ~ 0.089022], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=129, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.462054497978908, FLOP=40.81
[Search] : epoch=129/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:50:05] [epoch=129/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.761 (0.761)  Prec@1 71.48 (71.48) Prec@5 97.66 (97.66) Acls-loss 0.889 (0.889) FLOP-Loss 0.000 (0.000) Arch-Loss 0.889 (0.889)
**TRAIN** [2020-01-29 06:50:29] [epoch=129/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 1.118 (0.865)  Prec@1 63.10 (70.68) Prec@5 94.64 (97.53) Acls-loss 1.054 (0.883) FLOP-Loss 0.000 (0.000) Arch-Loss 1.054 (0.883)
 **TRAIN** Prec@1 70.68 Prec@5 97.53 Error@1 29.32 Error@5 2.47 Base-Loss:0.865, Arch-Loss=0.883
***[2020-01-29 06:50:29]*** TRAIN [epoch=129/600] base-loss = 0.864977, arch-loss = 0.883313, accuracy-1 = 70.68, accuracy-5 = 97.53
[epoch=129/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 12, 12, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.323456)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.393 0.240 0.368  ||  0.0794 -0.4141 0.0146  || discrepancy=0.03 || select=0/3
001/003-th : 0.377 0.153 0.470  ||  -0.0202 -0.9241 0.2000  || discrepancy=0.09 || select=2/3
002/003-th : 0.189 0.227 0.584  ||  -0.5407 -0.3563 0.5899  || discrepancy=0.36 || select=2/3
-----------------------------------------------
000/019-th : 0.062 0.083 0.109 0.112 0.139 0.148 0.170 0.177  ||  -0.647 -0.356 -0.082 -0.051 0.161 0.224 0.364 0.402   || dis=0.01 || select=7/8
001/019-th : 0.123 0.120 0.121 0.125 0.129 0.127 0.127 0.127  ||  -0.011 -0.038 -0.030 0.004 0.033 0.021 0.020 0.016    || dis=0.00 || select=4/8
002/019-th : 0.118 0.122 0.127 0.132 0.131 0.127 0.123 0.119  ||  -0.049 -0.019 0.024 0.058 0.051 0.023 -0.014 -0.041   || dis=0.00 || select=3/8
003/019-th : 0.121 0.125 0.123 0.124 0.127 0.128 0.126 0.126  ||  -0.029 -0.001 -0.016 -0.004 0.013 0.022 0.011 0.010   || dis=0.00 || select=5/8
004/019-th : 0.116 0.117 0.121 0.122 0.127 0.133 0.132 0.132  ||  -0.071 -0.067 -0.036 -0.022 0.016 0.062 0.057 0.052   || dis=0.00 || select=5/8
005/019-th : 0.113 0.113 0.120 0.125 0.128 0.130 0.134 0.136  ||  -0.097 -0.095 -0.038 0.001 0.027 0.044 0.072 0.084    || dis=0.00 || select=7/8
006/019-th : 0.111 0.109 0.124 0.120 0.126 0.130 0.139 0.141  ||  -0.120 -0.132 -0.011 -0.039 0.012 0.037 0.109 0.125   || dis=0.00 || select=7/8
007/019-th : 0.076 0.083 0.097 0.118 0.130 0.144 0.167 0.185  ||  -0.451 -0.359 -0.208 -0.013 0.081 0.185 0.336 0.436   || dis=0.02 || select=7/8
008/019-th : 0.064 0.076 0.096 0.130 0.141 0.156 0.170 0.167  ||  -0.606 -0.434 -0.200 0.103 0.183 0.286 0.373 0.353    || dis=0.00 || select=6/8
009/019-th : 0.104 0.102 0.101 0.112 0.125 0.139 0.148 0.169  ||  -0.174 -0.193 -0.202 -0.099 0.016 0.120 0.179 0.312   || dis=0.02 || select=7/8
010/019-th : 0.099 0.109 0.116 0.125 0.133 0.135 0.142 0.139  ||  -0.221 -0.130 -0.062 0.010 0.074 0.088 0.136 0.117    || dis=0.00 || select=6/8
011/019-th : 0.101 0.100 0.102 0.116 0.126 0.142 0.152 0.161  ||  -0.198 -0.204 -0.186 -0.063 0.021 0.144 0.211 0.268   || dis=0.01 || select=7/8
012/019-th : 0.107 0.112 0.113 0.118 0.128 0.135 0.140 0.148  ||  -0.153 -0.108 -0.098 -0.056 0.025 0.077 0.118 0.169   || dis=0.01 || select=7/8
013/019-th : 0.054 0.058 0.069 0.090 0.109 0.147 0.206 0.267  ||  -0.711 -0.638 -0.455 -0.186 -0.003 0.300 0.639 0.898  || dis=0.06 || select=7/8
014/019-th : 0.060 0.068 0.081 0.102 0.130 0.154 0.192 0.212  ||  -0.647 -0.524 -0.345 -0.117 0.124 0.294 0.511 0.613   || dis=0.02 || select=7/8
015/019-th : 0.054 0.050 0.065 0.090 0.110 0.150 0.216 0.265  ||  -0.666 -0.758 -0.482 -0.162 0.040 0.344 0.710 0.915   || dis=0.05 || select=7/8
016/019-th : 0.060 0.074 0.094 0.123 0.137 0.161 0.182 0.169  ||  -0.672 -0.459 -0.219 0.053 0.161 0.321 0.442 0.370    || dis=0.01 || select=6/8
017/019-th : 0.115 0.114 0.116 0.125 0.126 0.133 0.135 0.137  ||  -0.076 -0.093 -0.072 0.002 0.013 0.063 0.079 0.092    || dis=0.00 || select=7/8
018/019-th : 0.082 0.094 0.107 0.123 0.131 0.138 0.153 0.173  ||  -0.400 -0.258 -0.134 0.009 0.070 0.128 0.226 0.350    || dis=0.02 || select=7/8
[epoch=129/600] FLOP : 28.32 MB, ratio : 0.6940, Expected-ratio : 0.7000, Discrepancy : 0.033
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:50:29] [epoch=129/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.419 (2.419)  Prec@1 19.92 (19.92) Prec@5 73.83 (73.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:50:35] [epoch=129/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.848 (2.346)  Prec@1 39.88 (39.11) Prec@5 77.38 (84.27) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.11 Prec@5 84.27 Error@1 60.89 Error@5 15.73 Loss:2.346
***[2020-01-29 06:50:35]*** VALID [epoch=129/600] loss = 2.346376, accuracy@1 = 39.11, accuracy@5 = 84.27 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:50:36]*** start epoch=130/600 Time Left: [04:11:27], LR=[0.088857 ~ 0.088857], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=130, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.454007605569578, FLOP=40.81
[Search] : epoch=130/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:50:36] [epoch=130/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.806 (0.806)  Prec@1 74.22 (74.22) Prec@5 98.44 (98.44) Acls-loss 0.743 (0.743) FLOP-Loss 0.000 (0.000) Arch-Loss 0.743 (0.743)
**TRAIN** [2020-01-29 06:51:00] [epoch=130/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.960 (0.855)  Prec@1 63.10 (70.58) Prec@5 95.83 (97.58) Acls-loss 1.002 (0.900) FLOP-Loss 0.000 (0.000) Arch-Loss 1.002 (0.900)
 **TRAIN** Prec@1 70.58 Prec@5 97.58 Error@1 29.42 Error@5 2.42 Base-Loss:0.855, Arch-Loss=0.900
***[2020-01-29 06:51:00]*** TRAIN [epoch=130/600] base-loss = 0.854569, arch-loss = 0.899634, accuracy-1 = 70.58, accuracy-5 = 97.58
[epoch=130/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 12, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.558976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.389 0.240 0.371  ||  0.0715 -0.4127 0.0245  || discrepancy=0.02 || select=0/3
001/003-th : 0.373 0.151 0.477  ||  -0.0307 -0.9353 0.2161  || discrepancy=0.10 || select=2/3
002/003-th : 0.183 0.227 0.591  ||  -0.5631 -0.3477 0.6100  || discrepancy=0.36 || select=2/3
-----------------------------------------------
000/019-th : 0.061 0.082 0.106 0.112 0.142 0.148 0.172 0.177  ||  -0.654 -0.368 -0.107 -0.049 0.188 0.230 0.376 0.406   || dis=0.01 || select=7/8
001/019-th : 0.123 0.119 0.120 0.125 0.130 0.127 0.128 0.128  ||  -0.017 -0.047 -0.037 -0.001 0.045 0.021 0.027 0.023   || dis=0.00 || select=4/8
002/019-th : 0.117 0.121 0.127 0.132 0.133 0.128 0.123 0.120  ||  -0.060 -0.023 0.020 0.058 0.065 0.030 -0.007 -0.038   || dis=0.00 || select=4/8
003/019-th : 0.120 0.123 0.122 0.124 0.128 0.129 0.126 0.127  ||  -0.037 -0.013 -0.022 -0.007 0.028 0.036 0.013 0.016   || dis=0.00 || select=5/8
004/019-th : 0.116 0.117 0.120 0.121 0.127 0.134 0.132 0.134  ||  -0.079 -0.070 -0.043 -0.031 0.012 0.066 0.056 0.070   || dis=0.00 || select=7/8
005/019-th : 0.111 0.110 0.122 0.126 0.129 0.132 0.134 0.136  ||  -0.113 -0.121 -0.020 0.010 0.038 0.057 0.077 0.091    || dis=0.00 || select=7/8
006/019-th : 0.110 0.108 0.122 0.121 0.125 0.132 0.139 0.144  ||  -0.123 -0.147 -0.025 -0.035 0.003 0.054 0.108 0.141   || dis=0.00 || select=7/8
007/019-th : 0.073 0.084 0.098 0.118 0.130 0.143 0.168 0.186  ||  -0.488 -0.347 -0.199 -0.014 0.087 0.180 0.343 0.446   || dis=0.02 || select=7/8
008/019-th : 0.063 0.075 0.095 0.131 0.139 0.156 0.174 0.167  ||  -0.612 -0.449 -0.207 0.116 0.172 0.287 0.394 0.356    || dis=0.01 || select=6/8
009/019-th : 0.103 0.101 0.103 0.113 0.126 0.138 0.147 0.170  ||  -0.184 -0.204 -0.177 -0.084 0.017 0.108 0.173 0.317   || dis=0.02 || select=7/8
010/019-th : 0.099 0.108 0.116 0.125 0.133 0.137 0.143 0.140  ||  -0.224 -0.139 -0.063 0.006 0.068 0.097 0.142 0.122    || dis=0.00 || select=6/8
011/019-th : 0.101 0.099 0.102 0.114 0.125 0.141 0.153 0.165  ||  -0.198 -0.218 -0.189 -0.074 0.017 0.139 0.216 0.292   || dis=0.01 || select=7/8
012/019-th : 0.106 0.111 0.112 0.117 0.127 0.135 0.142 0.149  ||  -0.159 -0.114 -0.108 -0.064 0.019 0.083 0.131 0.180   || dis=0.01 || select=7/8
013/019-th : 0.053 0.057 0.070 0.091 0.108 0.145 0.206 0.271  ||  -0.721 -0.649 -0.443 -0.181 -0.009 0.291 0.639 0.915  || dis=0.07 || select=7/8
014/019-th : 0.060 0.067 0.080 0.103 0.129 0.154 0.192 0.215  ||  -0.644 -0.533 -0.364 -0.108 0.116 0.294 0.518 0.630   || dis=0.02 || select=7/8
015/019-th : 0.054 0.049 0.065 0.089 0.109 0.150 0.215 0.269  ||  -0.670 -0.770 -0.480 -0.168 0.030 0.349 0.713 0.936   || dis=0.05 || select=7/8
016/019-th : 0.059 0.073 0.093 0.124 0.137 0.162 0.181 0.171  ||  -0.683 -0.467 -0.223 0.057 0.160 0.329 0.439 0.382    || dis=0.01 || select=6/8
017/019-th : 0.115 0.112 0.114 0.127 0.128 0.133 0.135 0.137  ||  -0.083 -0.109 -0.089 0.020 0.030 0.064 0.080 0.100    || dis=0.00 || select=7/8
018/019-th : 0.083 0.094 0.106 0.123 0.129 0.139 0.154 0.172  ||  -0.386 -0.265 -0.137 0.010 0.060 0.129 0.234 0.345    || dis=0.02 || select=7/8
[epoch=130/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.034
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:51:01] [epoch=130/600][000/098] Time 0.35 (0.35) Data 0.28 (0.28) Loss 2.190 (2.190)  Prec@1 39.84 (39.84) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:51:06] [epoch=130/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.447 (2.305)  Prec@1 35.71 (36.70) Prec@5 73.21 (81.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.70 Prec@5 81.14 Error@1 63.30 Error@5 18.86 Loss:2.305
***[2020-01-29 06:51:06]*** VALID [epoch=130/600] loss = 2.304974, accuracy@1 = 36.70, accuracy@5 = 81.14 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:51:07]*** start epoch=131/600 Time Left: [04:10:51], LR=[0.088692 ~ 0.088692], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=131, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.445908513829941, FLOP=40.81
[Search] : epoch=131/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:51:07] [epoch=131/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.848 (0.848)  Prec@1 69.92 (69.92) Prec@5 98.44 (98.44) Acls-loss 0.985 (0.985) FLOP-Loss 0.000 (0.000) Arch-Loss 0.985 (0.985)
**TRAIN** [2020-01-29 06:51:31] [epoch=131/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.806 (0.847)  Prec@1 70.83 (71.04) Prec@5 99.40 (97.72) Acls-loss 0.774 (0.861) FLOP-Loss 0.000 (0.000) Arch-Loss 0.774 (0.861)
 **TRAIN** Prec@1 71.04 Prec@5 97.72 Error@1 28.96 Error@5 2.28 Base-Loss:0.847, Arch-Loss=0.861
***[2020-01-29 06:51:31]*** TRAIN [epoch=131/600] base-loss = 0.847165, arch-loss = 0.861290, accuracy-1 = 71.04, accuracy-5 = 97.72
[epoch=131/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 12, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.558976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.386 0.241 0.373  ||  0.0660 -0.4043 0.0314  || discrepancy=0.01 || select=0/3
001/003-th : 0.369 0.150 0.482  ||  -0.0384 -0.9406 0.2290  || discrepancy=0.11 || select=2/3
002/003-th : 0.178 0.222 0.601  ||  -0.5848 -0.3634 0.6338  || discrepancy=0.38 || select=2/3
-----------------------------------------------
000/019-th : 0.060 0.081 0.105 0.111 0.142 0.148 0.173 0.179  ||  -0.667 -0.374 -0.114 -0.059 0.189 0.232 0.389 0.422   || dis=0.01 || select=7/8
001/019-th : 0.121 0.119 0.119 0.125 0.130 0.128 0.129 0.128  ||  -0.027 -0.050 -0.048 0.004 0.046 0.024 0.038 0.029    || dis=0.00 || select=4/8
002/019-th : 0.115 0.121 0.126 0.131 0.134 0.129 0.124 0.121  ||  -0.073 -0.029 0.012 0.053 0.074 0.040 -0.002 -0.030   || dis=0.00 || select=4/8
003/019-th : 0.119 0.122 0.122 0.125 0.128 0.129 0.127 0.127  ||  -0.046 -0.023 -0.021 0.006 0.030 0.034 0.021 0.021    || dis=0.00 || select=5/8
004/019-th : 0.115 0.117 0.119 0.121 0.128 0.132 0.134 0.134  ||  -0.080 -0.069 -0.050 -0.035 0.019 0.058 0.071 0.067   || dis=0.00 || select=6/8
005/019-th : 0.111 0.110 0.122 0.126 0.128 0.130 0.135 0.138  ||  -0.115 -0.125 -0.017 0.014 0.025 0.042 0.079 0.103    || dis=0.00 || select=7/8
006/019-th : 0.110 0.108 0.120 0.120 0.128 0.131 0.138 0.145  ||  -0.126 -0.147 -0.037 -0.037 0.027 0.051 0.099 0.149   || dis=0.01 || select=7/8
007/019-th : 0.072 0.084 0.097 0.118 0.131 0.145 0.166 0.187  ||  -0.497 -0.353 -0.207 -0.013 0.098 0.199 0.334 0.453   || dis=0.02 || select=7/8
008/019-th : 0.062 0.074 0.092 0.130 0.139 0.158 0.176 0.168  ||  -0.626 -0.458 -0.233 0.113 0.173 0.307 0.411 0.368    || dis=0.01 || select=6/8
009/019-th : 0.101 0.100 0.105 0.113 0.125 0.139 0.148 0.170  ||  -0.200 -0.209 -0.164 -0.087 0.013 0.119 0.180 0.320   || dis=0.02 || select=7/8
010/019-th : 0.098 0.107 0.116 0.125 0.132 0.136 0.144 0.141  ||  -0.234 -0.148 -0.064 0.013 0.062 0.095 0.150 0.132    || dis=0.00 || select=6/8
011/019-th : 0.102 0.099 0.100 0.115 0.125 0.141 0.153 0.165  ||  -0.191 -0.219 -0.205 -0.065 0.014 0.137 0.219 0.297   || dis=0.01 || select=7/8
012/019-th : 0.106 0.110 0.111 0.117 0.130 0.137 0.142 0.148  ||  -0.162 -0.120 -0.116 -0.064 0.041 0.097 0.131 0.174   || dis=0.01 || select=7/8
013/019-th : 0.051 0.056 0.068 0.092 0.107 0.146 0.205 0.274  ||  -0.751 -0.650 -0.459 -0.163 -0.010 0.302 0.642 0.931  || dis=0.07 || select=7/8
014/019-th : 0.060 0.068 0.078 0.102 0.129 0.154 0.193 0.216  ||  -0.651 -0.520 -0.385 -0.116 0.123 0.299 0.522 0.637   || dis=0.02 || select=7/8
015/019-th : 0.053 0.048 0.064 0.088 0.108 0.153 0.214 0.272  ||  -0.688 -0.782 -0.498 -0.170 0.035 0.378 0.716 0.955   || dis=0.06 || select=7/8
016/019-th : 0.058 0.073 0.093 0.121 0.137 0.163 0.182 0.172  ||  -0.700 -0.461 -0.224 0.038 0.163 0.338 0.447 0.393    || dis=0.01 || select=6/8
017/019-th : 0.115 0.111 0.113 0.127 0.128 0.132 0.135 0.140  ||  -0.084 -0.114 -0.097 0.017 0.026 0.059 0.081 0.117    || dis=0.01 || select=7/8
018/019-th : 0.082 0.094 0.106 0.123 0.130 0.139 0.152 0.173  ||  -0.395 -0.255 -0.138 0.008 0.065 0.135 0.223 0.348    || dis=0.02 || select=7/8
[epoch=131/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.036
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:51:32] [epoch=131/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.549 (2.549)  Prec@1 37.50 (37.50) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:51:38] [epoch=131/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.865 (2.224)  Prec@1 24.40 (37.95) Prec@5 74.40 (82.77) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.95 Prec@5 82.77 Error@1 62.05 Error@5 17.23 Loss:2.224
***[2020-01-29 06:51:38]*** VALID [epoch=131/600] loss = 2.223838, accuracy@1 = 37.95, accuracy@5 = 82.77 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:51:38]*** start epoch=132/600 Time Left: [04:10:16], LR=[0.088526 ~ 0.088526], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=132, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.437757444800684, FLOP=40.81
[Search] : epoch=132/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:51:38] [epoch=132/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.894 (0.894)  Prec@1 69.53 (69.53) Prec@5 96.88 (96.88) Acls-loss 0.890 (0.890) FLOP-Loss 0.000 (0.000) Arch-Loss 0.890 (0.890)
**TRAIN** [2020-01-29 06:52:02] [epoch=132/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.888 (0.860)  Prec@1 70.24 (70.56) Prec@5 97.62 (97.50) Acls-loss 0.652 (0.869) FLOP-Loss 0.000 (0.027) Arch-Loss 0.652 (0.923)
 **TRAIN** Prec@1 70.56 Prec@5 97.50 Error@1 29.44 Error@5 2.50 Base-Loss:0.860, Arch-Loss=0.923
***[2020-01-29 06:52:02]*** TRAIN [epoch=132/600] base-loss = 0.859977, arch-loss = 0.923216, accuracy-1 = 70.56, accuracy-5 = 97.50
[epoch=132/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 12, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.558976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.385 0.242 0.373  ||  0.0645 -0.3995 0.0346  || discrepancy=0.01 || select=0/3
001/003-th : 0.366 0.149 0.484  ||  -0.0420 -0.9407 0.2373  || discrepancy=0.12 || select=2/3
002/003-th : 0.173 0.219 0.608  ||  -0.6034 -0.3659 0.6525  || discrepancy=0.39 || select=2/3
-----------------------------------------------
000/019-th : 0.062 0.082 0.105 0.112 0.141 0.147 0.171 0.180  ||  -0.644 -0.369 -0.118 -0.052 0.178 0.218 0.373 0.422   || dis=0.01 || select=7/8
001/019-th : 0.120 0.119 0.119 0.127 0.129 0.128 0.129 0.129  ||  -0.041 -0.048 -0.044 0.021 0.039 0.025 0.037 0.036    || dis=0.00 || select=4/8
002/019-th : 0.115 0.120 0.125 0.132 0.133 0.129 0.125 0.121  ||  -0.077 -0.034 0.003 0.059 0.070 0.040 0.003 -0.024    || dis=0.00 || select=4/8
003/019-th : 0.119 0.124 0.124 0.124 0.127 0.129 0.126 0.127  ||  -0.048 -0.008 -0.009 -0.003 0.019 0.037 0.012 0.018   || dis=0.00 || select=5/8
004/019-th : 0.115 0.117 0.118 0.121 0.128 0.133 0.135 0.133  ||  -0.082 -0.065 -0.059 -0.033 0.026 0.063 0.076 0.061   || dis=0.00 || select=6/8
005/019-th : 0.111 0.111 0.122 0.126 0.129 0.130 0.133 0.138  ||  -0.119 -0.114 -0.017 0.012 0.037 0.041 0.070 0.100    || dis=0.01 || select=7/8
006/019-th : 0.110 0.109 0.121 0.120 0.128 0.132 0.137 0.144  ||  -0.124 -0.134 -0.033 -0.041 0.024 0.056 0.095 0.141   || dis=0.01 || select=7/8
007/019-th : 0.073 0.083 0.098 0.116 0.131 0.146 0.165 0.188  ||  -0.493 -0.357 -0.196 -0.026 0.093 0.202 0.328 0.459   || dis=0.02 || select=7/8
008/019-th : 0.063 0.074 0.092 0.131 0.136 0.158 0.176 0.171  ||  -0.623 -0.461 -0.232 0.115 0.151 0.303 0.411 0.384    || dis=0.00 || select=6/8
009/019-th : 0.101 0.100 0.106 0.111 0.125 0.139 0.148 0.169  ||  -0.196 -0.214 -0.148 -0.102 0.017 0.120 0.184 0.315   || dis=0.02 || select=7/8
010/019-th : 0.098 0.107 0.114 0.128 0.131 0.137 0.144 0.140  ||  -0.236 -0.143 -0.081 0.035 0.058 0.099 0.152 0.126    || dis=0.00 || select=6/8
011/019-th : 0.103 0.097 0.101 0.116 0.125 0.140 0.154 0.165  ||  -0.181 -0.236 -0.196 -0.062 0.014 0.131 0.224 0.293   || dis=0.01 || select=7/8
012/019-th : 0.104 0.111 0.109 0.119 0.130 0.136 0.142 0.148  ||  -0.173 -0.115 -0.128 -0.041 0.043 0.093 0.130 0.178   || dis=0.01 || select=7/8
013/019-th : 0.052 0.056 0.068 0.091 0.107 0.146 0.206 0.274  ||  -0.738 -0.654 -0.460 -0.167 -0.010 0.300 0.644 0.932  || dis=0.07 || select=7/8
014/019-th : 0.058 0.069 0.077 0.101 0.129 0.154 0.193 0.218  ||  -0.668 -0.506 -0.397 -0.120 0.123 0.303 0.526 0.648   || dis=0.02 || select=7/8
015/019-th : 0.051 0.048 0.062 0.088 0.106 0.151 0.215 0.279  ||  -0.717 -0.770 -0.510 -0.171 0.023 0.375 0.730 0.987   || dis=0.06 || select=7/8
016/019-th : 0.058 0.072 0.093 0.122 0.136 0.164 0.182 0.173  ||  -0.698 -0.485 -0.220 0.052 0.156 0.342 0.448 0.400    || dis=0.01 || select=6/8
017/019-th : 0.114 0.113 0.113 0.125 0.128 0.131 0.135 0.140  ||  -0.089 -0.098 -0.098 0.007 0.028 0.053 0.081 0.117    || dis=0.01 || select=7/8
018/019-th : 0.081 0.095 0.105 0.121 0.130 0.141 0.154 0.174  ||  -0.408 -0.252 -0.150 -0.010 0.062 0.143 0.236 0.360   || dis=0.02 || select=7/8
[epoch=132/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.037
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:52:03] [epoch=132/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.051 (2.051)  Prec@1 46.88 (46.88) Prec@5 84.38 (84.38) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:52:09] [epoch=132/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.940 (2.181)  Prec@1 41.67 (36.44) Prec@5 92.26 (80.41) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.44 Prec@5 80.41 Error@1 63.56 Error@5 19.59 Loss:2.181
***[2020-01-29 06:52:09]*** VALID [epoch=132/600] loss = 2.180930, accuracy@1 = 36.44, accuracy@5 = 80.41 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:52:09]*** start epoch=133/600 Time Left: [04:09:39], LR=[0.088358 ~ 0.088358], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=133, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.429554621947484, FLOP=40.81
[Search] : epoch=133/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:52:09] [epoch=133/600][000/098] Time 0.75 (0.75) Data 0.37 (0.37) Base-Loss 0.995 (0.995)  Prec@1 64.06 (64.06) Prec@5 97.66 (97.66) Acls-loss 0.789 (0.789) FLOP-Loss 0.000 (0.000) Arch-Loss 0.789 (0.789)
**TRAIN** [2020-01-29 06:52:33] [epoch=133/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.578 (0.850)  Prec@1 80.95 (71.01) Prec@5 98.81 (97.63) Acls-loss 0.854 (0.885) FLOP-Loss 0.000 (0.081) Arch-Loss 0.854 (1.047)
 **TRAIN** Prec@1 71.01 Prec@5 97.63 Error@1 28.99 Error@5 2.37 Base-Loss:0.850, Arch-Loss=1.047
***[2020-01-29 06:52:33]*** TRAIN [epoch=133/600] base-loss = 0.849828, arch-loss = 1.046530, accuracy-1 = 71.01, accuracy-5 = 97.63
[epoch=133/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 12, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.061312)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.391 0.243 0.367  ||  0.0820 -0.3926 0.0187  || discrepancy=0.02 || select=0/3
001/003-th : 0.372 0.150 0.478  ||  -0.0257 -0.9338 0.2253  || discrepancy=0.11 || select=2/3
002/003-th : 0.171 0.222 0.607  ||  -0.6106 -0.3487 0.6574  || discrepancy=0.39 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.082 0.107 0.114 0.141 0.146 0.169 0.178  ||  -0.632 -0.368 -0.103 -0.040 0.176 0.213 0.357 0.408   || dis=0.01 || select=7/8
001/019-th : 0.122 0.120 0.121 0.129 0.128 0.127 0.127 0.127  ||  -0.021 -0.040 -0.028 0.031 0.024 0.017 0.020 0.019    || dis=0.00 || select=3/8
002/019-th : 0.117 0.123 0.127 0.132 0.132 0.128 0.122 0.120  ||  -0.063 -0.010 0.023 0.056 0.062 0.027 -0.022 -0.039   || dis=0.00 || select=4/8
003/019-th : 0.120 0.126 0.125 0.126 0.126 0.128 0.124 0.126  ||  -0.037 0.007 0.005 0.008 0.007 0.024 -0.007 0.009     || dis=0.00 || select=5/8
004/019-th : 0.116 0.119 0.122 0.123 0.128 0.131 0.133 0.129  ||  -0.072 -0.051 -0.027 -0.018 0.025 0.051 0.063 0.035   || dis=0.00 || select=6/8
005/019-th : 0.112 0.113 0.123 0.127 0.129 0.130 0.131 0.136  ||  -0.108 -0.097 -0.013 0.019 0.034 0.039 0.050 0.085    || dis=0.01 || select=7/8
006/019-th : 0.111 0.110 0.121 0.121 0.127 0.131 0.136 0.142  ||  -0.113 -0.125 -0.026 -0.028 0.021 0.047 0.084 0.131   || dis=0.01 || select=7/8
007/019-th : 0.074 0.084 0.099 0.115 0.131 0.143 0.166 0.189  ||  -0.479 -0.356 -0.185 -0.041 0.093 0.183 0.329 0.457   || dis=0.02 || select=7/8
008/019-th : 0.062 0.074 0.092 0.131 0.138 0.157 0.175 0.170  ||  -0.626 -0.454 -0.233 0.114 0.165 0.299 0.404 0.378    || dis=0.00 || select=6/8
009/019-th : 0.103 0.100 0.108 0.112 0.125 0.137 0.149 0.166  ||  -0.185 -0.206 -0.134 -0.099 0.012 0.107 0.188 0.297   || dis=0.02 || select=7/8
010/019-th : 0.100 0.109 0.115 0.127 0.131 0.137 0.141 0.138  ||  -0.211 -0.128 -0.073 0.027 0.054 0.101 0.131 0.109    || dis=0.00 || select=6/8
011/019-th : 0.104 0.097 0.102 0.116 0.126 0.141 0.152 0.163  ||  -0.171 -0.239 -0.188 -0.058 0.021 0.134 0.213 0.281   || dis=0.01 || select=7/8
012/019-th : 0.106 0.112 0.110 0.120 0.132 0.134 0.139 0.146  ||  -0.158 -0.105 -0.126 -0.032 0.061 0.078 0.114 0.165   || dis=0.01 || select=7/8
013/019-th : 0.051 0.056 0.069 0.092 0.108 0.147 0.203 0.272  ||  -0.744 -0.655 -0.448 -0.158 -0.000 0.309 0.628 0.922  || dis=0.07 || select=7/8
014/019-th : 0.059 0.069 0.077 0.101 0.131 0.155 0.193 0.214  ||  -0.656 -0.509 -0.392 -0.122 0.136 0.307 0.526 0.628   || dis=0.02 || select=7/8
015/019-th : 0.050 0.049 0.062 0.089 0.106 0.152 0.217 0.275  ||  -0.733 -0.758 -0.515 -0.151 0.024 0.378 0.735 0.974   || dis=0.06 || select=7/8
016/019-th : 0.058 0.072 0.095 0.123 0.138 0.165 0.179 0.171  ||  -0.703 -0.477 -0.207 0.055 0.168 0.353 0.432 0.384    || dis=0.01 || select=6/8
017/019-th : 0.116 0.115 0.113 0.124 0.130 0.130 0.135 0.137  ||  -0.074 -0.081 -0.094 -0.004 0.041 0.041 0.077 0.096   || dis=0.00 || select=7/8
018/019-th : 0.081 0.095 0.106 0.122 0.130 0.140 0.153 0.174  ||  -0.413 -0.247 -0.139 0.000 0.064 0.140 0.227 0.357    || dis=0.02 || select=7/8
[epoch=133/600] FLOP : 28.06 MB, ratio : 0.6876, Expected-ratio : 0.7000, Discrepancy : 0.036
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:52:34] [epoch=133/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.170 (2.170)  Prec@1 28.91 (28.91) Prec@5 71.09 (71.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:52:40] [epoch=133/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.983 (2.295)  Prec@1 38.10 (37.34) Prec@5 84.52 (82.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.34 Prec@5 82.89 Error@1 62.66 Error@5 17.11 Loss:2.295
***[2020-01-29 06:52:40]*** VALID [epoch=133/600] loss = 2.295174, accuracy@1 = 37.34, accuracy@5 = 82.89 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:52:40]*** start epoch=134/600 Time Left: [04:09:04], LR=[0.088190 ~ 0.088190], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=134, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.421300270154874, FLOP=40.81
[Search] : epoch=134/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:52:40] [epoch=134/600][000/098] Time 0.62 (0.62) Data 0.36 (0.36) Base-Loss 0.792 (0.792)  Prec@1 74.61 (74.61) Prec@5 96.88 (96.88) Acls-loss 0.788 (0.788) FLOP-Loss 0.000 (0.000) Arch-Loss 0.788 (0.788)
**TRAIN** [2020-01-29 06:53:04] [epoch=134/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.834 (0.827)  Prec@1 73.21 (71.49) Prec@5 95.83 (97.82) Acls-loss 0.891 (0.867) FLOP-Loss 0.000 (0.027) Arch-Loss 0.891 (0.921)
 **TRAIN** Prec@1 71.49 Prec@5 97.82 Error@1 28.51 Error@5 2.18 Base-Loss:0.827, Arch-Loss=0.921
***[2020-01-29 06:53:04]*** TRAIN [epoch=134/600] base-loss = 0.827184, arch-loss = 0.921422, accuracy-1 = 71.49, accuracy-5 = 97.82
[epoch=134/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 12, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.558976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.390 0.242 0.369  ||  0.0797 -0.3985 0.0240  || discrepancy=0.02 || select=0/3
001/003-th : 0.371 0.149 0.479  ||  -0.0254 -0.9375 0.2301  || discrepancy=0.11 || select=2/3
002/003-th : 0.166 0.220 0.614  ||  -0.6316 -0.3508 0.6778  || discrepancy=0.39 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.080 0.109 0.115 0.140 0.148 0.166 0.179  ||  -0.626 -0.387 -0.086 -0.030 0.168 0.221 0.340 0.410   || dis=0.01 || select=7/8
001/019-th : 0.123 0.119 0.121 0.128 0.129 0.126 0.127 0.128  ||  -0.017 -0.046 -0.031 0.026 0.030 0.007 0.015 0.028    || dis=0.00 || select=4/8
002/019-th : 0.118 0.124 0.128 0.131 0.132 0.127 0.121 0.120  ||  -0.057 -0.008 0.024 0.049 0.061 0.016 -0.026 -0.039   || dis=0.00 || select=4/8
003/019-th : 0.120 0.125 0.126 0.124 0.126 0.128 0.124 0.127  ||  -0.038 0.005 0.010 -0.011 0.010 0.026 -0.009 0.015    || dis=0.00 || select=5/8
004/019-th : 0.115 0.119 0.121 0.125 0.127 0.131 0.133 0.129  ||  -0.079 -0.048 -0.028 -0.000 0.019 0.050 0.064 0.034   || dis=0.00 || select=6/8
005/019-th : 0.113 0.113 0.123 0.128 0.130 0.130 0.130 0.135  ||  -0.100 -0.100 -0.015 0.024 0.039 0.041 0.045 0.078    || dis=0.01 || select=7/8
006/019-th : 0.111 0.109 0.120 0.120 0.129 0.132 0.135 0.142  ||  -0.112 -0.131 -0.034 -0.038 0.036 0.057 0.083 0.132   || dis=0.01 || select=7/8
007/019-th : 0.073 0.083 0.100 0.116 0.130 0.145 0.165 0.188  ||  -0.484 -0.366 -0.179 -0.028 0.087 0.199 0.323 0.455   || dis=0.02 || select=7/8
008/019-th : 0.062 0.073 0.093 0.133 0.139 0.157 0.172 0.172  ||  -0.633 -0.471 -0.229 0.129 0.176 0.300 0.389 0.386    || dis=0.00 || select=6/8
009/019-th : 0.102 0.101 0.107 0.112 0.123 0.139 0.150 0.167  ||  -0.190 -0.205 -0.143 -0.097 -0.001 0.116 0.194 0.303  || dis=0.02 || select=7/8
010/019-th : 0.101 0.109 0.116 0.126 0.131 0.139 0.142 0.136  ||  -0.208 -0.126 -0.069 0.015 0.056 0.117 0.134 0.094    || dis=0.00 || select=6/8
011/019-th : 0.103 0.098 0.103 0.115 0.126 0.138 0.154 0.162  ||  -0.180 -0.223 -0.175 -0.072 0.025 0.117 0.222 0.278   || dis=0.01 || select=7/8
012/019-th : 0.106 0.112 0.109 0.120 0.134 0.133 0.139 0.147  ||  -0.156 -0.105 -0.129 -0.031 0.072 0.065 0.109 0.169   || dis=0.01 || select=7/8
013/019-th : 0.051 0.056 0.070 0.091 0.108 0.147 0.203 0.274  ||  -0.748 -0.658 -0.437 -0.174 0.004 0.308 0.633 0.931   || dis=0.07 || select=7/8
014/019-th : 0.059 0.068 0.076 0.101 0.132 0.155 0.195 0.214  ||  -0.655 -0.513 -0.411 -0.119 0.149 0.306 0.538 0.628   || dis=0.02 || select=7/8
015/019-th : 0.050 0.049 0.061 0.089 0.107 0.152 0.217 0.274  ||  -0.727 -0.754 -0.531 -0.152 0.031 0.382 0.736 0.971   || dis=0.06 || select=7/8
016/019-th : 0.056 0.072 0.094 0.123 0.137 0.163 0.179 0.175  ||  -0.722 -0.476 -0.207 0.057 0.168 0.338 0.433 0.407    || dis=0.00 || select=6/8
017/019-th : 0.116 0.114 0.114 0.123 0.129 0.131 0.136 0.138  ||  -0.075 -0.091 -0.093 -0.016 0.032 0.052 0.086 0.104   || dis=0.00 || select=7/8
018/019-th : 0.081 0.094 0.105 0.120 0.129 0.140 0.154 0.177  ||  -0.409 -0.258 -0.151 -0.011 0.058 0.137 0.236 0.374   || dis=0.02 || select=7/8
[epoch=134/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.036
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:53:05] [epoch=134/600][000/098] Time 0.35 (0.35) Data 0.28 (0.28) Loss 3.176 (3.176)  Prec@1 33.59 (33.59) Prec@5 77.34 (77.34) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:53:10] [epoch=134/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 3.734 (2.155)  Prec@1 27.98 (37.28) Prec@5 84.52 (82.51) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.28 Prec@5 82.51 Error@1 62.72 Error@5 17.49 Loss:2.155
***[2020-01-29 06:53:11]*** VALID [epoch=134/600] loss = 2.154808, accuracy@1 = 37.28, accuracy@5 = 82.51 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:53:11]*** start epoch=135/600 Time Left: [04:08:27], LR=[0.088020 ~ 0.088020], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=135, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.412994615720076, FLOP=40.81
[Search] : epoch=135/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:53:11] [epoch=135/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.863 (0.863)  Prec@1 68.75 (68.75) Prec@5 96.09 (96.09) Acls-loss 0.803 (0.803) FLOP-Loss 0.000 (0.000) Arch-Loss 0.803 (0.803)
**TRAIN** [2020-01-29 06:53:35] [epoch=135/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.892 (0.840)  Prec@1 67.26 (71.42) Prec@5 95.83 (97.61) Acls-loss 0.808 (0.873) FLOP-Loss 2.622 (0.125) Arch-Loss 6.053 (1.124)
 **TRAIN** Prec@1 71.42 Prec@5 97.61 Error@1 28.58 Error@5 2.39 Base-Loss:0.840, Arch-Loss=1.124
***[2020-01-29 06:53:35]*** TRAIN [epoch=135/600] base-loss = 0.839706, arch-loss = 1.124111, accuracy-1 = 71.42, accuracy-5 = 97.61
[epoch=135/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.69824)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.399 0.242 0.358  ||  0.1062 -0.3921 -0.0010  || discrepancy=0.04 || select=0/3
001/003-th : 0.379 0.150 0.471  ||  -0.0049 -0.9330 0.2140  || discrepancy=0.09 || select=2/3
002/003-th : 0.167 0.224 0.609  ||  -0.6264 -0.3283 0.6704  || discrepancy=0.39 || select=2/3
-----------------------------------------------
000/019-th : 0.064 0.081 0.109 0.117 0.142 0.148 0.163 0.176  ||  -0.618 -0.378 -0.081 -0.012 0.177 0.221 0.316 0.393   || dis=0.01 || select=7/8
001/019-th : 0.127 0.121 0.123 0.128 0.127 0.124 0.124 0.125  ||  0.013 -0.029 -0.014 0.028 0.018 -0.009 -0.004 0.001   || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.129 0.133 0.132 0.123 0.120 0.118  ||  -0.039 0.017 0.035 0.065 0.055 -0.017 -0.042 -0.058   || dis=0.00 || select=3/8
003/019-th : 0.123 0.129 0.127 0.124 0.125 0.126 0.122 0.124  ||  -0.015 0.029 0.019 -0.005 -0.003 0.004 -0.023 -0.008  || dis=0.00 || select=1/8
004/019-th : 0.117 0.120 0.124 0.126 0.126 0.129 0.130 0.127  ||  -0.063 -0.036 -0.008 0.011 0.011 0.035 0.044 0.019    || dis=0.00 || select=6/8
005/019-th : 0.116 0.115 0.124 0.127 0.128 0.129 0.128 0.132  ||  -0.073 -0.079 -0.003 0.019 0.026 0.029 0.027 0.055    || dis=0.00 || select=7/8
006/019-th : 0.115 0.109 0.122 0.121 0.132 0.129 0.135 0.138  ||  -0.084 -0.129 -0.020 -0.030 0.059 0.033 0.078 0.100   || dis=0.00 || select=7/8
007/019-th : 0.075 0.084 0.101 0.118 0.131 0.145 0.162 0.184  ||  -0.470 -0.351 -0.168 -0.018 0.088 0.189 0.306 0.432   || dis=0.02 || select=7/8
008/019-th : 0.063 0.073 0.094 0.134 0.139 0.159 0.169 0.169  ||  -0.623 -0.469 -0.217 0.137 0.174 0.311 0.370 0.370    || dis=0.00 || select=7/8
009/019-th : 0.104 0.100 0.110 0.115 0.124 0.138 0.146 0.163  ||  -0.168 -0.214 -0.114 -0.075 0.000 0.110 0.170 0.281   || dis=0.02 || select=7/8
010/019-th : 0.101 0.111 0.116 0.127 0.130 0.138 0.142 0.135  ||  -0.207 -0.111 -0.066 0.024 0.046 0.109 0.132 0.088    || dis=0.00 || select=6/8
011/019-th : 0.105 0.103 0.106 0.114 0.126 0.136 0.150 0.160  ||  -0.161 -0.186 -0.154 -0.076 0.016 0.099 0.195 0.258   || dis=0.01 || select=7/8
012/019-th : 0.108 0.113 0.111 0.120 0.134 0.131 0.137 0.145  ||  -0.137 -0.094 -0.111 -0.032 0.074 0.052 0.096 0.152   || dis=0.01 || select=7/8
013/019-th : 0.052 0.056 0.069 0.090 0.109 0.148 0.201 0.274  ||  -0.730 -0.651 -0.446 -0.178 0.010 0.312 0.621 0.928   || dis=0.07 || select=7/8
014/019-th : 0.059 0.069 0.077 0.102 0.134 0.153 0.195 0.211  ||  -0.654 -0.510 -0.399 -0.112 0.160 0.295 0.537 0.614   || dis=0.02 || select=7/8
015/019-th : 0.050 0.049 0.062 0.091 0.109 0.153 0.215 0.271  ||  -0.729 -0.759 -0.520 -0.137 0.040 0.384 0.725 0.955   || dis=0.06 || select=7/8
016/019-th : 0.058 0.073 0.096 0.126 0.138 0.161 0.175 0.173  ||  -0.699 -0.475 -0.192 0.081 0.170 0.325 0.403 0.393    || dis=0.00 || select=6/8
017/019-th : 0.119 0.117 0.115 0.125 0.128 0.127 0.133 0.136  ||  -0.047 -0.065 -0.085 0.002 0.026 0.018 0.063 0.083    || dis=0.00 || select=7/8
018/019-th : 0.081 0.096 0.104 0.120 0.128 0.139 0.153 0.177  ||  -0.407 -0.238 -0.154 -0.011 0.052 0.130 0.230 0.376   || dis=0.02 || select=7/8
[epoch=135/600] FLOP : 28.70 MB, ratio : 0.7032, Expected-ratio : 0.7000, Discrepancy : 0.035
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:53:36] [epoch=135/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.506 (2.506)  Prec@1 35.94 (35.94) Prec@5 78.91 (78.91) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:53:42] [epoch=135/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.139 (2.316)  Prec@1 57.14 (37.55) Prec@5 95.24 (82.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.55 Prec@5 82.72 Error@1 62.45 Error@5 17.28 Loss:2.316
***[2020-01-29 06:53:42]*** VALID [epoch=135/600] loss = 2.316416, accuracy@1 = 37.55, accuracy@5 = 82.72 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:53:42]*** start epoch=136/600 Time Left: [04:07:52], LR=[0.087850 ~ 0.087850], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=136, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.404637886346803, FLOP=40.81
[Search] : epoch=136/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:53:42] [epoch=136/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.871 (0.871)  Prec@1 67.97 (67.97) Prec@5 99.61 (99.61) Acls-loss 0.938 (0.938) FLOP-Loss 2.620 (2.620) Arch-Loss 6.178 (6.178)
**TRAIN** [2020-01-29 06:54:06] [epoch=136/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.719 (0.849)  Prec@1 72.02 (70.89) Prec@5 97.62 (97.49) Acls-loss 0.919 (0.885) FLOP-Loss 0.000 (0.107) Arch-Loss 0.919 (1.099)
 **TRAIN** Prec@1 70.89 Prec@5 97.49 Error@1 29.11 Error@5 2.51 Base-Loss:0.849, Arch-Loss=1.099
***[2020-01-29 06:54:06]*** TRAIN [epoch=136/600] base-loss = 0.848919, arch-loss = 1.099172, accuracy-1 = 70.89, accuracy-5 = 97.49
[epoch=136/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.710656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.409 0.242 0.349  ||  0.1323 -0.3893 -0.0253  || discrepancy=0.06 || select=0/3
001/003-th : 0.388 0.148 0.464  ||  0.0192 -0.9470 0.1961  || discrepancy=0.08 || select=2/3
002/003-th : 0.169 0.230 0.601  ||  -0.6129 -0.3044 0.6551  || discrepancy=0.37 || select=2/3
-----------------------------------------------
000/019-th : 0.064 0.082 0.111 0.118 0.142 0.152 0.158 0.173  ||  -0.612 -0.369 -0.071 -0.010 0.177 0.246 0.286 0.376   || dis=0.01 || select=7/8
001/019-th : 0.130 0.123 0.126 0.129 0.126 0.121 0.121 0.123  ||  0.039 -0.017 0.008 0.034 0.005 -0.029 -0.029 -0.017   || dis=0.00 || select=0/8
002/019-th : 0.122 0.129 0.132 0.135 0.130 0.120 0.117 0.114  ||  -0.020 0.036 0.058 0.085 0.047 -0.037 -0.061 -0.083   || dis=0.00 || select=3/8
003/019-th : 0.125 0.131 0.129 0.125 0.125 0.123 0.119 0.122  ||  0.003 0.048 0.032 0.003 -0.003 -0.013 -0.046 -0.024   || dis=0.00 || select=1/8
004/019-th : 0.118 0.122 0.125 0.126 0.126 0.129 0.129 0.125  ||  -0.057 -0.020 0.003 0.015 0.012 0.036 0.031 0.003     || dis=0.00 || select=5/8
005/019-th : 0.119 0.116 0.125 0.126 0.127 0.129 0.128 0.131  ||  -0.052 -0.077 -0.002 0.009 0.012 0.029 0.023 0.046    || dis=0.00 || select=7/8
006/019-th : 0.117 0.110 0.122 0.122 0.132 0.129 0.133 0.135  ||  -0.063 -0.120 -0.021 -0.022 0.060 0.034 0.067 0.080   || dis=0.00 || select=7/8
007/019-th : 0.077 0.084 0.103 0.120 0.132 0.142 0.161 0.182  ||  -0.449 -0.354 -0.154 -0.004 0.095 0.168 0.293 0.413   || dis=0.02 || select=7/8
008/019-th : 0.064 0.073 0.094 0.137 0.139 0.159 0.167 0.167  ||  -0.609 -0.468 -0.219 0.157 0.173 0.306 0.357 0.355    || dis=0.00 || select=6/8
009/019-th : 0.106 0.102 0.110 0.116 0.124 0.136 0.144 0.162  ||  -0.156 -0.190 -0.116 -0.060 0.002 0.095 0.149 0.268   || dis=0.02 || select=7/8
010/019-th : 0.102 0.113 0.117 0.130 0.129 0.137 0.138 0.135  ||  -0.200 -0.098 -0.058 0.045 0.037 0.101 0.109 0.082    || dis=0.00 || select=6/8
011/019-th : 0.107 0.105 0.106 0.115 0.125 0.136 0.149 0.157  ||  -0.142 -0.166 -0.159 -0.072 0.011 0.098 0.183 0.241   || dis=0.01 || select=7/8
012/019-th : 0.110 0.114 0.113 0.121 0.133 0.132 0.135 0.142  ||  -0.123 -0.087 -0.096 -0.029 0.067 0.057 0.085 0.135   || dis=0.01 || select=7/8
013/019-th : 0.052 0.057 0.070 0.091 0.110 0.146 0.200 0.273  ||  -0.732 -0.640 -0.439 -0.172 0.017 0.297 0.613 0.924   || dis=0.07 || select=7/8
014/019-th : 0.061 0.069 0.076 0.103 0.135 0.155 0.194 0.207  ||  -0.632 -0.505 -0.409 -0.103 0.165 0.307 0.530 0.592   || dis=0.01 || select=7/8
015/019-th : 0.050 0.049 0.063 0.091 0.112 0.152 0.216 0.267  ||  -0.733 -0.761 -0.510 -0.135 0.067 0.377 0.724 0.937   || dis=0.05 || select=7/8
016/019-th : 0.058 0.074 0.100 0.128 0.139 0.158 0.172 0.171  ||  -0.698 -0.457 -0.160 0.091 0.172 0.301 0.384 0.381    || dis=0.00 || select=6/8
017/019-th : 0.123 0.119 0.117 0.125 0.126 0.125 0.132 0.133  ||  -0.016 -0.054 -0.067 -0.002 0.011 -0.001 0.054 0.061  || dis=0.00 || select=7/8
018/019-th : 0.083 0.097 0.105 0.122 0.129 0.140 0.149 0.176  ||  -0.391 -0.226 -0.146 0.001 0.053 0.136 0.197 0.365    || dis=0.03 || select=7/8
[epoch=136/600] FLOP : 26.71 MB, ratio : 0.6545, Expected-ratio : 0.7000, Discrepancy : 0.034
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:54:07] [epoch=136/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.567 (2.567)  Prec@1 25.78 (25.78) Prec@5 72.66 (72.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:54:12] [epoch=136/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.315 (2.042)  Prec@1 44.05 (41.17) Prec@5 89.29 (83.91) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.17 Prec@5 83.91 Error@1 58.83 Error@5 16.09 Loss:2.042
***[2020-01-29 06:54:12]*** VALID [epoch=136/600] loss = 2.041895, accuracy@1 = 41.17, accuracy@5 = 83.91 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:54:13]*** start epoch=137/600 Time Left: [04:07:16], LR=[0.087678 ~ 0.087678], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=137, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.396230311139013, FLOP=40.81
[Search] : epoch=137/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:54:13] [epoch=137/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.866 (0.866)  Prec@1 70.70 (70.70) Prec@5 97.27 (97.27) Acls-loss 0.984 (0.984) FLOP-Loss 0.000 (0.000) Arch-Loss 0.984 (0.984)
**TRAIN** [2020-01-29 06:54:37] [epoch=137/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.841 (0.845)  Prec@1 71.43 (71.20) Prec@5 95.24 (97.56) Acls-loss 0.795 (0.892) FLOP-Loss 0.000 (-0.027) Arch-Loss 0.795 (0.839)
 **TRAIN** Prec@1 71.20 Prec@5 97.56 Error@1 28.80 Error@5 2.44 Base-Loss:0.845, Arch-Loss=0.839
***[2020-01-29 06:54:37]*** TRAIN [epoch=137/600] base-loss = 0.844762, arch-loss = 0.839355, accuracy-1 = 71.20, accuracy-5 = 97.56
[epoch=137/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 12, 16, 16, 32, 28, 32, 25, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.574912)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.403 0.241 0.356  ||  0.1166 -0.3986 -0.0069  || discrepancy=0.05 || select=0/3
001/003-th : 0.381 0.146 0.473  ||  0.0025 -0.9611 0.2176  || discrepancy=0.09 || select=2/3
002/003-th : 0.163 0.225 0.612  ||  -0.6404 -0.3164 0.6821  || discrepancy=0.39 || select=2/3
-----------------------------------------------
000/019-th : 0.064 0.082 0.110 0.118 0.140 0.152 0.159 0.176  ||  -0.613 -0.373 -0.079 -0.010 0.164 0.246 0.290 0.390   || dis=0.02 || select=7/8
001/019-th : 0.128 0.121 0.124 0.129 0.129 0.123 0.123 0.125  ||  0.023 -0.029 -0.008 0.030 0.029 -0.018 -0.017 -0.003  || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.130 0.133 0.133 0.122 0.119 0.116  ||  -0.036 0.023 0.043 0.067 0.063 -0.023 -0.045 -0.069   || dis=0.00 || select=3/8
003/019-th : 0.123 0.130 0.127 0.124 0.127 0.124 0.121 0.123  ||  -0.014 0.040 0.017 -0.005 0.014 -0.003 -0.030 -0.014  || dis=0.00 || select=1/8
004/019-th : 0.116 0.120 0.124 0.126 0.127 0.131 0.130 0.127  ||  -0.072 -0.040 -0.004 0.012 0.021 0.048 0.041 0.019    || dis=0.00 || select=5/8
005/019-th : 0.118 0.114 0.123 0.125 0.125 0.130 0.131 0.134  ||  -0.063 -0.091 -0.016 0.002 0.002 0.035 0.044 0.065    || dis=0.00 || select=7/8
006/019-th : 0.115 0.109 0.120 0.121 0.131 0.132 0.134 0.137  ||  -0.076 -0.130 -0.040 -0.027 0.050 0.060 0.075 0.094   || dis=0.00 || select=7/8
007/019-th : 0.074 0.084 0.105 0.118 0.130 0.143 0.163 0.182  ||  -0.477 -0.351 -0.133 -0.013 0.084 0.175 0.306 0.418   || dis=0.02 || select=7/8
008/019-th : 0.064 0.074 0.093 0.134 0.138 0.159 0.169 0.169  ||  -0.609 -0.461 -0.234 0.136 0.167 0.307 0.370 0.369    || dis=0.00 || select=6/8
009/019-th : 0.104 0.101 0.109 0.119 0.125 0.135 0.145 0.163  ||  -0.173 -0.204 -0.127 -0.039 0.010 0.091 0.164 0.277   || dis=0.02 || select=7/8
010/019-th : 0.100 0.111 0.117 0.130 0.131 0.139 0.138 0.135  ||  -0.213 -0.107 -0.059 0.046 0.053 0.113 0.107 0.085    || dis=0.00 || select=5/8
011/019-th : 0.105 0.102 0.107 0.114 0.126 0.137 0.149 0.160  ||  -0.159 -0.193 -0.145 -0.082 0.022 0.105 0.190 0.256   || dis=0.01 || select=7/8
012/019-th : 0.108 0.112 0.112 0.120 0.133 0.133 0.137 0.145  ||  -0.140 -0.104 -0.107 -0.033 0.068 0.065 0.100 0.154   || dis=0.01 || select=7/8
013/019-th : 0.051 0.057 0.069 0.090 0.110 0.146 0.200 0.277  ||  -0.749 -0.634 -0.443 -0.182 0.020 0.299 0.614 0.943   || dis=0.08 || select=7/8
014/019-th : 0.059 0.067 0.076 0.102 0.134 0.155 0.194 0.213  ||  -0.653 -0.528 -0.407 -0.108 0.161 0.309 0.534 0.626   || dis=0.02 || select=7/8
015/019-th : 0.049 0.049 0.061 0.090 0.112 0.150 0.214 0.276  ||  -0.754 -0.754 -0.531 -0.143 0.074 0.371 0.723 0.978   || dis=0.06 || select=7/8
016/019-th : 0.057 0.072 0.098 0.126 0.139 0.161 0.174 0.172  ||  -0.713 -0.477 -0.172 0.081 0.174 0.325 0.400 0.392    || dis=0.00 || select=6/8
017/019-th : 0.122 0.116 0.115 0.125 0.128 0.126 0.134 0.135  ||  -0.026 -0.073 -0.087 -0.003 0.027 0.008 0.067 0.077   || dis=0.00 || select=7/8
018/019-th : 0.082 0.096 0.103 0.122 0.130 0.139 0.150 0.178  ||  -0.397 -0.239 -0.165 0.004 0.061 0.132 0.211 0.376    || dis=0.03 || select=7/8
[epoch=137/600] FLOP : 27.57 MB, ratio : 0.6756, Expected-ratio : 0.7000, Discrepancy : 0.036
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:54:38] [epoch=137/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.786 (1.786)  Prec@1 48.05 (48.05) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:54:43] [epoch=137/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.465 (2.068)  Prec@1 31.55 (38.75) Prec@5 83.93 (82.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.75 Prec@5 82.78 Error@1 61.25 Error@5 17.22 Loss:2.068
***[2020-01-29 06:54:43]*** VALID [epoch=137/600] loss = 2.068008, accuracy@1 = 38.75, accuracy@5 = 82.78 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:54:44]*** start epoch=138/600 Time Left: [04:06:40], LR=[0.087506 ~ 0.087506], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=138, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.387772120594626, FLOP=40.81
[Search] : epoch=138/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:54:44] [epoch=138/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.850 (0.850)  Prec@1 71.88 (71.88) Prec@5 96.88 (96.88) Acls-loss 0.825 (0.825) FLOP-Loss 0.000 (0.000) Arch-Loss 0.825 (0.825)
**TRAIN** [2020-01-29 06:55:08] [epoch=138/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.726 (0.866)  Prec@1 75.00 (70.20) Prec@5 98.21 (97.55) Acls-loss 0.885 (0.863) FLOP-Loss 0.000 (0.054) Arch-Loss 0.885 (0.970)
 **TRAIN** Prec@1 70.20 Prec@5 97.55 Error@1 29.80 Error@5 2.45 Base-Loss:0.866, Arch-Loss=0.970
***[2020-01-29 06:55:08]*** TRAIN [epoch=138/600] base-loss = 0.865626, arch-loss = 0.970268, accuracy-1 = 70.20, accuracy-5 = 97.55
[epoch=138/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 28, 32, 25, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.422912)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.405 0.242 0.353  ||  0.1238 -0.3907 -0.0132  || discrepancy=0.05 || select=0/3
001/003-th : 0.384 0.145 0.471  ||  0.0105 -0.9663 0.2143  || discrepancy=0.09 || select=2/3
002/003-th : 0.161 0.223 0.616  ||  -0.6509 -0.3217 0.6933  || discrepancy=0.39 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.083 0.109 0.116 0.140 0.152 0.159 0.176  ||  -0.607 -0.363 -0.084 -0.027 0.161 0.248 0.290 0.392   || dis=0.02 || select=7/8
001/019-th : 0.129 0.122 0.124 0.129 0.127 0.123 0.122 0.124  ||  0.029 -0.023 -0.009 0.028 0.018 -0.018 -0.022 -0.006  || dis=0.00 || select=0/8
002/019-th : 0.120 0.128 0.130 0.135 0.131 0.122 0.119 0.116  ||  -0.034 0.026 0.047 0.078 0.051 -0.024 -0.046 -0.075   || dis=0.00 || select=3/8
003/019-th : 0.124 0.130 0.128 0.126 0.125 0.123 0.122 0.123  ||  -0.009 0.038 0.021 0.010 0.003 -0.014 -0.026 -0.018   || dis=0.00 || select=1/8
004/019-th : 0.116 0.121 0.125 0.124 0.126 0.131 0.129 0.127  ||  -0.068 -0.034 0.003 -0.004 0.013 0.049 0.036 0.019    || dis=0.00 || select=5/8
005/019-th : 0.118 0.114 0.123 0.123 0.125 0.130 0.132 0.133  ||  -0.057 -0.092 -0.016 -0.016 -0.001 0.039 0.055 0.063  || dis=0.00 || select=7/8
006/019-th : 0.116 0.111 0.120 0.122 0.132 0.131 0.133 0.136  ||  -0.069 -0.118 -0.036 -0.021 0.055 0.048 0.065 0.087   || dis=0.00 || select=7/8
007/019-th : 0.075 0.085 0.106 0.117 0.130 0.145 0.161 0.181  ||  -0.473 -0.340 -0.128 -0.026 0.083 0.188 0.294 0.412   || dis=0.02 || select=7/8
008/019-th : 0.064 0.075 0.092 0.135 0.138 0.157 0.170 0.170  ||  -0.607 -0.448 -0.240 0.138 0.160 0.294 0.373 0.369    || dis=0.00 || select=6/8
009/019-th : 0.104 0.101 0.109 0.118 0.124 0.135 0.146 0.163  ||  -0.170 -0.205 -0.121 -0.042 0.008 0.088 0.164 0.275   || dis=0.02 || select=7/8
010/019-th : 0.101 0.110 0.117 0.131 0.132 0.139 0.137 0.134  ||  -0.208 -0.116 -0.061 0.053 0.061 0.113 0.101 0.082    || dis=0.00 || select=5/8
011/019-th : 0.106 0.104 0.106 0.113 0.126 0.136 0.150 0.159  ||  -0.156 -0.175 -0.154 -0.089 0.022 0.098 0.191 0.254   || dis=0.01 || select=7/8
012/019-th : 0.108 0.112 0.112 0.122 0.133 0.131 0.137 0.144  ||  -0.138 -0.103 -0.104 -0.019 0.070 0.051 0.100 0.150   || dis=0.01 || select=7/8
013/019-th : 0.051 0.057 0.070 0.090 0.112 0.144 0.197 0.279  ||  -0.756 -0.634 -0.438 -0.182 0.034 0.290 0.605 0.951   || dis=0.08 || select=7/8
014/019-th : 0.059 0.067 0.076 0.100 0.135 0.155 0.194 0.213  ||  -0.659 -0.535 -0.402 -0.123 0.173 0.314 0.536 0.631   || dis=0.02 || select=7/8
015/019-th : 0.048 0.048 0.062 0.090 0.113 0.151 0.214 0.274  ||  -0.774 -0.767 -0.510 -0.142 0.085 0.378 0.725 0.973   || dis=0.06 || select=7/8
016/019-th : 0.058 0.072 0.098 0.126 0.141 0.161 0.172 0.171  ||  -0.701 -0.478 -0.174 0.081 0.191 0.322 0.389 0.385    || dis=0.00 || select=6/8
017/019-th : 0.123 0.117 0.115 0.124 0.128 0.126 0.133 0.134  ||  -0.017 -0.065 -0.087 -0.009 0.024 0.004 0.064 0.072   || dis=0.00 || select=7/8
018/019-th : 0.082 0.095 0.102 0.124 0.129 0.140 0.149 0.179  ||  -0.393 -0.252 -0.174 0.020 0.059 0.139 0.201 0.384    || dis=0.03 || select=7/8
[epoch=138/600] FLOP : 26.42 MB, ratio : 0.6474, Expected-ratio : 0.7000, Discrepancy : 0.037
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:55:09] [epoch=138/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.276 (3.276)  Prec@1 28.12 (28.12) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:55:14] [epoch=138/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.016 (2.221)  Prec@1 29.76 (38.90) Prec@5 84.52 (83.09) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.90 Prec@5 83.09 Error@1 61.10 Error@5 16.91 Loss:2.221
***[2020-01-29 06:55:14]*** VALID [epoch=138/600] loss = 2.221284, accuracy@1 = 38.90, accuracy@5 = 83.09 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:55:15]*** start epoch=139/600 Time Left: [04:06:05], LR=[0.087332 ~ 0.087332], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=139, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.3792635465992085, FLOP=40.81
[Search] : epoch=139/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:55:15] [epoch=139/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.895 (0.895)  Prec@1 68.75 (68.75) Prec@5 96.88 (96.88) Acls-loss 0.862 (0.862) FLOP-Loss -2.618 (-2.618) Arch-Loss -4.375 (-4.375)
**TRAIN** [2020-01-29 06:55:39] [epoch=139/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.856 (0.856)  Prec@1 70.83 (70.93) Prec@5 98.81 (97.57) Acls-loss 1.030 (0.872) FLOP-Loss 0.000 (-0.027) Arch-Loss 1.030 (0.819)
 **TRAIN** Prec@1 70.93 Prec@5 97.57 Error@1 29.07 Error@5 2.43 Base-Loss:0.856, Arch-Loss=0.819
***[2020-01-29 06:55:39]*** TRAIN [epoch=139/600] base-loss = 0.856151, arch-loss = 0.819115, accuracy-1 = 70.93, accuracy-5 = 97.57
[epoch=139/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 8, 12, 16, 16, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.084864)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.400 0.239 0.361  ||  0.1096 -0.4067 0.0044  || discrepancy=0.04 || select=0/3
001/003-th : 0.377 0.143 0.480  ||  -0.0063 -0.9752 0.2349  || discrepancy=0.10 || select=2/3
002/003-th : 0.155 0.216 0.629  ||  -0.6793 -0.3434 0.7228  || discrepancy=0.41 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.082 0.110 0.115 0.140 0.150 0.159 0.180  ||  -0.604 -0.369 -0.084 -0.035 0.160 0.228 0.290 0.411   || dis=0.02 || select=7/8
001/019-th : 0.126 0.121 0.122 0.127 0.128 0.126 0.124 0.126  ||  0.010 -0.032 -0.023 0.017 0.025 0.008 -0.007 0.006    || dis=0.00 || select=4/8
002/019-th : 0.119 0.126 0.129 0.132 0.132 0.123 0.121 0.118  ||  -0.045 0.012 0.032 0.060 0.058 -0.010 -0.034 -0.059   || dis=0.00 || select=3/8
003/019-th : 0.122 0.126 0.127 0.126 0.126 0.123 0.124 0.125  ||  -0.025 0.011 0.018 0.010 0.012 -0.014 -0.006 0.001    || dis=0.00 || select=2/8
004/019-th : 0.115 0.119 0.124 0.123 0.128 0.132 0.131 0.128  ||  -0.079 -0.049 -0.005 -0.013 0.023 0.053 0.052 0.029   || dis=0.00 || select=5/8
005/019-th : 0.117 0.112 0.122 0.122 0.125 0.132 0.135 0.135  ||  -0.066 -0.110 -0.022 -0.025 -0.001 0.050 0.073 0.076  || dis=0.00 || select=7/8
006/019-th : 0.115 0.110 0.119 0.121 0.131 0.132 0.135 0.137  ||  -0.084 -0.125 -0.049 -0.026 0.054 0.059 0.078 0.098   || dis=0.00 || select=7/8
007/019-th : 0.075 0.083 0.104 0.116 0.131 0.146 0.162 0.186  ||  -0.472 -0.370 -0.142 -0.032 0.087 0.197 0.301 0.439   || dis=0.02 || select=7/8
008/019-th : 0.064 0.074 0.092 0.134 0.136 0.158 0.171 0.171  ||  -0.598 -0.457 -0.245 0.133 0.150 0.299 0.377 0.376    || dis=0.00 || select=6/8
009/019-th : 0.103 0.099 0.108 0.118 0.126 0.134 0.147 0.165  ||  -0.183 -0.217 -0.130 -0.048 0.019 0.084 0.178 0.291   || dis=0.02 || select=7/8
010/019-th : 0.099 0.109 0.117 0.131 0.131 0.140 0.139 0.135  ||  -0.222 -0.128 -0.060 0.054 0.056 0.122 0.116 0.088    || dis=0.00 || select=5/8
011/019-th : 0.104 0.104 0.107 0.112 0.126 0.135 0.150 0.162  ||  -0.169 -0.174 -0.147 -0.102 0.022 0.087 0.194 0.271   || dis=0.01 || select=7/8
012/019-th : 0.107 0.111 0.111 0.120 0.134 0.131 0.139 0.147  ||  -0.151 -0.112 -0.114 -0.037 0.072 0.052 0.111 0.170   || dis=0.01 || select=7/8
013/019-th : 0.050 0.056 0.069 0.088 0.111 0.144 0.200 0.282  ||  -0.759 -0.655 -0.435 -0.194 0.035 0.292 0.620 0.966   || dis=0.08 || select=7/8
014/019-th : 0.058 0.066 0.075 0.098 0.133 0.156 0.194 0.219  ||  -0.669 -0.536 -0.415 -0.144 0.161 0.323 0.541 0.660   || dis=0.02 || select=7/8
015/019-th : 0.047 0.047 0.062 0.089 0.113 0.149 0.216 0.277  ||  -0.782 -0.791 -0.508 -0.145 0.096 0.371 0.739 0.988   || dis=0.06 || select=7/8
016/019-th : 0.056 0.072 0.097 0.126 0.139 0.162 0.172 0.176  ||  -0.728 -0.481 -0.183 0.076 0.181 0.330 0.392 0.414    || dis=0.00 || select=7/8
017/019-th : 0.121 0.116 0.115 0.122 0.128 0.127 0.135 0.136  ||  -0.033 -0.077 -0.086 -0.024 0.026 0.014 0.080 0.085   || dis=0.00 || select=7/8
018/019-th : 0.082 0.093 0.103 0.121 0.127 0.141 0.150 0.182  ||  -0.394 -0.273 -0.166 -0.002 0.043 0.147 0.209 0.405   || dis=0.03 || select=7/8
[epoch=139/600] FLOP : 28.08 MB, ratio : 0.6881, Expected-ratio : 0.7000, Discrepancy : 0.039
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:55:40] [epoch=139/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.531 (2.531)  Prec@1 37.50 (37.50) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:55:46] [epoch=139/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.263 (2.150)  Prec@1 66.07 (39.58) Prec@5 94.64 (83.77) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.58 Prec@5 83.77 Error@1 60.42 Error@5 16.23 Loss:2.150
***[2020-01-29 06:55:46]*** VALID [epoch=139/600] loss = 2.149898, accuracy@1 = 39.58, accuracy@5 = 83.77 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:55:46]*** start epoch=140/600 Time Left: [04:05:30], LR=[0.087157 ~ 0.087157], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=140, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.370704822419616, FLOP=40.81
[Search] : epoch=140/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:55:46] [epoch=140/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.777 (0.777)  Prec@1 74.61 (74.61) Prec@5 98.83 (98.83) Acls-loss 0.948 (0.948) FLOP-Loss 0.000 (0.000) Arch-Loss 0.948 (0.948)
**TRAIN** [2020-01-29 06:56:10] [epoch=140/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.923 (0.842)  Prec@1 63.69 (71.04) Prec@5 95.83 (97.74) Acls-loss 0.820 (0.865) FLOP-Loss 0.000 (0.054) Arch-Loss 0.820 (0.973)
 **TRAIN** Prec@1 71.04 Prec@5 97.74 Error@1 28.96 Error@5 2.26 Base-Loss:0.842, Arch-Loss=0.973
***[2020-01-29 06:56:10]*** TRAIN [epoch=140/600] base-loss = 0.842317, arch-loss = 0.972772, accuracy-1 = 71.04, accuracy-5 = 97.74
[epoch=140/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 8, 12, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.454528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.402 0.239 0.359  ||  0.1154 -0.4055 0.0001  || discrepancy=0.04 || select=0/3
001/003-th : 0.378 0.144 0.478  ||  -0.0011 -0.9681 0.2325  || discrepancy=0.10 || select=2/3
002/003-th : 0.153 0.217 0.630  ||  -0.6844 -0.3390 0.7272  || discrepancy=0.41 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.082 0.109 0.116 0.141 0.149 0.159 0.178  ||  -0.591 -0.374 -0.093 -0.024 0.171 0.227 0.288 0.400   || dis=0.02 || select=7/8
001/019-th : 0.127 0.122 0.123 0.127 0.125 0.125 0.125 0.125  ||  0.017 -0.025 -0.014 0.018 -0.003 0.001 -0.005 -0.001  || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.129 0.132 0.132 0.124 0.120 0.117  ||  -0.038 0.016 0.034 0.053 0.057 -0.006 -0.041 -0.064   || dis=0.00 || select=4/8
003/019-th : 0.122 0.127 0.127 0.126 0.126 0.123 0.124 0.125  ||  -0.021 0.013 0.017 0.007 0.011 -0.014 -0.010 -0.000   || dis=0.00 || select=2/8
004/019-th : 0.116 0.119 0.126 0.124 0.124 0.133 0.130 0.127  ||  -0.074 -0.044 0.009 -0.003 -0.002 0.061 0.044 0.020   || dis=0.00 || select=5/8
005/019-th : 0.117 0.113 0.122 0.123 0.126 0.130 0.134 0.135  ||  -0.063 -0.105 -0.028 -0.016 0.004 0.041 0.068 0.076   || dis=0.00 || select=7/8
006/019-th : 0.115 0.111 0.117 0.120 0.131 0.131 0.135 0.138  ||  -0.079 -0.114 -0.061 -0.038 0.049 0.051 0.081 0.101   || dis=0.00 || select=7/8
007/019-th : 0.076 0.084 0.104 0.116 0.129 0.144 0.161 0.185  ||  -0.456 -0.362 -0.145 -0.030 0.076 0.184 0.296 0.436   || dis=0.02 || select=7/8
008/019-th : 0.064 0.073 0.091 0.136 0.137 0.160 0.169 0.171  ||  -0.603 -0.475 -0.254 0.154 0.156 0.317 0.366 0.379    || dis=0.00 || select=7/8
009/019-th : 0.102 0.100 0.109 0.117 0.126 0.134 0.149 0.163  ||  -0.188 -0.205 -0.125 -0.052 0.018 0.081 0.188 0.281   || dis=0.01 || select=7/8
010/019-th : 0.100 0.109 0.115 0.131 0.133 0.140 0.137 0.135  ||  -0.214 -0.126 -0.071 0.056 0.069 0.120 0.102 0.088    || dis=0.00 || select=5/8
011/019-th : 0.104 0.104 0.105 0.112 0.128 0.136 0.148 0.161  ||  -0.168 -0.173 -0.160 -0.098 0.039 0.099 0.183 0.268   || dis=0.01 || select=7/8
012/019-th : 0.108 0.112 0.112 0.120 0.133 0.131 0.138 0.147  ||  -0.145 -0.107 -0.105 -0.036 0.068 0.051 0.102 0.165   || dis=0.01 || select=7/8
013/019-th : 0.051 0.057 0.069 0.089 0.110 0.139 0.199 0.287  ||  -0.751 -0.639 -0.439 -0.191 0.028 0.258 0.618 0.984   || dis=0.09 || select=7/8
014/019-th : 0.057 0.065 0.075 0.099 0.133 0.156 0.196 0.218  ||  -0.676 -0.555 -0.409 -0.128 0.166 0.325 0.548 0.657   || dis=0.02 || select=7/8
015/019-th : 0.047 0.046 0.062 0.089 0.114 0.151 0.213 0.279  ||  -0.778 -0.803 -0.512 -0.148 0.102 0.382 0.726 0.998   || dis=0.07 || select=7/8
016/019-th : 0.056 0.073 0.096 0.126 0.140 0.164 0.170 0.175  ||  -0.736 -0.468 -0.187 0.081 0.183 0.345 0.381 0.408    || dis=0.00 || select=7/8
017/019-th : 0.121 0.115 0.115 0.122 0.130 0.126 0.135 0.137  ||  -0.028 -0.087 -0.083 -0.024 0.040 0.006 0.076 0.089   || dis=0.00 || select=7/8
018/019-th : 0.082 0.094 0.105 0.122 0.127 0.140 0.150 0.181  ||  -0.397 -0.261 -0.151 -0.001 0.040 0.139 0.208 0.398   || dis=0.03 || select=7/8
[epoch=140/600] FLOP : 28.45 MB, ratio : 0.6972, Expected-ratio : 0.7000, Discrepancy : 0.039
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:56:11] [epoch=140/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.595 (3.595)  Prec@1 21.09 (21.09) Prec@5 73.44 (73.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:56:17] [epoch=140/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.890 (2.222)  Prec@1 44.64 (38.48) Prec@5 85.71 (83.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.48 Prec@5 83.31 Error@1 61.52 Error@5 16.69 Loss:2.222
***[2020-01-29 06:56:17]*** VALID [epoch=140/600] loss = 2.221866, accuracy@1 = 38.48, accuracy@5 = 83.31 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:56:17]*** start epoch=141/600 Time Left: [04:04:55], LR=[0.086982 ~ 0.086982], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=141, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.362096182697594, FLOP=40.81
[Search] : epoch=141/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:56:17] [epoch=141/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.929 (0.929)  Prec@1 69.14 (69.14) Prec@5 96.88 (96.88) Acls-loss 0.827 (0.827) FLOP-Loss 0.000 (0.000) Arch-Loss 0.827 (0.827)
**TRAIN** [2020-01-29 06:56:41] [epoch=141/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.895 (0.851)  Prec@1 66.67 (70.92) Prec@5 98.81 (97.51) Acls-loss 0.993 (0.874) FLOP-Loss 0.000 (0.000) Arch-Loss 0.993 (0.874)
 **TRAIN** Prec@1 70.92 Prec@5 97.51 Error@1 29.08 Error@5 2.49 Base-Loss:0.851, Arch-Loss=0.874
***[2020-01-29 06:56:41]*** TRAIN [epoch=141/600] base-loss = 0.850650, arch-loss = 0.874290, accuracy-1 = 70.92, accuracy-5 = 97.51
[epoch=141/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 11, 12, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.454528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.400 0.237 0.363  ||  0.1084 -0.4147 0.0097  || discrepancy=0.04 || select=0/3
001/003-th : 0.374 0.144 0.482  ||  -0.0098 -0.9636 0.2438  || discrepancy=0.11 || select=2/3
002/003-th : 0.151 0.213 0.636  ||  -0.6981 -0.3494 0.7422  || discrepancy=0.42 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.081 0.106 0.117 0.141 0.150 0.160 0.180  ||  -0.589 -0.389 -0.118 -0.017 0.174 0.236 0.295 0.412   || dis=0.02 || select=7/8
001/019-th : 0.126 0.122 0.123 0.127 0.125 0.126 0.126 0.126  ||  0.007 -0.028 -0.015 0.013 -0.003 0.003 0.008 0.004    || dis=0.00 || select=3/8
002/019-th : 0.120 0.126 0.129 0.130 0.131 0.125 0.120 0.118  ||  -0.041 0.012 0.032 0.038 0.049 0.000 -0.037 -0.058    || dis=0.00 || select=4/8
003/019-th : 0.122 0.126 0.124 0.127 0.127 0.124 0.124 0.126  ||  -0.027 0.010 -0.005 0.018 0.019 -0.009 -0.008 0.007   || dis=0.00 || select=4/8
004/019-th : 0.115 0.118 0.125 0.125 0.125 0.132 0.131 0.128  ||  -0.082 -0.052 0.001 0.000 0.007 0.061 0.050 0.028     || dis=0.00 || select=5/8
005/019-th : 0.116 0.113 0.122 0.123 0.126 0.132 0.133 0.136  ||  -0.076 -0.100 -0.027 -0.017 0.007 0.053 0.063 0.082   || dis=0.00 || select=7/8
006/019-th : 0.115 0.110 0.116 0.119 0.130 0.133 0.136 0.140  ||  -0.084 -0.124 -0.071 -0.046 0.043 0.062 0.086 0.113   || dis=0.00 || select=7/8
007/019-th : 0.075 0.083 0.105 0.115 0.130 0.144 0.163 0.185  ||  -0.471 -0.365 -0.130 -0.040 0.081 0.185 0.307 0.435   || dis=0.02 || select=7/8
008/019-th : 0.062 0.074 0.089 0.134 0.138 0.163 0.169 0.171  ||  -0.628 -0.455 -0.267 0.137 0.167 0.334 0.371 0.382    || dis=0.00 || select=7/8
009/019-th : 0.102 0.098 0.107 0.118 0.124 0.136 0.150 0.165  ||  -0.187 -0.225 -0.143 -0.042 0.005 0.099 0.196 0.291   || dis=0.02 || select=7/8
010/019-th : 0.100 0.108 0.116 0.131 0.132 0.140 0.138 0.136  ||  -0.218 -0.134 -0.068 0.054 0.062 0.121 0.107 0.096    || dis=0.00 || select=5/8
011/019-th : 0.105 0.100 0.105 0.114 0.129 0.134 0.149 0.164  ||  -0.165 -0.207 -0.164 -0.083 0.046 0.086 0.190 0.285   || dis=0.02 || select=7/8
012/019-th : 0.107 0.111 0.113 0.120 0.130 0.132 0.138 0.149  ||  -0.153 -0.113 -0.101 -0.035 0.045 0.062 0.101 0.178   || dis=0.01 || select=7/8
013/019-th : 0.051 0.055 0.069 0.088 0.111 0.137 0.201 0.288  ||  -0.749 -0.656 -0.436 -0.199 0.034 0.249 0.634 0.993   || dis=0.09 || select=7/8
014/019-th : 0.057 0.065 0.075 0.100 0.130 0.157 0.196 0.220  ||  -0.675 -0.558 -0.410 -0.121 0.140 0.332 0.552 0.666   || dis=0.02 || select=7/8
015/019-th : 0.047 0.046 0.062 0.088 0.112 0.150 0.216 0.279  ||  -0.784 -0.809 -0.506 -0.152 0.090 0.381 0.747 1.002   || dis=0.06 || select=7/8
016/019-th : 0.056 0.073 0.095 0.127 0.141 0.165 0.169 0.175  ||  -0.737 -0.465 -0.199 0.086 0.192 0.351 0.372 0.409    || dis=0.01 || select=7/8
017/019-th : 0.122 0.114 0.114 0.122 0.129 0.128 0.135 0.137  ||  -0.028 -0.096 -0.096 -0.022 0.033 0.021 0.079 0.095   || dis=0.00 || select=7/8
018/019-th : 0.081 0.094 0.105 0.122 0.128 0.138 0.150 0.182  ||  -0.411 -0.263 -0.144 0.007 0.047 0.127 0.212 0.404    || dis=0.03 || select=7/8
[epoch=141/600] FLOP : 28.45 MB, ratio : 0.6972, Expected-ratio : 0.7000, Discrepancy : 0.040
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:56:42] [epoch=141/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.102 (2.102)  Prec@1 25.39 (25.39) Prec@5 80.08 (80.08) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:56:48] [epoch=141/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.909 (2.226)  Prec@1 21.43 (37.63) Prec@5 73.81 (81.81) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.63 Prec@5 81.81 Error@1 62.37 Error@5 18.19 Loss:2.226
***[2020-01-29 06:56:48]*** VALID [epoch=141/600] loss = 2.225578, accuracy@1 = 37.63, accuracy@5 = 81.81 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:56:48]*** start epoch=142/600 Time Left: [04:04:20], LR=[0.086805 ~ 0.086805], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=142, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.353437863443349, FLOP=40.81
[Search] : epoch=142/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:56:49] [epoch=142/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.764 (0.764)  Prec@1 72.27 (72.27) Prec@5 97.66 (97.66) Acls-loss 0.932 (0.932) FLOP-Loss 0.000 (0.000) Arch-Loss 0.932 (0.932)
**TRAIN** [2020-01-29 06:57:13] [epoch=142/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.984 (0.838)  Prec@1 67.86 (71.66) Prec@5 97.62 (97.62) Acls-loss 0.834 (0.868) FLOP-Loss 2.640 (0.045) Arch-Loss 6.114 (0.958)
 **TRAIN** Prec@1 71.66 Prec@5 97.62 Error@1 28.34 Error@5 2.38 Base-Loss:0.838, Arch-Loss=0.958
***[2020-01-29 06:57:13]*** TRAIN [epoch=142/600] base-loss = 0.837976, arch-loss = 0.957936, accuracy-1 = 71.66, accuracy-5 = 97.62
[epoch=142/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 9, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.454528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.403 0.234 0.364  ||  0.1119 -0.4316 0.0098  || discrepancy=0.04 || select=0/3
001/003-th : 0.374 0.144 0.483  ||  -0.0093 -0.9660 0.2471  || discrepancy=0.11 || select=2/3
002/003-th : 0.146 0.213 0.641  ||  -0.7192 -0.3416 0.7587  || discrepancy=0.43 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.082 0.104 0.116 0.141 0.153 0.157 0.180  ||  -0.585 -0.378 -0.131 -0.022 0.170 0.255 0.277 0.415   || dis=0.02 || select=7/8
001/019-th : 0.126 0.122 0.124 0.127 0.124 0.124 0.127 0.125  ||  0.008 -0.022 -0.011 0.014 -0.008 -0.009 0.011 0.001   || dis=0.00 || select=3/8
002/019-th : 0.120 0.128 0.129 0.128 0.130 0.126 0.120 0.118  ||  -0.038 0.021 0.029 0.026 0.041 0.007 -0.038 -0.061    || dis=0.00 || select=4/8
003/019-th : 0.122 0.126 0.124 0.129 0.126 0.124 0.124 0.125  ||  -0.023 0.009 -0.007 0.036 0.007 -0.007 -0.009 0.002   || dis=0.00 || select=3/8
004/019-th : 0.115 0.118 0.126 0.125 0.126 0.130 0.132 0.129  ||  -0.078 -0.059 0.010 0.001 0.006 0.043 0.053 0.031     || dis=0.00 || select=6/8
005/019-th : 0.115 0.113 0.122 0.124 0.127 0.130 0.133 0.135  ||  -0.081 -0.098 -0.023 -0.011 0.017 0.042 0.066 0.082   || dis=0.00 || select=7/8
006/019-th : 0.115 0.110 0.117 0.120 0.130 0.133 0.136 0.140  ||  -0.078 -0.130 -0.066 -0.041 0.039 0.063 0.085 0.111   || dis=0.00 || select=7/8
007/019-th : 0.075 0.083 0.105 0.115 0.131 0.143 0.161 0.186  ||  -0.466 -0.364 -0.131 -0.037 0.089 0.178 0.295 0.437   || dis=0.02 || select=7/8
008/019-th : 0.062 0.074 0.090 0.135 0.138 0.163 0.167 0.172  ||  -0.633 -0.461 -0.258 0.143 0.168 0.337 0.358 0.387    || dis=0.00 || select=7/8
009/019-th : 0.102 0.099 0.107 0.117 0.124 0.136 0.150 0.165  ||  -0.190 -0.221 -0.136 -0.050 0.008 0.098 0.194 0.291   || dis=0.02 || select=7/8
010/019-th : 0.100 0.108 0.116 0.130 0.132 0.139 0.139 0.136  ||  -0.215 -0.133 -0.063 0.045 0.060 0.116 0.113 0.093    || dis=0.00 || select=5/8
011/019-th : 0.105 0.098 0.104 0.114 0.130 0.137 0.148 0.163  ||  -0.161 -0.224 -0.165 -0.074 0.051 0.109 0.184 0.278   || dis=0.02 || select=7/8
012/019-th : 0.107 0.112 0.113 0.120 0.129 0.132 0.137 0.149  ||  -0.148 -0.107 -0.100 -0.038 0.037 0.060 0.097 0.178   || dis=0.01 || select=7/8
013/019-th : 0.050 0.055 0.068 0.087 0.111 0.136 0.201 0.290  ||  -0.752 -0.662 -0.444 -0.201 0.045 0.247 0.635 1.002   || dis=0.09 || select=7/8
014/019-th : 0.057 0.064 0.076 0.101 0.131 0.158 0.191 0.220  ||  -0.680 -0.562 -0.399 -0.108 0.151 0.335 0.527 0.666   || dis=0.03 || select=7/8
015/019-th : 0.047 0.046 0.062 0.088 0.113 0.149 0.215 0.281  ||  -0.786 -0.811 -0.506 -0.150 0.095 0.373 0.742 1.009   || dis=0.07 || select=7/8
016/019-th : 0.055 0.073 0.097 0.126 0.140 0.163 0.168 0.177  ||  -0.743 -0.461 -0.181 0.077 0.185 0.336 0.370 0.419    || dis=0.01 || select=7/8
017/019-th : 0.122 0.113 0.114 0.123 0.130 0.127 0.134 0.138  ||  -0.021 -0.098 -0.096 -0.016 0.039 0.013 0.070 0.096   || dis=0.00 || select=7/8
018/019-th : 0.081 0.094 0.105 0.123 0.126 0.138 0.151 0.181  ||  -0.409 -0.254 -0.150 0.011 0.034 0.130 0.218 0.400    || dis=0.03 || select=7/8
[epoch=142/600] FLOP : 28.45 MB, ratio : 0.6972, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:57:13] [epoch=142/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.105 (2.105)  Prec@1 45.31 (45.31) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:57:19] [epoch=142/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.843 (2.166)  Prec@1 35.71 (37.27) Prec@5 85.71 (82.74) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.27 Prec@5 82.74 Error@1 62.73 Error@5 17.26 Loss:2.166
***[2020-01-29 06:57:19]*** VALID [epoch=142/600] loss = 2.166208, accuracy@1 = 37.27, accuracy@5 = 82.74 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:57:19]*** start epoch=143/600 Time Left: [04:03:45], LR=[0.086627 ~ 0.086627], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=143, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.344730102029078, FLOP=40.81
[Search] : epoch=143/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:57:20] [epoch=143/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.935 (0.935)  Prec@1 68.75 (68.75) Prec@5 97.27 (97.27) Acls-loss 0.882 (0.882) FLOP-Loss 0.000 (0.000) Arch-Loss 0.882 (0.882)
**TRAIN** [2020-01-29 06:57:44] [epoch=143/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.987 (0.840)  Prec@1 64.88 (71.14) Prec@5 96.43 (97.70) Acls-loss 0.887 (0.883) FLOP-Loss 0.000 (0.000) Arch-Loss 0.887 (0.883)
 **TRAIN** Prec@1 71.14 Prec@5 97.70 Error@1 28.86 Error@5 2.30 Base-Loss:0.840, Arch-Loss=0.883
***[2020-01-29 06:57:44]*** TRAIN [epoch=143/600] base-loss = 0.840206, arch-loss = 0.882821, accuracy-1 = 71.14, accuracy-5 = 97.70
[epoch=143/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 9, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.454528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.402 0.232 0.366  ||  0.1099 -0.4410 0.0148  || discrepancy=0.04 || select=0/3
001/003-th : 0.371 0.144 0.485  ||  -0.0137 -0.9634 0.2545  || discrepancy=0.11 || select=2/3
002/003-th : 0.144 0.212 0.644  ||  -0.7291 -0.3429 0.7685  || discrepancy=0.43 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.083 0.105 0.116 0.137 0.154 0.159 0.182  ||  -0.604 -0.364 -0.127 -0.028 0.144 0.256 0.290 0.426   || dis=0.02 || select=7/8
001/019-th : 0.126 0.122 0.123 0.128 0.124 0.124 0.127 0.126  ||  0.006 -0.028 -0.020 0.021 -0.006 -0.011 0.017 0.006   || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.129 0.129 0.130 0.126 0.121 0.118  ||  -0.041 0.011 0.030 0.027 0.039 0.011 -0.033 -0.055    || dis=0.00 || select=4/8
003/019-th : 0.121 0.126 0.124 0.129 0.126 0.125 0.124 0.126  ||  -0.029 0.006 -0.010 0.033 0.009 -0.000 -0.004 0.006   || dis=0.00 || select=3/8
004/019-th : 0.114 0.116 0.125 0.125 0.128 0.131 0.132 0.129  ||  -0.086 -0.071 0.005 0.001 0.025 0.053 0.060 0.032     || dis=0.00 || select=6/8
005/019-th : 0.116 0.114 0.121 0.122 0.127 0.129 0.134 0.137  ||  -0.076 -0.092 -0.034 -0.022 0.014 0.034 0.070 0.088   || dis=0.00 || select=7/8
006/019-th : 0.114 0.109 0.118 0.120 0.129 0.133 0.137 0.140  ||  -0.087 -0.137 -0.060 -0.038 0.033 0.064 0.092 0.116   || dis=0.00 || select=7/8
007/019-th : 0.074 0.083 0.105 0.118 0.131 0.142 0.161 0.186  ||  -0.475 -0.369 -0.133 -0.016 0.094 0.171 0.297 0.438   || dis=0.02 || select=7/8
008/019-th : 0.061 0.073 0.091 0.134 0.140 0.164 0.166 0.171  ||  -0.641 -0.464 -0.246 0.136 0.180 0.344 0.351 0.384    || dis=0.01 || select=7/8
009/019-th : 0.102 0.098 0.106 0.116 0.126 0.135 0.149 0.167  ||  -0.191 -0.225 -0.148 -0.059 0.026 0.091 0.193 0.303   || dis=0.02 || select=7/8
010/019-th : 0.098 0.109 0.116 0.128 0.133 0.141 0.140 0.135  ||  -0.231 -0.127 -0.068 0.037 0.069 0.134 0.123 0.086    || dis=0.00 || select=5/8
011/019-th : 0.103 0.098 0.104 0.115 0.129 0.138 0.148 0.163  ||  -0.175 -0.229 -0.163 -0.066 0.050 0.118 0.185 0.283   || dis=0.02 || select=7/8
012/019-th : 0.107 0.111 0.112 0.120 0.129 0.134 0.138 0.148  ||  -0.149 -0.113 -0.105 -0.038 0.037 0.072 0.106 0.175   || dis=0.01 || select=7/8
013/019-th : 0.050 0.054 0.067 0.088 0.111 0.137 0.200 0.293  ||  -0.756 -0.668 -0.461 -0.191 0.040 0.253 0.634 1.015   || dis=0.09 || select=7/8
014/019-th : 0.057 0.064 0.075 0.102 0.132 0.155 0.192 0.222  ||  -0.681 -0.566 -0.406 -0.105 0.158 0.319 0.531 0.677   || dis=0.03 || select=7/8
015/019-th : 0.046 0.045 0.061 0.087 0.112 0.149 0.218 0.281  ||  -0.800 -0.811 -0.508 -0.158 0.092 0.380 0.759 1.014   || dis=0.06 || select=7/8
016/019-th : 0.056 0.073 0.098 0.125 0.139 0.162 0.170 0.177  ||  -0.740 -0.462 -0.178 0.071 0.177 0.333 0.376 0.421    || dis=0.01 || select=7/8
017/019-th : 0.121 0.114 0.113 0.121 0.129 0.128 0.136 0.138  ||  -0.029 -0.096 -0.099 -0.033 0.034 0.023 0.084 0.099   || dis=0.00 || select=7/8
018/019-th : 0.080 0.095 0.106 0.124 0.127 0.138 0.149 0.181  ||  -0.414 -0.251 -0.135 0.019 0.040 0.127 0.206 0.397    || dis=0.03 || select=7/8
[epoch=143/600] FLOP : 28.45 MB, ratio : 0.6972, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:57:44] [epoch=143/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.877 (1.877)  Prec@1 35.16 (35.16) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:57:50] [epoch=143/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.324 (2.001)  Prec@1 32.14 (40.79) Prec@5 80.36 (84.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.79 Prec@5 84.79 Error@1 59.21 Error@5 15.21 Loss:2.001
***[2020-01-29 06:57:50]*** VALID [epoch=143/600] loss = 2.001234, accuracy@1 = 40.79, accuracy@5 = 84.79 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:57:50]*** start epoch=144/600 Time Left: [04:03:11], LR=[0.086448 ~ 0.086448], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=144, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.335973137182458, FLOP=40.81
[Search] : epoch=144/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:57:51] [epoch=144/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.811 (0.811)  Prec@1 72.27 (72.27) Prec@5 98.44 (98.44) Acls-loss 0.830 (0.830) FLOP-Loss 0.000 (0.000) Arch-Loss 0.830 (0.830)
**TRAIN** [2020-01-29 06:58:15] [epoch=144/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.922 (0.840)  Prec@1 64.88 (71.56) Prec@5 97.02 (97.62) Acls-loss 0.802 (0.868) FLOP-Loss 0.000 (0.054) Arch-Loss 0.802 (0.977)
 **TRAIN** Prec@1 71.56 Prec@5 97.62 Error@1 28.44 Error@5 2.38 Base-Loss:0.840, Arch-Loss=0.977
***[2020-01-29 06:58:15]*** TRAIN [epoch=144/600] base-loss = 0.839773, arch-loss = 0.976576, accuracy-1 = 71.56, accuracy-5 = 97.62
[epoch=144/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 9, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.103872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.404 0.234 0.362  ||  0.1165 -0.4286 0.0088  || discrepancy=0.04 || select=0/3
001/003-th : 0.371 0.143 0.487  ||  -0.0133 -0.9694 0.2585  || discrepancy=0.12 || select=2/3
002/003-th : 0.141 0.212 0.647  ||  -0.7438 -0.3377 0.7805  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.083 0.105 0.117 0.137 0.151 0.159 0.181  ||  -0.588 -0.360 -0.123 -0.018 0.136 0.235 0.291 0.418   || dis=0.02 || select=7/8
001/019-th : 0.127 0.123 0.124 0.127 0.125 0.123 0.127 0.125  ||  0.015 -0.021 -0.013 0.013 -0.003 -0.016 0.011 -0.004  || dis=0.00 || select=0/8
002/019-th : 0.120 0.126 0.129 0.130 0.130 0.126 0.121 0.118  ||  -0.040 0.006 0.034 0.039 0.038 0.007 -0.035 -0.056    || dis=0.00 || select=3/8
003/019-th : 0.121 0.126 0.124 0.129 0.126 0.125 0.124 0.125  ||  -0.027 0.014 -0.005 0.033 0.006 0.002 -0.010 -0.001   || dis=0.00 || select=3/8
004/019-th : 0.115 0.117 0.126 0.123 0.126 0.130 0.134 0.129  ||  -0.086 -0.063 0.011 -0.019 0.010 0.044 0.068 0.035    || dis=0.00 || select=6/8
005/019-th : 0.116 0.115 0.122 0.124 0.125 0.129 0.133 0.135  ||  -0.072 -0.084 -0.028 -0.005 -0.001 0.030 0.064 0.079  || dis=0.00 || select=7/8
006/019-th : 0.115 0.110 0.119 0.121 0.127 0.132 0.136 0.140  ||  -0.082 -0.128 -0.049 -0.035 0.019 0.057 0.084 0.116   || dis=0.00 || select=7/8
007/019-th : 0.075 0.083 0.104 0.119 0.131 0.143 0.162 0.184  ||  -0.469 -0.368 -0.137 -0.009 0.088 0.175 0.300 0.429   || dis=0.02 || select=7/8
008/019-th : 0.058 0.075 0.094 0.133 0.139 0.165 0.165 0.171  ||  -0.691 -0.443 -0.208 0.137 0.177 0.347 0.351 0.384    || dis=0.01 || select=7/8
009/019-th : 0.100 0.100 0.105 0.118 0.126 0.136 0.149 0.166  ||  -0.206 -0.212 -0.155 -0.039 0.022 0.097 0.191 0.301   || dis=0.02 || select=7/8
010/019-th : 0.099 0.108 0.115 0.129 0.131 0.143 0.140 0.135  ||  -0.228 -0.132 -0.076 0.044 0.058 0.146 0.124 0.084    || dis=0.00 || select=5/8
011/019-th : 0.105 0.099 0.105 0.115 0.127 0.139 0.148 0.162  ||  -0.159 -0.221 -0.161 -0.065 0.029 0.119 0.183 0.274   || dis=0.01 || select=7/8
012/019-th : 0.108 0.111 0.113 0.119 0.130 0.135 0.139 0.146  ||  -0.140 -0.117 -0.097 -0.046 0.045 0.078 0.111 0.160   || dis=0.01 || select=7/8
013/019-th : 0.050 0.054 0.067 0.088 0.110 0.137 0.202 0.290  ||  -0.753 -0.670 -0.454 -0.193 0.038 0.256 0.643 1.004   || dis=0.09 || select=7/8
014/019-th : 0.057 0.064 0.076 0.103 0.132 0.155 0.194 0.220  ||  -0.681 -0.570 -0.399 -0.096 0.158 0.314 0.540 0.668   || dis=0.03 || select=7/8
015/019-th : 0.045 0.045 0.061 0.087 0.112 0.148 0.220 0.281  ||  -0.806 -0.816 -0.505 -0.159 0.092 0.375 0.773 1.017   || dis=0.06 || select=7/8
016/019-th : 0.055 0.073 0.097 0.126 0.141 0.161 0.168 0.179  ||  -0.743 -0.469 -0.181 0.076 0.191 0.327 0.365 0.431    || dis=0.01 || select=7/8
017/019-th : 0.121 0.115 0.115 0.121 0.129 0.128 0.135 0.136  ||  -0.031 -0.084 -0.086 -0.031 0.030 0.024 0.080 0.088   || dis=0.00 || select=7/8
018/019-th : 0.081 0.095 0.107 0.119 0.127 0.137 0.152 0.181  ||  -0.405 -0.250 -0.126 -0.021 0.043 0.122 0.224 0.395   || dis=0.03 || select=7/8
[epoch=144/600] FLOP : 27.10 MB, ratio : 0.6641, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:58:16] [epoch=144/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.926 (1.926)  Prec@1 26.95 (26.95) Prec@5 77.34 (77.34) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:58:22] [epoch=144/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.743 (2.074)  Prec@1 40.48 (37.66) Prec@5 78.57 (82.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.66 Prec@5 82.38 Error@1 62.34 Error@5 17.62 Loss:2.074
***[2020-01-29 06:58:22]*** VALID [epoch=144/600] loss = 2.074338, accuracy@1 = 37.66, accuracy@5 = 82.38 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:58:22]*** start epoch=145/600 Time Left: [04:02:37], LR=[0.086269 ~ 0.086269], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=145, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.3271672089801045, FLOP=40.81
[Search] : epoch=145/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:58:23] [epoch=145/600][000/098] Time 0.74 (0.74) Data 0.36 (0.36) Base-Loss 0.887 (0.887)  Prec@1 68.36 (68.36) Prec@5 98.05 (98.05) Acls-loss 0.781 (0.781) FLOP-Loss 0.000 (0.000) Arch-Loss 0.781 (0.781)
**TRAIN** [2020-01-29 06:58:46] [epoch=145/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.794 (0.837)  Prec@1 72.62 (71.62) Prec@5 98.21 (97.57) Acls-loss 0.775 (0.864) FLOP-Loss 0.000 (0.027) Arch-Loss 0.775 (0.918)
 **TRAIN** Prec@1 71.62 Prec@5 97.57 Error@1 28.38 Error@5 2.43 Base-Loss:0.837, Arch-Loss=0.918
***[2020-01-29 06:58:47]*** TRAIN [epoch=145/600] base-loss = 0.836537, arch-loss = 0.917679, accuracy-1 = 71.62, accuracy-5 = 97.57
[epoch=145/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 9, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.454528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.403 0.234 0.363  ||  0.1166 -0.4281 0.0106  || discrepancy=0.04 || select=0/3
001/003-th : 0.369 0.143 0.488  ||  -0.0155 -0.9654 0.2637  || discrepancy=0.12 || select=2/3
002/003-th : 0.136 0.210 0.654  ||  -0.7690 -0.3338 0.8013  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.084 0.106 0.116 0.135 0.150 0.163 0.182  ||  -0.600 -0.352 -0.118 -0.028 0.121 0.228 0.311 0.422   || dis=0.02 || select=7/8
001/019-th : 0.127 0.123 0.124 0.128 0.124 0.122 0.127 0.124  ||  0.015 -0.016 -0.012 0.021 -0.010 -0.025 0.016 -0.007  || dis=0.00 || select=3/8
002/019-th : 0.119 0.125 0.129 0.130 0.130 0.127 0.122 0.118  ||  -0.046 0.003 0.032 0.037 0.043 0.013 -0.027 -0.055    || dis=0.00 || select=4/8
003/019-th : 0.121 0.127 0.124 0.128 0.125 0.125 0.124 0.125  ||  -0.028 0.015 -0.006 0.027 0.003 -0.000 -0.009 0.003   || dis=0.00 || select=3/8
004/019-th : 0.114 0.116 0.125 0.122 0.127 0.132 0.134 0.130  ||  -0.092 -0.070 -0.002 -0.020 0.018 0.054 0.072 0.042   || dis=0.00 || select=6/8
005/019-th : 0.116 0.115 0.121 0.123 0.125 0.130 0.134 0.135  ||  -0.073 -0.081 -0.033 -0.014 0.000 0.038 0.069 0.078   || dis=0.00 || select=7/8
006/019-th : 0.115 0.110 0.117 0.120 0.127 0.133 0.136 0.141  ||  -0.079 -0.123 -0.065 -0.037 0.018 0.066 0.081 0.119   || dis=0.00 || select=7/8
007/019-th : 0.076 0.082 0.104 0.119 0.132 0.143 0.161 0.183  ||  -0.461 -0.374 -0.142 -0.002 0.094 0.180 0.296 0.423   || dis=0.02 || select=7/8
008/019-th : 0.058 0.074 0.094 0.133 0.141 0.166 0.164 0.172  ||  -0.697 -0.452 -0.215 0.134 0.192 0.359 0.347 0.391    || dis=0.01 || select=7/8
009/019-th : 0.100 0.099 0.105 0.120 0.124 0.137 0.148 0.166  ||  -0.204 -0.215 -0.155 -0.027 0.009 0.104 0.186 0.302   || dis=0.02 || select=7/8
010/019-th : 0.098 0.109 0.115 0.125 0.132 0.142 0.142 0.136  ||  -0.230 -0.128 -0.072 0.010 0.060 0.138 0.134 0.095    || dis=0.00 || select=5/8
011/019-th : 0.106 0.097 0.104 0.115 0.126 0.139 0.149 0.163  ||  -0.149 -0.235 -0.170 -0.072 0.027 0.119 0.192 0.282   || dis=0.01 || select=7/8
012/019-th : 0.108 0.110 0.113 0.119 0.129 0.135 0.139 0.146  ||  -0.143 -0.120 -0.093 -0.042 0.036 0.081 0.111 0.163   || dis=0.01 || select=7/8
013/019-th : 0.050 0.054 0.068 0.086 0.110 0.139 0.200 0.292  ||  -0.747 -0.684 -0.447 -0.207 0.035 0.273 0.636 1.014   || dis=0.09 || select=7/8
014/019-th : 0.057 0.063 0.076 0.101 0.135 0.154 0.195 0.218  ||  -0.679 -0.578 -0.396 -0.108 0.180 0.314 0.545 0.661   || dis=0.02 || select=7/8
015/019-th : 0.045 0.044 0.060 0.085 0.110 0.149 0.224 0.282  ||  -0.807 -0.821 -0.522 -0.173 0.086 0.388 0.794 1.026   || dis=0.06 || select=7/8
016/019-th : 0.055 0.072 0.098 0.128 0.140 0.158 0.170 0.179  ||  -0.751 -0.475 -0.170 0.092 0.183 0.308 0.377 0.431    || dis=0.01 || select=7/8
017/019-th : 0.121 0.113 0.114 0.122 0.130 0.128 0.135 0.136  ||  -0.031 -0.097 -0.087 -0.025 0.045 0.025 0.082 0.088   || dis=0.00 || select=7/8
018/019-th : 0.081 0.094 0.107 0.117 0.127 0.138 0.155 0.180  ||  -0.401 -0.254 -0.133 -0.035 0.041 0.126 0.244 0.391   || dis=0.02 || select=7/8
[epoch=145/600] FLOP : 28.45 MB, ratio : 0.6972, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:58:47] [epoch=145/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.318 (2.318)  Prec@1 34.77 (34.77) Prec@5 80.08 (80.08) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:58:53] [epoch=145/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 1.691 (2.303)  Prec@1 44.64 (37.90) Prec@5 91.07 (83.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.90 Prec@5 83.02 Error@1 62.10 Error@5 16.98 Loss:2.303
***[2020-01-29 06:58:53]*** VALID [epoch=145/600] loss = 2.302846, accuracy@1 = 37.90, accuracy@5 = 83.02 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:58:53]*** start epoch=146/600 Time Left: [04:02:03], LR=[0.086088 ~ 0.086088], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=146, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.318312558840987, FLOP=40.81
[Search] : epoch=146/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:58:54] [epoch=146/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.778 (0.778)  Prec@1 71.48 (71.48) Prec@5 97.66 (97.66) Acls-loss 0.705 (0.705) FLOP-Loss 0.000 (0.000) Arch-Loss 0.705 (0.705)
**TRAIN** [2020-01-29 06:59:18] [epoch=146/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.910 (0.831)  Prec@1 63.10 (71.52) Prec@5 97.62 (97.57) Acls-loss 0.822 (0.871) FLOP-Loss 0.000 (0.243) Arch-Loss 0.822 (1.356)
 **TRAIN** Prec@1 71.52 Prec@5 97.57 Error@1 28.48 Error@5 2.43 Base-Loss:0.831, Arch-Loss=1.356
***[2020-01-29 06:59:18]*** TRAIN [epoch=146/600] base-loss = 0.830951, arch-loss = 1.356245, accuracy-1 = 71.52, accuracy-5 = 97.57
[epoch=146/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 6, 12, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.640448)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.423 0.232 0.344  ||  0.1680 -0.4319 -0.0388  || discrepancy=0.08 || select=0/3
001/003-th : 0.388 0.145 0.467  ||  0.0330 -0.9524 0.2189  || discrepancy=0.08 || select=2/3
002/003-th : 0.141 0.223 0.636  ||  -0.7419 -0.2799 0.7670  || discrepancy=0.41 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.087 0.108 0.119 0.136 0.152 0.159 0.173  ||  -0.574 -0.324 -0.105 -0.008 0.128 0.238 0.282 0.371   || dis=0.01 || select=7/8
001/019-th : 0.132 0.129 0.128 0.134 0.119 0.117 0.121 0.119  ||  0.052 0.028 0.026 0.070 -0.046 -0.065 -0.029 -0.047   || dis=0.00 || select=3/8
002/019-th : 0.124 0.130 0.134 0.134 0.126 0.122 0.117 0.114  ||  -0.008 0.044 0.069 0.068 0.010 -0.023 -0.068 -0.094   || dis=0.00 || select=2/8
003/019-th : 0.127 0.131 0.128 0.131 0.123 0.122 0.119 0.120  ||  0.016 0.051 0.022 0.048 -0.018 -0.026 -0.051 -0.041   || dis=0.00 || select=1/8
004/019-th : 0.118 0.119 0.128 0.126 0.126 0.128 0.128 0.125  ||  -0.053 -0.043 0.028 0.009 0.013 0.030 0.028 0.004     || dis=0.00 || select=5/8
005/019-th : 0.121 0.120 0.122 0.127 0.124 0.126 0.129 0.130  ||  -0.030 -0.044 -0.025 0.018 -0.009 0.007 0.033 0.036   || dis=0.00 || select=7/8
006/019-th : 0.121 0.114 0.119 0.125 0.126 0.130 0.131 0.134  ||  -0.033 -0.095 -0.044 0.002 0.011 0.042 0.047 0.072    || dis=0.00 || select=7/8
007/019-th : 0.078 0.085 0.109 0.121 0.132 0.141 0.157 0.179  ||  -0.431 -0.350 -0.104 0.001 0.091 0.155 0.262 0.393    || dis=0.02 || select=7/8
008/019-th : 0.059 0.075 0.096 0.135 0.142 0.164 0.162 0.168  ||  -0.685 -0.444 -0.191 0.144 0.201 0.341 0.327 0.365    || dis=0.00 || select=7/8
009/019-th : 0.104 0.102 0.109 0.122 0.124 0.134 0.144 0.160  ||  -0.169 -0.188 -0.124 -0.013 0.007 0.086 0.151 0.262   || dis=0.02 || select=7/8
010/019-th : 0.103 0.112 0.118 0.129 0.129 0.139 0.139 0.131  ||  -0.188 -0.101 -0.047 0.037 0.037 0.113 0.112 0.052    || dis=0.00 || select=5/8
011/019-th : 0.110 0.102 0.104 0.117 0.128 0.136 0.145 0.158  ||  -0.116 -0.195 -0.168 -0.052 0.032 0.097 0.162 0.244   || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.119 0.121 0.127 0.132 0.134 0.140  ||  -0.101 -0.080 -0.049 -0.029 0.021 0.056 0.075 0.116   || dis=0.01 || select=7/8
013/019-th : 0.052 0.055 0.069 0.087 0.113 0.141 0.200 0.284  ||  -0.728 -0.664 -0.445 -0.200 0.051 0.277 0.626 0.977   || dis=0.08 || select=7/8
014/019-th : 0.060 0.065 0.078 0.105 0.138 0.154 0.189 0.210  ||  -0.642 -0.554 -0.379 -0.080 0.196 0.304 0.509 0.614   || dis=0.02 || select=7/8
015/019-th : 0.046 0.046 0.062 0.088 0.113 0.152 0.218 0.276  ||  -0.790 -0.809 -0.507 -0.156 0.097 0.393 0.756 0.993   || dis=0.06 || select=7/8
016/019-th : 0.056 0.075 0.102 0.130 0.142 0.156 0.164 0.175  ||  -0.731 -0.443 -0.137 0.108 0.192 0.286 0.338 0.401    || dis=0.01 || select=7/8
017/019-th : 0.126 0.119 0.118 0.124 0.129 0.124 0.130 0.130  ||  0.012 -0.050 -0.053 -0.005 0.033 -0.010 0.040 0.039   || dis=0.00 || select=6/8
018/019-th : 0.085 0.098 0.110 0.122 0.127 0.135 0.151 0.171  ||  -0.365 -0.217 -0.106 0.000 0.043 0.103 0.216 0.339    || dis=0.02 || select=7/8
[epoch=146/600] FLOP : 27.64 MB, ratio : 0.6772, Expected-ratio : 0.7000, Discrepancy : 0.038
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:59:18] [epoch=146/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.675 (2.675)  Prec@1 31.25 (31.25) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:59:24] [epoch=146/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.611 (2.275)  Prec@1 30.36 (36.23) Prec@5 71.43 (81.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.23 Prec@5 81.54 Error@1 63.77 Error@5 18.46 Loss:2.275
***[2020-01-29 06:59:24]*** VALID [epoch=146/600] loss = 2.275160, accuracy@1 = 36.23, accuracy@5 = 81.54 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:59:24]*** start epoch=147/600 Time Left: [04:01:28], LR=[0.085906 ~ 0.085906], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=147, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.309409429519812, FLOP=40.81
[Search] : epoch=147/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:59:25] [epoch=147/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.839 (0.839)  Prec@1 68.75 (68.75) Prec@5 97.27 (97.27) Acls-loss 0.947 (0.947) FLOP-Loss 0.000 (0.000) Arch-Loss 0.947 (0.947)
**TRAIN** [2020-01-29 06:59:49] [epoch=147/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.946 (0.847)  Prec@1 71.43 (71.02) Prec@5 95.24 (97.54) Acls-loss 0.936 (0.867) FLOP-Loss 0.000 (0.054) Arch-Loss 0.936 (0.974)
 **TRAIN** Prec@1 71.02 Prec@5 97.54 Error@1 28.98 Error@5 2.46 Base-Loss:0.847, Arch-Loss=0.974
***[2020-01-29 06:59:49]*** TRAIN [epoch=147/600] base-loss = 0.846853, arch-loss = 0.973837, accuracy-1 = 71.02, accuracy-5 = 97.54
[epoch=147/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 9, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.231296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.426 0.231 0.342  ||  0.1751 -0.4363 -0.0438  || discrepancy=0.08 || select=0/3
001/003-th : 0.389 0.148 0.463  ||  0.0399 -0.9302 0.2131  || discrepancy=0.07 || select=2/3
002/003-th : 0.139 0.226 0.635  ||  -0.7479 -0.2659 0.7690  || discrepancy=0.41 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.088 0.108 0.119 0.138 0.150 0.158 0.173  ||  -0.577 -0.312 -0.106 -0.010 0.140 0.224 0.278 0.371   || dis=0.01 || select=7/8
001/019-th : 0.132 0.128 0.128 0.135 0.121 0.117 0.121 0.119  ||  0.057 0.025 0.023 0.075 -0.030 -0.065 -0.034 -0.050   || dis=0.00 || select=3/8
002/019-th : 0.124 0.130 0.134 0.134 0.126 0.122 0.117 0.113  ||  -0.007 0.041 0.071 0.073 0.011 -0.024 -0.068 -0.095   || dis=0.00 || select=3/8
003/019-th : 0.127 0.131 0.127 0.133 0.123 0.120 0.119 0.120  ||  0.017 0.052 0.018 0.062 -0.014 -0.039 -0.048 -0.043   || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.127 0.125 0.127 0.128 0.129 0.125  ||  -0.050 -0.034 0.019 -0.003 0.015 0.028 0.030 0.002    || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.123 0.127 0.127 0.127 0.127 0.130  ||  -0.042 -0.033 -0.019 0.018 0.013 0.013 0.017 0.037    || dis=0.00 || select=7/8
006/019-th : 0.121 0.114 0.120 0.125 0.126 0.130 0.130 0.134  ||  -0.032 -0.091 -0.039 0.002 0.008 0.041 0.043 0.071    || dis=0.00 || select=7/8
007/019-th : 0.079 0.085 0.107 0.117 0.132 0.143 0.157 0.179  ||  -0.426 -0.348 -0.116 -0.028 0.092 0.173 0.268 0.398   || dis=0.02 || select=7/8
008/019-th : 0.059 0.074 0.095 0.137 0.141 0.161 0.163 0.169  ||  -0.685 -0.451 -0.202 0.166 0.192 0.326 0.336 0.372    || dis=0.01 || select=7/8
009/019-th : 0.104 0.103 0.110 0.121 0.124 0.134 0.144 0.161  ||  -0.174 -0.186 -0.114 -0.021 0.005 0.082 0.154 0.263   || dis=0.02 || select=7/8
010/019-th : 0.104 0.113 0.117 0.127 0.128 0.138 0.142 0.131  ||  -0.182 -0.096 -0.058 0.023 0.032 0.104 0.129 0.052    || dis=0.00 || select=6/8
011/019-th : 0.110 0.103 0.104 0.118 0.128 0.135 0.144 0.158  ||  -0.119 -0.185 -0.171 -0.045 0.035 0.085 0.156 0.247   || dis=0.01 || select=7/8
012/019-th : 0.115 0.115 0.119 0.121 0.128 0.129 0.135 0.138  ||  -0.084 -0.076 -0.043 -0.027 0.024 0.036 0.078 0.103   || dis=0.00 || select=7/8
013/019-th : 0.052 0.055 0.067 0.087 0.111 0.141 0.202 0.285  ||  -0.718 -0.663 -0.466 -0.206 0.045 0.283 0.639 0.982   || dis=0.08 || select=7/8
014/019-th : 0.060 0.066 0.078 0.103 0.139 0.156 0.190 0.209  ||  -0.634 -0.546 -0.383 -0.100 0.198 0.316 0.512 0.608   || dis=0.02 || select=7/8
015/019-th : 0.046 0.046 0.061 0.087 0.113 0.151 0.216 0.280  ||  -0.796 -0.808 -0.509 -0.156 0.098 0.392 0.746 1.006   || dis=0.06 || select=7/8
016/019-th : 0.057 0.075 0.102 0.132 0.142 0.157 0.162 0.173  ||  -0.718 -0.443 -0.141 0.119 0.195 0.296 0.323 0.391    || dis=0.01 || select=7/8
017/019-th : 0.126 0.120 0.119 0.122 0.129 0.124 0.130 0.129  ||  0.009 -0.042 -0.046 -0.020 0.036 -0.005 0.038 0.036   || dis=0.00 || select=6/8
018/019-th : 0.086 0.098 0.111 0.123 0.128 0.133 0.150 0.171  ||  -0.350 -0.218 -0.097 0.004 0.046 0.084 0.208 0.337    || dis=0.02 || select=7/8
[epoch=147/600] FLOP : 28.23 MB, ratio : 0.6917, Expected-ratio : 0.7000, Discrepancy : 0.039
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 06:59:49] [epoch=147/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.348 (2.348)  Prec@1 52.73 (52.73) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 06:59:55] [epoch=147/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.701 (2.290)  Prec@1 37.50 (38.70) Prec@5 79.76 (83.98) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.70 Prec@5 83.98 Error@1 61.30 Error@5 16.02 Loss:2.290
***[2020-01-29 06:59:55]*** VALID [epoch=147/600] loss = 2.290418, accuracy@1 = 38.70, accuracy@5 = 83.98 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 06:59:55]*** start epoch=148/600 Time Left: [04:00:54], LR=[0.085724 ~ 0.085724], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=148, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.3004580651003685, FLOP=40.81
[Search] : epoch=148/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 06:59:56] [epoch=148/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.878 (0.878)  Prec@1 66.02 (66.02) Prec@5 97.66 (97.66) Acls-loss 0.923 (0.923) FLOP-Loss 0.000 (0.000) Arch-Loss 0.923 (0.923)
**TRAIN** [2020-01-29 07:00:22] [epoch=148/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.748 (0.841)  Prec@1 76.79 (71.18) Prec@5 98.21 (97.74) Acls-loss 0.846 (0.866) FLOP-Loss 2.599 (0.125) Arch-Loss 6.044 (1.115)
 **TRAIN** Prec@1 71.18 Prec@5 97.74 Error@1 28.82 Error@5 2.26 Base-Loss:0.841, Arch-Loss=1.115
***[2020-01-29 07:00:22]*** TRAIN [epoch=148/600] base-loss = 0.841322, arch-loss = 1.115455, accuracy-1 = 71.18, accuracy-5 = 97.74
[epoch=148/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 6, 8, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.747392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.227 0.337  ||  0.1948 -0.4564 -0.0606  || discrepancy=0.10 || select=0/3
001/003-th : 0.397 0.147 0.455  ||  0.0601 -0.9314 0.1959  || discrepancy=0.06 || select=2/3
002/003-th : 0.141 0.231 0.628  ||  -0.7393 -0.2428 0.7567  || discrepancy=0.40 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.088 0.109 0.121 0.137 0.152 0.156 0.170  ||  -0.576 -0.303 -0.091 0.009 0.132 0.236 0.262 0.353    || dis=0.01 || select=7/8
001/019-th : 0.135 0.130 0.129 0.135 0.120 0.115 0.118 0.117  ||  0.079 0.043 0.032 0.081 -0.040 -0.081 -0.054 -0.069   || dis=0.00 || select=3/8
002/019-th : 0.126 0.132 0.135 0.136 0.125 0.120 0.115 0.111  ||  0.009 0.058 0.082 0.087 0.002 -0.037 -0.083 -0.113    || dis=0.00 || select=3/8
003/019-th : 0.129 0.134 0.129 0.132 0.121 0.119 0.117 0.118  ||  0.034 0.070 0.029 0.055 -0.033 -0.048 -0.063 -0.056   || dis=0.00 || select=1/8
004/019-th : 0.120 0.122 0.128 0.126 0.126 0.127 0.127 0.123  ||  -0.036 -0.024 0.025 0.014 0.014 0.020 0.017 -0.013    || dis=0.00 || select=2/8
005/019-th : 0.121 0.123 0.123 0.128 0.125 0.126 0.125 0.129  ||  -0.030 -0.019 -0.014 0.027 -0.003 0.006 -0.000 0.029  || dis=0.00 || select=7/8
006/019-th : 0.123 0.116 0.120 0.125 0.126 0.129 0.129 0.132  ||  -0.018 -0.072 -0.038 0.006 0.012 0.031 0.034 0.054    || dis=0.00 || select=7/8
007/019-th : 0.080 0.086 0.106 0.116 0.136 0.143 0.155 0.178  ||  -0.413 -0.337 -0.125 -0.037 0.118 0.172 0.254 0.387   || dis=0.02 || select=7/8
008/019-th : 0.059 0.076 0.096 0.137 0.139 0.160 0.164 0.169  ||  -0.676 -0.437 -0.200 0.160 0.174 0.314 0.339 0.366    || dis=0.01 || select=7/8
009/019-th : 0.105 0.100 0.113 0.124 0.123 0.134 0.143 0.158  ||  -0.160 -0.206 -0.088 0.004 -0.003 0.084 0.151 0.245   || dis=0.02 || select=7/8
010/019-th : 0.104 0.116 0.119 0.131 0.127 0.136 0.139 0.128  ||  -0.176 -0.073 -0.042 0.049 0.025 0.090 0.110 0.032    || dis=0.00 || select=6/8
011/019-th : 0.112 0.104 0.106 0.121 0.125 0.133 0.144 0.156  ||  -0.103 -0.175 -0.157 -0.025 0.013 0.068 0.151 0.228   || dis=0.01 || select=7/8
012/019-th : 0.116 0.118 0.120 0.121 0.127 0.128 0.132 0.137  ||  -0.069 -0.057 -0.035 -0.027 0.018 0.027 0.056 0.093   || dis=0.01 || select=7/8
013/019-th : 0.053 0.056 0.066 0.087 0.111 0.141 0.203 0.283  ||  -0.699 -0.646 -0.480 -0.209 0.039 0.281 0.640 0.974   || dis=0.08 || select=7/8
014/019-th : 0.061 0.066 0.080 0.104 0.138 0.154 0.189 0.207  ||  -0.624 -0.541 -0.360 -0.093 0.193 0.302 0.503 0.595   || dis=0.02 || select=7/8
015/019-th : 0.047 0.046 0.062 0.088 0.114 0.152 0.214 0.278  ||  -0.786 -0.797 -0.506 -0.159 0.100 0.391 0.734 0.997   || dis=0.06 || select=7/8
016/019-th : 0.058 0.076 0.103 0.132 0.145 0.155 0.161 0.169  ||  -0.710 -0.427 -0.130 0.123 0.213 0.282 0.318 0.369    || dis=0.01 || select=7/8
017/019-th : 0.128 0.122 0.121 0.125 0.127 0.123 0.127 0.128  ||  0.022 -0.024 -0.034 -0.001 0.019 -0.015 0.016 0.024   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.113 0.125 0.128 0.133 0.148 0.167  ||  -0.340 -0.218 -0.077 0.022 0.048 0.089 0.194 0.313    || dis=0.02 || select=7/8
[epoch=148/600] FLOP : 28.75 MB, ratio : 0.7044, Expected-ratio : 0.7000, Discrepancy : 0.038
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:00:22] [epoch=148/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.809 (1.809)  Prec@1 40.62 (40.62) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:00:28] [epoch=148/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.278 (2.217)  Prec@1 34.52 (36.76) Prec@5 70.83 (80.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.76 Prec@5 80.66 Error@1 63.24 Error@5 19.34 Loss:2.217
***[2020-01-29 07:00:28]*** VALID [epoch=148/600] loss = 2.216909, accuracy@1 = 36.76, accuracy@5 = 80.66 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:00:28]*** start epoch=149/600 Time Left: [04:00:25], LR=[0.085540 ~ 0.085540], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=149, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.291458710988832, FLOP=40.81
[Search] : epoch=149/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:00:29] [epoch=149/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.904 (0.904)  Prec@1 67.58 (67.58) Prec@5 98.05 (98.05) Acls-loss 0.779 (0.779) FLOP-Loss 2.599 (2.599) Arch-Loss 5.977 (5.977)
**TRAIN** [2020-01-29 07:00:54] [epoch=149/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.836 (0.853)  Prec@1 69.64 (70.84) Prec@5 97.62 (97.54) Acls-loss 0.938 (0.870) FLOP-Loss 0.000 (0.000) Arch-Loss 0.938 (0.870)
 **TRAIN** Prec@1 70.84 Prec@5 97.54 Error@1 29.16 Error@5 2.46 Base-Loss:0.853, Arch-Loss=0.870
***[2020-01-29 07:00:54]*** TRAIN [epoch=149/600] base-loss = 0.853307, arch-loss = 0.870046, accuracy-1 = 70.84, accuracy-5 = 97.54
[epoch=149/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.435 0.227 0.339  ||  0.1923 -0.4592 -0.0568  || discrepancy=0.10 || select=0/3
001/003-th : 0.396 0.148 0.456  ||  0.0574 -0.9261 0.1997  || discrepancy=0.06 || select=2/3
002/003-th : 0.138 0.229 0.633  ||  -0.7539 -0.2481 0.7693  || discrepancy=0.40 || select=2/3
-----------------------------------------------
000/019-th : 0.067 0.089 0.109 0.120 0.137 0.150 0.156 0.171  ||  -0.581 -0.301 -0.097 0.006 0.135 0.225 0.267 0.358    || dis=0.02 || select=7/8
001/019-th : 0.135 0.129 0.129 0.134 0.121 0.116 0.119 0.117  ||  0.077 0.035 0.029 0.072 -0.030 -0.078 -0.050 -0.064   || dis=0.00 || select=0/8
002/019-th : 0.125 0.132 0.134 0.135 0.126 0.121 0.115 0.112  ||  0.004 0.055 0.072 0.076 0.014 -0.034 -0.079 -0.106    || dis=0.00 || select=3/8
003/019-th : 0.130 0.134 0.128 0.130 0.121 0.120 0.119 0.119  ||  0.032 0.066 0.018 0.035 -0.038 -0.042 -0.055 -0.050   || dis=0.00 || select=1/8
004/019-th : 0.120 0.121 0.128 0.126 0.127 0.128 0.127 0.124  ||  -0.040 -0.032 0.023 0.012 0.019 0.026 0.018 -0.009    || dis=0.00 || select=5/8
005/019-th : 0.119 0.121 0.123 0.128 0.127 0.127 0.125 0.129  ||  -0.043 -0.026 -0.014 0.028 0.017 0.021 0.004 0.032    || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.120 0.126 0.125 0.129 0.130 0.132  ||  -0.024 -0.073 -0.043 0.009 0.001 0.031 0.044 0.059    || dis=0.00 || select=7/8
007/019-th : 0.079 0.086 0.107 0.116 0.136 0.142 0.156 0.178  ||  -0.422 -0.340 -0.121 -0.039 0.123 0.167 0.258 0.392   || dis=0.02 || select=7/8
008/019-th : 0.060 0.076 0.096 0.135 0.137 0.161 0.166 0.170  ||  -0.677 -0.437 -0.200 0.144 0.160 0.316 0.347 0.373    || dis=0.00 || select=7/8
009/019-th : 0.105 0.099 0.112 0.125 0.123 0.134 0.144 0.158  ||  -0.163 -0.217 -0.091 0.012 0.000 0.086 0.154 0.249    || dis=0.01 || select=7/8
010/019-th : 0.104 0.115 0.119 0.130 0.126 0.136 0.140 0.130  ||  -0.183 -0.079 -0.040 0.046 0.016 0.088 0.116 0.041    || dis=0.00 || select=6/8
011/019-th : 0.111 0.104 0.105 0.119 0.127 0.132 0.145 0.156  ||  -0.110 -0.172 -0.165 -0.036 0.023 0.068 0.158 0.233   || dis=0.01 || select=7/8
012/019-th : 0.116 0.117 0.120 0.121 0.127 0.129 0.133 0.137  ||  -0.075 -0.061 -0.037 -0.029 0.016 0.032 0.066 0.094   || dis=0.00 || select=7/8
013/019-th : 0.053 0.055 0.065 0.087 0.111 0.142 0.203 0.283  ||  -0.708 -0.663 -0.487 -0.198 0.045 0.285 0.646 0.978   || dis=0.08 || select=7/8
014/019-th : 0.061 0.066 0.079 0.105 0.138 0.153 0.190 0.208  ||  -0.628 -0.549 -0.367 -0.087 0.186 0.296 0.510 0.602   || dis=0.02 || select=7/8
015/019-th : 0.046 0.045 0.062 0.090 0.114 0.150 0.212 0.281  ||  -0.803 -0.817 -0.505 -0.135 0.104 0.382 0.728 1.008   || dis=0.07 || select=7/8
016/019-th : 0.057 0.076 0.102 0.131 0.145 0.157 0.163 0.170  ||  -0.724 -0.428 -0.134 0.115 0.213 0.293 0.330 0.371    || dis=0.01 || select=7/8
017/019-th : 0.127 0.121 0.121 0.124 0.127 0.125 0.127 0.129  ||  0.014 -0.031 -0.032 -0.011 0.015 0.000 0.019 0.031    || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.113 0.124 0.128 0.134 0.149 0.169  ||  -0.346 -0.222 -0.080 0.012 0.043 0.090 0.197 0.324    || dis=0.02 || select=7/8
[epoch=149/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.038
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:00:55] [epoch=149/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.334 (2.334)  Prec@1 30.08 (30.08) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:01:01] [epoch=149/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.053 (2.322)  Prec@1 33.33 (37.41) Prec@5 78.57 (82.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.41 Prec@5 82.07 Error@1 62.59 Error@5 17.93 Loss:2.322
***[2020-01-29 07:01:01]*** VALID [epoch=149/600] loss = 2.321640, accuracy@1 = 37.41, accuracy@5 = 82.07 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:01:01]*** start epoch=150/600 Time Left: [03:59:55], LR=[0.085355 ~ 0.085355], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=150, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.282411613907041, FLOP=40.81
[Search] : epoch=150/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:01:02] [epoch=150/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.907 (0.907)  Prec@1 69.14 (69.14) Prec@5 96.09 (96.09) Acls-loss 0.808 (0.808) FLOP-Loss 0.000 (0.000) Arch-Loss 0.808 (0.808)
**TRAIN** [2020-01-29 07:01:26] [epoch=150/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.780 (0.840)  Prec@1 72.62 (71.36) Prec@5 97.02 (97.64) Acls-loss 0.993 (0.895) FLOP-Loss 0.000 (0.000) Arch-Loss 0.993 (0.895)
 **TRAIN** Prec@1 71.36 Prec@5 97.64 Error@1 28.64 Error@5 2.36 Base-Loss:0.840, Arch-Loss=0.895
***[2020-01-29 07:01:26]*** TRAIN [epoch=150/600] base-loss = 0.840392, arch-loss = 0.895048, accuracy-1 = 71.36, accuracy-5 = 97.64
[epoch=150/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.434 0.224 0.342  ||  0.1874 -0.4716 -0.0500  || discrepancy=0.09 || select=0/3
001/003-th : 0.395 0.146 0.460  ||  0.0534 -0.9442 0.2061  || discrepancy=0.07 || select=2/3
002/003-th : 0.136 0.227 0.636  ||  -0.7623 -0.2523 0.7772  || discrepancy=0.41 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.088 0.109 0.118 0.140 0.150 0.156 0.172  ||  -0.589 -0.304 -0.095 -0.015 0.161 0.225 0.268 0.364   || dis=0.02 || select=7/8
001/019-th : 0.134 0.129 0.128 0.133 0.122 0.117 0.119 0.118  ||  0.072 0.030 0.026 0.063 -0.021 -0.068 -0.046 -0.061   || dis=0.00 || select=0/8
002/019-th : 0.125 0.131 0.133 0.133 0.127 0.122 0.116 0.113  ||  -0.001 0.050 0.063 0.062 0.014 -0.025 -0.074 -0.099   || dis=0.00 || select=2/8
003/019-th : 0.128 0.134 0.126 0.128 0.122 0.122 0.119 0.120  ||  0.024 0.064 0.006 0.022 -0.023 -0.027 -0.051 -0.044   || dis=0.01 || select=1/8
004/019-th : 0.120 0.120 0.126 0.124 0.128 0.129 0.129 0.124  ||  -0.041 -0.039 0.010 -0.003 0.024 0.031 0.029 -0.005   || dis=0.00 || select=5/8
005/019-th : 0.118 0.121 0.122 0.129 0.127 0.129 0.126 0.129  ||  -0.052 -0.031 -0.024 0.032 0.020 0.035 0.010 0.036    || dis=0.00 || select=7/8
006/019-th : 0.121 0.115 0.118 0.126 0.126 0.130 0.131 0.133  ||  -0.032 -0.080 -0.056 0.012 0.011 0.038 0.051 0.064    || dis=0.00 || select=7/8
007/019-th : 0.079 0.086 0.106 0.114 0.136 0.142 0.157 0.179  ||  -0.417 -0.343 -0.125 -0.052 0.124 0.163 0.264 0.396   || dis=0.02 || select=7/8
008/019-th : 0.059 0.076 0.096 0.134 0.137 0.161 0.167 0.172  ||  -0.687 -0.438 -0.203 0.131 0.155 0.316 0.356 0.384    || dis=0.00 || select=7/8
009/019-th : 0.104 0.099 0.112 0.123 0.124 0.134 0.145 0.160  ||  -0.173 -0.220 -0.094 -0.001 0.010 0.081 0.163 0.258   || dis=0.02 || select=7/8
010/019-th : 0.103 0.114 0.120 0.127 0.129 0.136 0.141 0.130  ||  -0.185 -0.088 -0.038 0.021 0.033 0.085 0.127 0.046    || dis=0.00 || select=6/8
011/019-th : 0.110 0.105 0.104 0.118 0.127 0.132 0.147 0.158  ||  -0.118 -0.169 -0.172 -0.053 0.025 0.061 0.171 0.240   || dis=0.01 || select=7/8
012/019-th : 0.115 0.116 0.119 0.122 0.127 0.129 0.134 0.137  ||  -0.078 -0.070 -0.045 -0.020 0.021 0.038 0.072 0.097   || dis=0.00 || select=7/8
013/019-th : 0.049 0.053 0.066 0.087 0.114 0.143 0.204 0.284  ||  -0.772 -0.684 -0.465 -0.200 0.076 0.300 0.657 0.986   || dis=0.08 || select=7/8
014/019-th : 0.059 0.066 0.077 0.105 0.140 0.153 0.190 0.208  ||  -0.651 -0.544 -0.385 -0.079 0.210 0.297 0.516 0.606   || dis=0.02 || select=7/8
015/019-th : 0.046 0.045 0.061 0.089 0.112 0.149 0.215 0.284  ||  -0.807 -0.816 -0.518 -0.139 0.090 0.374 0.741 1.022   || dis=0.07 || select=7/8
016/019-th : 0.056 0.076 0.103 0.131 0.144 0.156 0.164 0.170  ||  -0.728 -0.433 -0.128 0.115 0.206 0.290 0.336 0.372    || dis=0.01 || select=7/8
017/019-th : 0.126 0.121 0.121 0.122 0.127 0.126 0.128 0.130  ||  0.009 -0.034 -0.035 -0.023 0.013 0.005 0.022 0.038    || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.112 0.121 0.127 0.134 0.150 0.170  ||  -0.341 -0.221 -0.090 -0.008 0.040 0.094 0.203 0.328   || dis=0.02 || select=7/8
[epoch=150/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.038
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:01:27] [epoch=150/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.474 (1.474)  Prec@1 50.00 (50.00) Prec@5 94.14 (94.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:01:33] [epoch=150/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.708 (2.215)  Prec@1 52.38 (37.62) Prec@5 87.50 (82.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.62 Prec@5 82.65 Error@1 62.38 Error@5 17.35 Loss:2.215
***[2020-01-29 07:01:33]*** VALID [epoch=150/600] loss = 2.214795, accuracy@1 = 37.62, accuracy@5 = 82.65 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:01:33]*** start epoch=151/600 Time Left: [03:59:24], LR=[0.085170 ~ 0.085170], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=151, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.273317021885735, FLOP=40.81
[Search] : epoch=151/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:01:34] [epoch=151/600][000/098] Time 0.76 (0.76) Data 0.35 (0.35) Base-Loss 0.852 (0.852)  Prec@1 74.22 (74.22) Prec@5 96.88 (96.88) Acls-loss 0.871 (0.871) FLOP-Loss 0.000 (0.000) Arch-Loss 0.871 (0.871)
**TRAIN** [2020-01-29 07:01:59] [epoch=151/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.925 (0.829)  Prec@1 67.86 (72.08) Prec@5 96.43 (97.66) Acls-loss 0.761 (0.864) FLOP-Loss 0.000 (0.000) Arch-Loss 0.761 (0.864)
 **TRAIN** Prec@1 72.08 Prec@5 97.66 Error@1 27.92 Error@5 2.34 Base-Loss:0.829, Arch-Loss=0.864
***[2020-01-29 07:01:59]*** TRAIN [epoch=151/600] base-loss = 0.829287, arch-loss = 0.863750, accuracy-1 = 72.08, accuracy-5 = 97.66
[epoch=151/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.431 0.226 0.344  ||  0.1820 -0.4646 -0.0437  || discrepancy=0.09 || select=0/3
001/003-th : 0.393 0.146 0.462  ||  0.0494 -0.9407 0.2114  || discrepancy=0.07 || select=2/3
002/003-th : 0.135 0.225 0.640  ||  -0.7718 -0.2578 0.7863  || discrepancy=0.42 || select=2/3
-----------------------------------------------
000/019-th : 0.066 0.087 0.109 0.117 0.141 0.151 0.156 0.173  ||  -0.588 -0.317 -0.096 -0.017 0.164 0.233 0.268 0.369   || dis=0.02 || select=7/8
001/019-th : 0.134 0.128 0.128 0.132 0.122 0.118 0.120 0.118  ||  0.067 0.025 0.023 0.055 -0.022 -0.060 -0.039 -0.058   || dis=0.00 || select=0/8
002/019-th : 0.124 0.130 0.132 0.132 0.127 0.124 0.117 0.114  ||  -0.007 0.041 0.055 0.056 0.020 -0.012 -0.070 -0.091   || dis=0.00 || select=3/8
003/019-th : 0.127 0.133 0.125 0.128 0.125 0.122 0.120 0.120  ||  0.017 0.059 -0.003 0.020 -0.004 -0.024 -0.044 -0.039  || dis=0.01 || select=1/8
004/019-th : 0.118 0.119 0.125 0.125 0.129 0.130 0.128 0.125  ||  -0.050 -0.048 0.005 0.003 0.038 0.039 0.030 0.003     || dis=0.00 || select=5/8
005/019-th : 0.118 0.121 0.123 0.125 0.125 0.130 0.127 0.130  ||  -0.054 -0.033 -0.016 0.002 0.005 0.041 0.016 0.042    || dis=0.00 || select=7/8
006/019-th : 0.120 0.114 0.117 0.125 0.127 0.129 0.132 0.134  ||  -0.041 -0.088 -0.060 0.004 0.021 0.036 0.060 0.073    || dis=0.00 || select=7/8
007/019-th : 0.079 0.085 0.105 0.114 0.136 0.142 0.158 0.181  ||  -0.421 -0.348 -0.138 -0.057 0.123 0.164 0.268 0.407   || dis=0.02 || select=7/8
008/019-th : 0.058 0.075 0.095 0.132 0.138 0.161 0.169 0.172  ||  -0.696 -0.449 -0.205 0.124 0.168 0.320 0.368 0.388    || dis=0.00 || select=7/8
009/019-th : 0.103 0.098 0.111 0.123 0.124 0.134 0.146 0.160  ||  -0.175 -0.228 -0.102 -0.003 0.007 0.087 0.167 0.264   || dis=0.01 || select=7/8
010/019-th : 0.103 0.113 0.118 0.126 0.128 0.138 0.143 0.131  ||  -0.188 -0.098 -0.054 0.008 0.030 0.100 0.142 0.052    || dis=0.00 || select=6/8
011/019-th : 0.110 0.103 0.106 0.117 0.124 0.133 0.149 0.159  ||  -0.123 -0.181 -0.160 -0.058 0.001 0.073 0.181 0.246   || dis=0.01 || select=7/8
012/019-th : 0.115 0.116 0.119 0.120 0.129 0.129 0.135 0.138  ||  -0.081 -0.074 -0.046 -0.033 0.035 0.032 0.078 0.101   || dis=0.00 || select=7/8
013/019-th : 0.048 0.053 0.067 0.086 0.112 0.142 0.205 0.287  ||  -0.781 -0.686 -0.457 -0.205 0.063 0.295 0.661 0.999   || dis=0.08 || select=7/8
014/019-th : 0.059 0.066 0.077 0.104 0.140 0.153 0.192 0.209  ||  -0.649 -0.545 -0.394 -0.092 0.207 0.297 0.526 0.611   || dis=0.02 || select=7/8
015/019-th : 0.045 0.045 0.061 0.089 0.111 0.148 0.216 0.285  ||  -0.817 -0.823 -0.514 -0.138 0.084 0.372 0.752 1.027   || dis=0.07 || select=7/8
016/019-th : 0.056 0.075 0.103 0.132 0.143 0.156 0.164 0.170  ||  -0.732 -0.438 -0.132 0.121 0.203 0.287 0.339 0.376    || dis=0.01 || select=7/8
017/019-th : 0.126 0.121 0.120 0.123 0.126 0.126 0.129 0.130  ||  0.008 -0.037 -0.045 -0.021 0.010 0.007 0.027 0.042    || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.111 0.120 0.128 0.135 0.151 0.170  ||  -0.344 -0.223 -0.099 -0.019 0.047 0.102 0.211 0.328   || dis=0.02 || select=7/8
[epoch=151/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.039
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:01:59] [epoch=151/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.454 (2.454)  Prec@1 28.91 (28.91) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:02:06] [epoch=151/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 1.575 (2.359)  Prec@1 54.76 (37.58) Prec@5 90.48 (81.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.58 Prec@5 81.66 Error@1 62.42 Error@5 18.34 Loss:2.359
***[2020-01-29 07:02:06]*** VALID [epoch=151/600] loss = 2.358904, accuracy@1 = 37.58, accuracy@5 = 81.66 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:02:06]*** start epoch=152/600 Time Left: [03:58:54], LR=[0.084983 ~ 0.084983], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=152, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.264175184257745, FLOP=40.81
[Search] : epoch=152/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:02:07] [epoch=152/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.727 (0.727)  Prec@1 75.78 (75.78) Prec@5 97.66 (97.66) Acls-loss 0.837 (0.837) FLOP-Loss 0.000 (0.000) Arch-Loss 0.837 (0.837)
**TRAIN** [2020-01-29 07:02:32] [epoch=152/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.874 (0.829)  Prec@1 73.21 (71.76) Prec@5 97.62 (97.76) Acls-loss 0.773 (0.869) FLOP-Loss 0.000 (0.000) Arch-Loss 0.773 (0.869)
 **TRAIN** Prec@1 71.76 Prec@5 97.76 Error@1 28.24 Error@5 2.24 Base-Loss:0.829, Arch-Loss=0.869
***[2020-01-29 07:02:32]*** TRAIN [epoch=152/600] base-loss = 0.829053, arch-loss = 0.869065, accuracy-1 = 71.76, accuracy-5 = 97.76
[epoch=152/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.430 0.224 0.346  ||  0.1788 -0.4732 -0.0387  || discrepancy=0.08 || select=0/3
001/003-th : 0.390 0.145 0.464  ||  0.0449 -0.9428 0.2176  || discrepancy=0.07 || select=2/3
002/003-th : 0.132 0.223 0.644  ||  -0.7855 -0.2617 0.7981  || discrepancy=0.42 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.087 0.108 0.118 0.139 0.150 0.159 0.174  ||  -0.602 -0.318 -0.101 -0.010 0.149 0.226 0.283 0.377   || dis=0.01 || select=7/8
001/019-th : 0.133 0.127 0.128 0.131 0.123 0.119 0.121 0.118  ||  0.064 0.014 0.022 0.049 -0.019 -0.051 -0.031 -0.055   || dis=0.00 || select=0/8
002/019-th : 0.124 0.129 0.131 0.132 0.128 0.125 0.117 0.115  ||  -0.011 0.031 0.051 0.056 0.023 -0.002 -0.065 -0.087   || dis=0.00 || select=3/8
003/019-th : 0.127 0.132 0.125 0.126 0.126 0.123 0.120 0.121  ||  0.014 0.052 -0.005 0.010 0.008 -0.021 -0.040 -0.034   || dis=0.01 || select=1/8
004/019-th : 0.118 0.119 0.125 0.125 0.129 0.130 0.129 0.125  ||  -0.055 -0.047 0.006 0.002 0.036 0.041 0.034 0.003     || dis=0.00 || select=5/8
005/019-th : 0.117 0.119 0.123 0.124 0.127 0.131 0.127 0.131  ||  -0.064 -0.043 -0.012 -0.003 0.018 0.046 0.021 0.048   || dis=0.00 || select=7/8
006/019-th : 0.120 0.114 0.117 0.124 0.129 0.129 0.134 0.134  ||  -0.043 -0.090 -0.068 -0.003 0.033 0.030 0.069 0.075   || dis=0.00 || select=7/8
007/019-th : 0.079 0.084 0.105 0.113 0.134 0.146 0.158 0.182  ||  -0.424 -0.364 -0.140 -0.066 0.106 0.192 0.274 0.415   || dis=0.02 || select=7/8
008/019-th : 0.058 0.074 0.096 0.130 0.138 0.161 0.171 0.173  ||  -0.695 -0.456 -0.200 0.108 0.163 0.319 0.379 0.391    || dis=0.00 || select=7/8
009/019-th : 0.103 0.098 0.110 0.122 0.125 0.134 0.147 0.161  ||  -0.178 -0.233 -0.110 -0.012 0.013 0.085 0.176 0.269   || dis=0.01 || select=7/8
010/019-th : 0.103 0.112 0.118 0.123 0.128 0.139 0.144 0.132  ||  -0.190 -0.105 -0.056 -0.011 0.031 0.111 0.147 0.057   || dis=0.00 || select=6/8
011/019-th : 0.108 0.103 0.107 0.115 0.126 0.133 0.149 0.159  ||  -0.136 -0.183 -0.149 -0.074 0.015 0.074 0.184 0.251   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.118 0.122 0.130 0.129 0.133 0.138  ||  -0.087 -0.081 -0.048 -0.019 0.048 0.039 0.071 0.105   || dis=0.01 || select=7/8
013/019-th : 0.048 0.053 0.065 0.086 0.111 0.142 0.206 0.288  ||  -0.780 -0.686 -0.477 -0.204 0.051 0.302 0.670 1.007   || dis=0.08 || select=7/8
014/019-th : 0.058 0.066 0.076 0.104 0.140 0.152 0.192 0.212  ||  -0.665 -0.541 -0.403 -0.089 0.206 0.294 0.524 0.624   || dis=0.02 || select=7/8
015/019-th : 0.045 0.045 0.060 0.089 0.110 0.149 0.216 0.286  ||  -0.814 -0.825 -0.523 -0.136 0.077 0.379 0.750 1.032   || dis=0.07 || select=7/8
016/019-th : 0.056 0.075 0.101 0.130 0.145 0.156 0.166 0.171  ||  -0.736 -0.442 -0.143 0.109 0.217 0.288 0.349 0.380    || dis=0.01 || select=7/8
017/019-th : 0.125 0.119 0.120 0.124 0.125 0.126 0.129 0.131  ||  0.002 -0.047 -0.044 -0.013 -0.000 0.011 0.033 0.050   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.110 0.119 0.128 0.136 0.151 0.171  ||  -0.343 -0.218 -0.108 -0.029 0.044 0.106 0.209 0.334   || dis=0.02 || select=7/8
[epoch=152/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.039
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:02:32] [epoch=152/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 2.061 (2.061)  Prec@1 43.36 (43.36) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:02:38] [epoch=152/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.824 (2.211)  Prec@1 39.29 (37.59) Prec@5 83.93 (81.74) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.59 Prec@5 81.74 Error@1 62.41 Error@5 18.26 Loss:2.211
***[2020-01-29 07:02:38]*** VALID [epoch=152/600] loss = 2.210810, accuracy@1 = 37.59, accuracy@5 = 81.74 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:02:39]*** start epoch=153/600 Time Left: [03:58:23], LR=[0.084796 ~ 0.084796], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=153, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.25498635165117, FLOP=40.81
[Search] : epoch=153/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:02:39] [epoch=153/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.733 (0.733)  Prec@1 73.44 (73.44) Prec@5 97.66 (97.66) Acls-loss 1.000 (1.000) FLOP-Loss 0.000 (0.000) Arch-Loss 1.000 (1.000)
**TRAIN** [2020-01-29 07:03:04] [epoch=153/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.863 (0.832)  Prec@1 73.21 (71.67) Prec@5 96.43 (97.71) Acls-loss 0.859 (0.880) FLOP-Loss 0.000 (0.000) Arch-Loss 0.859 (0.880)
 **TRAIN** Prec@1 71.67 Prec@5 97.71 Error@1 28.33 Error@5 2.29 Base-Loss:0.832, Arch-Loss=0.880
***[2020-01-29 07:03:04]*** TRAIN [epoch=153/600] base-loss = 0.832271, arch-loss = 0.880305, accuracy-1 = 71.67, accuracy-5 = 97.71
[epoch=153/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.428 0.225 0.347  ||  0.1749 -0.4704 -0.0338  || discrepancy=0.08 || select=0/3
001/003-th : 0.388 0.144 0.468  ||  0.0389 -0.9531 0.2259  || discrepancy=0.08 || select=2/3
002/003-th : 0.130 0.222 0.648  ||  -0.7965 -0.2657 0.8080  || discrepancy=0.43 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.086 0.106 0.119 0.139 0.151 0.158 0.175  ||  -0.612 -0.321 -0.119 -0.007 0.156 0.237 0.283 0.386   || dis=0.02 || select=7/8
001/019-th : 0.132 0.126 0.127 0.131 0.124 0.120 0.121 0.119  ||  0.058 0.010 0.016 0.047 -0.006 -0.043 -0.028 -0.051   || dis=0.00 || select=0/8
002/019-th : 0.122 0.128 0.130 0.132 0.129 0.126 0.118 0.115  ||  -0.018 0.024 0.043 0.054 0.036 0.007 -0.058 -0.082    || dis=0.00 || select=3/8
003/019-th : 0.126 0.131 0.124 0.125 0.126 0.125 0.121 0.122  ||  0.008 0.042 -0.010 0.001 0.004 -0.006 -0.034 -0.026   || dis=0.01 || select=1/8
004/019-th : 0.117 0.119 0.124 0.124 0.128 0.132 0.130 0.126  ||  -0.063 -0.051 -0.006 -0.006 0.027 0.058 0.042 0.011   || dis=0.00 || select=5/8
005/019-th : 0.116 0.119 0.124 0.124 0.129 0.131 0.127 0.131  ||  -0.074 -0.049 -0.006 -0.005 0.035 0.052 0.021 0.053   || dis=0.00 || select=7/8
006/019-th : 0.118 0.113 0.116 0.124 0.128 0.130 0.135 0.136  ||  -0.053 -0.098 -0.073 -0.006 0.029 0.037 0.079 0.083   || dis=0.00 || select=7/8
007/019-th : 0.078 0.084 0.104 0.113 0.134 0.147 0.158 0.183  ||  -0.432 -0.362 -0.150 -0.061 0.106 0.198 0.275 0.420   || dis=0.02 || select=7/8
008/019-th : 0.057 0.073 0.095 0.130 0.138 0.162 0.171 0.174  ||  -0.710 -0.465 -0.203 0.110 0.169 0.327 0.384 0.400    || dis=0.00 || select=7/8
009/019-th : 0.103 0.096 0.110 0.121 0.127 0.135 0.147 0.162  ||  -0.179 -0.248 -0.113 -0.018 0.029 0.091 0.180 0.273   || dis=0.02 || select=7/8
010/019-th : 0.102 0.111 0.118 0.123 0.129 0.139 0.144 0.133  ||  -0.198 -0.110 -0.051 -0.014 0.034 0.112 0.148 0.066   || dis=0.00 || select=6/8
011/019-th : 0.107 0.103 0.107 0.116 0.125 0.135 0.147 0.161  ||  -0.148 -0.181 -0.150 -0.066 0.009 0.088 0.174 0.260   || dis=0.01 || select=7/8
012/019-th : 0.113 0.113 0.118 0.121 0.130 0.131 0.134 0.139  ||  -0.093 -0.091 -0.050 -0.024 0.043 0.049 0.079 0.111   || dis=0.01 || select=7/8
013/019-th : 0.048 0.054 0.065 0.085 0.109 0.143 0.204 0.291  ||  -0.776 -0.677 -0.481 -0.213 0.036 0.309 0.661 1.018   || dis=0.09 || select=7/8
014/019-th : 0.058 0.065 0.074 0.105 0.141 0.150 0.194 0.214  ||  -0.675 -0.549 -0.420 -0.078 0.219 0.278 0.536 0.634   || dis=0.02 || select=7/8
015/019-th : 0.045 0.045 0.060 0.089 0.109 0.150 0.215 0.288  ||  -0.826 -0.822 -0.528 -0.134 0.066 0.388 0.751 1.040   || dis=0.07 || select=7/8
016/019-th : 0.056 0.075 0.100 0.129 0.144 0.158 0.166 0.172  ||  -0.733 -0.443 -0.156 0.098 0.209 0.304 0.349 0.386    || dis=0.01 || select=7/8
017/019-th : 0.125 0.118 0.119 0.122 0.126 0.128 0.129 0.132  ||  -0.004 -0.055 -0.047 -0.025 0.010 0.023 0.034 0.057   || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.109 0.120 0.128 0.137 0.149 0.172  ||  -0.341 -0.213 -0.117 -0.022 0.041 0.114 0.196 0.337   || dis=0.02 || select=7/8
[epoch=153/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:03:05] [epoch=153/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.220 (2.220)  Prec@1 26.56 (26.56) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:03:11] [epoch=153/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.149 (2.262)  Prec@1 27.98 (38.23) Prec@5 74.40 (83.29) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.23 Prec@5 83.29 Error@1 61.77 Error@5 16.71 Loss:2.262
***[2020-01-29 07:03:11]*** VALID [epoch=153/600] loss = 2.261745, accuracy@1 = 38.23, accuracy@5 = 83.29 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:03:11]*** start epoch=154/600 Time Left: [03:57:53], LR=[0.084607 ~ 0.084607], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=154, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.245750775982497, FLOP=40.81
[Search] : epoch=154/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:03:12] [epoch=154/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.959 (0.959)  Prec@1 65.62 (65.62) Prec@5 96.09 (96.09) Acls-loss 0.922 (0.922) FLOP-Loss 0.000 (0.000) Arch-Loss 0.922 (0.922)
**TRAIN** [2020-01-29 07:03:37] [epoch=154/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.864 (0.838)  Prec@1 71.43 (71.37) Prec@5 97.62 (97.74) Acls-loss 0.669 (0.860) FLOP-Loss 0.000 (0.000) Arch-Loss 0.669 (0.860)
 **TRAIN** Prec@1 71.37 Prec@5 97.74 Error@1 28.63 Error@5 2.26 Base-Loss:0.838, Arch-Loss=0.860
***[2020-01-29 07:03:37]*** TRAIN [epoch=154/600] base-loss = 0.837564, arch-loss = 0.860457, accuracy-1 = 71.37, accuracy-5 = 97.74
[epoch=154/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.431552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.426 0.224 0.350  ||  0.1696 -0.4755 -0.0267  || discrepancy=0.08 || select=0/3
001/003-th : 0.386 0.145 0.469  ||  0.0352 -0.9398 0.2305  || discrepancy=0.08 || select=2/3
002/003-th : 0.127 0.220 0.652  ||  -0.8125 -0.2647 0.8201  || discrepancy=0.43 || select=2/3
-----------------------------------------------
000/019-th : 0.065 0.085 0.106 0.118 0.140 0.154 0.157 0.175  ||  -0.611 -0.333 -0.116 -0.013 0.162 0.258 0.276 0.387   || dis=0.02 || select=7/8
001/019-th : 0.131 0.125 0.127 0.130 0.125 0.121 0.122 0.119  ||  0.050 0.002 0.015 0.038 0.002 -0.032 -0.021 -0.045    || dis=0.00 || select=0/8
002/019-th : 0.122 0.127 0.130 0.131 0.129 0.126 0.119 0.116  ||  -0.022 0.020 0.038 0.049 0.028 0.012 -0.050 -0.077    || dis=0.00 || select=3/8
003/019-th : 0.126 0.130 0.122 0.126 0.126 0.125 0.121 0.123  ||  0.003 0.035 -0.024 0.003 0.009 0.000 -0.031 -0.015    || dis=0.00 || select=1/8
004/019-th : 0.116 0.117 0.123 0.123 0.129 0.134 0.130 0.127  ||  -0.071 -0.059 -0.010 -0.014 0.037 0.074 0.043 0.016   || dis=0.00 || select=5/8
005/019-th : 0.116 0.118 0.122 0.124 0.128 0.132 0.128 0.133  ||  -0.076 -0.051 -0.023 -0.005 0.023 0.054 0.027 0.061   || dis=0.00 || select=7/8
006/019-th : 0.117 0.112 0.116 0.124 0.128 0.130 0.136 0.135  ||  -0.062 -0.102 -0.069 -0.002 0.028 0.044 0.088 0.083   || dis=0.00 || select=6/8
007/019-th : 0.078 0.084 0.102 0.113 0.135 0.146 0.159 0.183  ||  -0.432 -0.359 -0.161 -0.065 0.116 0.193 0.279 0.421   || dis=0.02 || select=7/8
008/019-th : 0.058 0.073 0.094 0.130 0.138 0.162 0.173 0.174  ||  -0.705 -0.470 -0.214 0.109 0.171 0.328 0.394 0.399    || dis=0.00 || select=7/8
009/019-th : 0.103 0.096 0.108 0.118 0.127 0.138 0.147 0.162  ||  -0.175 -0.248 -0.128 -0.040 0.033 0.116 0.176 0.276   || dis=0.02 || select=7/8
010/019-th : 0.102 0.109 0.118 0.123 0.129 0.141 0.145 0.133  ||  -0.198 -0.127 -0.054 -0.013 0.038 0.125 0.154 0.067   || dis=0.00 || select=6/8
011/019-th : 0.106 0.101 0.105 0.118 0.126 0.134 0.148 0.161  ||  -0.148 -0.200 -0.161 -0.047 0.023 0.085 0.178 0.266   || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.118 0.120 0.128 0.132 0.135 0.140  ||  -0.094 -0.091 -0.050 -0.033 0.027 0.055 0.079 0.115   || dis=0.01 || select=7/8
013/019-th : 0.048 0.052 0.066 0.085 0.108 0.143 0.203 0.294  ||  -0.782 -0.699 -0.463 -0.207 0.026 0.310 0.659 1.029   || dis=0.09 || select=7/8
014/019-th : 0.056 0.064 0.074 0.104 0.141 0.152 0.195 0.214  ||  -0.693 -0.560 -0.418 -0.085 0.221 0.295 0.547 0.639   || dis=0.02 || select=7/8
015/019-th : 0.044 0.044 0.060 0.088 0.108 0.149 0.215 0.291  ||  -0.834 -0.835 -0.517 -0.141 0.061 0.387 0.753 1.053   || dis=0.08 || select=7/8
016/019-th : 0.056 0.075 0.100 0.128 0.143 0.158 0.166 0.173  ||  -0.731 -0.448 -0.153 0.087 0.199 0.302 0.353 0.394    || dis=0.01 || select=7/8
017/019-th : 0.124 0.118 0.120 0.121 0.127 0.127 0.130 0.133  ||  -0.010 -0.060 -0.042 -0.034 0.013 0.019 0.042 0.064   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.109 0.119 0.128 0.138 0.150 0.171  ||  -0.340 -0.221 -0.111 -0.032 0.042 0.120 0.205 0.334   || dis=0.02 || select=7/8
[epoch=154/600] FLOP : 27.43 MB, ratio : 0.6721, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:03:37] [epoch=154/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.533 (1.533)  Prec@1 52.73 (52.73) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:03:43] [epoch=154/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.367 (2.267)  Prec@1 51.79 (38.14) Prec@5 93.45 (82.87) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.14 Prec@5 82.87 Error@1 61.86 Error@5 17.13 Loss:2.267
***[2020-01-29 07:03:44]*** VALID [epoch=154/600] loss = 2.266961, accuracy@1 = 38.14, accuracy@5 = 82.87 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:03:44]*** start epoch=155/600 Time Left: [03:57:23], LR=[0.084418 ~ 0.084418], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=155, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.236468710449697, FLOP=40.81
[Search] : epoch=155/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:03:44] [epoch=155/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.837 (0.837)  Prec@1 71.09 (71.09) Prec@5 98.44 (98.44) Acls-loss 0.890 (0.890) FLOP-Loss 0.000 (0.000) Arch-Loss 0.890 (0.890)
**TRAIN** [2020-01-29 07:04:09] [epoch=155/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.784 (0.827)  Prec@1 74.40 (71.60) Prec@5 99.40 (97.80) Acls-loss 0.880 (0.848) FLOP-Loss 0.000 (0.000) Arch-Loss 0.880 (0.848)
 **TRAIN** Prec@1 71.60 Prec@5 97.80 Error@1 28.40 Error@5 2.20 Base-Loss:0.827, Arch-Loss=0.848
***[2020-01-29 07:04:09]*** TRAIN [epoch=155/600] base-loss = 0.826579, arch-loss = 0.847645, accuracy-1 = 71.60, accuracy-5 = 97.80
[epoch=155/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.425 0.222 0.354  ||  0.1642 -0.4868 -0.0189  || discrepancy=0.07 || select=0/3
001/003-th : 0.383 0.148 0.469  ||  0.0312 -0.9169 0.2349  || discrepancy=0.09 || select=2/3
002/003-th : 0.126 0.218 0.656  ||  -0.8217 -0.2711 0.8295  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.084 0.107 0.118 0.141 0.153 0.156 0.176  ||  -0.628 -0.342 -0.105 -0.003 0.172 0.254 0.275 0.392   || dis=0.02 || select=7/8
001/019-th : 0.130 0.124 0.126 0.129 0.127 0.122 0.123 0.120  ||  0.045 -0.006 0.008 0.031 0.017 -0.021 -0.015 -0.042   || dis=0.00 || select=0/8
002/019-th : 0.122 0.127 0.129 0.129 0.129 0.127 0.120 0.116  ||  -0.028 0.014 0.031 0.033 0.033 0.018 -0.040 -0.071    || dis=0.00 || select=3/8
003/019-th : 0.125 0.128 0.122 0.126 0.127 0.126 0.122 0.124  ||  -0.002 0.021 -0.029 0.007 0.018 0.008 -0.026 -0.008   || dis=0.00 || select=1/8
004/019-th : 0.116 0.116 0.123 0.123 0.130 0.134 0.131 0.128  ||  -0.075 -0.070 -0.015 -0.017 0.039 0.075 0.052 0.023   || dis=0.00 || select=5/8
005/019-th : 0.116 0.119 0.121 0.123 0.126 0.132 0.130 0.134  ||  -0.077 -0.053 -0.033 -0.012 0.008 0.055 0.037 0.067   || dis=0.00 || select=7/8
006/019-th : 0.116 0.112 0.117 0.124 0.127 0.131 0.136 0.137  ||  -0.067 -0.110 -0.066 -0.004 0.023 0.052 0.086 0.092   || dis=0.00 || select=7/8
007/019-th : 0.078 0.083 0.103 0.112 0.136 0.145 0.160 0.184  ||  -0.438 -0.371 -0.158 -0.068 0.123 0.187 0.286 0.429   || dis=0.02 || select=7/8
008/019-th : 0.057 0.073 0.092 0.129 0.138 0.161 0.173 0.176  ||  -0.706 -0.466 -0.230 0.104 0.172 0.325 0.395 0.410    || dis=0.00 || select=7/8
009/019-th : 0.103 0.095 0.109 0.117 0.126 0.139 0.147 0.163  ||  -0.177 -0.256 -0.124 -0.050 0.024 0.124 0.180 0.281   || dis=0.02 || select=7/8
010/019-th : 0.102 0.109 0.117 0.122 0.129 0.142 0.145 0.133  ||  -0.198 -0.132 -0.057 -0.017 0.036 0.132 0.156 0.070   || dis=0.00 || select=6/8
011/019-th : 0.106 0.099 0.103 0.120 0.126 0.134 0.148 0.163  ||  -0.155 -0.216 -0.175 -0.023 0.018 0.086 0.185 0.278   || dis=0.02 || select=7/8
012/019-th : 0.113 0.114 0.117 0.123 0.126 0.131 0.135 0.140  ||  -0.095 -0.089 -0.059 -0.015 0.014 0.051 0.080 0.118   || dis=0.01 || select=7/8
013/019-th : 0.048 0.052 0.066 0.083 0.110 0.142 0.203 0.296  ||  -0.785 -0.707 -0.462 -0.231 0.050 0.305 0.660 1.039   || dis=0.09 || select=7/8
014/019-th : 0.056 0.065 0.075 0.102 0.139 0.151 0.196 0.216  ||  -0.696 -0.558 -0.415 -0.097 0.211 0.291 0.550 0.649   || dis=0.02 || select=7/8
015/019-th : 0.044 0.043 0.060 0.088 0.111 0.150 0.212 0.292  ||  -0.839 -0.847 -0.521 -0.143 0.087 0.395 0.736 1.058   || dis=0.08 || select=7/8
016/019-th : 0.056 0.075 0.100 0.126 0.142 0.159 0.167 0.174  ||  -0.734 -0.446 -0.156 0.078 0.197 0.306 0.356 0.397    || dis=0.01 || select=7/8
017/019-th : 0.123 0.117 0.121 0.119 0.127 0.128 0.132 0.134  ||  -0.018 -0.063 -0.037 -0.049 0.013 0.021 0.051 0.068   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.110 0.119 0.127 0.139 0.150 0.170  ||  -0.341 -0.224 -0.108 -0.026 0.040 0.127 0.204 0.331   || dis=0.02 || select=7/8
[epoch=155/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:04:09] [epoch=155/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.837 (1.837)  Prec@1 53.52 (53.52) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:04:16] [epoch=155/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.859 (2.358)  Prec@1 44.05 (37.91) Prec@5 90.48 (83.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.91 Prec@5 83.43 Error@1 62.09 Error@5 16.57 Loss:2.358
***[2020-01-29 07:04:16]*** VALID [epoch=155/600] loss = 2.358306, accuracy@1 = 37.91, accuracy@5 = 83.43 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:04:16]*** start epoch=156/600 Time Left: [03:56:51], LR=[0.084227 ~ 0.084227], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=156, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.227140409525287, FLOP=40.81
[Search] : epoch=156/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:04:16] [epoch=156/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.843 (0.843)  Prec@1 73.83 (73.83) Prec@5 94.92 (94.92) Acls-loss 0.930 (0.930) FLOP-Loss 0.000 (0.000) Arch-Loss 0.930 (0.930)
**TRAIN** [2020-01-29 07:04:42] [epoch=156/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.836 (0.834)  Prec@1 70.83 (71.36) Prec@5 99.40 (97.67) Acls-loss 0.839 (0.863) FLOP-Loss 0.000 (0.000) Arch-Loss 0.839 (0.863)
 **TRAIN** Prec@1 71.36 Prec@5 97.67 Error@1 28.64 Error@5 2.33 Base-Loss:0.834, Arch-Loss=0.863
***[2020-01-29 07:04:42]*** TRAIN [epoch=156/600] base-loss = 0.834339, arch-loss = 0.863156, accuracy-1 = 71.36, accuracy-5 = 97.67
[epoch=156/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 11, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 29.443712)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.423 0.220 0.357  ||  0.1593 -0.4961 -0.0117  || discrepancy=0.07 || select=0/3
001/003-th : 0.380 0.148 0.472  ||  0.0258 -0.9144 0.2419  || discrepancy=0.09 || select=2/3
002/003-th : 0.124 0.218 0.658  ||  -0.8308 -0.2702 0.8368  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.083 0.104 0.119 0.142 0.154 0.159 0.177  ||  -0.635 -0.358 -0.134 0.001 0.181 0.259 0.296 0.402    || dis=0.02 || select=7/8
001/019-th : 0.129 0.124 0.125 0.127 0.129 0.122 0.123 0.120  ||  0.036 -0.005 0.002 0.020 0.037 -0.020 -0.009 -0.038   || dis=0.00 || select=4/8
002/019-th : 0.121 0.126 0.128 0.129 0.130 0.128 0.121 0.117  ||  -0.031 0.007 0.022 0.029 0.037 0.021 -0.036 -0.064    || dis=0.00 || select=4/8
003/019-th : 0.123 0.127 0.121 0.126 0.128 0.127 0.123 0.125  ||  -0.013 0.014 -0.034 0.005 0.025 0.016 -0.019 0.002    || dis=0.00 || select=4/8
004/019-th : 0.115 0.116 0.123 0.121 0.129 0.135 0.131 0.129  ||  -0.078 -0.076 -0.011 -0.027 0.035 0.077 0.051 0.033   || dis=0.00 || select=5/8
005/019-th : 0.115 0.118 0.122 0.123 0.126 0.133 0.129 0.134  ||  -0.079 -0.059 -0.028 -0.016 0.013 0.059 0.032 0.074   || dis=0.00 || select=7/8
006/019-th : 0.116 0.112 0.116 0.122 0.128 0.132 0.136 0.138  ||  -0.074 -0.107 -0.072 -0.019 0.026 0.056 0.088 0.099   || dis=0.00 || select=7/8
007/019-th : 0.077 0.083 0.102 0.110 0.137 0.144 0.161 0.186  ||  -0.444 -0.369 -0.164 -0.085 0.129 0.185 0.293 0.437   || dis=0.02 || select=7/8
008/019-th : 0.058 0.072 0.093 0.130 0.140 0.161 0.170 0.177  ||  -0.700 -0.481 -0.228 0.109 0.185 0.322 0.379 0.418    || dis=0.01 || select=7/8
009/019-th : 0.102 0.095 0.107 0.117 0.126 0.140 0.150 0.164  ||  -0.187 -0.256 -0.141 -0.047 0.025 0.127 0.196 0.285   || dis=0.01 || select=7/8
010/019-th : 0.101 0.108 0.117 0.123 0.129 0.142 0.146 0.134  ||  -0.204 -0.142 -0.059 -0.007 0.040 0.131 0.160 0.076   || dis=0.00 || select=6/8
011/019-th : 0.105 0.099 0.104 0.120 0.124 0.134 0.149 0.164  ||  -0.157 -0.217 -0.167 -0.030 0.009 0.082 0.190 0.282   || dis=0.02 || select=7/8
012/019-th : 0.112 0.114 0.118 0.121 0.128 0.130 0.135 0.142  ||  -0.102 -0.093 -0.057 -0.028 0.027 0.043 0.082 0.129   || dis=0.01 || select=7/8
013/019-th : 0.048 0.051 0.066 0.082 0.111 0.141 0.204 0.298  ||  -0.785 -0.716 -0.464 -0.240 0.058 0.301 0.669 1.047   || dis=0.09 || select=7/8
014/019-th : 0.056 0.064 0.074 0.102 0.138 0.152 0.196 0.217  ||  -0.694 -0.562 -0.419 -0.104 0.204 0.299 0.555 0.653   || dis=0.02 || select=7/8
015/019-th : 0.043 0.043 0.059 0.087 0.111 0.152 0.211 0.293  ||  -0.854 -0.846 -0.536 -0.149 0.098 0.411 0.738 1.065   || dis=0.08 || select=7/8
016/019-th : 0.057 0.075 0.100 0.125 0.143 0.158 0.169 0.175  ||  -0.726 -0.449 -0.162 0.065 0.198 0.297 0.368 0.399    || dis=0.01 || select=7/8
017/019-th : 0.122 0.116 0.120 0.118 0.130 0.127 0.132 0.134  ||  -0.023 -0.071 -0.042 -0.053 0.040 0.020 0.059 0.070   || dis=0.00 || select=7/8
018/019-th : 0.087 0.098 0.111 0.120 0.127 0.140 0.150 0.167  ||  -0.336 -0.225 -0.099 -0.020 0.037 0.139 0.207 0.313   || dis=0.02 || select=7/8
[epoch=156/600] FLOP : 29.44 MB, ratio : 0.7214, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:04:42] [epoch=156/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.464 (2.464)  Prec@1 32.42 (32.42) Prec@5 78.91 (78.91) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:04:48] [epoch=156/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.130 (2.175)  Prec@1 38.69 (38.20) Prec@5 85.71 (82.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.20 Prec@5 82.54 Error@1 61.80 Error@5 17.46 Loss:2.175
***[2020-01-29 07:04:48]*** VALID [epoch=156/600] loss = 2.175404, accuracy@1 = 38.20, accuracy@5 = 82.54 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:04:48]*** start epoch=157/600 Time Left: [03:56:21], LR=[0.084036 ~ 0.084036], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=157, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.217766128949349, FLOP=40.81
[Search] : epoch=157/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:04:49] [epoch=157/600][000/098] Time 0.76 (0.76) Data 0.35 (0.35) Base-Loss 0.904 (0.904)  Prec@1 73.44 (73.44) Prec@5 97.27 (97.27) Acls-loss 0.821 (0.821) FLOP-Loss 2.639 (2.639) Arch-Loss 6.099 (6.099)
**TRAIN** [2020-01-29 07:05:14] [epoch=157/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.971 (0.837)  Prec@1 66.67 (71.74) Prec@5 97.02 (97.68) Acls-loss 0.947 (0.867) FLOP-Loss 0.000 (0.054) Arch-Loss 0.947 (0.975)
 **TRAIN** Prec@1 71.74 Prec@5 97.68 Error@1 28.26 Error@5 2.32 Base-Loss:0.837, Arch-Loss=0.975
***[2020-01-29 07:05:14]*** TRAIN [epoch=157/600] base-loss = 0.837281, arch-loss = 0.974645, accuracy-1 = 71.74, accuracy-5 = 97.68
[epoch=157/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 11, 11, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.701888)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.425 0.217 0.358  ||  0.1610 -0.5098 -0.0109  || discrepancy=0.07 || select=0/3
001/003-th : 0.380 0.151 0.469  ||  0.0293 -0.8957 0.2392  || discrepancy=0.09 || select=2/3
002/003-th : 0.123 0.217 0.660  ||  -0.8387 -0.2675 0.8427  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.082 0.102 0.117 0.144 0.154 0.161 0.177  ||  -0.636 -0.367 -0.144 -0.008 0.198 0.266 0.309 0.402   || dis=0.02 || select=7/8
001/019-th : 0.129 0.124 0.125 0.127 0.129 0.122 0.124 0.120  ||  0.037 -0.003 0.004 0.015 0.035 -0.025 -0.010 -0.038   || dis=0.00 || select=0/8
002/019-th : 0.122 0.126 0.128 0.129 0.130 0.127 0.121 0.117  ||  -0.029 0.009 0.019 0.031 0.040 0.014 -0.035 -0.064    || dis=0.00 || select=4/8
003/019-th : 0.124 0.127 0.122 0.126 0.128 0.127 0.122 0.125  ||  -0.010 0.012 -0.026 0.009 0.022 0.014 -0.023 0.001    || dis=0.00 || select=4/8
004/019-th : 0.116 0.117 0.123 0.121 0.129 0.135 0.131 0.129  ||  -0.075 -0.067 -0.018 -0.035 0.036 0.080 0.048 0.030   || dis=0.00 || select=5/8
005/019-th : 0.117 0.117 0.121 0.124 0.126 0.132 0.129 0.135  ||  -0.068 -0.064 -0.030 -0.012 0.007 0.050 0.029 0.074   || dis=0.00 || select=7/8
006/019-th : 0.116 0.112 0.116 0.120 0.129 0.132 0.137 0.138  ||  -0.073 -0.106 -0.072 -0.042 0.034 0.054 0.089 0.104   || dis=0.00 || select=7/8
007/019-th : 0.078 0.084 0.101 0.110 0.137 0.145 0.160 0.186  ||  -0.435 -0.360 -0.171 -0.091 0.132 0.186 0.286 0.435   || dis=0.03 || select=7/8
008/019-th : 0.058 0.072 0.094 0.128 0.141 0.161 0.170 0.176  ||  -0.697 -0.475 -0.216 0.091 0.189 0.320 0.379 0.413    || dis=0.01 || select=7/8
009/019-th : 0.103 0.095 0.106 0.117 0.126 0.139 0.149 0.164  ||  -0.181 -0.255 -0.146 -0.047 0.024 0.125 0.188 0.289   || dis=0.02 || select=7/8
010/019-th : 0.101 0.108 0.117 0.124 0.129 0.141 0.146 0.134  ||  -0.205 -0.140 -0.055 -0.002 0.042 0.128 0.159 0.073   || dis=0.01 || select=6/8
011/019-th : 0.105 0.099 0.105 0.119 0.125 0.134 0.148 0.164  ||  -0.160 -0.220 -0.159 -0.032 0.017 0.084 0.183 0.284   || dis=0.02 || select=7/8
012/019-th : 0.113 0.114 0.118 0.122 0.130 0.130 0.134 0.141  ||  -0.098 -0.091 -0.056 -0.024 0.042 0.042 0.071 0.124   || dis=0.01 || select=7/8
013/019-th : 0.048 0.052 0.066 0.082 0.109 0.141 0.204 0.298  ||  -0.787 -0.705 -0.454 -0.243 0.046 0.299 0.669 1.047   || dis=0.09 || select=7/8
014/019-th : 0.056 0.065 0.074 0.102 0.138 0.151 0.198 0.216  ||  -0.692 -0.553 -0.420 -0.106 0.200 0.290 0.561 0.651   || dis=0.02 || select=7/8
015/019-th : 0.042 0.044 0.058 0.087 0.110 0.154 0.212 0.292  ||  -0.871 -0.819 -0.553 -0.143 0.088 0.422 0.744 1.063   || dis=0.08 || select=7/8
016/019-th : 0.056 0.075 0.099 0.124 0.143 0.157 0.171 0.174  ||  -0.734 -0.450 -0.166 0.061 0.204 0.296 0.381 0.399    || dis=0.00 || select=7/8
017/019-th : 0.122 0.117 0.121 0.119 0.128 0.127 0.132 0.133  ||  -0.024 -0.063 -0.033 -0.050 0.028 0.019 0.056 0.066   || dis=0.00 || select=7/8
018/019-th : 0.088 0.099 0.111 0.121 0.127 0.139 0.150 0.167  ||  -0.335 -0.216 -0.100 -0.012 0.036 0.130 0.203 0.311   || dis=0.02 || select=7/8
[epoch=157/600] FLOP : 27.70 MB, ratio : 0.6787, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:05:15] [epoch=157/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.509 (1.509)  Prec@1 50.39 (50.39) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:05:21] [epoch=157/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 1.536 (2.282)  Prec@1 46.43 (34.69) Prec@5 91.07 (81.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.69 Prec@5 81.26 Error@1 65.31 Error@5 18.74 Loss:2.282
***[2020-01-29 07:05:21]*** VALID [epoch=157/600] loss = 2.282033, accuracy@1 = 34.69, accuracy@5 = 81.26 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:05:21]*** start epoch=158/600 Time Left: [03:55:50], LR=[0.083844 ~ 0.083844], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=158, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.208346125722518, FLOP=40.81
[Search] : epoch=158/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:05:22] [epoch=158/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 1.106 (1.106)  Prec@1 57.81 (57.81) Prec@5 96.88 (96.88) Acls-loss 0.914 (0.914) FLOP-Loss 0.000 (0.000) Arch-Loss 0.914 (0.914)
**TRAIN** [2020-01-29 07:05:47] [epoch=158/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.821 (0.856)  Prec@1 73.21 (70.74) Prec@5 98.21 (97.64) Acls-loss 1.035 (0.873) FLOP-Loss 0.000 (0.081) Arch-Loss 1.035 (1.035)
 **TRAIN** Prec@1 70.74 Prec@5 97.64 Error@1 29.26 Error@5 2.36 Base-Loss:0.856, Arch-Loss=1.035
***[2020-01-29 07:05:47]*** TRAIN [epoch=158/600] base-loss = 0.856157, arch-loss = 1.035310, accuracy-1 = 70.74, accuracy-5 = 97.64
[epoch=158/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 11, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.701888)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.428 0.218 0.355  ||  0.1693 -0.5066 -0.0184  || discrepancy=0.07 || select=0/3
001/003-th : 0.382 0.155 0.464  ||  0.0374 -0.8675 0.2312  || discrepancy=0.08 || select=2/3
002/003-th : 0.122 0.218 0.660  ||  -0.8437 -0.2599 0.8450  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.062 0.082 0.102 0.119 0.143 0.153 0.162 0.176  ||  -0.646 -0.362 -0.148 0.006 0.193 0.258 0.315 0.401    || dis=0.01 || select=7/8
001/019-th : 0.130 0.126 0.125 0.128 0.129 0.121 0.123 0.119  ||  0.039 0.007 0.005 0.025 0.033 -0.026 -0.015 -0.045    || dis=0.00 || select=0/8
002/019-th : 0.122 0.127 0.128 0.129 0.130 0.127 0.120 0.117  ||  -0.026 0.015 0.026 0.027 0.041 0.015 -0.044 -0.068    || dis=0.00 || select=4/8
003/019-th : 0.125 0.128 0.123 0.127 0.126 0.126 0.121 0.125  ||  -0.002 0.021 -0.016 0.011 0.005 0.003 -0.031 -0.004   || dis=0.00 || select=1/8
004/019-th : 0.117 0.117 0.124 0.121 0.130 0.134 0.131 0.128  ||  -0.065 -0.069 -0.007 -0.033 0.037 0.068 0.045 0.022   || dis=0.00 || select=5/8
005/019-th : 0.118 0.118 0.122 0.124 0.126 0.130 0.128 0.134  ||  -0.062 -0.054 -0.023 -0.007 0.005 0.038 0.026 0.066   || dis=0.00 || select=7/8
006/019-th : 0.117 0.113 0.116 0.120 0.129 0.130 0.136 0.138  ||  -0.067 -0.097 -0.071 -0.039 0.028 0.039 0.088 0.100   || dis=0.00 || select=7/8
007/019-th : 0.076 0.084 0.102 0.110 0.139 0.145 0.160 0.184  ||  -0.456 -0.353 -0.162 -0.089 0.152 0.192 0.286 0.428   || dis=0.02 || select=7/8
008/019-th : 0.058 0.072 0.093 0.129 0.144 0.160 0.169 0.175  ||  -0.705 -0.474 -0.224 0.100 0.212 0.321 0.374 0.409    || dis=0.01 || select=7/8
009/019-th : 0.104 0.096 0.107 0.117 0.126 0.139 0.147 0.163  ||  -0.167 -0.250 -0.143 -0.049 0.023 0.124 0.174 0.283   || dis=0.02 || select=7/8
010/019-th : 0.102 0.109 0.118 0.125 0.130 0.139 0.144 0.134  ||  -0.199 -0.135 -0.052 0.006 0.042 0.115 0.149 0.073    || dis=0.00 || select=6/8
011/019-th : 0.105 0.099 0.106 0.119 0.125 0.133 0.149 0.163  ||  -0.162 -0.217 -0.153 -0.032 0.015 0.078 0.187 0.282   || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.119 0.123 0.130 0.130 0.133 0.139  ||  -0.096 -0.082 -0.040 -0.013 0.044 0.042 0.064 0.109   || dis=0.01 || select=7/8
013/019-th : 0.046 0.051 0.067 0.082 0.113 0.139 0.205 0.297  ||  -0.811 -0.709 -0.439 -0.245 0.077 0.284 0.673 1.045   || dis=0.09 || select=7/8
014/019-th : 0.057 0.065 0.074 0.102 0.139 0.153 0.196 0.213  ||  -0.688 -0.554 -0.416 -0.098 0.211 0.306 0.552 0.638   || dis=0.02 || select=7/8
015/019-th : 0.042 0.045 0.058 0.088 0.111 0.155 0.211 0.290  ||  -0.870 -0.812 -0.559 -0.133 0.093 0.429 0.736 1.055   || dis=0.08 || select=7/8
016/019-th : 0.056 0.076 0.099 0.125 0.144 0.156 0.170 0.174  ||  -0.737 -0.433 -0.172 0.067 0.206 0.289 0.373 0.399    || dis=0.00 || select=7/8
017/019-th : 0.123 0.119 0.122 0.119 0.129 0.125 0.131 0.132  ||  -0.015 -0.051 -0.024 -0.050 0.036 0.004 0.048 0.054   || dis=0.00 || select=7/8
018/019-th : 0.088 0.099 0.111 0.120 0.126 0.140 0.149 0.166  ||  -0.331 -0.208 -0.097 -0.020 0.033 0.138 0.197 0.305   || dis=0.02 || select=7/8
[epoch=158/600] FLOP : 27.70 MB, ratio : 0.6787, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:05:48] [epoch=158/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 1.559 (1.559)  Prec@1 61.72 (61.72) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:05:54] [epoch=158/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.174 (2.157)  Prec@1 34.52 (39.04) Prec@5 75.00 (82.46) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.04 Prec@5 82.46 Error@1 60.96 Error@5 17.54 Loss:2.157
***[2020-01-29 07:05:54]*** VALID [epoch=158/600] loss = 2.157337, accuracy@1 = 39.04, accuracy@5 = 82.46 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:05:54]*** start epoch=159/600 Time Left: [03:55:21], LR=[0.083651 ~ 0.083651], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=159, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.198880658098944, FLOP=40.81
[Search] : epoch=159/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:05:55] [epoch=159/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.819 (0.819)  Prec@1 71.09 (71.09) Prec@5 96.88 (96.88) Acls-loss 1.055 (1.055) FLOP-Loss 0.000 (0.000) Arch-Loss 1.055 (1.055)
**TRAIN** [2020-01-29 07:06:20] [epoch=159/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.819 (0.838)  Prec@1 75.60 (71.63) Prec@5 97.62 (97.55) Acls-loss 0.915 (0.871) FLOP-Loss 0.000 (0.027) Arch-Loss 0.915 (0.925)
 **TRAIN** Prec@1 71.63 Prec@5 97.55 Error@1 28.37 Error@5 2.45 Base-Loss:0.838, Arch-Loss=0.925
***[2020-01-29 07:06:20]*** TRAIN [epoch=159/600] base-loss = 0.838455, arch-loss = 0.924619, accuracy-1 = 71.63, accuracy-5 = 97.55
[epoch=159/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.946048)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.428 0.217 0.355  ||  0.1704 -0.5084 -0.0177  || discrepancy=0.07 || select=0/3
001/003-th : 0.381 0.156 0.462  ||  0.0387 -0.8544 0.2309  || discrepancy=0.08 || select=2/3
002/003-th : 0.119 0.217 0.664  ||  -0.8599 -0.2599 0.8578  || discrepancy=0.45 || select=2/3
-----------------------------------------------
000/019-th : 0.062 0.083 0.100 0.119 0.142 0.151 0.163 0.180  ||  -0.650 -0.354 -0.164 0.002 0.182 0.244 0.322 0.418    || dis=0.02 || select=7/8
001/019-th : 0.129 0.125 0.125 0.129 0.129 0.121 0.122 0.119  ||  0.037 0.005 0.005 0.038 0.033 -0.027 -0.016 -0.044    || dis=0.00 || select=3/8
002/019-th : 0.121 0.127 0.129 0.128 0.130 0.127 0.120 0.117  ||  -0.029 0.012 0.033 0.027 0.040 0.015 -0.038 -0.069    || dis=0.00 || select=4/8
003/019-th : 0.125 0.128 0.123 0.127 0.125 0.126 0.122 0.125  ||  -0.002 0.020 -0.019 0.017 -0.005 0.005 -0.029 -0.002  || dis=0.00 || select=1/8
004/019-th : 0.116 0.117 0.124 0.120 0.130 0.134 0.130 0.128  ||  -0.070 -0.065 -0.004 -0.039 0.040 0.073 0.044 0.023   || dis=0.00 || select=5/8
005/019-th : 0.117 0.118 0.124 0.123 0.126 0.130 0.128 0.133  ||  -0.063 -0.056 -0.011 -0.014 0.012 0.037 0.027 0.062   || dis=0.00 || select=7/8
006/019-th : 0.117 0.113 0.117 0.121 0.128 0.130 0.136 0.138  ||  -0.064 -0.100 -0.063 -0.034 0.021 0.042 0.084 0.099   || dis=0.00 || select=7/8
007/019-th : 0.075 0.084 0.103 0.111 0.141 0.144 0.159 0.183  ||  -0.468 -0.356 -0.152 -0.075 0.162 0.188 0.285 0.424   || dis=0.02 || select=7/8
008/019-th : 0.057 0.071 0.094 0.129 0.144 0.159 0.169 0.177  ||  -0.714 -0.490 -0.213 0.105 0.217 0.314 0.372 0.419    || dis=0.01 || select=7/8
009/019-th : 0.104 0.096 0.106 0.118 0.125 0.139 0.147 0.165  ||  -0.169 -0.251 -0.148 -0.046 0.013 0.124 0.176 0.290   || dis=0.02 || select=7/8
010/019-th : 0.102 0.109 0.119 0.126 0.130 0.138 0.143 0.133  ||  -0.200 -0.127 -0.046 0.015 0.046 0.106 0.140 0.070    || dis=0.00 || select=6/8
011/019-th : 0.104 0.099 0.105 0.121 0.125 0.133 0.150 0.164  ||  -0.165 -0.223 -0.163 -0.022 0.017 0.077 0.194 0.284   || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.118 0.124 0.129 0.131 0.133 0.138  ||  -0.094 -0.088 -0.053 -0.004 0.036 0.054 0.070 0.107   || dis=0.01 || select=7/8
013/019-th : 0.047 0.051 0.068 0.082 0.112 0.140 0.204 0.297  ||  -0.801 -0.715 -0.434 -0.246 0.073 0.291 0.667 1.045   || dis=0.09 || select=7/8
014/019-th : 0.056 0.065 0.074 0.100 0.139 0.156 0.197 0.212  ||  -0.695 -0.548 -0.423 -0.113 0.211 0.326 0.562 0.635   || dis=0.01 || select=7/8
015/019-th : 0.043 0.045 0.057 0.088 0.109 0.156 0.209 0.293  ||  -0.863 -0.808 -0.570 -0.132 0.080 0.434 0.727 1.066   || dis=0.08 || select=7/8
016/019-th : 0.056 0.075 0.097 0.126 0.143 0.158 0.171 0.174  ||  -0.729 -0.443 -0.189 0.076 0.198 0.301 0.377 0.400    || dis=0.00 || select=7/8
017/019-th : 0.122 0.118 0.123 0.119 0.130 0.125 0.131 0.132  ||  -0.019 -0.052 -0.016 -0.050 0.039 0.004 0.050 0.053   || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.111 0.120 0.126 0.140 0.149 0.167  ||  -0.342 -0.208 -0.098 -0.015 0.028 0.134 0.199 0.313   || dis=0.02 || select=7/8
[epoch=159/600] FLOP : 28.95 MB, ratio : 0.7092, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:06:20] [epoch=159/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.089 (2.089)  Prec@1 35.94 (35.94) Prec@5 78.12 (78.12) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:06:26] [epoch=159/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.192 (2.412)  Prec@1 40.48 (36.99) Prec@5 85.12 (80.95) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.99 Prec@5 80.95 Error@1 63.01 Error@5 19.05 Loss:2.412
***[2020-01-29 07:06:26]*** VALID [epoch=159/600] loss = 2.412318, accuracy@1 = 36.99, accuracy@5 = 80.95 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:06:26]*** start epoch=160/600 Time Left: [03:54:50], LR=[0.083457 ~ 0.083457], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=160, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.189369985579202, FLOP=40.81
[Search] : epoch=160/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:06:27] [epoch=160/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.860 (0.860)  Prec@1 66.41 (66.41) Prec@5 97.27 (97.27) Acls-loss 0.855 (0.855) FLOP-Loss 2.636 (2.636) Arch-Loss 6.127 (6.127)
**TRAIN** [2020-01-29 07:06:52] [epoch=160/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.780 (0.814)  Prec@1 75.00 (71.99) Prec@5 98.21 (97.74) Acls-loss 0.885 (0.861) FLOP-Loss 0.000 (0.027) Arch-Loss 0.885 (0.915)
 **TRAIN** Prec@1 71.99 Prec@5 97.74 Error@1 28.01 Error@5 2.26 Base-Loss:0.814, Arch-Loss=0.915
***[2020-01-29 07:06:52]*** TRAIN [epoch=160/600] base-loss = 0.813855, arch-loss = 0.914735, accuracy-1 = 71.99, accuracy-5 = 97.74
[epoch=160/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 9, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.429952)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.429 0.214 0.357  ||  0.1700 -0.5261 -0.0142  || discrepancy=0.07 || select=0/3
001/003-th : 0.381 0.154 0.465  ||  0.0374 -0.8727 0.2356  || discrepancy=0.08 || select=2/3
002/003-th : 0.118 0.218 0.664  ||  -0.8691 -0.2516 0.8630  || discrepancy=0.45 || select=2/3
-----------------------------------------------
000/019-th : 0.061 0.084 0.100 0.118 0.139 0.150 0.165 0.182  ||  -0.660 -0.349 -0.165 -0.005 0.160 0.237 0.332 0.432   || dis=0.02 || select=7/8
001/019-th : 0.129 0.124 0.125 0.129 0.129 0.122 0.123 0.119  ||  0.036 -0.001 0.005 0.036 0.034 -0.023 -0.013 -0.043   || dis=0.00 || select=3/8
002/019-th : 0.121 0.128 0.129 0.127 0.131 0.127 0.120 0.117  ||  -0.032 0.020 0.032 0.014 0.042 0.018 -0.039 -0.068    || dis=0.00 || select=4/8
003/019-th : 0.124 0.127 0.125 0.127 0.123 0.126 0.123 0.126  ||  -0.010 0.015 -0.006 0.015 -0.019 0.007 -0.021 0.003   || dis=0.00 || select=3/8
004/019-th : 0.116 0.117 0.125 0.121 0.129 0.135 0.130 0.127  ||  -0.071 -0.065 -0.000 -0.031 0.034 0.078 0.042 0.022   || dis=0.01 || select=5/8
005/019-th : 0.117 0.117 0.124 0.123 0.126 0.130 0.130 0.133  ||  -0.065 -0.065 -0.009 -0.017 0.008 0.038 0.040 0.063   || dis=0.00 || select=7/8
006/019-th : 0.117 0.112 0.116 0.122 0.129 0.130 0.137 0.137  ||  -0.063 -0.112 -0.073 -0.026 0.036 0.044 0.091 0.097   || dis=0.00 || select=7/8
007/019-th : 0.075 0.083 0.101 0.113 0.140 0.145 0.160 0.183  ||  -0.461 -0.365 -0.166 -0.060 0.155 0.193 0.289 0.425   || dis=0.02 || select=7/8
008/019-th : 0.057 0.071 0.093 0.128 0.148 0.159 0.168 0.177  ||  -0.715 -0.492 -0.220 0.100 0.243 0.312 0.367 0.419    || dis=0.01 || select=7/8
009/019-th : 0.104 0.096 0.106 0.117 0.126 0.138 0.148 0.165  ||  -0.173 -0.249 -0.150 -0.049 0.019 0.116 0.182 0.292   || dis=0.02 || select=7/8
010/019-th : 0.101 0.109 0.118 0.125 0.132 0.139 0.142 0.134  ||  -0.201 -0.134 -0.052 0.008 0.065 0.115 0.133 0.075    || dis=0.00 || select=6/8
011/019-th : 0.105 0.098 0.104 0.118 0.126 0.134 0.151 0.164  ||  -0.164 -0.229 -0.171 -0.041 0.024 0.081 0.204 0.289   || dis=0.01 || select=7/8
012/019-th : 0.112 0.113 0.118 0.125 0.129 0.131 0.134 0.138  ||  -0.098 -0.096 -0.054 0.009 0.041 0.053 0.077 0.106    || dis=0.00 || select=7/8
013/019-th : 0.047 0.051 0.067 0.082 0.110 0.140 0.205 0.298  ||  -0.792 -0.720 -0.446 -0.242 0.058 0.297 0.675 1.051   || dis=0.09 || select=7/8
014/019-th : 0.056 0.065 0.074 0.100 0.139 0.155 0.198 0.213  ||  -0.700 -0.550 -0.424 -0.113 0.216 0.323 0.566 0.638   || dis=0.01 || select=7/8
015/019-th : 0.043 0.045 0.057 0.090 0.110 0.156 0.207 0.294  ||  -0.862 -0.817 -0.578 -0.119 0.088 0.436 0.717 1.069   || dis=0.09 || select=7/8
016/019-th : 0.056 0.075 0.098 0.125 0.142 0.158 0.170 0.176  ||  -0.733 -0.446 -0.179 0.069 0.191 0.301 0.376 0.406    || dis=0.01 || select=7/8
017/019-th : 0.123 0.119 0.122 0.118 0.129 0.126 0.132 0.132  ||  -0.018 -0.051 -0.020 -0.060 0.033 0.006 0.055 0.054   || dis=0.00 || select=6/8
018/019-th : 0.089 0.100 0.111 0.121 0.128 0.137 0.149 0.166  ||  -0.324 -0.204 -0.102 -0.013 0.041 0.110 0.198 0.306   || dis=0.02 || select=7/8
[epoch=160/600] FLOP : 28.43 MB, ratio : 0.6966, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:06:53] [epoch=160/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.644 (2.644)  Prec@1 34.38 (34.38) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:06:59] [epoch=160/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.989 (2.163)  Prec@1 35.71 (38.97) Prec@5 73.81 (83.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.97 Prec@5 83.60 Error@1 61.03 Error@5 16.40 Loss:2.163
***[2020-01-29 07:06:59]*** VALID [epoch=160/600] loss = 2.162804, accuracy@1 = 38.97, accuracy@5 = 83.60 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:06:59]*** start epoch=161/600 Time Left: [03:54:20], LR=[0.083262 ~ 0.083262], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=161, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.179814368903184, FLOP=40.81
[Search] : epoch=161/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:07:00] [epoch=161/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 1.005 (1.005)  Prec@1 65.62 (65.62) Prec@5 97.66 (97.66) Acls-loss 0.904 (0.904) FLOP-Loss 0.000 (0.000) Arch-Loss 0.904 (0.904)
**TRAIN** [2020-01-29 07:07:25] [epoch=161/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.809 (0.834)  Prec@1 70.24 (71.68) Prec@5 98.81 (97.73) Acls-loss 0.974 (0.866) FLOP-Loss 0.000 (0.135) Arch-Loss 0.974 (1.136)
 **TRAIN** Prec@1 71.68 Prec@5 97.73 Error@1 28.32 Error@5 2.27 Base-Loss:0.834, Arch-Loss=1.136
***[2020-01-29 07:07:25]*** TRAIN [epoch=161/600] base-loss = 0.834491, arch-loss = 1.135674, accuracy-1 = 71.68, accuracy-5 = 97.73
[epoch=161/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 6, 12, 16, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.435 0.212 0.353  ||  0.1830 -0.5370 -0.0250  || discrepancy=0.08 || select=0/3
001/003-th : 0.386 0.156 0.458  ||  0.0524 -0.8541 0.2215  || discrepancy=0.07 || select=2/3
002/003-th : 0.118 0.221 0.661  ||  -0.8682 -0.2369 0.8590  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.062 0.085 0.100 0.119 0.139 0.149 0.163 0.183  ||  -0.649 -0.339 -0.168 0.002 0.159 0.224 0.319 0.432    || dis=0.02 || select=7/8
001/019-th : 0.131 0.126 0.128 0.131 0.126 0.120 0.120 0.118  ||  0.048 0.013 0.027 0.055 0.015 -0.037 -0.033 -0.056    || dis=0.00 || select=3/8
002/019-th : 0.123 0.129 0.131 0.128 0.128 0.125 0.119 0.115  ||  -0.016 0.033 0.047 0.024 0.019 0.001 -0.049 -0.082    || dis=0.00 || select=2/8
003/019-th : 0.125 0.129 0.127 0.128 0.124 0.124 0.121 0.124  ||  -0.003 0.029 0.017 0.020 -0.007 -0.011 -0.034 -0.012  || dis=0.00 || select=1/8
004/019-th : 0.118 0.117 0.125 0.123 0.130 0.132 0.128 0.127  ||  -0.059 -0.061 0.003 -0.014 0.039 0.058 0.025 0.019    || dis=0.00 || select=5/8
005/019-th : 0.118 0.119 0.127 0.123 0.126 0.128 0.129 0.131  ||  -0.057 -0.046 0.013 -0.016 0.005 0.022 0.030 0.046    || dis=0.00 || select=7/8
006/019-th : 0.119 0.112 0.117 0.122 0.130 0.129 0.136 0.136  ||  -0.051 -0.104 -0.066 -0.020 0.041 0.034 0.084 0.083   || dis=0.00 || select=6/8
007/019-th : 0.077 0.085 0.103 0.113 0.139 0.143 0.160 0.181  ||  -0.448 -0.347 -0.151 -0.061 0.147 0.172 0.285 0.411   || dis=0.02 || select=7/8
008/019-th : 0.057 0.072 0.094 0.130 0.147 0.161 0.165 0.174  ||  -0.713 -0.483 -0.212 0.111 0.234 0.328 0.352 0.406    || dis=0.01 || select=7/8
009/019-th : 0.104 0.098 0.107 0.119 0.126 0.138 0.146 0.162  ||  -0.166 -0.232 -0.145 -0.032 0.019 0.113 0.170 0.275   || dis=0.02 || select=7/8
010/019-th : 0.103 0.110 0.119 0.125 0.132 0.138 0.139 0.133  ||  -0.191 -0.118 -0.044 0.005 0.064 0.105 0.115 0.069    || dis=0.00 || select=6/8
011/019-th : 0.107 0.099 0.104 0.117 0.125 0.132 0.151 0.164  ||  -0.146 -0.217 -0.170 -0.050 0.012 0.066 0.201 0.285   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.119 0.126 0.128 0.129 0.132 0.137  ||  -0.086 -0.077 -0.043 0.015 0.033 0.034 0.058 0.097    || dis=0.01 || select=7/8
013/019-th : 0.048 0.051 0.067 0.082 0.111 0.139 0.204 0.298  ||  -0.786 -0.717 -0.436 -0.242 0.059 0.288 0.673 1.049   || dis=0.09 || select=7/8
014/019-th : 0.057 0.065 0.073 0.101 0.140 0.158 0.196 0.210  ||  -0.686 -0.545 -0.427 -0.106 0.220 0.339 0.554 0.622   || dis=0.01 || select=7/8
015/019-th : 0.042 0.046 0.058 0.091 0.109 0.156 0.208 0.291  ||  -0.874 -0.791 -0.563 -0.110 0.071 0.430 0.720 1.057   || dis=0.08 || select=7/8
016/019-th : 0.057 0.075 0.099 0.126 0.142 0.159 0.168 0.174  ||  -0.716 -0.442 -0.167 0.069 0.191 0.303 0.363 0.394    || dis=0.01 || select=7/8
017/019-th : 0.124 0.121 0.124 0.118 0.129 0.124 0.130 0.130  ||  -0.004 -0.035 -0.006 -0.053 0.034 -0.005 0.037 0.038  || dis=0.00 || select=7/8
018/019-th : 0.090 0.101 0.110 0.123 0.127 0.136 0.150 0.163  ||  -0.310 -0.196 -0.105 0.001 0.039 0.101 0.202 0.288    || dis=0.01 || select=7/8
[epoch=161/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:07:25] [epoch=161/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.600 (2.600)  Prec@1 36.33 (36.33) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:07:32] [epoch=161/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.602 (2.266)  Prec@1 16.67 (37.90) Prec@5 60.71 (82.19) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.90 Prec@5 82.19 Error@1 62.10 Error@5 17.81 Loss:2.266
***[2020-01-29 07:07:32]*** VALID [epoch=161/600] loss = 2.265771, accuracy@1 = 37.90, accuracy@5 = 82.19 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:07:32]*** start epoch=162/600 Time Left: [03:53:50], LR=[0.083066 ~ 0.083066], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=162, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.170214070042947, FLOP=40.81
[Search] : epoch=162/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:07:32] [epoch=162/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.745 (0.745)  Prec@1 75.00 (75.00) Prec@5 98.83 (98.83) Acls-loss 0.837 (0.837) FLOP-Loss 0.000 (0.000) Arch-Loss 0.837 (0.837)
**TRAIN** [2020-01-29 07:07:58] [epoch=162/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.771 (0.832)  Prec@1 74.40 (71.53) Prec@5 98.21 (97.70) Acls-loss 0.856 (0.884) FLOP-Loss 0.000 (0.107) Arch-Loss 0.856 (1.099)
 **TRAIN** Prec@1 71.53 Prec@5 97.70 Error@1 28.47 Error@5 2.30 Base-Loss:0.832, Arch-Loss=1.099
***[2020-01-29 07:07:58]*** TRAIN [epoch=162/600] base-loss = 0.832422, arch-loss = 1.099302, accuracy-1 = 71.53, accuracy-5 = 97.70
[epoch=162/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.173504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.212 0.348  ||  0.1973 -0.5317 -0.0387  || discrepancy=0.09 || select=0/3
001/003-th : 0.391 0.155 0.454  ||  0.0639 -0.8633 0.2130  || discrepancy=0.06 || select=2/3
002/003-th : 0.118 0.226 0.656  ||  -0.8620 -0.2171 0.8493  || discrepancy=0.43 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.085 0.102 0.121 0.139 0.148 0.163 0.181  ||  -0.636 -0.341 -0.153 0.014 0.153 0.218 0.314 0.417    || dis=0.02 || select=7/8
001/019-th : 0.132 0.127 0.130 0.133 0.126 0.118 0.119 0.116  ||  0.058 0.024 0.043 0.065 0.015 -0.052 -0.045 -0.069    || dis=0.00 || select=3/8
002/019-th : 0.125 0.131 0.132 0.129 0.127 0.124 0.118 0.114  ||  -0.002 0.046 0.055 0.032 0.011 -0.013 -0.062 -0.093   || dis=0.00 || select=2/8
003/019-th : 0.126 0.130 0.128 0.130 0.123 0.122 0.119 0.122  ||  0.010 0.039 0.027 0.037 -0.015 -0.026 -0.047 -0.023   || dis=0.00 || select=1/8
004/019-th : 0.120 0.119 0.126 0.122 0.128 0.130 0.127 0.127  ||  -0.045 -0.054 0.010 -0.025 0.026 0.041 0.017 0.018    || dis=0.00 || select=5/8
005/019-th : 0.119 0.120 0.128 0.125 0.125 0.127 0.128 0.129  ||  -0.046 -0.040 0.021 -0.003 -0.001 0.016 0.027 0.029   || dis=0.00 || select=7/8
006/019-th : 0.120 0.114 0.119 0.121 0.130 0.129 0.133 0.134  ||  -0.042 -0.092 -0.044 -0.028 0.044 0.033 0.067 0.071   || dis=0.00 || select=7/8
007/019-th : 0.078 0.085 0.103 0.114 0.139 0.141 0.159 0.182  ||  -0.436 -0.346 -0.152 -0.058 0.145 0.156 0.276 0.413   || dis=0.02 || select=7/8
008/019-th : 0.057 0.071 0.095 0.131 0.146 0.163 0.163 0.173  ||  -0.706 -0.488 -0.200 0.117 0.228 0.337 0.337 0.399    || dis=0.01 || select=7/8
009/019-th : 0.104 0.100 0.109 0.118 0.128 0.136 0.144 0.161  ||  -0.167 -0.212 -0.126 -0.046 0.035 0.095 0.156 0.268   || dis=0.02 || select=7/8
010/019-th : 0.104 0.111 0.120 0.126 0.133 0.136 0.137 0.133  ||  -0.180 -0.113 -0.035 0.010 0.064 0.092 0.100 0.068    || dis=0.00 || select=6/8
011/019-th : 0.108 0.101 0.107 0.115 0.125 0.131 0.149 0.163  ||  -0.140 -0.201 -0.147 -0.069 0.011 0.059 0.189 0.277   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.121 0.125 0.130 0.127 0.132 0.136  ||  -0.082 -0.079 -0.030 0.002 0.046 0.025 0.060 0.092    || dis=0.00 || select=7/8
013/019-th : 0.048 0.051 0.066 0.082 0.114 0.141 0.199 0.298  ||  -0.782 -0.717 -0.459 -0.237 0.088 0.303 0.646 1.049   || dis=0.10 || select=7/8
014/019-th : 0.057 0.065 0.075 0.102 0.139 0.160 0.194 0.208  ||  -0.678 -0.546 -0.413 -0.104 0.207 0.352 0.543 0.615   || dis=0.01 || select=7/8
015/019-th : 0.041 0.048 0.058 0.091 0.109 0.152 0.210 0.291  ||  -0.915 -0.746 -0.549 -0.107 0.072 0.405 0.731 1.054   || dis=0.08 || select=7/8
016/019-th : 0.058 0.077 0.100 0.126 0.141 0.158 0.169 0.171  ||  -0.708 -0.419 -0.159 0.067 0.185 0.295 0.367 0.375    || dis=0.00 || select=7/8
017/019-th : 0.125 0.122 0.124 0.120 0.129 0.123 0.127 0.128  ||  0.005 -0.019 -0.004 -0.037 0.035 -0.013 0.018 0.026   || dis=0.00 || select=4/8
018/019-th : 0.091 0.103 0.112 0.123 0.129 0.135 0.147 0.160  ||  -0.299 -0.177 -0.088 0.000 0.051 0.099 0.184 0.265    || dis=0.01 || select=7/8
[epoch=162/600] FLOP : 27.17 MB, ratio : 0.6658, Expected-ratio : 0.7000, Discrepancy : 0.040
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:07:58] [epoch=162/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.469 (1.469)  Prec@1 46.48 (46.48) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:08:04] [epoch=162/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.411 (2.271)  Prec@1 14.29 (37.04) Prec@5 57.74 (81.39) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.04 Prec@5 81.39 Error@1 62.96 Error@5 18.61 Loss:2.271
***[2020-01-29 07:08:04]*** VALID [epoch=162/600] loss = 2.270708, accuracy@1 = 37.04, accuracy@5 = 81.39 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:08:04]*** start epoch=163/600 Time Left: [03:53:19], LR=[0.082869 ~ 0.082869], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=163, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.160569352195535, FLOP=40.81
[Search] : epoch=163/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:08:05] [epoch=163/600][000/098] Time 0.76 (0.76) Data 0.36 (0.36) Base-Loss 0.818 (0.818)  Prec@1 68.75 (68.75) Prec@5 98.44 (98.44) Acls-loss 0.786 (0.786) FLOP-Loss 0.000 (0.000) Arch-Loss 0.786 (0.786)
**TRAIN** [2020-01-29 07:08:30] [epoch=163/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.728 (0.834)  Prec@1 77.98 (71.27) Prec@5 98.81 (97.64) Acls-loss 0.856 (0.856) FLOP-Loss 0.000 (0.027) Arch-Loss 0.856 (0.910)
 **TRAIN** Prec@1 71.27 Prec@5 97.64 Error@1 28.73 Error@5 2.36 Base-Loss:0.834, Arch-Loss=0.910
***[2020-01-29 07:08:30]*** TRAIN [epoch=163/600] base-loss = 0.834228, arch-loss = 0.909985, accuracy-1 = 71.27, accuracy-5 = 97.64
[epoch=163/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 12, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.173504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.214 0.347  ||  0.1964 -0.5193 -0.0371  || discrepancy=0.09 || select=0/3
001/003-th : 0.391 0.153 0.456  ||  0.0620 -0.8745 0.2178  || discrepancy=0.07 || select=2/3
002/003-th : 0.118 0.225 0.658  ||  -0.8660 -0.2203 0.8542  || discrepancy=0.43 || select=2/3
-----------------------------------------------
000/019-th : 0.063 0.083 0.101 0.120 0.139 0.147 0.166 0.182  ||  -0.641 -0.353 -0.165 0.008 0.155 0.217 0.333 0.428    || dis=0.02 || select=7/8
001/019-th : 0.132 0.125 0.131 0.132 0.125 0.118 0.119 0.117  ||  0.058 0.008 0.051 0.061 0.007 -0.048 -0.041 -0.063    || dis=0.00 || select=3/8
002/019-th : 0.125 0.130 0.132 0.128 0.129 0.125 0.118 0.114  ||  -0.004 0.040 0.052 0.023 0.029 0.001 -0.062 -0.094    || dis=0.00 || select=2/8
003/019-th : 0.127 0.129 0.127 0.130 0.124 0.121 0.120 0.123  ||  0.014 0.030 0.017 0.035 -0.012 -0.031 -0.046 -0.016   || dis=0.00 || select=3/8
004/019-th : 0.119 0.118 0.126 0.121 0.128 0.133 0.128 0.127  ||  -0.050 -0.061 0.009 -0.029 0.024 0.058 0.022 0.019    || dis=0.01 || select=5/8
005/019-th : 0.120 0.119 0.127 0.124 0.126 0.126 0.129 0.129  ||  -0.041 -0.046 0.015 -0.011 0.009 0.011 0.032 0.030    || dis=0.00 || select=6/8
006/019-th : 0.120 0.114 0.118 0.121 0.130 0.129 0.134 0.135  ||  -0.043 -0.091 -0.052 -0.034 0.043 0.033 0.068 0.077   || dis=0.00 || select=7/8
007/019-th : 0.078 0.084 0.102 0.117 0.137 0.140 0.158 0.183  ||  -0.427 -0.364 -0.165 -0.028 0.133 0.154 0.273 0.421   || dis=0.02 || select=7/8
008/019-th : 0.058 0.070 0.095 0.129 0.147 0.161 0.165 0.175  ||  -0.698 -0.505 -0.207 0.108 0.232 0.329 0.348 0.411    || dis=0.01 || select=7/8
009/019-th : 0.105 0.100 0.107 0.119 0.127 0.135 0.144 0.163  ||  -0.159 -0.216 -0.143 -0.039 0.026 0.093 0.156 0.275   || dis=0.02 || select=7/8
010/019-th : 0.104 0.111 0.117 0.127 0.134 0.137 0.138 0.132  ||  -0.181 -0.111 -0.059 0.024 0.079 0.100 0.104 0.061    || dis=0.00 || select=6/8
011/019-th : 0.108 0.101 0.106 0.115 0.125 0.131 0.149 0.164  ||  -0.137 -0.203 -0.155 -0.075 0.012 0.059 0.188 0.284   || dis=0.02 || select=7/8
012/019-th : 0.113 0.115 0.120 0.125 0.131 0.127 0.132 0.137  ||  -0.091 -0.078 -0.036 0.007 0.053 0.024 0.061 0.096    || dis=0.01 || select=7/8
013/019-th : 0.047 0.050 0.065 0.082 0.113 0.140 0.205 0.300  ||  -0.796 -0.730 -0.468 -0.238 0.081 0.297 0.680 1.060   || dis=0.10 || select=7/8
014/019-th : 0.057 0.065 0.074 0.100 0.137 0.164 0.195 0.209  ||  -0.678 -0.545 -0.422 -0.117 0.198 0.375 0.548 0.618   || dis=0.01 || select=7/8
015/019-th : 0.040 0.047 0.059 0.090 0.108 0.154 0.213 0.288  ||  -0.919 -0.775 -0.530 -0.110 0.070 0.420 0.748 1.048   || dis=0.07 || select=7/8
016/019-th : 0.058 0.078 0.101 0.127 0.140 0.157 0.169 0.171  ||  -0.701 -0.413 -0.155 0.073 0.172 0.288 0.364 0.373    || dis=0.00 || select=7/8
017/019-th : 0.125 0.122 0.125 0.120 0.129 0.123 0.128 0.128  ||  0.004 -0.026 -0.001 -0.036 0.030 -0.013 0.024 0.029   || dis=0.00 || select=4/8
018/019-th : 0.092 0.102 0.110 0.123 0.131 0.134 0.148 0.160  ||  -0.289 -0.183 -0.110 0.004 0.064 0.091 0.190 0.265    || dis=0.01 || select=7/8
[epoch=163/600] FLOP : 27.17 MB, ratio : 0.6658, Expected-ratio : 0.7000, Discrepancy : 0.040
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:08:31] [epoch=163/600][000/098] Time 0.39 (0.39) Data 0.31 (0.31) Loss 2.829 (2.829)  Prec@1 39.84 (39.84) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:08:37] [epoch=163/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 1.416 (2.027)  Prec@1 54.76 (40.72) Prec@5 94.64 (85.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.72 Prec@5 85.42 Error@1 59.28 Error@5 14.58 Loss:2.027
***[2020-01-29 07:08:37]*** VALID [epoch=163/600] loss = 2.027429, accuracy@1 = 40.72, accuracy@5 = 85.42 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:08:37]*** start epoch=164/600 Time Left: [03:52:49], LR=[0.082671 ~ 0.082671], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=164, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.150880479775759, FLOP=40.81
[Search] : epoch=164/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:08:38] [epoch=164/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.783 (0.783)  Prec@1 73.83 (73.83) Prec@5 97.66 (97.66) Acls-loss 0.885 (0.885) FLOP-Loss 0.000 (0.000) Arch-Loss 0.885 (0.885)
**TRAIN** [2020-01-29 07:09:03] [epoch=164/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.919 (0.831)  Prec@1 69.64 (71.30) Prec@5 98.21 (97.61) Acls-loss 0.843 (0.860) FLOP-Loss 0.000 (-0.054) Arch-Loss 0.843 (0.752)
 **TRAIN** Prec@1 71.30 Prec@5 97.61 Error@1 28.70 Error@5 2.39 Base-Loss:0.831, Arch-Loss=0.752
***[2020-01-29 07:09:03]*** TRAIN [epoch=164/600] base-loss = 0.830753, arch-loss = 0.752478, accuracy-1 = 71.30, accuracy-5 = 97.61
[epoch=164/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 12, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.432 0.215 0.353  ||  0.1818 -0.5138 -0.0209  || discrepancy=0.08 || select=0/3
001/003-th : 0.383 0.154 0.463  ||  0.0458 -0.8632 0.2346  || discrepancy=0.08 || select=2/3
002/003-th : 0.114 0.219 0.667  ||  -0.8907 -0.2343 0.8771  || discrepancy=0.45 || select=2/3
-----------------------------------------------
000/019-th : 0.060 0.081 0.102 0.120 0.140 0.148 0.167 0.183  ||  -0.669 -0.381 -0.151 0.015 0.171 0.227 0.346 0.436    || dis=0.02 || select=7/8
001/019-th : 0.130 0.124 0.129 0.130 0.127 0.120 0.121 0.118  ||  0.047 -0.007 0.032 0.047 0.021 -0.034 -0.027 -0.050   || dis=0.00 || select=0/8
002/019-th : 0.123 0.128 0.131 0.127 0.129 0.127 0.120 0.116  ||  -0.019 0.021 0.044 0.015 0.028 0.015 -0.042 -0.079    || dis=0.00 || select=2/8
003/019-th : 0.125 0.127 0.126 0.128 0.125 0.122 0.122 0.125  ||  0.001 0.015 0.006 0.025 -0.005 -0.026 -0.027 -0.002   || dis=0.00 || select=3/8
004/019-th : 0.117 0.115 0.123 0.120 0.131 0.134 0.131 0.130  ||  -0.066 -0.086 -0.016 -0.045 0.047 0.070 0.046 0.039   || dis=0.00 || select=5/8
005/019-th : 0.117 0.119 0.125 0.123 0.127 0.126 0.132 0.131  ||  -0.067 -0.050 0.002 -0.018 0.015 0.012 0.054 0.050    || dis=0.00 || select=6/8
006/019-th : 0.118 0.113 0.117 0.120 0.130 0.128 0.136 0.137  ||  -0.058 -0.099 -0.065 -0.036 0.040 0.028 0.086 0.093   || dis=0.00 || select=7/8
007/019-th : 0.078 0.081 0.101 0.115 0.136 0.143 0.160 0.187  ||  -0.433 -0.393 -0.177 -0.038 0.126 0.173 0.287 0.443   || dis=0.03 || select=7/8
008/019-th : 0.057 0.069 0.091 0.126 0.146 0.164 0.168 0.179  ||  -0.708 -0.518 -0.245 0.089 0.233 0.352 0.373 0.437    || dis=0.01 || select=7/8
009/019-th : 0.103 0.098 0.106 0.115 0.127 0.138 0.148 0.165  ||  -0.178 -0.231 -0.152 -0.069 0.030 0.116 0.180 0.291   || dis=0.02 || select=7/8
010/019-th : 0.102 0.109 0.115 0.124 0.137 0.137 0.139 0.135  ||  -0.194 -0.129 -0.075 -0.003 0.100 0.102 0.116 0.086   || dis=0.00 || select=6/8
011/019-th : 0.107 0.099 0.105 0.114 0.124 0.133 0.151 0.167  ||  -0.147 -0.225 -0.167 -0.078 0.007 0.078 0.203 0.300   || dis=0.02 || select=7/8
012/019-th : 0.111 0.113 0.118 0.123 0.133 0.130 0.135 0.138  ||  -0.109 -0.094 -0.050 -0.009 0.066 0.043 0.082 0.105   || dis=0.00 || select=7/8
013/019-th : 0.046 0.050 0.065 0.081 0.110 0.137 0.202 0.309  ||  -0.810 -0.730 -0.468 -0.237 0.063 0.284 0.672 1.094   || dis=0.11 || select=7/8
014/019-th : 0.056 0.063 0.073 0.101 0.136 0.162 0.196 0.213  ||  -0.687 -0.572 -0.430 -0.107 0.191 0.369 0.558 0.639   || dis=0.02 || select=7/8
015/019-th : 0.041 0.045 0.059 0.088 0.107 0.154 0.217 0.290  ||  -0.906 -0.795 -0.537 -0.135 0.062 0.430 0.772 1.060   || dis=0.07 || select=7/8
016/019-th : 0.057 0.076 0.099 0.124 0.139 0.159 0.172 0.174  ||  -0.716 -0.434 -0.171 0.054 0.170 0.305 0.384 0.392    || dis=0.00 || select=7/8
017/019-th : 0.123 0.119 0.124 0.120 0.129 0.125 0.130 0.130  ||  -0.013 -0.047 -0.003 -0.041 0.038 0.005 0.039 0.041   || dis=0.00 || select=7/8
018/019-th : 0.090 0.100 0.108 0.124 0.129 0.137 0.150 0.161  ||  -0.306 -0.203 -0.123 0.012 0.055 0.115 0.205 0.275    || dis=0.01 || select=7/8
[epoch=164/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:09:03] [epoch=164/600][000/098] Time 0.37 (0.37) Data 0.30 (0.30) Loss 2.827 (2.827)  Prec@1 44.92 (44.92) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:09:09] [epoch=164/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.299 (2.197)  Prec@1 30.36 (38.80) Prec@5 78.57 (84.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.80 Prec@5 84.13 Error@1 61.20 Error@5 15.87 Loss:2.197
***[2020-01-29 07:09:10]*** VALID [epoch=164/600] loss = 2.197404, accuracy@1 = 38.80, accuracy@5 = 84.13 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:09:10]*** start epoch=165/600 Time Left: [03:52:18], LR=[0.082472 ~ 0.082472], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=165, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.141147718408949, FLOP=40.81
[Search] : epoch=165/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:09:10] [epoch=165/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.784 (0.784)  Prec@1 75.39 (75.39) Prec@5 98.44 (98.44) Acls-loss 0.865 (0.865) FLOP-Loss 0.000 (0.000) Arch-Loss 0.865 (0.865)
**TRAIN** [2020-01-29 07:09:36] [epoch=165/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.776 (0.833)  Prec@1 75.00 (71.43) Prec@5 98.81 (97.83) Acls-loss 1.123 (0.854) FLOP-Loss 0.000 (0.054) Arch-Loss 1.123 (0.963)
 **TRAIN** Prec@1 71.43 Prec@5 97.83 Error@1 28.57 Error@5 2.17 Base-Loss:0.833, Arch-Loss=0.963
***[2020-01-29 07:09:36]*** TRAIN [epoch=165/600] base-loss = 0.832554, arch-loss = 0.962577, accuracy-1 = 71.43, accuracy-5 = 97.83
[epoch=165/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.434 0.214 0.352  ||  0.1861 -0.5183 -0.0235  || discrepancy=0.08 || select=0/3
001/003-th : 0.382 0.154 0.463  ||  0.0446 -0.8614 0.2377  || discrepancy=0.08 || select=2/3
002/003-th : 0.112 0.219 0.669  ||  -0.9013 -0.2312 0.8847  || discrepancy=0.45 || select=2/3
-----------------------------------------------
000/019-th : 0.061 0.080 0.102 0.120 0.140 0.148 0.167 0.183  ||  -0.666 -0.384 -0.149 0.019 0.167 0.225 0.344 0.436    || dis=0.02 || select=7/8
001/019-th : 0.131 0.124 0.128 0.131 0.127 0.121 0.121 0.118  ||  0.053 -0.008 0.023 0.049 0.015 -0.033 -0.027 -0.051   || dis=0.00 || select=0/8
002/019-th : 0.122 0.128 0.131 0.129 0.128 0.127 0.120 0.115  ||  -0.020 0.022 0.045 0.034 0.026 0.018 -0.043 -0.083    || dis=0.00 || select=2/8
003/019-th : 0.126 0.127 0.125 0.130 0.125 0.122 0.121 0.124  ||  0.005 0.017 -0.003 0.039 -0.004 -0.023 -0.029 -0.007  || dis=0.00 || select=3/8
004/019-th : 0.117 0.116 0.123 0.120 0.132 0.133 0.130 0.130  ||  -0.066 -0.074 -0.017 -0.041 0.053 0.060 0.039 0.037   || dis=0.00 || select=5/8
005/019-th : 0.118 0.119 0.124 0.123 0.126 0.127 0.131 0.131  ||  -0.057 -0.053 -0.005 -0.013 0.011 0.014 0.048 0.048   || dis=0.00 || select=7/8
006/019-th : 0.118 0.114 0.117 0.121 0.131 0.128 0.136 0.136  ||  -0.058 -0.094 -0.062 -0.032 0.048 0.027 0.085 0.086   || dis=0.00 || select=7/8
007/019-th : 0.078 0.082 0.099 0.114 0.138 0.142 0.160 0.186  ||  -0.429 -0.379 -0.191 -0.051 0.138 0.171 0.289 0.440   || dis=0.03 || select=7/8
008/019-th : 0.057 0.069 0.091 0.125 0.147 0.165 0.168 0.178  ||  -0.704 -0.513 -0.241 0.075 0.238 0.356 0.372 0.431    || dis=0.01 || select=7/8
009/019-th : 0.102 0.099 0.106 0.115 0.128 0.138 0.146 0.165  ||  -0.187 -0.217 -0.148 -0.068 0.035 0.114 0.170 0.292   || dis=0.02 || select=7/8
010/019-th : 0.103 0.109 0.114 0.123 0.137 0.138 0.140 0.136  ||  -0.192 -0.133 -0.086 -0.008 0.101 0.103 0.123 0.089   || dis=0.00 || select=6/8
011/019-th : 0.107 0.098 0.102 0.115 0.124 0.135 0.151 0.167  ||  -0.142 -0.227 -0.190 -0.073 0.009 0.093 0.204 0.301   || dis=0.02 || select=7/8
012/019-th : 0.111 0.112 0.117 0.122 0.134 0.131 0.135 0.138  ||  -0.112 -0.103 -0.058 -0.015 0.077 0.053 0.088 0.106   || dis=0.00 || select=7/8
013/019-th : 0.046 0.050 0.064 0.082 0.108 0.138 0.202 0.310  ||  -0.801 -0.732 -0.471 -0.232 0.047 0.288 0.671 1.100   || dis=0.11 || select=7/8
014/019-th : 0.057 0.063 0.074 0.101 0.134 0.161 0.199 0.212  ||  -0.683 -0.572 -0.417 -0.107 0.174 0.359 0.571 0.633   || dis=0.01 || select=7/8
015/019-th : 0.039 0.045 0.059 0.087 0.106 0.155 0.218 0.291  ||  -0.938 -0.798 -0.525 -0.136 0.057 0.439 0.779 1.070   || dis=0.07 || select=7/8
016/019-th : 0.058 0.077 0.098 0.123 0.139 0.161 0.171 0.173  ||  -0.712 -0.422 -0.176 0.047 0.167 0.317 0.374 0.391    || dis=0.00 || select=7/8
017/019-th : 0.123 0.120 0.124 0.120 0.128 0.126 0.130 0.130  ||  -0.011 -0.043 -0.003 -0.042 0.022 0.010 0.038 0.039   || dis=0.00 || select=7/8
018/019-th : 0.089 0.099 0.108 0.125 0.130 0.136 0.150 0.161  ||  -0.314 -0.208 -0.121 0.023 0.062 0.108 0.204 0.277    || dis=0.01 || select=7/8
[epoch=165/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:09:36] [epoch=165/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.890 (1.890)  Prec@1 42.58 (42.58) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:09:42] [epoch=165/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.458 (2.185)  Prec@1 49.40 (39.70) Prec@5 87.50 (84.09) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.70 Prec@5 84.09 Error@1 60.30 Error@5 15.91 Loss:2.185
***[2020-01-29 07:09:42]*** VALID [epoch=165/600] loss = 2.185455, accuracy@1 = 39.70, accuracy@5 = 84.09 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:09:42]*** start epoch=166/600 Time Left: [03:51:48], LR=[0.082273 ~ 0.082273], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=166, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.131371334923679, FLOP=40.81
[Search] : epoch=166/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:09:43] [epoch=166/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.917 (0.917)  Prec@1 66.41 (66.41) Prec@5 97.27 (97.27) Acls-loss 0.749 (0.749) FLOP-Loss 0.000 (0.000) Arch-Loss 0.749 (0.749)
**TRAIN** [2020-01-29 07:10:08] [epoch=166/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.924 (0.842)  Prec@1 69.05 (70.99) Prec@5 97.02 (97.68) Acls-loss 0.799 (0.846) FLOP-Loss -2.619 (0.198) Arch-Loss -4.439 (1.242)
 **TRAIN** Prec@1 70.99 Prec@5 97.68 Error@1 29.01 Error@5 2.32 Base-Loss:0.842, Arch-Loss=1.242
***[2020-01-29 07:10:08]*** TRAIN [epoch=166/600] base-loss = 0.842453, arch-loss = 1.241736, accuracy-1 = 70.99, accuracy-5 = 97.68
[epoch=166/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 11, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.446 0.212 0.342  ||  0.2148 -0.5294 -0.0508  || discrepancy=0.10 || select=0/3
001/003-th : 0.391 0.156 0.453  ||  0.0692 -0.8506 0.2146  || discrepancy=0.06 || select=2/3
002/003-th : 0.112 0.225 0.663  ||  -0.8997 -0.2034 0.8755  || discrepancy=0.44 || select=2/3
-----------------------------------------------
000/019-th : 0.062 0.082 0.105 0.122 0.141 0.145 0.163 0.179  ||  -0.652 -0.363 -0.118 0.032 0.172 0.203 0.320 0.412    || dis=0.02 || select=7/8
001/019-th : 0.134 0.127 0.130 0.134 0.125 0.117 0.118 0.115  ||  0.076 0.022 0.040 0.077 0.002 -0.058 -0.055 -0.079    || dis=0.00 || select=3/8
002/019-th : 0.126 0.131 0.134 0.131 0.126 0.124 0.116 0.112  ||  0.008 0.048 0.073 0.047 0.010 -0.006 -0.069 -0.112    || dis=0.00 || select=2/8
003/019-th : 0.129 0.130 0.127 0.132 0.123 0.119 0.119 0.121  ||  0.032 0.042 0.014 0.053 -0.015 -0.049 -0.053 -0.033   || dis=0.00 || select=3/8
004/019-th : 0.120 0.119 0.124 0.123 0.131 0.128 0.127 0.127  ||  -0.041 -0.048 -0.006 -0.019 0.049 0.026 0.018 0.015   || dis=0.00 || select=4/8
005/019-th : 0.121 0.121 0.125 0.126 0.125 0.125 0.128 0.128  ||  -0.034 -0.031 0.003 0.007 -0.003 -0.000 0.027 0.026   || dis=0.00 || select=6/8
006/019-th : 0.121 0.117 0.119 0.124 0.128 0.126 0.132 0.133  ||  -0.032 -0.068 -0.047 -0.008 0.022 0.013 0.058 0.063   || dis=0.00 || select=7/8
007/019-th : 0.079 0.085 0.100 0.113 0.141 0.142 0.158 0.182  ||  -0.417 -0.351 -0.182 -0.062 0.161 0.164 0.275 0.416   || dis=0.02 || select=7/8
008/019-th : 0.058 0.071 0.092 0.126 0.149 0.165 0.166 0.174  ||  -0.694 -0.497 -0.233 0.085 0.248 0.350 0.362 0.406    || dis=0.01 || select=7/8
009/019-th : 0.105 0.102 0.108 0.116 0.127 0.137 0.143 0.162  ||  -0.163 -0.188 -0.139 -0.060 0.024 0.102 0.145 0.272   || dis=0.02 || select=7/8
010/019-th : 0.106 0.111 0.116 0.125 0.134 0.137 0.137 0.133  ||  -0.162 -0.112 -0.066 0.008 0.076 0.096 0.097 0.064    || dis=0.00 || select=6/8
011/019-th : 0.107 0.100 0.103 0.117 0.126 0.136 0.150 0.161  ||  -0.139 -0.211 -0.182 -0.049 0.025 0.095 0.194 0.269   || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.119 0.123 0.135 0.128 0.133 0.135  ||  -0.092 -0.084 -0.040 -0.007 0.082 0.033 0.069 0.085   || dis=0.00 || select=7/8
013/019-th : 0.048 0.051 0.066 0.082 0.108 0.138 0.204 0.304  ||  -0.781 -0.712 -0.451 -0.234 0.041 0.283 0.674 1.074   || dis=0.10 || select=7/8
014/019-th : 0.058 0.065 0.075 0.103 0.136 0.159 0.195 0.208  ||  -0.664 -0.554 -0.411 -0.093 0.188 0.345 0.549 0.614   || dis=0.01 || select=7/8
015/019-th : 0.039 0.046 0.060 0.088 0.106 0.155 0.220 0.287  ||  -0.942 -0.784 -0.507 -0.136 0.057 0.435 0.784 1.050   || dis=0.07 || select=7/8
016/019-th : 0.059 0.079 0.101 0.124 0.141 0.158 0.167 0.171  ||  -0.697 -0.402 -0.149 0.052 0.177 0.292 0.351 0.375    || dis=0.00 || select=7/8
017/019-th : 0.126 0.123 0.127 0.121 0.126 0.124 0.127 0.127  ||  0.012 -0.018 0.013 -0.032 0.008 -0.011 0.015 0.017    || dis=0.00 || select=7/8
018/019-th : 0.090 0.100 0.109 0.126 0.130 0.138 0.148 0.159  ||  -0.304 -0.199 -0.111 0.028 0.057 0.117 0.190 0.261    || dis=0.01 || select=7/8
[epoch=166/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.040
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:10:09] [epoch=166/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.165 (2.165)  Prec@1 33.98 (33.98) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:10:15] [epoch=166/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.733 (2.444)  Prec@1 51.19 (37.02) Prec@5 95.24 (82.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.02 Prec@5 82.58 Error@1 62.98 Error@5 17.42 Loss:2.444
***[2020-01-29 07:10:15]*** VALID [epoch=166/600] loss = 2.443851, accuracy@1 = 37.02, accuracy@5 = 82.58 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:10:15]*** start epoch=167/600 Time Left: [03:51:17], LR=[0.082072 ~ 0.082072], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=167, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.121551597344437, FLOP=40.81
[Search] : epoch=167/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:10:15] [epoch=167/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.819 (0.819)  Prec@1 72.66 (72.66) Prec@5 98.44 (98.44) Acls-loss 0.932 (0.932) FLOP-Loss 2.621 (2.621) Arch-Loss 6.174 (6.174)
**TRAIN** [2020-01-29 07:10:39] [epoch=167/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.930 (0.831)  Prec@1 69.05 (71.77) Prec@5 97.62 (97.72) Acls-loss 0.791 (0.857) FLOP-Loss 0.000 (0.000) Arch-Loss 0.791 (0.857)
 **TRAIN** Prec@1 71.77 Prec@5 97.72 Error@1 28.23 Error@5 2.28 Base-Loss:0.831, Arch-Loss=0.857
***[2020-01-29 07:10:39]*** TRAIN [epoch=167/600] base-loss = 0.831188, arch-loss = 0.856636, accuracy-1 = 71.77, accuracy-5 = 97.72
[epoch=167/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 11, 14, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.050624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.211 0.345  ||  0.2089 -0.5344 -0.0429  || discrepancy=0.10 || select=0/3
001/003-th : 0.387 0.157 0.456  ||  0.0610 -0.8424 0.2237  || discrepancy=0.07 || select=2/3
002/003-th : 0.109 0.221 0.670  ||  -0.9189 -0.2146 0.8935  || discrepancy=0.45 || select=2/3
-----------------------------------------------
000/019-th : 0.059 0.083 0.104 0.121 0.142 0.146 0.164 0.182  ||  -0.701 -0.353 -0.126 0.029 0.183 0.212 0.327 0.433    || dis=0.02 || select=7/8
001/019-th : 0.133 0.127 0.129 0.133 0.124 0.119 0.119 0.116  ||  0.068 0.018 0.031 0.067 -0.002 -0.048 -0.048 -0.070   || dis=0.00 || select=0/8
002/019-th : 0.125 0.129 0.134 0.129 0.127 0.126 0.117 0.113  ||  0.001 0.037 0.069 0.036 0.018 0.012 -0.067 -0.103     || dis=0.01 || select=2/8
003/019-th : 0.127 0.129 0.127 0.130 0.124 0.120 0.119 0.123  ||  0.018 0.035 0.019 0.036 -0.007 -0.043 -0.045 -0.020   || dis=0.00 || select=3/8
004/019-th : 0.119 0.119 0.123 0.121 0.131 0.129 0.129 0.128  ||  -0.049 -0.052 -0.020 -0.030 0.049 0.031 0.032 0.023   || dis=0.00 || select=4/8
005/019-th : 0.120 0.120 0.123 0.127 0.126 0.126 0.129 0.129  ||  -0.040 -0.040 -0.018 0.013 0.010 0.012 0.033 0.033    || dis=0.00 || select=6/8
006/019-th : 0.120 0.116 0.119 0.121 0.127 0.129 0.134 0.134  ||  -0.038 -0.079 -0.052 -0.029 0.015 0.029 0.071 0.072   || dis=0.00 || select=7/8
007/019-th : 0.079 0.083 0.100 0.112 0.139 0.144 0.159 0.184  ||  -0.418 -0.364 -0.188 -0.068 0.143 0.185 0.278 0.427   || dis=0.02 || select=7/8
008/019-th : 0.057 0.070 0.091 0.126 0.149 0.163 0.168 0.176  ||  -0.702 -0.499 -0.242 0.084 0.249 0.342 0.369 0.417    || dis=0.01 || select=7/8
009/019-th : 0.103 0.101 0.108 0.116 0.127 0.138 0.143 0.164  ||  -0.179 -0.197 -0.137 -0.064 0.025 0.112 0.149 0.285   || dis=0.02 || select=7/8
010/019-th : 0.105 0.112 0.115 0.125 0.133 0.138 0.137 0.135  ||  -0.173 -0.111 -0.076 0.003 0.065 0.102 0.096 0.081    || dis=0.00 || select=5/8
011/019-th : 0.107 0.098 0.102 0.117 0.126 0.137 0.151 0.161  ||  -0.141 -0.228 -0.184 -0.047 0.027 0.105 0.205 0.269   || dis=0.01 || select=7/8
012/019-th : 0.112 0.113 0.119 0.123 0.134 0.129 0.133 0.137  ||  -0.100 -0.090 -0.046 -0.010 0.076 0.035 0.072 0.097   || dis=0.00 || select=7/8
013/019-th : 0.047 0.051 0.066 0.081 0.107 0.138 0.206 0.304  ||  -0.788 -0.717 -0.449 -0.242 0.036 0.289 0.688 1.076   || dis=0.10 || select=7/8
014/019-th : 0.057 0.064 0.074 0.102 0.136 0.159 0.197 0.210  ||  -0.676 -0.558 -0.414 -0.096 0.188 0.341 0.557 0.624   || dis=0.01 || select=7/8
015/019-th : 0.039 0.045 0.060 0.086 0.107 0.154 0.219 0.289  ||  -0.933 -0.798 -0.507 -0.150 0.063 0.430 0.785 1.061   || dis=0.07 || select=7/8
016/019-th : 0.058 0.078 0.100 0.123 0.142 0.157 0.169 0.173  ||  -0.712 -0.407 -0.161 0.047 0.188 0.291 0.361 0.385    || dis=0.00 || select=7/8
017/019-th : 0.125 0.122 0.126 0.119 0.126 0.125 0.128 0.128  ||  0.001 -0.024 0.008 -0.046 0.009 0.002 0.022 0.028     || dis=0.00 || select=7/8
018/019-th : 0.090 0.099 0.108 0.126 0.129 0.137 0.149 0.161  ||  -0.313 -0.211 -0.122 0.030 0.053 0.116 0.198 0.275    || dis=0.01 || select=7/8
[epoch=167/600] FLOP : 27.05 MB, ratio : 0.6628, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:10:40] [epoch=167/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.606 (2.606)  Prec@1 33.59 (33.59) Prec@5 79.30 (79.30) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:10:46] [epoch=167/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.736 (2.211)  Prec@1 55.95 (37.17) Prec@5 88.10 (83.35) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.17 Prec@5 83.35 Error@1 62.83 Error@5 16.65 Loss:2.211
***[2020-01-29 07:10:46]*** VALID [epoch=167/600] loss = 2.210915, accuracy@1 = 37.17, accuracy@5 = 83.35 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:10:46]*** start epoch=168/600 Time Left: [03:50:42], LR=[0.081871 ~ 0.081871], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=168, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.11168877488429, FLOP=40.81
[Search] : epoch=168/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:10:46] [epoch=168/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.762 (0.762)  Prec@1 75.00 (75.00) Prec@5 97.66 (97.66) Acls-loss 0.912 (0.912) FLOP-Loss 0.000 (0.000) Arch-Loss 0.912 (0.912)
**TRAIN** [2020-01-29 07:11:10] [epoch=168/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.958 (0.832)  Prec@1 61.90 (71.67) Prec@5 97.62 (97.79) Acls-loss 0.952 (0.889) FLOP-Loss 0.000 (0.000) Arch-Loss 0.952 (0.889)
 **TRAIN** Prec@1 71.67 Prec@5 97.79 Error@1 28.33 Error@5 2.21 Base-Loss:0.832, Arch-Loss=0.889
***[2020-01-29 07:11:10]*** TRAIN [epoch=168/600] base-loss = 0.831605, arch-loss = 0.888968, accuracy-1 = 71.67, accuracy-5 = 97.79
[epoch=168/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 11, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.640448)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.216 0.344  ||  0.2057 -0.5082 -0.0404  || discrepancy=0.10 || select=0/3
001/003-th : 0.385 0.157 0.458  ||  0.0562 -0.8387 0.2298  || discrepancy=0.07 || select=2/3
002/003-th : 0.107 0.219 0.674  ||  -0.9317 -0.2207 0.9053  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.082 0.104 0.121 0.141 0.148 0.164 0.183  ||  -0.725 -0.359 -0.124 0.030 0.183 0.231 0.330 0.442    || dis=0.02 || select=7/8
001/019-th : 0.132 0.126 0.128 0.133 0.125 0.120 0.119 0.117  ||  0.061 0.013 0.024 0.068 0.006 -0.036 -0.044 -0.066    || dis=0.00 || select=3/8
002/019-th : 0.124 0.129 0.133 0.129 0.128 0.126 0.118 0.113  ||  -0.004 0.033 0.061 0.030 0.023 0.009 -0.060 -0.096    || dis=0.00 || select=2/8
003/019-th : 0.125 0.129 0.127 0.129 0.126 0.120 0.120 0.123  ||  0.003 0.033 0.021 0.036 0.007 -0.035 -0.039 -0.015    || dis=0.00 || select=3/8
004/019-th : 0.118 0.119 0.122 0.119 0.132 0.131 0.131 0.129  ||  -0.056 -0.055 -0.030 -0.053 0.049 0.048 0.044 0.029   || dis=0.00 || select=4/8
005/019-th : 0.119 0.120 0.122 0.127 0.126 0.128 0.128 0.130  ||  -0.050 -0.041 -0.021 0.015 0.009 0.025 0.027 0.041    || dis=0.00 || select=7/8
006/019-th : 0.120 0.115 0.117 0.120 0.128 0.129 0.135 0.136  ||  -0.042 -0.084 -0.063 -0.042 0.025 0.033 0.073 0.082   || dis=0.00 || select=7/8
007/019-th : 0.079 0.081 0.098 0.108 0.141 0.147 0.160 0.185  ||  -0.419 -0.387 -0.199 -0.099 0.162 0.207 0.291 0.437   || dis=0.02 || select=7/8
008/019-th : 0.057 0.070 0.091 0.127 0.145 0.162 0.172 0.176  ||  -0.711 -0.508 -0.241 0.093 0.228 0.335 0.395 0.421    || dis=0.00 || select=7/8
009/019-th : 0.103 0.101 0.107 0.115 0.127 0.138 0.144 0.165  ||  -0.182 -0.200 -0.141 -0.071 0.026 0.111 0.152 0.292   || dis=0.02 || select=7/8
010/019-th : 0.104 0.111 0.115 0.126 0.132 0.139 0.138 0.135  ||  -0.179 -0.117 -0.083 0.010 0.062 0.109 0.104 0.084    || dis=0.00 || select=5/8
011/019-th : 0.106 0.096 0.103 0.116 0.126 0.139 0.153 0.162  ||  -0.151 -0.242 -0.179 -0.058 0.027 0.120 0.216 0.273   || dis=0.01 || select=7/8
012/019-th : 0.112 0.114 0.117 0.124 0.131 0.129 0.134 0.138  ||  -0.104 -0.085 -0.061 0.001 0.054 0.035 0.078 0.102    || dis=0.00 || select=7/8
013/019-th : 0.046 0.050 0.066 0.081 0.107 0.139 0.205 0.304  ||  -0.800 -0.735 -0.442 -0.237 0.038 0.299 0.687 1.080   || dis=0.10 || select=7/8
014/019-th : 0.056 0.064 0.074 0.101 0.133 0.161 0.198 0.213  ||  -0.690 -0.562 -0.415 -0.106 0.165 0.356 0.568 0.638   || dis=0.01 || select=7/8
015/019-th : 0.039 0.045 0.059 0.085 0.108 0.155 0.217 0.292  ||  -0.934 -0.805 -0.519 -0.156 0.075 0.438 0.777 1.073   || dis=0.07 || select=7/8
016/019-th : 0.058 0.078 0.099 0.123 0.143 0.158 0.168 0.173  ||  -0.714 -0.409 -0.166 0.044 0.198 0.297 0.356 0.389    || dis=0.00 || select=7/8
017/019-th : 0.124 0.121 0.123 0.120 0.125 0.127 0.130 0.129  ||  -0.005 -0.030 -0.017 -0.046 -0.001 0.019 0.037 0.034  || dis=0.00 || select=6/8
018/019-th : 0.089 0.099 0.110 0.126 0.125 0.139 0.151 0.160  ||  -0.315 -0.211 -0.109 0.030 0.022 0.129 0.207 0.269    || dis=0.01 || select=7/8
[epoch=168/600] FLOP : 27.64 MB, ratio : 0.6772, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:11:11] [epoch=168/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.750 (1.750)  Prec@1 48.44 (48.44) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:11:17] [epoch=168/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.669 (2.056)  Prec@1 49.40 (40.84) Prec@5 85.71 (85.37) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.84 Prec@5 85.37 Error@1 59.16 Error@5 14.63 Loss:2.056
***[2020-01-29 07:11:17]*** VALID [epoch=168/600] loss = 2.055527, accuracy@1 = 40.84, accuracy@5 = 85.37 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:11:17]*** start epoch=169/600 Time Left: [03:50:07], LR=[0.081669 ~ 0.081669], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=169, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.101783137937497, FLOP=40.81
[Search] : epoch=169/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:11:18] [epoch=169/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.918 (0.918)  Prec@1 67.19 (67.19) Prec@5 95.70 (95.70) Acls-loss 0.896 (0.896) FLOP-Loss 0.000 (0.000) Arch-Loss 0.896 (0.896)
**TRAIN** [2020-01-29 07:11:41] [epoch=169/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.920 (0.818)  Prec@1 67.26 (72.18) Prec@5 97.02 (97.95) Acls-loss 0.668 (0.854) FLOP-Loss 0.000 (0.027) Arch-Loss 0.668 (0.908)
 **TRAIN** Prec@1 72.18 Prec@5 97.95 Error@1 27.82 Error@5 2.05 Base-Loss:0.818, Arch-Loss=0.908
***[2020-01-29 07:11:41]*** TRAIN [epoch=169/600] base-loss = 0.818137, arch-loss = 0.908390, accuracy-1 = 72.18, accuracy-5 = 97.95
[epoch=169/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.131968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.439 0.218 0.343  ||  0.2066 -0.4928 -0.0413  || discrepancy=0.10 || select=0/3
001/003-th : 0.384 0.158 0.457  ||  0.0569 -0.8312 0.2304  || discrepancy=0.07 || select=2/3
002/003-th : 0.105 0.216 0.679  ||  -0.9487 -0.2255 0.9198  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.083 0.104 0.120 0.139 0.149 0.165 0.184  ||  -0.739 -0.350 -0.118 0.019 0.169 0.234 0.339 0.447    || dis=0.02 || select=7/8
001/019-th : 0.132 0.126 0.128 0.133 0.125 0.120 0.120 0.117  ||  0.060 0.008 0.025 0.062 0.000 -0.039 -0.036 -0.064    || dis=0.00 || select=3/8
002/019-th : 0.124 0.129 0.132 0.130 0.128 0.125 0.118 0.114  ||  -0.006 0.032 0.051 0.036 0.024 0.003 -0.057 -0.091    || dis=0.00 || select=2/8
003/019-th : 0.125 0.128 0.127 0.129 0.126 0.122 0.120 0.123  ||  0.005 0.025 0.014 0.031 0.010 -0.025 -0.036 -0.014    || dis=0.00 || select=3/8
004/019-th : 0.118 0.119 0.122 0.118 0.131 0.131 0.132 0.130  ||  -0.059 -0.055 -0.030 -0.063 0.046 0.045 0.049 0.035   || dis=0.00 || select=6/8
005/019-th : 0.119 0.120 0.123 0.125 0.125 0.129 0.129 0.130  ||  -0.050 -0.042 -0.013 -0.000 0.002 0.030 0.029 0.043   || dis=0.00 || select=7/8
006/019-th : 0.120 0.115 0.116 0.121 0.130 0.128 0.135 0.136  ||  -0.042 -0.086 -0.072 -0.030 0.037 0.021 0.075 0.083   || dis=0.00 || select=7/8
007/019-th : 0.079 0.080 0.098 0.108 0.139 0.148 0.162 0.186  ||  -0.414 -0.400 -0.195 -0.105 0.152 0.213 0.300 0.439   || dis=0.02 || select=7/8
008/019-th : 0.056 0.070 0.091 0.125 0.147 0.161 0.173 0.176  ||  -0.722 -0.499 -0.242 0.078 0.242 0.333 0.405 0.418    || dis=0.00 || select=7/8
009/019-th : 0.102 0.100 0.108 0.114 0.128 0.138 0.144 0.166  ||  -0.188 -0.205 -0.132 -0.081 0.036 0.109 0.155 0.295   || dis=0.02 || select=7/8
010/019-th : 0.105 0.112 0.113 0.125 0.133 0.138 0.139 0.136  ||  -0.176 -0.108 -0.098 -0.001 0.067 0.105 0.108 0.086   || dis=0.00 || select=6/8
011/019-th : 0.106 0.096 0.104 0.117 0.126 0.138 0.152 0.162  ||  -0.150 -0.250 -0.163 -0.053 0.023 0.114 0.211 0.274   || dis=0.01 || select=7/8
012/019-th : 0.112 0.114 0.117 0.125 0.130 0.129 0.135 0.137  ||  -0.104 -0.090 -0.057 0.007 0.045 0.036 0.086 0.098    || dis=0.00 || select=7/8
013/019-th : 0.046 0.049 0.066 0.082 0.107 0.139 0.205 0.307  ||  -0.800 -0.745 -0.450 -0.229 0.035 0.297 0.687 1.090   || dis=0.10 || select=7/8
014/019-th : 0.056 0.064 0.074 0.102 0.132 0.161 0.199 0.213  ||  -0.692 -0.570 -0.421 -0.092 0.162 0.358 0.571 0.639   || dis=0.01 || select=7/8
015/019-th : 0.038 0.045 0.060 0.085 0.108 0.153 0.216 0.295  ||  -0.956 -0.800 -0.514 -0.157 0.084 0.429 0.772 1.083   || dis=0.08 || select=7/8
016/019-th : 0.057 0.079 0.098 0.121 0.143 0.159 0.169 0.173  ||  -0.718 -0.402 -0.178 0.032 0.199 0.303 0.366 0.390    || dis=0.00 || select=7/8
017/019-th : 0.124 0.120 0.123 0.118 0.128 0.128 0.130 0.129  ||  -0.008 -0.040 -0.016 -0.056 0.026 0.027 0.039 0.034   || dis=0.00 || select=6/8
018/019-th : 0.089 0.099 0.109 0.126 0.127 0.137 0.152 0.161  ||  -0.323 -0.210 -0.118 0.027 0.038 0.114 0.217 0.274    || dis=0.01 || select=7/8
[epoch=169/600] FLOP : 28.13 MB, ratio : 0.6893, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:11:42] [epoch=169/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.347 (2.347)  Prec@1 33.20 (33.20) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:11:48] [epoch=169/600][097/098] Time 0.14 (0.06) Data 0.00 (0.00) Loss 1.183 (2.188)  Prec@1 56.55 (35.21) Prec@5 91.67 (80.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.21 Prec@5 80.26 Error@1 64.79 Error@5 19.74 Loss:2.188
***[2020-01-29 07:11:48]*** VALID [epoch=169/600] loss = 2.188495, accuracy@1 = 35.21, accuracy@5 = 80.26 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:11:48]*** start epoch=170/600 Time Left: [03:49:33], LR=[0.081466 ~ 0.081466], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=170, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.091834958072102, FLOP=40.81
[Search] : epoch=170/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:11:48] [epoch=170/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.765 (0.765)  Prec@1 71.48 (71.48) Prec@5 99.22 (99.22) Acls-loss 0.992 (0.992) FLOP-Loss 0.000 (0.000) Arch-Loss 0.992 (0.992)
**TRAIN** [2020-01-29 07:12:12] [epoch=170/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 1.024 (0.834)  Prec@1 67.86 (71.60) Prec@5 94.05 (97.80) Acls-loss 0.765 (0.856) FLOP-Loss 0.000 (0.108) Arch-Loss 0.765 (1.072)
 **TRAIN** Prec@1 71.60 Prec@5 97.80 Error@1 28.40 Error@5 2.20 Base-Loss:0.834, Arch-Loss=1.072
***[2020-01-29 07:12:12]*** TRAIN [epoch=170/600] base-loss = 0.834286, arch-loss = 1.071735, accuracy-1 = 71.60, accuracy-5 = 97.80
[epoch=170/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 6, 12, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.215 0.340  ||  0.2171 -0.5071 -0.0496  || discrepancy=0.10 || select=0/3
001/003-th : 0.389 0.159 0.452  ||  0.0692 -0.8250 0.2196  || discrepancy=0.06 || select=2/3
002/003-th : 0.105 0.218 0.678  ||  -0.9488 -0.2176 0.9182  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.084 0.105 0.118 0.137 0.152 0.165 0.182  ||  -0.727 -0.339 -0.114 0.001 0.155 0.255 0.340 0.433    || dis=0.02 || select=7/8
001/019-th : 0.134 0.127 0.129 0.134 0.123 0.119 0.119 0.116  ||  0.073 0.019 0.032 0.070 -0.015 -0.047 -0.046 -0.075   || dis=0.00 || select=0/8
002/019-th : 0.125 0.130 0.133 0.130 0.129 0.124 0.117 0.113  ||  0.004 0.041 0.064 0.039 0.030 -0.006 -0.067 -0.103    || dis=0.00 || select=2/8
003/019-th : 0.127 0.129 0.128 0.128 0.124 0.121 0.120 0.123  ||  0.017 0.029 0.021 0.026 -0.010 -0.038 -0.041 -0.018   || dis=0.00 || select=1/8
004/019-th : 0.119 0.120 0.123 0.119 0.128 0.131 0.130 0.129  ||  -0.050 -0.044 -0.017 -0.054 0.022 0.046 0.037 0.028   || dis=0.00 || select=5/8
005/019-th : 0.120 0.121 0.123 0.125 0.125 0.128 0.129 0.128  ||  -0.038 -0.029 -0.013 -0.002 -0.004 0.025 0.027 0.026  || dis=0.00 || select=6/8
006/019-th : 0.121 0.115 0.119 0.122 0.130 0.127 0.132 0.134  ||  -0.034 -0.080 -0.051 -0.026 0.041 0.015 0.059 0.074   || dis=0.00 || select=7/8
007/019-th : 0.078 0.082 0.100 0.110 0.140 0.147 0.159 0.184  ||  -0.423 -0.379 -0.184 -0.084 0.153 0.205 0.282 0.429   || dis=0.02 || select=7/8
008/019-th : 0.056 0.071 0.091 0.127 0.147 0.162 0.170 0.175  ||  -0.722 -0.483 -0.243 0.090 0.240 0.339 0.384 0.413    || dis=0.00 || select=7/8
009/019-th : 0.103 0.100 0.109 0.116 0.128 0.138 0.143 0.163  ||  -0.177 -0.213 -0.122 -0.056 0.041 0.114 0.146 0.278   || dis=0.02 || select=7/8
010/019-th : 0.106 0.113 0.116 0.125 0.132 0.137 0.138 0.134  ||  -0.159 -0.103 -0.075 -0.000 0.054 0.091 0.102 0.072   || dis=0.00 || select=6/8
011/019-th : 0.108 0.096 0.104 0.119 0.126 0.137 0.150 0.160  ||  -0.132 -0.247 -0.165 -0.037 0.024 0.109 0.196 0.264   || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.119 0.125 0.131 0.128 0.134 0.135  ||  -0.095 -0.080 -0.041 0.002 0.051 0.028 0.075 0.086    || dis=0.00 || select=7/8
013/019-th : 0.046 0.049 0.067 0.082 0.108 0.138 0.204 0.305  ||  -0.808 -0.741 -0.426 -0.228 0.044 0.290 0.679 1.083   || dis=0.10 || select=7/8
014/019-th : 0.057 0.063 0.074 0.104 0.132 0.161 0.199 0.211  ||  -0.687 -0.577 -0.414 -0.079 0.165 0.359 0.570 0.629   || dis=0.01 || select=7/8
015/019-th : 0.039 0.045 0.060 0.085 0.109 0.153 0.215 0.293  ||  -0.937 -0.809 -0.504 -0.157 0.090 0.425 0.768 1.075   || dis=0.08 || select=7/8
016/019-th : 0.058 0.080 0.099 0.122 0.146 0.158 0.168 0.171  ||  -0.713 -0.388 -0.174 0.037 0.217 0.297 0.356 0.377    || dis=0.00 || select=7/8
017/019-th : 0.125 0.121 0.125 0.119 0.127 0.126 0.128 0.128  ||  0.002 -0.030 0.003 -0.050 0.017 0.005 0.026 0.028     || dis=0.00 || select=7/8
018/019-th : 0.089 0.102 0.109 0.125 0.126 0.138 0.151 0.160  ||  -0.316 -0.189 -0.115 0.017 0.028 0.119 0.205 0.268    || dis=0.01 || select=7/8
[epoch=170/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:12:13] [epoch=170/600][000/098] Time 0.34 (0.34) Data 0.27 (0.27) Loss 1.836 (1.836)  Prec@1 43.36 (43.36) Prec@5 90.62 (90.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:12:19] [epoch=170/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.240 (2.183)  Prec@1 20.24 (38.01) Prec@5 63.69 (83.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.01 Prec@5 83.06 Error@1 61.99 Error@5 16.94 Loss:2.183
***[2020-01-29 07:12:19]*** VALID [epoch=170/600] loss = 2.183332, accuracy@1 = 38.01, accuracy@5 = 83.06 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:12:19]*** start epoch=171/600 Time Left: [03:48:58], LR=[0.081262 ~ 0.081262], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=171, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.081844508022479, FLOP=40.81
[Search] : epoch=171/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:12:19] [epoch=171/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.942 (0.942)  Prec@1 69.53 (69.53) Prec@5 97.66 (97.66) Acls-loss 1.032 (1.032) FLOP-Loss 0.000 (0.000) Arch-Loss 1.032 (1.032)
**TRAIN** [2020-01-29 07:12:44] [epoch=171/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.724 (0.813)  Prec@1 73.81 (72.13) Prec@5 99.40 (97.72) Acls-loss 0.727 (0.860) FLOP-Loss -2.622 (0.117) Arch-Loss -4.517 (1.094)
 **TRAIN** Prec@1 72.13 Prec@5 97.72 Error@1 27.87 Error@5 2.28 Base-Loss:0.813, Arch-Loss=1.094
***[2020-01-29 07:12:44]*** TRAIN [epoch=171/600] base-loss = 0.813273, arch-loss = 1.093917, accuracy-1 = 72.13, accuracy-5 = 97.72
[epoch=171/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 6, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.215 0.336  ||  0.2309 -0.5092 -0.0624  || discrepancy=0.11 || select=0/3
001/003-th : 0.394 0.159 0.447  ||  0.0818 -0.8260 0.2090  || discrepancy=0.05 || select=2/3
002/003-th : 0.104 0.219 0.677  ||  -0.9561 -0.2068 0.9206  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.084 0.107 0.120 0.138 0.151 0.164 0.179  ||  -0.719 -0.341 -0.095 0.020 0.155 0.247 0.333 0.417    || dis=0.01 || select=7/8
001/019-th : 0.135 0.128 0.130 0.136 0.121 0.118 0.117 0.114  ||  0.081 0.030 0.041 0.090 -0.024 -0.049 -0.058 -0.089   || dis=0.00 || select=3/8
002/019-th : 0.126 0.132 0.134 0.131 0.127 0.124 0.116 0.111  ||  0.011 0.054 0.069 0.053 0.018 -0.009 -0.076 -0.115    || dis=0.00 || select=2/8
003/019-th : 0.128 0.130 0.128 0.129 0.123 0.120 0.119 0.122  ||  0.025 0.038 0.025 0.033 -0.018 -0.042 -0.046 -0.028   || dis=0.00 || select=1/8
004/019-th : 0.121 0.121 0.124 0.120 0.127 0.130 0.130 0.127  ||  -0.036 -0.034 -0.014 -0.047 0.013 0.038 0.034 0.014   || dis=0.00 || select=5/8
005/019-th : 0.121 0.122 0.124 0.125 0.124 0.128 0.128 0.128  ||  -0.032 -0.025 -0.010 -0.001 -0.005 0.021 0.019 0.025  || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.118 0.123 0.129 0.126 0.132 0.133  ||  -0.026 -0.073 -0.053 -0.014 0.034 0.008 0.058 0.065   || dis=0.00 || select=7/8
007/019-th : 0.078 0.084 0.099 0.112 0.142 0.145 0.158 0.181  ||  -0.430 -0.358 -0.190 -0.067 0.173 0.193 0.280 0.413   || dis=0.02 || select=7/8
008/019-th : 0.056 0.072 0.092 0.127 0.148 0.164 0.168 0.173  ||  -0.719 -0.478 -0.235 0.094 0.246 0.350 0.370 0.399    || dis=0.00 || select=7/8
009/019-th : 0.104 0.100 0.109 0.117 0.128 0.139 0.141 0.161  ||  -0.169 -0.210 -0.125 -0.050 0.037 0.124 0.136 0.270   || dis=0.02 || select=7/8
010/019-th : 0.107 0.115 0.116 0.127 0.131 0.134 0.137 0.134  ||  -0.158 -0.085 -0.072 0.015 0.044 0.071 0.091 0.074    || dis=0.00 || select=6/8
011/019-th : 0.108 0.097 0.106 0.119 0.125 0.137 0.147 0.159  ||  -0.129 -0.235 -0.147 -0.037 0.013 0.109 0.179 0.257   || dis=0.01 || select=7/8
012/019-th : 0.114 0.116 0.121 0.126 0.129 0.126 0.134 0.134  ||  -0.087 -0.070 -0.024 0.015 0.033 0.009 0.072 0.076    || dis=0.00 || select=7/8
013/019-th : 0.047 0.050 0.068 0.082 0.109 0.138 0.202 0.305  ||  -0.791 -0.736 -0.424 -0.234 0.050 0.284 0.668 1.081   || dis=0.10 || select=7/8
014/019-th : 0.056 0.063 0.075 0.105 0.131 0.161 0.198 0.210  ||  -0.689 -0.572 -0.407 -0.067 0.156 0.359 0.566 0.623   || dis=0.01 || select=7/8
015/019-th : 0.039 0.044 0.060 0.084 0.111 0.152 0.216 0.293  ||  -0.935 -0.813 -0.503 -0.169 0.106 0.422 0.769 1.075   || dis=0.08 || select=7/8
016/019-th : 0.058 0.080 0.099 0.123 0.146 0.158 0.167 0.170  ||  -0.709 -0.386 -0.171 0.047 0.215 0.298 0.353 0.368    || dis=0.00 || select=7/8
017/019-th : 0.127 0.122 0.126 0.121 0.126 0.125 0.127 0.127  ||  0.014 -0.023 0.006 -0.034 0.013 0.003 0.013 0.015     || dis=0.00 || select=7/8
018/019-th : 0.090 0.103 0.110 0.125 0.128 0.137 0.147 0.160  ||  -0.313 -0.171 -0.113 0.022 0.040 0.106 0.181 0.267    || dis=0.01 || select=7/8
[epoch=171/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:12:44] [epoch=171/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.588 (1.588)  Prec@1 43.75 (43.75) Prec@5 88.67 (88.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:12:50] [epoch=171/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.904 (2.204)  Prec@1 21.43 (39.06) Prec@5 72.62 (83.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.06 Prec@5 83.52 Error@1 60.94 Error@5 16.48 Loss:2.204
***[2020-01-29 07:12:50]*** VALID [epoch=171/600] loss = 2.204201, accuracy@1 = 39.06, accuracy@5 = 83.52 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:12:51]*** start epoch=172/600 Time Left: [03:48:25], LR=[0.081057 ~ 0.081057], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=172, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.07181206168186, FLOP=40.81
[Search] : epoch=172/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:12:51] [epoch=172/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.807 (0.807)  Prec@1 71.88 (71.88) Prec@5 98.44 (98.44) Acls-loss 1.074 (1.074) FLOP-Loss 2.623 (2.623) Arch-Loss 6.320 (6.320)
**TRAIN** [2020-01-29 07:13:15] [epoch=172/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.736 (0.820)  Prec@1 76.19 (72.18) Prec@5 98.81 (97.74) Acls-loss 0.894 (0.856) FLOP-Loss 2.623 (0.072) Arch-Loss 6.141 (0.999)
 **TRAIN** Prec@1 72.18 Prec@5 97.74 Error@1 27.82 Error@5 2.26 Base-Loss:0.820, Arch-Loss=0.999
***[2020-01-29 07:13:15]*** TRAIN [epoch=172/600] base-loss = 0.819570, arch-loss = 0.999067, accuracy-1 = 72.18, accuracy-5 = 97.74
[epoch=172/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 19, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.330304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.451 0.216 0.333  ||  0.2352 -0.5000 -0.0668  || discrepancy=0.12 || select=0/3
001/003-th : 0.395 0.158 0.447  ||  0.0840 -0.8311 0.2084  || discrepancy=0.05 || select=2/3
002/003-th : 0.102 0.219 0.679  ||  -0.9680 -0.2039 0.9280  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.084 0.107 0.122 0.136 0.150 0.165 0.177  ||  -0.713 -0.337 -0.093 0.031 0.142 0.243 0.338 0.407    || dis=0.01 || select=7/8
001/019-th : 0.135 0.128 0.130 0.136 0.122 0.118 0.117 0.113  ||  0.084 0.032 0.046 0.091 -0.023 -0.056 -0.059 -0.092   || dis=0.00 || select=3/8
002/019-th : 0.126 0.132 0.133 0.132 0.126 0.124 0.116 0.111  ||  0.012 0.055 0.066 0.057 0.013 -0.008 -0.074 -0.118    || dis=0.00 || select=2/8
003/019-th : 0.129 0.130 0.128 0.131 0.123 0.119 0.119 0.121  ||  0.029 0.038 0.021 0.048 -0.020 -0.048 -0.048 -0.029   || dis=0.00 || select=3/8
004/019-th : 0.121 0.121 0.124 0.121 0.126 0.130 0.130 0.127  ||  -0.037 -0.037 -0.013 -0.038 0.006 0.037 0.037 0.016   || dis=0.00 || select=6/8
005/019-th : 0.119 0.122 0.127 0.126 0.123 0.127 0.127 0.128  ||  -0.051 -0.022 0.016 0.013 -0.011 0.019 0.020 0.027    || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.120 0.123 0.128 0.127 0.131 0.133  ||  -0.022 -0.076 -0.043 -0.014 0.021 0.015 0.050 0.064   || dis=0.00 || select=7/8
007/019-th : 0.078 0.083 0.100 0.111 0.141 0.145 0.159 0.181  ||  -0.426 -0.365 -0.177 -0.077 0.163 0.190 0.284 0.414   || dis=0.02 || select=7/8
008/019-th : 0.057 0.071 0.093 0.126 0.150 0.163 0.168 0.172  ||  -0.712 -0.491 -0.223 0.087 0.259 0.344 0.372 0.395    || dis=0.00 || select=7/8
009/019-th : 0.104 0.099 0.108 0.116 0.130 0.141 0.142 0.160  ||  -0.171 -0.218 -0.130 -0.055 0.052 0.137 0.144 0.265   || dis=0.02 || select=7/8
010/019-th : 0.106 0.115 0.117 0.126 0.131 0.134 0.138 0.133  ||  -0.162 -0.082 -0.068 0.012 0.049 0.069 0.099 0.068    || dis=0.00 || select=6/8
011/019-th : 0.109 0.098 0.106 0.118 0.125 0.136 0.148 0.160  ||  -0.128 -0.232 -0.151 -0.041 0.009 0.100 0.184 0.259   || dis=0.01 || select=7/8
012/019-th : 0.114 0.116 0.121 0.126 0.129 0.126 0.134 0.134  ||  -0.088 -0.070 -0.024 0.011 0.039 0.010 0.072 0.075    || dis=0.00 || select=7/8
013/019-th : 0.047 0.050 0.068 0.082 0.107 0.137 0.203 0.307  ||  -0.793 -0.732 -0.425 -0.231 0.037 0.279 0.672 1.087   || dis=0.10 || select=7/8
014/019-th : 0.056 0.063 0.075 0.106 0.132 0.162 0.197 0.209  ||  -0.688 -0.584 -0.409 -0.053 0.164 0.365 0.560 0.622   || dis=0.01 || select=7/8
015/019-th : 0.040 0.045 0.059 0.085 0.111 0.152 0.214 0.294  ||  -0.923 -0.807 -0.520 -0.165 0.109 0.419 0.763 1.077   || dis=0.08 || select=7/8
016/019-th : 0.058 0.080 0.100 0.124 0.144 0.157 0.167 0.170  ||  -0.709 -0.384 -0.165 0.057 0.204 0.287 0.354 0.366    || dis=0.00 || select=7/8
017/019-th : 0.127 0.122 0.124 0.122 0.127 0.125 0.126 0.127  ||  0.018 -0.023 -0.011 -0.023 0.015 0.000 0.011 0.018    || dis=0.00 || select=0/8
018/019-th : 0.090 0.103 0.108 0.125 0.131 0.138 0.146 0.160  ||  -0.308 -0.171 -0.124 0.015 0.065 0.115 0.171 0.264    || dis=0.01 || select=7/8
[epoch=172/600] FLOP : 25.33 MB, ratio : 0.6206, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:13:16] [epoch=172/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.820 (1.820)  Prec@1 46.48 (46.48) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:13:22] [epoch=172/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 3.361 (2.508)  Prec@1 22.62 (36.11) Prec@5 67.26 (81.75) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.11 Prec@5 81.75 Error@1 63.89 Error@5 18.25 Loss:2.508
***[2020-01-29 07:13:22]*** VALID [epoch=172/600] loss = 2.508280, accuracy@1 = 36.11, accuracy@5 = 81.75 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:13:22]*** start epoch=173/600 Time Left: [03:47:52], LR=[0.080852 ~ 0.080852], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=173, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.0617378940948345, FLOP=40.81
[Search] : epoch=173/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:13:23] [epoch=173/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.773 (0.773)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44) Acls-loss 0.874 (0.874) FLOP-Loss -2.623 (-2.623) Arch-Loss -4.372 (-4.372)
**TRAIN** [2020-01-29 07:13:47] [epoch=173/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.778 (0.826)  Prec@1 74.40 (72.07) Prec@5 97.62 (97.69) Acls-loss 0.861 (0.869) FLOP-Loss 0.000 (0.027) Arch-Loss 0.861 (0.923)
 **TRAIN** Prec@1 72.07 Prec@5 97.69 Error@1 27.93 Error@5 2.31 Base-Loss:0.826, Arch-Loss=0.923
***[2020-01-29 07:13:47]*** TRAIN [epoch=173/600] base-loss = 0.825574, arch-loss = 0.923076, accuracy-1 = 72.07, accuracy-5 = 97.69
[epoch=173/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 12, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.959936)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.218 0.332  ||  0.2349 -0.4872 -0.0665  || discrepancy=0.12 || select=0/3
001/003-th : 0.394 0.158 0.447  ||  0.0838 -0.8296 0.2095  || discrepancy=0.05 || select=2/3
002/003-th : 0.101 0.218 0.681  ||  -0.9757 -0.2033 0.9334  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.108 0.121 0.137 0.152 0.166 0.177  ||  -0.722 -0.350 -0.085 0.025 0.152 0.254 0.343 0.409    || dis=0.01 || select=7/8
001/019-th : 0.135 0.128 0.131 0.136 0.122 0.118 0.117 0.113  ||  0.082 0.029 0.051 0.090 -0.018 -0.054 -0.059 -0.093   || dis=0.00 || select=3/8
002/019-th : 0.126 0.131 0.133 0.133 0.126 0.123 0.116 0.111  ||  0.012 0.053 0.064 0.061 0.015 -0.009 -0.071 -0.119    || dis=0.00 || select=2/8
003/019-th : 0.128 0.129 0.127 0.131 0.124 0.120 0.120 0.122  ||  0.025 0.034 0.014 0.046 -0.011 -0.042 -0.041 -0.028   || dis=0.00 || select=3/8
004/019-th : 0.120 0.121 0.124 0.121 0.126 0.131 0.130 0.128  ||  -0.043 -0.037 -0.011 -0.037 0.002 0.044 0.040 0.018   || dis=0.00 || select=5/8
005/019-th : 0.119 0.123 0.126 0.127 0.122 0.128 0.127 0.129  ||  -0.051 -0.019 0.006 0.015 -0.021 0.022 0.017 0.031    || dis=0.00 || select=7/8
006/019-th : 0.122 0.115 0.121 0.124 0.126 0.127 0.131 0.133  ||  -0.021 -0.083 -0.031 -0.011 0.010 0.016 0.051 0.064   || dis=0.00 || select=7/8
007/019-th : 0.079 0.083 0.101 0.111 0.139 0.146 0.161 0.181  ||  -0.418 -0.366 -0.175 -0.082 0.142 0.192 0.290 0.412   || dis=0.02 || select=7/8
008/019-th : 0.057 0.071 0.092 0.126 0.149 0.164 0.168 0.173  ||  -0.712 -0.493 -0.226 0.087 0.248 0.346 0.372 0.400    || dis=0.00 || select=7/8
009/019-th : 0.104 0.099 0.107 0.116 0.129 0.143 0.142 0.161  ||  -0.172 -0.220 -0.139 -0.059 0.046 0.152 0.145 0.269   || dis=0.02 || select=7/8
010/019-th : 0.106 0.115 0.117 0.126 0.132 0.133 0.138 0.133  ||  -0.165 -0.081 -0.063 0.013 0.055 0.063 0.100 0.068    || dis=0.01 || select=6/8
011/019-th : 0.109 0.098 0.106 0.118 0.124 0.135 0.150 0.160  ||  -0.126 -0.234 -0.154 -0.048 0.002 0.091 0.196 0.261   || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.121 0.126 0.130 0.127 0.134 0.134  ||  -0.092 -0.074 -0.023 0.017 0.042 0.020 0.074 0.073    || dis=0.00 || select=6/8
013/019-th : 0.046 0.050 0.067 0.082 0.108 0.136 0.202 0.308  ||  -0.815 -0.727 -0.430 -0.228 0.046 0.277 0.673 1.092   || dis=0.11 || select=7/8
014/019-th : 0.056 0.063 0.074 0.107 0.132 0.160 0.198 0.210  ||  -0.694 -0.586 -0.411 -0.048 0.158 0.352 0.568 0.626   || dis=0.01 || select=7/8
015/019-th : 0.040 0.044 0.059 0.084 0.110 0.151 0.218 0.294  ||  -0.921 -0.810 -0.521 -0.173 0.097 0.411 0.783 1.081   || dis=0.08 || select=7/8
016/019-th : 0.058 0.080 0.099 0.126 0.144 0.155 0.167 0.170  ||  -0.706 -0.384 -0.171 0.065 0.203 0.278 0.352 0.369    || dis=0.00 || select=7/8
017/019-th : 0.127 0.122 0.124 0.123 0.125 0.125 0.126 0.128  ||  0.018 -0.024 -0.012 -0.019 0.004 0.003 0.011 0.021    || dis=0.00 || select=7/8
018/019-th : 0.091 0.103 0.109 0.122 0.129 0.139 0.146 0.161  ||  -0.305 -0.176 -0.118 -0.008 0.051 0.123 0.171 0.272   || dis=0.02 || select=7/8
[epoch=173/600] FLOP : 27.96 MB, ratio : 0.6851, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:13:47] [epoch=173/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.165 (3.165)  Prec@1 20.70 (20.70) Prec@5 70.70 (70.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:13:53] [epoch=173/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.297 (2.145)  Prec@1 23.81 (41.76) Prec@5 79.17 (85.39) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.76 Prec@5 85.39 Error@1 58.24 Error@5 14.61 Loss:2.145
***[2020-01-29 07:13:53]*** VALID [epoch=173/600] loss = 2.145360, accuracy@1 = 41.76, accuracy@5 = 85.39 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:13:53]*** start epoch=174/600 Time Left: [03:47:18], LR=[0.080645 ~ 0.080645], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=174, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.051622281449792, FLOP=40.81
[Search] : epoch=174/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:13:54] [epoch=174/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.865 (0.865)  Prec@1 70.31 (70.31) Prec@5 98.05 (98.05) Acls-loss 0.782 (0.782) FLOP-Loss 0.000 (0.000) Arch-Loss 0.782 (0.782)
**TRAIN** [2020-01-29 07:14:18] [epoch=174/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.976 (0.821)  Prec@1 67.86 (71.86) Prec@5 97.62 (97.72) Acls-loss 0.900 (0.840) FLOP-Loss 0.000 (0.027) Arch-Loss 0.900 (0.894)
 **TRAIN** Prec@1 71.86 Prec@5 97.72 Error@1 28.14 Error@5 2.28 Base-Loss:0.821, Arch-Loss=0.894
***[2020-01-29 07:14:18]*** TRAIN [epoch=174/600] base-loss = 0.820549, arch-loss = 0.894226, accuracy-1 = 71.86, accuracy-5 = 97.72
[epoch=174/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.219 0.332  ||  0.2350 -0.4827 -0.0662  || discrepancy=0.12 || select=0/3
001/003-th : 0.394 0.159 0.447  ||  0.0836 -0.8205 0.2103  || discrepancy=0.05 || select=2/3
002/003-th : 0.100 0.218 0.682  ||  -0.9841 -0.2021 0.9390  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.108 0.121 0.137 0.151 0.166 0.177  ||  -0.721 -0.351 -0.088 0.026 0.154 0.251 0.347 0.409    || dis=0.01 || select=7/8
001/019-th : 0.135 0.128 0.131 0.135 0.122 0.118 0.117 0.114  ||  0.082 0.029 0.053 0.081 -0.020 -0.055 -0.060 -0.089   || dis=0.00 || select=0/8
002/019-th : 0.126 0.132 0.133 0.130 0.126 0.124 0.117 0.111  ||  0.011 0.054 0.065 0.040 0.012 -0.010 -0.065 -0.118    || dis=0.00 || select=2/8
003/019-th : 0.128 0.129 0.126 0.131 0.124 0.120 0.120 0.122  ||  0.024 0.032 0.008 0.049 -0.012 -0.043 -0.042 -0.023   || dis=0.00 || select=3/8
004/019-th : 0.119 0.121 0.124 0.122 0.126 0.131 0.130 0.128  ||  -0.047 -0.038 -0.009 -0.026 0.003 0.044 0.039 0.019   || dis=0.00 || select=5/8
005/019-th : 0.117 0.122 0.126 0.125 0.126 0.129 0.127 0.129  ||  -0.066 -0.022 0.011 0.006 0.009 0.033 0.018 0.035     || dis=0.00 || select=7/8
006/019-th : 0.122 0.115 0.121 0.125 0.126 0.126 0.132 0.133  ||  -0.022 -0.082 -0.032 0.001 0.005 0.012 0.053 0.063    || dis=0.00 || select=7/8
007/019-th : 0.079 0.083 0.100 0.112 0.136 0.148 0.161 0.181  ||  -0.416 -0.368 -0.183 -0.073 0.124 0.206 0.292 0.412   || dis=0.02 || select=7/8
008/019-th : 0.057 0.070 0.091 0.127 0.148 0.167 0.167 0.173  ||  -0.713 -0.505 -0.234 0.093 0.249 0.370 0.369 0.402    || dis=0.01 || select=7/8
009/019-th : 0.102 0.099 0.107 0.116 0.129 0.143 0.143 0.161  ||  -0.186 -0.218 -0.139 -0.053 0.049 0.154 0.153 0.270   || dis=0.02 || select=7/8
010/019-th : 0.105 0.115 0.118 0.125 0.131 0.133 0.138 0.134  ||  -0.171 -0.084 -0.054 0.005 0.049 0.067 0.102 0.072    || dis=0.00 || select=6/8
011/019-th : 0.109 0.097 0.106 0.118 0.124 0.135 0.151 0.161  ||  -0.129 -0.240 -0.149 -0.049 0.005 0.093 0.198 0.263   || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.121 0.126 0.129 0.127 0.134 0.134  ||  -0.092 -0.075 -0.024 0.017 0.040 0.024 0.073 0.073    || dis=0.00 || select=7/8
013/019-th : 0.046 0.049 0.067 0.082 0.108 0.138 0.200 0.310  ||  -0.811 -0.736 -0.431 -0.233 0.047 0.288 0.661 1.099   || dis=0.11 || select=7/8
014/019-th : 0.056 0.062 0.075 0.107 0.132 0.160 0.198 0.211  ||  -0.696 -0.589 -0.407 -0.048 0.157 0.351 0.566 0.629   || dis=0.01 || select=7/8
015/019-th : 0.040 0.044 0.059 0.083 0.111 0.147 0.223 0.295  ||  -0.919 -0.819 -0.528 -0.182 0.108 0.388 0.805 1.086   || dis=0.07 || select=7/8
016/019-th : 0.058 0.080 0.100 0.125 0.144 0.155 0.168 0.170  ||  -0.711 -0.389 -0.166 0.062 0.203 0.277 0.357 0.371    || dis=0.00 || select=7/8
017/019-th : 0.127 0.121 0.123 0.124 0.126 0.125 0.126 0.127  ||  0.015 -0.030 -0.014 -0.003 0.013 0.006 0.011 0.021    || dis=0.00 || select=7/8
018/019-th : 0.091 0.103 0.108 0.122 0.131 0.138 0.146 0.161  ||  -0.304 -0.179 -0.124 -0.003 0.065 0.118 0.174 0.269   || dis=0.02 || select=7/8
[epoch=174/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:14:18] [epoch=174/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.770 (1.770)  Prec@1 37.11 (37.11) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:14:24] [epoch=174/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.848 (2.132)  Prec@1 35.71 (38.38) Prec@5 83.33 (82.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.38 Prec@5 82.62 Error@1 61.62 Error@5 17.38 Loss:2.132
***[2020-01-29 07:14:24]*** VALID [epoch=174/600] loss = 2.131785, accuracy@1 = 38.38, accuracy@5 = 82.62 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:14:24]*** start epoch=175/600 Time Left: [03:46:43], LR=[0.080438 ~ 0.080438], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=175, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.041465501071365, FLOP=40.81
[Search] : epoch=175/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:14:25] [epoch=175/600][000/098] Time 0.74 (0.74) Data 0.37 (0.37) Base-Loss 0.853 (0.853)  Prec@1 73.44 (73.44) Prec@5 96.88 (96.88) Acls-loss 0.782 (0.782) FLOP-Loss 0.000 (0.000) Arch-Loss 0.782 (0.782)
**TRAIN** [2020-01-29 07:14:49] [epoch=175/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.830 (0.823)  Prec@1 72.02 (72.18) Prec@5 97.02 (97.76) Acls-loss 0.806 (0.860) FLOP-Loss 0.000 (0.081) Arch-Loss 0.806 (1.021)
 **TRAIN** Prec@1 72.18 Prec@5 97.76 Error@1 27.82 Error@5 2.24 Base-Loss:0.823, Arch-Loss=1.021
***[2020-01-29 07:14:49]*** TRAIN [epoch=175/600] base-loss = 0.822776, arch-loss = 1.021404, accuracy-1 = 72.18, accuracy-5 = 97.76
[epoch=175/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 12, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.218 0.332  ||  0.2372 -0.4903 -0.0672  || discrepancy=0.12 || select=0/3
001/003-th : 0.394 0.160 0.445  ||  0.0867 -0.8129 0.2078  || discrepancy=0.05 || select=2/3
002/003-th : 0.100 0.219 0.682  ||  -0.9852 -0.1982 0.9388  || discrepancy=0.46 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.082 0.107 0.120 0.137 0.154 0.165 0.177  ||  -0.718 -0.354 -0.090 0.025 0.154 0.269 0.339 0.408    || dis=0.01 || select=7/8
001/019-th : 0.135 0.129 0.132 0.135 0.122 0.118 0.116 0.114  ||  0.083 0.034 0.057 0.082 -0.022 -0.057 -0.066 -0.092   || dis=0.00 || select=0/8
002/019-th : 0.127 0.133 0.134 0.130 0.127 0.123 0.117 0.110  ||  0.015 0.059 0.069 0.042 0.013 -0.017 -0.067 -0.123    || dis=0.00 || select=2/8
003/019-th : 0.129 0.130 0.127 0.130 0.123 0.120 0.120 0.122  ||  0.028 0.035 0.014 0.035 -0.017 -0.043 -0.046 -0.025   || dis=0.00 || select=3/8
004/019-th : 0.120 0.121 0.123 0.123 0.125 0.131 0.130 0.127  ||  -0.045 -0.037 -0.015 -0.021 0.001 0.042 0.042 0.017   || dis=0.00 || select=5/8
005/019-th : 0.117 0.122 0.127 0.126 0.125 0.128 0.126 0.129  ||  -0.061 -0.019 0.016 0.011 0.005 0.025 0.015 0.031     || dis=0.00 || select=7/8
006/019-th : 0.123 0.115 0.122 0.125 0.125 0.126 0.132 0.133  ||  -0.017 -0.080 -0.026 -0.004 -0.001 0.008 0.052 0.060  || dis=0.00 || select=7/8
007/019-th : 0.079 0.084 0.101 0.113 0.137 0.147 0.160 0.180  ||  -0.417 -0.363 -0.177 -0.062 0.131 0.200 0.285 0.407   || dis=0.02 || select=7/8
008/019-th : 0.056 0.069 0.091 0.126 0.150 0.169 0.167 0.173  ||  -0.720 -0.514 -0.238 0.090 0.264 0.380 0.371 0.404    || dis=0.00 || select=7/8
009/019-th : 0.102 0.099 0.108 0.115 0.129 0.144 0.142 0.160  ||  -0.184 -0.213 -0.130 -0.063 0.052 0.159 0.149 0.263   || dis=0.02 || select=7/8
010/019-th : 0.105 0.114 0.118 0.126 0.132 0.134 0.138 0.133  ||  -0.168 -0.089 -0.058 0.011 0.061 0.070 0.104 0.067    || dis=0.00 || select=6/8
011/019-th : 0.109 0.096 0.105 0.118 0.127 0.135 0.150 0.160  ||  -0.124 -0.245 -0.158 -0.046 0.031 0.090 0.195 0.261   || dis=0.01 || select=7/8
012/019-th : 0.114 0.116 0.122 0.125 0.129 0.128 0.133 0.133  ||  -0.085 -0.073 -0.022 0.003 0.039 0.025 0.069 0.070    || dis=0.00 || select=7/8
013/019-th : 0.046 0.050 0.067 0.082 0.109 0.137 0.200 0.309  ||  -0.806 -0.732 -0.429 -0.233 0.050 0.285 0.659 1.096   || dis=0.11 || select=7/8
014/019-th : 0.056 0.062 0.074 0.106 0.132 0.160 0.200 0.210  ||  -0.689 -0.599 -0.414 -0.055 0.165 0.354 0.579 0.626   || dis=0.01 || select=7/8
015/019-th : 0.039 0.044 0.059 0.084 0.111 0.145 0.224 0.295  ||  -0.934 -0.820 -0.529 -0.168 0.110 0.381 0.811 1.087   || dis=0.07 || select=7/8
016/019-th : 0.058 0.080 0.100 0.126 0.142 0.154 0.168 0.170  ||  -0.706 -0.382 -0.162 0.068 0.189 0.269 0.355 0.367    || dis=0.00 || select=7/8
017/019-th : 0.127 0.121 0.124 0.123 0.126 0.126 0.126 0.127  ||  0.015 -0.026 -0.002 -0.014 0.010 0.006 0.008 0.018    || dis=0.00 || select=7/8
018/019-th : 0.090 0.103 0.108 0.124 0.132 0.138 0.145 0.160  ||  -0.305 -0.178 -0.124 0.009 0.071 0.120 0.170 0.264    || dis=0.02 || select=7/8
[epoch=175/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.041
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:14:49] [epoch=175/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.842 (1.842)  Prec@1 46.48 (46.48) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:14:55] [epoch=175/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.680 (2.475)  Prec@1 39.88 (35.35) Prec@5 86.90 (81.01) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.35 Prec@5 81.01 Error@1 64.65 Error@5 18.99 Loss:2.475
***[2020-01-29 07:14:55]*** VALID [epoch=175/600] loss = 2.475424, accuracy@1 = 35.35, accuracy@5 = 81.01 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:14:56]*** start epoch=176/600 Time Left: [03:46:10], LR=[0.080230 ~ 0.080230], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=176, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.031267831412819, FLOP=40.81
[Search] : epoch=176/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:14:56] [epoch=176/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.746 (0.746)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44) Acls-loss 0.657 (0.657) FLOP-Loss 0.000 (0.000) Arch-Loss 0.657 (0.657)
**TRAIN** [2020-01-29 07:15:20] [epoch=176/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.763 (0.825)  Prec@1 76.19 (71.92) Prec@5 98.81 (97.77) Acls-loss 0.848 (0.847) FLOP-Loss 0.000 (0.000) Arch-Loss 0.848 (0.847)
 **TRAIN** Prec@1 71.92 Prec@5 97.77 Error@1 28.08 Error@5 2.23 Base-Loss:0.825, Arch-Loss=0.847
***[2020-01-29 07:15:20]*** TRAIN [epoch=176/600] base-loss = 0.824994, arch-loss = 0.847232, accuracy-1 = 71.92, accuracy-5 = 97.77
[epoch=176/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 6, 14, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.854016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.448 0.219 0.333  ||  0.2333 -0.4836 -0.0628  || discrepancy=0.11 || select=0/3
001/003-th : 0.393 0.159 0.448  ||  0.0827 -0.8204 0.2130  || discrepancy=0.05 || select=2/3
002/003-th : 0.098 0.217 0.684  ||  -0.9933 -0.2020 0.9459  || discrepancy=0.47 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.082 0.107 0.119 0.136 0.157 0.165 0.176  ||  -0.722 -0.359 -0.088 0.018 0.145 0.289 0.343 0.408    || dis=0.01 || select=7/8
001/019-th : 0.135 0.129 0.130 0.133 0.123 0.118 0.117 0.114  ||  0.079 0.032 0.046 0.068 -0.014 -0.052 -0.061 -0.087   || dis=0.00 || select=0/8
002/019-th : 0.126 0.132 0.133 0.130 0.127 0.124 0.117 0.111  ||  0.008 0.055 0.065 0.036 0.018 -0.011 -0.062 -0.117    || dis=0.00 || select=2/8
003/019-th : 0.128 0.129 0.127 0.129 0.122 0.121 0.120 0.123  ||  0.024 0.031 0.011 0.026 -0.024 -0.037 -0.042 -0.019   || dis=0.00 || select=1/8
004/019-th : 0.119 0.120 0.122 0.123 0.127 0.130 0.132 0.128  ||  -0.052 -0.042 -0.023 -0.020 0.011 0.039 0.052 0.023   || dis=0.00 || select=6/8
005/019-th : 0.116 0.122 0.126 0.127 0.124 0.129 0.127 0.129  ||  -0.069 -0.023 0.010 0.020 -0.009 0.034 0.020 0.036    || dis=0.00 || select=7/8
006/019-th : 0.122 0.114 0.121 0.126 0.125 0.126 0.133 0.133  ||  -0.023 -0.088 -0.031 0.006 0.002 0.005 0.062 0.064    || dis=0.00 || select=7/8
007/019-th : 0.077 0.083 0.100 0.114 0.138 0.147 0.160 0.180  ||  -0.440 -0.361 -0.175 -0.053 0.143 0.206 0.288 0.410   || dis=0.02 || select=7/8
008/019-th : 0.056 0.069 0.090 0.127 0.150 0.170 0.168 0.172  ||  -0.725 -0.517 -0.244 0.095 0.262 0.388 0.376 0.404    || dis=0.00 || select=7/8
009/019-th : 0.102 0.099 0.108 0.114 0.129 0.144 0.143 0.161  ||  -0.188 -0.213 -0.131 -0.076 0.049 0.159 0.153 0.269   || dis=0.02 || select=7/8
010/019-th : 0.105 0.113 0.117 0.125 0.132 0.134 0.140 0.134  ||  -0.169 -0.097 -0.067 0.001 0.060 0.074 0.116 0.071    || dis=0.01 || select=6/8
011/019-th : 0.108 0.097 0.104 0.118 0.126 0.136 0.151 0.161  ||  -0.130 -0.242 -0.169 -0.045 0.024 0.095 0.200 0.266   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.121 0.124 0.128 0.128 0.135 0.135  ||  -0.089 -0.078 -0.033 -0.009 0.025 0.029 0.081 0.078   || dis=0.00 || select=6/8
013/019-th : 0.046 0.049 0.067 0.081 0.107 0.138 0.199 0.312  ||  -0.805 -0.741 -0.431 -0.238 0.041 0.291 0.656 1.107   || dis=0.11 || select=7/8
014/019-th : 0.056 0.061 0.074 0.105 0.132 0.160 0.202 0.210  ||  -0.695 -0.607 -0.420 -0.059 0.165 0.358 0.589 0.631   || dis=0.01 || select=7/8
015/019-th : 0.039 0.043 0.058 0.084 0.111 0.145 0.223 0.296  ||  -0.940 -0.831 -0.531 -0.166 0.115 0.382 0.811 1.093   || dis=0.07 || select=7/8
016/019-th : 0.058 0.081 0.100 0.126 0.140 0.155 0.168 0.171  ||  -0.710 -0.377 -0.164 0.066 0.172 0.274 0.356 0.369    || dis=0.00 || select=7/8
017/019-th : 0.126 0.121 0.124 0.123 0.126 0.126 0.126 0.128  ||  0.009 -0.029 -0.006 -0.010 0.013 0.010 0.009 0.024    || dis=0.00 || select=7/8
018/019-th : 0.090 0.103 0.109 0.125 0.131 0.137 0.145 0.160  ||  -0.305 -0.176 -0.122 0.017 0.068 0.111 0.168 0.264    || dis=0.02 || select=7/8
[epoch=176/600] FLOP : 26.85 MB, ratio : 0.6580, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:15:21] [epoch=176/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.232 (1.232)  Prec@1 60.94 (60.94) Prec@5 96.88 (96.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:15:27] [epoch=176/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.375 (2.418)  Prec@1 51.79 (38.02) Prec@5 89.88 (82.64) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.02 Prec@5 82.64 Error@1 61.98 Error@5 17.36 Loss:2.418
***[2020-01-29 07:15:27]*** VALID [epoch=176/600] loss = 2.417664, accuracy@1 = 38.02, accuracy@5 = 82.64 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:15:27]*** start epoch=177/600 Time Left: [03:45:36], LR=[0.080021 ~ 0.080021], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=177, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.021029552048416, FLOP=40.81
[Search] : epoch=177/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:15:27] [epoch=177/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.734 (0.734)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44) Acls-loss 0.661 (0.661) FLOP-Loss 0.000 (0.000) Arch-Loss 0.661 (0.661)
**TRAIN** [2020-01-29 07:15:51] [epoch=177/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.833 (0.833)  Prec@1 72.02 (71.54) Prec@5 98.21 (97.65) Acls-loss 1.055 (0.868) FLOP-Loss 0.000 (0.000) Arch-Loss 1.055 (0.868)
 **TRAIN** Prec@1 71.54 Prec@5 97.65 Error@1 28.46 Error@5 2.35 Base-Loss:0.833, Arch-Loss=0.868
***[2020-01-29 07:15:51]*** TRAIN [epoch=177/600] base-loss = 0.832749, arch-loss = 0.868277, accuracy-1 = 71.54, accuracy-5 = 97.65
[epoch=177/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 6, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.446 0.221 0.333  ||  0.2309 -0.4706 -0.0605  || discrepancy=0.11 || select=0/3
001/003-th : 0.392 0.156 0.451  ||  0.0787 -0.8405 0.2189  || discrepancy=0.06 || select=2/3
002/003-th : 0.097 0.216 0.688  ||  -1.0046 -0.2051 0.9550  || discrepancy=0.47 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.081 0.106 0.119 0.139 0.156 0.166 0.176  ||  -0.722 -0.363 -0.104 0.014 0.168 0.287 0.350 0.410    || dis=0.01 || select=7/8
001/019-th : 0.134 0.128 0.130 0.133 0.123 0.119 0.118 0.115  ||  0.074 0.027 0.040 0.068 -0.015 -0.048 -0.055 -0.082   || dis=0.00 || select=0/8
002/019-th : 0.125 0.132 0.132 0.129 0.127 0.124 0.118 0.112  ||  0.003 0.052 0.057 0.032 0.019 -0.005 -0.056 -0.113    || dis=0.00 || select=2/8
003/019-th : 0.127 0.129 0.126 0.128 0.125 0.121 0.121 0.124  ||  0.017 0.026 0.002 0.021 -0.002 -0.037 -0.033 -0.013   || dis=0.00 || select=1/8
004/019-th : 0.118 0.119 0.122 0.123 0.127 0.129 0.132 0.129  ||  -0.055 -0.047 -0.027 -0.016 0.013 0.029 0.056 0.031   || dis=0.00 || select=6/8
005/019-th : 0.116 0.122 0.124 0.127 0.124 0.130 0.127 0.130  ||  -0.070 -0.023 -0.006 0.017 -0.008 0.045 0.022 0.039   || dis=0.00 || select=5/8
006/019-th : 0.121 0.114 0.120 0.125 0.127 0.126 0.133 0.134  ||  -0.029 -0.091 -0.036 -0.001 0.015 0.008 0.064 0.070   || dis=0.00 || select=7/8
007/019-th : 0.077 0.083 0.101 0.113 0.138 0.148 0.160 0.181  ||  -0.443 -0.364 -0.172 -0.053 0.140 0.213 0.288 0.411   || dis=0.02 || select=7/8
008/019-th : 0.056 0.067 0.090 0.128 0.148 0.172 0.167 0.172  ||  -0.722 -0.533 -0.249 0.106 0.255 0.402 0.376 0.406    || dis=0.00 || select=7/8
009/019-th : 0.101 0.099 0.106 0.114 0.130 0.144 0.144 0.161  ||  -0.195 -0.214 -0.144 -0.072 0.059 0.156 0.162 0.272   || dis=0.02 || select=7/8
010/019-th : 0.104 0.112 0.116 0.127 0.131 0.135 0.140 0.134  ||  -0.181 -0.102 -0.066 0.017 0.050 0.080 0.121 0.077    || dis=0.01 || select=6/8
011/019-th : 0.108 0.097 0.104 0.118 0.123 0.137 0.151 0.162  ||  -0.138 -0.236 -0.173 -0.048 -0.005 0.105 0.203 0.274  || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.120 0.122 0.128 0.130 0.136 0.136  ||  -0.095 -0.082 -0.042 -0.025 0.028 0.044 0.084 0.085   || dis=0.00 || select=7/8
013/019-th : 0.045 0.048 0.067 0.080 0.108 0.139 0.202 0.311  ||  -0.817 -0.757 -0.433 -0.248 0.051 0.302 0.675 1.109   || dis=0.11 || select=7/8
014/019-th : 0.055 0.061 0.073 0.104 0.134 0.160 0.202 0.211  ||  -0.704 -0.610 -0.425 -0.067 0.182 0.359 0.592 0.636   || dis=0.01 || select=7/8
015/019-th : 0.038 0.043 0.058 0.084 0.111 0.148 0.224 0.296  ||  -0.968 -0.837 -0.536 -0.167 0.119 0.404 0.819 1.097   || dis=0.07 || select=7/8
016/019-th : 0.058 0.081 0.100 0.125 0.139 0.156 0.170 0.171  ||  -0.714 -0.377 -0.164 0.060 0.163 0.279 0.364 0.370    || dis=0.00 || select=7/8
017/019-th : 0.125 0.120 0.124 0.123 0.127 0.125 0.126 0.128  ||  0.004 -0.036 -0.004 -0.010 0.020 0.007 0.014 0.029    || dis=0.00 || select=7/8
018/019-th : 0.090 0.103 0.110 0.124 0.130 0.136 0.146 0.161  ||  -0.309 -0.176 -0.113 0.011 0.059 0.102 0.172 0.269    || dis=0.02 || select=7/8
[epoch=177/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:15:52] [epoch=177/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.685 (1.685)  Prec@1 36.72 (36.72) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:15:58] [epoch=177/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.325 (2.290)  Prec@1 30.95 (37.30) Prec@5 74.40 (82.35) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.30 Prec@5 82.35 Error@1 62.70 Error@5 17.65 Loss:2.290
***[2020-01-29 07:15:58]*** VALID [epoch=177/600] loss = 2.290453, accuracy@1 = 37.30, accuracy@5 = 82.35 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:15:58]*** start epoch=178/600 Time Left: [03:45:02], LR=[0.079811 ~ 0.079811], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=178, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.010750943665759, FLOP=40.81
[Search] : epoch=178/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:15:58] [epoch=178/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.689 (0.689)  Prec@1 77.34 (77.34) Prec@5 98.83 (98.83) Acls-loss 0.922 (0.922) FLOP-Loss 0.000 (0.000) Arch-Loss 0.922 (0.922)
**TRAIN** [2020-01-29 07:16:22] [epoch=178/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.857 (0.838)  Prec@1 72.02 (71.62) Prec@5 97.02 (97.66) Acls-loss 0.989 (0.857) FLOP-Loss 0.000 (-0.027) Arch-Loss 0.989 (0.803)
 **TRAIN** Prec@1 71.62 Prec@5 97.66 Error@1 28.38 Error@5 2.34 Base-Loss:0.838, Arch-Loss=0.803
***[2020-01-29 07:16:23]*** TRAIN [epoch=178/600] base-loss = 0.837616, arch-loss = 0.803495, accuracy-1 = 71.62, accuracy-5 = 97.66
[epoch=178/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 6, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.222 0.335  ||  0.2249 -0.4665 -0.0537  || discrepancy=0.11 || select=0/3
001/003-th : 0.390 0.155 0.454  ||  0.0731 -0.8467 0.2258  || discrepancy=0.06 || select=2/3
002/003-th : 0.094 0.212 0.694  ||  -1.0249 -0.2155 0.9727  || discrepancy=0.48 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.081 0.104 0.117 0.139 0.157 0.167 0.178  ||  -0.718 -0.367 -0.119 0.001 0.170 0.290 0.356 0.416    || dis=0.01 || select=7/8
001/019-th : 0.134 0.128 0.129 0.132 0.124 0.120 0.119 0.116  ||  0.068 0.022 0.030 0.052 -0.006 -0.041 -0.048 -0.074   || dis=0.00 || select=0/8
002/019-th : 0.124 0.131 0.132 0.129 0.128 0.125 0.119 0.112  ||  -0.005 0.046 0.051 0.031 0.024 0.001 -0.048 -0.106    || dis=0.00 || select=2/8
003/019-th : 0.127 0.127 0.126 0.126 0.126 0.121 0.122 0.125  ||  0.013 0.016 0.002 0.006 0.006 -0.034 -0.027 -0.006    || dis=0.00 || select=1/8
004/019-th : 0.118 0.119 0.121 0.121 0.127 0.130 0.134 0.130  ||  -0.061 -0.055 -0.034 -0.031 0.017 0.036 0.067 0.038   || dis=0.00 || select=6/8
005/019-th : 0.116 0.121 0.122 0.125 0.124 0.132 0.129 0.131  ||  -0.077 -0.027 -0.019 -0.001 -0.007 0.055 0.030 0.050  || dis=0.00 || select=5/8
006/019-th : 0.120 0.113 0.119 0.123 0.128 0.127 0.134 0.135  ||  -0.037 -0.096 -0.046 -0.013 0.029 0.021 0.068 0.076   || dis=0.00 || select=7/8
007/019-th : 0.075 0.082 0.101 0.112 0.138 0.151 0.160 0.181  ||  -0.467 -0.369 -0.166 -0.062 0.145 0.235 0.293 0.418   || dis=0.02 || select=7/8
008/019-th : 0.056 0.066 0.088 0.129 0.147 0.172 0.168 0.174  ||  -0.723 -0.546 -0.268 0.115 0.247 0.405 0.384 0.417    || dis=0.00 || select=7/8
009/019-th : 0.099 0.099 0.107 0.114 0.129 0.144 0.145 0.164  ||  -0.214 -0.218 -0.141 -0.073 0.048 0.162 0.166 0.288   || dis=0.02 || select=7/8
010/019-th : 0.104 0.112 0.117 0.127 0.130 0.134 0.140 0.136  ||  -0.184 -0.108 -0.062 0.016 0.042 0.076 0.119 0.089    || dis=0.00 || select=6/8
011/019-th : 0.107 0.097 0.105 0.117 0.121 0.136 0.153 0.163  ||  -0.145 -0.240 -0.167 -0.052 -0.019 0.097 0.216 0.280  || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.119 0.122 0.128 0.132 0.136 0.137  ||  -0.100 -0.091 -0.051 -0.023 0.023 0.057 0.088 0.092   || dis=0.00 || select=7/8
013/019-th : 0.045 0.048 0.067 0.079 0.104 0.139 0.203 0.315  ||  -0.822 -0.758 -0.421 -0.263 0.018 0.306 0.685 1.122   || dis=0.11 || select=7/8
014/019-th : 0.055 0.059 0.073 0.103 0.134 0.161 0.203 0.212  ||  -0.710 -0.627 -0.428 -0.080 0.189 0.369 0.602 0.643   || dis=0.01 || select=7/8
015/019-th : 0.036 0.043 0.057 0.082 0.111 0.147 0.226 0.298  ||  -0.996 -0.832 -0.545 -0.176 0.126 0.403 0.836 1.109   || dis=0.07 || select=7/8
016/019-th : 0.058 0.080 0.099 0.124 0.140 0.157 0.170 0.171  ||  -0.709 -0.391 -0.179 0.055 0.175 0.290 0.369 0.374    || dis=0.00 || select=7/8
017/019-th : 0.124 0.119 0.122 0.124 0.129 0.126 0.127 0.129  ||  -0.006 -0.045 -0.018 -0.004 0.034 0.017 0.024 0.034   || dis=0.00 || select=7/8
018/019-th : 0.089 0.101 0.109 0.123 0.130 0.138 0.148 0.162  ||  -0.323 -0.194 -0.119 -0.000 0.057 0.121 0.189 0.278   || dis=0.01 || select=7/8
[epoch=178/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.043
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:16:23] [epoch=178/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.323 (2.323)  Prec@1 53.91 (53.91) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:16:29] [epoch=178/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.951 (2.324)  Prec@1 37.50 (36.71) Prec@5 85.71 (82.19) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.71 Prec@5 82.19 Error@1 63.29 Error@5 17.81 Loss:2.324
***[2020-01-29 07:16:29]*** VALID [epoch=178/600] loss = 2.324052, accuracy@1 = 36.71, accuracy@5 = 82.19 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:16:29]*** start epoch=179/600 Time Left: [03:44:28], LR=[0.079601 ~ 0.079601], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=179, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=4.0004322880580885, FLOP=40.81
[Search] : epoch=179/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:16:30] [epoch=179/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.743 (0.743)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.817 (0.817) FLOP-Loss 0.000 (0.000) Arch-Loss 0.817 (0.817)
**TRAIN** [2020-01-29 07:16:54] [epoch=179/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.795 (0.841)  Prec@1 71.43 (71.49) Prec@5 98.81 (97.64) Acls-loss 0.845 (0.854) FLOP-Loss 0.000 (-0.163) Arch-Loss 0.845 (0.528)
 **TRAIN** Prec@1 71.49 Prec@5 97.64 Error@1 28.51 Error@5 2.36 Base-Loss:0.841, Arch-Loss=0.528
***[2020-01-29 07:16:54]*** TRAIN [epoch=179/600] base-loss = 0.840626, arch-loss = 0.528316, accuracy-1 = 71.49, accuracy-5 = 97.64
[epoch=179/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 11, 16, 14, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.01376)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.434 0.224 0.342  ||  0.2048 -0.4566 -0.0324  || discrepancy=0.09 || select=0/3
001/003-th : 0.383 0.153 0.464  ||  0.0539 -0.8665 0.2469  || discrepancy=0.08 || select=2/3
002/003-th : 0.091 0.205 0.704  ||  -1.0502 -0.2380 0.9981  || discrepancy=0.50 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.081 0.102 0.114 0.139 0.156 0.170 0.181  ||  -0.736 -0.369 -0.136 -0.023 0.171 0.287 0.375 0.436   || dis=0.01 || select=7/8
001/019-th : 0.130 0.125 0.127 0.130 0.126 0.122 0.122 0.118  ||  0.045 0.001 0.016 0.038 0.012 -0.020 -0.025 -0.055    || dis=0.00 || select=0/8
002/019-th : 0.121 0.128 0.129 0.126 0.130 0.128 0.122 0.115  ||  -0.029 0.024 0.035 0.008 0.042 0.022 -0.026 -0.083    || dis=0.00 || select=4/8
003/019-th : 0.124 0.124 0.123 0.124 0.128 0.124 0.126 0.128  ||  -0.011 -0.007 -0.023 -0.009 0.018 -0.015 0.002 0.018  || dis=0.00 || select=7/8
004/019-th : 0.115 0.117 0.119 0.120 0.128 0.132 0.137 0.133  ||  -0.086 -0.070 -0.053 -0.043 0.019 0.054 0.088 0.061   || dis=0.00 || select=6/8
005/019-th : 0.113 0.119 0.121 0.123 0.124 0.134 0.131 0.135  ||  -0.097 -0.048 -0.032 -0.018 -0.007 0.071 0.049 0.075  || dis=0.00 || select=7/8
006/019-th : 0.117 0.111 0.117 0.122 0.130 0.129 0.136 0.137  ||  -0.060 -0.115 -0.061 -0.017 0.045 0.034 0.087 0.096   || dis=0.00 || select=7/8
007/019-th : 0.074 0.082 0.098 0.112 0.136 0.153 0.162 0.185  ||  -0.480 -0.379 -0.198 -0.063 0.135 0.250 0.307 0.439   || dis=0.02 || select=7/8
008/019-th : 0.054 0.065 0.086 0.127 0.147 0.175 0.170 0.176  ||  -0.740 -0.569 -0.278 0.106 0.250 0.427 0.401 0.432    || dis=0.00 || select=7/8
009/019-th : 0.097 0.097 0.106 0.112 0.128 0.146 0.147 0.166  ||  -0.229 -0.237 -0.150 -0.088 0.047 0.174 0.185 0.305   || dis=0.02 || select=7/8
010/019-th : 0.102 0.110 0.115 0.125 0.130 0.137 0.141 0.139  ||  -0.196 -0.124 -0.082 0.004 0.046 0.096 0.127 0.108    || dis=0.00 || select=6/8
011/019-th : 0.105 0.096 0.103 0.114 0.122 0.138 0.155 0.167  ||  -0.163 -0.248 -0.180 -0.079 -0.010 0.111 0.226 0.301  || dis=0.01 || select=7/8
012/019-th : 0.111 0.112 0.116 0.120 0.127 0.134 0.140 0.140  ||  -0.118 -0.112 -0.072 -0.040 0.015 0.069 0.116 0.114   || dis=0.00 || select=6/8
013/019-th : 0.043 0.047 0.066 0.078 0.103 0.140 0.206 0.317  ||  -0.854 -0.770 -0.431 -0.267 0.013 0.317 0.705 1.137   || dis=0.11 || select=7/8
014/019-th : 0.054 0.058 0.071 0.102 0.131 0.158 0.207 0.218  ||  -0.726 -0.645 -0.442 -0.089 0.166 0.353 0.623 0.672   || dis=0.01 || select=7/8
015/019-th : 0.036 0.042 0.056 0.081 0.110 0.144 0.229 0.303  ||  -1.003 -0.849 -0.554 -0.191 0.124 0.386 0.854 1.134   || dis=0.07 || select=7/8
016/019-th : 0.057 0.078 0.096 0.121 0.140 0.159 0.174 0.175  ||  -0.728 -0.409 -0.204 0.032 0.178 0.302 0.392 0.397    || dis=0.00 || select=7/8
017/019-th : 0.121 0.117 0.120 0.123 0.131 0.128 0.129 0.132  ||  -0.027 -0.063 -0.036 -0.010 0.054 0.026 0.041 0.058   || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.107 0.121 0.131 0.141 0.151 0.164  ||  -0.348 -0.213 -0.134 -0.010 0.064 0.140 0.209 0.295   || dis=0.01 || select=7/8
[epoch=179/600] FLOP : 27.01 MB, ratio : 0.6619, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:16:54] [epoch=179/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.236 (2.236)  Prec@1 35.16 (35.16) Prec@5 79.69 (79.69) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:17:00] [epoch=179/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.349 (2.432)  Prec@1 55.95 (33.29) Prec@5 92.86 (78.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.29 Prec@5 78.13 Error@1 66.71 Error@5 21.87 Loss:2.432
***[2020-01-29 07:17:00]*** VALID [epoch=179/600] loss = 2.432166, accuracy@1 = 33.29, accuracy@5 = 78.13 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:17:00]*** start epoch=180/600 Time Left: [03:43:54], LR=[0.079389 ~ 0.079389], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=180, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.9900738681165597, FLOP=40.81
[Search] : epoch=180/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:17:01] [epoch=180/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.766 (0.766)  Prec@1 74.61 (74.61) Prec@5 98.05 (98.05) Acls-loss 0.844 (0.844) FLOP-Loss 0.000 (0.000) Arch-Loss 0.844 (0.844)
**TRAIN** [2020-01-29 07:17:25] [epoch=180/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.765 (0.829)  Prec@1 69.64 (71.75) Prec@5 99.40 (97.68) Acls-loss 0.875 (0.866) FLOP-Loss 0.000 (-0.054) Arch-Loss 0.875 (0.757)
 **TRAIN** Prec@1 71.75 Prec@5 97.68 Error@1 28.25 Error@5 2.32 Base-Loss:0.829, Arch-Loss=0.757
***[2020-01-29 07:17:25]*** TRAIN [epoch=180/600] base-loss = 0.829080, arch-loss = 0.756745, accuracy-1 = 71.75, accuracy-5 = 97.68
[epoch=180/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 11, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.946048)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.430 0.224 0.346  ||  0.1961 -0.4565 -0.0226  || discrepancy=0.08 || select=0/3
001/003-th : 0.379 0.152 0.469  ||  0.0443 -0.8724 0.2579  || discrepancy=0.09 || select=2/3
002/003-th : 0.089 0.202 0.709  ||  -1.0635 -0.2457 1.0104  || discrepancy=0.51 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.081 0.101 0.113 0.138 0.156 0.174 0.182  ||  -0.740 -0.367 -0.148 -0.039 0.161 0.286 0.394 0.442   || dis=0.01 || select=7/8
001/019-th : 0.129 0.124 0.125 0.129 0.128 0.122 0.123 0.119  ||  0.034 -0.006 0.005 0.034 0.025 -0.018 -0.015 -0.045   || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.128 0.126 0.132 0.129 0.123 0.116  ||  -0.041 0.014 0.025 0.010 0.056 0.033 -0.017 -0.073    || dis=0.00 || select=4/8
003/019-th : 0.123 0.124 0.122 0.123 0.130 0.124 0.126 0.129  ||  -0.022 -0.014 -0.027 -0.015 0.034 -0.011 0.008 0.028  || dis=0.00 || select=4/8
004/019-th : 0.114 0.115 0.117 0.120 0.129 0.133 0.138 0.133  ||  -0.093 -0.081 -0.064 -0.042 0.031 0.064 0.100 0.066   || dis=0.01 || select=6/8
005/019-th : 0.112 0.118 0.120 0.122 0.124 0.136 0.132 0.136  ||  -0.104 -0.059 -0.036 -0.024 -0.004 0.083 0.055 0.083  || dis=0.00 || select=5/8
006/019-th : 0.116 0.110 0.116 0.122 0.131 0.131 0.136 0.138  ||  -0.071 -0.120 -0.068 -0.020 0.056 0.052 0.091 0.101   || dis=0.00 || select=7/8
007/019-th : 0.073 0.081 0.097 0.110 0.135 0.156 0.163 0.185  ||  -0.485 -0.388 -0.205 -0.080 0.130 0.275 0.315 0.444   || dis=0.02 || select=7/8
008/019-th : 0.054 0.064 0.086 0.126 0.146 0.176 0.171 0.177  ||  -0.747 -0.579 -0.280 0.104 0.247 0.434 0.407 0.439    || dis=0.00 || select=7/8
009/019-th : 0.097 0.096 0.105 0.113 0.128 0.145 0.149 0.167  ||  -0.238 -0.245 -0.153 -0.080 0.042 0.170 0.196 0.313   || dis=0.02 || select=7/8
010/019-th : 0.101 0.108 0.114 0.125 0.130 0.140 0.142 0.140  ||  -0.208 -0.142 -0.084 0.006 0.048 0.118 0.135 0.116    || dis=0.00 || select=6/8
011/019-th : 0.103 0.096 0.102 0.113 0.122 0.139 0.156 0.168  ||  -0.175 -0.253 -0.188 -0.083 -0.010 0.118 0.237 0.311  || dis=0.01 || select=7/8
012/019-th : 0.110 0.111 0.115 0.119 0.128 0.134 0.141 0.141  ||  -0.128 -0.119 -0.081 -0.046 0.028 0.073 0.123 0.124   || dis=0.00 || select=7/8
013/019-th : 0.042 0.047 0.065 0.078 0.102 0.141 0.207 0.318  ||  -0.868 -0.777 -0.447 -0.267 0.011 0.334 0.715 1.146   || dis=0.11 || select=7/8
014/019-th : 0.053 0.058 0.071 0.100 0.133 0.158 0.208 0.218  ||  -0.733 -0.643 -0.450 -0.102 0.179 0.351 0.630 0.677   || dis=0.01 || select=7/8
015/019-th : 0.036 0.041 0.056 0.078 0.110 0.142 0.230 0.307  ||  -0.994 -0.864 -0.558 -0.214 0.124 0.381 0.860 1.151   || dis=0.08 || select=7/8
016/019-th : 0.057 0.077 0.095 0.120 0.139 0.160 0.175 0.176  ||  -0.727 -0.419 -0.208 0.025 0.168 0.308 0.398 0.405    || dis=0.00 || select=7/8
017/019-th : 0.119 0.116 0.119 0.122 0.133 0.129 0.130 0.133  ||  -0.040 -0.069 -0.043 -0.020 0.066 0.036 0.048 0.067   || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.104 0.121 0.132 0.141 0.151 0.166  ||  -0.356 -0.209 -0.158 -0.013 0.078 0.139 0.212 0.304   || dis=0.02 || select=7/8
[epoch=180/600] FLOP : 28.95 MB, ratio : 0.7092, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:17:25] [epoch=180/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.791 (1.791)  Prec@1 42.97 (42.97) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:17:31] [epoch=180/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.920 (2.041)  Prec@1 35.12 (38.84) Prec@5 73.21 (82.90) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.84 Prec@5 82.90 Error@1 61.16 Error@5 17.10 Loss:2.041
***[2020-01-29 07:17:31]*** VALID [epoch=180/600] loss = 2.040699, accuracy@1 = 38.84, accuracy@5 = 82.90 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:17:31]*** start epoch=181/600 Time Left: [03:43:20], LR=[0.079177 ~ 0.079177], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=181, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.979675967822488, FLOP=40.81
[Search] : epoch=181/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:17:32] [epoch=181/600][000/098] Time 0.75 (0.75) Data 0.36 (0.36) Base-Loss 0.724 (0.724)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44) Acls-loss 0.870 (0.870) FLOP-Loss 2.664 (2.664) Arch-Loss 6.198 (6.198)
**TRAIN** [2020-01-29 07:17:56] [epoch=181/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.744 (0.819)  Prec@1 77.98 (71.86) Prec@5 97.62 (97.84) Acls-loss 0.890 (0.848) FLOP-Loss 0.000 (-0.027) Arch-Loss 0.890 (0.794)
 **TRAIN** Prec@1 71.86 Prec@5 97.84 Error@1 28.14 Error@5 2.16 Base-Loss:0.819, Arch-Loss=0.794
***[2020-01-29 07:17:56]*** TRAIN [epoch=181/600] base-loss = 0.819274, arch-loss = 0.794153, accuracy-1 = 71.86, accuracy-5 = 97.84
[epoch=181/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 11, 14, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.78336)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.427 0.226 0.348  ||  0.1898 -0.4481 -0.0157  || discrepancy=0.08 || select=0/3
001/003-th : 0.377 0.151 0.473  ||  0.0381 -0.8780 0.2655  || discrepancy=0.10 || select=2/3
002/003-th : 0.088 0.200 0.712  ||  -1.0748 -0.2500 1.0201  || discrepancy=0.51 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.082 0.101 0.112 0.136 0.156 0.176 0.182  ||  -0.750 -0.361 -0.149 -0.043 0.153 0.289 0.407 0.441   || dis=0.01 || select=7/8
001/019-th : 0.128 0.123 0.125 0.129 0.128 0.123 0.124 0.120  ||  0.028 -0.011 -0.001 0.030 0.029 -0.016 -0.009 -0.037  || dis=0.00 || select=3/8
002/019-th : 0.119 0.125 0.127 0.126 0.132 0.130 0.124 0.117  ||  -0.047 0.002 0.021 0.012 0.058 0.040 -0.009 -0.066    || dis=0.00 || select=4/8
003/019-th : 0.122 0.122 0.121 0.124 0.130 0.125 0.126 0.130  ||  -0.025 -0.023 -0.030 -0.010 0.035 -0.005 0.009 0.034  || dis=0.00 || select=4/8
004/019-th : 0.113 0.115 0.116 0.119 0.130 0.134 0.139 0.135  ||  -0.099 -0.087 -0.073 -0.048 0.041 0.066 0.104 0.074   || dis=0.00 || select=6/8
005/019-th : 0.112 0.118 0.119 0.122 0.125 0.135 0.132 0.137  ||  -0.110 -0.059 -0.044 -0.019 -0.001 0.078 0.059 0.090  || dis=0.00 || select=7/8
006/019-th : 0.115 0.110 0.115 0.122 0.131 0.133 0.137 0.139  ||  -0.080 -0.125 -0.080 -0.022 0.051 0.066 0.097 0.109   || dis=0.00 || select=7/8
007/019-th : 0.073 0.080 0.097 0.110 0.134 0.157 0.163 0.186  ||  -0.492 -0.393 -0.203 -0.080 0.122 0.279 0.315 0.451   || dis=0.02 || select=7/8
008/019-th : 0.054 0.064 0.085 0.126 0.145 0.177 0.172 0.177  ||  -0.752 -0.572 -0.291 0.098 0.240 0.442 0.411 0.442    || dis=0.00 || select=7/8
009/019-th : 0.096 0.095 0.104 0.112 0.129 0.144 0.151 0.168  ||  -0.242 -0.252 -0.165 -0.085 0.056 0.162 0.208 0.319   || dis=0.02 || select=7/8
010/019-th : 0.100 0.108 0.113 0.125 0.132 0.140 0.143 0.140  ||  -0.213 -0.143 -0.098 0.005 0.064 0.124 0.139 0.118    || dis=0.00 || select=6/8
011/019-th : 0.104 0.095 0.101 0.114 0.122 0.137 0.157 0.169  ||  -0.171 -0.257 -0.195 -0.082 -0.008 0.108 0.243 0.314  || dis=0.01 || select=7/8
012/019-th : 0.109 0.110 0.114 0.119 0.129 0.134 0.142 0.142  ||  -0.133 -0.123 -0.086 -0.045 0.030 0.075 0.129 0.128   || dis=0.00 || select=6/8
013/019-th : 0.043 0.046 0.064 0.076 0.099 0.143 0.210 0.318  ||  -0.861 -0.776 -0.449 -0.280 -0.016 0.347 0.734 1.149  || dis=0.11 || select=7/8
014/019-th : 0.053 0.058 0.070 0.098 0.133 0.161 0.209 0.218  ||  -0.741 -0.650 -0.451 -0.119 0.186 0.373 0.636 0.681   || dis=0.01 || select=7/8
015/019-th : 0.036 0.041 0.056 0.077 0.109 0.140 0.234 0.308  ||  -0.995 -0.868 -0.548 -0.227 0.116 0.369 0.882 1.155   || dis=0.07 || select=7/8
016/019-th : 0.057 0.077 0.095 0.119 0.138 0.161 0.175 0.177  ||  -0.729 -0.423 -0.209 0.016 0.157 0.317 0.400 0.411    || dis=0.00 || select=7/8
017/019-th : 0.118 0.115 0.117 0.121 0.134 0.129 0.131 0.133  ||  -0.048 -0.075 -0.055 -0.021 0.080 0.041 0.057 0.073   || dis=0.00 || select=4/8
018/019-th : 0.085 0.098 0.105 0.121 0.132 0.142 0.152 0.165  ||  -0.357 -0.221 -0.154 -0.009 0.078 0.152 0.220 0.299   || dis=0.01 || select=7/8
[epoch=181/600] FLOP : 26.78 MB, ratio : 0.6562, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:17:56] [epoch=181/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.301 (1.301)  Prec@1 58.20 (58.20) Prec@5 96.48 (96.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:18:02] [epoch=181/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 3.031 (2.271)  Prec@1 20.83 (39.30) Prec@5 67.86 (83.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.30 Prec@5 83.80 Error@1 60.70 Error@5 16.20 Loss:2.271
***[2020-01-29 07:18:03]*** VALID [epoch=181/600] loss = 2.271369, accuracy@1 = 39.30, accuracy@5 = 83.80 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:18:03]*** start epoch=182/600 Time Left: [03:42:47], LR=[0.078964 ~ 0.078964], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=182, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.969238872239563, FLOP=40.81
[Search] : epoch=182/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:18:03] [epoch=182/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.827 (0.827)  Prec@1 69.53 (69.53) Prec@5 97.66 (97.66) Acls-loss 0.900 (0.900) FLOP-Loss 0.000 (0.000) Arch-Loss 0.900 (0.900)
**TRAIN** [2020-01-29 07:18:27] [epoch=182/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.965 (0.827)  Prec@1 66.67 (71.53) Prec@5 97.62 (97.74) Acls-loss 0.997 (0.849) FLOP-Loss 0.000 (-0.027) Arch-Loss 0.997 (0.795)
 **TRAIN** Prec@1 71.53 Prec@5 97.74 Error@1 28.47 Error@5 2.26 Base-Loss:0.827, Arch-Loss=0.795
***[2020-01-29 07:18:27]*** TRAIN [epoch=182/600] base-loss = 0.827208, arch-loss = 0.794710, accuracy-1 = 71.53, accuracy-5 = 97.74
[epoch=182/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 11, 16, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.477632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.423 0.227 0.350  ||  0.1814 -0.4422 -0.0066  || discrepancy=0.07 || select=0/3
001/003-th : 0.373 0.151 0.476  ||  0.0303 -0.8737 0.2742  || discrepancy=0.10 || select=2/3
002/003-th : 0.085 0.197 0.718  ||  -1.0955 -0.2586 1.0376  || discrepancy=0.52 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.081 0.101 0.113 0.136 0.156 0.175 0.183  ||  -0.754 -0.368 -0.148 -0.035 0.148 0.290 0.404 0.446   || dis=0.01 || select=7/8
001/019-th : 0.127 0.122 0.123 0.129 0.130 0.123 0.124 0.121  ||  0.021 -0.018 -0.009 0.037 0.041 -0.013 -0.004 -0.031  || dis=0.00 || select=4/8
002/019-th : 0.118 0.124 0.127 0.125 0.133 0.130 0.124 0.118  ||  -0.054 -0.003 0.015 0.004 0.067 0.044 -0.005 -0.058   || dis=0.00 || select=4/8
003/019-th : 0.121 0.122 0.121 0.124 0.130 0.125 0.127 0.130  ||  -0.031 -0.027 -0.033 -0.012 0.038 0.002 0.014 0.039   || dis=0.00 || select=7/8
004/019-th : 0.112 0.113 0.116 0.120 0.132 0.134 0.139 0.135  ||  -0.110 -0.094 -0.075 -0.040 0.062 0.074 0.109 0.077   || dis=0.00 || select=6/8
005/019-th : 0.112 0.117 0.118 0.122 0.126 0.135 0.133 0.138  ||  -0.112 -0.064 -0.058 -0.024 0.010 0.080 0.062 0.097   || dis=0.00 || select=7/8
006/019-th : 0.114 0.110 0.114 0.121 0.131 0.133 0.138 0.140  ||  -0.085 -0.127 -0.091 -0.031 0.051 0.064 0.106 0.115   || dis=0.00 || select=7/8
007/019-th : 0.073 0.080 0.097 0.109 0.134 0.155 0.164 0.188  ||  -0.492 -0.392 -0.201 -0.089 0.122 0.266 0.319 0.456   || dis=0.02 || select=7/8
008/019-th : 0.054 0.064 0.085 0.124 0.146 0.177 0.172 0.178  ||  -0.754 -0.574 -0.295 0.085 0.250 0.443 0.415 0.448    || dis=0.00 || select=7/8
009/019-th : 0.095 0.095 0.102 0.113 0.129 0.143 0.152 0.170  ||  -0.249 -0.258 -0.181 -0.077 0.055 0.159 0.214 0.330   || dis=0.02 || select=7/8
010/019-th : 0.100 0.107 0.112 0.125 0.132 0.142 0.142 0.140  ||  -0.218 -0.151 -0.101 0.010 0.060 0.137 0.136 0.124    || dis=0.00 || select=5/8
011/019-th : 0.104 0.094 0.101 0.115 0.121 0.138 0.157 0.170  ||  -0.171 -0.266 -0.196 -0.074 -0.022 0.114 0.244 0.320  || dis=0.01 || select=7/8
012/019-th : 0.108 0.110 0.114 0.118 0.127 0.137 0.142 0.143  ||  -0.140 -0.125 -0.092 -0.054 0.021 0.094 0.133 0.133   || dis=0.00 || select=7/8
013/019-th : 0.043 0.046 0.063 0.075 0.098 0.143 0.212 0.321  ||  -0.859 -0.780 -0.471 -0.295 -0.020 0.355 0.748 1.161  || dis=0.11 || select=7/8
014/019-th : 0.052 0.057 0.070 0.097 0.130 0.162 0.213 0.220  ||  -0.754 -0.653 -0.460 -0.131 0.166 0.388 0.657 0.689   || dis=0.01 || select=7/8
015/019-th : 0.035 0.041 0.055 0.076 0.109 0.139 0.234 0.310  ||  -1.002 -0.866 -0.562 -0.234 0.123 0.365 0.885 1.167   || dis=0.08 || select=7/8
016/019-th : 0.056 0.076 0.094 0.119 0.137 0.162 0.176 0.179  ||  -0.735 -0.431 -0.219 0.010 0.156 0.323 0.406 0.423    || dis=0.00 || select=7/8
017/019-th : 0.118 0.114 0.116 0.121 0.135 0.131 0.132 0.134  ||  -0.053 -0.081 -0.070 -0.024 0.083 0.054 0.063 0.078   || dis=0.00 || select=4/8
018/019-th : 0.085 0.098 0.104 0.119 0.131 0.141 0.154 0.168  ||  -0.367 -0.225 -0.164 -0.027 0.072 0.141 0.233 0.319   || dis=0.01 || select=7/8
[epoch=182/600] FLOP : 27.48 MB, ratio : 0.6733, Expected-ratio : 0.7000, Discrepancy : 0.045
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:18:28] [epoch=182/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.705 (1.705)  Prec@1 54.30 (54.30) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:18:34] [epoch=182/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.293 (2.190)  Prec@1 33.33 (35.56) Prec@5 78.57 (81.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.56 Prec@5 81.94 Error@1 64.44 Error@5 18.06 Loss:2.190
***[2020-01-29 07:18:34]*** VALID [epoch=182/600] loss = 2.190401, accuracy@1 = 35.56, accuracy@5 = 81.94 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:18:34]*** start epoch=183/600 Time Left: [03:42:13], LR=[0.078750 ~ 0.078750], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=183, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.9587628675060333, FLOP=40.81
[Search] : epoch=183/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:18:34] [epoch=183/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.747 (0.747)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44) Acls-loss 0.833 (0.833) FLOP-Loss 0.000 (0.000) Arch-Loss 0.833 (0.833)
**TRAIN** [2020-01-29 07:18:58] [epoch=183/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.864 (0.805)  Prec@1 67.26 (72.42) Prec@5 98.81 (97.95) Acls-loss 0.832 (0.841) FLOP-Loss 0.000 (0.137) Arch-Loss 0.832 (1.115)
 **TRAIN** Prec@1 72.42 Prec@5 97.95 Error@1 27.58 Error@5 2.05 Base-Loss:0.805, Arch-Loss=1.115
***[2020-01-29 07:18:59]*** TRAIN [epoch=183/600] base-loss = 0.805401, arch-loss = 1.115001, accuracy-1 = 72.42, accuracy-5 = 97.95
[epoch=183/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 11, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.471488)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.427 0.226 0.347  ||  0.1920 -0.4432 -0.0169  || discrepancy=0.08 || select=0/3
001/003-th : 0.377 0.151 0.472  ||  0.0406 -0.8769 0.2655  || discrepancy=0.09 || select=2/3
002/003-th : 0.085 0.199 0.716  ||  -1.0940 -0.2480 1.0335  || discrepancy=0.52 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.080 0.101 0.114 0.137 0.158 0.173 0.181  ||  -0.739 -0.382 -0.147 -0.022 0.159 0.305 0.394 0.436   || dis=0.01 || select=7/8
001/019-th : 0.128 0.124 0.126 0.130 0.129 0.122 0.123 0.119  ||  0.030 -0.006 0.008 0.041 0.035 -0.024 -0.016 -0.043   || dis=0.00 || select=3/8
002/019-th : 0.119 0.126 0.129 0.127 0.131 0.129 0.123 0.116  ||  -0.047 0.009 0.033 0.017 0.051 0.037 -0.017 -0.068    || dis=0.00 || select=4/8
003/019-th : 0.123 0.122 0.121 0.126 0.129 0.125 0.126 0.128  ||  -0.019 -0.021 -0.031 0.007 0.029 -0.001 0.004 0.027   || dis=0.00 || select=4/8
004/019-th : 0.112 0.114 0.117 0.122 0.131 0.133 0.137 0.133  ||  -0.103 -0.088 -0.059 -0.017 0.049 0.070 0.095 0.068   || dis=0.00 || select=6/8
005/019-th : 0.113 0.119 0.120 0.123 0.124 0.132 0.132 0.136  ||  -0.099 -0.053 -0.040 -0.014 -0.005 0.058 0.051 0.087  || dis=0.00 || select=7/8
006/019-th : 0.116 0.111 0.115 0.122 0.129 0.132 0.137 0.138  ||  -0.070 -0.117 -0.076 -0.023 0.035 0.060 0.095 0.100   || dis=0.00 || select=7/8
007/019-th : 0.073 0.080 0.099 0.110 0.136 0.153 0.162 0.186  ||  -0.483 -0.392 -0.183 -0.075 0.129 0.248 0.308 0.446   || dis=0.02 || select=7/8
008/019-th : 0.054 0.064 0.087 0.124 0.147 0.175 0.172 0.177  ||  -0.745 -0.575 -0.277 0.084 0.252 0.427 0.413 0.439    || dis=0.00 || select=7/8
009/019-th : 0.096 0.095 0.103 0.113 0.129 0.144 0.151 0.169  ||  -0.243 -0.253 -0.171 -0.081 0.049 0.161 0.213 0.321   || dis=0.02 || select=7/8
010/019-th : 0.100 0.107 0.114 0.126 0.133 0.140 0.140 0.139  ||  -0.211 -0.146 -0.082 0.016 0.072 0.124 0.126 0.114    || dis=0.00 || select=6/8
011/019-th : 0.105 0.096 0.103 0.115 0.121 0.137 0.154 0.168  ||  -0.159 -0.253 -0.184 -0.070 -0.016 0.107 0.224 0.309  || dis=0.01 || select=7/8
012/019-th : 0.110 0.112 0.115 0.116 0.127 0.137 0.142 0.142  ||  -0.131 -0.114 -0.081 -0.073 0.018 0.090 0.125 0.127   || dis=0.00 || select=7/8
013/019-th : 0.043 0.047 0.064 0.075 0.098 0.143 0.211 0.320  ||  -0.861 -0.766 -0.455 -0.296 -0.025 0.350 0.740 1.158  || dis=0.11 || select=7/8
014/019-th : 0.053 0.057 0.070 0.097 0.131 0.163 0.211 0.217  ||  -0.737 -0.660 -0.448 -0.125 0.176 0.392 0.647 0.677   || dis=0.01 || select=7/8
015/019-th : 0.036 0.040 0.055 0.077 0.109 0.141 0.234 0.309  ||  -0.982 -0.882 -0.566 -0.223 0.116 0.375 0.882 1.161   || dis=0.07 || select=7/8
016/019-th : 0.057 0.077 0.096 0.120 0.138 0.161 0.174 0.177  ||  -0.724 -0.423 -0.207 0.022 0.160 0.318 0.391 0.412    || dis=0.00 || select=7/8
017/019-th : 0.120 0.116 0.116 0.120 0.133 0.130 0.132 0.133  ||  -0.039 -0.072 -0.069 -0.031 0.070 0.046 0.057 0.070   || dis=0.00 || select=4/8
018/019-th : 0.086 0.100 0.105 0.121 0.130 0.138 0.153 0.166  ||  -0.352 -0.202 -0.155 -0.013 0.060 0.121 0.223 0.304   || dis=0.01 || select=7/8
[epoch=183/600] FLOP : 27.47 MB, ratio : 0.6731, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:18:59] [epoch=183/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.642 (1.642)  Prec@1 48.44 (48.44) Prec@5 90.62 (90.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:19:05] [epoch=183/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.472 (2.080)  Prec@1 49.40 (40.00) Prec@5 90.48 (83.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.00 Prec@5 83.70 Error@1 60.00 Error@5 16.30 Loss:2.080
***[2020-01-29 07:19:05]*** VALID [epoch=183/600] loss = 2.080035, accuracy@1 = 40.00, accuracy@5 = 83.70 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:19:05]*** start epoch=184/600 Time Left: [03:41:39], LR=[0.078536 ~ 0.078536], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=184, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.9482482408268584, FLOP=40.81
[Search] : epoch=184/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:19:06] [epoch=184/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.944 (0.944)  Prec@1 66.41 (66.41) Prec@5 97.66 (97.66) Acls-loss 0.917 (0.917) FLOP-Loss 0.000 (0.000) Arch-Loss 0.917 (0.917)
**TRAIN** [2020-01-29 07:19:30] [epoch=184/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 1.280 (0.828)  Prec@1 55.95 (71.89) Prec@5 96.43 (97.74) Acls-loss 0.937 (0.859) FLOP-Loss 0.000 (0.109) Arch-Loss 0.937 (1.078)
 **TRAIN** Prec@1 71.89 Prec@5 97.74 Error@1 28.11 Error@5 2.26 Base-Loss:0.828, Arch-Loss=1.078
***[2020-01-29 07:19:30]*** TRAIN [epoch=184/600] base-loss = 0.828323, arch-loss = 1.077905, accuracy-1 = 71.89, accuracy-5 = 97.74
[epoch=184/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 11, 14, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.959936)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.432 0.222 0.346  ||  0.2003 -0.4664 -0.0230  || discrepancy=0.09 || select=0/3
001/003-th : 0.379 0.151 0.469  ||  0.0473 -0.8711 0.2599  || discrepancy=0.09 || select=2/3
002/003-th : 0.085 0.201 0.713  ||  -1.0943 -0.2346 1.0295  || discrepancy=0.51 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.080 0.101 0.115 0.139 0.159 0.171 0.179  ||  -0.734 -0.382 -0.141 -0.011 0.171 0.310 0.380 0.428   || dis=0.01 || select=7/8
001/019-th : 0.129 0.124 0.127 0.130 0.128 0.122 0.122 0.118  ||  0.037 -0.003 0.016 0.041 0.024 -0.021 -0.019 -0.051   || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.130 0.128 0.129 0.128 0.122 0.116  ||  -0.040 0.016 0.040 0.025 0.033 0.028 -0.021 -0.075    || dis=0.00 || select=2/8
003/019-th : 0.123 0.123 0.123 0.126 0.128 0.124 0.125 0.128  ||  -0.018 -0.016 -0.018 0.011 0.026 -0.005 0.001 0.021   || dis=0.00 || select=4/8
004/019-th : 0.113 0.115 0.119 0.122 0.130 0.132 0.136 0.133  ||  -0.098 -0.078 -0.048 -0.021 0.039 0.061 0.088 0.064   || dis=0.00 || select=6/8
005/019-th : 0.115 0.119 0.121 0.122 0.124 0.134 0.130 0.136  ||  -0.088 -0.054 -0.037 -0.026 -0.007 0.067 0.040 0.085  || dis=0.00 || select=7/8
006/019-th : 0.117 0.111 0.116 0.123 0.130 0.131 0.136 0.137  ||  -0.064 -0.112 -0.073 -0.014 0.046 0.048 0.089 0.093   || dis=0.00 || select=7/8
007/019-th : 0.073 0.081 0.099 0.112 0.138 0.151 0.160 0.185  ||  -0.484 -0.387 -0.184 -0.058 0.151 0.241 0.297 0.440   || dis=0.02 || select=7/8
008/019-th : 0.055 0.065 0.088 0.125 0.148 0.173 0.170 0.177  ||  -0.740 -0.566 -0.266 0.089 0.256 0.413 0.395 0.438    || dis=0.00 || select=7/8
009/019-th : 0.096 0.095 0.104 0.114 0.129 0.144 0.150 0.167  ||  -0.244 -0.252 -0.158 -0.069 0.052 0.166 0.208 0.313   || dis=0.02 || select=7/8
010/019-th : 0.101 0.107 0.115 0.126 0.131 0.140 0.141 0.138  ||  -0.202 -0.146 -0.080 0.019 0.057 0.122 0.126 0.109    || dis=0.00 || select=6/8
011/019-th : 0.106 0.097 0.103 0.116 0.120 0.139 0.152 0.167  ||  -0.153 -0.240 -0.180 -0.063 -0.032 0.119 0.211 0.302  || dis=0.02 || select=7/8
012/019-th : 0.109 0.112 0.116 0.118 0.127 0.135 0.141 0.141  ||  -0.132 -0.107 -0.074 -0.053 0.022 0.081 0.123 0.119   || dis=0.00 || select=6/8
013/019-th : 0.042 0.047 0.063 0.075 0.098 0.143 0.212 0.319  ||  -0.868 -0.753 -0.460 -0.290 -0.030 0.352 0.748 1.155  || dis=0.11 || select=7/8
014/019-th : 0.054 0.058 0.071 0.097 0.132 0.162 0.209 0.218  ||  -0.722 -0.650 -0.450 -0.129 0.174 0.380 0.637 0.678   || dis=0.01 || select=7/8
015/019-th : 0.037 0.041 0.055 0.077 0.107 0.142 0.231 0.310  ||  -0.970 -0.866 -0.565 -0.226 0.099 0.383 0.870 1.161   || dis=0.08 || select=7/8
016/019-th : 0.057 0.078 0.096 0.121 0.137 0.161 0.173 0.176  ||  -0.718 -0.411 -0.201 0.027 0.155 0.314 0.383 0.405    || dis=0.00 || select=7/8
017/019-th : 0.121 0.117 0.117 0.121 0.131 0.129 0.131 0.133  ||  -0.032 -0.064 -0.058 -0.028 0.051 0.036 0.051 0.063   || dis=0.00 || select=7/8
018/019-th : 0.088 0.102 0.106 0.123 0.129 0.137 0.152 0.164  ||  -0.334 -0.184 -0.151 0.001 0.046 0.110 0.214 0.289    || dis=0.01 || select=7/8
[epoch=184/600] FLOP : 27.96 MB, ratio : 0.6851, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:19:30] [epoch=184/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.303 (2.303)  Prec@1 38.28 (38.28) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:19:36] [epoch=184/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.325 (2.280)  Prec@1 28.57 (37.01) Prec@5 85.71 (82.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.01 Prec@5 82.18 Error@1 62.99 Error@5 17.82 Loss:2.280
***[2020-01-29 07:19:36]*** VALID [epoch=184/600] loss = 2.279539, accuracy@1 = 37.01, accuracy@5 = 82.18 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:19:36]*** start epoch=185/600 Time Left: [03:41:05], LR=[0.078320 ~ 0.078320], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=185, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.937695280465841, FLOP=40.81
[Search] : epoch=185/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:19:37] [epoch=185/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.941 (0.941)  Prec@1 68.75 (68.75) Prec@5 98.05 (98.05) Acls-loss 0.913 (0.913) FLOP-Loss 0.000 (0.000) Arch-Loss 0.913 (0.913)
**TRAIN** [2020-01-29 07:20:01] [epoch=185/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.977 (0.837)  Prec@1 69.64 (71.47) Prec@5 97.02 (97.56) Acls-loss 0.947 (0.874) FLOP-Loss 0.000 (0.489) Arch-Loss 0.947 (1.851)
 **TRAIN** Prec@1 71.47 Prec@5 97.56 Error@1 28.53 Error@5 2.44 Base-Loss:0.837, Arch-Loss=1.851
***[2020-01-29 07:20:01]*** TRAIN [epoch=185/600] base-loss = 0.837080, arch-loss = 1.850975, accuracy-1 = 71.47, accuracy-5 = 97.56
[epoch=185/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 9, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.156544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.455 0.215 0.331  ||  0.2485 -0.5006 -0.0702  || discrepancy=0.12 || select=0/3
001/003-th : 0.397 0.154 0.448  ||  0.0939 -0.8513 0.2143  || discrepancy=0.05 || select=2/3
002/003-th : 0.088 0.213 0.698  ||  -1.0711 -0.1884 0.9976  || discrepancy=0.48 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.084 0.103 0.119 0.142 0.158 0.164 0.173  ||  -0.717 -0.331 -0.124 0.012 0.194 0.298 0.336 0.391    || dis=0.01 || select=7/8
001/019-th : 0.135 0.130 0.131 0.136 0.123 0.117 0.116 0.113  ||  0.082 0.042 0.054 0.090 -0.011 -0.062 -0.066 -0.099   || dis=0.00 || select=3/8
002/019-th : 0.124 0.132 0.137 0.133 0.124 0.123 0.116 0.110  ||  -0.000 0.062 0.097 0.070 -0.004 -0.015 -0.068 -0.122  || dis=0.00 || select=2/8
003/019-th : 0.128 0.129 0.128 0.132 0.123 0.118 0.120 0.122  ||  0.025 0.030 0.027 0.056 -0.012 -0.055 -0.042 -0.025   || dis=0.00 || select=3/8
004/019-th : 0.117 0.120 0.125 0.126 0.127 0.128 0.131 0.126  ||  -0.059 -0.035 0.001 0.011 0.018 0.029 0.049 0.015     || dis=0.00 || select=6/8
005/019-th : 0.120 0.123 0.124 0.125 0.121 0.130 0.125 0.131  ||  -0.042 -0.017 -0.015 -0.001 -0.032 0.038 -0.002 0.046  || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.121 0.127 0.126 0.125 0.131 0.131  ||  -0.022 -0.070 -0.030 0.022 0.014 0.005 0.049 0.051    || dis=0.00 || select=7/8
007/019-th : 0.076 0.084 0.101 0.116 0.141 0.148 0.155 0.179  ||  -0.452 -0.349 -0.164 -0.033 0.163 0.216 0.260 0.402   || dis=0.02 || select=7/8
008/019-th : 0.057 0.067 0.092 0.127 0.150 0.170 0.166 0.171  ||  -0.709 -0.537 -0.228 0.101 0.268 0.392 0.365 0.396    || dis=0.00 || select=7/8
009/019-th : 0.100 0.099 0.108 0.119 0.128 0.140 0.145 0.160  ||  -0.203 -0.214 -0.123 -0.031 0.045 0.134 0.164 0.268   || dis=0.02 || select=7/8
010/019-th : 0.105 0.112 0.118 0.130 0.129 0.136 0.136 0.133  ||  -0.164 -0.105 -0.053 0.047 0.041 0.093 0.091 0.068    || dis=0.00 || select=5/8
011/019-th : 0.111 0.102 0.108 0.118 0.120 0.134 0.147 0.160  ||  -0.110 -0.195 -0.138 -0.050 -0.030 0.080 0.173 0.254  || dis=0.01 || select=7/8
012/019-th : 0.115 0.117 0.120 0.121 0.125 0.130 0.135 0.136  ||  -0.087 -0.063 -0.039 -0.029 0.002 0.040 0.076 0.081   || dis=0.00 || select=7/8
013/019-th : 0.044 0.049 0.064 0.078 0.100 0.144 0.211 0.310  ||  -0.844 -0.718 -0.458 -0.267 -0.011 0.352 0.730 1.115  || dis=0.10 || select=7/8
014/019-th : 0.056 0.060 0.074 0.101 0.135 0.162 0.202 0.209  ||  -0.681 -0.613 -0.410 -0.101 0.190 0.376 0.595 0.629   || dis=0.01 || select=7/8
015/019-th : 0.038 0.042 0.057 0.080 0.111 0.144 0.226 0.302  ||  -0.945 -0.841 -0.548 -0.208 0.122 0.383 0.836 1.124   || dis=0.08 || select=7/8
016/019-th : 0.060 0.081 0.100 0.125 0.141 0.156 0.167 0.170  ||  -0.675 -0.375 -0.164 0.057 0.174 0.278 0.347 0.361    || dis=0.00 || select=7/8
017/019-th : 0.127 0.123 0.123 0.124 0.126 0.124 0.126 0.127  ||  0.015 -0.018 -0.012 -0.007 0.005 -0.011 0.008 0.019   || dis=0.00 || select=7/8
018/019-th : 0.092 0.107 0.109 0.124 0.129 0.134 0.146 0.158  ||  -0.294 -0.138 -0.123 0.008 0.049 0.086 0.173 0.252    || dis=0.01 || select=7/8
[epoch=185/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.042
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:20:01] [epoch=185/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.788 (1.788)  Prec@1 41.02 (41.02) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:20:07] [epoch=185/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.473 (2.034)  Prec@1 44.64 (39.00) Prec@5 88.69 (83.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.00 Prec@5 83.30 Error@1 61.00 Error@5 16.70 Loss:2.034
***[2020-01-29 07:20:07]*** VALID [epoch=185/600] loss = 2.034016, accuracy@1 = 39.00, accuracy@5 = 83.30 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:20:07]*** start epoch=186/600 Time Left: [03:40:31], LR=[0.078104 ~ 0.078104], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=186, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.92710427573772, FLOP=40.81
[Search] : epoch=186/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:20:08] [epoch=186/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.796 (0.796)  Prec@1 73.05 (73.05) Prec@5 98.83 (98.83) Acls-loss 0.823 (0.823) FLOP-Loss 0.000 (0.000) Arch-Loss 0.823 (0.823)
**TRAIN** [2020-01-29 07:20:32] [epoch=186/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.884 (0.811)  Prec@1 69.05 (72.44) Prec@5 98.81 (97.74) Acls-loss 0.800 (0.859) FLOP-Loss 0.000 (0.054) Arch-Loss 0.800 (0.967)
 **TRAIN** Prec@1 72.44 Prec@5 97.74 Error@1 27.56 Error@5 2.26 Base-Loss:0.811, Arch-Loss=0.967
***[2020-01-29 07:20:32]*** TRAIN [epoch=186/600] base-loss = 0.811223, arch-loss = 0.967296, accuracy-1 = 72.44, accuracy-5 = 97.74
[epoch=186/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.454 0.217 0.329  ||  0.2506 -0.4899 -0.0724  || discrepancy=0.12 || select=0/3
001/003-th : 0.399 0.153 0.448  ||  0.0965 -0.8643 0.2134  || discrepancy=0.05 || select=2/3
002/003-th : 0.088 0.213 0.699  ||  -1.0764 -0.1856 1.0003  || discrepancy=0.49 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.084 0.104 0.120 0.142 0.156 0.163 0.174  ||  -0.715 -0.336 -0.119 0.020 0.192 0.283 0.331 0.394    || dis=0.01 || select=7/8
001/019-th : 0.135 0.130 0.132 0.135 0.123 0.117 0.117 0.113  ||  0.083 0.042 0.058 0.081 -0.015 -0.063 -0.065 -0.100   || dis=0.00 || select=0/8
002/019-th : 0.124 0.133 0.137 0.134 0.123 0.123 0.116 0.110  ||  -0.000 0.063 0.096 0.071 -0.010 -0.012 -0.068 -0.123  || dis=0.00 || select=2/8
003/019-th : 0.129 0.129 0.129 0.130 0.122 0.119 0.120 0.122  ||  0.028 0.034 0.033 0.035 -0.023 -0.054 -0.043 -0.026   || dis=0.00 || select=3/8
004/019-th : 0.118 0.120 0.123 0.126 0.127 0.128 0.131 0.127  ||  -0.058 -0.036 -0.010 0.010 0.021 0.031 0.050 0.016    || dis=0.00 || select=6/8
005/019-th : 0.120 0.123 0.122 0.123 0.123 0.131 0.125 0.131  ||  -0.042 -0.016 -0.023 -0.017 -0.019 0.045 -0.000 0.046  || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.121 0.128 0.128 0.125 0.130 0.130  ||  -0.022 -0.071 -0.024 0.026 0.032 0.005 0.045 0.047    || dis=0.00 || select=7/8
007/019-th : 0.077 0.084 0.101 0.116 0.140 0.148 0.155 0.179  ||  -0.446 -0.351 -0.170 -0.033 0.160 0.216 0.260 0.402   || dis=0.02 || select=7/8
008/019-th : 0.056 0.067 0.091 0.128 0.150 0.168 0.167 0.172  ||  -0.714 -0.539 -0.230 0.108 0.266 0.377 0.371 0.399    || dis=0.00 || select=7/8
009/019-th : 0.100 0.099 0.108 0.119 0.127 0.142 0.144 0.161  ||  -0.203 -0.211 -0.127 -0.031 0.034 0.142 0.160 0.268   || dis=0.02 || select=7/8
010/019-th : 0.106 0.112 0.118 0.130 0.129 0.136 0.137 0.132  ||  -0.162 -0.104 -0.054 0.045 0.040 0.090 0.095 0.064    || dis=0.00 || select=6/8
011/019-th : 0.111 0.102 0.107 0.118 0.122 0.133 0.147 0.159  ||  -0.110 -0.196 -0.144 -0.046 -0.014 0.075 0.175 0.252  || dis=0.01 || select=7/8
012/019-th : 0.115 0.117 0.121 0.122 0.125 0.129 0.135 0.136  ||  -0.083 -0.064 -0.036 -0.022 -0.005 0.033 0.078 0.080  || dis=0.00 || select=7/8
013/019-th : 0.044 0.050 0.064 0.078 0.100 0.146 0.211 0.309  ||  -0.844 -0.715 -0.465 -0.267 -0.014 0.363 0.733 1.113  || dis=0.10 || select=7/8
014/019-th : 0.057 0.060 0.073 0.101 0.134 0.163 0.202 0.210  ||  -0.673 -0.619 -0.420 -0.101 0.187 0.380 0.594 0.632   || dis=0.01 || select=7/8
015/019-th : 0.039 0.042 0.057 0.079 0.110 0.143 0.227 0.304  ||  -0.935 -0.842 -0.551 -0.214 0.110 0.376 0.841 1.130   || dis=0.08 || select=7/8
016/019-th : 0.060 0.081 0.100 0.125 0.141 0.158 0.166 0.170  ||  -0.673 -0.373 -0.164 0.053 0.174 0.288 0.339 0.362    || dis=0.00 || select=7/8
017/019-th : 0.127 0.123 0.124 0.123 0.126 0.123 0.126 0.128  ||  0.012 -0.018 -0.009 -0.013 0.010 -0.013 0.008 0.022   || dis=0.00 || select=7/8
018/019-th : 0.091 0.108 0.110 0.125 0.129 0.132 0.147 0.158  ||  -0.299 -0.135 -0.114 0.012 0.048 0.073 0.174 0.252    || dis=0.01 || select=7/8
[epoch=186/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.043
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:20:33] [epoch=186/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 2.044 (2.044)  Prec@1 45.31 (45.31) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:20:39] [epoch=186/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.312 (2.277)  Prec@1 33.93 (38.46) Prec@5 79.76 (81.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.46 Prec@5 81.53 Error@1 61.54 Error@5 18.47 Loss:2.277
***[2020-01-29 07:20:39]*** VALID [epoch=186/600] loss = 2.277035, accuracy@1 = 38.46, accuracy@5 = 81.53 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:20:39]*** start epoch=187/600 Time Left: [03:39:58], LR=[0.077887 ~ 0.077887], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=187, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.9164755170002414, FLOP=40.81
[Search] : epoch=187/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:20:39] [epoch=187/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.837 (0.837)  Prec@1 72.27 (72.27) Prec@5 97.27 (97.27) Acls-loss 0.993 (0.993) FLOP-Loss 0.000 (0.000) Arch-Loss 0.993 (0.993)
**TRAIN** [2020-01-29 07:21:04] [epoch=187/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.763 (0.828)  Prec@1 73.81 (71.59) Prec@5 98.81 (97.77) Acls-loss 1.042 (0.852) FLOP-Loss 0.000 (0.000) Arch-Loss 1.042 (0.852)
 **TRAIN** Prec@1 71.59 Prec@5 97.77 Error@1 28.41 Error@5 2.23 Base-Loss:0.828, Arch-Loss=0.852
***[2020-01-29 07:21:04]*** TRAIN [epoch=187/600] base-loss = 0.828187, arch-loss = 0.852478, accuracy-1 = 71.59, accuracy-5 = 97.77
[epoch=187/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 9, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.050624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.453 0.217 0.330  ||  0.2471 -0.4893 -0.0680  || discrepancy=0.12 || select=0/3
001/003-th : 0.397 0.153 0.449  ||  0.0942 -0.8578 0.2163  || discrepancy=0.05 || select=2/3
002/003-th : 0.086 0.211 0.703  ||  -1.0933 -0.1898 1.0132  || discrepancy=0.49 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.104 0.119 0.141 0.158 0.163 0.174  ||  -0.716 -0.344 -0.123 0.019 0.187 0.298 0.332 0.397    || dis=0.01 || select=7/8
001/019-th : 0.135 0.129 0.132 0.134 0.122 0.118 0.117 0.113  ||  0.078 0.036 0.056 0.076 -0.019 -0.057 -0.059 -0.094   || dis=0.00 || select=0/8
002/019-th : 0.124 0.132 0.136 0.133 0.123 0.124 0.117 0.111  ||  -0.004 0.060 0.085 0.062 -0.010 -0.006 -0.063 -0.117  || dis=0.00 || select=2/8
003/019-th : 0.128 0.129 0.129 0.129 0.123 0.119 0.120 0.122  ||  0.024 0.028 0.031 0.031 -0.014 -0.048 -0.039 -0.022   || dis=0.00 || select=3/8
004/019-th : 0.118 0.120 0.123 0.123 0.126 0.129 0.132 0.128  ||  -0.060 -0.041 -0.012 -0.013 0.011 0.031 0.054 0.028   || dis=0.00 || select=6/8
005/019-th : 0.120 0.123 0.123 0.123 0.123 0.131 0.126 0.132  ||  -0.044 -0.020 -0.022 -0.018 -0.021 0.043 0.002 0.051  || dis=0.00 || select=7/8
006/019-th : 0.121 0.115 0.121 0.127 0.129 0.125 0.131 0.131  ||  -0.026 -0.076 -0.025 0.018 0.034 0.002 0.049 0.053    || dis=0.00 || select=7/8
007/019-th : 0.076 0.083 0.099 0.115 0.142 0.150 0.156 0.179  ||  -0.451 -0.358 -0.186 -0.035 0.174 0.228 0.266 0.406   || dis=0.02 || select=7/8
008/019-th : 0.057 0.067 0.092 0.128 0.148 0.168 0.168 0.173  ||  -0.712 -0.545 -0.229 0.104 0.250 0.375 0.377 0.405    || dis=0.00 || select=7/8
009/019-th : 0.100 0.099 0.107 0.118 0.130 0.140 0.145 0.161  ||  -0.208 -0.212 -0.135 -0.041 0.056 0.134 0.169 0.272   || dis=0.02 || select=7/8
010/019-th : 0.105 0.112 0.117 0.131 0.128 0.137 0.137 0.132  ||  -0.164 -0.107 -0.058 0.050 0.031 0.100 0.099 0.064    || dis=0.00 || select=5/8
011/019-th : 0.110 0.102 0.107 0.117 0.124 0.133 0.148 0.160  ||  -0.118 -0.196 -0.147 -0.057 0.001 0.076 0.182 0.256   || dis=0.01 || select=7/8
012/019-th : 0.114 0.117 0.121 0.122 0.124 0.130 0.135 0.136  ||  -0.089 -0.068 -0.031 -0.023 -0.006 0.036 0.079 0.086  || dis=0.00 || select=7/8
013/019-th : 0.043 0.049 0.063 0.078 0.101 0.144 0.211 0.311  ||  -0.852 -0.716 -0.479 -0.264 -0.006 0.355 0.733 1.122  || dis=0.10 || select=7/8
014/019-th : 0.057 0.060 0.073 0.101 0.133 0.163 0.202 0.211  ||  -0.677 -0.623 -0.421 -0.099 0.178 0.380 0.597 0.638   || dis=0.01 || select=7/8
015/019-th : 0.038 0.042 0.056 0.078 0.109 0.143 0.229 0.304  ||  -0.943 -0.850 -0.550 -0.221 0.111 0.378 0.851 1.136   || dis=0.07 || select=7/8
016/019-th : 0.060 0.080 0.099 0.125 0.141 0.158 0.166 0.170  ||  -0.682 -0.382 -0.172 0.060 0.182 0.293 0.341 0.368    || dis=0.00 || select=7/8
017/019-th : 0.126 0.123 0.123 0.124 0.125 0.124 0.127 0.129  ||  0.006 -0.021 -0.017 -0.009 -0.004 -0.007 0.012 0.030  || dis=0.00 || select=7/8
018/019-th : 0.091 0.107 0.109 0.124 0.132 0.132 0.148 0.159  ||  -0.303 -0.143 -0.122 0.009 0.067 0.070 0.183 0.254    || dis=0.01 || select=7/8
[epoch=187/600] FLOP : 27.05 MB, ratio : 0.6628, Expected-ratio : 0.7000, Discrepancy : 0.043
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:21:04] [epoch=187/600][000/098] Time 0.57 (0.57) Data 0.41 (0.41) Loss 4.724 (4.724)  Prec@1 29.30 (29.30) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:21:10] [epoch=187/600][097/098] Time 0.06 (0.07) Data 0.00 (0.01) Loss 2.955 (2.576)  Prec@1 35.12 (37.65) Prec@5 78.57 (81.73) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.65 Prec@5 81.73 Error@1 62.35 Error@5 18.27 Loss:2.576
***[2020-01-29 07:21:10]*** VALID [epoch=187/600] loss = 2.575884, accuracy@1 = 37.65, accuracy@5 = 81.73 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:21:10]*** start epoch=188/600 Time Left: [03:39:25], LR=[0.077670 ~ 0.077670], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=188, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.9058092956461934, FLOP=40.81
[Search] : epoch=188/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:21:11] [epoch=188/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.837 (0.837)  Prec@1 70.31 (70.31) Prec@5 97.66 (97.66) Acls-loss 0.678 (0.678) FLOP-Loss 0.000 (0.000) Arch-Loss 0.678 (0.678)
**TRAIN** [2020-01-29 07:21:35] [epoch=188/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.873 (0.827)  Prec@1 70.24 (71.70) Prec@5 98.21 (97.68) Acls-loss 1.254 (0.843) FLOP-Loss 0.000 (0.000) Arch-Loss 1.254 (0.843)
 **TRAIN** Prec@1 71.70 Prec@5 97.68 Error@1 28.30 Error@5 2.32 Base-Loss:0.827, Arch-Loss=0.843
***[2020-01-29 07:21:35]*** TRAIN [epoch=188/600] base-loss = 0.827058, arch-loss = 0.842712, accuracy-1 = 71.70, accuracy-5 = 97.68
[epoch=188/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 6, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.156544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.451 0.217 0.332  ||  0.2436 -0.4889 -0.0635  || discrepancy=0.12 || select=0/3
001/003-th : 0.396 0.153 0.451  ||  0.0901 -0.8616 0.2217  || discrepancy=0.05 || select=2/3
002/003-th : 0.084 0.209 0.707  ||  -1.1046 -0.1969 1.0238  || discrepancy=0.50 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.082 0.103 0.118 0.143 0.159 0.164 0.175  ||  -0.715 -0.356 -0.128 0.005 0.201 0.305 0.335 0.402    || dis=0.01 || select=7/8
001/019-th : 0.134 0.129 0.132 0.134 0.123 0.118 0.118 0.113  ||  0.071 0.035 0.056 0.076 -0.011 -0.054 -0.056 -0.092   || dis=0.00 || select=3/8
002/019-th : 0.123 0.132 0.135 0.132 0.124 0.125 0.118 0.111  ||  -0.010 0.055 0.080 0.054 -0.009 0.003 -0.056 -0.112   || dis=0.00 || select=2/8
003/019-th : 0.128 0.128 0.128 0.127 0.125 0.120 0.121 0.123  ||  0.020 0.026 0.025 0.018 -0.004 -0.041 -0.035 -0.019   || dis=0.00 || select=1/8
004/019-th : 0.117 0.119 0.123 0.123 0.127 0.129 0.133 0.129  ||  -0.067 -0.045 -0.012 -0.019 0.014 0.033 0.061 0.032   || dis=0.00 || select=6/8
005/019-th : 0.120 0.122 0.123 0.123 0.122 0.130 0.126 0.133  ||  -0.047 -0.028 -0.017 -0.019 -0.028 0.037 0.007 0.060  || dis=0.00 || select=7/8
006/019-th : 0.121 0.115 0.121 0.126 0.130 0.125 0.130 0.132  ||  -0.031 -0.078 -0.030 0.014 0.045 0.005 0.047 0.059    || dis=0.00 || select=7/8
007/019-th : 0.076 0.084 0.098 0.115 0.140 0.150 0.156 0.182  ||  -0.456 -0.357 -0.201 -0.039 0.161 0.228 0.268 0.420   || dis=0.03 || select=7/8
008/019-th : 0.056 0.066 0.091 0.129 0.147 0.167 0.170 0.175  ||  -0.730 -0.552 -0.236 0.110 0.245 0.369 0.390 0.416    || dis=0.00 || select=7/8
009/019-th : 0.099 0.099 0.108 0.119 0.128 0.141 0.144 0.162  ||  -0.210 -0.214 -0.130 -0.033 0.040 0.139 0.163 0.275   || dis=0.02 || select=7/8
010/019-th : 0.104 0.110 0.118 0.132 0.130 0.138 0.136 0.133  ||  -0.173 -0.116 -0.053 0.062 0.045 0.105 0.093 0.069    || dis=0.00 || select=5/8
011/019-th : 0.109 0.102 0.106 0.116 0.123 0.134 0.149 0.160  ||  -0.127 -0.189 -0.152 -0.065 -0.007 0.081 0.188 0.260  || dis=0.01 || select=7/8
012/019-th : 0.113 0.116 0.120 0.121 0.125 0.132 0.136 0.136  ||  -0.097 -0.073 -0.038 -0.028 0.001 0.052 0.084 0.088   || dis=0.00 || select=7/8
013/019-th : 0.043 0.049 0.062 0.078 0.101 0.145 0.210 0.312  ||  -0.855 -0.722 -0.482 -0.265 0.003 0.357 0.732 1.126   || dis=0.10 || select=7/8
014/019-th : 0.056 0.060 0.073 0.101 0.132 0.163 0.203 0.212  ||  -0.682 -0.623 -0.421 -0.098 0.170 0.378 0.597 0.642   || dis=0.01 || select=7/8
015/019-th : 0.037 0.042 0.055 0.078 0.109 0.144 0.230 0.305  ||  -0.955 -0.852 -0.572 -0.220 0.112 0.390 0.860 1.144   || dis=0.07 || select=7/8
016/019-th : 0.059 0.080 0.100 0.124 0.142 0.157 0.168 0.171  ||  -0.691 -0.392 -0.166 0.054 0.184 0.287 0.354 0.371    || dis=0.00 || select=7/8
017/019-th : 0.125 0.122 0.122 0.123 0.125 0.125 0.127 0.130  ||  0.001 -0.025 -0.024 -0.018 -0.000 0.001 0.016 0.036   || dis=0.00 || select=7/8
018/019-th : 0.090 0.106 0.109 0.124 0.131 0.132 0.148 0.159  ||  -0.311 -0.147 -0.121 0.010 0.064 0.072 0.186 0.259    || dis=0.01 || select=7/8
[epoch=188/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:21:35] [epoch=188/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.468 (1.468)  Prec@1 46.09 (46.09) Prec@5 90.62 (90.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:21:41] [epoch=188/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.261 (2.186)  Prec@1 55.95 (38.70) Prec@5 92.26 (82.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.70 Prec@5 82.58 Error@1 61.30 Error@5 17.42 Loss:2.186
***[2020-01-29 07:21:41]*** VALID [epoch=188/600] loss = 2.185837, accuracy@1 = 38.70, accuracy@5 = 82.58 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:21:41]*** start epoch=189/600 Time Left: [03:38:51], LR=[0.077451 ~ 0.077451], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=189, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.8951059040954235, FLOP=40.81
[Search] : epoch=189/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:21:42] [epoch=189/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.875 (0.875)  Prec@1 67.97 (67.97) Prec@5 98.05 (98.05) Acls-loss 0.770 (0.770) FLOP-Loss 0.000 (0.000) Arch-Loss 0.770 (0.770)
**TRAIN** [2020-01-29 07:22:06] [epoch=189/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.764 (0.843)  Prec@1 71.43 (71.24) Prec@5 97.62 (97.77) Acls-loss 0.867 (0.866) FLOP-Loss 0.000 (0.000) Arch-Loss 0.867 (0.866)
 **TRAIN** Prec@1 71.24 Prec@5 97.77 Error@1 28.76 Error@5 2.23 Base-Loss:0.843, Arch-Loss=0.866
***[2020-01-29 07:22:06]*** TRAIN [epoch=189/600] base-loss = 0.842502, arch-loss = 0.866283, accuracy-1 = 71.24, accuracy-5 = 97.77
[epoch=189/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 8, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.156544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.217 0.334  ||  0.2393 -0.4882 -0.0582  || discrepancy=0.11 || select=0/3
001/003-th : 0.394 0.152 0.454  ||  0.0849 -0.8651 0.2280  || discrepancy=0.06 || select=2/3
002/003-th : 0.083 0.206 0.711  ||  -1.1158 -0.2031 1.0340  || discrepancy=0.51 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.082 0.103 0.116 0.144 0.158 0.165 0.175  ||  -0.715 -0.352 -0.126 -0.009 0.205 0.299 0.341 0.401   || dis=0.01 || select=7/8
001/019-th : 0.133 0.128 0.132 0.134 0.123 0.118 0.118 0.114  ||  0.066 0.029 0.058 0.075 -0.009 -0.052 -0.054 -0.086   || dis=0.00 || select=3/8
002/019-th : 0.123 0.131 0.135 0.131 0.124 0.126 0.118 0.112  ||  -0.016 0.050 0.078 0.051 -0.005 0.007 -0.051 -0.107   || dis=0.00 || select=2/8
003/019-th : 0.127 0.127 0.128 0.127 0.125 0.120 0.121 0.124  ||  0.014 0.018 0.026 0.016 -0.002 -0.038 -0.030 -0.012   || dis=0.00 || select=2/8
004/019-th : 0.116 0.119 0.123 0.123 0.128 0.129 0.133 0.129  ||  -0.071 -0.047 -0.016 -0.018 0.024 0.031 0.061 0.036   || dis=0.00 || select=6/8
005/019-th : 0.119 0.121 0.123 0.124 0.122 0.130 0.127 0.134  ||  -0.050 -0.036 -0.017 -0.014 -0.026 0.038 0.010 0.065  || dis=0.00 || select=7/8
006/019-th : 0.120 0.114 0.121 0.126 0.130 0.124 0.131 0.133  ||  -0.038 -0.083 -0.026 0.017 0.047 -0.001 0.051 0.064   || dis=0.00 || select=7/8
007/019-th : 0.075 0.084 0.096 0.116 0.141 0.149 0.157 0.183  ||  -0.465 -0.355 -0.215 -0.029 0.164 0.224 0.274 0.425   || dis=0.03 || select=7/8
008/019-th : 0.054 0.066 0.091 0.128 0.148 0.166 0.172 0.175  ||  -0.752 -0.555 -0.228 0.106 0.256 0.368 0.404 0.418    || dis=0.00 || select=7/8
009/019-th : 0.098 0.099 0.109 0.119 0.126 0.141 0.145 0.163  ||  -0.221 -0.215 -0.121 -0.035 0.028 0.135 0.167 0.283   || dis=0.02 || select=7/8
010/019-th : 0.104 0.109 0.116 0.132 0.131 0.138 0.136 0.133  ||  -0.175 -0.129 -0.062 0.066 0.055 0.111 0.098 0.074    || dis=0.00 || select=5/8
011/019-th : 0.108 0.102 0.106 0.116 0.125 0.134 0.149 0.160  ||  -0.135 -0.195 -0.150 -0.062 0.009 0.083 0.192 0.262   || dis=0.01 || select=7/8
012/019-th : 0.112 0.115 0.120 0.121 0.125 0.133 0.137 0.137  ||  -0.104 -0.078 -0.043 -0.034 0.005 0.063 0.090 0.093   || dis=0.00 || select=7/8
013/019-th : 0.043 0.048 0.061 0.077 0.102 0.143 0.211 0.314  ||  -0.857 -0.733 -0.496 -0.267 0.013 0.351 0.739 1.135   || dis=0.10 || select=7/8
014/019-th : 0.056 0.060 0.074 0.101 0.129 0.164 0.204 0.213  ||  -0.692 -0.620 -0.415 -0.097 0.142 0.383 0.601 0.649   || dis=0.01 || select=7/8
015/019-th : 0.037 0.041 0.054 0.078 0.109 0.143 0.229 0.308  ||  -0.953 -0.873 -0.580 -0.215 0.117 0.386 0.860 1.157   || dis=0.08 || select=7/8
016/019-th : 0.059 0.079 0.099 0.124 0.143 0.157 0.169 0.171  ||  -0.697 -0.400 -0.171 0.052 0.194 0.291 0.360 0.374    || dis=0.00 || select=7/8
017/019-th : 0.124 0.122 0.123 0.121 0.125 0.127 0.129 0.130  ||  -0.008 -0.029 -0.021 -0.032 -0.000 0.011 0.026 0.039  || dis=0.00 || select=7/8
018/019-th : 0.090 0.105 0.108 0.125 0.131 0.131 0.148 0.162  ||  -0.311 -0.157 -0.130 0.017 0.063 0.063 0.182 0.274    || dis=0.01 || select=7/8
[epoch=189/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:22:06] [epoch=189/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.565 (2.565)  Prec@1 22.66 (22.66) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:22:12] [epoch=189/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.081 (2.150)  Prec@1 33.93 (35.68) Prec@5 77.98 (80.37) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.68 Prec@5 80.37 Error@1 64.32 Error@5 19.63 Loss:2.150
***[2020-01-29 07:22:12]*** VALID [epoch=189/600] loss = 2.149524, accuracy@1 = 35.68, accuracy@5 = 80.37 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:22:12]*** start epoch=190/600 Time Left: [03:38:18], LR=[0.077232 ~ 0.077232], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=190, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.884365635786817, FLOP=40.81
[Search] : epoch=190/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:22:13] [epoch=190/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.786 (0.786)  Prec@1 71.88 (71.88) Prec@5 97.27 (97.27) Acls-loss 0.883 (0.883) FLOP-Loss 0.000 (0.000) Arch-Loss 0.883 (0.883)
**TRAIN** [2020-01-29 07:22:37] [epoch=190/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.847 (0.822)  Prec@1 72.02 (72.15) Prec@5 98.21 (97.74) Acls-loss 0.861 (0.842) FLOP-Loss 0.000 (0.135) Arch-Loss 0.861 (1.113)
 **TRAIN** Prec@1 72.15 Prec@5 97.74 Error@1 27.85 Error@5 2.26 Base-Loss:0.822, Arch-Loss=1.113
***[2020-01-29 07:22:37]*** TRAIN [epoch=190/600] base-loss = 0.821574, arch-loss = 1.113060, accuracy-1 = 72.15, accuracy-5 = 97.74
[epoch=190/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 8, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.156544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.453 0.217 0.330  ||  0.2495 -0.4871 -0.0682  || discrepancy=0.12 || select=0/3
001/003-th : 0.397 0.153 0.451  ||  0.0933 -0.8627 0.2208  || discrepancy=0.05 || select=2/3
002/003-th : 0.082 0.208 0.710  ||  -1.1212 -0.1951 1.0350  || discrepancy=0.50 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.084 0.103 0.117 0.142 0.160 0.163 0.174  ||  -0.720 -0.333 -0.124 0.002 0.192 0.310 0.328 0.394    || dis=0.01 || select=7/8
001/019-th : 0.134 0.129 0.133 0.134 0.122 0.118 0.117 0.113  ||  0.075 0.039 0.063 0.076 -0.020 -0.056 -0.062 -0.095   || dis=0.00 || select=3/8
002/019-th : 0.124 0.133 0.136 0.131 0.124 0.125 0.117 0.111  ||  -0.010 0.061 0.084 0.052 -0.010 0.000 -0.061 -0.114   || dis=0.00 || select=2/8
003/019-th : 0.128 0.128 0.129 0.127 0.124 0.120 0.120 0.123  ||  0.025 0.024 0.030 0.018 -0.007 -0.042 -0.040 -0.020   || dis=0.00 || select=2/8
004/019-th : 0.117 0.120 0.124 0.125 0.128 0.128 0.131 0.128  ||  -0.062 -0.041 -0.008 -0.001 0.025 0.025 0.051 0.025   || dis=0.00 || select=6/8
005/019-th : 0.120 0.122 0.124 0.125 0.123 0.129 0.125 0.132  ||  -0.042 -0.024 -0.011 -0.004 -0.016 0.029 0.001 0.052  || dis=0.00 || select=7/8
006/019-th : 0.121 0.115 0.122 0.128 0.129 0.124 0.130 0.131  ||  -0.027 -0.078 -0.021 0.025 0.038 -0.001 0.046 0.052   || dis=0.00 || select=7/8
007/019-th : 0.075 0.084 0.097 0.117 0.141 0.150 0.155 0.180  ||  -0.458 -0.349 -0.203 -0.022 0.165 0.230 0.263 0.412   || dis=0.02 || select=7/8
008/019-th : 0.054 0.066 0.093 0.129 0.149 0.165 0.171 0.174  ||  -0.754 -0.553 -0.216 0.117 0.260 0.360 0.395 0.413    || dis=0.00 || select=7/8
009/019-th : 0.099 0.100 0.110 0.119 0.129 0.138 0.143 0.162  ||  -0.219 -0.207 -0.111 -0.028 0.049 0.114 0.156 0.279   || dis=0.02 || select=7/8
010/019-th : 0.104 0.109 0.116 0.131 0.133 0.138 0.137 0.132  ||  -0.170 -0.126 -0.066 0.055 0.072 0.106 0.099 0.068    || dis=0.00 || select=5/8
011/019-th : 0.109 0.102 0.107 0.116 0.125 0.134 0.148 0.158  ||  -0.127 -0.186 -0.141 -0.061 0.012 0.084 0.184 0.248   || dis=0.01 || select=7/8
012/019-th : 0.113 0.116 0.120 0.121 0.125 0.133 0.136 0.136  ||  -0.099 -0.075 -0.038 -0.031 0.002 0.060 0.086 0.088   || dis=0.00 || select=7/8
013/019-th : 0.043 0.048 0.062 0.076 0.104 0.141 0.212 0.314  ||  -0.844 -0.740 -0.489 -0.282 0.027 0.339 0.744 1.134   || dis=0.10 || select=7/8
014/019-th : 0.056 0.061 0.074 0.101 0.129 0.164 0.202 0.214  ||  -0.686 -0.612 -0.413 -0.101 0.141 0.382 0.593 0.648   || dis=0.01 || select=7/8
015/019-th : 0.037 0.041 0.055 0.080 0.110 0.142 0.227 0.309  ||  -0.959 -0.874 -0.574 -0.197 0.124 0.379 0.846 1.155   || dis=0.08 || select=7/8
016/019-th : 0.059 0.079 0.100 0.123 0.143 0.159 0.168 0.169  ||  -0.691 -0.392 -0.159 0.047 0.193 0.299 0.354 0.364    || dis=0.00 || select=7/8
017/019-th : 0.125 0.122 0.123 0.122 0.125 0.126 0.127 0.129  ||  -0.000 -0.021 -0.014 -0.027 0.001 0.005 0.017 0.029   || dis=0.00 || select=7/8
018/019-th : 0.090 0.107 0.109 0.126 0.131 0.131 0.146 0.161  ||  -0.317 -0.143 -0.122 0.026 0.060 0.062 0.174 0.270    || dis=0.02 || select=7/8
[epoch=190/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:22:38] [epoch=190/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.047 (2.047)  Prec@1 30.47 (30.47) Prec@5 77.34 (77.34) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:22:44] [epoch=190/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.277 (2.052)  Prec@1 57.14 (40.35) Prec@5 95.24 (83.29) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.35 Prec@5 83.29 Error@1 59.65 Error@5 16.71 Loss:2.052
***[2020-01-29 07:22:44]*** VALID [epoch=190/600] loss = 2.052463, accuracy@1 = 40.35, accuracy@5 = 83.29 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:22:44]*** start epoch=191/600 Time Left: [03:37:44], LR=[0.077012 ~ 0.077012], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=191, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.8735887851702553, FLOP=40.81
[Search] : epoch=191/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:22:44] [epoch=191/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.792 (0.792)  Prec@1 72.27 (72.27) Prec@5 99.22 (99.22) Acls-loss 0.955 (0.955) FLOP-Loss 0.000 (0.000) Arch-Loss 0.955 (0.955)
**TRAIN** [2020-01-29 07:23:08] [epoch=191/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.793 (0.816)  Prec@1 72.62 (72.22) Prec@5 97.02 (97.72) Acls-loss 0.829 (0.843) FLOP-Loss 0.000 (0.081) Arch-Loss 0.829 (1.005)
 **TRAIN** Prec@1 72.22 Prec@5 97.72 Error@1 27.78 Error@5 2.28 Base-Loss:0.816, Arch-Loss=1.005
***[2020-01-29 07:23:08]*** TRAIN [epoch=191/600] base-loss = 0.815700, arch-loss = 1.005412, accuracy-1 = 72.22, accuracy-5 = 97.72
[epoch=191/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 8, 14, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.156544)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.454 0.218 0.328  ||  0.2530 -0.4821 -0.0715  || discrepancy=0.13 || select=0/3
001/003-th : 0.398 0.152 0.449  ||  0.0976 -0.8650 0.2178  || discrepancy=0.05 || select=2/3
002/003-th : 0.081 0.208 0.711  ||  -1.1313 -0.1884 1.0395  || discrepancy=0.50 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.104 0.117 0.143 0.160 0.164 0.173  ||  -0.723 -0.342 -0.119 -0.002 0.198 0.312 0.335 0.393   || dis=0.01 || select=7/8
001/019-th : 0.134 0.130 0.134 0.134 0.121 0.117 0.117 0.113  ||  0.076 0.044 0.072 0.078 -0.025 -0.057 -0.064 -0.100   || dis=0.00 || select=3/8
002/019-th : 0.123 0.133 0.136 0.131 0.124 0.124 0.117 0.111  ||  -0.010 0.066 0.084 0.051 -0.009 -0.002 -0.064 -0.114  || dis=0.00 || select=2/8
003/019-th : 0.129 0.128 0.129 0.127 0.124 0.120 0.120 0.122  ||  0.030 0.023 0.032 0.017 -0.006 -0.044 -0.039 -0.024   || dis=0.00 || select=2/8
004/019-th : 0.117 0.120 0.124 0.126 0.129 0.127 0.131 0.127  ||  -0.061 -0.036 -0.005 0.009 0.032 0.023 0.050 0.016    || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.124 0.125 0.123 0.130 0.125 0.131  ||  -0.040 -0.030 -0.005 0.004 -0.016 0.042 -0.002 0.046  || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.122 0.129 0.128 0.124 0.129 0.130  ||  -0.022 -0.071 -0.020 0.037 0.029 -0.001 0.038 0.045   || dis=0.00 || select=7/8
007/019-th : 0.075 0.084 0.098 0.116 0.141 0.150 0.155 0.180  ||  -0.463 -0.351 -0.199 -0.026 0.170 0.227 0.264 0.414   || dis=0.02 || select=7/8
008/019-th : 0.054 0.066 0.092 0.131 0.149 0.164 0.170 0.174  ||  -0.750 -0.550 -0.228 0.133 0.258 0.353 0.391 0.413    || dis=0.00 || select=7/8
009/019-th : 0.099 0.101 0.110 0.119 0.128 0.137 0.144 0.162  ||  -0.213 -0.198 -0.109 -0.035 0.039 0.107 0.155 0.275   || dis=0.02 || select=7/8
010/019-th : 0.105 0.109 0.116 0.130 0.134 0.137 0.137 0.132  ||  -0.166 -0.124 -0.069 0.048 0.075 0.104 0.102 0.064    || dis=0.00 || select=5/8
011/019-th : 0.109 0.104 0.106 0.115 0.125 0.134 0.148 0.158  ||  -0.126 -0.174 -0.148 -0.067 0.015 0.080 0.181 0.248   || dis=0.01 || select=7/8
012/019-th : 0.113 0.117 0.120 0.121 0.124 0.132 0.136 0.136  ||  -0.098 -0.069 -0.036 -0.035 -0.005 0.058 0.082 0.088  || dis=0.00 || select=7/8
013/019-th : 0.043 0.049 0.062 0.076 0.104 0.140 0.212 0.314  ||  -0.844 -0.731 -0.484 -0.287 0.028 0.325 0.744 1.136   || dis=0.10 || select=7/8
014/019-th : 0.056 0.061 0.073 0.101 0.130 0.161 0.202 0.214  ||  -0.684 -0.606 -0.425 -0.100 0.153 0.367 0.592 0.651   || dis=0.01 || select=7/8
015/019-th : 0.037 0.041 0.054 0.080 0.112 0.141 0.227 0.308  ||  -0.955 -0.870 -0.583 -0.201 0.140 0.374 0.848 1.153   || dis=0.08 || select=7/8
016/019-th : 0.059 0.079 0.100 0.125 0.142 0.159 0.168 0.168  ||  -0.691 -0.394 -0.162 0.059 0.190 0.304 0.356 0.359    || dis=0.00 || select=7/8
017/019-th : 0.125 0.123 0.123 0.123 0.125 0.126 0.127 0.129  ||  0.002 -0.018 -0.019 -0.019 0.002 0.003 0.013 0.029    || dis=0.00 || select=7/8
018/019-th : 0.089 0.107 0.110 0.126 0.131 0.130 0.146 0.161  ||  -0.318 -0.142 -0.115 0.026 0.066 0.059 0.170 0.268    || dis=0.02 || select=7/8
[epoch=191/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:23:09] [epoch=191/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.344 (3.344)  Prec@1 29.69 (29.69) Prec@5 75.78 (75.78) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:23:15] [epoch=191/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.415 (2.233)  Prec@1 23.81 (35.52) Prec@5 75.60 (80.98) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.52 Prec@5 80.98 Error@1 64.48 Error@5 19.02 Loss:2.233
***[2020-01-29 07:23:15]*** VALID [epoch=191/600] loss = 2.233076, accuracy@1 = 35.52, accuracy@5 = 80.98 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:23:15]*** start epoch=192/600 Time Left: [03:37:10], LR=[0.076791 ~ 0.076791], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=192, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.862775647698542, FLOP=40.81
[Search] : epoch=192/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:23:15] [epoch=192/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.853 (0.853)  Prec@1 73.05 (73.05) Prec@5 97.27 (97.27) Acls-loss 0.987 (0.987) FLOP-Loss 0.000 (0.000) Arch-Loss 0.987 (0.987)
**TRAIN** [2020-01-29 07:23:39] [epoch=192/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.806 (0.828)  Prec@1 73.21 (72.01) Prec@5 98.21 (97.78) Acls-loss 0.784 (0.855) FLOP-Loss 0.000 (0.081) Arch-Loss 0.784 (1.017)
 **TRAIN** Prec@1 72.01 Prec@5 97.78 Error@1 27.99 Error@5 2.22 Base-Loss:0.828, Arch-Loss=1.017
***[2020-01-29 07:23:39]*** TRAIN [epoch=192/600] base-loss = 0.827678, arch-loss = 1.016694, accuracy-1 = 72.01, accuracy-5 = 97.78
[epoch=192/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 8, 14, 16, 9, 32, 32, 32, 25, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.992832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.456 0.217 0.327  ||  0.2571 -0.4858 -0.0747  || discrepancy=0.13 || select=0/3
001/003-th : 0.401 0.150 0.449  ||  0.1015 -0.8803 0.2161  || discrepancy=0.05 || select=2/3
002/003-th : 0.080 0.208 0.713  ||  -1.1449 -0.1856 1.0477  || discrepancy=0.51 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.084 0.103 0.117 0.141 0.161 0.165 0.172  ||  -0.711 -0.333 -0.132 -0.003 0.186 0.317 0.343 0.384   || dis=0.01 || select=7/8
001/019-th : 0.135 0.131 0.132 0.135 0.122 0.118 0.116 0.112  ||  0.080 0.049 0.063 0.079 -0.022 -0.055 -0.069 -0.104   || dis=0.00 || select=0/8
002/019-th : 0.124 0.133 0.136 0.132 0.124 0.124 0.117 0.111  ||  -0.007 0.068 0.085 0.055 -0.002 -0.007 -0.067 -0.118  || dis=0.00 || select=2/8
003/019-th : 0.129 0.128 0.130 0.128 0.124 0.120 0.120 0.122  ||  0.032 0.023 0.039 0.025 -0.011 -0.045 -0.043 -0.027   || dis=0.00 || select=2/8
004/019-th : 0.117 0.120 0.125 0.126 0.129 0.127 0.131 0.126  ||  -0.060 -0.035 0.005 0.009 0.033 0.022 0.049 0.010     || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.126 0.126 0.123 0.130 0.124 0.131  ||  -0.038 -0.032 0.008 0.006 -0.016 0.039 -0.007 0.045   || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.122 0.130 0.128 0.124 0.129 0.129  ||  -0.018 -0.069 -0.015 0.043 0.028 -0.003 0.034 0.039   || dis=0.00 || select=3/8
007/019-th : 0.076 0.084 0.098 0.117 0.141 0.149 0.155 0.180  ||  -0.455 -0.352 -0.195 -0.023 0.165 0.222 0.260 0.411   || dis=0.02 || select=7/8
008/019-th : 0.055 0.066 0.091 0.133 0.148 0.165 0.170 0.172  ||  -0.739 -0.551 -0.229 0.145 0.253 0.358 0.390 0.401    || dis=0.00 || select=7/8
009/019-th : 0.101 0.101 0.111 0.118 0.127 0.136 0.144 0.162  ||  -0.204 -0.202 -0.107 -0.043 0.032 0.101 0.155 0.276   || dis=0.02 || select=7/8
010/019-th : 0.106 0.111 0.115 0.128 0.132 0.138 0.138 0.132  ||  -0.162 -0.116 -0.073 0.034 0.064 0.104 0.103 0.065    || dis=0.00 || select=5/8
011/019-th : 0.109 0.104 0.107 0.116 0.125 0.134 0.148 0.157  ||  -0.128 -0.171 -0.147 -0.063 0.014 0.081 0.182 0.243   || dis=0.01 || select=7/8
012/019-th : 0.114 0.116 0.121 0.123 0.122 0.133 0.136 0.136  ||  -0.095 -0.074 -0.032 -0.019 -0.023 0.060 0.086 0.085  || dis=0.00 || select=6/8
013/019-th : 0.043 0.049 0.063 0.076 0.103 0.141 0.211 0.314  ||  -0.843 -0.729 -0.479 -0.278 0.019 0.330 0.737 1.135   || dis=0.10 || select=7/8
014/019-th : 0.056 0.061 0.074 0.101 0.132 0.160 0.201 0.215  ||  -0.684 -0.606 -0.419 -0.106 0.163 0.359 0.585 0.655   || dis=0.01 || select=7/8
015/019-th : 0.038 0.040 0.055 0.079 0.112 0.141 0.228 0.308  ||  -0.945 -0.887 -0.574 -0.212 0.146 0.374 0.852 1.154   || dis=0.08 || select=7/8
016/019-th : 0.059 0.080 0.100 0.125 0.143 0.158 0.167 0.168  ||  -0.687 -0.390 -0.160 0.065 0.193 0.293 0.352 0.356    || dis=0.00 || select=7/8
017/019-th : 0.126 0.123 0.122 0.123 0.126 0.125 0.127 0.129  ||  0.003 -0.013 -0.025 -0.019 0.010 -0.003 0.014 0.027   || dis=0.00 || select=7/8
018/019-th : 0.090 0.108 0.109 0.127 0.132 0.129 0.145 0.161  ||  -0.318 -0.128 -0.124 0.030 0.067 0.045 0.166 0.270    || dis=0.02 || select=7/8
[epoch=192/600] FLOP : 25.99 MB, ratio : 0.6369, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:23:40] [epoch=192/600][000/098] Time 0.37 (0.37) Data 0.30 (0.30) Loss 2.086 (2.086)  Prec@1 36.72 (36.72) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:23:46] [epoch=192/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.740 (2.513)  Prec@1 37.50 (36.04) Prec@5 77.38 (79.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.04 Prec@5 79.60 Error@1 63.96 Error@5 20.40 Loss:2.513
***[2020-01-29 07:23:46]*** VALID [epoch=192/600] loss = 2.512748, accuracy@1 = 36.04, accuracy@5 = 79.60 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:23:46]*** start epoch=193/600 Time Left: [03:36:36], LR=[0.076570 ~ 0.076570], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=193, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.8519265198193033, FLOP=40.81
[Search] : epoch=193/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:23:46] [epoch=193/600][000/098] Time 0.75 (0.75) Data 0.34 (0.34) Base-Loss 0.891 (0.891)  Prec@1 75.78 (75.78) Prec@5 96.88 (96.88) Acls-loss 0.906 (0.906) FLOP-Loss -2.635 (-2.635) Arch-Loss -4.364 (-4.364)
**TRAIN** [2020-01-29 07:24:10] [epoch=193/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.786 (0.819)  Prec@1 72.62 (72.18) Prec@5 98.21 (97.94) Acls-loss 0.678 (0.854) FLOP-Loss 0.000 (0.054) Arch-Loss 0.678 (0.962)
 **TRAIN** Prec@1 72.18 Prec@5 97.94 Error@1 27.82 Error@5 2.06 Base-Loss:0.819, Arch-Loss=0.962
***[2020-01-29 07:24:11]*** TRAIN [epoch=193/600] base-loss = 0.819047, arch-loss = 0.962085, accuracy-1 = 72.18, accuracy-5 = 97.94
[epoch=193/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 4, 14, 16, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.457 0.216 0.327  ||  0.2588 -0.4918 -0.0751  || discrepancy=0.13 || select=0/3
001/003-th : 0.401 0.150 0.449  ||  0.1020 -0.8793 0.2167  || discrepancy=0.05 || select=2/3
002/003-th : 0.079 0.207 0.715  ||  -1.1537 -0.1862 1.0543  || discrepancy=0.51 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.085 0.104 0.117 0.137 0.160 0.165 0.174  ||  -0.710 -0.329 -0.126 -0.004 0.156 0.305 0.341 0.392   || dis=0.01 || select=7/8
001/019-th : 0.135 0.130 0.131 0.135 0.122 0.118 0.116 0.112  ||  0.080 0.047 0.053 0.081 -0.022 -0.049 -0.067 -0.104   || dis=0.00 || select=3/8
002/019-th : 0.124 0.134 0.135 0.130 0.126 0.124 0.116 0.111  ||  -0.006 0.069 0.080 0.046 0.015 -0.007 -0.069 -0.118   || dis=0.00 || select=2/8
003/019-th : 0.130 0.128 0.129 0.127 0.125 0.119 0.120 0.122  ||  0.034 0.026 0.031 0.010 -0.004 -0.047 -0.039 -0.028   || dis=0.00 || select=0/8
004/019-th : 0.116 0.119 0.126 0.125 0.130 0.126 0.131 0.126  ||  -0.066 -0.040 0.012 0.007 0.044 0.012 0.053 0.014     || dis=0.00 || select=6/8
005/019-th : 0.120 0.121 0.127 0.125 0.122 0.130 0.125 0.130  ||  -0.042 -0.030 0.016 0.001 -0.023 0.037 -0.001 0.043   || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.123 0.129 0.126 0.124 0.130 0.130  ||  -0.023 -0.071 -0.009 0.038 0.012 -0.007 0.043 0.043   || dis=0.00 || select=6/8
007/019-th : 0.075 0.084 0.098 0.118 0.138 0.150 0.156 0.181  ||  -0.469 -0.350 -0.198 -0.008 0.147 0.231 0.265 0.414   || dis=0.02 || select=7/8
008/019-th : 0.055 0.065 0.092 0.133 0.146 0.166 0.170 0.172  ||  -0.730 -0.565 -0.226 0.144 0.240 0.366 0.389 0.404    || dis=0.00 || select=7/8
009/019-th : 0.099 0.100 0.112 0.118 0.129 0.136 0.144 0.162  ||  -0.216 -0.208 -0.094 -0.041 0.051 0.100 0.157 0.277   || dis=0.02 || select=7/8
010/019-th : 0.105 0.111 0.115 0.128 0.133 0.137 0.138 0.132  ||  -0.164 -0.113 -0.079 0.033 0.071 0.098 0.108 0.063    || dis=0.00 || select=6/8
011/019-th : 0.109 0.105 0.108 0.115 0.125 0.132 0.148 0.159  ||  -0.130 -0.167 -0.139 -0.072 0.011 0.068 0.179 0.251   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.121 0.121 0.123 0.134 0.136 0.136  ||  -0.090 -0.084 -0.033 -0.030 -0.015 0.067 0.084 0.087  || dis=0.00 || select=7/8
013/019-th : 0.043 0.048 0.062 0.077 0.104 0.139 0.212 0.315  ||  -0.845 -0.747 -0.490 -0.267 0.031 0.324 0.741 1.139   || dis=0.10 || select=7/8
014/019-th : 0.056 0.061 0.072 0.101 0.132 0.162 0.202 0.214  ||  -0.685 -0.606 -0.434 -0.102 0.167 0.370 0.592 0.651   || dis=0.01 || select=7/8
015/019-th : 0.038 0.040 0.055 0.077 0.111 0.138 0.230 0.312  ||  -0.931 -0.887 -0.573 -0.233 0.135 0.356 0.863 1.168   || dis=0.08 || select=7/8
016/019-th : 0.059 0.080 0.100 0.128 0.141 0.157 0.167 0.168  ||  -0.698 -0.387 -0.163 0.086 0.179 0.290 0.353 0.358    || dis=0.00 || select=7/8
017/019-th : 0.125 0.124 0.121 0.124 0.127 0.124 0.128 0.128  ||  -0.003 -0.009 -0.032 -0.011 0.012 -0.004 0.021 0.027  || dis=0.00 || select=7/8
018/019-th : 0.090 0.108 0.110 0.126 0.132 0.128 0.145 0.161  ||  -0.313 -0.133 -0.114 0.025 0.066 0.040 0.163 0.271    || dis=0.02 || select=7/8
[epoch=193/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.044
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:24:11] [epoch=193/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.746 (1.746)  Prec@1 37.89 (37.89) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:24:17] [epoch=193/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.992 (2.242)  Prec@1 39.88 (38.36) Prec@5 92.26 (82.96) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.36 Prec@5 82.96 Error@1 61.64 Error@5 17.04 Loss:2.242
***[2020-01-29 07:24:17]*** VALID [epoch=193/600] loss = 2.241526, accuracy@1 = 38.36, accuracy@5 = 82.96 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:24:17]*** start epoch=194/600 Time Left: [03:36:03], LR=[0.076348 ~ 0.076348], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=194, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.8410416989668605, FLOP=40.81
[Search] : epoch=194/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:24:18] [epoch=194/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 1.002 (1.002)  Prec@1 67.19 (67.19) Prec@5 94.53 (94.53) Acls-loss 0.841 (0.841) FLOP-Loss 0.000 (0.000) Arch-Loss 0.841 (0.841)
**TRAIN** [2020-01-29 07:24:41] [epoch=194/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.603 (0.809)  Prec@1 79.17 (72.25) Prec@5 99.40 (97.99) Acls-loss 0.865 (0.855) FLOP-Loss 0.000 (0.000) Arch-Loss 0.865 (0.855)
 **TRAIN** Prec@1 72.25 Prec@5 97.99 Error@1 27.75 Error@5 2.01 Base-Loss:0.809, Arch-Loss=0.855
***[2020-01-29 07:24:42]*** TRAIN [epoch=194/600] base-loss = 0.808946, arch-loss = 0.854606, accuracy-1 = 72.25, accuracy-5 = 97.99
[epoch=194/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 4, 14, 16, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.329152)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.456 0.214 0.330  ||  0.2536 -0.5015 -0.0678  || discrepancy=0.13 || select=0/3
001/003-th : 0.398 0.151 0.451  ||  0.0978 -0.8741 0.2219  || discrepancy=0.05 || select=2/3
002/003-th : 0.077 0.204 0.719  ||  -1.1674 -0.1911 1.0659  || discrepancy=0.52 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.084 0.102 0.118 0.139 0.160 0.165 0.174  ||  -0.717 -0.338 -0.137 0.005 0.173 0.312 0.343 0.394    || dis=0.01 || select=7/8
001/019-th : 0.135 0.130 0.131 0.133 0.122 0.120 0.117 0.113  ||  0.077 0.041 0.049 0.067 -0.024 -0.042 -0.059 -0.099   || dis=0.00 || select=0/8
002/019-th : 0.123 0.133 0.134 0.131 0.127 0.125 0.117 0.111  ||  -0.012 0.063 0.076 0.054 0.017 0.001 -0.066 -0.114    || dis=0.00 || select=2/8
003/019-th : 0.128 0.128 0.128 0.125 0.125 0.121 0.121 0.122  ||  0.026 0.022 0.026 0.001 0.003 -0.038 -0.031 -0.022    || dis=0.00 || select=0/8
004/019-th : 0.115 0.119 0.124 0.126 0.130 0.127 0.132 0.127  ||  -0.074 -0.044 -0.002 0.009 0.042 0.021 0.061 0.020    || dis=0.00 || select=6/8
005/019-th : 0.118 0.120 0.126 0.126 0.123 0.130 0.125 0.131  ||  -0.053 -0.037 0.006 0.009 -0.013 0.042 0.005 0.051    || dis=0.00 || select=7/8
006/019-th : 0.120 0.116 0.123 0.127 0.128 0.125 0.131 0.130  ||  -0.035 -0.073 -0.012 0.022 0.031 0.003 0.051 0.046    || dis=0.00 || select=6/8
007/019-th : 0.074 0.084 0.097 0.117 0.138 0.149 0.159 0.181  ||  -0.471 -0.352 -0.204 -0.018 0.147 0.225 0.285 0.415   || dis=0.02 || select=7/8
008/019-th : 0.054 0.065 0.091 0.132 0.146 0.167 0.173 0.173  ||  -0.745 -0.566 -0.236 0.139 0.239 0.373 0.407 0.409    || dis=0.00 || select=7/8
009/019-th : 0.099 0.100 0.110 0.117 0.129 0.137 0.145 0.163  ||  -0.219 -0.208 -0.111 -0.049 0.044 0.109 0.164 0.284   || dis=0.02 || select=7/8
010/019-th : 0.105 0.110 0.114 0.126 0.136 0.137 0.139 0.132  ||  -0.169 -0.124 -0.082 0.019 0.096 0.104 0.116 0.066    || dis=0.00 || select=6/8
011/019-th : 0.108 0.104 0.106 0.114 0.125 0.133 0.149 0.161  ||  -0.137 -0.172 -0.155 -0.085 0.013 0.073 0.189 0.263   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.120 0.123 0.122 0.133 0.136 0.137  ||  -0.092 -0.086 -0.043 -0.019 -0.022 0.063 0.085 0.095  || dis=0.00 || select=7/8
013/019-th : 0.043 0.047 0.061 0.076 0.103 0.142 0.211 0.317  ||  -0.850 -0.766 -0.492 -0.277 0.024 0.351 0.742 1.152   || dis=0.11 || select=7/8
014/019-th : 0.056 0.061 0.072 0.100 0.131 0.159 0.205 0.216  ||  -0.692 -0.609 -0.434 -0.109 0.163 0.355 0.607 0.659   || dis=0.01 || select=7/8
015/019-th : 0.038 0.040 0.055 0.075 0.110 0.140 0.229 0.313  ||  -0.922 -0.883 -0.573 -0.250 0.125 0.368 0.860 1.174   || dis=0.08 || select=7/8
016/019-th : 0.058 0.079 0.099 0.127 0.141 0.159 0.168 0.168  ||  -0.707 -0.390 -0.166 0.080 0.184 0.302 0.360 0.358    || dis=0.00 || select=6/8
017/019-th : 0.124 0.123 0.120 0.123 0.127 0.125 0.128 0.130  ||  -0.009 -0.015 -0.041 -0.019 0.019 -0.002 0.027 0.036  || dis=0.00 || select=7/8
018/019-th : 0.089 0.107 0.110 0.126 0.133 0.128 0.144 0.162  ||  -0.327 -0.137 -0.112 0.024 0.080 0.042 0.160 0.278    || dis=0.02 || select=7/8
[epoch=194/600] FLOP : 27.33 MB, ratio : 0.6696, Expected-ratio : 0.7000, Discrepancy : 0.045
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:24:42] [epoch=194/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.886 (1.886)  Prec@1 44.92 (44.92) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:24:48] [epoch=194/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.263 (2.452)  Prec@1 41.07 (34.88) Prec@5 87.50 (81.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.88 Prec@5 81.52 Error@1 65.12 Error@5 18.48 Loss:2.452
***[2020-01-29 07:24:48]*** VALID [epoch=194/600] loss = 2.451527, accuracy@1 = 34.88, accuracy@5 = 81.52 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:24:48]*** start epoch=195/600 Time Left: [03:35:29], LR=[0.076125 ~ 0.076125], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=195, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.830121483554075, FLOP=40.81
[Search] : epoch=195/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:24:49] [epoch=195/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.841 (0.841)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 1.033 (1.033) FLOP-Loss 0.000 (0.000) Arch-Loss 1.033 (1.033)
**TRAIN** [2020-01-29 07:25:13] [epoch=195/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.725 (0.811)  Prec@1 79.76 (72.24) Prec@5 96.43 (97.84) Acls-loss 0.798 (0.843) FLOP-Loss 0.000 (0.000) Arch-Loss 0.798 (0.843)
 **TRAIN** Prec@1 72.24 Prec@5 97.84 Error@1 27.76 Error@5 2.16 Base-Loss:0.811, Arch-Loss=0.843
***[2020-01-29 07:25:13]*** TRAIN [epoch=195/600] base-loss = 0.810948, arch-loss = 0.842985, accuracy-1 = 72.24, accuracy-5 = 97.84
[epoch=195/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 8, 14, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.804864)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.453 0.214 0.333  ||  0.2471 -0.5012 -0.0600  || discrepancy=0.12 || select=0/3
001/003-th : 0.396 0.150 0.453  ||  0.0937 -0.8765 0.2275  || discrepancy=0.06 || select=2/3
002/003-th : 0.076 0.201 0.723  ||  -1.1804 -0.1994 1.0784  || discrepancy=0.52 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.084 0.100 0.118 0.141 0.161 0.165 0.173  ||  -0.712 -0.331 -0.157 0.003 0.187 0.315 0.342 0.391    || dis=0.01 || select=7/8
001/019-th : 0.134 0.129 0.130 0.132 0.123 0.121 0.118 0.113  ||  0.072 0.037 0.040 0.057 -0.015 -0.031 -0.055 -0.095   || dis=0.00 || select=0/8
002/019-th : 0.122 0.131 0.133 0.131 0.128 0.126 0.117 0.112  ||  -0.016 0.051 0.070 0.054 0.031 0.010 -0.062 -0.109    || dis=0.00 || select=2/8
003/019-th : 0.127 0.127 0.127 0.125 0.126 0.122 0.122 0.123  ||  0.016 0.016 0.017 0.000 0.004 -0.026 -0.022 -0.015    || dis=0.00 || select=2/8
004/019-th : 0.115 0.119 0.123 0.125 0.129 0.129 0.133 0.128  ||  -0.076 -0.049 -0.014 -0.000 0.032 0.031 0.064 0.028   || dis=0.00 || select=6/8
005/019-th : 0.117 0.119 0.124 0.126 0.124 0.131 0.126 0.132  ||  -0.062 -0.044 -0.004 0.011 -0.003 0.048 0.011 0.060   || dis=0.00 || select=7/8
006/019-th : 0.120 0.115 0.121 0.128 0.127 0.126 0.132 0.132  ||  -0.041 -0.077 -0.030 0.024 0.023 0.010 0.055 0.057    || dis=0.00 || select=7/8
007/019-th : 0.073 0.083 0.096 0.117 0.140 0.149 0.160 0.181  ||  -0.490 -0.354 -0.212 -0.013 0.162 0.227 0.300 0.418   || dis=0.02 || select=7/8
008/019-th : 0.054 0.067 0.091 0.131 0.144 0.168 0.172 0.174  ||  -0.756 -0.545 -0.238 0.127 0.227 0.377 0.404 0.415    || dis=0.00 || select=7/8
009/019-th : 0.099 0.100 0.109 0.117 0.129 0.138 0.145 0.164  ||  -0.217 -0.207 -0.120 -0.054 0.045 0.112 0.167 0.285   || dis=0.02 || select=7/8
010/019-th : 0.104 0.109 0.114 0.126 0.136 0.137 0.140 0.133  ||  -0.176 -0.128 -0.081 0.019 0.094 0.099 0.121 0.073    || dis=0.00 || select=6/8
011/019-th : 0.107 0.103 0.106 0.114 0.124 0.134 0.150 0.161  ||  -0.146 -0.178 -0.152 -0.078 0.001 0.084 0.195 0.266   || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.119 0.124 0.121 0.134 0.138 0.138  ||  -0.102 -0.093 -0.045 -0.009 -0.031 0.071 0.098 0.097  || dis=0.00 || select=6/8
013/019-th : 0.043 0.047 0.060 0.076 0.103 0.142 0.212 0.318  ||  -0.851 -0.763 -0.508 -0.281 0.032 0.347 0.749 1.156   || dis=0.11 || select=7/8
014/019-th : 0.056 0.060 0.072 0.099 0.131 0.160 0.206 0.216  ||  -0.690 -0.620 -0.435 -0.122 0.164 0.362 0.613 0.664   || dis=0.01 || select=7/8
015/019-th : 0.039 0.040 0.055 0.075 0.109 0.139 0.227 0.316  ||  -0.920 -0.889 -0.564 -0.250 0.117 0.363 0.852 1.184   || dis=0.09 || select=7/8
016/019-th : 0.057 0.079 0.098 0.126 0.140 0.161 0.169 0.169  ||  -0.719 -0.393 -0.174 0.076 0.177 0.319 0.367 0.363    || dis=0.00 || select=6/8
017/019-th : 0.123 0.122 0.119 0.122 0.129 0.126 0.129 0.130  ||  -0.015 -0.024 -0.050 -0.020 0.028 0.007 0.032 0.044   || dis=0.00 || select=7/8
018/019-th : 0.088 0.107 0.110 0.125 0.133 0.130 0.145 0.163  ||  -0.335 -0.136 -0.113 0.013 0.081 0.053 0.164 0.280    || dis=0.02 || select=7/8
[epoch=195/600] FLOP : 26.80 MB, ratio : 0.6568, Expected-ratio : 0.7000, Discrepancy : 0.045
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:25:13] [epoch=195/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.000 (3.000)  Prec@1 28.52 (28.52) Prec@5 72.66 (72.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:25:19] [epoch=195/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 4.264 (2.327)  Prec@1 38.69 (37.05) Prec@5 83.33 (80.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.05 Prec@5 80.80 Error@1 62.95 Error@5 19.20 Loss:2.327
***[2020-01-29 07:25:19]*** VALID [epoch=195/600] loss = 2.326838, accuracy@1 = 37.05, accuracy@5 = 80.80 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:25:19]*** start epoch=196/600 Time Left: [03:34:56], LR=[0.075901 ~ 0.075901], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=196, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.8191661729641697, FLOP=40.81
[Search] : epoch=196/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:25:20] [epoch=196/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.743 (0.743)  Prec@1 76.95 (76.95) Prec@5 98.05 (98.05) Acls-loss 0.702 (0.702) FLOP-Loss 0.000 (0.000) Arch-Loss 0.702 (0.702)
**TRAIN** [2020-01-29 07:25:44] [epoch=196/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.891 (0.807)  Prec@1 67.26 (72.40) Prec@5 97.62 (97.79) Acls-loss 0.770 (0.845) FLOP-Loss 0.000 (0.000) Arch-Loss 0.770 (0.845)
 **TRAIN** Prec@1 72.40 Prec@5 97.79 Error@1 27.60 Error@5 2.21 Base-Loss:0.807, Arch-Loss=0.845
***[2020-01-29 07:25:44]*** TRAIN [epoch=196/600] base-loss = 0.807047, arch-loss = 0.845151, accuracy-1 = 72.40, accuracy-5 = 97.79
[epoch=196/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 8, 14, 16, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.329152)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.214 0.335  ||  0.2419 -0.5017 -0.0534  || discrepancy=0.11 || select=0/3
001/003-th : 0.393 0.151 0.456  ||  0.0862 -0.8705 0.2360  || discrepancy=0.06 || select=2/3
002/003-th : 0.075 0.199 0.726  ||  -1.1894 -0.2052 1.0875  || discrepancy=0.53 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.084 0.101 0.117 0.139 0.163 0.165 0.174  ||  -0.707 -0.337 -0.152 -0.005 0.171 0.328 0.341 0.393   || dis=0.01 || select=7/8
001/019-th : 0.133 0.128 0.130 0.131 0.125 0.121 0.119 0.114  ||  0.065 0.031 0.040 0.049 -0.000 -0.027 -0.048 -0.091   || dis=0.00 || select=0/8
002/019-th : 0.122 0.130 0.133 0.131 0.128 0.127 0.118 0.112  ||  -0.021 0.042 0.065 0.054 0.031 0.018 -0.055 -0.105    || dis=0.00 || select=2/8
003/019-th : 0.127 0.127 0.127 0.124 0.125 0.123 0.123 0.124  ||  0.011 0.012 0.018 -0.006 0.000 -0.021 -0.019 -0.009   || dis=0.00 || select=2/8
004/019-th : 0.115 0.118 0.122 0.124 0.131 0.129 0.133 0.128  ||  -0.080 -0.055 -0.017 -0.007 0.050 0.035 0.065 0.031   || dis=0.00 || select=6/8
005/019-th : 0.116 0.120 0.123 0.124 0.125 0.131 0.128 0.133  ||  -0.071 -0.042 -0.013 -0.002 0.002 0.047 0.024 0.065   || dis=0.00 || select=7/8
006/019-th : 0.118 0.115 0.121 0.127 0.127 0.127 0.133 0.133  ||  -0.051 -0.084 -0.030 0.017 0.019 0.016 0.066 0.063    || dis=0.00 || select=6/8
007/019-th : 0.072 0.083 0.096 0.117 0.141 0.148 0.162 0.182  ||  -0.500 -0.359 -0.215 -0.017 0.169 0.218 0.310 0.426   || dis=0.02 || select=7/8
008/019-th : 0.054 0.066 0.091 0.130 0.142 0.169 0.170 0.177  ||  -0.759 -0.556 -0.234 0.126 0.208 0.387 0.392 0.434    || dis=0.01 || select=7/8
009/019-th : 0.098 0.099 0.108 0.118 0.131 0.137 0.146 0.163  ||  -0.222 -0.220 -0.125 -0.038 0.066 0.106 0.171 0.286   || dis=0.02 || select=7/8
010/019-th : 0.104 0.108 0.114 0.128 0.136 0.136 0.141 0.134  ||  -0.178 -0.134 -0.086 0.030 0.092 0.090 0.127 0.078    || dis=0.00 || select=6/8
011/019-th : 0.106 0.104 0.106 0.115 0.121 0.135 0.151 0.163  ||  -0.151 -0.174 -0.152 -0.076 -0.019 0.086 0.198 0.274  || dis=0.01 || select=7/8
012/019-th : 0.112 0.113 0.119 0.124 0.122 0.133 0.138 0.140  ||  -0.110 -0.101 -0.052 -0.011 -0.024 0.065 0.100 0.112  || dis=0.00 || select=7/8
013/019-th : 0.043 0.046 0.059 0.076 0.102 0.143 0.212 0.320  ||  -0.850 -0.770 -0.530 -0.277 0.022 0.362 0.754 1.167   || dis=0.11 || select=7/8
014/019-th : 0.056 0.060 0.072 0.097 0.129 0.161 0.207 0.218  ||  -0.693 -0.620 -0.440 -0.133 0.150 0.372 0.622 0.673   || dis=0.01 || select=7/8
015/019-th : 0.039 0.040 0.055 0.075 0.108 0.137 0.228 0.317  ||  -0.917 -0.891 -0.564 -0.250 0.115 0.350 0.858 1.188   || dis=0.09 || select=7/8
016/019-th : 0.057 0.079 0.098 0.126 0.142 0.160 0.170 0.168  ||  -0.716 -0.393 -0.178 0.076 0.191 0.311 0.371 0.360    || dis=0.00 || select=6/8
017/019-th : 0.122 0.121 0.119 0.122 0.128 0.127 0.130 0.131  ||  -0.022 -0.030 -0.052 -0.023 0.026 0.018 0.037 0.049   || dis=0.00 || select=7/8
018/019-th : 0.088 0.106 0.109 0.127 0.133 0.129 0.146 0.162  ||  -0.338 -0.146 -0.117 0.031 0.078 0.052 0.172 0.279    || dis=0.02 || select=7/8
[epoch=196/600] FLOP : 27.33 MB, ratio : 0.6696, Expected-ratio : 0.7000, Discrepancy : 0.046
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:25:44] [epoch=196/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.969 (1.969)  Prec@1 31.64 (31.64) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:25:50] [epoch=196/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 3.352 (2.338)  Prec@1 48.21 (36.93) Prec@5 76.79 (81.98) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.93 Prec@5 81.98 Error@1 63.07 Error@5 18.02 Loss:2.338
***[2020-01-29 07:25:50]*** VALID [epoch=196/600] loss = 2.337645, accuracy@1 = 36.93, accuracy@5 = 81.98 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:25:51]*** start epoch=197/600 Time Left: [03:34:23], LR=[0.075677 ~ 0.075677], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=197, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.8081760675425174, FLOP=40.81
[Search] : epoch=197/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:25:51] [epoch=197/600][000/098] Time 0.64 (0.64) Data 0.38 (0.38) Base-Loss 0.692 (0.692)  Prec@1 75.00 (75.00) Prec@5 97.66 (97.66) Acls-loss 0.849 (0.849) FLOP-Loss 0.000 (0.000) Arch-Loss 0.849 (0.849)
**TRAIN** [2020-01-29 07:26:15] [epoch=197/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.766 (0.816)  Prec@1 75.00 (72.22) Prec@5 95.24 (97.76) Acls-loss 0.797 (0.873) FLOP-Loss 0.000 (0.000) Arch-Loss 0.797 (0.873)
 **TRAIN** Prec@1 72.22 Prec@5 97.76 Error@1 27.78 Error@5 2.24 Base-Loss:0.816, Arch-Loss=0.873
***[2020-01-29 07:26:15]*** TRAIN [epoch=197/600] base-loss = 0.816488, arch-loss = 0.872852, accuracy-1 = 72.22, accuracy-5 = 97.76
[epoch=197/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 8, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.492992)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.215 0.338  ||  0.2340 -0.4957 -0.0446  || discrepancy=0.11 || select=0/3
001/003-th : 0.389 0.153 0.458  ||  0.0798 -0.8552 0.2427  || discrepancy=0.07 || select=2/3
002/003-th : 0.074 0.198 0.728  ||  -1.1980 -0.2078 1.0951  || discrepancy=0.53 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.082 0.101 0.116 0.140 0.162 0.167 0.173  ||  -0.709 -0.355 -0.145 -0.008 0.181 0.327 0.354 0.392   || dis=0.01 || select=7/8
001/019-th : 0.133 0.128 0.128 0.130 0.125 0.122 0.120 0.115  ||  0.060 0.026 0.023 0.042 0.001 -0.026 -0.041 -0.080    || dis=0.00 || select=0/8
002/019-th : 0.121 0.128 0.133 0.131 0.128 0.127 0.118 0.113  ||  -0.028 0.032 0.063 0.050 0.031 0.021 -0.050 -0.094    || dis=0.00 || select=2/8
003/019-th : 0.124 0.125 0.127 0.125 0.126 0.123 0.125 0.125  ||  -0.005 -0.000 0.015 -0.000 0.006 -0.017 -0.001 0.001  || dis=0.00 || select=2/8
004/019-th : 0.114 0.118 0.123 0.123 0.132 0.130 0.133 0.129  ||  -0.087 -0.055 -0.016 -0.014 0.056 0.045 0.064 0.033   || dis=0.00 || select=6/8
005/019-th : 0.116 0.118 0.123 0.125 0.125 0.130 0.129 0.133  ||  -0.073 -0.052 -0.015 0.005 0.004 0.042 0.036 0.065    || dis=0.00 || select=7/8
006/019-th : 0.117 0.114 0.120 0.126 0.129 0.127 0.133 0.134  ||  -0.062 -0.084 -0.036 0.015 0.032 0.021 0.065 0.071    || dis=0.00 || select=7/8
007/019-th : 0.071 0.083 0.096 0.117 0.142 0.148 0.163 0.181  ||  -0.512 -0.357 -0.214 -0.017 0.178 0.222 0.316 0.425   || dis=0.02 || select=7/8
008/019-th : 0.053 0.066 0.090 0.130 0.142 0.169 0.171 0.179  ||  -0.771 -0.551 -0.242 0.125 0.208 0.387 0.395 0.442    || dis=0.01 || select=7/8
009/019-th : 0.097 0.098 0.107 0.120 0.131 0.136 0.148 0.164  ||  -0.238 -0.225 -0.136 -0.024 0.070 0.106 0.188 0.290   || dis=0.02 || select=7/8
010/019-th : 0.103 0.108 0.114 0.126 0.134 0.137 0.142 0.136  ||  -0.190 -0.135 -0.087 0.016 0.076 0.102 0.137 0.088    || dis=0.00 || select=6/8
011/019-th : 0.104 0.104 0.107 0.114 0.122 0.135 0.149 0.164  ||  -0.175 -0.167 -0.147 -0.079 -0.010 0.092 0.189 0.286  || dis=0.02 || select=7/8
012/019-th : 0.112 0.113 0.118 0.123 0.123 0.133 0.139 0.139  ||  -0.110 -0.102 -0.056 -0.013 -0.012 0.067 0.105 0.109  || dis=0.00 || select=7/8
013/019-th : 0.042 0.046 0.057 0.074 0.100 0.145 0.213 0.323  ||  -0.847 -0.774 -0.551 -0.288 0.004 0.378 0.765 1.183   || dis=0.11 || select=7/8
014/019-th : 0.055 0.059 0.072 0.095 0.129 0.162 0.208 0.219  ||  -0.702 -0.624 -0.432 -0.152 0.148 0.379 0.628 0.681   || dis=0.01 || select=7/8
015/019-th : 0.039 0.039 0.054 0.075 0.107 0.137 0.230 0.319  ||  -0.907 -0.897 -0.587 -0.252 0.105 0.354 0.873 1.198   || dis=0.09 || select=7/8
016/019-th : 0.057 0.079 0.097 0.127 0.141 0.161 0.170 0.168  ||  -0.718 -0.397 -0.184 0.083 0.183 0.320 0.374 0.360    || dis=0.00 || select=6/8
017/019-th : 0.122 0.120 0.119 0.122 0.128 0.128 0.130 0.131  ||  -0.025 -0.039 -0.048 -0.025 0.026 0.026 0.042 0.050   || dis=0.00 || select=7/8
018/019-th : 0.088 0.106 0.111 0.125 0.133 0.128 0.146 0.163  ||  -0.338 -0.146 -0.105 0.021 0.078 0.041 0.175 0.281    || dis=0.02 || select=7/8
[epoch=197/600] FLOP : 27.49 MB, ratio : 0.6736, Expected-ratio : 0.7000, Discrepancy : 0.046
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:26:16] [epoch=197/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.080 (2.080)  Prec@1 41.80 (41.80) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:26:22] [epoch=197/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.756 (2.318)  Prec@1 42.26 (38.37) Prec@5 86.31 (82.05) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.37 Prec@5 82.05 Error@1 61.63 Error@5 17.95 Loss:2.318
***[2020-01-29 07:26:22]*** VALID [epoch=197/600] loss = 2.317724, accuracy@1 = 38.37, accuracy@5 = 82.05 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:26:22]*** start epoch=198/600 Time Left: [03:33:49], LR=[0.075452 ~ 0.075452], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=198, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.7971514685884102, FLOP=40.81
[Search] : epoch=198/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:26:22] [epoch=198/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.891 (0.891)  Prec@1 71.88 (71.88) Prec@5 96.09 (96.09) Acls-loss 0.696 (0.696) FLOP-Loss 0.000 (0.000) Arch-Loss 0.696 (0.696)
**TRAIN** [2020-01-29 07:26:46] [epoch=198/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.876 (0.827)  Prec@1 70.24 (71.79) Prec@5 98.21 (97.86) Acls-loss 0.962 (0.847) FLOP-Loss 0.000 (0.000) Arch-Loss 0.962 (0.847)
 **TRAIN** Prec@1 71.79 Prec@5 97.86 Error@1 28.21 Error@5 2.14 Base-Loss:0.827, Arch-Loss=0.847
***[2020-01-29 07:26:46]*** TRAIN [epoch=198/600] base-loss = 0.827106, arch-loss = 0.846996, accuracy-1 = 71.79, accuracy-5 = 97.86
[epoch=198/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 11, 11, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.492992)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.214 0.341  ||  0.2293 -0.5030 -0.0378  || discrepancy=0.10 || select=0/3
001/003-th : 0.386 0.152 0.462  ||  0.0723 -0.8570 0.2517  || discrepancy=0.08 || select=2/3
002/003-th : 0.072 0.197 0.731  ||  -1.2103 -0.2091 1.1047  || discrepancy=0.53 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.100 0.117 0.139 0.163 0.167 0.174  ||  -0.726 -0.349 -0.152 -0.003 0.169 0.334 0.359 0.398   || dis=0.01 || select=7/8
001/019-th : 0.132 0.127 0.126 0.130 0.126 0.122 0.120 0.116  ||  0.053 0.019 0.011 0.040 0.008 -0.020 -0.037 -0.070    || dis=0.00 || select=0/8
002/019-th : 0.121 0.128 0.131 0.130 0.128 0.129 0.120 0.115  ||  -0.034 0.026 0.049 0.039 0.025 0.031 -0.040 -0.085    || dis=0.00 || select=2/8
003/019-th : 0.123 0.124 0.125 0.124 0.128 0.123 0.127 0.126  ||  -0.012 -0.009 0.002 -0.010 0.022 -0.015 0.013 0.008   || dis=0.00 || select=4/8
004/019-th : 0.114 0.117 0.120 0.122 0.134 0.130 0.133 0.130  ||  -0.092 -0.059 -0.037 -0.018 0.071 0.045 0.069 0.042   || dis=0.00 || select=4/8
005/019-th : 0.114 0.117 0.123 0.124 0.127 0.129 0.131 0.135  ||  -0.086 -0.067 -0.014 -0.002 0.023 0.035 0.048 0.079   || dis=0.00 || select=7/8
006/019-th : 0.116 0.113 0.120 0.126 0.130 0.127 0.133 0.134  ||  -0.068 -0.092 -0.034 0.012 0.042 0.025 0.066 0.076    || dis=0.00 || select=7/8
007/019-th : 0.071 0.081 0.096 0.115 0.140 0.149 0.165 0.183  ||  -0.512 -0.381 -0.209 -0.026 0.169 0.228 0.333 0.433   || dis=0.02 || select=7/8
008/019-th : 0.054 0.066 0.091 0.129 0.141 0.169 0.170 0.180  ||  -0.765 -0.559 -0.230 0.117 0.201 0.383 0.393 0.449    || dis=0.01 || select=7/8
009/019-th : 0.097 0.098 0.107 0.118 0.132 0.135 0.149 0.164  ||  -0.239 -0.227 -0.132 -0.035 0.073 0.097 0.195 0.292   || dis=0.02 || select=7/8
010/019-th : 0.101 0.108 0.113 0.125 0.136 0.138 0.142 0.138  ||  -0.204 -0.140 -0.094 0.005 0.094 0.107 0.134 0.104    || dis=0.00 || select=6/8
011/019-th : 0.103 0.103 0.106 0.112 0.124 0.135 0.151 0.166  ||  -0.181 -0.185 -0.149 -0.099 0.008 0.093 0.201 0.297   || dis=0.02 || select=7/8
012/019-th : 0.111 0.113 0.117 0.122 0.123 0.135 0.139 0.141  ||  -0.117 -0.103 -0.062 -0.025 -0.015 0.075 0.104 0.120  || dis=0.00 || select=7/8
013/019-th : 0.042 0.045 0.057 0.073 0.097 0.146 0.217 0.324  ||  -0.860 -0.786 -0.544 -0.303 -0.015 0.391 0.789 1.193  || dis=0.11 || select=7/8
014/019-th : 0.055 0.059 0.072 0.095 0.128 0.162 0.208 0.222  ||  -0.705 -0.634 -0.437 -0.152 0.144 0.377 0.629 0.693   || dis=0.01 || select=7/8
015/019-th : 0.039 0.039 0.054 0.074 0.105 0.137 0.231 0.320  ||  -0.906 -0.907 -0.579 -0.255 0.093 0.359 0.880 1.203   || dis=0.09 || select=7/8
016/019-th : 0.057 0.078 0.097 0.126 0.140 0.162 0.170 0.169  ||  -0.719 -0.409 -0.183 0.074 0.181 0.325 0.376 0.368    || dis=0.00 || select=6/8
017/019-th : 0.122 0.119 0.119 0.121 0.127 0.129 0.130 0.133  ||  -0.027 -0.046 -0.053 -0.031 0.018 0.034 0.043 0.059   || dis=0.00 || select=7/8
018/019-th : 0.087 0.106 0.111 0.125 0.133 0.128 0.146 0.164  ||  -0.347 -0.152 -0.102 0.021 0.081 0.045 0.174 0.286    || dis=0.02 || select=7/8
[epoch=198/600] FLOP : 27.49 MB, ratio : 0.6736, Expected-ratio : 0.7000, Discrepancy : 0.047
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:26:47] [epoch=198/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.033 (3.033)  Prec@1 28.91 (28.91) Prec@5 67.58 (67.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:26:53] [epoch=198/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.330 (2.304)  Prec@1 39.88 (38.77) Prec@5 78.57 (83.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.77 Prec@5 83.42 Error@1 61.23 Error@5 16.58 Loss:2.304
***[2020-01-29 07:26:53]*** VALID [epoch=198/600] loss = 2.304232, accuracy@1 = 38.77, accuracy@5 = 83.42 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:26:53]*** start epoch=199/600 Time Left: [03:33:16], LR=[0.075226 ~ 0.075226], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=199, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.7860926783467974, FLOP=40.81
[Search] : epoch=199/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:26:54] [epoch=199/600][000/098] Time 0.74 (0.74) Data 0.36 (0.36) Base-Loss 0.681 (0.681)  Prec@1 77.73 (77.73) Prec@5 98.44 (98.44) Acls-loss 0.812 (0.812) FLOP-Loss 0.000 (0.000) Arch-Loss 0.812 (0.812)
**TRAIN** [2020-01-29 07:27:18] [epoch=199/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.817 (0.815)  Prec@1 70.83 (71.99) Prec@5 97.62 (97.92) Acls-loss 0.825 (0.854) FLOP-Loss 0.000 (0.000) Arch-Loss 0.825 (0.854)
 **TRAIN** Prec@1 71.99 Prec@5 97.92 Error@1 28.01 Error@5 2.08 Base-Loss:0.815, Arch-Loss=0.854
***[2020-01-29 07:27:18]*** TRAIN [epoch=199/600] base-loss = 0.814730, arch-loss = 0.854226, accuracy-1 = 71.99, accuracy-5 = 97.92
[epoch=199/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 8, 14, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.542144)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.442 0.214 0.344  ||  0.2217 -0.5041 -0.0285  || discrepancy=0.10 || select=0/3
001/003-th : 0.383 0.152 0.465  ||  0.0655 -0.8605 0.2602  || discrepancy=0.08 || select=2/3
002/003-th : 0.071 0.193 0.736  ||  -1.2258 -0.2189 1.1199  || discrepancy=0.54 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.099 0.115 0.139 0.164 0.168 0.175  ||  -0.721 -0.345 -0.164 -0.017 0.175 0.336 0.363 0.400   || dis=0.01 || select=7/8
001/019-th : 0.131 0.127 0.126 0.129 0.126 0.123 0.121 0.117  ||  0.048 0.016 0.010 0.030 0.009 -0.015 -0.031 -0.066    || dis=0.00 || select=0/8
002/019-th : 0.120 0.127 0.130 0.129 0.128 0.130 0.120 0.116  ||  -0.042 0.019 0.041 0.035 0.027 0.039 -0.036 -0.075    || dis=0.00 || select=2/8
003/019-th : 0.123 0.123 0.123 0.123 0.128 0.125 0.128 0.127  ||  -0.017 -0.020 -0.014 -0.014 0.022 0.002 0.026 0.012   || dis=0.00 || select=6/8
004/019-th : 0.113 0.117 0.119 0.122 0.132 0.131 0.135 0.131  ||  -0.098 -0.064 -0.049 -0.019 0.060 0.047 0.079 0.051   || dis=0.00 || select=6/8
005/019-th : 0.114 0.115 0.121 0.124 0.129 0.130 0.131 0.136  ||  -0.085 -0.080 -0.033 -0.007 0.032 0.044 0.053 0.087   || dis=0.01 || select=7/8
006/019-th : 0.116 0.113 0.119 0.124 0.129 0.130 0.134 0.135  ||  -0.074 -0.096 -0.043 -0.005 0.035 0.042 0.077 0.081   || dis=0.00 || select=7/8
007/019-th : 0.071 0.080 0.094 0.114 0.142 0.148 0.166 0.184  ||  -0.513 -0.385 -0.227 -0.038 0.181 0.227 0.338 0.445   || dis=0.02 || select=7/8
008/019-th : 0.053 0.064 0.090 0.129 0.142 0.169 0.172 0.182  ||  -0.774 -0.585 -0.239 0.122 0.213 0.388 0.404 0.461    || dis=0.01 || select=7/8
009/019-th : 0.095 0.096 0.107 0.118 0.131 0.137 0.151 0.165  ||  -0.248 -0.246 -0.130 -0.040 0.065 0.115 0.208 0.301   || dis=0.01 || select=7/8
010/019-th : 0.101 0.107 0.113 0.126 0.136 0.137 0.142 0.139  ||  -0.209 -0.148 -0.094 0.015 0.090 0.103 0.136 0.111    || dis=0.00 || select=6/8
011/019-th : 0.102 0.101 0.105 0.113 0.124 0.136 0.152 0.167  ||  -0.185 -0.200 -0.164 -0.087 0.006 0.101 0.212 0.305   || dis=0.02 || select=7/8
012/019-th : 0.110 0.112 0.117 0.122 0.124 0.136 0.139 0.142  ||  -0.126 -0.109 -0.068 -0.023 -0.007 0.085 0.106 0.126  || dis=0.00 || select=7/8
013/019-th : 0.041 0.043 0.058 0.073 0.094 0.147 0.216 0.327  ||  -0.876 -0.817 -0.527 -0.289 -0.037 0.406 0.792 1.205  || dis=0.11 || select=7/8
014/019-th : 0.054 0.059 0.072 0.094 0.130 0.158 0.209 0.224  ||  -0.714 -0.635 -0.432 -0.163 0.156 0.352 0.637 0.705   || dis=0.02 || select=7/8
015/019-th : 0.038 0.038 0.053 0.073 0.104 0.137 0.232 0.325  ||  -0.915 -0.916 -0.589 -0.270 0.086 0.365 0.890 1.227   || dis=0.09 || select=7/8
016/019-th : 0.057 0.077 0.096 0.127 0.138 0.163 0.171 0.171  ||  -0.724 -0.418 -0.194 0.079 0.165 0.333 0.380 0.380    || dis=0.00 || select=7/8
017/019-th : 0.120 0.118 0.119 0.121 0.128 0.129 0.131 0.134  ||  -0.043 -0.056 -0.050 -0.030 0.025 0.033 0.049 0.073   || dis=0.00 || select=7/8
018/019-th : 0.086 0.104 0.112 0.124 0.131 0.130 0.149 0.165  ||  -0.355 -0.169 -0.095 0.009 0.065 0.056 0.192 0.293    || dis=0.02 || select=7/8
[epoch=199/600] FLOP : 27.54 MB, ratio : 0.6748, Expected-ratio : 0.7000, Discrepancy : 0.047
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:27:18] [epoch=199/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.613 (1.613)  Prec@1 53.52 (53.52) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:27:24] [epoch=199/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.609 (2.073)  Prec@1 44.05 (38.50) Prec@5 88.69 (81.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.50 Prec@5 81.17 Error@1 61.50 Error@5 18.83 Loss:2.073
***[2020-01-29 07:27:24]*** VALID [epoch=199/600] loss = 2.073441, accuracy@1 = 38.50, accuracy@5 = 81.17 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:27:24]*** start epoch=200/600 Time Left: [03:32:43], LR=[0.075000 ~ 0.075000], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=200, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.7750000000000004, FLOP=40.81
[Search] : epoch=200/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:27:25] [epoch=200/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.796 (0.796)  Prec@1 72.66 (72.66) Prec@5 99.22 (99.22) Acls-loss 0.978 (0.978) FLOP-Loss 0.000 (0.000) Arch-Loss 0.978 (0.978)
**TRAIN** [2020-01-29 07:27:49] [epoch=200/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.855 (0.805)  Prec@1 70.83 (72.38) Prec@5 97.62 (97.75) Acls-loss 0.776 (0.837) FLOP-Loss 0.000 (0.027) Arch-Loss 0.776 (0.891)
 **TRAIN** Prec@1 72.38 Prec@5 97.75 Error@1 27.62 Error@5 2.25 Base-Loss:0.805, Arch-Loss=0.891
***[2020-01-29 07:27:49]*** TRAIN [epoch=200/600] base-loss = 0.805447, arch-loss = 0.891292, accuracy-1 = 72.38, accuracy-5 = 97.75
[epoch=200/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 14, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.755136)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.215 0.345  ||  0.2191 -0.4962 -0.0253  || discrepancy=0.10 || select=0/3
001/003-th : 0.381 0.151 0.467  ||  0.0617 -0.8621 0.2658  || discrepancy=0.09 || select=2/3
002/003-th : 0.070 0.193 0.738  ||  -1.2357 -0.2161 1.1266  || discrepancy=0.54 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.083 0.100 0.113 0.140 0.163 0.169 0.176  ||  -0.728 -0.344 -0.160 -0.036 0.181 0.330 0.366 0.410   || dis=0.01 || select=7/8
001/019-th : 0.130 0.127 0.126 0.129 0.126 0.124 0.121 0.117  ||  0.038 0.020 0.007 0.037 0.013 -0.005 -0.032 -0.062    || dis=0.00 || select=0/8
002/019-th : 0.119 0.127 0.128 0.130 0.128 0.130 0.122 0.116  ||  -0.049 0.018 0.027 0.040 0.028 0.041 -0.026 -0.070    || dis=0.00 || select=5/8
003/019-th : 0.122 0.121 0.124 0.122 0.127 0.126 0.129 0.128  ||  -0.023 -0.030 -0.012 -0.021 0.018 0.008 0.033 0.022   || dis=0.00 || select=6/8
004/019-th : 0.113 0.115 0.118 0.123 0.133 0.131 0.135 0.132  ||  -0.101 -0.077 -0.050 -0.012 0.066 0.049 0.082 0.056   || dis=0.00 || select=6/8
005/019-th : 0.113 0.115 0.119 0.125 0.130 0.130 0.132 0.136  ||  -0.098 -0.079 -0.041 0.002 0.047 0.043 0.059 0.090    || dis=0.00 || select=7/8
006/019-th : 0.115 0.113 0.119 0.124 0.129 0.131 0.134 0.136  ||  -0.080 -0.100 -0.048 -0.002 0.032 0.050 0.074 0.090   || dis=0.00 || select=7/8
007/019-th : 0.070 0.080 0.094 0.113 0.142 0.150 0.164 0.186  ||  -0.519 -0.385 -0.227 -0.045 0.186 0.241 0.325 0.451   || dis=0.02 || select=7/8
008/019-th : 0.053 0.064 0.089 0.131 0.140 0.169 0.173 0.182  ||  -0.778 -0.589 -0.247 0.132 0.200 0.391 0.414 0.463    || dis=0.01 || select=7/8
009/019-th : 0.096 0.096 0.107 0.116 0.131 0.138 0.151 0.166  ||  -0.243 -0.247 -0.139 -0.051 0.068 0.116 0.208 0.303   || dis=0.02 || select=7/8
010/019-th : 0.100 0.106 0.113 0.126 0.135 0.138 0.142 0.140  ||  -0.216 -0.153 -0.093 0.013 0.086 0.105 0.134 0.124    || dis=0.00 || select=6/8
011/019-th : 0.102 0.102 0.105 0.112 0.123 0.137 0.152 0.168  ||  -0.192 -0.193 -0.164 -0.095 -0.002 0.108 0.213 0.309  || dis=0.02 || select=7/8
012/019-th : 0.110 0.111 0.116 0.122 0.122 0.135 0.140 0.142  ||  -0.127 -0.113 -0.069 -0.019 -0.020 0.081 0.113 0.132  || dis=0.00 || select=7/8
013/019-th : 0.041 0.044 0.058 0.074 0.093 0.147 0.213 0.330  ||  -0.878 -0.809 -0.524 -0.282 -0.050 0.409 0.778 1.214  || dis=0.12 || select=7/8
014/019-th : 0.054 0.058 0.071 0.094 0.130 0.158 0.210 0.224  ||  -0.714 -0.650 -0.437 -0.163 0.165 0.358 0.641 0.708   || dis=0.01 || select=7/8
015/019-th : 0.038 0.038 0.052 0.074 0.102 0.136 0.234 0.326  ||  -0.914 -0.918 -0.601 -0.256 0.074 0.355 0.902 1.234   || dis=0.09 || select=7/8
016/019-th : 0.057 0.076 0.097 0.127 0.139 0.163 0.171 0.171  ||  -0.722 -0.427 -0.191 0.081 0.171 0.331 0.378 0.381    || dis=0.00 || select=7/8
017/019-th : 0.119 0.117 0.120 0.120 0.128 0.129 0.132 0.135  ||  -0.045 -0.066 -0.040 -0.039 0.024 0.030 0.056 0.079   || dis=0.00 || select=7/8
018/019-th : 0.087 0.104 0.111 0.125 0.130 0.130 0.150 0.164  ||  -0.351 -0.167 -0.097 0.015 0.054 0.055 0.199 0.288    || dis=0.01 || select=7/8
[epoch=200/600] FLOP : 27.76 MB, ratio : 0.6801, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:27:49] [epoch=200/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.758 (1.758)  Prec@1 41.02 (41.02) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:27:55] [epoch=200/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.266 (2.297)  Prec@1 38.69 (36.74) Prec@5 85.71 (82.51) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.74 Prec@5 82.51 Error@1 63.26 Error@5 17.49 Loss:2.297
***[2020-01-29 07:27:55]*** VALID [epoch=200/600] loss = 2.297499, accuracy@1 = 36.74, accuracy@5 = 82.51 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:27:55]*** start epoch=201/600 Time Left: [03:32:09], LR=[0.074773 ~ 0.074773], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=201, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.763873737659399, FLOP=40.81
[Search] : epoch=201/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:27:56] [epoch=201/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.826 (0.826)  Prec@1 71.48 (71.48) Prec@5 97.27 (97.27) Acls-loss 0.864 (0.864) FLOP-Loss 0.000 (0.000) Arch-Loss 0.864 (0.864)
**TRAIN** [2020-01-29 07:28:20] [epoch=201/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.821 (0.814)  Prec@1 71.43 (72.26) Prec@5 99.40 (97.88) Acls-loss 0.802 (0.847) FLOP-Loss 0.000 (0.027) Arch-Loss 0.802 (0.902)
 **TRAIN** Prec@1 72.26 Prec@5 97.88 Error@1 27.74 Error@5 2.12 Base-Loss:0.814, Arch-Loss=0.902
***[2020-01-29 07:28:20]*** TRAIN [epoch=201/600] base-loss = 0.814252, arch-loss = 0.901957, accuracy-1 = 72.26, accuracy-5 = 97.88
[epoch=201/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 14, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.212 0.348  ||  0.2172 -0.5150 -0.0201  || discrepancy=0.09 || select=0/3
001/003-th : 0.381 0.148 0.471  ||  0.0603 -0.8860 0.2709  || discrepancy=0.09 || select=2/3
002/003-th : 0.069 0.193 0.737  ||  -1.2387 -0.2105 1.1277  || discrepancy=0.54 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.083 0.099 0.111 0.141 0.164 0.171 0.177  ||  -0.759 -0.340 -0.161 -0.052 0.192 0.339 0.382 0.418   || dis=0.01 || select=7/8
001/019-th : 0.129 0.128 0.126 0.128 0.127 0.125 0.120 0.117  ||  0.035 0.025 0.007 0.022 0.020 -0.001 -0.035 -0.061    || dis=0.00 || select=0/8
002/019-th : 0.118 0.127 0.129 0.131 0.129 0.129 0.122 0.116  ||  -0.053 0.015 0.034 0.050 0.032 0.031 -0.023 -0.069    || dis=0.00 || select=3/8
003/019-th : 0.121 0.122 0.124 0.123 0.128 0.125 0.130 0.128  ||  -0.034 -0.024 -0.008 -0.019 0.027 0.003 0.037 0.022   || dis=0.00 || select=6/8
004/019-th : 0.112 0.116 0.119 0.124 0.133 0.130 0.135 0.132  ||  -0.104 -0.075 -0.046 -0.004 0.062 0.044 0.080 0.058   || dis=0.00 || select=6/8
005/019-th : 0.112 0.115 0.117 0.124 0.131 0.131 0.133 0.136  ||  -0.105 -0.078 -0.059 -0.003 0.053 0.054 0.068 0.093   || dis=0.00 || select=7/8
006/019-th : 0.115 0.112 0.118 0.124 0.131 0.131 0.133 0.136  ||  -0.082 -0.105 -0.052 -0.005 0.051 0.051 0.069 0.092   || dis=0.00 || select=7/8
007/019-th : 0.070 0.078 0.096 0.113 0.141 0.149 0.166 0.187  ||  -0.528 -0.409 -0.208 -0.044 0.176 0.235 0.340 0.462   || dis=0.02 || select=7/8
008/019-th : 0.053 0.063 0.089 0.130 0.140 0.170 0.174 0.182  ||  -0.772 -0.589 -0.252 0.126 0.201 0.395 0.416 0.464    || dis=0.01 || select=7/8
009/019-th : 0.095 0.096 0.104 0.117 0.130 0.138 0.152 0.166  ||  -0.249 -0.241 -0.159 -0.047 0.064 0.119 0.219 0.306   || dis=0.01 || select=7/8
010/019-th : 0.100 0.105 0.112 0.128 0.135 0.138 0.142 0.141  ||  -0.216 -0.163 -0.099 0.030 0.088 0.105 0.133 0.126    || dis=0.00 || select=6/8
011/019-th : 0.101 0.100 0.104 0.112 0.123 0.138 0.153 0.168  ||  -0.196 -0.208 -0.164 -0.090 -0.001 0.114 0.218 0.314  || dis=0.02 || select=7/8
012/019-th : 0.109 0.112 0.116 0.121 0.123 0.136 0.141 0.142  ||  -0.131 -0.109 -0.077 -0.032 -0.018 0.085 0.123 0.132  || dis=0.00 || select=7/8
013/019-th : 0.041 0.043 0.057 0.074 0.093 0.148 0.215 0.330  ||  -0.881 -0.810 -0.539 -0.273 -0.055 0.413 0.788 1.216  || dis=0.12 || select=7/8
014/019-th : 0.054 0.057 0.072 0.094 0.130 0.156 0.210 0.225  ||  -0.718 -0.656 -0.423 -0.160 0.165 0.346 0.640 0.711   || dis=0.02 || select=7/8
015/019-th : 0.038 0.037 0.052 0.074 0.100 0.133 0.237 0.328  ||  -0.904 -0.940 -0.600 -0.250 0.060 0.344 0.919 1.245   || dis=0.09 || select=7/8
016/019-th : 0.057 0.077 0.097 0.126 0.138 0.164 0.170 0.171  ||  -0.712 -0.422 -0.190 0.070 0.164 0.334 0.374 0.381    || dis=0.00 || select=7/8
017/019-th : 0.120 0.116 0.119 0.120 0.129 0.129 0.132 0.136  ||  -0.043 -0.070 -0.045 -0.042 0.029 0.029 0.055 0.083   || dis=0.00 || select=7/8
018/019-th : 0.088 0.105 0.113 0.123 0.128 0.130 0.149 0.165  ||  -0.340 -0.161 -0.084 -0.004 0.035 0.052 0.193 0.294   || dis=0.02 || select=7/8
[epoch=201/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:28:20] [epoch=201/600][000/098] Time 0.37 (0.37) Data 0.30 (0.30) Loss 1.767 (1.767)  Prec@1 51.17 (51.17) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:28:26] [epoch=201/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.867 (2.118)  Prec@1 50.00 (39.20) Prec@5 92.26 (83.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.20 Prec@5 83.34 Error@1 60.80 Error@5 16.66 Loss:2.118
***[2020-01-29 07:28:26]*** VALID [epoch=201/600] loss = 2.117527, accuracy@1 = 39.20, accuracy@5 = 83.34 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:28:27]*** start epoch=202/600 Time Left: [03:31:36], LR=[0.074545 ~ 0.074545], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=202, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.7527141963570956, FLOP=40.81
[Search] : epoch=202/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:28:27] [epoch=202/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.704 (0.704)  Prec@1 73.05 (73.05) Prec@5 98.83 (98.83) Acls-loss 0.812 (0.812) FLOP-Loss 0.000 (0.000) Arch-Loss 0.812 (0.812)
**TRAIN** [2020-01-29 07:28:51] [epoch=202/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.875 (0.813)  Prec@1 67.86 (72.13) Prec@5 97.62 (97.88) Acls-loss 0.913 (0.844) FLOP-Loss 0.000 (0.000) Arch-Loss 0.913 (0.844)
 **TRAIN** Prec@1 72.13 Prec@5 97.88 Error@1 27.87 Error@5 2.12 Base-Loss:0.813, Arch-Loss=0.844
***[2020-01-29 07:28:51]*** TRAIN [epoch=202/600] base-loss = 0.813031, arch-loss = 0.843540, accuracy-1 = 72.13, accuracy-5 = 97.88
[epoch=202/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 14, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.214 0.349  ||  0.2116 -0.5027 -0.0141  || discrepancy=0.09 || select=0/3
001/003-th : 0.379 0.146 0.475  ||  0.0549 -0.8978 0.2792  || discrepancy=0.10 || select=2/3
002/003-th : 0.067 0.190 0.743  ||  -1.2626 -0.2148 1.1465  || discrepancy=0.55 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.083 0.100 0.110 0.141 0.163 0.170 0.176  ||  -0.754 -0.337 -0.149 -0.056 0.192 0.337 0.377 0.411   || dis=0.01 || select=7/8
001/019-th : 0.128 0.128 0.125 0.126 0.127 0.125 0.122 0.118  ||  0.028 0.026 -0.001 0.009 0.019 -0.002 -0.025 -0.054   || dis=0.00 || select=0/8
002/019-th : 0.118 0.126 0.128 0.130 0.129 0.130 0.123 0.117  ||  -0.058 0.010 0.029 0.040 0.035 0.038 -0.017 -0.063    || dis=0.00 || select=3/8
003/019-th : 0.120 0.121 0.122 0.124 0.126 0.127 0.131 0.128  ||  -0.041 -0.033 -0.022 -0.005 0.010 0.015 0.050 0.027   || dis=0.00 || select=6/8
004/019-th : 0.112 0.115 0.119 0.125 0.131 0.130 0.137 0.132  ||  -0.109 -0.084 -0.044 0.000 0.047 0.041 0.095 0.060    || dis=0.01 || select=6/8
005/019-th : 0.111 0.116 0.117 0.125 0.130 0.132 0.134 0.137  ||  -0.114 -0.073 -0.064 0.004 0.042 0.057 0.074 0.094    || dis=0.00 || select=7/8
006/019-th : 0.114 0.112 0.117 0.123 0.131 0.131 0.135 0.136  ||  -0.085 -0.109 -0.058 -0.007 0.052 0.053 0.082 0.090   || dis=0.00 || select=7/8
007/019-th : 0.067 0.078 0.096 0.113 0.140 0.150 0.167 0.188  ||  -0.560 -0.405 -0.203 -0.043 0.177 0.244 0.353 0.468   || dis=0.02 || select=7/8
008/019-th : 0.052 0.064 0.089 0.128 0.138 0.171 0.175 0.183  ||  -0.791 -0.585 -0.245 0.115 0.188 0.403 0.429 0.469    || dis=0.01 || select=7/8
009/019-th : 0.095 0.096 0.102 0.118 0.128 0.137 0.155 0.169  ||  -0.256 -0.242 -0.180 -0.039 0.044 0.114 0.235 0.323   || dis=0.01 || select=7/8
010/019-th : 0.101 0.106 0.112 0.127 0.134 0.137 0.142 0.141  ||  -0.211 -0.161 -0.098 0.021 0.080 0.097 0.137 0.129    || dis=0.00 || select=6/8
011/019-th : 0.100 0.100 0.103 0.113 0.122 0.139 0.155 0.168  ||  -0.203 -0.209 -0.177 -0.085 -0.004 0.123 0.231 0.314  || dis=0.01 || select=7/8
012/019-th : 0.110 0.111 0.115 0.120 0.122 0.137 0.142 0.143  ||  -0.130 -0.118 -0.078 -0.037 -0.026 0.095 0.126 0.136  || dis=0.00 || select=7/8
013/019-th : 0.039 0.043 0.056 0.074 0.092 0.147 0.217 0.332  ||  -0.906 -0.812 -0.546 -0.273 -0.059 0.414 0.805 1.229  || dis=0.12 || select=7/8
014/019-th : 0.053 0.057 0.073 0.094 0.130 0.157 0.209 0.227  ||  -0.731 -0.660 -0.420 -0.161 0.166 0.355 0.635 0.719   || dis=0.02 || select=7/8
015/019-th : 0.037 0.037 0.052 0.074 0.099 0.131 0.238 0.332  ||  -0.922 -0.938 -0.603 -0.247 0.053 0.333 0.929 1.260   || dis=0.09 || select=7/8
016/019-th : 0.057 0.077 0.096 0.125 0.137 0.164 0.172 0.172  ||  -0.719 -0.424 -0.196 0.065 0.157 0.337 0.385 0.387    || dis=0.00 || select=7/8
017/019-th : 0.119 0.114 0.119 0.119 0.131 0.130 0.132 0.136  ||  -0.049 -0.086 -0.048 -0.044 0.049 0.039 0.058 0.089   || dis=0.00 || select=7/8
018/019-th : 0.088 0.104 0.114 0.123 0.127 0.131 0.147 0.166  ||  -0.341 -0.164 -0.079 -0.001 0.030 0.061 0.178 0.301   || dis=0.02 || select=7/8
[epoch=202/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:28:52] [epoch=202/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.729 (2.729)  Prec@1 16.02 (16.02) Prec@5 61.33 (61.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:28:57] [epoch=202/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.961 (2.225)  Prec@1 32.14 (37.67) Prec@5 72.62 (81.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.67 Prec@5 81.16 Error@1 62.33 Error@5 18.84 Loss:2.225
***[2020-01-29 07:28:57]*** VALID [epoch=202/600] loss = 2.224939, accuracy@1 = 37.67, accuracy@5 = 81.16 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:28:58]*** start epoch=203/600 Time Left: [03:31:03], LR=[0.074317 ~ 0.074317], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=203, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.741521682037552, FLOP=40.81
[Search] : epoch=203/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:28:58] [epoch=203/600][000/098] Time 0.63 (0.63) Data 0.37 (0.37) Base-Loss 0.839 (0.839)  Prec@1 74.22 (74.22) Prec@5 95.31 (95.31) Acls-loss 0.779 (0.779) FLOP-Loss 0.000 (0.000) Arch-Loss 0.779 (0.779)
**TRAIN** [2020-01-29 07:29:22] [epoch=203/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.715 (0.816)  Prec@1 76.19 (72.34) Prec@5 99.40 (97.72) Acls-loss 0.842 (0.836) FLOP-Loss 0.000 (0.000) Arch-Loss 0.842 (0.836)
 **TRAIN** Prec@1 72.34 Prec@5 97.72 Error@1 27.66 Error@5 2.28 Base-Loss:0.816, Arch-Loss=0.836
***[2020-01-29 07:29:22]*** TRAIN [epoch=203/600] base-loss = 0.816075, arch-loss = 0.835547, accuracy-1 = 72.34, accuracy-5 = 97.72
[epoch=203/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 14, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.187264)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.434 0.215 0.351  ||  0.2045 -0.4960 -0.0060  || discrepancy=0.08 || select=0/3
001/003-th : 0.376 0.145 0.479  ||  0.0470 -0.9088 0.2899  || discrepancy=0.10 || select=2/3
002/003-th : 0.064 0.185 0.751  ||  -1.2871 -0.2314 1.1707  || discrepancy=0.57 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.083 0.100 0.111 0.141 0.163 0.170 0.176  ||  -0.740 -0.343 -0.154 -0.050 0.186 0.332 0.375 0.411   || dis=0.01 || select=7/8
001/019-th : 0.128 0.128 0.125 0.125 0.128 0.125 0.123 0.120  ||  0.020 0.023 -0.003 -0.001 0.020 -0.001 -0.018 -0.045  || dis=0.00 || select=1/8
002/019-th : 0.117 0.125 0.128 0.130 0.129 0.129 0.123 0.118  ||  -0.064 0.007 0.023 0.046 0.037 0.037 -0.015 -0.056    || dis=0.00 || select=3/8
003/019-th : 0.119 0.120 0.122 0.123 0.126 0.129 0.132 0.129  ||  -0.051 -0.038 -0.022 -0.013 0.011 0.032 0.057 0.031   || dis=0.00 || select=6/8
004/019-th : 0.111 0.114 0.118 0.122 0.132 0.132 0.138 0.133  ||  -0.117 -0.089 -0.050 -0.025 0.057 0.060 0.104 0.065   || dis=0.01 || select=6/8
005/019-th : 0.108 0.117 0.118 0.124 0.129 0.130 0.136 0.138  ||  -0.137 -0.065 -0.055 0.001 0.035 0.045 0.089 0.106    || dis=0.00 || select=7/8
006/019-th : 0.114 0.111 0.117 0.124 0.130 0.131 0.136 0.137  ||  -0.088 -0.112 -0.059 -0.006 0.040 0.051 0.088 0.096   || dis=0.00 || select=7/8
007/019-th : 0.068 0.077 0.094 0.113 0.139 0.149 0.169 0.190  ||  -0.548 -0.418 -0.222 -0.041 0.169 0.239 0.363 0.478   || dis=0.02 || select=7/8
008/019-th : 0.052 0.063 0.089 0.127 0.139 0.169 0.178 0.184  ||  -0.793 -0.594 -0.243 0.105 0.195 0.392 0.442 0.479    || dis=0.01 || select=7/8
009/019-th : 0.094 0.095 0.102 0.116 0.128 0.140 0.155 0.169  ||  -0.258 -0.249 -0.185 -0.049 0.049 0.132 0.235 0.325   || dis=0.01 || select=7/8
010/019-th : 0.099 0.106 0.110 0.127 0.133 0.139 0.143 0.143  ||  -0.221 -0.160 -0.118 0.021 0.073 0.114 0.139 0.141    || dis=0.00 || select=7/8
011/019-th : 0.099 0.098 0.103 0.113 0.123 0.139 0.156 0.169  ||  -0.213 -0.224 -0.170 -0.084 0.003 0.124 0.238 0.319   || dis=0.01 || select=7/8
012/019-th : 0.109 0.110 0.114 0.120 0.123 0.136 0.142 0.145  ||  -0.136 -0.122 -0.088 -0.041 -0.013 0.088 0.131 0.147  || dis=0.00 || select=7/8
013/019-th : 0.038 0.043 0.056 0.073 0.090 0.147 0.217 0.336  ||  -0.938 -0.816 -0.536 -0.281 -0.064 0.424 0.809 1.248  || dis=0.12 || select=7/8
014/019-th : 0.053 0.057 0.073 0.092 0.130 0.156 0.209 0.230  ||  -0.733 -0.667 -0.417 -0.177 0.167 0.349 0.641 0.733   || dis=0.02 || select=7/8
015/019-th : 0.036 0.037 0.050 0.073 0.100 0.131 0.239 0.333  ||  -0.947 -0.936 -0.623 -0.248 0.064 0.339 0.940 1.271   || dis=0.09 || select=7/8
016/019-th : 0.056 0.075 0.096 0.123 0.136 0.166 0.174 0.174  ||  -0.734 -0.440 -0.195 0.051 0.156 0.353 0.397 0.397    || dis=0.00 || select=7/8
017/019-th : 0.118 0.112 0.119 0.118 0.132 0.131 0.133 0.137  ||  -0.052 -0.102 -0.048 -0.058 0.056 0.054 0.067 0.094   || dis=0.00 || select=7/8
018/019-th : 0.087 0.104 0.111 0.121 0.129 0.131 0.148 0.169  ||  -0.351 -0.166 -0.102 -0.016 0.047 0.066 0.183 0.315   || dis=0.02 || select=7/8
[epoch=203/600] FLOP : 28.19 MB, ratio : 0.6906, Expected-ratio : 0.7000, Discrepancy : 0.049
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:29:23] [epoch=203/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.602 (1.602)  Prec@1 40.62 (40.62) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:29:29] [epoch=203/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.519 (2.190)  Prec@1 27.98 (38.32) Prec@5 76.19 (81.69) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.32 Prec@5 81.69 Error@1 61.68 Error@5 18.31 Loss:2.190
***[2020-01-29 07:29:29]*** VALID [epoch=203/600] loss = 2.190301, accuracy@1 = 38.32, accuracy@5 = 81.69 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:29:29]*** start epoch=204/600 Time Left: [03:30:29], LR=[0.074088 ~ 0.074088], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=204, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.7302965015492027, FLOP=40.81
[Search] : epoch=204/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:29:30] [epoch=204/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.841 (0.841)  Prec@1 71.88 (71.88) Prec@5 97.27 (97.27) Acls-loss 0.844 (0.844) FLOP-Loss 0.000 (0.000) Arch-Loss 0.844 (0.844)
**TRAIN** [2020-01-29 07:29:53] [epoch=204/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.648 (0.801)  Prec@1 78.57 (72.52) Prec@5 98.81 (97.90) Acls-loss 0.752 (0.841) FLOP-Loss 0.000 (0.274) Arch-Loss 0.752 (1.390)
 **TRAIN** Prec@1 72.52 Prec@5 97.90 Error@1 27.48 Error@5 2.10 Base-Loss:0.801, Arch-Loss=1.390
***[2020-01-29 07:29:53]*** TRAIN [epoch=204/600] base-loss = 0.800762, arch-loss = 1.389859, accuracy-1 = 72.52, accuracy-5 = 97.90
[epoch=204/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 14, 14, 14, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.138112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.215 0.335  ||  0.2463 -0.4912 -0.0490  || discrepancy=0.11 || select=0/3
001/003-th : 0.391 0.145 0.463  ||  0.0852 -0.9040 0.2541  || discrepancy=0.07 || select=2/3
002/003-th : 0.064 0.190 0.745  ||  -1.2882 -0.2031 1.1618  || discrepancy=0.55 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.082 0.101 0.114 0.140 0.167 0.166 0.173  ||  -0.720 -0.358 -0.142 -0.028 0.183 0.354 0.353 0.391   || dis=0.01 || select=7/8
001/019-th : 0.131 0.131 0.128 0.131 0.125 0.122 0.118 0.115  ||  0.050 0.051 0.024 0.048 -0.001 -0.025 -0.055 -0.081   || dis=0.00 || select=1/8
002/019-th : 0.121 0.130 0.132 0.133 0.127 0.125 0.119 0.113  ||  -0.032 0.043 0.056 0.064 0.017 0.003 -0.044 -0.094    || dis=0.00 || select=3/8
003/019-th : 0.123 0.124 0.126 0.125 0.125 0.127 0.128 0.124  ||  -0.015 -0.005 0.008 -0.001 -0.001 0.015 0.022 -0.010  || dis=0.00 || select=6/8
004/019-th : 0.115 0.117 0.121 0.124 0.132 0.129 0.133 0.128  ||  -0.080 -0.058 -0.029 -0.003 0.062 0.039 0.064 0.027   || dis=0.00 || select=6/8
005/019-th : 0.111 0.122 0.122 0.126 0.127 0.127 0.134 0.132  ||  -0.113 -0.020 -0.023 0.009 0.018 0.017 0.070 0.061    || dis=0.00 || select=6/8
006/019-th : 0.118 0.115 0.122 0.128 0.127 0.127 0.132 0.132  ||  -0.054 -0.079 -0.017 0.026 0.023 0.016 0.055 0.056    || dis=0.00 || select=7/8
007/019-th : 0.070 0.080 0.098 0.113 0.141 0.148 0.165 0.184  ||  -0.521 -0.397 -0.186 -0.045 0.174 0.225 0.335 0.443   || dis=0.02 || select=7/8
008/019-th : 0.053 0.063 0.093 0.128 0.138 0.169 0.178 0.179  ||  -0.762 -0.594 -0.211 0.109 0.182 0.386 0.439 0.444    || dis=0.00 || select=7/8
009/019-th : 0.098 0.098 0.104 0.119 0.129 0.136 0.152 0.164  ||  -0.225 -0.226 -0.163 -0.027 0.046 0.101 0.212 0.290   || dis=0.01 || select=7/8
010/019-th : 0.103 0.108 0.114 0.129 0.133 0.134 0.139 0.140  ||  -0.186 -0.136 -0.090 0.036 0.067 0.076 0.112 0.115    || dis=0.00 || select=7/8
011/019-th : 0.102 0.101 0.106 0.114 0.122 0.137 0.153 0.164  ||  -0.186 -0.196 -0.149 -0.076 -0.006 0.108 0.216 0.288  || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.116 0.121 0.124 0.134 0.138 0.139  ||  -0.102 -0.089 -0.072 -0.029 -0.003 0.068 0.101 0.111  || dis=0.00 || select=7/8
013/019-th : 0.038 0.043 0.057 0.075 0.093 0.149 0.215 0.331  ||  -0.933 -0.806 -0.540 -0.262 -0.048 0.425 0.797 1.226  || dis=0.12 || select=7/8
014/019-th : 0.054 0.058 0.075 0.095 0.132 0.157 0.203 0.225  ||  -0.722 -0.644 -0.391 -0.151 0.173 0.346 0.606 0.706   || dis=0.02 || select=7/8
015/019-th : 0.037 0.037 0.051 0.073 0.100 0.133 0.243 0.325  ||  -0.931 -0.931 -0.618 -0.246 0.062 0.350 0.953 1.243   || dis=0.08 || select=7/8
016/019-th : 0.058 0.077 0.100 0.126 0.136 0.163 0.170 0.169  ||  -0.701 -0.417 -0.164 0.072 0.151 0.332 0.372 0.363    || dis=0.00 || select=6/8
017/019-th : 0.124 0.117 0.121 0.118 0.131 0.127 0.129 0.132  ||  -0.010 -0.064 -0.031 -0.054 0.052 0.019 0.035 0.056   || dis=0.00 || select=7/8
018/019-th : 0.088 0.105 0.114 0.125 0.127 0.131 0.143 0.167  ||  -0.336 -0.157 -0.078 0.014 0.033 0.064 0.147 0.305    || dis=0.02 || select=7/8
[epoch=204/600] FLOP : 28.14 MB, ratio : 0.6894, Expected-ratio : 0.7000, Discrepancy : 0.047
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:29:54] [epoch=204/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.606 (1.606)  Prec@1 49.61 (49.61) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:30:00] [epoch=204/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.160 (2.315)  Prec@1 48.81 (37.93) Prec@5 86.31 (81.27) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.93 Prec@5 81.27 Error@1 62.07 Error@5 18.73 Loss:2.315
***[2020-01-29 07:30:00]*** VALID [epoch=204/600] loss = 2.314836, accuracy@1 = 37.93, accuracy@5 = 81.27 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:30:00]*** start epoch=205/600 Time Left: [03:29:56], LR=[0.073858 ~ 0.073858], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=205, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.719038962636041, FLOP=40.81
[Search] : epoch=205/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:30:01] [epoch=205/600][000/098] Time 0.75 (0.75) Data 0.36 (0.36) Base-Loss 0.844 (0.844)  Prec@1 70.31 (70.31) Prec@5 97.66 (97.66) Acls-loss 0.771 (0.771) FLOP-Loss 0.000 (0.000) Arch-Loss 0.771 (0.771)
**TRAIN** [2020-01-29 07:30:25] [epoch=205/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.939 (0.831)  Prec@1 70.24 (71.84) Prec@5 98.21 (97.74) Acls-loss 0.881 (0.843) FLOP-Loss 0.000 (0.027) Arch-Loss 0.881 (0.898)
 **TRAIN** Prec@1 71.84 Prec@5 97.74 Error@1 28.16 Error@5 2.26 Base-Loss:0.831, Arch-Loss=0.898
***[2020-01-29 07:30:25]*** TRAIN [epoch=205/600] base-loss = 0.831350, arch-loss = 0.897786, accuracy-1 = 71.84, accuracy-5 = 97.74
[epoch=205/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 12, 11, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.513472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.448 0.215 0.337  ||  0.2426 -0.4950 -0.0433  || discrepancy=0.11 || select=0/3
001/003-th : 0.390 0.148 0.463  ||  0.0836 -0.8864 0.2560  || discrepancy=0.07 || select=2/3
002/003-th : 0.062 0.187 0.750  ||  -1.3097 -0.2083 1.1796  || discrepancy=0.56 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.081 0.099 0.114 0.142 0.168 0.167 0.172  ||  -0.716 -0.365 -0.160 -0.022 0.195 0.364 0.358 0.386   || dis=0.00 || select=7/8
001/019-th : 0.131 0.130 0.127 0.131 0.124 0.123 0.119 0.115  ||  0.048 0.044 0.018 0.046 -0.005 -0.015 -0.050 -0.078   || dis=0.00 || select=0/8
002/019-th : 0.120 0.130 0.130 0.133 0.127 0.126 0.120 0.114  ||  -0.035 0.038 0.042 0.064 0.022 0.011 -0.041 -0.089    || dis=0.00 || select=3/8
003/019-th : 0.122 0.123 0.126 0.125 0.126 0.127 0.127 0.124  ||  -0.020 -0.011 0.014 0.002 0.014 0.018 0.015 -0.007    || dis=0.00 || select=5/8
004/019-th : 0.114 0.116 0.121 0.123 0.134 0.130 0.134 0.129  ||  -0.088 -0.071 -0.027 -0.014 0.075 0.043 0.071 0.034   || dis=0.00 || select=4/8
005/019-th : 0.112 0.123 0.120 0.127 0.125 0.127 0.133 0.133  ||  -0.109 -0.012 -0.037 0.015 0.004 0.019 0.064 0.064    || dis=0.00 || select=7/8
006/019-th : 0.117 0.115 0.121 0.129 0.126 0.126 0.133 0.132  ||  -0.064 -0.078 -0.027 0.036 0.014 0.015 0.069 0.058    || dis=0.00 || select=6/8
007/019-th : 0.070 0.079 0.098 0.113 0.141 0.149 0.166 0.185  ||  -0.530 -0.401 -0.187 -0.048 0.176 0.230 0.340 0.448   || dis=0.02 || select=7/8
008/019-th : 0.053 0.063 0.093 0.126 0.136 0.168 0.180 0.181  ||  -0.769 -0.593 -0.214 0.097 0.175 0.382 0.452 0.456    || dis=0.00 || select=7/8
009/019-th : 0.097 0.097 0.103 0.120 0.130 0.136 0.152 0.163  ||  -0.233 -0.230 -0.170 -0.017 0.063 0.107 0.218 0.286   || dis=0.01 || select=7/8
010/019-th : 0.103 0.107 0.113 0.128 0.134 0.135 0.139 0.141  ||  -0.187 -0.150 -0.093 0.030 0.072 0.084 0.113 0.123    || dis=0.00 || select=7/8
011/019-th : 0.102 0.101 0.106 0.114 0.122 0.138 0.152 0.166  ||  -0.189 -0.201 -0.146 -0.074 -0.011 0.115 0.209 0.297  || dis=0.01 || select=7/8
012/019-th : 0.113 0.114 0.115 0.122 0.126 0.133 0.137 0.140  ||  -0.103 -0.090 -0.078 -0.024 0.008 0.067 0.095 0.114   || dis=0.00 || select=7/8
013/019-th : 0.038 0.043 0.057 0.073 0.094 0.146 0.219 0.330  ||  -0.939 -0.801 -0.536 -0.280 -0.028 0.408 0.813 1.225  || dis=0.11 || select=7/8
014/019-th : 0.053 0.058 0.075 0.095 0.132 0.157 0.206 0.224  ||  -0.732 -0.643 -0.388 -0.157 0.179 0.348 0.618 0.703   || dis=0.02 || select=7/8
015/019-th : 0.037 0.036 0.050 0.074 0.100 0.132 0.244 0.326  ||  -0.930 -0.950 -0.620 -0.235 0.063 0.347 0.959 1.249   || dis=0.08 || select=7/8
016/019-th : 0.058 0.076 0.100 0.127 0.134 0.163 0.171 0.169  ||  -0.701 -0.429 -0.156 0.081 0.135 0.331 0.375 0.367    || dis=0.00 || select=6/8
017/019-th : 0.123 0.116 0.120 0.118 0.132 0.129 0.129 0.132  ||  -0.013 -0.069 -0.039 -0.057 0.056 0.034 0.033 0.060   || dis=0.00 || select=7/8
018/019-th : 0.087 0.106 0.114 0.125 0.127 0.130 0.143 0.168  ||  -0.344 -0.153 -0.075 0.013 0.029 0.056 0.149 0.313    || dis=0.03 || select=7/8
[epoch=205/600] FLOP : 27.51 MB, ratio : 0.6741, Expected-ratio : 0.7000, Discrepancy : 0.047
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:30:25] [epoch=205/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.030 (2.030)  Prec@1 32.81 (32.81) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:30:31] [epoch=205/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 3.661 (2.243)  Prec@1 36.90 (38.73) Prec@5 80.36 (82.00) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.73 Prec@5 82.00 Error@1 61.27 Error@5 18.00 Loss:2.243
***[2020-01-29 07:30:31]*** VALID [epoch=205/600] loss = 2.242951, accuracy@1 = 38.73, accuracy@5 = 82.00 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:30:31]*** start epoch=206/600 Time Left: [03:29:23], LR=[0.073628 ~ 0.073628], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=206, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.707749373929183, FLOP=40.81
[Search] : epoch=206/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:30:32] [epoch=206/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.825 (0.825)  Prec@1 71.09 (71.09) Prec@5 96.48 (96.48) Acls-loss 0.958 (0.958) FLOP-Loss 0.000 (0.000) Arch-Loss 0.958 (0.958)
**TRAIN** [2020-01-29 07:30:57] [epoch=206/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.959 (0.811)  Prec@1 67.26 (72.32) Prec@5 97.62 (97.93) Acls-loss 0.677 (0.840) FLOP-Loss 0.000 (0.027) Arch-Loss 0.677 (0.895)
 **TRAIN** Prec@1 72.32 Prec@5 97.93 Error@1 27.68 Error@5 2.07 Base-Loss:0.811, Arch-Loss=0.895
***[2020-01-29 07:30:57]*** TRAIN [epoch=206/600] base-loss = 0.811051, arch-loss = 0.894528, accuracy-1 = 72.32, accuracy-5 = 97.93
[epoch=206/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 12, 11, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.513472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.211 0.340  ||  0.2406 -0.5119 -0.0382  || discrepancy=0.11 || select=0/3
001/003-th : 0.387 0.147 0.466  ||  0.0789 -0.8907 0.2629  || discrepancy=0.08 || select=2/3
002/003-th : 0.061 0.186 0.753  ||  -1.3232 -0.2088 1.1902  || discrepancy=0.57 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.081 0.098 0.112 0.143 0.168 0.169 0.172  ||  -0.723 -0.364 -0.176 -0.040 0.206 0.366 0.375 0.392   || dis=0.00 || select=7/8
001/019-th : 0.131 0.130 0.128 0.131 0.124 0.123 0.119 0.116  ||  0.049 0.038 0.023 0.048 -0.010 -0.014 -0.050 -0.075   || dis=0.00 || select=0/8
002/019-th : 0.120 0.129 0.129 0.133 0.128 0.126 0.120 0.115  ||  -0.036 0.037 0.032 0.064 0.027 0.009 -0.040 -0.085    || dis=0.00 || select=3/8
003/019-th : 0.122 0.122 0.125 0.127 0.127 0.127 0.126 0.124  ||  -0.020 -0.024 0.002 0.017 0.017 0.023 0.015 -0.002    || dis=0.00 || select=5/8
004/019-th : 0.113 0.116 0.121 0.125 0.134 0.131 0.133 0.128  ||  -0.098 -0.071 -0.025 0.004 0.073 0.056 0.069 0.031    || dis=0.00 || select=4/8
005/019-th : 0.112 0.123 0.120 0.127 0.124 0.128 0.133 0.133  ||  -0.108 -0.011 -0.036 0.014 -0.007 0.023 0.064 0.065   || dis=0.00 || select=7/8
006/019-th : 0.116 0.115 0.120 0.127 0.127 0.128 0.135 0.132  ||  -0.067 -0.078 -0.036 0.017 0.018 0.027 0.083 0.054    || dis=0.00 || select=6/8
007/019-th : 0.069 0.078 0.099 0.114 0.139 0.150 0.166 0.186  ||  -0.540 -0.409 -0.179 -0.039 0.163 0.239 0.341 0.452   || dis=0.02 || select=7/8
008/019-th : 0.053 0.063 0.093 0.128 0.136 0.166 0.180 0.182  ||  -0.773 -0.605 -0.211 0.108 0.170 0.372 0.455 0.466    || dis=0.00 || select=7/8
009/019-th : 0.097 0.096 0.103 0.122 0.130 0.137 0.152 0.163  ||  -0.233 -0.238 -0.171 -0.005 0.059 0.112 0.217 0.286   || dis=0.01 || select=7/8
010/019-th : 0.102 0.107 0.113 0.129 0.133 0.137 0.139 0.141  ||  -0.196 -0.153 -0.096 0.039 0.066 0.102 0.111 0.125    || dis=0.00 || select=7/8
011/019-th : 0.101 0.100 0.105 0.114 0.124 0.137 0.153 0.165  ||  -0.199 -0.202 -0.154 -0.076 0.008 0.112 0.220 0.294   || dis=0.01 || select=7/8
012/019-th : 0.112 0.114 0.115 0.122 0.126 0.134 0.134 0.142  ||  -0.107 -0.087 -0.080 -0.025 0.009 0.073 0.075 0.129   || dis=0.01 || select=7/8
013/019-th : 0.038 0.043 0.056 0.074 0.094 0.146 0.219 0.330  ||  -0.930 -0.805 -0.549 -0.275 -0.028 0.409 0.815 1.227  || dis=0.11 || select=7/8
014/019-th : 0.053 0.058 0.075 0.095 0.130 0.156 0.207 0.226  ||  -0.743 -0.646 -0.388 -0.155 0.161 0.345 0.626 0.715   || dis=0.02 || select=7/8
015/019-th : 0.037 0.036 0.048 0.072 0.099 0.133 0.247 0.328  ||  -0.925 -0.941 -0.654 -0.252 0.065 0.356 0.977 1.260   || dis=0.08 || select=7/8
016/019-th : 0.058 0.077 0.101 0.127 0.135 0.161 0.171 0.170  ||  -0.703 -0.424 -0.153 0.076 0.140 0.314 0.376 0.370    || dis=0.00 || select=6/8
017/019-th : 0.122 0.117 0.120 0.118 0.133 0.128 0.129 0.133  ||  -0.020 -0.063 -0.041 -0.055 0.063 0.029 0.031 0.064   || dis=0.00 || select=7/8
018/019-th : 0.087 0.104 0.115 0.125 0.128 0.130 0.142 0.169  ||  -0.349 -0.169 -0.065 0.014 0.039 0.058 0.145 0.318    || dis=0.03 || select=7/8
[epoch=206/600] FLOP : 27.51 MB, ratio : 0.6741, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:30:57] [epoch=206/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.708 (1.708)  Prec@1 44.53 (44.53) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:31:03] [epoch=206/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.582 (2.187)  Prec@1 19.05 (36.82) Prec@5 70.83 (81.76) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.82 Prec@5 81.76 Error@1 63.18 Error@5 18.24 Loss:2.187
***[2020-01-29 07:31:03]*** VALID [epoch=206/600] loss = 2.186984, accuracy@1 = 36.82, accuracy@5 = 81.76 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:31:03]*** start epoch=207/600 Time Left: [03:28:51], LR=[0.073396 ~ 0.073396], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=207, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.6964280449384055, FLOP=40.81
[Search] : epoch=207/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:31:04] [epoch=207/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.683 (0.683)  Prec@1 76.17 (76.17) Prec@5 98.83 (98.83) Acls-loss 0.902 (0.902) FLOP-Loss 0.000 (0.000) Arch-Loss 0.902 (0.902)
**TRAIN** [2020-01-29 07:31:28] [epoch=207/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.978 (0.807)  Prec@1 66.07 (72.46) Prec@5 97.62 (97.90) Acls-loss 0.962 (0.843) FLOP-Loss 0.000 (0.028) Arch-Loss 0.962 (0.898)
 **TRAIN** Prec@1 72.46 Prec@5 97.90 Error@1 27.54 Error@5 2.10 Base-Loss:0.807, Arch-Loss=0.898
***[2020-01-29 07:31:28]*** TRAIN [epoch=207/600] base-loss = 0.807065, arch-loss = 0.897985, accuracy-1 = 72.46, accuracy-5 = 97.90
[epoch=207/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 12, 12, 14, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.271552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.215 0.340  ||  0.2364 -0.4914 -0.0345  || discrepancy=0.10 || select=0/3
001/003-th : 0.386 0.147 0.467  ||  0.0769 -0.8880 0.2664  || discrepancy=0.08 || select=2/3
002/003-th : 0.060 0.184 0.756  ||  -1.3345 -0.2139 1.2013  || discrepancy=0.57 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.081 0.097 0.111 0.138 0.169 0.171 0.175  ||  -0.709 -0.368 -0.186 -0.052 0.170 0.371 0.383 0.406   || dis=0.00 || select=7/8
001/019-th : 0.130 0.130 0.127 0.131 0.125 0.123 0.118 0.116  ||  0.044 0.038 0.020 0.046 -0.000 -0.012 -0.051 -0.072   || dis=0.00 || select=3/8
002/019-th : 0.120 0.128 0.128 0.133 0.129 0.126 0.120 0.115  ||  -0.040 0.029 0.026 0.064 0.031 0.013 -0.036 -0.077    || dis=0.00 || select=3/8
003/019-th : 0.121 0.121 0.125 0.125 0.128 0.128 0.126 0.125  ||  -0.026 -0.027 0.000 0.002 0.027 0.031 0.015 0.005     || dis=0.00 || select=5/8
004/019-th : 0.111 0.116 0.122 0.122 0.133 0.134 0.133 0.129  ||  -0.108 -0.069 -0.021 -0.018 0.071 0.075 0.066 0.038   || dis=0.00 || select=5/8
005/019-th : 0.112 0.121 0.120 0.127 0.122 0.129 0.135 0.134  ||  -0.107 -0.028 -0.039 0.014 -0.023 0.031 0.075 0.072   || dis=0.00 || select=6/8
006/019-th : 0.116 0.115 0.120 0.126 0.128 0.129 0.135 0.133  ||  -0.075 -0.082 -0.040 0.009 0.026 0.035 0.082 0.063    || dis=0.00 || select=6/8
007/019-th : 0.069 0.078 0.098 0.113 0.138 0.151 0.166 0.187  ||  -0.536 -0.409 -0.185 -0.044 0.153 0.244 0.343 0.457   || dis=0.02 || select=7/8
008/019-th : 0.053 0.062 0.091 0.127 0.136 0.170 0.179 0.181  ||  -0.766 -0.609 -0.223 0.106 0.173 0.397 0.451 0.461    || dis=0.00 || select=7/8
009/019-th : 0.095 0.097 0.103 0.121 0.131 0.137 0.152 0.164  ||  -0.248 -0.237 -0.168 -0.010 0.065 0.110 0.220 0.294   || dis=0.01 || select=7/8
010/019-th : 0.102 0.106 0.112 0.131 0.133 0.137 0.138 0.141  ||  -0.198 -0.157 -0.102 0.052 0.072 0.101 0.109 0.126    || dis=0.00 || select=7/8
011/019-th : 0.100 0.100 0.106 0.113 0.125 0.138 0.153 0.165  ||  -0.201 -0.207 -0.152 -0.083 0.021 0.113 0.218 0.297   || dis=0.01 || select=7/8
012/019-th : 0.112 0.114 0.115 0.123 0.126 0.133 0.136 0.142  ||  -0.110 -0.090 -0.083 -0.016 0.006 0.067 0.085 0.128   || dis=0.01 || select=7/8
013/019-th : 0.038 0.044 0.056 0.074 0.093 0.145 0.221 0.329  ||  -0.940 -0.794 -0.540 -0.272 -0.041 0.406 0.825 1.223  || dis=0.11 || select=7/8
014/019-th : 0.052 0.057 0.075 0.094 0.127 0.158 0.208 0.228  ||  -0.747 -0.656 -0.381 -0.164 0.139 0.356 0.635 0.727   || dis=0.02 || select=7/8
015/019-th : 0.037 0.036 0.048 0.073 0.099 0.134 0.246 0.327  ||  -0.919 -0.956 -0.663 -0.239 0.067 0.364 0.976 1.261   || dis=0.08 || select=7/8
016/019-th : 0.058 0.077 0.100 0.127 0.136 0.159 0.171 0.171  ||  -0.706 -0.425 -0.156 0.080 0.150 0.304 0.376 0.375    || dis=0.00 || select=6/8
017/019-th : 0.121 0.118 0.119 0.118 0.134 0.128 0.129 0.134  ||  -0.029 -0.055 -0.047 -0.054 0.069 0.026 0.031 0.069   || dis=0.00 || select=4/8
018/019-th : 0.086 0.104 0.116 0.125 0.128 0.129 0.142 0.170  ||  -0.353 -0.165 -0.061 0.013 0.038 0.049 0.144 0.324    || dis=0.03 || select=7/8
[epoch=207/600] FLOP : 27.27 MB, ratio : 0.6682, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:31:29] [epoch=207/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.236 (3.236)  Prec@1 22.66 (22.66) Prec@5 73.83 (73.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:31:35] [epoch=207/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.484 (2.432)  Prec@1 19.05 (34.56) Prec@5 64.88 (80.00) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.56 Prec@5 80.00 Error@1 65.44 Error@5 20.00 Loss:2.432
***[2020-01-29 07:31:35]*** VALID [epoch=207/600] loss = 2.432059, accuracy@1 = 34.56, accuracy@5 = 80.00 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:31:35]*** start epoch=208/600 Time Left: [03:28:19], LR=[0.073165 ~ 0.073165], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=208, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.685075286043662, FLOP=40.81
[Search] : epoch=208/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:31:35] [epoch=208/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.888 (0.888)  Prec@1 65.62 (65.62) Prec@5 97.66 (97.66) Acls-loss 0.697 (0.697) FLOP-Loss 0.000 (0.000) Arch-Loss 0.697 (0.697)
**TRAIN** [2020-01-29 07:32:00] [epoch=208/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.723 (0.825)  Prec@1 75.00 (71.67) Prec@5 99.40 (97.76) Acls-loss 0.856 (0.839) FLOP-Loss 0.000 (0.137) Arch-Loss 0.856 (1.113)
 **TRAIN** Prec@1 71.67 Prec@5 97.76 Error@1 28.33 Error@5 2.24 Base-Loss:0.825, Arch-Loss=1.113
***[2020-01-29 07:32:00]*** TRAIN [epoch=208/600] base-loss = 0.825367, arch-loss = 1.112942, accuracy-1 = 71.67, accuracy-5 = 97.76
[epoch=208/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 11, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.271552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.452 0.212 0.335  ||  0.2516 -0.5055 -0.0479  || discrepancy=0.12 || select=0/3
001/003-th : 0.392 0.148 0.461  ||  0.0914 -0.8838 0.2536  || discrepancy=0.07 || select=2/3
002/003-th : 0.060 0.186 0.754  ||  -1.3340 -0.2004 1.1966  || discrepancy=0.57 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.081 0.098 0.112 0.138 0.171 0.171 0.172  ||  -0.701 -0.362 -0.179 -0.044 0.165 0.380 0.384 0.385   || dis=0.00 || select=7/8
001/019-th : 0.132 0.131 0.128 0.132 0.123 0.122 0.117 0.114  ||  0.058 0.048 0.031 0.061 -0.010 -0.020 -0.067 -0.086   || dis=0.00 || select=3/8
002/019-th : 0.121 0.130 0.131 0.134 0.127 0.125 0.119 0.114  ||  -0.027 0.040 0.046 0.068 0.021 0.002 -0.047 -0.094    || dis=0.00 || select=3/8
003/019-th : 0.122 0.122 0.127 0.126 0.127 0.127 0.125 0.123  ||  -0.020 -0.017 0.023 0.015 0.024 0.019 0.005 -0.009    || dis=0.00 || select=4/8
004/019-th : 0.113 0.116 0.124 0.124 0.132 0.132 0.132 0.128  ||  -0.096 -0.068 -0.005 -0.001 0.061 0.058 0.057 0.027   || dis=0.00 || select=4/8
005/019-th : 0.114 0.124 0.121 0.127 0.121 0.128 0.132 0.133  ||  -0.091 -0.011 -0.031 0.016 -0.028 0.021 0.056 0.060   || dis=0.00 || select=7/8
006/019-th : 0.117 0.116 0.122 0.128 0.126 0.128 0.133 0.131  ||  -0.063 -0.070 -0.022 0.027 0.012 0.026 0.067 0.048    || dis=0.00 || select=6/8
007/019-th : 0.069 0.079 0.099 0.115 0.139 0.149 0.165 0.185  ||  -0.537 -0.399 -0.180 -0.029 0.161 0.235 0.332 0.447   || dis=0.02 || select=7/8
008/019-th : 0.052 0.063 0.092 0.130 0.135 0.171 0.178 0.180  ||  -0.791 -0.595 -0.211 0.126 0.166 0.405 0.443 0.453    || dis=0.00 || select=7/8
009/019-th : 0.097 0.098 0.104 0.121 0.130 0.136 0.151 0.163  ||  -0.238 -0.224 -0.162 -0.009 0.058 0.103 0.210 0.285   || dis=0.01 || select=7/8
010/019-th : 0.102 0.108 0.114 0.132 0.132 0.137 0.136 0.139  ||  -0.194 -0.142 -0.088 0.061 0.062 0.099 0.094 0.115    || dis=0.00 || select=7/8
011/019-th : 0.102 0.100 0.107 0.113 0.127 0.137 0.152 0.163  ||  -0.190 -0.205 -0.138 -0.087 0.035 0.108 0.211 0.279   || dis=0.01 || select=7/8
012/019-th : 0.113 0.115 0.116 0.125 0.126 0.133 0.134 0.140  ||  -0.100 -0.082 -0.069 0.001 0.009 0.062 0.071 0.113    || dis=0.01 || select=7/8
013/019-th : 0.038 0.044 0.057 0.075 0.093 0.149 0.219 0.325  ||  -0.934 -0.801 -0.533 -0.261 -0.042 0.428 0.812 1.209  || dis=0.11 || select=7/8
014/019-th : 0.052 0.058 0.077 0.095 0.128 0.158 0.207 0.225  ||  -0.747 -0.645 -0.360 -0.155 0.147 0.355 0.624 0.708   || dis=0.02 || select=7/8
015/019-th : 0.037 0.036 0.048 0.073 0.101 0.134 0.247 0.323  ||  -0.930 -0.948 -0.660 -0.237 0.082 0.369 0.977 1.246   || dis=0.08 || select=7/8
016/019-th : 0.059 0.078 0.101 0.128 0.139 0.157 0.169 0.169  ||  -0.688 -0.413 -0.151 0.083 0.165 0.291 0.363 0.360    || dis=0.00 || select=6/8
017/019-th : 0.123 0.119 0.120 0.119 0.133 0.127 0.127 0.132  ||  -0.015 -0.044 -0.042 -0.047 0.060 0.021 0.019 0.056   || dis=0.00 || select=4/8
018/019-th : 0.087 0.104 0.118 0.126 0.129 0.129 0.140 0.168  ||  -0.349 -0.165 -0.041 0.023 0.046 0.046 0.130 0.313    || dis=0.03 || select=7/8
[epoch=208/600] FLOP : 27.27 MB, ratio : 0.6682, Expected-ratio : 0.7000, Discrepancy : 0.047
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:32:00] [epoch=208/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.212 (1.212)  Prec@1 57.81 (57.81) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:32:06] [epoch=208/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.060 (2.365)  Prec@1 35.71 (37.39) Prec@5 77.98 (81.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.39 Prec@5 81.99 Error@1 62.61 Error@5 18.01 Loss:2.365
***[2020-01-29 07:32:06]*** VALID [epoch=208/600] loss = 2.365458, accuracy@1 = 37.39, accuracy@5 = 81.99 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:32:06]*** start epoch=209/600 Time Left: [03:27:46], LR=[0.072932 ~ 0.072932], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=209, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.673691408486573, FLOP=40.81
[Search] : epoch=209/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:32:07] [epoch=209/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.757 (0.757)  Prec@1 76.56 (76.56) Prec@5 98.83 (98.83) Acls-loss 0.990 (0.990) FLOP-Loss 0.000 (0.000) Arch-Loss 0.990 (0.990)
**TRAIN** [2020-01-29 07:32:31] [epoch=209/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.794 (0.810)  Prec@1 71.43 (72.44) Prec@5 100.00 (97.84) Acls-loss 0.917 (0.832) FLOP-Loss 0.000 (0.000) Arch-Loss 0.917 (0.832)
 **TRAIN** Prec@1 72.44 Prec@5 97.84 Error@1 27.56 Error@5 2.16 Base-Loss:0.810, Arch-Loss=0.832
***[2020-01-29 07:32:31]*** TRAIN [epoch=209/600] base-loss = 0.810392, arch-loss = 0.831993, accuracy-1 = 72.44, accuracy-5 = 97.84
[epoch=209/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 11, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.000448)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.214 0.337  ||  0.2459 -0.4954 -0.0416  || discrepancy=0.11 || select=0/3
001/003-th : 0.389 0.147 0.464  ||  0.0845 -0.8862 0.2622  || discrepancy=0.08 || select=2/3
002/003-th : 0.058 0.183 0.759  ||  -1.3527 -0.2090 1.2135  || discrepancy=0.58 || select=2/3
-----------------------------------------------
000/019-th : 0.058 0.080 0.097 0.112 0.137 0.171 0.173 0.172  ||  -0.703 -0.377 -0.187 -0.041 0.165 0.384 0.397 0.389   || dis=0.00 || select=6/8
001/019-th : 0.130 0.129 0.128 0.134 0.124 0.123 0.117 0.115  ||  0.045 0.039 0.030 0.072 -0.002 -0.014 -0.061 -0.076   || dis=0.00 || select=3/8
002/019-th : 0.120 0.129 0.130 0.131 0.129 0.125 0.120 0.115  ||  -0.035 0.033 0.041 0.052 0.035 0.003 -0.039 -0.083    || dis=0.00 || select=3/8
003/019-th : 0.121 0.121 0.126 0.125 0.129 0.127 0.126 0.125  ||  -0.030 -0.026 0.014 0.008 0.034 0.024 0.012 0.002     || dis=0.00 || select=4/8
004/019-th : 0.112 0.116 0.124 0.123 0.132 0.132 0.133 0.128  ||  -0.101 -0.071 -0.004 -0.009 0.061 0.057 0.065 0.030   || dis=0.00 || select=6/8
005/019-th : 0.114 0.121 0.119 0.125 0.124 0.129 0.133 0.133  ||  -0.089 -0.032 -0.045 0.003 -0.004 0.034 0.063 0.066   || dis=0.00 || select=7/8
006/019-th : 0.116 0.116 0.120 0.126 0.126 0.129 0.135 0.131  ||  -0.073 -0.068 -0.038 0.013 0.012 0.037 0.078 0.054    || dis=0.00 || select=6/8
007/019-th : 0.069 0.079 0.099 0.115 0.138 0.149 0.166 0.185  ||  -0.538 -0.406 -0.175 -0.028 0.157 0.230 0.337 0.450   || dis=0.02 || select=7/8
008/019-th : 0.052 0.063 0.091 0.127 0.134 0.172 0.178 0.182  ||  -0.791 -0.598 -0.224 0.111 0.162 0.412 0.447 0.468    || dis=0.00 || select=7/8
009/019-th : 0.095 0.097 0.103 0.122 0.132 0.137 0.151 0.163  ||  -0.250 -0.227 -0.175 -0.001 0.079 0.111 0.214 0.286   || dis=0.01 || select=7/8
010/019-th : 0.102 0.107 0.113 0.133 0.131 0.137 0.136 0.140  ||  -0.192 -0.144 -0.094 0.066 0.053 0.102 0.094 0.118    || dis=0.00 || select=7/8
011/019-th : 0.101 0.099 0.105 0.112 0.127 0.136 0.154 0.165  ||  -0.194 -0.216 -0.153 -0.088 0.036 0.099 0.227 0.293   || dis=0.01 || select=7/8
012/019-th : 0.112 0.114 0.116 0.124 0.126 0.131 0.136 0.141  ||  -0.109 -0.092 -0.069 -0.007 0.011 0.053 0.084 0.125   || dis=0.00 || select=7/8
013/019-th : 0.038 0.043 0.057 0.076 0.094 0.146 0.219 0.327  ||  -0.935 -0.818 -0.537 -0.243 -0.032 0.411 0.815 1.217  || dis=0.11 || select=7/8
014/019-th : 0.052 0.058 0.076 0.094 0.126 0.158 0.209 0.226  ||  -0.749 -0.641 -0.370 -0.164 0.134 0.358 0.638 0.715   || dis=0.02 || select=7/8
015/019-th : 0.036 0.036 0.048 0.072 0.103 0.134 0.248 0.324  ||  -0.951 -0.948 -0.662 -0.254 0.102 0.371 0.986 1.253   || dis=0.08 || select=7/8
016/019-th : 0.058 0.077 0.100 0.127 0.138 0.158 0.171 0.171  ||  -0.703 -0.422 -0.159 0.079 0.157 0.295 0.374 0.375    || dis=0.00 || select=7/8
017/019-th : 0.122 0.118 0.118 0.118 0.134 0.127 0.129 0.133  ||  -0.025 -0.053 -0.053 -0.058 0.074 0.020 0.033 0.067   || dis=0.00 || select=4/8
018/019-th : 0.087 0.103 0.115 0.126 0.130 0.128 0.142 0.169  ||  -0.346 -0.175 -0.064 0.026 0.056 0.045 0.142 0.317    || dis=0.03 || select=7/8
[epoch=209/600] FLOP : 27.00 MB, ratio : 0.6616, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:32:32] [epoch=209/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 4.016 (4.016)  Prec@1 19.14 (19.14) Prec@5 69.53 (69.53) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:32:38] [epoch=209/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.402 (2.214)  Prec@1 48.81 (40.56) Prec@5 86.90 (85.00) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.56 Prec@5 85.00 Error@1 59.44 Error@5 15.00 Loss:2.214
***[2020-01-29 07:32:38]*** VALID [epoch=209/600] loss = 2.213695, accuracy@1 = 40.56, accuracy@5 = 85.00 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:32:38]*** start epoch=210/600 Time Left: [03:27:14], LR=[0.072700 ~ 0.072700], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=210, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.66227672436189, FLOP=40.81
[Search] : epoch=210/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:32:38] [epoch=210/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.724 (0.724)  Prec@1 72.66 (72.66) Prec@5 98.05 (98.05) Acls-loss 0.892 (0.892) FLOP-Loss 0.000 (0.000) Arch-Loss 0.892 (0.892)
**TRAIN** [2020-01-29 07:33:03] [epoch=210/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.856 (0.806)  Prec@1 70.83 (72.41) Prec@5 96.43 (97.93) Acls-loss 0.807 (0.827) FLOP-Loss 0.000 (0.000) Arch-Loss 0.807 (0.827)
 **TRAIN** Prec@1 72.41 Prec@5 97.93 Error@1 27.59 Error@5 2.07 Base-Loss:0.806, Arch-Loss=0.827
***[2020-01-29 07:33:03]*** TRAIN [epoch=210/600] base-loss = 0.806254, arch-loss = 0.826723, accuracy-1 = 72.41, accuracy-5 = 97.93
[epoch=210/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 11, 11, 12, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.43872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.215 0.340  ||  0.2364 -0.4899 -0.0310  || discrepancy=0.10 || select=0/3
001/003-th : 0.384 0.148 0.468  ||  0.0740 -0.8778 0.2735  || discrepancy=0.08 || select=2/3
002/003-th : 0.058 0.180 0.762  ||  -1.3605 -0.2170 1.2235  || discrepancy=0.58 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.079 0.097 0.111 0.141 0.169 0.171 0.174  ||  -0.711 -0.389 -0.180 -0.046 0.193 0.372 0.384 0.403   || dis=0.00 || select=7/8
001/019-th : 0.129 0.129 0.128 0.133 0.125 0.123 0.117 0.116  ||  0.035 0.035 0.027 0.068 0.010 -0.010 -0.058 -0.068    || dis=0.00 || select=3/8
002/019-th : 0.120 0.128 0.129 0.130 0.130 0.127 0.121 0.115  ||  -0.039 0.022 0.035 0.043 0.043 0.015 -0.035 -0.078    || dis=0.00 || select=4/8
003/019-th : 0.120 0.121 0.127 0.124 0.129 0.126 0.127 0.126  ||  -0.038 -0.030 0.016 -0.003 0.037 0.014 0.016 0.014    || dis=0.00 || select=4/8
004/019-th : 0.111 0.114 0.124 0.123 0.133 0.134 0.133 0.128  ||  -0.110 -0.081 -0.005 -0.013 0.066 0.079 0.068 0.032   || dis=0.00 || select=5/8
005/019-th : 0.114 0.120 0.118 0.126 0.124 0.130 0.134 0.134  ||  -0.092 -0.038 -0.058 0.005 -0.006 0.037 0.070 0.074   || dis=0.00 || select=7/8
006/019-th : 0.116 0.114 0.119 0.127 0.127 0.128 0.135 0.133  ||  -0.075 -0.086 -0.044 0.019 0.021 0.031 0.084 0.063    || dis=0.00 || select=6/8
007/019-th : 0.069 0.078 0.100 0.115 0.138 0.147 0.166 0.188  ||  -0.540 -0.415 -0.172 -0.029 0.153 0.217 0.339 0.462   || dis=0.02 || select=7/8
008/019-th : 0.051 0.062 0.090 0.127 0.134 0.172 0.179 0.184  ||  -0.799 -0.605 -0.236 0.111 0.165 0.413 0.452 0.480    || dis=0.01 || select=7/8
009/019-th : 0.095 0.097 0.102 0.122 0.132 0.137 0.153 0.163  ||  -0.252 -0.234 -0.176 -0.004 0.074 0.114 0.224 0.287   || dis=0.01 || select=7/8
010/019-th : 0.101 0.107 0.112 0.134 0.130 0.137 0.138 0.141  ||  -0.208 -0.145 -0.099 0.074 0.049 0.095 0.106 0.128    || dis=0.00 || select=7/8
011/019-th : 0.101 0.096 0.106 0.113 0.125 0.139 0.154 0.165  ||  -0.199 -0.244 -0.145 -0.078 0.022 0.124 0.230 0.299   || dis=0.01 || select=7/8
012/019-th : 0.111 0.112 0.117 0.122 0.128 0.131 0.136 0.142  ||  -0.116 -0.110 -0.061 -0.018 0.027 0.053 0.089 0.133   || dis=0.01 || select=7/8
013/019-th : 0.038 0.043 0.057 0.076 0.096 0.144 0.221 0.326  ||  -0.947 -0.817 -0.529 -0.243 -0.015 0.398 0.822 1.211  || dis=0.11 || select=7/8
014/019-th : 0.052 0.058 0.075 0.092 0.125 0.157 0.213 0.228  ||  -0.745 -0.644 -0.384 -0.176 0.126 0.353 0.657 0.725   || dis=0.02 || select=7/8
015/019-th : 0.035 0.037 0.048 0.070 0.101 0.136 0.248 0.325  ||  -0.964 -0.929 -0.652 -0.271 0.085 0.384 0.988 1.256   || dis=0.08 || select=7/8
016/019-th : 0.057 0.077 0.100 0.128 0.136 0.160 0.170 0.171  ||  -0.714 -0.422 -0.157 0.086 0.147 0.308 0.371 0.378    || dis=0.00 || select=7/8
017/019-th : 0.120 0.117 0.119 0.118 0.136 0.127 0.129 0.134  ||  -0.038 -0.061 -0.048 -0.056 0.089 0.020 0.033 0.077   || dis=0.00 || select=4/8
018/019-th : 0.087 0.102 0.116 0.124 0.129 0.128 0.143 0.170  ||  -0.347 -0.184 -0.059 0.012 0.049 0.043 0.155 0.322    || dis=0.03 || select=7/8
[epoch=210/600] FLOP : 27.44 MB, ratio : 0.6723, Expected-ratio : 0.7000, Discrepancy : 0.049
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:33:03] [epoch=210/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.710 (2.710)  Prec@1 15.62 (15.62) Prec@5 61.33 (61.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:33:09] [epoch=210/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.966 (2.564)  Prec@1 33.33 (36.00) Prec@5 88.10 (81.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.00 Prec@5 81.38 Error@1 64.00 Error@5 18.62 Loss:2.564
***[2020-01-29 07:33:10]*** VALID [epoch=210/600] loss = 2.563849, accuracy@1 = 36.00, accuracy@5 = 81.38 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:33:10]*** start epoch=211/600 Time Left: [03:26:42], LR=[0.072466 ~ 0.072466], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=211, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.6508315466089467, FLOP=40.81
[Search] : epoch=211/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:33:10] [epoch=211/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.680 (0.680)  Prec@1 78.91 (78.91) Prec@5 99.22 (99.22) Acls-loss 0.897 (0.897) FLOP-Loss 0.000 (0.000) Arch-Loss 0.897 (0.897)
**TRAIN** [2020-01-29 07:33:35] [epoch=211/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.813 (0.797)  Prec@1 72.62 (72.92) Prec@5 98.81 (97.92) Acls-loss 0.875 (0.831) FLOP-Loss 0.000 (0.082) Arch-Loss 0.875 (0.996)
 **TRAIN** Prec@1 72.92 Prec@5 97.92 Error@1 27.08 Error@5 2.08 Base-Loss:0.797, Arch-Loss=0.996
***[2020-01-29 07:33:35]*** TRAIN [epoch=211/600] base-loss = 0.797179, arch-loss = 0.995987, accuracy-1 = 72.92, accuracy-5 = 97.92
[epoch=211/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 12, 14, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.240064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.213 0.340  ||  0.2409 -0.5010 -0.0334  || discrepancy=0.11 || select=0/3
001/003-th : 0.385 0.150 0.465  ||  0.0797 -0.8614 0.2683  || discrepancy=0.08 || select=2/3
002/003-th : 0.057 0.181 0.762  ||  -1.3630 -0.2145 1.2257  || discrepancy=0.58 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.079 0.098 0.108 0.142 0.170 0.172 0.174  ||  -0.717 -0.388 -0.174 -0.074 0.203 0.381 0.393 0.402   || dis=0.00 || select=7/8
001/019-th : 0.130 0.129 0.128 0.134 0.125 0.122 0.116 0.115  ||  0.042 0.040 0.030 0.074 0.005 -0.017 -0.065 -0.074    || dis=0.00 || select=3/8
002/019-th : 0.121 0.128 0.130 0.131 0.130 0.127 0.119 0.115  ||  -0.033 0.026 0.043 0.046 0.040 0.015 -0.045 -0.083    || dis=0.00 || select=3/8
003/019-th : 0.120 0.122 0.127 0.126 0.128 0.125 0.126 0.126  ||  -0.034 -0.023 0.021 0.014 0.030 0.003 0.009 0.008     || dis=0.00 || select=4/8
004/019-th : 0.112 0.115 0.123 0.124 0.130 0.137 0.132 0.127  ||  -0.104 -0.076 -0.013 -0.005 0.046 0.095 0.063 0.025   || dis=0.01 || select=5/8
005/019-th : 0.115 0.121 0.119 0.125 0.124 0.128 0.134 0.134  ||  -0.082 -0.029 -0.054 -0.002 -0.008 0.025 0.069 0.066  || dis=0.00 || select=6/8
006/019-th : 0.116 0.115 0.120 0.127 0.126 0.128 0.135 0.133  ||  -0.070 -0.080 -0.040 0.016 0.006 0.028 0.077 0.065    || dis=0.00 || select=6/8
007/019-th : 0.069 0.078 0.101 0.116 0.137 0.147 0.165 0.186  ||  -0.539 -0.414 -0.157 -0.020 0.146 0.213 0.335 0.454   || dis=0.02 || select=7/8
008/019-th : 0.051 0.062 0.090 0.126 0.135 0.173 0.180 0.183  ||  -0.793 -0.611 -0.239 0.100 0.169 0.420 0.462 0.477    || dis=0.00 || select=7/8
009/019-th : 0.095 0.097 0.103 0.121 0.130 0.138 0.152 0.163  ||  -0.251 -0.227 -0.173 -0.009 0.063 0.123 0.216 0.287   || dis=0.01 || select=7/8
010/019-th : 0.102 0.107 0.112 0.132 0.130 0.136 0.140 0.141  ||  -0.199 -0.151 -0.101 0.059 0.047 0.092 0.121 0.126    || dis=0.00 || select=7/8
011/019-th : 0.102 0.096 0.107 0.112 0.122 0.138 0.154 0.167  ||  -0.185 -0.245 -0.137 -0.091 -0.005 0.118 0.228 0.307  || dis=0.01 || select=7/8
012/019-th : 0.112 0.112 0.117 0.123 0.126 0.132 0.136 0.142  ||  -0.109 -0.105 -0.065 -0.010 0.009 0.059 0.087 0.128   || dis=0.01 || select=7/8
013/019-th : 0.037 0.044 0.058 0.076 0.097 0.145 0.220 0.325  ||  -0.974 -0.798 -0.520 -0.245 -0.003 0.400 0.817 1.207  || dis=0.11 || select=7/8
014/019-th : 0.053 0.058 0.076 0.092 0.126 0.157 0.211 0.228  ||  -0.737 -0.647 -0.378 -0.178 0.134 0.351 0.648 0.724   || dis=0.02 || select=7/8
015/019-th : 0.035 0.036 0.048 0.071 0.098 0.135 0.248 0.328  ||  -0.965 -0.929 -0.653 -0.258 0.061 0.383 0.989 1.268   || dis=0.08 || select=7/8
016/019-th : 0.058 0.078 0.102 0.126 0.137 0.158 0.170 0.171  ||  -0.706 -0.415 -0.145 0.072 0.155 0.296 0.368 0.373    || dis=0.00 || select=7/8
017/019-th : 0.121 0.118 0.119 0.118 0.134 0.126 0.129 0.134  ||  -0.033 -0.054 -0.046 -0.052 0.074 0.010 0.034 0.074   || dis=0.00 || select=4/8
018/019-th : 0.087 0.102 0.116 0.127 0.129 0.127 0.144 0.168  ||  -0.343 -0.187 -0.058 0.032 0.050 0.034 0.162 0.310    || dis=0.02 || select=7/8
[epoch=211/600] FLOP : 27.24 MB, ratio : 0.6674, Expected-ratio : 0.7000, Discrepancy : 0.048
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:33:35] [epoch=211/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.083 (2.083)  Prec@1 40.23 (40.23) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:33:41] [epoch=211/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.304 (2.345)  Prec@1 34.52 (35.72) Prec@5 70.83 (79.86) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.72 Prec@5 79.86 Error@1 64.28 Error@5 20.14 Loss:2.345
***[2020-01-29 07:33:41]*** VALID [epoch=211/600] loss = 2.344884, accuracy@1 = 35.72, accuracy@5 = 79.86 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:33:41]*** start epoch=212/600 Time Left: [03:26:09], LR=[0.072232 ~ 0.072232], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=212, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.6393561890030726, FLOP=40.81
[Search] : epoch=212/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:33:42] [epoch=212/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.936 (0.936)  Prec@1 66.41 (66.41) Prec@5 98.44 (98.44) Acls-loss 0.786 (0.786) FLOP-Loss 0.000 (0.000) Arch-Loss 0.786 (0.786)
**TRAIN** [2020-01-29 07:34:06] [epoch=212/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.993 (0.801)  Prec@1 65.48 (72.59) Prec@5 97.62 (98.04) Acls-loss 0.716 (0.839) FLOP-Loss 0.000 (0.027) Arch-Loss 0.716 (0.894)
 **TRAIN** Prec@1 72.59 Prec@5 98.04 Error@1 27.41 Error@5 1.96 Base-Loss:0.801, Arch-Loss=0.894
***[2020-01-29 07:34:06]*** TRAIN [epoch=212/600] base-loss = 0.801173, arch-loss = 0.893614, accuracy-1 = 72.59, accuracy-5 = 98.04
[epoch=212/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 12, 14, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.665472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.446 0.214 0.340  ||  0.2404 -0.4947 -0.0322  || discrepancy=0.11 || select=0/3
001/003-th : 0.385 0.148 0.468  ||  0.0780 -0.8780 0.2732  || discrepancy=0.08 || select=2/3
002/003-th : 0.056 0.178 0.766  ||  -1.3781 -0.2180 1.2385  || discrepancy=0.59 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.079 0.098 0.106 0.142 0.170 0.173 0.176  ||  -0.722 -0.389 -0.171 -0.091 0.202 0.382 0.396 0.413   || dis=0.00 || select=7/8
001/019-th : 0.130 0.129 0.127 0.133 0.126 0.123 0.117 0.116  ||  0.046 0.034 0.017 0.065 0.013 -0.015 -0.061 -0.073    || dis=0.00 || select=3/8
002/019-th : 0.120 0.127 0.131 0.131 0.129 0.127 0.120 0.115  ||  -0.037 0.020 0.047 0.048 0.036 0.018 -0.042 -0.079    || dis=0.00 || select=3/8
003/019-th : 0.121 0.121 0.126 0.126 0.129 0.124 0.126 0.127  ||  -0.033 -0.028 0.009 0.012 0.034 -0.004 0.010 0.016    || dis=0.00 || select=4/8
004/019-th : 0.112 0.115 0.123 0.123 0.131 0.136 0.133 0.128  ||  -0.105 -0.078 -0.009 -0.011 0.051 0.086 0.065 0.029   || dis=0.00 || select=5/8
005/019-th : 0.115 0.121 0.119 0.126 0.124 0.128 0.134 0.133  ||  -0.083 -0.032 -0.051 0.007 -0.007 0.021 0.068 0.066   || dis=0.00 || select=6/8
006/019-th : 0.116 0.114 0.119 0.127 0.125 0.129 0.135 0.134  ||  -0.069 -0.094 -0.044 0.020 0.003 0.036 0.076 0.073    || dis=0.00 || select=6/8
007/019-th : 0.068 0.078 0.100 0.117 0.136 0.148 0.165 0.187  ||  -0.546 -0.415 -0.165 -0.014 0.143 0.228 0.334 0.456   || dis=0.02 || select=7/8
008/019-th : 0.051 0.063 0.088 0.125 0.133 0.176 0.182 0.184  ||  -0.808 -0.597 -0.251 0.094 0.155 0.437 0.470 0.482    || dis=0.00 || select=7/8
009/019-th : 0.095 0.097 0.103 0.121 0.129 0.138 0.152 0.164  ||  -0.254 -0.230 -0.168 -0.014 0.056 0.117 0.217 0.295   || dis=0.01 || select=7/8
010/019-th : 0.102 0.106 0.113 0.132 0.130 0.134 0.139 0.142  ||  -0.194 -0.156 -0.093 0.061 0.046 0.079 0.115 0.130    || dis=0.00 || select=7/8
011/019-th : 0.102 0.096 0.106 0.113 0.122 0.138 0.154 0.169  ||  -0.188 -0.249 -0.151 -0.085 -0.004 0.116 0.227 0.319  || dis=0.02 || select=7/8
012/019-th : 0.111 0.112 0.116 0.123 0.126 0.133 0.137 0.142  ||  -0.114 -0.110 -0.075 -0.010 0.011 0.064 0.092 0.134   || dis=0.00 || select=7/8
013/019-th : 0.036 0.044 0.058 0.075 0.097 0.146 0.219 0.325  ||  -0.985 -0.795 -0.514 -0.255 -0.000 0.410 0.814 1.211  || dis=0.11 || select=7/8
014/019-th : 0.053 0.057 0.076 0.092 0.125 0.157 0.212 0.229  ||  -0.735 -0.664 -0.374 -0.184 0.123 0.357 0.656 0.732   || dis=0.02 || select=7/8
015/019-th : 0.034 0.036 0.048 0.071 0.098 0.134 0.246 0.333  ||  -1.000 -0.936 -0.651 -0.250 0.067 0.381 0.987 1.289   || dis=0.09 || select=7/8
016/019-th : 0.058 0.077 0.101 0.125 0.138 0.159 0.172 0.170  ||  -0.705 -0.423 -0.150 0.062 0.161 0.304 0.380 0.370    || dis=0.00 || select=6/8
017/019-th : 0.120 0.118 0.119 0.117 0.135 0.126 0.130 0.135  ||  -0.037 -0.053 -0.044 -0.060 0.076 0.007 0.038 0.077   || dis=0.00 || select=7/8
018/019-th : 0.087 0.101 0.117 0.126 0.130 0.127 0.144 0.168  ||  -0.347 -0.197 -0.050 0.028 0.057 0.034 0.162 0.314    || dis=0.02 || select=7/8
[epoch=212/600] FLOP : 28.67 MB, ratio : 0.7024, Expected-ratio : 0.7000, Discrepancy : 0.049
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:34:06] [epoch=212/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.645 (1.645)  Prec@1 39.45 (39.45) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:34:12] [epoch=212/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.792 (2.409)  Prec@1 22.62 (36.66) Prec@5 75.60 (80.85) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.66 Prec@5 80.85 Error@1 63.34 Error@5 19.15 Loss:2.409
***[2020-01-29 07:34:12]*** VALID [epoch=212/600] loss = 2.408971, accuracy@1 = 36.66, accuracy@5 = 80.85 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:34:12]*** start epoch=213/600 Time Left: [03:25:36], LR=[0.071997 ~ 0.071997], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=213, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.6278509661469927, FLOP=40.81
[Search] : epoch=213/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:34:13] [epoch=213/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.930 (0.930)  Prec@1 68.36 (68.36) Prec@5 96.88 (96.88) Acls-loss 0.912 (0.912) FLOP-Loss 2.679 (2.679) Arch-Loss 6.269 (6.269)
**TRAIN** [2020-01-29 07:34:37] [epoch=213/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.756 (0.819)  Prec@1 76.19 (72.10) Prec@5 98.21 (97.95) Acls-loss 0.785 (0.852) FLOP-Loss 0.000 (0.027) Arch-Loss 0.785 (0.907)
 **TRAIN** Prec@1 72.10 Prec@5 97.95 Error@1 27.90 Error@5 2.05 Base-Loss:0.819, Arch-Loss=0.907
***[2020-01-29 07:34:37]*** TRAIN [epoch=213/600] base-loss = 0.819317, arch-loss = 0.906920, accuracy-1 = 72.10, accuracy-5 = 97.95
[epoch=213/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 12, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 44, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.05856)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.213 0.342  ||  0.2357 -0.4985 -0.0256  || discrepancy=0.10 || select=0/3
001/003-th : 0.384 0.146 0.470  ||  0.0763 -0.8899 0.2778  || discrepancy=0.09 || select=2/3
002/003-th : 0.055 0.178 0.768  ||  -1.3955 -0.2145 1.2499  || discrepancy=0.59 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.079 0.099 0.106 0.142 0.169 0.173 0.176  ||  -0.731 -0.383 -0.162 -0.091 0.200 0.377 0.395 0.413   || dis=0.00 || select=7/8
001/019-th : 0.130 0.129 0.127 0.133 0.125 0.122 0.118 0.116  ||  0.045 0.031 0.019 0.063 0.002 -0.019 -0.055 -0.070    || dis=0.00 || select=3/8
002/019-th : 0.120 0.128 0.129 0.130 0.129 0.128 0.120 0.117  ||  -0.044 0.023 0.031 0.039 0.030 0.023 -0.039 -0.068    || dis=0.00 || select=3/8
003/019-th : 0.120 0.121 0.124 0.127 0.129 0.126 0.127 0.127  ||  -0.038 -0.029 -0.007 0.018 0.034 0.008 0.016 0.018    || dis=0.00 || select=4/8
004/019-th : 0.112 0.115 0.122 0.122 0.129 0.136 0.134 0.130  ||  -0.107 -0.079 -0.021 -0.023 0.037 0.087 0.071 0.041   || dis=0.00 || select=5/8
005/019-th : 0.113 0.122 0.120 0.126 0.126 0.127 0.133 0.133  ||  -0.098 -0.025 -0.036 0.012 0.011 0.017 0.062 0.065    || dis=0.00 || select=7/8
006/019-th : 0.115 0.113 0.118 0.126 0.129 0.129 0.134 0.135  ||  -0.078 -0.098 -0.051 0.009 0.032 0.035 0.073 0.082    || dis=0.00 || select=7/8
007/019-th : 0.068 0.079 0.099 0.118 0.134 0.148 0.166 0.188  ||  -0.551 -0.402 -0.177 -0.007 0.126 0.223 0.335 0.464   || dis=0.02 || select=7/8
008/019-th : 0.051 0.061 0.087 0.122 0.132 0.175 0.188 0.184  ||  -0.804 -0.613 -0.259 0.076 0.151 0.437 0.508 0.484    || dis=0.00 || select=6/8
009/019-th : 0.096 0.096 0.104 0.121 0.127 0.138 0.152 0.166  ||  -0.249 -0.242 -0.161 -0.011 0.036 0.118 0.216 0.302   || dis=0.01 || select=7/8
010/019-th : 0.102 0.105 0.115 0.133 0.128 0.136 0.137 0.143  ||  -0.194 -0.170 -0.076 0.071 0.030 0.088 0.100 0.140    || dis=0.01 || select=7/8
011/019-th : 0.101 0.096 0.106 0.113 0.123 0.137 0.154 0.169  ||  -0.200 -0.245 -0.145 -0.080 0.003 0.111 0.228 0.320   || dis=0.02 || select=7/8
012/019-th : 0.110 0.111 0.113 0.123 0.127 0.133 0.138 0.144  ||  -0.121 -0.120 -0.094 -0.009 0.023 0.068 0.099 0.144   || dis=0.01 || select=7/8
013/019-th : 0.036 0.043 0.056 0.075 0.096 0.143 0.222 0.329  ||  -0.987 -0.799 -0.535 -0.248 -0.008 0.397 0.834 1.229  || dis=0.11 || select=7/8
014/019-th : 0.052 0.056 0.075 0.091 0.125 0.157 0.214 0.229  ||  -0.741 -0.673 -0.377 -0.191 0.132 0.357 0.670 0.735   || dis=0.02 || select=7/8
015/019-th : 0.033 0.036 0.048 0.070 0.097 0.134 0.248 0.334  ||  -1.004 -0.939 -0.649 -0.268 0.061 0.387 0.999 1.298   || dis=0.09 || select=7/8
016/019-th : 0.058 0.077 0.100 0.124 0.140 0.160 0.172 0.169  ||  -0.709 -0.422 -0.157 0.054 0.178 0.311 0.386 0.366    || dis=0.00 || select=6/8
017/019-th : 0.120 0.118 0.119 0.117 0.135 0.126 0.130 0.135  ||  -0.039 -0.055 -0.046 -0.061 0.083 0.007 0.038 0.080   || dis=0.00 || select=4/8
018/019-th : 0.086 0.100 0.119 0.126 0.130 0.129 0.144 0.166  ||  -0.350 -0.200 -0.027 0.024 0.062 0.048 0.158 0.301    || dis=0.02 || select=7/8
[epoch=213/600] FLOP : 27.06 MB, ratio : 0.6630, Expected-ratio : 0.7000, Discrepancy : 0.050
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:34:38] [epoch=213/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.345 (2.345)  Prec@1 37.50 (37.50) Prec@5 79.69 (79.69) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:34:44] [epoch=213/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.497 (2.182)  Prec@1 45.24 (40.32) Prec@5 86.90 (83.55) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.32 Prec@5 83.55 Error@1 59.68 Error@5 16.45 Loss:2.182
***[2020-01-29 07:34:44]*** VALID [epoch=213/600] loss = 2.182053, accuracy@1 = 40.32, accuracy@5 = 83.55 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:34:44]*** start epoch=214/600 Time Left: [03:25:03], LR=[0.071762 ~ 0.071762], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=214, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.616316193462203, FLOP=40.81
[Search] : epoch=214/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:34:45] [epoch=214/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.846 (0.846)  Prec@1 69.92 (69.92) Prec@5 97.66 (97.66) Acls-loss 0.905 (0.905) FLOP-Loss 0.000 (0.000) Arch-Loss 0.905 (0.905)
**TRAIN** [2020-01-29 07:35:09] [epoch=214/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.748 (0.809)  Prec@1 72.62 (72.35) Prec@5 98.81 (97.86) Acls-loss 0.739 (0.845) FLOP-Loss 0.000 (0.000) Arch-Loss 0.739 (0.845)
 **TRAIN** Prec@1 72.35 Prec@5 97.86 Error@1 27.65 Error@5 2.14 Base-Loss:0.809, Arch-Loss=0.845
***[2020-01-29 07:35:09]*** TRAIN [epoch=214/600] base-loss = 0.808546, arch-loss = 0.845201, accuracy-1 = 72.35, accuracy-5 = 97.86
[epoch=214/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 12, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.45248)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.214 0.345  ||  0.2286 -0.4933 -0.0172  || discrepancy=0.10 || select=0/3
001/003-th : 0.381 0.147 0.473  ||  0.0694 -0.8845 0.2860  || discrepancy=0.09 || select=2/3
002/003-th : 0.054 0.176 0.770  ||  -1.3943 -0.2236 1.2549  || discrepancy=0.59 || select=2/3
-----------------------------------------------
000/019-th : 0.057 0.080 0.097 0.106 0.140 0.168 0.174 0.178  ||  -0.716 -0.381 -0.181 -0.091 0.182 0.367 0.403 0.421   || dis=0.00 || select=7/8
001/019-th : 0.130 0.128 0.127 0.133 0.125 0.123 0.118 0.117  ||  0.038 0.026 0.015 0.061 0.000 -0.013 -0.052 -0.061    || dis=0.00 || select=3/8
002/019-th : 0.119 0.126 0.128 0.129 0.128 0.129 0.122 0.118  ||  -0.051 0.011 0.022 0.034 0.027 0.030 -0.027 -0.057    || dis=0.00 || select=3/8
003/019-th : 0.120 0.120 0.124 0.125 0.130 0.126 0.127 0.128  ||  -0.038 -0.041 -0.006 0.002 0.040 0.011 0.017 0.027    || dis=0.00 || select=4/8
004/019-th : 0.111 0.115 0.121 0.120 0.130 0.137 0.136 0.131  ||  -0.118 -0.083 -0.030 -0.036 0.039 0.094 0.084 0.049   || dis=0.00 || select=5/8
005/019-th : 0.111 0.121 0.120 0.126 0.127 0.128 0.133 0.133  ||  -0.113 -0.025 -0.035 0.013 0.023 0.026 0.068 0.064    || dis=0.00 || select=6/8
006/019-th : 0.114 0.111 0.116 0.124 0.130 0.133 0.135 0.137  ||  -0.089 -0.114 -0.068 -0.003 0.041 0.063 0.079 0.094   || dis=0.00 || select=7/8
007/019-th : 0.068 0.077 0.099 0.118 0.134 0.148 0.166 0.189  ||  -0.549 -0.424 -0.175 -0.004 0.129 0.222 0.339 0.471   || dis=0.02 || select=7/8
008/019-th : 0.050 0.061 0.087 0.122 0.131 0.175 0.190 0.184  ||  -0.812 -0.616 -0.266 0.077 0.145 0.437 0.522 0.490    || dis=0.01 || select=6/8
009/019-th : 0.095 0.096 0.104 0.121 0.126 0.138 0.154 0.166  ||  -0.253 -0.243 -0.167 -0.013 0.032 0.122 0.226 0.303   || dis=0.01 || select=7/8
010/019-th : 0.101 0.105 0.115 0.132 0.128 0.136 0.138 0.144  ||  -0.208 -0.168 -0.074 0.061 0.031 0.087 0.107 0.150    || dis=0.01 || select=7/8
011/019-th : 0.099 0.096 0.107 0.113 0.122 0.139 0.155 0.170  ||  -0.211 -0.250 -0.139 -0.084 -0.005 0.122 0.230 0.327  || dis=0.02 || select=7/8
012/019-th : 0.110 0.110 0.114 0.124 0.126 0.133 0.138 0.145  ||  -0.124 -0.124 -0.091 -0.001 0.015 0.064 0.100 0.149   || dis=0.01 || select=7/8
013/019-th : 0.035 0.043 0.055 0.073 0.096 0.140 0.227 0.331  ||  -0.993 -0.800 -0.548 -0.265 0.001 0.380 0.864 1.244   || dis=0.10 || select=7/8
014/019-th : 0.051 0.056 0.075 0.091 0.125 0.158 0.213 0.231  ||  -0.765 -0.666 -0.385 -0.188 0.135 0.363 0.666 0.747   || dis=0.02 || select=7/8
015/019-th : 0.032 0.035 0.048 0.070 0.096 0.135 0.247 0.337  ||  -1.039 -0.941 -0.646 -0.261 0.053 0.399 1.005 1.315   || dis=0.09 || select=7/8
016/019-th : 0.058 0.077 0.101 0.124 0.139 0.161 0.173 0.168  ||  -0.708 -0.423 -0.152 0.055 0.171 0.316 0.390 0.360    || dis=0.00 || select=6/8
017/019-th : 0.119 0.117 0.117 0.117 0.134 0.128 0.131 0.136  ||  -0.046 -0.068 -0.060 -0.063 0.075 0.024 0.051 0.089   || dis=0.00 || select=7/8
018/019-th : 0.086 0.101 0.119 0.126 0.129 0.129 0.144 0.165  ||  -0.355 -0.196 -0.027 0.031 0.047 0.054 0.164 0.297    || dis=0.02 || select=7/8
[epoch=214/600] FLOP : 28.45 MB, ratio : 0.6971, Expected-ratio : 0.7000, Discrepancy : 0.050
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:35:09] [epoch=214/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.011 (3.011)  Prec@1 11.72 (11.72) Prec@5 55.86 (55.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:35:15] [epoch=214/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.578 (2.303)  Prec@1 48.81 (37.00) Prec@5 88.69 (81.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.00 Prec@5 81.31 Error@1 63.00 Error@5 18.69 Loss:2.303
***[2020-01-29 07:35:16]*** VALID [epoch=214/600] loss = 2.303024, accuracy@1 = 37.00, accuracy@5 = 81.31 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:35:16]*** start epoch=215/600 Time Left: [03:24:31], LR=[0.071526 ~ 0.071526], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=215, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.6047521871803236, FLOP=40.81
[Search] : epoch=215/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:35:16] [epoch=215/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 1.046 (1.046)  Prec@1 65.62 (65.62) Prec@5 94.92 (94.92) Acls-loss 0.984 (0.984) FLOP-Loss 0.000 (0.000) Arch-Loss 0.984 (0.984)
**TRAIN** [2020-01-29 07:35:41] [epoch=215/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.878 (0.810)  Prec@1 67.86 (72.53) Prec@5 97.62 (97.76) Acls-loss 0.709 (0.840) FLOP-Loss 0.000 (0.028) Arch-Loss 0.709 (0.895)
 **TRAIN** Prec@1 72.53 Prec@5 97.76 Error@1 27.47 Error@5 2.24 Base-Loss:0.810, Arch-Loss=0.895
***[2020-01-29 07:35:41]*** TRAIN [epoch=215/600] base-loss = 0.810381, arch-loss = 0.895451, accuracy-1 = 72.53, accuracy-5 = 97.76
[epoch=215/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 12, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.45248)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.215 0.345  ||  0.2275 -0.4875 -0.0153  || discrepancy=0.10 || select=0/3
001/003-th : 0.379 0.146 0.475  ||  0.0655 -0.8887 0.2922  || discrepancy=0.10 || select=2/3
002/003-th : 0.053 0.174 0.772  ||  -1.4058 -0.2239 1.2645  || discrepancy=0.60 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.080 0.097 0.104 0.140 0.169 0.174 0.179  ||  -0.726 -0.376 -0.183 -0.113 0.186 0.373 0.405 0.433   || dis=0.01 || select=7/8
001/019-th : 0.129 0.127 0.125 0.133 0.126 0.124 0.119 0.118  ||  0.036 0.020 0.005 0.062 0.007 -0.008 -0.047 -0.059    || dis=0.00 || select=3/8
002/019-th : 0.119 0.127 0.128 0.129 0.128 0.129 0.122 0.119  ||  -0.053 0.013 0.020 0.033 0.022 0.028 -0.025 -0.054    || dis=0.00 || select=3/8
003/019-th : 0.119 0.119 0.123 0.125 0.132 0.126 0.127 0.129  ||  -0.048 -0.045 -0.010 0.003 0.055 0.013 0.021 0.032    || dis=0.00 || select=4/8
004/019-th : 0.111 0.114 0.120 0.122 0.131 0.136 0.135 0.131  ||  -0.113 -0.093 -0.037 -0.021 0.046 0.084 0.082 0.052   || dis=0.00 || select=5/8
005/019-th : 0.110 0.122 0.121 0.126 0.126 0.128 0.134 0.133  ||  -0.120 -0.019 -0.032 0.013 0.009 0.027 0.073 0.067    || dis=0.00 || select=6/8
006/019-th : 0.114 0.111 0.117 0.124 0.130 0.134 0.134 0.137  ||  -0.090 -0.117 -0.065 -0.006 0.040 0.072 0.075 0.096   || dis=0.00 || select=7/8
007/019-th : 0.068 0.077 0.098 0.118 0.136 0.149 0.165 0.188  ||  -0.550 -0.423 -0.187 -0.000 0.144 0.233 0.336 0.466   || dis=0.02 || select=7/8
008/019-th : 0.050 0.061 0.086 0.122 0.130 0.170 0.194 0.186  ||  -0.809 -0.616 -0.272 0.078 0.143 0.410 0.539 0.498    || dis=0.01 || select=6/8
009/019-th : 0.096 0.096 0.103 0.121 0.125 0.136 0.157 0.166  ||  -0.245 -0.243 -0.174 -0.017 0.018 0.105 0.246 0.302   || dis=0.01 || select=7/8
010/019-th : 0.101 0.105 0.115 0.132 0.127 0.135 0.140 0.145  ||  -0.206 -0.172 -0.075 0.057 0.023 0.081 0.117 0.155    || dis=0.00 || select=7/8
011/019-th : 0.099 0.095 0.107 0.112 0.123 0.141 0.154 0.170  ||  -0.217 -0.257 -0.132 -0.091 0.003 0.140 0.226 0.326   || dis=0.02 || select=7/8
012/019-th : 0.109 0.110 0.115 0.124 0.128 0.132 0.138 0.145  ||  -0.132 -0.122 -0.083 -0.006 0.024 0.059 0.102 0.152   || dis=0.01 || select=7/8
013/019-th : 0.035 0.042 0.056 0.074 0.096 0.137 0.229 0.330  ||  -0.993 -0.815 -0.536 -0.261 0.010 0.364 0.874 1.241   || dis=0.10 || select=7/8
014/019-th : 0.051 0.056 0.075 0.091 0.122 0.159 0.214 0.232  ||  -0.759 -0.672 -0.384 -0.183 0.108 0.374 0.670 0.750   || dis=0.02 || select=7/8
015/019-th : 0.032 0.035 0.048 0.068 0.095 0.132 0.246 0.343  ||  -1.037 -0.945 -0.640 -0.277 0.056 0.384 1.004 1.335   || dis=0.10 || select=7/8
016/019-th : 0.058 0.077 0.099 0.125 0.139 0.160 0.172 0.169  ||  -0.701 -0.421 -0.167 0.061 0.172 0.312 0.384 0.366    || dis=0.00 || select=6/8
017/019-th : 0.119 0.116 0.117 0.117 0.134 0.128 0.131 0.136  ||  -0.043 -0.072 -0.064 -0.060 0.072 0.027 0.052 0.089   || dis=0.00 || select=7/8
018/019-th : 0.085 0.100 0.120 0.126 0.127 0.131 0.145 0.166  ||  -0.363 -0.207 -0.019 0.030 0.033 0.063 0.167 0.306    || dis=0.02 || select=7/8
[epoch=215/600] FLOP : 28.45 MB, ratio : 0.6971, Expected-ratio : 0.7000, Discrepancy : 0.051
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:35:41] [epoch=215/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 4.598 (4.598)  Prec@1 19.14 (19.14) Prec@5 63.67 (63.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:35:47] [epoch=215/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.779 (2.316)  Prec@1 44.05 (38.83) Prec@5 79.76 (81.68) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.83 Prec@5 81.68 Error@1 61.17 Error@5 18.32 Loss:2.316
***[2020-01-29 07:35:47]*** VALID [epoch=215/600] loss = 2.315656, accuracy@1 = 38.83, accuracy@5 = 81.68 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:35:47]*** start epoch=216/600 Time Left: [03:23:59], LR=[0.071289 ~ 0.071289], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=216, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.5931592643344286, FLOP=40.81
[Search] : epoch=216/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:35:48] [epoch=216/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.968 (0.968)  Prec@1 66.41 (66.41) Prec@5 97.27 (97.27) Acls-loss 0.660 (0.660) FLOP-Loss 0.000 (0.000) Arch-Loss 0.660 (0.660)
**TRAIN** [2020-01-29 07:36:12] [epoch=216/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.960 (0.789)  Prec@1 66.07 (73.19) Prec@5 98.21 (98.05) Acls-loss 0.678 (0.824) FLOP-Loss 0.000 (0.055) Arch-Loss 0.678 (0.934)
 **TRAIN** Prec@1 73.19 Prec@5 98.05 Error@1 26.81 Error@5 1.95 Base-Loss:0.789, Arch-Loss=0.934
***[2020-01-29 07:36:13]*** TRAIN [epoch=216/600] base-loss = 0.788990, arch-loss = 0.934176, accuracy-1 = 73.19, accuracy-5 = 98.05
[epoch=216/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 12, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.45248)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.215 0.344  ||  0.2314 -0.4881 -0.0180  || discrepancy=0.10 || select=0/3
001/003-th : 0.378 0.148 0.475  ||  0.0653 -0.8750 0.2931  || discrepancy=0.10 || select=2/3
002/003-th : 0.053 0.174 0.773  ||  -1.4086 -0.2235 1.2680  || discrepancy=0.60 || select=2/3
-----------------------------------------------
000/019-th : 0.056 0.081 0.097 0.102 0.139 0.169 0.177 0.180  ||  -0.731 -0.365 -0.181 -0.128 0.174 0.370 0.418 0.435   || dis=0.00 || select=7/8
001/019-th : 0.129 0.127 0.126 0.133 0.126 0.124 0.118 0.117  ||  0.038 0.018 0.013 0.063 0.015 -0.006 -0.050 -0.064    || dis=0.00 || select=3/8
002/019-th : 0.119 0.127 0.129 0.129 0.127 0.129 0.123 0.118  ||  -0.052 0.013 0.026 0.032 0.015 0.029 -0.021 -0.057    || dis=0.00 || select=3/8
003/019-th : 0.120 0.120 0.122 0.125 0.130 0.127 0.127 0.128  ||  -0.042 -0.037 -0.024 0.002 0.044 0.019 0.020 0.028    || dis=0.00 || select=4/8
004/019-th : 0.112 0.114 0.122 0.121 0.129 0.135 0.135 0.131  ||  -0.109 -0.093 -0.022 -0.030 0.037 0.082 0.079 0.052   || dis=0.00 || select=5/8
005/019-th : 0.111 0.121 0.119 0.126 0.126 0.128 0.134 0.133  ||  -0.113 -0.031 -0.043 0.012 0.015 0.029 0.076 0.067    || dis=0.00 || select=6/8
006/019-th : 0.115 0.112 0.116 0.124 0.130 0.132 0.134 0.136  ||  -0.085 -0.107 -0.068 -0.006 0.043 0.059 0.075 0.091   || dis=0.00 || select=7/8
007/019-th : 0.069 0.077 0.098 0.118 0.138 0.148 0.166 0.187  ||  -0.543 -0.423 -0.186 -0.000 0.152 0.225 0.338 0.457   || dis=0.02 || select=7/8
008/019-th : 0.051 0.061 0.086 0.123 0.130 0.169 0.193 0.187  ||  -0.793 -0.614 -0.276 0.080 0.141 0.400 0.532 0.500    || dis=0.01 || select=6/8
009/019-th : 0.097 0.097 0.104 0.120 0.124 0.136 0.157 0.166  ||  -0.241 -0.232 -0.171 -0.025 0.009 0.101 0.247 0.300   || dis=0.01 || select=7/8
010/019-th : 0.101 0.104 0.115 0.130 0.128 0.135 0.141 0.145  ||  -0.204 -0.174 -0.076 0.042 0.030 0.084 0.125 0.153    || dis=0.00 || select=7/8
011/019-th : 0.100 0.096 0.108 0.113 0.121 0.140 0.153 0.168  ||  -0.207 -0.241 -0.126 -0.086 -0.010 0.131 0.221 0.315  || dis=0.02 || select=7/8
012/019-th : 0.108 0.110 0.116 0.124 0.128 0.132 0.138 0.145  ||  -0.140 -0.127 -0.071 -0.007 0.027 0.060 0.102 0.154   || dis=0.01 || select=7/8
013/019-th : 0.036 0.042 0.055 0.074 0.094 0.137 0.229 0.333  ||  -0.984 -0.820 -0.543 -0.255 -0.008 0.362 0.880 1.254  || dis=0.10 || select=7/8
014/019-th : 0.051 0.056 0.075 0.091 0.123 0.158 0.216 0.231  ||  -0.759 -0.676 -0.383 -0.180 0.113 0.368 0.678 0.745   || dis=0.02 || select=7/8
015/019-th : 0.032 0.035 0.047 0.068 0.096 0.131 0.248 0.344  ||  -1.033 -0.954 -0.643 -0.285 0.062 0.378 1.014 1.341   || dis=0.10 || select=7/8
016/019-th : 0.058 0.077 0.099 0.126 0.138 0.161 0.172 0.169  ||  -0.709 -0.416 -0.172 0.070 0.166 0.315 0.382 0.368    || dis=0.00 || select=6/8
017/019-th : 0.120 0.117 0.117 0.117 0.133 0.129 0.131 0.137  ||  -0.040 -0.066 -0.063 -0.063 0.062 0.030 0.044 0.090   || dis=0.00 || select=7/8
018/019-th : 0.086 0.101 0.120 0.128 0.127 0.130 0.143 0.165  ||  -0.360 -0.196 -0.021 0.046 0.034 0.060 0.154 0.299    || dis=0.02 || select=7/8
[epoch=216/600] FLOP : 28.45 MB, ratio : 0.6971, Expected-ratio : 0.7000, Discrepancy : 0.050
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:36:13] [epoch=216/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.709 (1.709)  Prec@1 45.31 (45.31) Prec@5 79.69 (79.69) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:36:19] [epoch=216/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.473 (2.228)  Prec@1 59.52 (39.16) Prec@5 92.26 (83.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.16 Prec@5 83.32 Error@1 60.84 Error@5 16.68 Loss:2.228
***[2020-01-29 07:36:19]*** VALID [epoch=216/600] loss = 2.227922, accuracy@1 = 39.16, accuracy@5 = 83.32 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:36:19]*** start epoch=217/600 Time Left: [03:23:27], LR=[0.071052 ~ 0.071052], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=217, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.581537742750353, FLOP=40.81
[Search] : epoch=217/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:36:20] [epoch=217/600][000/098] Time 0.75 (0.75) Data 0.37 (0.37) Base-Loss 0.802 (0.802)  Prec@1 74.22 (74.22) Prec@5 97.66 (97.66) Acls-loss 0.894 (0.894) FLOP-Loss 0.000 (0.000) Arch-Loss 0.894 (0.894)
**TRAIN** [2020-01-29 07:36:44] [epoch=217/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.887 (0.806)  Prec@1 69.64 (72.24) Prec@5 97.02 (97.84) Acls-loss 0.818 (0.863) FLOP-Loss 2.693 (0.046) Arch-Loss 6.204 (0.955)
 **TRAIN** Prec@1 72.24 Prec@5 97.84 Error@1 27.76 Error@5 2.16 Base-Loss:0.806, Arch-Loss=0.955
***[2020-01-29 07:36:44]*** TRAIN [epoch=217/600] base-loss = 0.805907, arch-loss = 0.954667, accuracy-1 = 72.24, accuracy-5 = 97.84
[epoch=217/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 11, 12, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.353152)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.216 0.344  ||  0.2318 -0.4836 -0.0175  || discrepancy=0.10 || select=0/3
001/003-th : 0.376 0.149 0.475  ||  0.0625 -0.8648 0.2969  || discrepancy=0.10 || select=2/3
002/003-th : 0.052 0.173 0.774  ||  -1.4168 -0.2219 1.2748  || discrepancy=0.60 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.080 0.097 0.103 0.139 0.167 0.179 0.180  ||  -0.747 -0.376 -0.183 -0.115 0.180 0.361 0.435 0.441   || dis=0.00 || select=7/8
001/019-th : 0.130 0.128 0.126 0.131 0.126 0.123 0.119 0.117  ||  0.039 0.023 0.012 0.048 0.014 -0.010 -0.047 -0.065    || dis=0.00 || select=3/8
002/019-th : 0.118 0.127 0.130 0.128 0.128 0.130 0.122 0.118  ||  -0.060 0.013 0.039 0.022 0.022 0.036 -0.020 -0.057    || dis=0.00 || select=2/8
003/019-th : 0.119 0.120 0.121 0.126 0.130 0.128 0.127 0.129  ||  -0.048 -0.036 -0.033 0.011 0.040 0.030 0.016 0.033    || dis=0.00 || select=4/8
004/019-th : 0.111 0.114 0.122 0.122 0.129 0.135 0.135 0.132  ||  -0.116 -0.087 -0.021 -0.023 0.033 0.080 0.078 0.055   || dis=0.00 || select=5/8
005/019-th : 0.113 0.120 0.121 0.127 0.124 0.129 0.134 0.133  ||  -0.100 -0.040 -0.034 0.021 -0.009 0.030 0.073 0.065   || dis=0.00 || select=6/8
006/019-th : 0.115 0.113 0.117 0.122 0.129 0.134 0.133 0.136  ||  -0.081 -0.101 -0.062 -0.020 0.037 0.072 0.067 0.089   || dis=0.00 || select=7/8
007/019-th : 0.069 0.078 0.098 0.118 0.136 0.149 0.166 0.187  ||  -0.542 -0.417 -0.188 -0.002 0.142 0.230 0.339 0.458   || dis=0.02 || select=7/8
008/019-th : 0.051 0.060 0.087 0.122 0.131 0.171 0.191 0.186  ||  -0.800 -0.627 -0.264 0.076 0.151 0.416 0.525 0.500    || dis=0.01 || select=6/8
009/019-th : 0.096 0.097 0.104 0.122 0.123 0.136 0.156 0.165  ||  -0.244 -0.239 -0.162 -0.005 0.005 0.101 0.241 0.299   || dis=0.01 || select=7/8
010/019-th : 0.101 0.103 0.116 0.130 0.127 0.136 0.141 0.145  ||  -0.212 -0.186 -0.064 0.048 0.024 0.092 0.125 0.157    || dis=0.00 || select=7/8
011/019-th : 0.100 0.097 0.108 0.111 0.120 0.139 0.154 0.170  ||  -0.205 -0.238 -0.131 -0.097 -0.023 0.126 0.227 0.327  || dis=0.02 || select=7/8
012/019-th : 0.108 0.109 0.116 0.123 0.130 0.133 0.138 0.144  ||  -0.142 -0.134 -0.069 -0.010 0.043 0.067 0.102 0.151   || dis=0.01 || select=7/8
013/019-th : 0.034 0.042 0.055 0.074 0.094 0.136 0.229 0.335  ||  -1.013 -0.817 -0.547 -0.243 -0.007 0.364 0.885 1.262  || dis=0.11 || select=7/8
014/019-th : 0.051 0.056 0.074 0.092 0.121 0.160 0.213 0.232  ||  -0.764 -0.665 -0.390 -0.173 0.101 0.381 0.665 0.753   || dis=0.02 || select=7/8
015/019-th : 0.031 0.035 0.047 0.068 0.095 0.132 0.249 0.343  ||  -1.054 -0.950 -0.642 -0.272 0.054 0.386 1.019 1.342   || dis=0.09 || select=7/8
016/019-th : 0.058 0.078 0.098 0.126 0.137 0.160 0.173 0.170  ||  -0.712 -0.410 -0.176 0.072 0.153 0.313 0.388 0.371    || dis=0.00 || select=6/8
017/019-th : 0.119 0.117 0.118 0.118 0.133 0.128 0.131 0.136  ||  -0.046 -0.068 -0.056 -0.059 0.065 0.026 0.050 0.089   || dis=0.00 || select=7/8
018/019-th : 0.085 0.101 0.121 0.129 0.128 0.129 0.142 0.166  ||  -0.370 -0.193 -0.014 0.055 0.041 0.048 0.148 0.303    || dis=0.02 || select=7/8
[epoch=217/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.051
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:36:45] [epoch=217/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.275 (2.275)  Prec@1 39.06 (39.06) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:36:51] [epoch=217/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.018 (2.148)  Prec@1 32.14 (39.86) Prec@5 83.33 (84.12) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.86 Prec@5 84.12 Error@1 60.14 Error@5 15.88 Loss:2.148
***[2020-01-29 07:36:51]*** VALID [epoch=217/600] loss = 2.147747, accuracy@1 = 39.86, accuracy@5 = 84.12 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:36:51]*** start epoch=218/600 Time Left: [03:22:55], LR=[0.070814 ~ 0.070814], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=218, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.5698879410379836, FLOP=40.81
[Search] : epoch=218/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:36:51] [epoch=218/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.862 (0.862)  Prec@1 66.02 (66.02) Prec@5 98.83 (98.83) Acls-loss 0.939 (0.939) FLOP-Loss 0.000 (0.000) Arch-Loss 0.939 (0.939)
**TRAIN** [2020-01-29 07:37:16] [epoch=218/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.992 (0.803)  Prec@1 67.86 (72.44) Prec@5 97.02 (97.90) Acls-loss 0.764 (0.838) FLOP-Loss 0.000 (0.055) Arch-Loss 0.764 (0.948)
 **TRAIN** Prec@1 72.44 Prec@5 97.90 Error@1 27.56 Error@5 2.10 Base-Loss:0.803, Arch-Loss=0.948
***[2020-01-29 07:37:16]*** TRAIN [epoch=218/600] base-loss = 0.803294, arch-loss = 0.948045, accuracy-1 = 72.44, accuracy-5 = 97.90
[epoch=218/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 12, 12, 14, 12, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.13664)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.213 0.343  ||  0.2364 -0.4960 -0.0194  || discrepancy=0.10 || select=0/3
001/003-th : 0.377 0.149 0.474  ||  0.0651 -0.8622 0.2961  || discrepancy=0.10 || select=2/3
002/003-th : 0.051 0.172 0.776  ||  -1.4329 -0.2190 1.2861  || discrepancy=0.60 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.080 0.097 0.104 0.138 0.165 0.180 0.182  ||  -0.759 -0.370 -0.177 -0.113 0.174 0.353 0.436 0.449   || dis=0.00 || select=7/8
001/019-th : 0.131 0.128 0.126 0.129 0.127 0.123 0.119 0.117  ||  0.049 0.025 0.009 0.032 0.015 -0.015 -0.049 -0.068    || dis=0.00 || select=0/8
002/019-th : 0.119 0.127 0.129 0.127 0.129 0.130 0.122 0.118  ||  -0.052 0.014 0.032 0.014 0.033 0.035 -0.025 -0.060    || dis=0.00 || select=5/8
003/019-th : 0.120 0.119 0.121 0.125 0.129 0.130 0.127 0.130  ||  -0.043 -0.050 -0.033 0.005 0.031 0.043 0.017 0.037    || dis=0.00 || select=5/8
004/019-th : 0.111 0.116 0.121 0.122 0.130 0.135 0.134 0.131  ||  -0.113 -0.076 -0.029 -0.025 0.041 0.080 0.069 0.053   || dis=0.00 || select=5/8
005/019-th : 0.114 0.120 0.121 0.129 0.123 0.127 0.133 0.133  ||  -0.093 -0.039 -0.029 0.029 -0.013 0.015 0.065 0.064   || dis=0.00 || select=6/8
006/019-th : 0.115 0.113 0.118 0.123 0.128 0.136 0.133 0.135  ||  -0.077 -0.098 -0.059 -0.015 0.023 0.088 0.062 0.081   || dis=0.00 || select=5/8
007/019-th : 0.068 0.077 0.098 0.119 0.136 0.150 0.166 0.185  ||  -0.550 -0.422 -0.185 0.011 0.138 0.241 0.339 0.451    || dis=0.02 || select=7/8
008/019-th : 0.050 0.061 0.087 0.122 0.132 0.172 0.190 0.188  ||  -0.822 -0.619 -0.264 0.076 0.158 0.418 0.519 0.509    || dis=0.00 || select=6/8
009/019-th : 0.097 0.097 0.106 0.121 0.123 0.136 0.156 0.165  ||  -0.234 -0.240 -0.149 -0.018 0.003 0.100 0.236 0.295   || dis=0.01 || select=7/8
010/019-th : 0.100 0.103 0.116 0.132 0.128 0.138 0.141 0.143  ||  -0.215 -0.186 -0.068 0.059 0.028 0.106 0.128 0.144    || dis=0.00 || select=7/8
011/019-th : 0.101 0.096 0.108 0.111 0.120 0.139 0.156 0.169  ||  -0.195 -0.242 -0.132 -0.100 -0.027 0.125 0.240 0.319  || dis=0.01 || select=7/8
012/019-th : 0.108 0.109 0.117 0.122 0.131 0.131 0.137 0.145  ||  -0.139 -0.129 -0.065 -0.021 0.052 0.052 0.100 0.153   || dis=0.01 || select=7/8
013/019-th : 0.035 0.041 0.055 0.075 0.093 0.137 0.226 0.337  ||  -0.997 -0.827 -0.548 -0.237 -0.016 0.371 0.872 1.269  || dis=0.11 || select=7/8
014/019-th : 0.051 0.056 0.074 0.094 0.120 0.158 0.213 0.235  ||  -0.764 -0.670 -0.398 -0.157 0.094 0.369 0.666 0.763   || dis=0.02 || select=7/8
015/019-th : 0.031 0.035 0.047 0.068 0.095 0.129 0.250 0.344  ||  -1.063 -0.947 -0.644 -0.274 0.065 0.371 1.030 1.350   || dis=0.09 || select=7/8
016/019-th : 0.058 0.077 0.097 0.127 0.137 0.161 0.171 0.170  ||  -0.697 -0.418 -0.188 0.082 0.154 0.316 0.379 0.372    || dis=0.00 || select=6/8
017/019-th : 0.119 0.116 0.117 0.118 0.134 0.128 0.131 0.136  ||  -0.045 -0.069 -0.062 -0.051 0.075 0.030 0.047 0.084   || dis=0.00 || select=7/8
018/019-th : 0.084 0.101 0.120 0.129 0.126 0.131 0.142 0.167  ||  -0.372 -0.193 -0.023 0.055 0.025 0.064 0.145 0.310    || dis=0.03 || select=7/8
[epoch=218/600] FLOP : 27.14 MB, ratio : 0.6649, Expected-ratio : 0.7000, Discrepancy : 0.051
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:37:16] [epoch=218/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.854 (1.854)  Prec@1 39.45 (39.45) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:37:22] [epoch=218/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.247 (2.168)  Prec@1 26.19 (38.49) Prec@5 67.86 (82.24) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.49 Prec@5 82.24 Error@1 61.51 Error@5 17.76 Loss:2.168
***[2020-01-29 07:37:22]*** VALID [epoch=218/600] loss = 2.167951, accuracy@1 = 38.49, accuracy@5 = 82.24 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:37:22]*** start epoch=219/600 Time Left: [03:22:22], LR=[0.070576 ~ 0.070576], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=219, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.558210178582517, FLOP=40.81
[Search] : epoch=219/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:37:23] [epoch=219/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.655 (0.655)  Prec@1 76.56 (76.56) Prec@5 99.22 (99.22) Acls-loss 0.873 (0.873) FLOP-Loss 0.000 (0.000) Arch-Loss 0.873 (0.873)
**TRAIN** [2020-01-29 07:37:47] [epoch=219/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.683 (0.804)  Prec@1 79.17 (73.00) Prec@5 99.40 (97.86) Acls-loss 0.797 (0.831) FLOP-Loss 0.000 (-0.055) Arch-Loss 0.797 (0.720)
 **TRAIN** Prec@1 73.00 Prec@5 97.86 Error@1 27.00 Error@5 2.14 Base-Loss:0.804, Arch-Loss=0.720
***[2020-01-29 07:37:47]*** TRAIN [epoch=219/600] base-loss = 0.804300, arch-loss = 0.720049, accuracy-1 = 73.00, accuracy-5 = 97.86
[epoch=219/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 12, 16, 14, 16, 12, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.214 0.350  ||  0.2185 -0.4921 0.0003  || discrepancy=0.09 || select=0/3
001/003-th : 0.367 0.148 0.485  ||  0.0427 -0.8680 0.3206  || discrepancy=0.12 || select=2/3
002/003-th : 0.049 0.167 0.785  ||  -1.4621 -0.2354 1.3144  || discrepancy=0.62 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.078 0.095 0.105 0.138 0.166 0.181 0.183  ||  -0.768 -0.397 -0.194 -0.096 0.180 0.361 0.449 0.460   || dis=0.00 || select=7/8
001/019-th : 0.129 0.125 0.124 0.127 0.129 0.125 0.121 0.120  ||  0.029 0.002 -0.005 0.016 0.035 -0.002 -0.031 -0.043   || dis=0.00 || select=4/8
002/019-th : 0.117 0.125 0.127 0.125 0.130 0.131 0.124 0.121  ||  -0.071 -0.005 0.017 -0.000 0.040 0.047 -0.006 -0.036  || dis=0.00 || select=5/8
003/019-th : 0.118 0.116 0.120 0.124 0.129 0.132 0.129 0.132  ||  -0.055 -0.076 -0.043 -0.004 0.036 0.055 0.031 0.059   || dis=0.00 || select=7/8
004/019-th : 0.110 0.113 0.120 0.121 0.131 0.135 0.136 0.134  ||  -0.127 -0.103 -0.041 -0.031 0.049 0.081 0.089 0.075   || dis=0.00 || select=6/8
005/019-th : 0.112 0.119 0.120 0.126 0.124 0.128 0.135 0.135  ||  -0.105 -0.049 -0.036 0.012 -0.006 0.022 0.077 0.080   || dis=0.00 || select=7/8
006/019-th : 0.114 0.110 0.115 0.122 0.127 0.138 0.137 0.137  ||  -0.090 -0.127 -0.077 -0.025 0.020 0.100 0.096 0.094   || dis=0.00 || select=5/8
007/019-th : 0.067 0.075 0.097 0.116 0.134 0.153 0.168 0.190  ||  -0.567 -0.446 -0.194 -0.010 0.131 0.265 0.357 0.483   || dis=0.02 || select=7/8
008/019-th : 0.049 0.060 0.086 0.120 0.131 0.171 0.193 0.190  ||  -0.839 -0.633 -0.267 0.068 0.156 0.422 0.542 0.523    || dis=0.00 || select=6/8
009/019-th : 0.096 0.096 0.104 0.120 0.123 0.137 0.156 0.167  ||  -0.244 -0.246 -0.162 -0.025 -0.001 0.113 0.243 0.309  || dis=0.01 || select=7/8
010/019-th : 0.098 0.101 0.115 0.130 0.127 0.138 0.146 0.145  ||  -0.231 -0.206 -0.077 0.050 0.022 0.111 0.164 0.155    || dis=0.00 || select=6/8
011/019-th : 0.099 0.097 0.106 0.110 0.118 0.141 0.158 0.172  ||  -0.218 -0.239 -0.149 -0.108 -0.040 0.142 0.257 0.337  || dis=0.01 || select=7/8
012/019-th : 0.107 0.107 0.116 0.121 0.130 0.133 0.140 0.148  ||  -0.152 -0.152 -0.072 -0.029 0.041 0.065 0.118 0.171   || dis=0.01 || select=7/8
013/019-th : 0.034 0.041 0.054 0.073 0.092 0.138 0.227 0.341  ||  -1.011 -0.832 -0.554 -0.250 -0.018 0.384 0.879 1.287  || dis=0.11 || select=7/8
014/019-th : 0.050 0.054 0.073 0.092 0.121 0.161 0.213 0.237  ||  -0.782 -0.699 -0.400 -0.168 0.105 0.391 0.673 0.780   || dis=0.02 || select=7/8
015/019-th : 0.030 0.034 0.046 0.067 0.095 0.126 0.250 0.352  ||  -1.069 -0.958 -0.648 -0.279 0.067 0.353 1.037 1.380   || dis=0.10 || select=7/8
016/019-th : 0.057 0.075 0.095 0.124 0.137 0.162 0.174 0.175  ||  -0.712 -0.442 -0.204 0.058 0.161 0.327 0.395 0.400    || dis=0.00 || select=7/8
017/019-th : 0.117 0.115 0.114 0.118 0.134 0.130 0.133 0.139  ||  -0.062 -0.081 -0.089 -0.053 0.071 0.045 0.062 0.109   || dis=0.01 || select=7/8
018/019-th : 0.083 0.100 0.117 0.128 0.127 0.134 0.142 0.169  ||  -0.387 -0.201 -0.046 0.044 0.038 0.088 0.145 0.323    || dis=0.03 || select=7/8
[epoch=219/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.053
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:37:48] [epoch=219/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.245 (2.245)  Prec@1 40.23 (40.23) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:37:54] [epoch=219/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.031 (2.387)  Prec@1 39.88 (35.49) Prec@5 86.31 (80.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.49 Prec@5 80.52 Error@1 64.51 Error@5 19.48 Loss:2.387
***[2020-01-29 07:37:54]*** VALID [epoch=219/600] loss = 2.387255, accuracy@1 = 35.49, accuracy@5 = 80.52 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:37:54]*** start epoch=220/600 Time Left: [03:21:50], LR=[0.070337 ~ 0.070337], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=220, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.5465047755357113, FLOP=40.81
[Search] : epoch=220/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:37:54] [epoch=220/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.713 (0.713)  Prec@1 75.39 (75.39) Prec@5 98.44 (98.44) Acls-loss 0.754 (0.754) FLOP-Loss 0.000 (0.000) Arch-Loss 0.754 (0.754)
**TRAIN** [2020-01-29 07:38:19] [epoch=220/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.781 (0.787)  Prec@1 73.81 (73.42) Prec@5 97.02 (97.93) Acls-loss 0.809 (0.828) FLOP-Loss 0.000 (0.055) Arch-Loss 0.809 (0.939)
 **TRAIN** Prec@1 73.42 Prec@5 97.93 Error@1 26.58 Error@5 2.07 Base-Loss:0.787, Arch-Loss=0.939
***[2020-01-29 07:38:19]*** TRAIN [epoch=220/600] base-loss = 0.787320, arch-loss = 0.938552, accuracy-1 = 73.42, accuracy-5 = 97.93
[epoch=220/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 4, 12, 16, 14, 16, 14, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.60416)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.213 0.350  ||  0.2198 -0.4957 0.0009  || discrepancy=0.09 || select=0/3
001/003-th : 0.368 0.148 0.484  ||  0.0452 -0.8656 0.3201  || discrepancy=0.12 || select=2/3
002/003-th : 0.048 0.167 0.785  ||  -1.4768 -0.2263 1.3224  || discrepancy=0.62 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.077 0.094 0.104 0.140 0.166 0.183 0.181  ||  -0.763 -0.399 -0.207 -0.103 0.195 0.363 0.463 0.452   || dis=0.00 || select=6/8
001/019-th : 0.129 0.125 0.125 0.126 0.127 0.125 0.121 0.120  ||  0.034 -0.000 0.002 0.009 0.018 0.002 -0.032 -0.043    || dis=0.00 || select=0/8
002/019-th : 0.117 0.124 0.128 0.124 0.130 0.131 0.125 0.120  ||  -0.065 -0.005 0.026 -0.005 0.037 0.046 -0.004 -0.045  || dis=0.00 || select=5/8
003/019-th : 0.118 0.117 0.119 0.125 0.129 0.130 0.129 0.132  ||  -0.053 -0.067 -0.051 0.003 0.034 0.043 0.033 0.057    || dis=0.00 || select=7/8
004/019-th : 0.110 0.113 0.120 0.119 0.131 0.136 0.136 0.135  ||  -0.127 -0.097 -0.037 -0.045 0.045 0.085 0.088 0.076   || dis=0.00 || select=6/8
005/019-th : 0.112 0.117 0.122 0.128 0.123 0.129 0.134 0.135  ||  -0.109 -0.064 -0.022 0.023 -0.012 0.035 0.074 0.080   || dis=0.00 || select=7/8
006/019-th : 0.115 0.111 0.116 0.121 0.128 0.134 0.138 0.138  ||  -0.084 -0.122 -0.074 -0.028 0.024 0.070 0.101 0.098   || dis=0.00 || select=6/8
007/019-th : 0.067 0.075 0.098 0.117 0.134 0.153 0.167 0.190  ||  -0.565 -0.452 -0.185 -0.004 0.128 0.264 0.354 0.480   || dis=0.02 || select=7/8
008/019-th : 0.048 0.059 0.085 0.121 0.129 0.170 0.197 0.191  ||  -0.838 -0.649 -0.275 0.077 0.140 0.418 0.562 0.534    || dis=0.01 || select=6/8
009/019-th : 0.096 0.096 0.104 0.120 0.124 0.136 0.154 0.168  ||  -0.242 -0.243 -0.163 -0.023 0.009 0.103 0.229 0.316   || dis=0.01 || select=7/8
010/019-th : 0.097 0.102 0.114 0.129 0.126 0.139 0.146 0.146  ||  -0.249 -0.191 -0.082 0.044 0.013 0.118 0.167 0.166    || dis=0.00 || select=6/8
011/019-th : 0.098 0.094 0.108 0.110 0.117 0.143 0.158 0.171  ||  -0.225 -0.263 -0.121 -0.103 -0.041 0.156 0.258 0.332  || dis=0.01 || select=7/8
012/019-th : 0.108 0.108 0.116 0.120 0.128 0.132 0.141 0.147  ||  -0.143 -0.139 -0.069 -0.033 0.030 0.056 0.121 0.163   || dis=0.01 || select=7/8
013/019-th : 0.034 0.041 0.054 0.073 0.091 0.136 0.226 0.345  ||  -1.014 -0.822 -0.547 -0.254 -0.032 0.373 0.878 1.304  || dis=0.12 || select=7/8
014/019-th : 0.050 0.054 0.072 0.092 0.121 0.162 0.213 0.236  ||  -0.778 -0.695 -0.416 -0.161 0.107 0.401 0.672 0.777   || dis=0.02 || select=7/8
015/019-th : 0.031 0.034 0.046 0.066 0.095 0.124 0.250 0.354  ||  -1.061 -0.945 -0.658 -0.292 0.069 0.343 1.043 1.389   || dis=0.10 || select=7/8
016/019-th : 0.057 0.076 0.096 0.124 0.139 0.161 0.171 0.176  ||  -0.722 -0.434 -0.202 0.059 0.175 0.316 0.380 0.410    || dis=0.00 || select=7/8
017/019-th : 0.117 0.116 0.113 0.119 0.134 0.130 0.132 0.138  ||  -0.059 -0.070 -0.102 -0.045 0.071 0.046 0.061 0.102   || dis=0.00 || select=7/8
018/019-th : 0.083 0.100 0.117 0.127 0.130 0.134 0.142 0.167  ||  -0.390 -0.197 -0.046 0.039 0.063 0.091 0.146 0.309    || dis=0.03 || select=7/8
[epoch=220/600] FLOP : 26.60 MB, ratio : 0.6519, Expected-ratio : 0.7000, Discrepancy : 0.053
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:38:19] [epoch=220/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.689 (1.689)  Prec@1 37.89 (37.89) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:38:26] [epoch=220/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.989 (2.224)  Prec@1 39.88 (38.68) Prec@5 84.52 (81.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.68 Prec@5 81.79 Error@1 61.32 Error@5 18.21 Loss:2.224
***[2020-01-29 07:38:26]*** VALID [epoch=220/600] loss = 2.223689, accuracy@1 = 38.68, accuracy@5 = 81.79 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:38:26]*** start epoch=221/600 Time Left: [03:21:18], LR=[0.070097 ~ 0.070097], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=221, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.534772052807103, FLOP=40.81
[Search] : epoch=221/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:38:26] [epoch=221/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.811 (0.811)  Prec@1 71.48 (71.48) Prec@5 96.09 (96.09) Acls-loss 0.815 (0.815) FLOP-Loss 0.000 (0.000) Arch-Loss 0.815 (0.815)
**TRAIN** [2020-01-29 07:38:51] [epoch=221/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.707 (0.810)  Prec@1 75.00 (72.30) Prec@5 99.40 (97.70) Acls-loss 0.973 (0.835) FLOP-Loss 0.000 (0.000) Arch-Loss 0.973 (0.835)
 **TRAIN** Prec@1 72.30 Prec@5 97.70 Error@1 27.70 Error@5 2.30 Base-Loss:0.810, Arch-Loss=0.835
***[2020-01-29 07:38:51]*** TRAIN [epoch=221/600] base-loss = 0.810415, arch-loss = 0.834717, accuracy-1 = 72.30, accuracy-5 = 97.70
[epoch=221/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 4, 11, 16, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.714752)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.433 0.212 0.355  ||  0.2116 -0.5018 0.0118  || discrepancy=0.08 || select=0/3
001/003-th : 0.364 0.145 0.491  ||  0.0350 -0.8819 0.3340  || discrepancy=0.13 || select=2/3
002/003-th : 0.047 0.164 0.789  ||  -1.4866 -0.2339 1.3344  || discrepancy=0.62 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.077 0.092 0.101 0.139 0.167 0.187 0.184  ||  -0.755 -0.405 -0.228 -0.127 0.187 0.370 0.482 0.466   || dis=0.00 || select=6/8
001/019-th : 0.127 0.125 0.125 0.127 0.127 0.127 0.121 0.121  ||  0.018 -0.002 0.004 0.018 0.018 0.014 -0.032 -0.033    || dis=0.00 || select=0/8
002/019-th : 0.116 0.124 0.127 0.126 0.131 0.130 0.125 0.121  ||  -0.075 -0.010 0.012 0.004 0.045 0.041 0.003 -0.032    || dis=0.00 || select=4/8
003/019-th : 0.116 0.116 0.120 0.125 0.130 0.130 0.130 0.132  ||  -0.071 -0.073 -0.038 0.007 0.038 0.044 0.045 0.060    || dis=0.00 || select=7/8
004/019-th : 0.110 0.113 0.117 0.118 0.132 0.135 0.138 0.136  ||  -0.130 -0.102 -0.062 -0.055 0.059 0.080 0.099 0.089   || dis=0.00 || select=6/8
005/019-th : 0.111 0.116 0.123 0.124 0.124 0.131 0.134 0.135  ||  -0.112 -0.072 -0.012 -0.003 -0.003 0.052 0.074 0.083  || dis=0.00 || select=7/8
006/019-th : 0.114 0.110 0.115 0.120 0.129 0.135 0.138 0.138  ||  -0.086 -0.128 -0.081 -0.035 0.031 0.078 0.102 0.102   || dis=0.00 || select=7/8
007/019-th : 0.065 0.075 0.096 0.116 0.136 0.153 0.168 0.191  ||  -0.585 -0.451 -0.198 -0.013 0.152 0.268 0.363 0.488   || dis=0.02 || select=7/8
008/019-th : 0.048 0.058 0.086 0.121 0.128 0.170 0.196 0.193  ||  -0.839 -0.653 -0.266 0.074 0.133 0.417 0.558 0.542    || dis=0.00 || select=6/8
009/019-th : 0.097 0.095 0.104 0.121 0.125 0.135 0.153 0.170  ||  -0.239 -0.254 -0.164 -0.015 0.018 0.095 0.217 0.327   || dis=0.02 || select=7/8
010/019-th : 0.097 0.101 0.113 0.128 0.128 0.140 0.148 0.146  ||  -0.248 -0.203 -0.090 0.034 0.031 0.122 0.177 0.164    || dis=0.00 || select=6/8
011/019-th : 0.097 0.095 0.109 0.109 0.116 0.142 0.159 0.173  ||  -0.235 -0.254 -0.117 -0.115 -0.052 0.150 0.260 0.346  || dis=0.01 || select=7/8
012/019-th : 0.106 0.107 0.114 0.120 0.130 0.134 0.141 0.148  ||  -0.157 -0.149 -0.090 -0.038 0.043 0.074 0.127 0.175   || dis=0.01 || select=7/8
013/019-th : 0.034 0.040 0.054 0.071 0.089 0.135 0.227 0.350  ||  -1.017 -0.843 -0.543 -0.263 -0.042 0.372 0.892 1.325  || dis=0.12 || select=7/8
014/019-th : 0.050 0.053 0.072 0.090 0.120 0.164 0.213 0.238  ||  -0.773 -0.714 -0.406 -0.180 0.101 0.414 0.678 0.787   || dis=0.02 || select=7/8
015/019-th : 0.030 0.034 0.045 0.065 0.094 0.123 0.251 0.359  ||  -1.076 -0.948 -0.662 -0.292 0.067 0.336 1.051 1.409   || dis=0.11 || select=7/8
016/019-th : 0.056 0.076 0.096 0.124 0.139 0.161 0.174 0.176  ||  -0.739 -0.435 -0.201 0.059 0.170 0.318 0.398 0.411    || dis=0.00 || select=7/8
017/019-th : 0.117 0.115 0.112 0.119 0.134 0.130 0.134 0.139  ||  -0.063 -0.077 -0.110 -0.046 0.072 0.042 0.071 0.109   || dis=0.01 || select=7/8
018/019-th : 0.083 0.100 0.116 0.128 0.128 0.135 0.142 0.168  ||  -0.390 -0.200 -0.054 0.042 0.047 0.099 0.146 0.317    || dis=0.03 || select=7/8
[epoch=221/600] FLOP : 26.71 MB, ratio : 0.6546, Expected-ratio : 0.7000, Discrepancy : 0.054
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:38:51] [epoch=221/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.612 (2.612)  Prec@1 27.34 (27.34) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:38:57] [epoch=221/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.944 (2.306)  Prec@1 56.55 (37.80) Prec@5 92.86 (81.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.80 Prec@5 81.53 Error@1 62.20 Error@5 18.47 Loss:2.306
***[2020-01-29 07:38:57]*** VALID [epoch=221/600] loss = 2.306358, accuracy@1 = 37.80, accuracy@5 = 81.53 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:38:57]*** start epoch=222/600 Time Left: [03:20:46], LR=[0.069857 ~ 0.069857], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=222, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.5230123320552127, FLOP=40.81
[Search] : epoch=222/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:38:58] [epoch=222/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.913 (0.913)  Prec@1 70.70 (70.70) Prec@5 95.70 (95.70) Acls-loss 0.910 (0.910) FLOP-Loss 0.000 (0.000) Arch-Loss 0.910 (0.910)
**TRAIN** [2020-01-29 07:39:22] [epoch=222/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.842 (0.817)  Prec@1 70.24 (71.95) Prec@5 98.81 (97.71) Acls-loss 0.711 (0.851) FLOP-Loss 0.000 (0.000) Arch-Loss 0.711 (0.851)
 **TRAIN** Prec@1 71.95 Prec@5 97.71 Error@1 28.05 Error@5 2.29 Base-Loss:0.817, Arch-Loss=0.851
***[2020-01-29 07:39:22]*** TRAIN [epoch=222/600] base-loss = 0.816716, arch-loss = 0.850777, accuracy-1 = 71.95, accuracy-5 = 97.71
[epoch=222/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 11, 11, 16, 14, 14, 14, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.16576)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.429 0.214 0.357  ||  0.2038 -0.4904 0.0200  || discrepancy=0.07 || select=0/3
001/003-th : 0.359 0.146 0.495  ||  0.0242 -0.8771 0.3462  || discrepancy=0.14 || select=2/3
002/003-th : 0.046 0.160 0.794  ||  -1.5030 -0.2489 1.3542  || discrepancy=0.63 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.076 0.091 0.102 0.138 0.168 0.187 0.185  ||  -0.752 -0.420 -0.235 -0.124 0.182 0.376 0.489 0.474   || dis=0.00 || select=6/8
001/019-th : 0.125 0.123 0.125 0.128 0.128 0.127 0.122 0.122  ||  0.005 -0.014 0.004 0.026 0.028 0.019 -0.022 -0.026    || dis=0.00 || select=4/8
002/019-th : 0.115 0.122 0.126 0.128 0.131 0.130 0.126 0.122  ||  -0.081 -0.026 0.009 0.025 0.048 0.042 0.011 -0.027    || dis=0.00 || select=4/8
003/019-th : 0.114 0.115 0.119 0.125 0.131 0.130 0.132 0.133  ||  -0.087 -0.081 -0.047 0.006 0.053 0.044 0.060 0.069    || dis=0.00 || select=7/8
004/019-th : 0.109 0.112 0.117 0.118 0.134 0.135 0.139 0.136  ||  -0.138 -0.107 -0.064 -0.059 0.073 0.081 0.109 0.089   || dis=0.00 || select=6/8
005/019-th : 0.110 0.113 0.122 0.124 0.125 0.133 0.137 0.136  ||  -0.124 -0.099 -0.016 0.000 0.004 0.064 0.100 0.086    || dis=0.00 || select=6/8
006/019-th : 0.114 0.110 0.114 0.120 0.131 0.135 0.138 0.138  ||  -0.089 -0.125 -0.093 -0.039 0.049 0.080 0.102 0.102   || dis=0.00 || select=6/8
007/019-th : 0.066 0.074 0.093 0.116 0.136 0.154 0.168 0.193  ||  -0.578 -0.457 -0.227 -0.008 0.155 0.273 0.363 0.502   || dis=0.02 || select=7/8
008/019-th : 0.048 0.057 0.084 0.120 0.130 0.172 0.195 0.193  ||  -0.840 -0.670 -0.281 0.074 0.154 0.429 0.555 0.548    || dis=0.00 || select=6/8
009/019-th : 0.096 0.096 0.103 0.119 0.125 0.138 0.154 0.170  ||  -0.247 -0.249 -0.174 -0.030 0.017 0.115 0.229 0.327   || dis=0.02 || select=7/8
010/019-th : 0.096 0.099 0.111 0.130 0.127 0.139 0.150 0.148  ||  -0.250 -0.220 -0.111 0.046 0.024 0.113 0.195 0.180    || dis=0.00 || select=6/8
011/019-th : 0.097 0.094 0.107 0.107 0.117 0.142 0.160 0.175  ||  -0.234 -0.267 -0.129 -0.129 -0.041 0.149 0.271 0.360  || dis=0.01 || select=7/8
012/019-th : 0.105 0.106 0.113 0.121 0.129 0.134 0.142 0.149  ||  -0.168 -0.155 -0.099 -0.023 0.040 0.076 0.134 0.182   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.054 0.070 0.089 0.134 0.227 0.353  ||  -1.001 -0.855 -0.538 -0.276 -0.046 0.366 0.896 1.336  || dis=0.13 || select=7/8
014/019-th : 0.050 0.052 0.072 0.091 0.119 0.162 0.212 0.242  ||  -0.775 -0.740 -0.405 -0.169 0.100 0.404 0.676 0.807   || dis=0.03 || select=7/8
015/019-th : 0.030 0.034 0.044 0.065 0.092 0.121 0.249 0.363  ||  -1.075 -0.940 -0.675 -0.290 0.059 0.330 1.050 1.427   || dis=0.11 || select=7/8
016/019-th : 0.055 0.075 0.096 0.125 0.137 0.161 0.175 0.176  ||  -0.756 -0.441 -0.196 0.068 0.159 0.325 0.408 0.414    || dis=0.00 || select=7/8
017/019-th : 0.116 0.115 0.112 0.117 0.134 0.130 0.136 0.140  ||  -0.070 -0.084 -0.109 -0.064 0.071 0.042 0.087 0.118   || dis=0.00 || select=7/8
018/019-th : 0.083 0.100 0.115 0.128 0.129 0.136 0.141 0.168  ||  -0.387 -0.199 -0.062 0.042 0.054 0.105 0.141 0.314    || dis=0.03 || select=7/8
[epoch=222/600] FLOP : 28.17 MB, ratio : 0.6901, Expected-ratio : 0.7000, Discrepancy : 0.055
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:39:23] [epoch=222/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.065 (2.065)  Prec@1 32.42 (32.42) Prec@5 78.52 (78.52) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:39:29] [epoch=222/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.541 (2.116)  Prec@1 45.24 (39.46) Prec@5 92.26 (84.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.46 Prec@5 84.30 Error@1 60.54 Error@5 15.70 Loss:2.116
***[2020-01-29 07:39:29]*** VALID [epoch=222/600] loss = 2.115948, accuracy@1 = 39.46, accuracy@5 = 84.30 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:39:29]*** start epoch=223/600 Time Left: [03:20:13], LR=[0.069617 ~ 0.069617], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=223, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.5112259356787257, FLOP=40.81
[Search] : epoch=223/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:39:30] [epoch=223/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.745 (0.745)  Prec@1 74.61 (74.61) Prec@5 99.22 (99.22) Acls-loss 1.026 (1.026) FLOP-Loss 0.000 (0.000) Arch-Loss 1.026 (1.026)
**TRAIN** [2020-01-29 07:39:54] [epoch=223/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.681 (0.796)  Prec@1 80.95 (72.85) Prec@5 97.62 (97.92) Acls-loss 0.846 (0.841) FLOP-Loss 0.000 (0.111) Arch-Loss 0.846 (1.064)
 **TRAIN** Prec@1 72.85 Prec@5 97.92 Error@1 27.15 Error@5 2.08 Base-Loss:0.796, Arch-Loss=1.064
***[2020-01-29 07:39:54]*** TRAIN [epoch=223/600] base-loss = 0.796347, arch-loss = 1.063787, accuracy-1 = 72.85, accuracy-5 = 97.92
[epoch=223/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 11, 14, 16, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.343936)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.435 0.212 0.353  ||  0.2172 -0.4997 0.0089  || discrepancy=0.08 || select=0/3
001/003-th : 0.365 0.147 0.488  ||  0.0401 -0.8684 0.3322  || discrepancy=0.12 || select=2/3
002/003-th : 0.045 0.161 0.794  ||  -1.5060 -0.2406 1.3551  || discrepancy=0.63 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.076 0.093 0.104 0.138 0.167 0.184 0.184  ||  -0.760 -0.419 -0.218 -0.098 0.183 0.371 0.471 0.467   || dis=0.00 || select=6/8
001/019-th : 0.126 0.124 0.127 0.128 0.127 0.127 0.121 0.120  ||  0.013 -0.007 0.018 0.025 0.015 0.019 -0.028 -0.038    || dis=0.00 || select=3/8
002/019-th : 0.117 0.124 0.128 0.130 0.129 0.128 0.124 0.120  ||  -0.067 -0.007 0.023 0.042 0.033 0.028 -0.008 -0.042   || dis=0.00 || select=3/8
003/019-th : 0.116 0.115 0.120 0.126 0.132 0.129 0.131 0.131  ||  -0.067 -0.083 -0.038 0.012 0.056 0.038 0.050 0.052    || dis=0.00 || select=4/8
004/019-th : 0.111 0.114 0.118 0.116 0.133 0.134 0.138 0.136  ||  -0.122 -0.096 -0.060 -0.071 0.061 0.073 0.102 0.087   || dis=0.00 || select=6/8
005/019-th : 0.110 0.115 0.123 0.126 0.125 0.131 0.134 0.135  ||  -0.124 -0.078 -0.010 0.015 0.008 0.053 0.074 0.080    || dis=0.00 || select=7/8
006/019-th : 0.115 0.111 0.115 0.120 0.133 0.131 0.138 0.137  ||  -0.082 -0.113 -0.080 -0.043 0.061 0.046 0.103 0.096   || dis=0.00 || select=6/8
007/019-th : 0.066 0.075 0.094 0.119 0.135 0.152 0.168 0.192  ||  -0.575 -0.451 -0.222 0.014 0.141 0.257 0.359 0.495    || dis=0.02 || select=7/8
008/019-th : 0.048 0.057 0.086 0.121 0.132 0.171 0.192 0.194  ||  -0.837 -0.674 -0.266 0.077 0.164 0.422 0.539 0.548    || dis=0.00 || select=7/8
009/019-th : 0.097 0.098 0.104 0.119 0.122 0.139 0.153 0.167  ||  -0.235 -0.228 -0.166 -0.035 -0.004 0.126 0.222 0.308  || dis=0.01 || select=7/8
010/019-th : 0.098 0.101 0.111 0.130 0.126 0.138 0.150 0.146  ||  -0.231 -0.209 -0.108 0.048 0.017 0.105 0.190 0.166    || dis=0.00 || select=6/8
011/019-th : 0.096 0.094 0.108 0.112 0.117 0.141 0.159 0.174  ||  -0.242 -0.262 -0.123 -0.092 -0.042 0.140 0.260 0.351  || dis=0.01 || select=7/8
012/019-th : 0.106 0.108 0.114 0.122 0.132 0.134 0.139 0.146  ||  -0.156 -0.142 -0.088 -0.020 0.062 0.080 0.111 0.160   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.055 0.071 0.089 0.134 0.226 0.353  ||  -0.994 -0.872 -0.527 -0.271 -0.045 0.365 0.888 1.338  || dis=0.13 || select=7/8
014/019-th : 0.051 0.052 0.072 0.092 0.120 0.163 0.210 0.241  ||  -0.762 -0.742 -0.402 -0.162 0.104 0.408 0.661 0.801   || dis=0.03 || select=7/8
015/019-th : 0.030 0.034 0.045 0.065 0.092 0.120 0.245 0.368  ||  -1.067 -0.936 -0.665 -0.289 0.054 0.317 1.033 1.438   || dis=0.12 || select=7/8
016/019-th : 0.054 0.076 0.098 0.126 0.139 0.159 0.173 0.174  ||  -0.767 -0.422 -0.173 0.077 0.175 0.309 0.395 0.401    || dis=0.00 || select=7/8
017/019-th : 0.119 0.115 0.115 0.117 0.131 0.129 0.134 0.140  ||  -0.049 -0.081 -0.081 -0.065 0.046 0.029 0.072 0.110   || dis=0.01 || select=7/8
018/019-th : 0.082 0.102 0.114 0.128 0.130 0.137 0.141 0.166  ||  -0.395 -0.186 -0.071 0.042 0.058 0.116 0.142 0.307    || dis=0.03 || select=7/8
[epoch=223/600] FLOP : 28.34 MB, ratio : 0.6945, Expected-ratio : 0.7000, Discrepancy : 0.056
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:39:54] [epoch=223/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.110 (2.110)  Prec@1 50.00 (50.00) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:40:00] [epoch=223/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.872 (2.376)  Prec@1 47.02 (37.34) Prec@5 83.93 (82.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.34 Prec@5 82.79 Error@1 62.66 Error@5 17.21 Loss:2.376
***[2020-01-29 07:40:00]*** VALID [epoch=223/600] loss = 2.376155, accuracy@1 = 37.34, accuracy@5 = 82.79 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:40:01]*** start epoch=224/600 Time Left: [03:19:41], LR=[0.069376 ~ 0.069376], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=224, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4994131868076526, FLOP=40.81
[Search] : epoch=224/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:40:01] [epoch=224/600][000/098] Time 0.76 (0.76) Data 0.37 (0.37) Base-Loss 0.812 (0.812)  Prec@1 72.66 (72.66) Prec@5 97.27 (97.27) Acls-loss 0.711 (0.711) FLOP-Loss 0.000 (0.000) Arch-Loss 0.711 (0.711)
**TRAIN** [2020-01-29 07:40:26] [epoch=224/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.915 (0.800)  Prec@1 72.62 (72.81) Prec@5 97.02 (97.93) Acls-loss 0.817 (0.855) FLOP-Loss 0.000 (0.028) Arch-Loss 0.817 (0.912)
 **TRAIN** Prec@1 72.81 Prec@5 97.93 Error@1 27.19 Error@5 2.07 Base-Loss:0.800, Arch-Loss=0.912
***[2020-01-29 07:40:26]*** TRAIN [epoch=224/600] base-loss = 0.800446, arch-loss = 0.911525, accuracy-1 = 72.81, accuracy-5 = 97.93
[epoch=224/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 11, 14, 14, 14, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.39616)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.433 0.213 0.354  ||  0.2148 -0.4963 0.0125  || discrepancy=0.08 || select=0/3
001/003-th : 0.365 0.146 0.489  ||  0.0401 -0.8743 0.3346  || discrepancy=0.12 || select=2/3
002/003-th : 0.045 0.161 0.794  ||  -1.5037 -0.2397 1.3557  || discrepancy=0.63 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.076 0.092 0.104 0.139 0.166 0.184 0.184  ||  -0.755 -0.415 -0.220 -0.100 0.184 0.365 0.469 0.467   || dis=0.00 || select=6/8
001/019-th : 0.127 0.123 0.127 0.127 0.127 0.128 0.121 0.121  ||  0.016 -0.012 0.014 0.017 0.018 0.023 -0.032 -0.035    || dis=0.00 || select=5/8
002/019-th : 0.117 0.123 0.127 0.129 0.131 0.127 0.124 0.121  ||  -0.067 -0.012 0.018 0.033 0.043 0.019 -0.005 -0.034   || dis=0.00 || select=4/8
003/019-th : 0.117 0.115 0.120 0.126 0.131 0.130 0.131 0.131  ||  -0.064 -0.082 -0.040 0.008 0.053 0.041 0.053 0.048    || dis=0.00 || select=4/8
004/019-th : 0.110 0.113 0.118 0.117 0.132 0.135 0.138 0.137  ||  -0.131 -0.098 -0.058 -0.061 0.059 0.076 0.102 0.091   || dis=0.00 || select=6/8
005/019-th : 0.109 0.115 0.126 0.124 0.128 0.130 0.134 0.134  ||  -0.132 -0.077 0.012 -0.001 0.027 0.043 0.077 0.076    || dis=0.00 || select=6/8
006/019-th : 0.114 0.111 0.114 0.120 0.132 0.132 0.140 0.137  ||  -0.087 -0.113 -0.091 -0.042 0.058 0.056 0.113 0.093   || dis=0.00 || select=6/8
007/019-th : 0.066 0.074 0.096 0.116 0.135 0.151 0.168 0.193  ||  -0.579 -0.457 -0.203 -0.007 0.145 0.256 0.362 0.497   || dis=0.02 || select=7/8
008/019-th : 0.048 0.057 0.086 0.119 0.132 0.171 0.194 0.193  ||  -0.837 -0.681 -0.263 0.062 0.167 0.427 0.551 0.546    || dis=0.00 || select=6/8
009/019-th : 0.098 0.098 0.104 0.119 0.120 0.140 0.153 0.168  ||  -0.225 -0.232 -0.172 -0.032 -0.024 0.133 0.217 0.313  || dis=0.02 || select=7/8
010/019-th : 0.098 0.100 0.110 0.129 0.126 0.139 0.151 0.146  ||  -0.232 -0.216 -0.116 0.040 0.016 0.118 0.202 0.167    || dis=0.01 || select=6/8
011/019-th : 0.094 0.094 0.109 0.111 0.118 0.141 0.161 0.172  ||  -0.260 -0.264 -0.115 -0.093 -0.037 0.145 0.275 0.345  || dis=0.01 || select=7/8
012/019-th : 0.107 0.108 0.115 0.120 0.131 0.134 0.138 0.147  ||  -0.152 -0.138 -0.081 -0.034 0.056 0.077 0.105 0.165   || dis=0.01 || select=7/8
013/019-th : 0.034 0.038 0.055 0.070 0.090 0.132 0.225 0.355  ||  -0.996 -0.879 -0.526 -0.275 -0.033 0.358 0.890 1.343  || dis=0.13 || select=7/8
014/019-th : 0.051 0.052 0.072 0.093 0.121 0.162 0.210 0.241  ||  -0.756 -0.740 -0.411 -0.157 0.111 0.402 0.661 0.799   || dis=0.03 || select=7/8
015/019-th : 0.029 0.034 0.046 0.066 0.092 0.120 0.246 0.368  ||  -1.084 -0.953 -0.648 -0.284 0.058 0.320 1.037 1.440   || dis=0.12 || select=7/8
016/019-th : 0.054 0.077 0.099 0.127 0.141 0.156 0.173 0.173  ||  -0.779 -0.411 -0.163 0.082 0.192 0.291 0.392 0.396    || dis=0.00 || select=7/8
017/019-th : 0.119 0.114 0.117 0.116 0.131 0.129 0.135 0.139  ||  -0.047 -0.091 -0.068 -0.076 0.045 0.034 0.078 0.107   || dis=0.00 || select=7/8
018/019-th : 0.083 0.102 0.115 0.127 0.130 0.137 0.140 0.167  ||  -0.390 -0.184 -0.066 0.035 0.060 0.112 0.133 0.311    || dis=0.03 || select=7/8
[epoch=224/600] FLOP : 28.40 MB, ratio : 0.6958, Expected-ratio : 0.7000, Discrepancy : 0.056
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:40:26] [epoch=224/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.519 (1.519)  Prec@1 51.95 (51.95) Prec@5 94.14 (94.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:40:32] [epoch=224/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.031 (2.387)  Prec@1 41.07 (36.69) Prec@5 86.31 (81.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.69 Prec@5 81.32 Error@1 63.31 Error@5 18.68 Loss:2.387
***[2020-01-29 07:40:32]*** VALID [epoch=224/600] loss = 2.387015, accuracy@1 = 36.69, accuracy@5 = 81.32 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:40:32]*** start epoch=225/600 Time Left: [03:19:09], LR=[0.069134 ~ 0.069134], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=225, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4875744092944703, FLOP=40.81
[Search] : epoch=225/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:40:33] [epoch=225/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.906 (0.906)  Prec@1 69.14 (69.14) Prec@5 97.66 (97.66) Acls-loss 0.874 (0.874) FLOP-Loss 0.000 (0.000) Arch-Loss 0.874 (0.874)
**TRAIN** [2020-01-29 07:40:57] [epoch=225/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.632 (0.792)  Prec@1 79.17 (73.36) Prec@5 99.40 (97.96) Acls-loss 0.942 (0.829) FLOP-Loss 0.000 (0.056) Arch-Loss 0.942 (0.940)
 **TRAIN** Prec@1 73.36 Prec@5 97.96 Error@1 26.64 Error@5 2.04 Base-Loss:0.792, Arch-Loss=0.940
***[2020-01-29 07:40:57]*** TRAIN [epoch=225/600] base-loss = 0.792170, arch-loss = 0.940376, accuracy-1 = 73.36, accuracy-5 = 97.96
[epoch=225/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 12, 11, 11, 14, 14, 14, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.39616)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.435 0.212 0.353  ||  0.2189 -0.4979 0.0098  || discrepancy=0.08 || select=0/3
001/003-th : 0.366 0.145 0.489  ||  0.0432 -0.8812 0.3341  || discrepancy=0.12 || select=2/3
002/003-th : 0.043 0.157 0.799  ||  -1.5358 -0.2451 1.3808  || discrepancy=0.64 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.076 0.091 0.105 0.140 0.164 0.185 0.185  ||  -0.765 -0.413 -0.233 -0.089 0.195 0.354 0.473 0.472   || dis=0.00 || select=6/8
001/019-th : 0.127 0.124 0.127 0.127 0.126 0.128 0.121 0.120  ||  0.018 -0.008 0.014 0.019 0.011 0.023 -0.032 -0.038    || dis=0.00 || select=5/8
002/019-th : 0.116 0.124 0.126 0.131 0.131 0.129 0.124 0.120  ||  -0.073 -0.008 0.007 0.051 0.051 0.031 -0.005 -0.039   || dis=0.00 || select=4/8
003/019-th : 0.116 0.116 0.120 0.122 0.133 0.131 0.131 0.131  ||  -0.072 -0.074 -0.041 -0.018 0.067 0.051 0.054 0.049   || dis=0.00 || select=4/8
004/019-th : 0.111 0.114 0.116 0.118 0.133 0.135 0.137 0.136  ||  -0.121 -0.087 -0.070 -0.061 0.062 0.079 0.094 0.085   || dis=0.00 || select=6/8
005/019-th : 0.108 0.116 0.127 0.124 0.129 0.128 0.135 0.133  ||  -0.138 -0.072 0.019 -0.006 0.036 0.032 0.084 0.071    || dis=0.00 || select=6/8
006/019-th : 0.114 0.111 0.115 0.122 0.131 0.132 0.138 0.137  ||  -0.091 -0.111 -0.084 -0.021 0.050 0.057 0.103 0.094   || dis=0.00 || select=6/8
007/019-th : 0.066 0.074 0.097 0.117 0.135 0.151 0.168 0.192  ||  -0.574 -0.461 -0.190 -0.003 0.141 0.253 0.357 0.491   || dis=0.02 || select=7/8
008/019-th : 0.049 0.055 0.085 0.118 0.134 0.173 0.194 0.193  ||  -0.831 -0.708 -0.268 0.060 0.184 0.438 0.554 0.549    || dis=0.00 || select=6/8
009/019-th : 0.097 0.096 0.104 0.120 0.121 0.141 0.153 0.168  ||  -0.231 -0.243 -0.169 -0.024 -0.017 0.136 0.221 0.315  || dis=0.02 || select=7/8
010/019-th : 0.099 0.099 0.110 0.130 0.124 0.140 0.151 0.146  ||  -0.221 -0.224 -0.121 0.050 0.001 0.121 0.201 0.168    || dis=0.01 || select=6/8
011/019-th : 0.093 0.094 0.109 0.113 0.119 0.141 0.160 0.170  ||  -0.275 -0.263 -0.107 -0.072 -0.026 0.149 0.272 0.335  || dis=0.01 || select=7/8
012/019-th : 0.107 0.109 0.115 0.119 0.131 0.134 0.138 0.146  ||  -0.147 -0.131 -0.076 -0.041 0.052 0.071 0.105 0.162   || dis=0.01 || select=7/8
013/019-th : 0.034 0.038 0.054 0.071 0.088 0.132 0.228 0.356  ||  -1.007 -0.894 -0.527 -0.265 -0.050 0.363 0.907 1.352  || dis=0.13 || select=7/8
014/019-th : 0.051 0.051 0.073 0.093 0.120 0.161 0.209 0.241  ||  -0.746 -0.748 -0.394 -0.155 0.103 0.395 0.656 0.798   || dis=0.03 || select=7/8
015/019-th : 0.030 0.034 0.045 0.065 0.092 0.120 0.245 0.370  ||  -1.078 -0.941 -0.653 -0.295 0.055 0.320 1.032 1.446   || dis=0.12 || select=7/8
016/019-th : 0.053 0.076 0.099 0.126 0.141 0.157 0.173 0.175  ||  -0.781 -0.425 -0.165 0.074 0.188 0.299 0.393 0.408    || dis=0.00 || select=7/8
017/019-th : 0.119 0.114 0.119 0.116 0.131 0.129 0.134 0.138  ||  -0.050 -0.091 -0.052 -0.072 0.049 0.036 0.073 0.101   || dis=0.00 || select=7/8
018/019-th : 0.082 0.100 0.114 0.127 0.132 0.138 0.140 0.167  ||  -0.404 -0.196 -0.073 0.039 0.075 0.122 0.136 0.314    || dis=0.03 || select=7/8
[epoch=225/600] FLOP : 28.40 MB, ratio : 0.6958, Expected-ratio : 0.7000, Discrepancy : 0.056
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:40:58] [epoch=225/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.466 (2.466)  Prec@1 49.61 (49.61) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:41:04] [epoch=225/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.937 (2.220)  Prec@1 30.95 (35.33) Prec@5 80.36 (81.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.33 Prec@5 81.18 Error@1 64.67 Error@5 18.82 Loss:2.220
***[2020-01-29 07:41:04]*** VALID [epoch=225/600] loss = 2.219775, accuracy@1 = 35.33, accuracy@5 = 81.18 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:41:04]*** start epoch=226/600 Time Left: [03:18:37], LR=[0.068892 ~ 0.068892], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=226, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4757099277052452, FLOP=40.81
[Search] : epoch=226/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:41:05] [epoch=226/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.767 (0.767)  Prec@1 74.22 (74.22) Prec@5 99.22 (99.22) Acls-loss 0.897 (0.897) FLOP-Loss 0.000 (0.000) Arch-Loss 0.897 (0.897)
**TRAIN** [2020-01-29 07:41:29] [epoch=226/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.796 (0.803)  Prec@1 71.43 (72.92) Prec@5 97.02 (97.91) Acls-loss 0.778 (0.842) FLOP-Loss 0.000 (0.194) Arch-Loss 0.778 (1.230)
 **TRAIN** Prec@1 72.92 Prec@5 97.91 Error@1 27.08 Error@5 2.09 Base-Loss:0.803, Arch-Loss=1.230
***[2020-01-29 07:41:29]*** TRAIN [epoch=226/600] base-loss = 0.802706, arch-loss = 1.230219, accuracy-1 = 72.92, accuracy-5 = 97.91
[epoch=226/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 11, 14, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.595392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.212 0.343  ||  0.2451 -0.4972 -0.0162  || discrepancy=0.10 || select=0/3
001/003-th : 0.376 0.146 0.478  ||  0.0700 -0.8753 0.3097  || discrepancy=0.10 || select=2/3
002/003-th : 0.043 0.161 0.796  ||  -1.5424 -0.2227 1.3770  || discrepancy=0.64 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.078 0.093 0.108 0.140 0.162 0.181 0.183  ||  -0.752 -0.391 -0.219 -0.070 0.191 0.338 0.445 0.456   || dis=0.00 || select=7/8
001/019-th : 0.130 0.127 0.127 0.130 0.125 0.124 0.119 0.118  ||  0.043 0.016 0.018 0.043 -0.003 -0.004 -0.052 -0.061   || dis=0.00 || select=0/8
002/019-th : 0.118 0.127 0.129 0.134 0.128 0.126 0.119 0.117  ||  -0.051 0.023 0.034 0.076 0.031 0.014 -0.043 -0.064    || dis=0.01 || select=3/8
003/019-th : 0.117 0.118 0.123 0.123 0.132 0.129 0.129 0.128  ||  -0.058 -0.050 -0.014 -0.013 0.060 0.038 0.034 0.026   || dis=0.00 || select=4/8
004/019-th : 0.113 0.117 0.119 0.121 0.133 0.133 0.133 0.132  ||  -0.095 -0.068 -0.048 -0.034 0.064 0.062 0.065 0.054   || dis=0.00 || select=6/8
005/019-th : 0.110 0.119 0.128 0.125 0.128 0.125 0.134 0.131  ||  -0.127 -0.048 0.027 0.008 0.031 0.006 0.073 0.053     || dis=0.00 || select=6/8
006/019-th : 0.117 0.115 0.118 0.122 0.129 0.130 0.135 0.135  ||  -0.066 -0.085 -0.058 -0.022 0.034 0.042 0.075 0.077   || dis=0.00 || select=7/8
007/019-th : 0.068 0.076 0.099 0.117 0.134 0.151 0.168 0.188  ||  -0.551 -0.443 -0.178 -0.011 0.127 0.248 0.357 0.468   || dis=0.02 || select=7/8
008/019-th : 0.048 0.057 0.087 0.119 0.133 0.172 0.192 0.193  ||  -0.838 -0.679 -0.256 0.062 0.174 0.430 0.539 0.544    || dis=0.00 || select=7/8
009/019-th : 0.100 0.098 0.105 0.122 0.120 0.139 0.151 0.164  ||  -0.203 -0.229 -0.162 -0.005 -0.024 0.125 0.207 0.288  || dis=0.01 || select=7/8
010/019-th : 0.102 0.101 0.112 0.131 0.126 0.136 0.149 0.143  ||  -0.192 -0.204 -0.102 0.056 0.016 0.092 0.181 0.139    || dis=0.01 || select=6/8
011/019-th : 0.094 0.096 0.109 0.115 0.119 0.140 0.158 0.169  ||  -0.263 -0.246 -0.113 -0.063 -0.022 0.139 0.256 0.325  || dis=0.01 || select=7/8
012/019-th : 0.110 0.111 0.117 0.122 0.131 0.131 0.134 0.145  ||  -0.120 -0.114 -0.064 -0.022 0.047 0.048 0.071 0.150   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.055 0.071 0.088 0.133 0.228 0.353  ||  -1.008 -0.856 -0.526 -0.265 -0.053 0.361 0.900 1.337  || dis=0.12 || select=7/8
014/019-th : 0.053 0.052 0.074 0.093 0.121 0.160 0.210 0.237  ||  -0.722 -0.731 -0.387 -0.157 0.105 0.384 0.656 0.776   || dis=0.03 || select=7/8
015/019-th : 0.030 0.035 0.046 0.065 0.093 0.121 0.242 0.368  ||  -1.075 -0.928 -0.644 -0.299 0.060 0.324 1.019 1.437   || dis=0.13 || select=7/8
016/019-th : 0.054 0.077 0.101 0.128 0.142 0.156 0.170 0.172  ||  -0.774 -0.419 -0.143 0.089 0.200 0.293 0.379 0.387    || dis=0.00 || select=7/8
017/019-th : 0.122 0.117 0.123 0.117 0.128 0.127 0.131 0.135  ||  -0.028 -0.063 -0.017 -0.067 0.020 0.013 0.048 0.077   || dis=0.00 || select=7/8
018/019-th : 0.083 0.103 0.114 0.127 0.133 0.137 0.139 0.164  ||  -0.389 -0.174 -0.073 0.037 0.082 0.115 0.130 0.295    || dis=0.02 || select=7/8
[epoch=226/600] FLOP : 27.60 MB, ratio : 0.6761, Expected-ratio : 0.7000, Discrepancy : 0.056
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:41:30] [epoch=226/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.637 (1.637)  Prec@1 47.27 (47.27) Prec@5 92.19 (92.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:41:36] [epoch=226/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.002 (2.427)  Prec@1 45.24 (37.22) Prec@5 89.88 (80.88) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.22 Prec@5 80.88 Error@1 62.78 Error@5 19.12 Loss:2.427
***[2020-01-29 07:41:36]*** VALID [epoch=226/600] loss = 2.427257, accuracy@1 = 37.22, accuracy@5 = 80.88 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:41:36]*** start epoch=227/600 Time Left: [03:18:05], LR=[0.068649 ~ 0.068649], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=227, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.463820067310732, FLOP=40.81
[Search] : epoch=227/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:41:36] [epoch=227/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.881 (0.881)  Prec@1 71.88 (71.88) Prec@5 95.31 (95.31) Acls-loss 0.750 (0.750) FLOP-Loss 0.000 (0.000) Arch-Loss 0.750 (0.750)
**TRAIN** [2020-01-29 07:42:02] [epoch=227/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.908 (0.793)  Prec@1 72.02 (73.11) Prec@5 94.64 (97.86) Acls-loss 1.001 (0.846) FLOP-Loss 0.000 (0.110) Arch-Loss 1.001 (1.067)
 **TRAIN** Prec@1 73.11 Prec@5 97.86 Error@1 26.89 Error@5 2.14 Base-Loss:0.793, Arch-Loss=1.067
***[2020-01-29 07:42:02]*** TRAIN [epoch=227/600] base-loss = 0.793124, arch-loss = 1.066844, accuracy-1 = 73.11, accuracy-5 = 97.86
[epoch=227/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 11, 12, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.710656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.209 0.341  ||  0.2546 -0.5136 -0.0231  || discrepancy=0.11 || select=0/3
001/003-th : 0.380 0.148 0.472  ||  0.0815 -0.8632 0.2991  || discrepancy=0.09 || select=2/3
002/003-th : 0.042 0.161 0.797  ||  -1.5559 -0.2166 1.3850  || discrepancy=0.64 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.079 0.093 0.110 0.141 0.161 0.181 0.182  ||  -0.760 -0.385 -0.219 -0.054 0.196 0.328 0.446 0.450   || dis=0.00 || select=7/8
001/019-th : 0.132 0.129 0.127 0.130 0.125 0.123 0.118 0.117  ||  0.052 0.029 0.018 0.039 -0.002 -0.021 -0.057 -0.068   || dis=0.00 || select=0/8
002/019-th : 0.120 0.129 0.130 0.137 0.127 0.125 0.118 0.115  ||  -0.039 0.035 0.046 0.093 0.019 0.003 -0.052 -0.080    || dis=0.01 || select=3/8
003/019-th : 0.118 0.120 0.124 0.125 0.130 0.128 0.128 0.127  ||  -0.052 -0.042 -0.005 0.002 0.044 0.026 0.026 0.020    || dis=0.00 || select=4/8
004/019-th : 0.114 0.118 0.120 0.119 0.133 0.133 0.133 0.130  ||  -0.088 -0.058 -0.038 -0.044 0.061 0.066 0.066 0.040   || dis=0.00 || select=5/8
005/019-th : 0.111 0.120 0.127 0.124 0.128 0.125 0.133 0.131  ||  -0.119 -0.038 0.019 -0.003 0.031 0.005 0.068 0.051    || dis=0.00 || select=6/8
006/019-th : 0.118 0.115 0.117 0.123 0.128 0.131 0.134 0.135  ||  -0.057 -0.084 -0.061 -0.016 0.023 0.047 0.068 0.075   || dis=0.00 || select=7/8
007/019-th : 0.069 0.076 0.100 0.117 0.135 0.149 0.169 0.186  ||  -0.544 -0.435 -0.162 -0.013 0.133 0.231 0.356 0.452   || dis=0.02 || select=7/8
008/019-th : 0.049 0.056 0.087 0.121 0.131 0.172 0.191 0.191  ||  -0.828 -0.684 -0.248 0.079 0.161 0.432 0.536 0.535    || dis=0.00 || select=6/8
009/019-th : 0.101 0.099 0.105 0.123 0.121 0.138 0.150 0.164  ||  -0.198 -0.220 -0.156 -0.003 -0.021 0.114 0.195 0.286  || dis=0.01 || select=7/8
010/019-th : 0.102 0.103 0.114 0.131 0.125 0.135 0.147 0.142  ||  -0.192 -0.184 -0.085 0.055 0.009 0.084 0.171 0.133    || dis=0.01 || select=6/8
011/019-th : 0.096 0.096 0.109 0.115 0.119 0.139 0.157 0.169  ||  -0.242 -0.239 -0.118 -0.061 -0.027 0.126 0.246 0.320  || dis=0.01 || select=7/8
012/019-th : 0.112 0.113 0.118 0.122 0.129 0.130 0.133 0.143  ||  -0.108 -0.099 -0.059 -0.021 0.038 0.042 0.065 0.139   || dis=0.01 || select=7/8
013/019-th : 0.034 0.040 0.054 0.071 0.089 0.135 0.228 0.349  ||  -0.995 -0.854 -0.538 -0.266 -0.044 0.373 0.897 1.324  || dis=0.12 || select=7/8
014/019-th : 0.054 0.053 0.074 0.095 0.122 0.160 0.206 0.237  ||  -0.711 -0.716 -0.391 -0.145 0.106 0.384 0.634 0.772   || dis=0.03 || select=7/8
015/019-th : 0.030 0.035 0.045 0.065 0.092 0.122 0.240 0.370  ||  -1.069 -0.927 -0.655 -0.290 0.055 0.328 1.008 1.442   || dis=0.13 || select=7/8
016/019-th : 0.055 0.077 0.101 0.128 0.143 0.156 0.170 0.170  ||  -0.754 -0.414 -0.149 0.091 0.203 0.287 0.376 0.376    || dis=0.00 || select=6/8
017/019-th : 0.123 0.119 0.125 0.118 0.127 0.124 0.131 0.134  ||  -0.018 -0.053 -0.005 -0.063 0.016 -0.012 0.042 0.069  || dis=0.00 || select=7/8
018/019-th : 0.084 0.102 0.115 0.128 0.131 0.136 0.140 0.164  ||  -0.376 -0.186 -0.066 0.045 0.070 0.108 0.137 0.290    || dis=0.02 || select=7/8
[epoch=227/600] FLOP : 26.71 MB, ratio : 0.6545, Expected-ratio : 0.7000, Discrepancy : 0.055
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:42:02] [epoch=227/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.617 (1.617)  Prec@1 44.53 (44.53) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:42:08] [epoch=227/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.589 (1.991)  Prec@1 22.62 (39.58) Prec@5 86.31 (83.56) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.58 Prec@5 83.56 Error@1 60.42 Error@5 16.44 Loss:1.991
***[2020-01-29 07:42:08]*** VALID [epoch=227/600] loss = 1.990759, accuracy@1 = 39.58, accuracy@5 = 83.56 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:42:08]*** start epoch=228/600 Time Left: [03:17:34], LR=[0.068406 ~ 0.068406], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=228, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.451905154077462, FLOP=40.81
[Search] : epoch=228/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:42:09] [epoch=228/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.732 (0.732)  Prec@1 75.00 (75.00) Prec@5 97.27 (97.27) Acls-loss 0.847 (0.847) FLOP-Loss 0.000 (0.000) Arch-Loss 0.847 (0.847)
**TRAIN** [2020-01-29 07:42:34] [epoch=228/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.871 (0.803)  Prec@1 70.24 (72.68) Prec@5 97.62 (97.80) Acls-loss 0.847 (0.836) FLOP-Loss 0.000 (0.028) Arch-Loss 0.847 (0.891)
 **TRAIN** Prec@1 72.68 Prec@5 97.80 Error@1 27.32 Error@5 2.20 Base-Loss:0.803, Arch-Loss=0.891
***[2020-01-29 07:42:34]*** TRAIN [epoch=228/600] base-loss = 0.802807, arch-loss = 0.891499, accuracy-1 = 72.68, accuracy-5 = 97.80
[epoch=228/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 12, 14, 14, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.62304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.207 0.344  ||  0.2513 -0.5241 -0.0173  || discrepancy=0.11 || select=0/3
001/003-th : 0.379 0.148 0.473  ||  0.0800 -0.8586 0.3019  || discrepancy=0.09 || select=2/3
002/003-th : 0.041 0.159 0.800  ||  -1.5745 -0.2183 1.4002  || discrepancy=0.64 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.079 0.093 0.109 0.142 0.162 0.181 0.181  ||  -0.780 -0.377 -0.221 -0.056 0.207 0.337 0.450 0.449   || dis=0.00 || select=6/8
001/019-th : 0.130 0.128 0.128 0.130 0.126 0.122 0.118 0.117  ||  0.040 0.028 0.022 0.042 0.010 -0.023 -0.055 -0.062    || dis=0.00 || select=3/8
002/019-th : 0.120 0.129 0.130 0.135 0.126 0.126 0.119 0.116  ||  -0.040 0.032 0.039 0.082 0.012 0.009 -0.046 -0.076    || dis=0.01 || select=3/8
003/019-th : 0.118 0.119 0.122 0.123 0.128 0.130 0.129 0.129  ||  -0.053 -0.051 -0.020 -0.012 0.028 0.043 0.034 0.032   || dis=0.00 || select=5/8
004/019-th : 0.112 0.118 0.120 0.120 0.131 0.133 0.134 0.131  ||  -0.105 -0.053 -0.042 -0.036 0.047 0.065 0.075 0.049   || dis=0.00 || select=6/8
005/019-th : 0.110 0.118 0.129 0.125 0.128 0.126 0.132 0.131  ||  -0.122 -0.054 0.037 0.006 0.032 0.015 0.062 0.049     || dis=0.00 || select=6/8
006/019-th : 0.116 0.114 0.117 0.120 0.130 0.133 0.134 0.135  ||  -0.070 -0.091 -0.062 -0.037 0.041 0.065 0.072 0.081   || dis=0.00 || select=7/8
007/019-th : 0.068 0.077 0.098 0.115 0.136 0.150 0.168 0.188  ||  -0.544 -0.431 -0.184 -0.029 0.139 0.238 0.356 0.468   || dis=0.02 || select=7/8
008/019-th : 0.048 0.055 0.087 0.122 0.130 0.176 0.191 0.191  ||  -0.840 -0.698 -0.243 0.088 0.150 0.455 0.539 0.537    || dis=0.00 || select=6/8
009/019-th : 0.101 0.098 0.105 0.123 0.120 0.137 0.151 0.164  ||  -0.196 -0.226 -0.156 -0.003 -0.025 0.107 0.202 0.289  || dis=0.01 || select=7/8
010/019-th : 0.103 0.104 0.112 0.129 0.125 0.137 0.148 0.142  ||  -0.185 -0.180 -0.099 0.039 0.006 0.098 0.176 0.131    || dis=0.01 || select=6/8
011/019-th : 0.096 0.093 0.109 0.115 0.117 0.140 0.159 0.170  ||  -0.241 -0.271 -0.115 -0.060 -0.044 0.138 0.263 0.329  || dis=0.01 || select=7/8
012/019-th : 0.112 0.113 0.118 0.122 0.127 0.131 0.133 0.143  ||  -0.108 -0.101 -0.052 -0.022 0.022 0.051 0.068 0.136   || dis=0.01 || select=7/8
013/019-th : 0.034 0.040 0.054 0.070 0.087 0.135 0.227 0.353  ||  -0.997 -0.842 -0.530 -0.277 -0.067 0.377 0.895 1.340  || dis=0.13 || select=7/8
014/019-th : 0.053 0.053 0.073 0.095 0.123 0.162 0.205 0.237  ||  -0.722 -0.723 -0.403 -0.133 0.116 0.393 0.629 0.776   || dis=0.03 || select=7/8
015/019-th : 0.030 0.035 0.045 0.063 0.093 0.122 0.237 0.374  ||  -1.071 -0.922 -0.651 -0.319 0.060 0.338 1.000 1.457   || dis=0.14 || select=7/8
016/019-th : 0.055 0.077 0.100 0.125 0.142 0.158 0.172 0.172  ||  -0.762 -0.416 -0.152 0.069 0.193 0.302 0.387 0.385    || dis=0.00 || select=6/8
017/019-th : 0.123 0.118 0.124 0.118 0.128 0.124 0.131 0.135  ||  -0.019 -0.059 -0.010 -0.057 0.019 -0.008 0.043 0.072  || dis=0.00 || select=7/8
018/019-th : 0.084 0.102 0.115 0.125 0.130 0.139 0.141 0.165  ||  -0.379 -0.186 -0.067 0.021 0.060 0.125 0.141 0.296    || dis=0.02 || select=7/8
[epoch=228/600] FLOP : 27.62 MB, ratio : 0.6768, Expected-ratio : 0.7000, Discrepancy : 0.056
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:42:35] [epoch=228/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.085 (2.085)  Prec@1 28.91 (28.91) Prec@5 74.22 (74.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:42:41] [epoch=228/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.642 (2.342)  Prec@1 44.64 (36.19) Prec@5 91.07 (82.29) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.19 Prec@5 82.29 Error@1 63.81 Error@5 17.71 Loss:2.342
***[2020-01-29 07:42:41]*** VALID [epoch=228/600] loss = 2.342131, accuracy@1 = 36.19, accuracy@5 = 82.29 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:42:41]*** start epoch=229/600 Time Left: [03:17:04], LR=[0.068163 ~ 0.068163], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=229, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4399655146587977, FLOP=40.81
[Search] : epoch=229/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:42:42] [epoch=229/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.152 (1.152)  Prec@1 60.16 (60.16) Prec@5 93.75 (93.75) Acls-loss 0.835 (0.835) FLOP-Loss 0.000 (0.000) Arch-Loss 0.835 (0.835)
**TRAIN** [2020-01-29 07:43:06] [epoch=229/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.810 (0.813)  Prec@1 73.81 (72.43) Prec@5 98.21 (97.79) Acls-loss 0.866 (0.836) FLOP-Loss 0.000 (0.000) Arch-Loss 0.866 (0.836)
 **TRAIN** Prec@1 72.43 Prec@5 97.79 Error@1 27.57 Error@5 2.21 Base-Loss:0.813, Arch-Loss=0.836
***[2020-01-29 07:43:06]*** TRAIN [epoch=229/600] base-loss = 0.812910, arch-loss = 0.836124, accuracy-1 = 72.43, accuracy-5 = 97.79
[epoch=229/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 12, 14, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.507776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.206 0.347  ||  0.2442 -0.5303 -0.0077  || discrepancy=0.10 || select=0/3
001/003-th : 0.376 0.147 0.477  ||  0.0737 -0.8633 0.3103  || discrepancy=0.10 || select=2/3
002/003-th : 0.039 0.155 0.806  ||  -1.6020 -0.2239 1.4233  || discrepancy=0.65 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.080 0.093 0.110 0.141 0.161 0.183 0.180  ||  -0.790 -0.368 -0.213 -0.052 0.199 0.334 0.459 0.442   || dis=0.00 || select=6/8
001/019-th : 0.128 0.128 0.127 0.128 0.126 0.124 0.120 0.119  ||  0.023 0.024 0.015 0.028 0.011 -0.004 -0.040 -0.052    || dis=0.00 || select=3/8
002/019-th : 0.120 0.128 0.128 0.135 0.125 0.128 0.120 0.117  ||  -0.041 0.024 0.024 0.075 0.003 0.021 -0.041 -0.067    || dis=0.01 || select=3/8
003/019-th : 0.116 0.117 0.122 0.124 0.128 0.131 0.130 0.130  ||  -0.068 -0.061 -0.021 -0.003 0.027 0.052 0.041 0.042   || dis=0.00 || select=5/8
004/019-th : 0.112 0.118 0.118 0.119 0.131 0.132 0.135 0.135  ||  -0.108 -0.058 -0.055 -0.051 0.045 0.055 0.077 0.074   || dis=0.00 || select=6/8
005/019-th : 0.110 0.117 0.127 0.125 0.129 0.128 0.133 0.131  ||  -0.126 -0.060 0.019 0.005 0.033 0.030 0.066 0.055     || dis=0.00 || select=6/8
006/019-th : 0.115 0.113 0.116 0.119 0.132 0.133 0.135 0.137  ||  -0.079 -0.099 -0.069 -0.047 0.059 0.063 0.079 0.091   || dis=0.00 || select=7/8
007/019-th : 0.067 0.076 0.098 0.113 0.136 0.150 0.171 0.189  ||  -0.562 -0.437 -0.180 -0.043 0.148 0.246 0.372 0.472   || dis=0.02 || select=7/8
008/019-th : 0.047 0.056 0.087 0.121 0.129 0.176 0.191 0.192  ||  -0.855 -0.688 -0.245 0.083 0.146 0.459 0.540 0.545    || dis=0.00 || select=7/8
009/019-th : 0.100 0.098 0.105 0.121 0.119 0.138 0.151 0.167  ||  -0.204 -0.230 -0.160 -0.017 -0.033 0.114 0.204 0.306  || dis=0.02 || select=7/8
010/019-th : 0.102 0.102 0.112 0.129 0.125 0.140 0.148 0.143  ||  -0.193 -0.198 -0.106 0.037 0.011 0.120 0.176 0.140    || dis=0.01 || select=6/8
011/019-th : 0.096 0.091 0.107 0.116 0.119 0.141 0.160 0.171  ||  -0.244 -0.298 -0.127 -0.050 -0.024 0.141 0.269 0.336  || dis=0.01 || select=7/8
012/019-th : 0.111 0.112 0.119 0.120 0.128 0.130 0.135 0.144  ||  -0.114 -0.110 -0.048 -0.034 0.029 0.044 0.076 0.147   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.053 0.069 0.085 0.132 0.227 0.361  ||  -0.995 -0.852 -0.548 -0.287 -0.071 0.367 0.909 1.370  || dis=0.13 || select=7/8
014/019-th : 0.052 0.053 0.072 0.095 0.121 0.161 0.206 0.239  ||  -0.731 -0.716 -0.416 -0.136 0.106 0.392 0.638 0.788   || dis=0.03 || select=7/8
015/019-th : 0.029 0.034 0.046 0.062 0.091 0.121 0.238 0.380  ||  -1.086 -0.928 -0.638 -0.339 0.051 0.334 1.013 1.482   || dis=0.14 || select=7/8
016/019-th : 0.053 0.076 0.099 0.125 0.139 0.161 0.172 0.174  ||  -0.780 -0.422 -0.159 0.070 0.179 0.323 0.389 0.400    || dis=0.00 || select=7/8
017/019-th : 0.122 0.117 0.122 0.117 0.126 0.127 0.133 0.136  ||  -0.027 -0.071 -0.024 -0.066 0.006 0.010 0.063 0.081   || dis=0.00 || select=7/8
018/019-th : 0.084 0.102 0.113 0.127 0.129 0.138 0.143 0.165  ||  -0.379 -0.188 -0.082 0.033 0.054 0.120 0.152 0.296    || dis=0.02 || select=7/8
[epoch=229/600] FLOP : 28.51 MB, ratio : 0.6985, Expected-ratio : 0.7000, Discrepancy : 0.057
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:43:07] [epoch=229/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.948 (3.948)  Prec@1 40.23 (40.23) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:43:13] [epoch=229/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.857 (2.392)  Prec@1 45.83 (37.41) Prec@5 84.52 (80.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.41 Prec@5 80.72 Error@1 62.59 Error@5 19.28 Loss:2.392
***[2020-01-29 07:43:13]*** VALID [epoch=229/600] loss = 2.392155, accuracy@1 = 37.41, accuracy@5 = 80.72 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:43:13]*** start epoch=230/600 Time Left: [03:16:32], LR=[0.067918 ~ 0.067918], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=230, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4280014763859854, FLOP=40.81
[Search] : epoch=230/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:43:13] [epoch=230/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.768 (0.768)  Prec@1 73.83 (73.83) Prec@5 98.83 (98.83) Acls-loss 0.815 (0.815) FLOP-Loss 0.000 (0.000) Arch-Loss 0.815 (0.815)
**TRAIN** [2020-01-29 07:43:38] [epoch=230/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.956 (0.790)  Prec@1 65.48 (73.09) Prec@5 95.83 (97.92) Acls-loss 0.688 (0.839) FLOP-Loss 0.000 (0.000) Arch-Loss 0.688 (0.839)
 **TRAIN** Prec@1 73.09 Prec@5 97.92 Error@1 26.91 Error@5 2.08 Base-Loss:0.790, Arch-Loss=0.839
***[2020-01-29 07:43:38]*** TRAIN [epoch=230/600] base-loss = 0.789906, arch-loss = 0.839116, accuracy-1 = 73.09, accuracy-5 = 97.92
[epoch=230/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 16, 16, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.507776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.204 0.353  ||  0.2342 -0.5427 0.0056  || discrepancy=0.09 || select=0/3
001/003-th : 0.373 0.146 0.481  ||  0.0657 -0.8686 0.3205  || discrepancy=0.11 || select=2/3
002/003-th : 0.038 0.152 0.810  ||  -1.6161 -0.2329 1.4393  || discrepancy=0.66 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.079 0.093 0.109 0.142 0.165 0.181 0.179  ||  -0.796 -0.380 -0.215 -0.052 0.208 0.357 0.455 0.442   || dis=0.00 || select=6/8
001/019-th : 0.127 0.126 0.126 0.129 0.126 0.126 0.121 0.120  ||  0.017 0.008 0.008 0.029 0.010 0.007 -0.031 -0.043     || dis=0.00 || select=3/8
002/019-th : 0.119 0.127 0.128 0.135 0.126 0.128 0.121 0.117  ||  -0.047 0.016 0.023 0.077 0.006 0.022 -0.034 -0.061    || dis=0.01 || select=3/8
003/019-th : 0.115 0.118 0.121 0.125 0.129 0.130 0.131 0.132  ||  -0.083 -0.057 -0.029 0.000 0.034 0.041 0.045 0.056    || dis=0.00 || select=7/8
004/019-th : 0.112 0.117 0.119 0.119 0.131 0.132 0.135 0.136  ||  -0.114 -0.068 -0.050 -0.053 0.045 0.051 0.078 0.087   || dis=0.00 || select=7/8
005/019-th : 0.110 0.116 0.126 0.125 0.128 0.128 0.135 0.132  ||  -0.127 -0.070 0.016 0.002 0.031 0.031 0.078 0.058     || dis=0.00 || select=6/8
006/019-th : 0.115 0.113 0.117 0.119 0.129 0.132 0.137 0.139  ||  -0.085 -0.104 -0.066 -0.049 0.033 0.056 0.092 0.106   || dis=0.00 || select=7/8
007/019-th : 0.066 0.077 0.097 0.114 0.135 0.147 0.173 0.192  ||  -0.576 -0.428 -0.197 -0.032 0.139 0.222 0.384 0.492   || dis=0.02 || select=7/8
008/019-th : 0.047 0.056 0.085 0.120 0.130 0.177 0.191 0.193  ||  -0.860 -0.689 -0.265 0.079 0.160 0.466 0.543 0.553    || dis=0.00 || select=7/8
009/019-th : 0.099 0.096 0.103 0.121 0.119 0.139 0.155 0.168  ||  -0.219 -0.242 -0.172 -0.017 -0.034 0.121 0.229 0.315  || dis=0.01 || select=7/8
010/019-th : 0.102 0.102 0.111 0.128 0.127 0.139 0.150 0.142  ||  -0.197 -0.197 -0.107 0.031 0.023 0.116 0.188 0.135    || dis=0.01 || select=6/8
011/019-th : 0.096 0.089 0.108 0.115 0.119 0.141 0.161 0.172  ||  -0.239 -0.314 -0.125 -0.057 -0.028 0.147 0.276 0.342  || dis=0.01 || select=7/8
012/019-th : 0.110 0.111 0.118 0.120 0.130 0.130 0.136 0.146  ||  -0.129 -0.114 -0.055 -0.038 0.040 0.041 0.086 0.157   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.052 0.068 0.085 0.130 0.229 0.364  ||  -0.982 -0.860 -0.562 -0.293 -0.071 0.356 0.920 1.384  || dis=0.13 || select=7/8
014/019-th : 0.052 0.053 0.072 0.092 0.121 0.162 0.206 0.242  ||  -0.744 -0.713 -0.410 -0.161 0.108 0.398 0.639 0.804   || dis=0.04 || select=7/8
015/019-th : 0.029 0.034 0.045 0.061 0.092 0.122 0.235 0.382  ||  -1.085 -0.945 -0.643 -0.341 0.063 0.345 1.002 1.489   || dis=0.15 || select=7/8
016/019-th : 0.053 0.076 0.099 0.124 0.139 0.161 0.175 0.175  ||  -0.792 -0.430 -0.166 0.062 0.175 0.323 0.408 0.410    || dis=0.00 || select=7/8
017/019-th : 0.121 0.115 0.122 0.118 0.126 0.127 0.134 0.137  ||  -0.033 -0.084 -0.029 -0.061 0.008 0.011 0.069 0.092   || dis=0.00 || select=7/8
018/019-th : 0.085 0.102 0.112 0.126 0.128 0.139 0.145 0.164  ||  -0.369 -0.188 -0.092 0.027 0.045 0.125 0.167 0.290    || dis=0.02 || select=7/8
[epoch=230/600] FLOP : 28.51 MB, ratio : 0.6985, Expected-ratio : 0.7000, Discrepancy : 0.058
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:43:38] [epoch=230/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.748 (1.748)  Prec@1 57.03 (57.03) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:43:44] [epoch=230/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.675 (2.256)  Prec@1 37.50 (37.48) Prec@5 81.55 (81.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.48 Prec@5 81.40 Error@1 62.52 Error@5 18.60 Loss:2.256
***[2020-01-29 07:43:45]*** VALID [epoch=230/600] loss = 2.256233, accuracy@1 = 37.48, accuracy@5 = 81.40 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:43:45]*** start epoch=231/600 Time Left: [03:16:00], LR=[0.067674 ~ 0.067674], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=231, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4160133672591804, FLOP=40.81
[Search] : epoch=231/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:43:45] [epoch=231/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.623 (0.623)  Prec@1 79.30 (79.30) Prec@5 98.83 (98.83) Acls-loss 0.658 (0.658) FLOP-Loss 0.000 (0.000) Arch-Loss 0.658 (0.658)
**TRAIN** [2020-01-29 07:44:09] [epoch=231/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.707 (0.807)  Prec@1 76.79 (72.45) Prec@5 100.00 (97.94) Acls-loss 0.953 (0.854) FLOP-Loss 0.000 (0.056) Arch-Loss 0.953 (0.965)
 **TRAIN** Prec@1 72.45 Prec@5 97.94 Error@1 27.55 Error@5 2.06 Base-Loss:0.807, Arch-Loss=0.965
***[2020-01-29 07:44:10]*** TRAIN [epoch=231/600] base-loss = 0.807083, arch-loss = 0.965231, accuracy-1 = 72.45, accuracy-5 = 97.94
[epoch=231/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 16, 14, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.458624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.202 0.355  ||  0.2335 -0.5552 0.0095  || discrepancy=0.09 || select=0/3
001/003-th : 0.372 0.147 0.481  ||  0.0650 -0.8627 0.3226  || discrepancy=0.11 || select=2/3
002/003-th : 0.038 0.151 0.811  ||  -1.6231 -0.2335 1.4469  || discrepancy=0.66 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.080 0.093 0.111 0.141 0.162 0.180 0.179  ||  -0.780 -0.366 -0.218 -0.043 0.198 0.338 0.442 0.439   || dis=0.00 || select=6/8
001/019-th : 0.127 0.125 0.125 0.130 0.126 0.126 0.121 0.119  ||  0.019 0.005 0.000 0.045 0.009 0.010 -0.027 -0.048     || dis=0.00 || select=3/8
002/019-th : 0.119 0.127 0.128 0.135 0.125 0.128 0.120 0.117  ||  -0.045 0.016 0.028 0.080 0.004 0.025 -0.041 -0.064    || dis=0.01 || select=3/8
003/019-th : 0.116 0.118 0.122 0.124 0.127 0.130 0.130 0.132  ||  -0.075 -0.055 -0.026 -0.007 0.020 0.043 0.039 0.057   || dis=0.00 || select=7/8
004/019-th : 0.112 0.117 0.121 0.119 0.132 0.129 0.136 0.135  ||  -0.113 -0.066 -0.031 -0.047 0.053 0.029 0.082 0.079   || dis=0.00 || select=6/8
005/019-th : 0.110 0.117 0.126 0.126 0.130 0.127 0.134 0.131  ||  -0.128 -0.065 0.012 0.011 0.042 0.020 0.075 0.053     || dis=0.00 || select=6/8
006/019-th : 0.115 0.112 0.119 0.117 0.130 0.133 0.135 0.139  ||  -0.084 -0.105 -0.051 -0.063 0.042 0.064 0.079 0.106   || dis=0.00 || select=7/8
007/019-th : 0.066 0.076 0.097 0.117 0.134 0.145 0.174 0.192  ||  -0.580 -0.440 -0.189 -0.007 0.128 0.212 0.389 0.491   || dis=0.02 || select=7/8
008/019-th : 0.048 0.056 0.083 0.120 0.131 0.178 0.191 0.194  ||  -0.848 -0.688 -0.285 0.081 0.162 0.471 0.540 0.555    || dis=0.00 || select=7/8
009/019-th : 0.100 0.098 0.105 0.121 0.117 0.138 0.154 0.169  ||  -0.213 -0.230 -0.161 -0.021 -0.051 0.116 0.222 0.314  || dis=0.02 || select=7/8
010/019-th : 0.101 0.102 0.111 0.124 0.127 0.141 0.151 0.143  ||  -0.207 -0.194 -0.108 0.003 0.025 0.127 0.200 0.142    || dis=0.01 || select=6/8
011/019-th : 0.095 0.088 0.107 0.115 0.120 0.142 0.161 0.172  ||  -0.245 -0.327 -0.130 -0.055 -0.013 0.151 0.277 0.347  || dis=0.01 || select=7/8
012/019-th : 0.110 0.112 0.118 0.119 0.129 0.128 0.136 0.148  ||  -0.128 -0.105 -0.061 -0.045 0.031 0.027 0.085 0.169   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.052 0.068 0.084 0.131 0.226 0.366  ||  -0.974 -0.851 -0.560 -0.298 -0.079 0.364 0.908 1.389  || dis=0.14 || select=7/8
014/019-th : 0.051 0.052 0.073 0.092 0.124 0.163 0.204 0.242  ||  -0.752 -0.732 -0.401 -0.164 0.132 0.405 0.631 0.804   || dis=0.04 || select=7/8
015/019-th : 0.029 0.034 0.044 0.062 0.091 0.122 0.236 0.383  ||  -1.079 -0.934 -0.672 -0.330 0.053 0.349 1.008 1.495   || dis=0.15 || select=7/8
016/019-th : 0.054 0.074 0.098 0.125 0.140 0.161 0.175 0.173  ||  -0.774 -0.445 -0.172 0.073 0.184 0.323 0.409 0.400    || dis=0.00 || select=6/8
017/019-th : 0.122 0.114 0.121 0.118 0.127 0.126 0.134 0.137  ||  -0.022 -0.093 -0.032 -0.059 0.012 0.003 0.071 0.091   || dis=0.00 || select=7/8
018/019-th : 0.086 0.101 0.113 0.124 0.128 0.141 0.142 0.166  ||  -0.353 -0.196 -0.083 0.007 0.042 0.135 0.146 0.299    || dis=0.02 || select=7/8
[epoch=231/600] FLOP : 28.46 MB, ratio : 0.6973, Expected-ratio : 0.7000, Discrepancy : 0.059
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:44:10] [epoch=231/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.454 (2.454)  Prec@1 36.72 (36.72) Prec@5 80.86 (80.86) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:44:16] [epoch=231/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.310 (2.223)  Prec@1 30.36 (39.08) Prec@5 73.21 (82.97) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.08 Prec@5 82.97 Error@1 60.92 Error@5 17.03 Loss:2.223
***[2020-01-29 07:44:16]*** VALID [epoch=231/600] loss = 2.223267, accuracy@1 = 39.08, accuracy@5 = 82.97 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:44:16]*** start epoch=232/600 Time Left: [03:15:27], LR=[0.067429 ~ 0.067429], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=232, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.4040015159384476, FLOP=40.81
[Search] : epoch=232/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:44:17] [epoch=232/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.903 (0.903)  Prec@1 70.31 (70.31) Prec@5 98.05 (98.05) Acls-loss 0.844 (0.844) FLOP-Loss 0.000 (0.000) Arch-Loss 0.844 (0.844)
**TRAIN** [2020-01-29 07:44:41] [epoch=232/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.721 (0.803)  Prec@1 71.43 (72.53) Prec@5 98.81 (97.94) Acls-loss 0.798 (0.847) FLOP-Loss 0.000 (0.056) Arch-Loss 0.798 (0.958)
 **TRAIN** Prec@1 72.53 Prec@5 97.94 Error@1 27.47 Error@5 2.06 Base-Loss:0.803, Arch-Loss=0.958
***[2020-01-29 07:44:41]*** TRAIN [epoch=232/600] base-loss = 0.803215, arch-loss = 0.958193, accuracy-1 = 72.53, accuracy-5 = 97.94
[epoch=232/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 16, 14, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.507776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.201 0.356  ||  0.2334 -0.5608 0.0119  || discrepancy=0.09 || select=0/3
001/003-th : 0.372 0.147 0.481  ||  0.0667 -0.8636 0.3231  || discrepancy=0.11 || select=2/3
002/003-th : 0.037 0.150 0.813  ||  -1.6380 -0.2327 1.4592  || discrepancy=0.66 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.080 0.093 0.111 0.145 0.161 0.180 0.177  ||  -0.776 -0.369 -0.220 -0.045 0.226 0.333 0.443 0.426   || dis=0.00 || select=6/8
001/019-th : 0.128 0.125 0.125 0.130 0.126 0.125 0.121 0.119  ||  0.023 0.002 0.003 0.044 0.006 0.005 -0.029 -0.047     || dis=0.00 || select=3/8
002/019-th : 0.119 0.127 0.128 0.135 0.125 0.128 0.121 0.117  ||  -0.047 0.014 0.026 0.082 0.005 0.023 -0.035 -0.063    || dis=0.01 || select=3/8
003/019-th : 0.116 0.116 0.122 0.125 0.128 0.130 0.130 0.133  ||  -0.070 -0.075 -0.022 -0.003 0.023 0.044 0.038 0.062   || dis=0.00 || select=7/8
004/019-th : 0.110 0.117 0.121 0.121 0.131 0.128 0.136 0.135  ||  -0.123 -0.068 -0.031 -0.028 0.050 0.026 0.087 0.080   || dis=0.00 || select=6/8
005/019-th : 0.110 0.117 0.126 0.127 0.129 0.128 0.132 0.131  ||  -0.124 -0.066 0.016 0.023 0.035 0.028 0.061 0.050     || dis=0.00 || select=6/8
006/019-th : 0.115 0.113 0.116 0.119 0.130 0.133 0.135 0.140  ||  -0.084 -0.099 -0.075 -0.049 0.038 0.059 0.080 0.112   || dis=0.01 || select=7/8
007/019-th : 0.062 0.075 0.097 0.118 0.133 0.149 0.174 0.193  ||  -0.632 -0.444 -0.186 0.010 0.129 0.243 0.398 0.500    || dis=0.02 || select=7/8
008/019-th : 0.047 0.056 0.084 0.120 0.131 0.177 0.191 0.194  ||  -0.867 -0.678 -0.277 0.079 0.164 0.466 0.541 0.558    || dis=0.00 || select=7/8
009/019-th : 0.096 0.101 0.104 0.120 0.117 0.140 0.154 0.168  ||  -0.247 -0.198 -0.166 -0.020 -0.045 0.129 0.223 0.312  || dis=0.01 || select=7/8
010/019-th : 0.102 0.102 0.112 0.124 0.127 0.141 0.151 0.141  ||  -0.198 -0.194 -0.102 0.001 0.026 0.129 0.200 0.130    || dis=0.01 || select=6/8
011/019-th : 0.096 0.088 0.106 0.115 0.122 0.142 0.159 0.172  ||  -0.242 -0.322 -0.136 -0.055 -0.002 0.151 0.269 0.346  || dis=0.01 || select=7/8
012/019-th : 0.111 0.112 0.116 0.120 0.131 0.127 0.136 0.147  ||  -0.121 -0.107 -0.074 -0.038 0.046 0.021 0.087 0.165   || dis=0.01 || select=7/8
013/019-th : 0.034 0.039 0.052 0.067 0.084 0.130 0.227 0.367  ||  -0.977 -0.844 -0.556 -0.306 -0.081 0.355 0.914 1.394  || dis=0.14 || select=7/8
014/019-th : 0.051 0.052 0.072 0.093 0.123 0.165 0.201 0.242  ||  -0.756 -0.726 -0.402 -0.158 0.126 0.423 0.619 0.802   || dis=0.04 || select=7/8
015/019-th : 0.030 0.033 0.044 0.062 0.091 0.123 0.237 0.382  ||  -1.065 -0.964 -0.674 -0.329 0.056 0.359 1.014 1.492   || dis=0.15 || select=7/8
016/019-th : 0.054 0.075 0.099 0.125 0.137 0.162 0.174 0.174  ||  -0.768 -0.440 -0.166 0.071 0.165 0.333 0.400 0.401    || dis=0.00 || select=7/8
017/019-th : 0.123 0.115 0.122 0.119 0.125 0.125 0.134 0.138  ||  -0.023 -0.088 -0.027 -0.050 -0.005 -0.006 0.068 0.096  || dis=0.00 || select=7/8
018/019-th : 0.086 0.101 0.113 0.125 0.128 0.140 0.140 0.167  ||  -0.351 -0.199 -0.087 0.019 0.041 0.134 0.130 0.308    || dis=0.03 || select=7/8
[epoch=232/600] FLOP : 28.51 MB, ratio : 0.6985, Expected-ratio : 0.7000, Discrepancy : 0.059
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:44:42] [epoch=232/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.918 (3.918)  Prec@1 10.55 (10.55) Prec@5 57.03 (57.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:44:48] [epoch=232/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.601 (2.108)  Prec@1 15.48 (36.17) Prec@5 67.86 (80.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.17 Prec@5 80.70 Error@1 63.83 Error@5 19.30 Loss:2.108
***[2020-01-29 07:44:48]*** VALID [epoch=232/600] loss = 2.107517, accuracy@1 = 36.17, accuracy@5 = 80.70 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:44:48]*** start epoch=233/600 Time Left: [03:14:55], LR=[0.067183 ~ 0.067183], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=233, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.39196625173476, FLOP=40.81
[Search] : epoch=233/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:44:49] [epoch=233/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.882 (0.882)  Prec@1 68.75 (68.75) Prec@5 97.66 (97.66) Acls-loss 0.815 (0.815) FLOP-Loss 0.000 (0.000) Arch-Loss 0.815 (0.815)
**TRAIN** [2020-01-29 07:45:13] [epoch=233/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.701 (0.822)  Prec@1 77.38 (72.22) Prec@5 99.40 (97.73) Acls-loss 0.769 (0.826) FLOP-Loss 0.000 (0.000) Arch-Loss 0.769 (0.826)
 **TRAIN** Prec@1 72.22 Prec@5 97.73 Error@1 27.78 Error@5 2.27 Base-Loss:0.822, Arch-Loss=0.826
***[2020-01-29 07:45:13]*** TRAIN [epoch=233/600] base-loss = 0.821731, arch-loss = 0.825974, accuracy-1 = 72.22, accuracy-5 = 97.73
[epoch=233/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 16, 16, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.507776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.202 0.357  ||  0.2281 -0.5514 0.0182  || discrepancy=0.08 || select=0/3
001/003-th : 0.369 0.145 0.486  ||  0.0591 -0.8724 0.3336  || discrepancy=0.12 || select=2/3
002/003-th : 0.036 0.146 0.818  ||  -1.6509 -0.2470 1.4769  || discrepancy=0.67 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.080 0.091 0.110 0.144 0.162 0.182 0.178  ||  -0.789 -0.360 -0.238 -0.049 0.223 0.337 0.456 0.435   || dis=0.00 || select=6/8
001/019-th : 0.125 0.125 0.125 0.132 0.126 0.126 0.121 0.119  ||  0.005 0.004 0.001 0.059 0.014 0.013 -0.025 -0.043     || dis=0.01 || select=3/8
002/019-th : 0.118 0.125 0.127 0.134 0.126 0.129 0.122 0.119  ||  -0.060 0.004 0.018 0.071 0.008 0.037 -0.024 -0.051    || dis=0.01 || select=3/8
003/019-th : 0.116 0.116 0.123 0.123 0.126 0.131 0.131 0.134  ||  -0.072 -0.074 -0.020 -0.013 0.007 0.044 0.044 0.070   || dis=0.00 || select=7/8
004/019-th : 0.110 0.116 0.122 0.120 0.129 0.130 0.136 0.136  ||  -0.126 -0.070 -0.025 -0.037 0.034 0.042 0.085 0.086   || dis=0.00 || select=7/8
005/019-th : 0.109 0.118 0.124 0.128 0.129 0.126 0.133 0.132  ||  -0.130 -0.053 -0.004 0.026 0.034 0.015 0.063 0.061    || dis=0.00 || select=6/8
006/019-th : 0.114 0.112 0.115 0.120 0.129 0.136 0.134 0.140  ||  -0.086 -0.111 -0.079 -0.042 0.033 0.086 0.070 0.117   || dis=0.00 || select=7/8
007/019-th : 0.062 0.076 0.097 0.116 0.132 0.149 0.176 0.193  ||  -0.640 -0.431 -0.188 -0.002 0.125 0.242 0.409 0.502   || dis=0.02 || select=7/8
008/019-th : 0.047 0.055 0.083 0.118 0.130 0.180 0.190 0.197  ||  -0.860 -0.698 -0.286 0.064 0.162 0.485 0.540 0.577    || dis=0.01 || select=7/8
009/019-th : 0.094 0.101 0.103 0.121 0.118 0.141 0.153 0.169  ||  -0.263 -0.197 -0.180 -0.015 -0.037 0.136 0.223 0.323  || dis=0.02 || select=7/8
010/019-th : 0.101 0.101 0.112 0.124 0.129 0.140 0.152 0.141  ||  -0.202 -0.201 -0.101 -0.002 0.043 0.123 0.208 0.128   || dis=0.01 || select=6/8
011/019-th : 0.096 0.089 0.107 0.114 0.119 0.139 0.162 0.174  ||  -0.239 -0.319 -0.132 -0.068 -0.024 0.132 0.286 0.358  || dis=0.01 || select=7/8
012/019-th : 0.109 0.110 0.115 0.122 0.130 0.129 0.137 0.148  ||  -0.136 -0.124 -0.078 -0.022 0.042 0.035 0.091 0.175   || dis=0.01 || select=7/8
013/019-th : 0.034 0.038 0.051 0.065 0.083 0.129 0.232 0.368  ||  -0.967 -0.854 -0.573 -0.323 -0.085 0.356 0.943 1.404  || dis=0.14 || select=7/8
014/019-th : 0.050 0.053 0.072 0.092 0.120 0.162 0.205 0.246  ||  -0.775 -0.714 -0.407 -0.162 0.108 0.406 0.640 0.823   || dis=0.04 || select=7/8
015/019-th : 0.029 0.033 0.043 0.062 0.090 0.123 0.234 0.386  ||  -1.068 -0.966 -0.678 -0.324 0.049 0.361 1.007 1.508   || dis=0.15 || select=7/8
016/019-th : 0.054 0.074 0.098 0.122 0.137 0.165 0.176 0.176  ||  -0.775 -0.456 -0.170 0.046 0.164 0.350 0.414 0.414    || dis=0.00 || select=7/8
017/019-th : 0.121 0.115 0.122 0.118 0.124 0.126 0.135 0.139  ||  -0.037 -0.089 -0.027 -0.057 -0.013 0.003 0.078 0.106  || dis=0.00 || select=7/8
018/019-th : 0.086 0.100 0.112 0.125 0.127 0.142 0.141 0.168  ||  -0.361 -0.209 -0.093 0.016 0.034 0.148 0.138 0.317    || dis=0.03 || select=7/8
[epoch=233/600] FLOP : 28.51 MB, ratio : 0.6985, Expected-ratio : 0.7000, Discrepancy : 0.060
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:45:14] [epoch=233/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.739 (1.739)  Prec@1 42.97 (42.97) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:45:20] [epoch=233/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.827 (2.477)  Prec@1 44.05 (35.96) Prec@5 85.12 (80.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.96 Prec@5 80.13 Error@1 64.04 Error@5 19.87 Loss:2.477
***[2020-01-29 07:45:20]*** VALID [epoch=233/600] loss = 2.477433, accuracy@1 = 35.96, accuracy@5 = 80.13 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:45:20]*** start epoch=234/600 Time Left: [03:14:24], LR=[0.066937 ~ 0.066937], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=234, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.3799079046009646, FLOP=40.81
[Search] : epoch=234/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:45:21] [epoch=234/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.757 (0.757)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83) Acls-loss 0.763 (0.763) FLOP-Loss 0.000 (0.000) Arch-Loss 0.763 (0.763)
**TRAIN** [2020-01-29 07:45:45] [epoch=234/600][097/098] Time 0.31 (0.26) Data 0.00 (0.00) Base-Loss 0.731 (0.804)  Prec@1 73.81 (72.66) Prec@5 97.62 (97.77) Acls-loss 0.780 (0.834) FLOP-Loss 0.000 (0.000) Arch-Loss 0.780 (0.834)
 **TRAIN** Prec@1 72.66 Prec@5 97.77 Error@1 27.34 Error@5 2.23 Base-Loss:0.804, Arch-Loss=0.834
***[2020-01-29 07:45:45]*** TRAIN [epoch=234/600] base-loss = 0.803702, arch-loss = 0.834334, accuracy-1 = 72.66, accuracy-5 = 97.77
[epoch=234/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 14, 9, 9, 16, 16, 14, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.507776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.203 0.361  ||  0.2177 -0.5454 0.0300  || discrepancy=0.08 || select=0/3
001/003-th : 0.365 0.148 0.488  ||  0.0505 -0.8536 0.3416  || discrepancy=0.12 || select=2/3
002/003-th : 0.035 0.141 0.824  ||  -1.6717 -0.2626 1.5009  || discrepancy=0.68 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.081 0.092 0.109 0.143 0.160 0.182 0.180  ||  -0.795 -0.355 -0.227 -0.055 0.211 0.329 0.456 0.446   || dis=0.00 || select=6/8
001/019-th : 0.124 0.125 0.123 0.130 0.127 0.127 0.122 0.120  ||  -0.002 0.003 -0.010 0.046 0.020 0.018 -0.019 -0.036   || dis=0.00 || select=3/8
002/019-th : 0.117 0.125 0.127 0.132 0.125 0.132 0.123 0.120  ||  -0.068 -0.004 0.019 0.053 -0.002 0.051 -0.015 -0.041  || dis=0.00 || select=3/8
003/019-th : 0.117 0.115 0.124 0.123 0.125 0.131 0.131 0.135  ||  -0.070 -0.081 -0.013 -0.018 -0.002 0.044 0.045 0.076  || dis=0.00 || select=7/8
004/019-th : 0.110 0.116 0.120 0.119 0.129 0.130 0.137 0.138  ||  -0.126 -0.079 -0.041 -0.048 0.035 0.038 0.094 0.102   || dis=0.00 || select=7/8
005/019-th : 0.108 0.118 0.124 0.127 0.126 0.128 0.135 0.134  ||  -0.143 -0.057 -0.001 0.023 0.009 0.029 0.077 0.071    || dis=0.00 || select=6/8
006/019-th : 0.114 0.111 0.116 0.119 0.130 0.135 0.134 0.141  ||  -0.094 -0.116 -0.072 -0.046 0.042 0.076 0.075 0.123   || dis=0.01 || select=7/8
007/019-th : 0.061 0.076 0.095 0.116 0.131 0.149 0.177 0.195  ||  -0.642 -0.423 -0.210 -0.004 0.113 0.247 0.419 0.512   || dis=0.02 || select=7/8
008/019-th : 0.045 0.055 0.084 0.118 0.130 0.178 0.193 0.197  ||  -0.890 -0.700 -0.277 0.067 0.162 0.478 0.562 0.582    || dis=0.00 || select=7/8
009/019-th : 0.093 0.098 0.102 0.121 0.118 0.141 0.155 0.172  ||  -0.274 -0.218 -0.183 -0.015 -0.034 0.138 0.234 0.340  || dis=0.02 || select=7/8
010/019-th : 0.099 0.101 0.111 0.125 0.129 0.141 0.152 0.141  ||  -0.222 -0.204 -0.106 0.011 0.046 0.135 0.205 0.134    || dis=0.01 || select=6/8
011/019-th : 0.096 0.086 0.107 0.112 0.119 0.140 0.162 0.177  ||  -0.235 -0.345 -0.130 -0.079 -0.022 0.138 0.288 0.375  || dis=0.01 || select=7/8
012/019-th : 0.107 0.110 0.116 0.121 0.132 0.128 0.137 0.149  ||  -0.150 -0.125 -0.071 -0.029 0.061 0.025 0.099 0.178   || dis=0.01 || select=7/8
013/019-th : 0.034 0.038 0.051 0.065 0.082 0.131 0.228 0.371  ||  -0.963 -0.864 -0.575 -0.328 -0.090 0.375 0.930 1.416  || dis=0.14 || select=7/8
014/019-th : 0.049 0.052 0.071 0.090 0.119 0.159 0.209 0.249  ||  -0.784 -0.719 -0.417 -0.173 0.105 0.393 0.667 0.839   || dis=0.04 || select=7/8
015/019-th : 0.029 0.032 0.043 0.062 0.089 0.120 0.235 0.390  ||  -1.084 -0.967 -0.683 -0.319 0.045 0.350 1.018 1.526   || dis=0.16 || select=7/8
016/019-th : 0.053 0.074 0.098 0.121 0.135 0.165 0.175 0.178  ||  -0.780 -0.450 -0.174 0.043 0.150 0.353 0.409 0.428    || dis=0.00 || select=7/8
017/019-th : 0.120 0.113 0.121 0.119 0.123 0.126 0.137 0.141  ||  -0.040 -0.101 -0.039 -0.054 -0.021 0.007 0.089 0.117  || dis=0.00 || select=7/8
018/019-th : 0.085 0.099 0.112 0.124 0.126 0.141 0.142 0.171  ||  -0.365 -0.217 -0.089 0.012 0.027 0.142 0.143 0.330    || dis=0.03 || select=7/8
[epoch=234/600] FLOP : 28.51 MB, ratio : 0.6985, Expected-ratio : 0.7000, Discrepancy : 0.061
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:45:46] [epoch=234/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.948 (2.948)  Prec@1 32.42 (32.42) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:45:52] [epoch=234/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.227 (2.004)  Prec@1 57.74 (40.31) Prec@5 94.64 (83.77) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.31 Prec@5 83.77 Error@1 59.69 Error@5 16.23 Loss:2.004
***[2020-01-29 07:45:52]*** VALID [epoch=234/600] loss = 2.004415, accuracy@1 = 40.31, accuracy@5 = 83.77 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:45:52]*** start epoch=235/600 Time Left: [03:13:52], LR=[0.066690 ~ 0.066690], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=235, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.3678268051227387, FLOP=40.81
[Search] : epoch=235/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:45:52] [epoch=235/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.740 (0.740)  Prec@1 76.56 (76.56) Prec@5 99.22 (99.22) Acls-loss 0.855 (0.855) FLOP-Loss 0.000 (0.000) Arch-Loss 0.855 (0.855)
**TRAIN** [2020-01-29 07:46:17] [epoch=235/600][097/098] Time 0.31 (0.26) Data 0.00 (0.00) Base-Loss 0.824 (0.790)  Prec@1 73.81 (72.91) Prec@5 98.81 (98.08) Acls-loss 0.839 (0.817) FLOP-Loss 0.000 (0.056) Arch-Loss 0.839 (0.929)
 **TRAIN** Prec@1 72.91 Prec@5 98.08 Error@1 27.09 Error@5 1.92 Base-Loss:0.790, Arch-Loss=0.929
***[2020-01-29 07:46:17]*** TRAIN [epoch=235/600] base-loss = 0.790208, arch-loss = 0.928502, accuracy-1 = 72.91, accuracy-5 = 98.08
[epoch=235/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 16, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.747392)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.203 0.359  ||  0.2241 -0.5431 0.0249  || discrepancy=0.08 || select=0/3
001/003-th : 0.365 0.149 0.487  ||  0.0526 -0.8458 0.3408  || discrepancy=0.12 || select=2/3
002/003-th : 0.034 0.140 0.826  ||  -1.6832 -0.2605 1.5108  || discrepancy=0.69 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.080 0.093 0.108 0.139 0.161 0.183 0.183  ||  -0.798 -0.365 -0.213 -0.062 0.189 0.330 0.462 0.462   || dis=0.00 || select=7/8
001/019-th : 0.125 0.125 0.123 0.131 0.128 0.126 0.122 0.121  ||  0.000 -0.000 -0.011 0.047 0.023 0.011 -0.025 -0.029   || dis=0.00 || select=3/8
002/019-th : 0.117 0.125 0.127 0.132 0.125 0.131 0.123 0.119  ||  -0.063 0.002 0.018 0.057 0.003 0.046 -0.019 -0.047    || dis=0.00 || select=3/8
003/019-th : 0.117 0.116 0.123 0.123 0.126 0.131 0.130 0.134  ||  -0.066 -0.072 -0.013 -0.019 0.005 0.042 0.037 0.070   || dis=0.00 || select=7/8
004/019-th : 0.111 0.116 0.120 0.119 0.129 0.133 0.136 0.137  ||  -0.121 -0.076 -0.042 -0.051 0.034 0.061 0.084 0.094   || dis=0.00 || select=7/8
005/019-th : 0.109 0.118 0.123 0.129 0.126 0.127 0.134 0.135  ||  -0.138 -0.059 -0.010 0.035 0.008 0.017 0.073 0.076    || dis=0.00 || select=7/8
006/019-th : 0.114 0.113 0.115 0.122 0.130 0.133 0.134 0.140  ||  -0.087 -0.103 -0.085 -0.026 0.040 0.065 0.072 0.115   || dis=0.01 || select=7/8
007/019-th : 0.062 0.075 0.093 0.114 0.134 0.151 0.177 0.194  ||  -0.632 -0.439 -0.226 -0.018 0.138 0.260 0.422 0.512   || dis=0.02 || select=7/8
008/019-th : 0.046 0.055 0.085 0.118 0.130 0.177 0.194 0.195  ||  -0.873 -0.701 -0.268 0.067 0.164 0.468 0.564 0.566    || dis=0.00 || select=7/8
009/019-th : 0.094 0.098 0.102 0.121 0.120 0.138 0.155 0.172  ||  -0.265 -0.220 -0.184 -0.015 -0.020 0.115 0.234 0.340  || dis=0.02 || select=7/8
010/019-th : 0.098 0.102 0.112 0.123 0.129 0.141 0.152 0.142  ||  -0.229 -0.193 -0.094 -0.002 0.042 0.132 0.207 0.136   || dis=0.01 || select=6/8
011/019-th : 0.096 0.087 0.107 0.113 0.120 0.139 0.161 0.176  ||  -0.235 -0.334 -0.128 -0.076 -0.017 0.136 0.279 0.371  || dis=0.01 || select=7/8
012/019-th : 0.108 0.111 0.116 0.121 0.132 0.126 0.137 0.149  ||  -0.144 -0.117 -0.069 -0.029 0.059 0.010 0.097 0.178   || dis=0.01 || select=7/8
013/019-th : 0.034 0.038 0.051 0.065 0.083 0.132 0.227 0.371  ||  -0.973 -0.855 -0.577 -0.329 -0.083 0.380 0.922 1.416  || dis=0.14 || select=7/8
014/019-th : 0.049 0.051 0.071 0.091 0.119 0.161 0.207 0.250  ||  -0.789 -0.736 -0.410 -0.167 0.100 0.408 0.657 0.846   || dis=0.04 || select=7/8
015/019-th : 0.029 0.032 0.043 0.061 0.088 0.121 0.239 0.388  ||  -1.080 -0.983 -0.674 -0.332 0.041 0.358 1.037 1.522   || dis=0.15 || select=7/8
016/019-th : 0.053 0.074 0.098 0.121 0.133 0.166 0.177 0.177  ||  -0.781 -0.448 -0.174 0.044 0.136 0.358 0.420 0.424    || dis=0.00 || select=7/8
017/019-th : 0.121 0.113 0.121 0.120 0.123 0.125 0.138 0.140  ||  -0.037 -0.104 -0.034 -0.047 -0.015 -0.004 0.094 0.112  || dis=0.00 || select=7/8
018/019-th : 0.084 0.099 0.112 0.125 0.127 0.141 0.142 0.169  ||  -0.375 -0.214 -0.089 0.022 0.037 0.144 0.146 0.322    || dis=0.03 || select=7/8
[epoch=235/600] FLOP : 28.75 MB, ratio : 0.7044, Expected-ratio : 0.7000, Discrepancy : 0.061
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:46:18] [epoch=235/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.529 (1.529)  Prec@1 55.47 (55.47) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:46:24] [epoch=235/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.404 (2.226)  Prec@1 26.79 (36.67) Prec@5 70.83 (79.51) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.67 Prec@5 79.51 Error@1 63.33 Error@5 20.49 Loss:2.226
***[2020-01-29 07:46:24]*** VALID [epoch=235/600] loss = 2.225514, accuracy@1 = 36.67, accuracy@5 = 79.51 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:46:24]*** start epoch=236/600 Time Left: [03:13:20], LR=[0.066443 ~ 0.066443], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=236, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.355723284509529, FLOP=40.81
[Search] : epoch=236/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:46:25] [epoch=236/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.951 (0.951)  Prec@1 66.80 (66.80) Prec@5 96.48 (96.48) Acls-loss 0.800 (0.800) FLOP-Loss 2.725 (2.725) Arch-Loss 6.250 (6.250)
**TRAIN** [2020-01-29 07:46:49] [epoch=236/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.920 (0.802)  Prec@1 67.26 (72.77) Prec@5 97.62 (97.84) Acls-loss 0.868 (0.831) FLOP-Loss 0.000 (0.084) Arch-Loss 0.868 (0.998)
 **TRAIN** Prec@1 72.77 Prec@5 97.84 Error@1 27.23 Error@5 2.16 Base-Loss:0.802, Arch-Loss=0.998
***[2020-01-29 07:46:49]*** TRAIN [epoch=236/600] base-loss = 0.802029, arch-loss = 0.998350, accuracy-1 = 72.77, accuracy-5 = 97.84
[epoch=236/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.911808)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.442 0.202 0.356  ||  0.2330 -0.5505 0.0184  || discrepancy=0.09 || select=0/3
001/003-th : 0.366 0.148 0.486  ||  0.0569 -0.8521 0.3395  || discrepancy=0.12 || select=2/3
002/003-th : 0.033 0.140 0.827  ||  -1.6926 -0.2601 1.5199  || discrepancy=0.69 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.080 0.093 0.108 0.138 0.161 0.183 0.184  ||  -0.781 -0.369 -0.219 -0.065 0.176 0.335 0.457 0.466   || dis=0.00 || select=7/8
001/019-th : 0.126 0.126 0.124 0.129 0.127 0.126 0.121 0.120  ||  0.011 0.010 -0.009 0.033 0.020 0.005 -0.030 -0.036    || dis=0.00 || select=3/8
002/019-th : 0.118 0.125 0.129 0.132 0.127 0.130 0.120 0.118  ||  -0.055 0.002 0.035 0.060 0.021 0.045 -0.036 -0.058    || dis=0.00 || select=3/8
003/019-th : 0.118 0.117 0.123 0.123 0.127 0.129 0.129 0.133  ||  -0.059 -0.063 -0.019 -0.016 0.018 0.034 0.027 0.064   || dis=0.00 || select=7/8
004/019-th : 0.110 0.116 0.121 0.121 0.129 0.131 0.136 0.136  ||  -0.126 -0.072 -0.028 -0.033 0.033 0.048 0.083 0.089   || dis=0.00 || select=7/8
005/019-th : 0.110 0.118 0.125 0.129 0.125 0.126 0.132 0.135  ||  -0.127 -0.053 -0.002 0.033 0.002 0.009 0.053 0.080    || dis=0.00 || select=7/8
006/019-th : 0.115 0.112 0.114 0.122 0.132 0.132 0.134 0.139  ||  -0.084 -0.106 -0.090 -0.023 0.054 0.057 0.075 0.112   || dis=0.01 || select=7/8
007/019-th : 0.061 0.075 0.095 0.116 0.133 0.150 0.176 0.194  ||  -0.641 -0.442 -0.203 -0.008 0.134 0.254 0.412 0.511   || dis=0.02 || select=7/8
008/019-th : 0.045 0.056 0.085 0.118 0.133 0.176 0.194 0.193  ||  -0.891 -0.688 -0.261 0.066 0.187 0.462 0.561 0.556    || dis=0.00 || select=6/8
009/019-th : 0.094 0.101 0.101 0.120 0.120 0.137 0.155 0.173  ||  -0.268 -0.199 -0.194 -0.020 -0.018 0.107 0.231 0.344  || dis=0.02 || select=7/8
010/019-th : 0.099 0.102 0.113 0.122 0.130 0.139 0.154 0.142  ||  -0.218 -0.197 -0.095 -0.016 0.047 0.118 0.217 0.139   || dis=0.01 || select=6/8
011/019-th : 0.098 0.087 0.108 0.112 0.120 0.138 0.160 0.176  ||  -0.219 -0.338 -0.121 -0.081 -0.014 0.127 0.273 0.366  || dis=0.02 || select=7/8
012/019-th : 0.107 0.112 0.115 0.121 0.131 0.126 0.139 0.148  ||  -0.151 -0.103 -0.075 -0.029 0.053 0.009 0.114 0.171   || dis=0.01 || select=7/8
013/019-th : 0.034 0.038 0.050 0.065 0.083 0.132 0.227 0.370  ||  -0.965 -0.857 -0.586 -0.330 -0.079 0.382 0.926 1.414  || dis=0.14 || select=7/8
014/019-th : 0.049 0.052 0.070 0.091 0.118 0.162 0.208 0.250  ||  -0.786 -0.727 -0.424 -0.167 0.096 0.412 0.663 0.846   || dis=0.04 || select=7/8
015/019-th : 0.029 0.032 0.042 0.061 0.088 0.121 0.237 0.391  ||  -1.076 -0.983 -0.687 -0.324 0.037 0.357 1.031 1.534   || dis=0.15 || select=7/8
016/019-th : 0.054 0.075 0.098 0.120 0.133 0.169 0.175 0.177  ||  -0.774 -0.438 -0.172 0.033 0.134 0.372 0.407 0.420    || dis=0.00 || select=7/8
017/019-th : 0.122 0.114 0.121 0.121 0.123 0.123 0.137 0.139  ||  -0.024 -0.095 -0.033 -0.039 -0.022 -0.019 0.089 0.104  || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.113 0.126 0.127 0.139 0.143 0.169  ||  -0.379 -0.219 -0.080 0.031 0.034 0.127 0.157 0.321    || dis=0.03 || select=7/8
[epoch=236/600] FLOP : 27.91 MB, ratio : 0.6839, Expected-ratio : 0.7000, Discrepancy : 0.061
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:46:50] [epoch=236/600][000/098] Time 0.40 (0.40) Data 0.30 (0.30) Loss 4.820 (4.820)  Prec@1 19.14 (19.14) Prec@5 64.06 (64.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:46:56] [epoch=236/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.869 (2.510)  Prec@1 30.36 (35.98) Prec@5 73.81 (82.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.98 Prec@5 82.02 Error@1 64.02 Error@5 17.98 Loss:2.510
***[2020-01-29 07:46:56]*** VALID [epoch=236/600] loss = 2.510217, accuracy@1 = 35.98, accuracy@5 = 82.02 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:46:56]*** start epoch=237/600 Time Left: [03:12:49], LR=[0.066196 ~ 0.066196], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=237, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.3435976745854665, FLOP=40.81
[Search] : epoch=237/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:46:57] [epoch=237/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.755 (0.755)  Prec@1 74.22 (74.22) Prec@5 98.44 (98.44) Acls-loss 0.795 (0.795) FLOP-Loss 0.000 (0.000) Arch-Loss 0.795 (0.795)
**TRAIN** [2020-01-29 07:47:22] [epoch=237/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.686 (0.801)  Prec@1 76.79 (72.99) Prec@5 98.21 (97.98) Acls-loss 0.820 (0.835) FLOP-Loss 0.000 (0.000) Arch-Loss 0.820 (0.835)
 **TRAIN** Prec@1 72.99 Prec@5 97.98 Error@1 27.01 Error@5 2.02 Base-Loss:0.801, Arch-Loss=0.835
***[2020-01-29 07:47:22]*** TRAIN [epoch=237/600] base-loss = 0.800793, arch-loss = 0.835227, accuracy-1 = 72.99, accuracy-5 = 97.98
[epoch=237/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.372608)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.203 0.360  ||  0.2236 -0.5439 0.0291  || discrepancy=0.08 || select=0/3
001/003-th : 0.361 0.147 0.493  ||  0.0432 -0.8550 0.3553  || discrepancy=0.13 || select=2/3
002/003-th : 0.032 0.134 0.833  ||  -1.7050 -0.2844 1.5422  || discrepancy=0.70 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.078 0.092 0.107 0.139 0.161 0.182 0.188  ||  -0.778 -0.389 -0.227 -0.078 0.185 0.332 0.456 0.490   || dis=0.01 || select=7/8
001/019-th : 0.124 0.126 0.125 0.128 0.128 0.127 0.121 0.121  ||  -0.008 0.012 0.000 0.029 0.030 0.019 -0.030 -0.031    || dis=0.00 || select=4/8
002/019-th : 0.118 0.124 0.127 0.132 0.128 0.132 0.122 0.118  ||  -0.055 -0.007 0.014 0.057 0.024 0.053 -0.024 -0.054   || dis=0.00 || select=3/8
003/019-th : 0.116 0.117 0.121 0.125 0.127 0.130 0.129 0.135  ||  -0.073 -0.063 -0.034 -0.003 0.016 0.036 0.031 0.078   || dis=0.01 || select=7/8
004/019-th : 0.109 0.116 0.119 0.120 0.129 0.131 0.137 0.138  ||  -0.135 -0.076 -0.044 -0.036 0.034 0.049 0.095 0.099   || dis=0.00 || select=7/8
005/019-th : 0.108 0.117 0.125 0.128 0.126 0.129 0.131 0.135  ||  -0.141 -0.066 0.002 0.028 0.014 0.036 0.048 0.080     || dis=0.00 || select=7/8
006/019-th : 0.115 0.112 0.113 0.122 0.132 0.132 0.135 0.140  ||  -0.084 -0.111 -0.100 -0.020 0.056 0.058 0.078 0.115   || dis=0.01 || select=7/8
007/019-th : 0.061 0.075 0.093 0.112 0.132 0.152 0.177 0.199  ||  -0.647 -0.442 -0.221 -0.037 0.126 0.270 0.424 0.537   || dis=0.02 || select=7/8
008/019-th : 0.046 0.054 0.084 0.118 0.136 0.175 0.195 0.192  ||  -0.879 -0.708 -0.270 0.063 0.208 0.459 0.568 0.554    || dis=0.00 || select=6/8
009/019-th : 0.093 0.100 0.101 0.120 0.120 0.136 0.157 0.173  ||  -0.273 -0.205 -0.195 -0.020 -0.022 0.105 0.245 0.348  || dis=0.02 || select=7/8
010/019-th : 0.099 0.102 0.111 0.121 0.131 0.138 0.156 0.143  ||  -0.226 -0.196 -0.108 -0.025 0.054 0.111 0.233 0.147   || dis=0.01 || select=6/8
011/019-th : 0.098 0.088 0.108 0.111 0.120 0.139 0.159 0.177  ||  -0.222 -0.323 -0.119 -0.090 -0.020 0.132 0.263 0.370  || dis=0.02 || select=7/8
012/019-th : 0.106 0.111 0.114 0.121 0.131 0.127 0.140 0.150  ||  -0.165 -0.114 -0.088 -0.028 0.053 0.023 0.116 0.186   || dis=0.01 || select=7/8
013/019-th : 0.033 0.038 0.050 0.066 0.082 0.132 0.233 0.367  ||  -0.996 -0.868 -0.587 -0.305 -0.090 0.386 0.954 1.408  || dis=0.13 || select=7/8
014/019-th : 0.048 0.051 0.071 0.090 0.117 0.160 0.210 0.252  ||  -0.806 -0.738 -0.408 -0.172 0.093 0.405 0.676 0.858   || dis=0.04 || select=7/8
015/019-th : 0.029 0.031 0.043 0.061 0.088 0.121 0.233 0.394  ||  -1.071 -0.993 -0.683 -0.326 0.042 0.362 1.017 1.540   || dis=0.16 || select=7/8
016/019-th : 0.052 0.074 0.098 0.122 0.131 0.165 0.178 0.179  ||  -0.794 -0.448 -0.172 0.050 0.124 0.350 0.428 0.435    || dis=0.00 || select=7/8
017/019-th : 0.121 0.113 0.119 0.122 0.122 0.125 0.139 0.141  ||  -0.038 -0.104 -0.055 -0.030 -0.030 0.000 0.101 0.119  || dis=0.00 || select=7/8
018/019-th : 0.083 0.098 0.113 0.126 0.127 0.138 0.143 0.173  ||  -0.387 -0.220 -0.084 0.025 0.038 0.117 0.152 0.343    || dis=0.03 || select=7/8
[epoch=237/600] FLOP : 28.37 MB, ratio : 0.6952, Expected-ratio : 0.7000, Discrepancy : 0.063
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:47:22] [epoch=237/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.171 (2.171)  Prec@1 48.44 (48.44) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:47:29] [epoch=237/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 2.367 (2.100)  Prec@1 51.19 (39.43) Prec@5 85.71 (82.39) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.43 Prec@5 82.39 Error@1 60.57 Error@5 17.61 Loss:2.100
***[2020-01-29 07:47:29]*** VALID [epoch=237/600] loss = 2.100225, accuracy@1 = 39.43, accuracy@5 = 82.39 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:47:29]*** start epoch=238/600 Time Left: [03:12:18], LR=[0.065948 ~ 0.065948], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=238, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.3314503077802717, FLOP=40.81
[Search] : epoch=238/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:47:29] [epoch=238/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.916 (0.916)  Prec@1 67.58 (67.58) Prec@5 98.05 (98.05) Acls-loss 0.817 (0.817) FLOP-Loss 0.000 (0.000) Arch-Loss 0.817 (0.817)
**TRAIN** [2020-01-29 07:47:54] [epoch=238/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.799 (0.796)  Prec@1 73.81 (72.86) Prec@5 98.21 (97.84) Acls-loss 0.868 (0.826) FLOP-Loss 0.000 (0.028) Arch-Loss 0.868 (0.882)
 **TRAIN** Prec@1 72.86 Prec@5 97.84 Error@1 27.14 Error@5 2.16 Base-Loss:0.796, Arch-Loss=0.882
***[2020-01-29 07:47:54]*** TRAIN [epoch=238/600] base-loss = 0.796334, arch-loss = 0.881774, accuracy-1 = 72.86, accuracy-5 = 97.84
[epoch=238/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.323456)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.203 0.361  ||  0.2215 -0.5416 0.0329  || discrepancy=0.08 || select=0/3
001/003-th : 0.357 0.146 0.496  ||  0.0363 -0.8559 0.3643  || discrepancy=0.14 || select=2/3
002/003-th : 0.031 0.131 0.838  ||  -1.7339 -0.2904 1.5679  || discrepancy=0.71 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.077 0.090 0.107 0.140 0.161 0.182 0.190  ||  -0.783 -0.400 -0.245 -0.074 0.196 0.339 0.461 0.499   || dis=0.01 || select=7/8
001/019-th : 0.124 0.127 0.124 0.127 0.128 0.127 0.122 0.121  ||  -0.009 0.014 -0.007 0.020 0.027 0.016 -0.024 -0.027   || dis=0.00 || select=4/8
002/019-th : 0.119 0.124 0.127 0.133 0.126 0.131 0.123 0.119  ||  -0.053 -0.008 0.014 0.059 0.005 0.050 -0.019 -0.052   || dis=0.00 || select=3/8
003/019-th : 0.115 0.117 0.121 0.122 0.127 0.131 0.130 0.136  ||  -0.085 -0.064 -0.034 -0.021 0.019 0.043 0.043 0.086   || dis=0.01 || select=7/8
004/019-th : 0.109 0.116 0.118 0.120 0.131 0.131 0.136 0.138  ||  -0.137 -0.074 -0.052 -0.038 0.048 0.052 0.087 0.104   || dis=0.00 || select=7/8
005/019-th : 0.109 0.117 0.125 0.126 0.127 0.130 0.130 0.136  ||  -0.135 -0.067 0.005 0.011 0.020 0.038 0.040 0.084     || dis=0.01 || select=7/8
006/019-th : 0.114 0.113 0.113 0.122 0.131 0.131 0.135 0.141  ||  -0.089 -0.098 -0.099 -0.022 0.049 0.045 0.081 0.120   || dis=0.01 || select=7/8
007/019-th : 0.061 0.074 0.094 0.113 0.130 0.152 0.176 0.199  ||  -0.649 -0.445 -0.211 -0.029 0.116 0.269 0.417 0.540   || dis=0.02 || select=7/8
008/019-th : 0.046 0.055 0.083 0.118 0.134 0.174 0.195 0.194  ||  -0.882 -0.700 -0.283 0.067 0.196 0.458 0.571 0.565    || dis=0.00 || select=6/8
009/019-th : 0.092 0.100 0.101 0.120 0.119 0.137 0.158 0.173  ||  -0.286 -0.201 -0.190 -0.019 -0.025 0.111 0.255 0.344  || dis=0.01 || select=7/8
010/019-th : 0.099 0.101 0.111 0.121 0.130 0.138 0.155 0.144  ||  -0.221 -0.203 -0.108 -0.020 0.050 0.109 0.226 0.153   || dis=0.01 || select=6/8
011/019-th : 0.098 0.088 0.107 0.112 0.123 0.138 0.158 0.176  ||  -0.216 -0.323 -0.129 -0.087 0.005 0.120 0.257 0.367   || dis=0.02 || select=7/8
012/019-th : 0.105 0.110 0.113 0.121 0.129 0.129 0.141 0.152  ||  -0.168 -0.129 -0.099 -0.030 0.038 0.032 0.126 0.200   || dis=0.01 || select=7/8
013/019-th : 0.032 0.038 0.050 0.066 0.083 0.132 0.234 0.366  ||  -1.027 -0.864 -0.587 -0.305 -0.078 0.387 0.961 1.407  || dis=0.13 || select=7/8
014/019-th : 0.047 0.051 0.070 0.089 0.118 0.161 0.212 0.251  ||  -0.810 -0.736 -0.415 -0.181 0.100 0.413 0.687 0.854   || dis=0.04 || select=7/8
015/019-th : 0.029 0.031 0.043 0.061 0.088 0.124 0.229 0.396  ||  -1.082 -0.999 -0.682 -0.329 0.047 0.383 1.001 1.548   || dis=0.17 || select=7/8
016/019-th : 0.053 0.074 0.097 0.119 0.131 0.165 0.181 0.181  ||  -0.792 -0.451 -0.183 0.028 0.121 0.354 0.444 0.444    || dis=0.00 || select=6/8
017/019-th : 0.120 0.112 0.118 0.122 0.122 0.125 0.140 0.141  ||  -0.040 -0.112 -0.057 -0.025 -0.023 -0.004 0.111 0.119  || dis=0.00 || select=7/8
018/019-th : 0.083 0.098 0.113 0.125 0.128 0.136 0.142 0.175  ||  -0.388 -0.222 -0.084 0.019 0.045 0.101 0.148 0.358    || dis=0.03 || select=7/8
[epoch=238/600] FLOP : 28.32 MB, ratio : 0.6940, Expected-ratio : 0.7000, Discrepancy : 0.064
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:47:55] [epoch=238/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.741 (1.741)  Prec@1 49.22 (49.22) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:48:01] [epoch=238/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.680 (2.213)  Prec@1 50.60 (35.20) Prec@5 86.31 (80.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.20 Prec@5 80.21 Error@1 64.80 Error@5 19.79 Loss:2.213
***[2020-01-29 07:48:01]*** VALID [epoch=238/600] loss = 2.213037, accuracy@1 = 35.20, accuracy@5 = 80.21 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:48:01]*** start epoch=239/600 Time Left: [03:11:48], LR=[0.065700 ~ 0.065700], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=239, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.3192815171201424, FLOP=40.81
[Search] : epoch=239/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:48:02] [epoch=239/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.793 (0.793)  Prec@1 74.61 (74.61) Prec@5 97.27 (97.27) Acls-loss 0.792 (0.792) FLOP-Loss 0.000 (0.000) Arch-Loss 0.792 (0.792)
**TRAIN** [2020-01-29 07:48:27] [epoch=239/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.661 (0.793)  Prec@1 77.98 (72.84) Prec@5 99.40 (97.86) Acls-loss 0.714 (0.817) FLOP-Loss 0.000 (0.084) Arch-Loss 0.714 (0.985)
 **TRAIN** Prec@1 72.84 Prec@5 97.86 Error@1 27.16 Error@5 2.14 Base-Loss:0.793, Arch-Loss=0.985
***[2020-01-29 07:48:27]*** TRAIN [epoch=239/600] base-loss = 0.793245, arch-loss = 0.985376, accuracy-1 = 72.84, accuracy-5 = 97.86
[epoch=239/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.323456)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.200 0.360  ||  0.2283 -0.5587 0.0300  || discrepancy=0.08 || select=0/3
001/003-th : 0.361 0.146 0.493  ||  0.0457 -0.8610 0.3584  || discrepancy=0.13 || select=2/3
002/003-th : 0.030 0.130 0.840  ||  -1.7503 -0.2878 1.5813  || discrepancy=0.71 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.076 0.090 0.109 0.139 0.161 0.182 0.190  ||  -0.772 -0.415 -0.247 -0.051 0.185 0.337 0.456 0.500   || dis=0.01 || select=7/8
001/019-th : 0.125 0.126 0.126 0.127 0.127 0.126 0.121 0.121  ||  0.003 0.010 0.007 0.020 0.020 0.012 -0.028 -0.036     || dis=0.00 || select=4/8
002/019-th : 0.119 0.125 0.126 0.133 0.127 0.131 0.122 0.117  ||  -0.047 0.002 0.012 0.063 0.017 0.047 -0.025 -0.064    || dis=0.00 || select=3/8
003/019-th : 0.115 0.116 0.123 0.125 0.127 0.130 0.130 0.134  ||  -0.082 -0.073 -0.018 0.003 0.020 0.045 0.040 0.071    || dis=0.00 || select=7/8
004/019-th : 0.110 0.117 0.119 0.120 0.131 0.130 0.133 0.139  ||  -0.124 -0.063 -0.044 -0.043 0.052 0.041 0.066 0.105   || dis=0.01 || select=7/8
005/019-th : 0.111 0.118 0.125 0.126 0.128 0.129 0.129 0.135  ||  -0.122 -0.061 0.003 0.009 0.026 0.032 0.032 0.074     || dis=0.01 || select=7/8
006/019-th : 0.114 0.114 0.112 0.123 0.130 0.130 0.136 0.141  ||  -0.090 -0.094 -0.104 -0.011 0.040 0.040 0.083 0.122   || dis=0.00 || select=7/8
007/019-th : 0.059 0.074 0.094 0.113 0.133 0.151 0.179 0.198  ||  -0.672 -0.449 -0.206 -0.022 0.136 0.265 0.435 0.536   || dis=0.02 || select=7/8
008/019-th : 0.046 0.055 0.083 0.119 0.134 0.176 0.195 0.192  ||  -0.881 -0.698 -0.288 0.076 0.195 0.465 0.571 0.556    || dis=0.00 || select=6/8
009/019-th : 0.093 0.099 0.101 0.121 0.119 0.139 0.157 0.171  ||  -0.279 -0.213 -0.193 -0.011 -0.024 0.125 0.252 0.337  || dis=0.01 || select=7/8
010/019-th : 0.099 0.101 0.111 0.122 0.131 0.137 0.155 0.143  ||  -0.224 -0.200 -0.107 -0.014 0.056 0.106 0.226 0.149   || dis=0.01 || select=6/8
011/019-th : 0.099 0.089 0.107 0.113 0.125 0.136 0.158 0.173  ||  -0.212 -0.313 -0.133 -0.079 0.026 0.107 0.258 0.348   || dis=0.01 || select=7/8
012/019-th : 0.106 0.109 0.115 0.120 0.131 0.129 0.142 0.150  ||  -0.164 -0.135 -0.082 -0.038 0.050 0.034 0.130 0.188   || dis=0.01 || select=7/8
013/019-th : 0.032 0.038 0.050 0.066 0.082 0.130 0.239 0.363  ||  -1.036 -0.860 -0.590 -0.297 -0.081 0.374 0.985 1.401  || dis=0.12 || select=7/8
014/019-th : 0.048 0.051 0.071 0.088 0.118 0.160 0.212 0.252  ||  -0.800 -0.737 -0.411 -0.192 0.100 0.408 0.684 0.861   || dis=0.04 || select=7/8
015/019-th : 0.029 0.031 0.042 0.061 0.089 0.124 0.231 0.393  ||  -1.070 -1.001 -0.692 -0.327 0.052 0.384 1.008 1.540   || dis=0.16 || select=7/8
016/019-th : 0.052 0.074 0.097 0.119 0.132 0.164 0.181 0.181  ||  -0.793 -0.451 -0.180 0.027 0.128 0.348 0.445 0.444    || dis=0.00 || select=6/8
017/019-th : 0.122 0.112 0.120 0.122 0.122 0.123 0.139 0.140  ||  -0.028 -0.109 -0.044 -0.024 -0.029 -0.020 0.105 0.114  || dis=0.00 || select=7/8
018/019-th : 0.083 0.099 0.112 0.124 0.129 0.136 0.142 0.175  ||  -0.390 -0.212 -0.094 0.011 0.048 0.107 0.147 0.359    || dis=0.03 || select=7/8
[epoch=239/600] FLOP : 28.32 MB, ratio : 0.6940, Expected-ratio : 0.7000, Discrepancy : 0.063
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:48:27] [epoch=239/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.503 (1.503)  Prec@1 48.83 (48.83) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:48:33] [epoch=239/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.936 (2.247)  Prec@1 48.21 (34.75) Prec@5 92.86 (80.41) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.75 Prec@5 80.41 Error@1 65.25 Error@5 19.59 Loss:2.247
***[2020-01-29 07:48:33]*** VALID [epoch=239/600] loss = 2.246676, accuracy@1 = 34.75, accuracy@5 = 80.41 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:48:33]*** start epoch=240/600 Time Left: [03:11:16], LR=[0.065451 ~ 0.065451], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=240, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.3070916362186216, FLOP=40.81
[Search] : epoch=240/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:48:34] [epoch=240/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 0.795 (0.795)  Prec@1 71.88 (71.88) Prec@5 98.83 (98.83) Acls-loss 0.834 (0.834) FLOP-Loss 0.000 (0.000) Arch-Loss 0.834 (0.834)
**TRAIN** [2020-01-29 07:49:00] [epoch=240/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.954 (0.801)  Prec@1 63.10 (72.52) Prec@5 96.43 (97.86) Acls-loss 0.838 (0.822) FLOP-Loss 0.000 (0.028) Arch-Loss 0.838 (0.878)
 **TRAIN** Prec@1 72.52 Prec@5 97.86 Error@1 27.48 Error@5 2.14 Base-Loss:0.801, Arch-Loss=0.878
***[2020-01-29 07:49:00]*** TRAIN [epoch=240/600] base-loss = 0.801019, arch-loss = 0.877651, accuracy-1 = 72.52, accuracy-5 = 97.86
[epoch=240/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.862656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.202 0.362  ||  0.2234 -0.5480 0.0356  || discrepancy=0.07 || select=0/3
001/003-th : 0.359 0.147 0.494  ||  0.0429 -0.8529 0.3622  || discrepancy=0.14 || select=2/3
002/003-th : 0.029 0.127 0.844  ||  -1.7666 -0.2951 1.5991  || discrepancy=0.72 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.077 0.090 0.110 0.137 0.163 0.182 0.189  ||  -0.788 -0.407 -0.241 -0.046 0.173 0.351 0.462 0.496   || dis=0.01 || select=7/8
001/019-th : 0.123 0.125 0.126 0.128 0.127 0.126 0.122 0.122  ||  -0.013 0.005 0.009 0.025 0.020 0.013 -0.019 -0.026    || dis=0.00 || select=3/8
002/019-th : 0.120 0.125 0.127 0.131 0.128 0.129 0.122 0.118  ||  -0.044 0.001 0.015 0.046 0.022 0.032 -0.022 -0.060    || dis=0.00 || select=3/8
003/019-th : 0.114 0.116 0.122 0.124 0.127 0.130 0.131 0.135  ||  -0.091 -0.075 -0.021 -0.002 0.022 0.045 0.050 0.076   || dis=0.00 || select=7/8
004/019-th : 0.110 0.115 0.120 0.119 0.133 0.131 0.133 0.139  ||  -0.129 -0.078 -0.040 -0.046 0.063 0.050 0.064 0.110   || dis=0.01 || select=7/8
005/019-th : 0.111 0.117 0.125 0.126 0.128 0.130 0.130 0.134  ||  -0.122 -0.067 0.001 0.006 0.022 0.039 0.041 0.071     || dis=0.00 || select=7/8
006/019-th : 0.113 0.113 0.112 0.123 0.132 0.132 0.135 0.140  ||  -0.097 -0.096 -0.107 -0.012 0.056 0.057 0.078 0.119   || dis=0.01 || select=7/8
007/019-th : 0.058 0.073 0.093 0.112 0.132 0.153 0.181 0.199  ||  -0.681 -0.455 -0.218 -0.027 0.134 0.280 0.449 0.543   || dis=0.02 || select=7/8
008/019-th : 0.045 0.056 0.080 0.118 0.135 0.175 0.196 0.195  ||  -0.887 -0.685 -0.318 0.071 0.204 0.462 0.576 0.570    || dis=0.00 || select=6/8
009/019-th : 0.092 0.096 0.098 0.121 0.117 0.143 0.161 0.172  ||  -0.278 -0.240 -0.214 -0.011 -0.039 0.158 0.275 0.343  || dis=0.01 || select=7/8
010/019-th : 0.098 0.102 0.111 0.121 0.132 0.137 0.153 0.146  ||  -0.232 -0.193 -0.112 -0.018 0.062 0.100 0.215 0.166   || dis=0.01 || select=6/8
011/019-th : 0.098 0.088 0.108 0.113 0.126 0.136 0.160 0.172  ||  -0.218 -0.329 -0.119 -0.076 0.032 0.107 0.269 0.343   || dis=0.01 || select=7/8
012/019-th : 0.105 0.109 0.115 0.119 0.130 0.129 0.142 0.150  ||  -0.168 -0.136 -0.076 -0.044 0.046 0.035 0.134 0.190   || dis=0.01 || select=7/8
013/019-th : 0.032 0.038 0.049 0.065 0.083 0.130 0.238 0.363  ||  -1.023 -0.851 -0.594 -0.313 -0.072 0.373 0.980 1.401  || dis=0.12 || select=7/8
014/019-th : 0.048 0.051 0.070 0.087 0.116 0.161 0.212 0.255  ||  -0.806 -0.730 -0.415 -0.198 0.089 0.413 0.688 0.872   || dis=0.04 || select=7/8
015/019-th : 0.029 0.031 0.043 0.060 0.087 0.124 0.232 0.395  ||  -1.076 -0.997 -0.680 -0.345 0.040 0.389 1.015 1.546   || dis=0.16 || select=7/8
016/019-th : 0.053 0.073 0.096 0.119 0.132 0.165 0.183 0.180  ||  -0.782 -0.467 -0.191 0.028 0.129 0.354 0.455 0.443    || dis=0.00 || select=6/8
017/019-th : 0.120 0.112 0.119 0.122 0.122 0.125 0.139 0.141  ||  -0.043 -0.107 -0.052 -0.029 -0.025 0.000 0.104 0.122  || dis=0.00 || select=7/8
018/019-th : 0.082 0.100 0.112 0.124 0.129 0.135 0.142 0.175  ||  -0.403 -0.202 -0.085 0.016 0.056 0.097 0.147 0.357    || dis=0.03 || select=7/8
[epoch=240/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.063
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:49:01] [epoch=240/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.394 (2.394)  Prec@1 31.64 (31.64) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:49:07] [epoch=240/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.215 (2.113)  Prec@1 59.52 (42.24) Prec@5 95.24 (85.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.24 Prec@5 85.26 Error@1 57.76 Error@5 14.74 Loss:2.113
***[2020-01-29 07:49:07]*** VALID [epoch=240/600] loss = 2.113332, accuracy@1 = 42.24, accuracy@5 = 85.26 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:49:07]*** start epoch=241/600 Time Left: [03:10:46], LR=[0.065202 ~ 0.065202], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=241, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.2948809992674515, FLOP=40.81
[Search] : epoch=241/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:49:07] [epoch=241/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.791 (0.791)  Prec@1 69.53 (69.53) Prec@5 96.88 (96.88) Acls-loss 0.864 (0.864) FLOP-Loss 0.000 (0.000) Arch-Loss 0.864 (0.864)
**TRAIN** [2020-01-29 07:49:32] [epoch=241/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.816 (0.795)  Prec@1 72.02 (72.50) Prec@5 99.40 (98.02) Acls-loss 0.822 (0.826) FLOP-Loss 0.000 (0.251) Arch-Loss 0.822 (1.329)
 **TRAIN** Prec@1 72.50 Prec@5 98.02 Error@1 27.50 Error@5 1.98 Base-Loss:0.795, Arch-Loss=1.329
***[2020-01-29 07:49:32]*** TRAIN [epoch=241/600] base-loss = 0.794714, arch-loss = 1.328593, accuracy-1 = 72.50, accuracy-5 = 98.02
[epoch=241/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.632256)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.454 0.199 0.347  ||  0.2648 -0.5595 -0.0037  || discrepancy=0.11 || select=0/3
001/003-th : 0.377 0.147 0.476  ||  0.0886 -0.8514 0.3206  || discrepancy=0.10 || select=2/3
002/003-th : 0.029 0.129 0.843  ||  -1.7777 -0.2766 1.6020  || discrepancy=0.71 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.078 0.093 0.112 0.137 0.163 0.178 0.185  ||  -0.770 -0.389 -0.223 -0.030 0.170 0.344 0.432 0.468   || dis=0.01 || select=7/8
001/019-th : 0.129 0.129 0.130 0.128 0.126 0.123 0.118 0.117  ||  0.033 0.030 0.042 0.028 0.010 -0.019 -0.054 -0.068    || dis=0.00 || select=2/8
002/019-th : 0.124 0.129 0.132 0.134 0.126 0.126 0.117 0.112  ||  -0.005 0.031 0.054 0.073 0.008 0.008 -0.060 -0.104    || dis=0.00 || select=3/8
003/019-th : 0.118 0.119 0.126 0.128 0.127 0.127 0.126 0.130  ||  -0.059 -0.049 0.007 0.025 0.017 0.017 0.006 0.045     || dis=0.00 || select=7/8
004/019-th : 0.114 0.119 0.123 0.123 0.132 0.128 0.127 0.135  ||  -0.094 -0.044 -0.015 -0.015 0.055 0.023 0.019 0.077   || dis=0.00 || select=7/8
005/019-th : 0.112 0.121 0.128 0.126 0.128 0.129 0.126 0.130  ||  -0.107 -0.028 0.026 0.008 0.022 0.029 0.012 0.038     || dis=0.00 || select=7/8
006/019-th : 0.117 0.118 0.116 0.125 0.131 0.130 0.130 0.133  ||  -0.058 -0.051 -0.075 0.004 0.048 0.046 0.040 0.068    || dis=0.00 || select=7/8
007/019-th : 0.060 0.076 0.094 0.116 0.133 0.152 0.176 0.193  ||  -0.663 -0.425 -0.212 0.002 0.136 0.266 0.414 0.507    || dis=0.02 || select=7/8
008/019-th : 0.045 0.057 0.082 0.121 0.136 0.173 0.193 0.193  ||  -0.892 -0.667 -0.300 0.089 0.209 0.445 0.558 0.555    || dis=0.00 || select=6/8
009/019-th : 0.095 0.098 0.103 0.122 0.117 0.143 0.154 0.167  ||  -0.249 -0.220 -0.178 -0.006 -0.043 0.156 0.232 0.309  || dis=0.01 || select=7/8
010/019-th : 0.102 0.105 0.113 0.125 0.131 0.133 0.149 0.143  ||  -0.199 -0.169 -0.093 0.007 0.056 0.070 0.182 0.140    || dis=0.01 || select=6/8
011/019-th : 0.101 0.090 0.111 0.115 0.127 0.134 0.156 0.166  ||  -0.188 -0.304 -0.098 -0.064 0.034 0.090 0.243 0.304   || dis=0.01 || select=7/8
012/019-th : 0.110 0.113 0.117 0.121 0.129 0.125 0.138 0.145  ||  -0.125 -0.097 -0.062 -0.026 0.036 0.006 0.106 0.155   || dis=0.01 || select=7/8
013/019-th : 0.033 0.038 0.050 0.067 0.084 0.128 0.241 0.360  ||  -0.995 -0.854 -0.596 -0.299 -0.069 0.350 0.987 1.386  || dis=0.12 || select=7/8
014/019-th : 0.049 0.053 0.070 0.088 0.117 0.162 0.210 0.251  ||  -0.790 -0.706 -0.418 -0.199 0.088 0.417 0.677 0.855   || dis=0.04 || select=7/8
015/019-th : 0.029 0.032 0.043 0.060 0.090 0.127 0.235 0.385  ||  -1.083 -0.966 -0.683 -0.350 0.059 0.400 1.017 1.513   || dis=0.15 || select=7/8
016/019-th : 0.055 0.075 0.097 0.123 0.132 0.163 0.181 0.175  ||  -0.757 -0.439 -0.185 0.053 0.130 0.338 0.441 0.409    || dis=0.01 || select=6/8
017/019-th : 0.126 0.117 0.122 0.125 0.120 0.122 0.133 0.135  ||  0.004 -0.070 -0.023 -0.004 -0.041 -0.030 0.062 0.077  || dis=0.00 || select=7/8
018/019-th : 0.083 0.101 0.115 0.124 0.131 0.134 0.140 0.172  ||  -0.386 -0.190 -0.065 0.014 0.064 0.086 0.135 0.338    || dis=0.03 || select=7/8
[epoch=241/600] FLOP : 27.63 MB, ratio : 0.6770, Expected-ratio : 0.7000, Discrepancy : 0.061
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:49:32] [epoch=241/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.129 (2.129)  Prec@1 48.83 (48.83) Prec@5 90.62 (90.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:49:38] [epoch=241/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.677 (2.137)  Prec@1 48.21 (40.08) Prec@5 86.31 (84.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.08 Prec@5 84.06 Error@1 59.92 Error@5 15.94 Loss:2.137
***[2020-01-29 07:49:38]*** VALID [epoch=241/600] loss = 2.136859, accuracy@1 = 40.08, accuracy@5 = 84.06 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:49:39]*** start epoch=242/600 Time Left: [03:10:14], LR=[0.064952 ~ 0.064952], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=242, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.2826499410274126, FLOP=40.81
[Search] : epoch=242/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:49:39] [epoch=242/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.886 (0.886)  Prec@1 71.48 (71.48) Prec@5 96.48 (96.48) Acls-loss 0.856 (0.856) FLOP-Loss 0.000 (0.000) Arch-Loss 0.856 (0.856)
**TRAIN** [2020-01-29 07:50:04] [epoch=242/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.852 (0.810)  Prec@1 72.02 (72.30) Prec@5 96.43 (97.88) Acls-loss 0.818 (0.835) FLOP-Loss 0.000 (0.000) Arch-Loss 0.818 (0.835)
 **TRAIN** Prec@1 72.30 Prec@5 97.88 Error@1 27.70 Error@5 2.12 Base-Loss:0.810, Arch-Loss=0.835
***[2020-01-29 07:50:04]*** TRAIN [epoch=242/600] base-loss = 0.809512, arch-loss = 0.835358, accuracy-1 = 72.30, accuracy-5 = 97.88
[epoch=242/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 12, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.308672)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.203 0.347  ||  0.2591 -0.5368 0.0010  || discrepancy=0.10 || select=0/3
001/003-th : 0.372 0.148 0.479  ||  0.0786 -0.8415 0.3309  || discrepancy=0.11 || select=2/3
002/003-th : 0.029 0.129 0.843  ||  -1.7756 -0.2762 1.6036  || discrepancy=0.71 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.078 0.093 0.112 0.136 0.162 0.177 0.189  ||  -0.773 -0.394 -0.222 -0.029 0.160 0.336 0.423 0.493   || dis=0.01 || select=7/8
001/019-th : 0.129 0.127 0.129 0.127 0.125 0.125 0.120 0.118  ||  0.029 0.016 0.033 0.017 -0.000 -0.004 -0.038 -0.060   || dis=0.00 || select=2/8
002/019-th : 0.122 0.128 0.129 0.133 0.128 0.127 0.119 0.113  ||  -0.019 0.027 0.031 0.067 0.027 0.016 -0.044 -0.096    || dis=0.00 || select=3/8
003/019-th : 0.116 0.118 0.126 0.127 0.126 0.128 0.128 0.132  ||  -0.077 -0.056 0.007 0.017 0.013 0.028 0.022 0.057     || dis=0.00 || select=7/8
004/019-th : 0.112 0.116 0.121 0.122 0.132 0.130 0.130 0.136  ||  -0.103 -0.070 -0.027 -0.023 0.061 0.039 0.043 0.085   || dis=0.00 || select=7/8
005/019-th : 0.111 0.119 0.128 0.125 0.128 0.131 0.127 0.131  ||  -0.113 -0.051 0.029 -0.002 0.028 0.045 0.017 0.048    || dis=0.00 || select=7/8
006/019-th : 0.117 0.116 0.116 0.122 0.131 0.134 0.130 0.133  ||  -0.064 -0.069 -0.069 -0.016 0.049 0.076 0.045 0.070   || dis=0.00 || select=5/8
007/019-th : 0.060 0.075 0.092 0.117 0.132 0.151 0.177 0.196  ||  -0.662 -0.437 -0.234 0.006 0.132 0.265 0.424 0.526    || dis=0.02 || select=7/8
008/019-th : 0.046 0.056 0.080 0.120 0.135 0.172 0.196 0.195  ||  -0.881 -0.675 -0.320 0.085 0.200 0.440 0.573 0.570    || dis=0.00 || select=6/8
009/019-th : 0.095 0.098 0.101 0.120 0.117 0.146 0.156 0.167  ||  -0.257 -0.221 -0.188 -0.022 -0.049 0.178 0.242 0.313  || dis=0.01 || select=7/8
010/019-th : 0.100 0.105 0.113 0.125 0.130 0.133 0.150 0.144  ||  -0.215 -0.166 -0.090 0.009 0.048 0.070 0.188 0.150    || dis=0.01 || select=6/8
011/019-th : 0.099 0.090 0.111 0.111 0.127 0.135 0.158 0.169  ||  -0.210 -0.307 -0.095 -0.094 0.042 0.098 0.255 0.322   || dis=0.01 || select=7/8
012/019-th : 0.109 0.113 0.117 0.121 0.129 0.127 0.140 0.144  ||  -0.130 -0.097 -0.064 -0.028 0.039 0.018 0.118 0.146   || dis=0.00 || select=7/8
013/019-th : 0.033 0.038 0.049 0.067 0.085 0.127 0.241 0.359  ||  -0.995 -0.857 -0.605 -0.293 -0.059 0.348 0.987 1.384  || dis=0.12 || select=7/8
014/019-th : 0.048 0.053 0.070 0.087 0.115 0.162 0.214 0.251  ||  -0.797 -0.702 -0.425 -0.200 0.077 0.417 0.698 0.858   || dis=0.04 || select=7/8
015/019-th : 0.028 0.031 0.042 0.058 0.089 0.126 0.237 0.388  ||  -1.082 -0.983 -0.690 -0.365 0.061 0.403 1.035 1.528   || dis=0.15 || select=7/8
016/019-th : 0.054 0.074 0.097 0.122 0.132 0.163 0.182 0.176  ||  -0.760 -0.457 -0.182 0.051 0.131 0.340 0.448 0.418    || dis=0.01 || select=6/8
017/019-th : 0.124 0.115 0.121 0.124 0.121 0.123 0.135 0.137  ||  -0.009 -0.082 -0.034 -0.010 -0.034 -0.019 0.074 0.091  || dis=0.00 || select=7/8
018/019-th : 0.084 0.102 0.115 0.123 0.130 0.134 0.140 0.172  ||  -0.377 -0.189 -0.062 0.006 0.058 0.088 0.131 0.337    || dis=0.03 || select=7/8
[epoch=242/600] FLOP : 27.31 MB, ratio : 0.6691, Expected-ratio : 0.7000, Discrepancy : 0.061
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:50:04] [epoch=242/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.765 (1.765)  Prec@1 41.02 (41.02) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:50:10] [epoch=242/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.529 (2.091)  Prec@1 17.26 (41.59) Prec@5 64.29 (84.11) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.59 Prec@5 84.11 Error@1 58.41 Error@5 15.89 Loss:2.091
***[2020-01-29 07:50:10]*** VALID [epoch=242/600] loss = 2.090696, accuracy@1 = 41.59, accuracy@5 = 84.11 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:50:10]*** start epoch=243/600 Time Left: [03:09:42], LR=[0.064702 ~ 0.064702], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=243, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.2703987968191446, FLOP=40.81
[Search] : epoch=243/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:50:11] [epoch=243/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 1.348 (1.348)  Prec@1 51.56 (51.56) Prec@5 95.31 (95.31) Acls-loss 0.909 (0.909) FLOP-Loss 0.000 (0.000) Arch-Loss 0.909 (0.909)
**TRAIN** [2020-01-29 07:50:36] [epoch=243/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.031 (0.793)  Prec@1 66.07 (73.06) Prec@5 95.24 (98.03) Acls-loss 0.616 (0.821) FLOP-Loss 0.000 (-0.056) Arch-Loss 0.616 (0.709)
 **TRAIN** Prec@1 73.06 Prec@5 98.03 Error@1 26.94 Error@5 1.97 Base-Loss:0.793, Arch-Loss=0.709
***[2020-01-29 07:50:36]*** TRAIN [epoch=243/600] base-loss = 0.793306, arch-loss = 0.709143, accuracy-1 = 73.06, accuracy-5 = 98.03
[epoch=243/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 16, 16, 16, 12, 32, 28, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.230272)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.439 0.205 0.356  ||  0.2347 -0.5272 0.0266  || discrepancy=0.08 || select=0/3
001/003-th : 0.362 0.147 0.491  ||  0.0535 -0.8447 0.3575  || discrepancy=0.13 || select=2/3
002/003-th : 0.028 0.124 0.848  ||  -1.7895 -0.2983 1.6263  || discrepancy=0.72 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.077 0.091 0.112 0.134 0.163 0.177 0.193  ||  -0.775 -0.408 -0.234 -0.031 0.152 0.343 0.430 0.512   || dis=0.02 || select=7/8
001/019-th : 0.126 0.124 0.126 0.127 0.125 0.128 0.123 0.120  ||  0.011 -0.005 0.011 0.015 -0.003 0.022 -0.017 -0.040   || dis=0.00 || select=5/8
002/019-th : 0.119 0.125 0.127 0.131 0.130 0.130 0.122 0.115  ||  -0.044 0.003 0.016 0.052 0.041 0.046 -0.022 -0.076    || dis=0.00 || select=3/8
003/019-th : 0.111 0.115 0.125 0.125 0.127 0.132 0.130 0.135  ||  -0.110 -0.079 0.002 0.002 0.024 0.062 0.043 0.080     || dis=0.00 || select=7/8
004/019-th : 0.110 0.115 0.118 0.122 0.132 0.131 0.134 0.138  ||  -0.122 -0.081 -0.054 -0.022 0.058 0.049 0.069 0.099   || dis=0.00 || select=7/8
005/019-th : 0.109 0.116 0.126 0.124 0.130 0.133 0.128 0.134  ||  -0.138 -0.071 0.012 -0.008 0.042 0.068 0.029 0.071    || dis=0.00 || select=7/8
006/019-th : 0.116 0.115 0.115 0.121 0.130 0.136 0.133 0.136  ||  -0.075 -0.082 -0.081 -0.032 0.041 0.088 0.065 0.084   || dis=0.00 || select=5/8
007/019-th : 0.059 0.073 0.092 0.115 0.132 0.148 0.180 0.200  ||  -0.673 -0.453 -0.223 -0.006 0.136 0.250 0.441 0.547   || dis=0.02 || select=7/8
008/019-th : 0.045 0.056 0.078 0.120 0.135 0.172 0.198 0.197  ||  -0.900 -0.679 -0.337 0.086 0.204 0.450 0.588 0.582    || dis=0.00 || select=6/8
009/019-th : 0.093 0.096 0.100 0.119 0.117 0.148 0.157 0.172  ||  -0.276 -0.242 -0.199 -0.029 -0.045 0.189 0.254 0.340  || dis=0.01 || select=7/8
010/019-th : 0.098 0.102 0.114 0.125 0.131 0.133 0.150 0.147  ||  -0.235 -0.191 -0.083 0.006 0.057 0.072 0.195 0.171    || dis=0.00 || select=6/8
011/019-th : 0.096 0.089 0.107 0.112 0.126 0.138 0.160 0.172  ||  -0.234 -0.319 -0.126 -0.086 0.032 0.122 0.273 0.344   || dis=0.01 || select=7/8
012/019-th : 0.108 0.112 0.116 0.119 0.129 0.128 0.141 0.146  ||  -0.145 -0.107 -0.072 -0.045 0.040 0.032 0.128 0.163   || dis=0.01 || select=7/8
013/019-th : 0.033 0.038 0.048 0.067 0.084 0.127 0.243 0.362  ||  -1.003 -0.865 -0.623 -0.293 -0.062 0.351 1.002 1.402  || dis=0.12 || select=7/8
014/019-th : 0.046 0.052 0.070 0.088 0.114 0.161 0.214 0.255  ||  -0.833 -0.705 -0.423 -0.187 0.074 0.418 0.701 0.876   || dis=0.04 || select=7/8
015/019-th : 0.028 0.030 0.042 0.057 0.089 0.124 0.236 0.394  ||  -1.088 -1.005 -0.686 -0.383 0.064 0.402 1.043 1.556   || dis=0.16 || select=7/8
016/019-th : 0.054 0.072 0.095 0.121 0.130 0.163 0.187 0.178  ||  -0.771 -0.474 -0.193 0.041 0.118 0.343 0.478 0.432    || dis=0.01 || select=6/8
017/019-th : 0.120 0.112 0.120 0.123 0.122 0.125 0.137 0.141  ||  -0.040 -0.106 -0.041 -0.020 -0.021 -0.002 0.090 0.120  || dis=0.00 || select=7/8
018/019-th : 0.084 0.102 0.114 0.123 0.128 0.133 0.141 0.175  ||  -0.384 -0.187 -0.069 0.006 0.043 0.077 0.141 0.354    || dis=0.03 || select=7/8
[epoch=243/600] FLOP : 28.23 MB, ratio : 0.6917, Expected-ratio : 0.7000, Discrepancy : 0.063
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:50:36] [epoch=243/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.802 (3.802)  Prec@1 16.80 (16.80) Prec@5 64.84 (64.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:50:42] [epoch=243/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.884 (2.355)  Prec@1 36.31 (36.21) Prec@5 84.52 (80.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.21 Prec@5 80.32 Error@1 63.79 Error@5 19.68 Loss:2.355
***[2020-01-29 07:50:42]*** VALID [epoch=243/600] loss = 2.355424, accuracy@1 = 36.21, accuracy@5 = 80.32 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:50:42]*** start epoch=244/600 Time Left: [03:09:10], LR=[0.064452 ~ 0.064452], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=244, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.2581279025139556, FLOP=40.81
[Search] : epoch=244/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:50:43] [epoch=244/600][000/098] Time 0.82 (0.82) Data 0.38 (0.38) Base-Loss 0.756 (0.756)  Prec@1 75.39 (75.39) Prec@5 96.88 (96.88) Acls-loss 0.933 (0.933) FLOP-Loss 0.000 (0.000) Arch-Loss 0.933 (0.933)
**TRAIN** [2020-01-29 07:51:08] [epoch=244/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.818 (0.791)  Prec@1 69.64 (73.29) Prec@5 98.21 (98.10) Acls-loss 0.922 (0.829) FLOP-Loss 2.733 (0.074) Arch-Loss 6.388 (0.978)
 **TRAIN** Prec@1 73.29 Prec@5 98.10 Error@1 26.71 Error@5 1.90 Base-Loss:0.791, Arch-Loss=0.978
***[2020-01-29 07:51:08]*** TRAIN [epoch=244/600] base-loss = 0.791224, arch-loss = 0.978104, accuracy-1 = 73.29, accuracy-5 = 98.10
[epoch=244/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 11, 16, 16, 16, 12, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.325056)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.208 0.352  ||  0.2419 -0.5102 0.0185  || discrepancy=0.09 || select=0/3
001/003-th : 0.365 0.149 0.487  ||  0.0618 -0.8352 0.3503  || discrepancy=0.12 || select=2/3
002/003-th : 0.027 0.124 0.849  ||  -1.8017 -0.2917 1.6350  || discrepancy=0.72 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.077 0.093 0.112 0.136 0.159 0.176 0.194  ||  -0.781 -0.400 -0.222 -0.035 0.164 0.322 0.423 0.515   || dis=0.02 || select=7/8
001/019-th : 0.127 0.127 0.127 0.127 0.124 0.127 0.122 0.119  ||  0.018 0.014 0.011 0.013 -0.011 0.013 -0.024 -0.048    || dis=0.00 || select=0/8
002/019-th : 0.118 0.125 0.126 0.130 0.131 0.131 0.121 0.116  ||  -0.051 0.006 0.014 0.042 0.053 0.053 -0.027 -0.072    || dis=0.00 || select=4/8
003/019-th : 0.111 0.114 0.124 0.128 0.127 0.132 0.130 0.135  ||  -0.112 -0.087 -0.005 0.026 0.019 0.058 0.041 0.083    || dis=0.00 || select=7/8
004/019-th : 0.110 0.115 0.120 0.118 0.135 0.131 0.134 0.137  ||  -0.127 -0.076 -0.037 -0.052 0.084 0.049 0.072 0.092   || dis=0.00 || select=7/8
005/019-th : 0.110 0.115 0.126 0.121 0.131 0.135 0.127 0.135  ||  -0.130 -0.078 0.013 -0.029 0.045 0.076 0.019 0.077    || dis=0.00 || select=7/8
006/019-th : 0.117 0.116 0.116 0.120 0.130 0.136 0.131 0.135  ||  -0.061 -0.072 -0.071 -0.037 0.042 0.085 0.046 0.078   || dis=0.00 || select=5/8
007/019-th : 0.058 0.073 0.094 0.115 0.134 0.148 0.178 0.199  ||  -0.682 -0.454 -0.206 -0.003 0.145 0.249 0.434 0.541   || dis=0.02 || select=7/8
008/019-th : 0.045 0.056 0.079 0.119 0.135 0.171 0.195 0.200  ||  -0.889 -0.673 -0.333 0.073 0.205 0.437 0.569 0.597    || dis=0.01 || select=7/8
009/019-th : 0.091 0.095 0.102 0.120 0.116 0.148 0.157 0.171  ||  -0.292 -0.249 -0.177 -0.018 -0.049 0.193 0.253 0.339  || dis=0.01 || select=7/8
010/019-th : 0.097 0.102 0.116 0.125 0.132 0.132 0.150 0.145  ||  -0.241 -0.193 -0.062 0.013 0.066 0.065 0.193 0.160    || dis=0.01 || select=6/8
011/019-th : 0.097 0.089 0.108 0.113 0.125 0.137 0.161 0.170  ||  -0.229 -0.311 -0.124 -0.078 0.022 0.118 0.276 0.334   || dis=0.01 || select=7/8
012/019-th : 0.110 0.114 0.116 0.120 0.127 0.128 0.140 0.145  ||  -0.125 -0.088 -0.075 -0.039 0.023 0.028 0.117 0.150   || dis=0.00 || select=7/8
013/019-th : 0.032 0.038 0.048 0.068 0.083 0.128 0.242 0.362  ||  -1.034 -0.854 -0.618 -0.276 -0.076 0.362 1.000 1.402  || dis=0.12 || select=7/8
014/019-th : 0.046 0.053 0.069 0.088 0.114 0.161 0.214 0.254  ||  -0.829 -0.698 -0.428 -0.183 0.075 0.414 0.701 0.871   || dis=0.04 || select=7/8
015/019-th : 0.028 0.030 0.041 0.056 0.088 0.121 0.236 0.398  ||  -1.072 -1.005 -0.690 -0.390 0.065 0.380 1.050 1.571   || dis=0.16 || select=7/8
016/019-th : 0.054 0.072 0.096 0.122 0.132 0.161 0.186 0.176  ||  -0.766 -0.472 -0.190 0.053 0.131 0.332 0.477 0.420    || dis=0.01 || select=6/8
017/019-th : 0.118 0.114 0.120 0.123 0.125 0.125 0.137 0.139  ||  -0.053 -0.094 -0.039 -0.017 0.000 0.002 0.093 0.108   || dis=0.00 || select=7/8
018/019-th : 0.085 0.102 0.115 0.124 0.127 0.132 0.143 0.173  ||  -0.370 -0.182 -0.068 0.007 0.033 0.071 0.151 0.342    || dis=0.03 || select=7/8
[epoch=244/600] FLOP : 27.33 MB, ratio : 0.6695, Expected-ratio : 0.7000, Discrepancy : 0.063
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:51:08] [epoch=244/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.445 (1.445)  Prec@1 47.66 (47.66) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:51:15] [epoch=244/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.558 (2.098)  Prec@1 48.21 (39.61) Prec@5 89.88 (82.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.61 Prec@5 82.94 Error@1 60.39 Error@5 17.06 Loss:2.098
***[2020-01-29 07:51:15]*** VALID [epoch=244/600] loss = 2.098370, accuracy@1 = 39.61, accuracy@5 = 82.94 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:51:15]*** start epoch=245/600 Time Left: [03:08:39], LR=[0.064201 ~ 0.064201], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=245, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.245837594524611, FLOP=40.81
[Search] : epoch=245/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:51:16] [epoch=245/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.744 (0.744)  Prec@1 72.27 (72.27) Prec@5 99.22 (99.22) Acls-loss 0.782 (0.782) FLOP-Loss 0.000 (0.000) Arch-Loss 0.782 (0.782)
**TRAIN** [2020-01-29 07:51:40] [epoch=245/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.677 (0.792)  Prec@1 76.79 (72.84) Prec@5 98.81 (97.94) Acls-loss 0.824 (0.831) FLOP-Loss 0.000 (0.084) Arch-Loss 0.824 (0.998)
 **TRAIN** Prec@1 72.84 Prec@5 97.94 Error@1 27.16 Error@5 2.06 Base-Loss:0.792, Arch-Loss=0.998
***[2020-01-29 07:51:40]*** TRAIN [epoch=245/600] base-loss = 0.792361, arch-loss = 0.998232, accuracy-1 = 72.84, accuracy-5 = 97.94
[epoch=245/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 11, 16, 16, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.1504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.205 0.349  ||  0.2529 -0.5207 0.0101  || discrepancy=0.10 || select=0/3
001/003-th : 0.369 0.147 0.484  ||  0.0732 -0.8469 0.3432  || discrepancy=0.11 || select=2/3
002/003-th : 0.027 0.125 0.848  ||  -1.8098 -0.2801 1.6386  || discrepancy=0.72 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.079 0.092 0.112 0.138 0.159 0.176 0.191  ||  -0.781 -0.384 -0.227 -0.031 0.174 0.319 0.422 0.499   || dis=0.02 || select=7/8
001/019-th : 0.128 0.130 0.129 0.127 0.122 0.124 0.120 0.119  ||  0.025 0.035 0.030 0.016 -0.023 -0.009 -0.040 -0.055   || dis=0.00 || select=1/8
002/019-th : 0.120 0.127 0.129 0.130 0.130 0.129 0.121 0.114  ||  -0.041 0.018 0.030 0.040 0.044 0.036 -0.028 -0.087    || dis=0.00 || select=4/8
003/019-th : 0.112 0.115 0.124 0.128 0.126 0.131 0.130 0.134  ||  -0.109 -0.079 -0.000 0.027 0.012 0.053 0.040 0.076    || dis=0.00 || select=7/8
004/019-th : 0.111 0.117 0.120 0.118 0.134 0.131 0.133 0.137  ||  -0.118 -0.066 -0.041 -0.058 0.071 0.049 0.067 0.092   || dis=0.00 || select=7/8
005/019-th : 0.112 0.118 0.126 0.120 0.130 0.134 0.127 0.133  ||  -0.112 -0.060 0.010 -0.037 0.039 0.069 0.013 0.064    || dis=0.00 || select=5/8
006/019-th : 0.119 0.116 0.116 0.121 0.131 0.134 0.129 0.134  ||  -0.049 -0.075 -0.071 -0.027 0.051 0.073 0.037 0.074   || dis=0.00 || select=7/8
007/019-th : 0.058 0.074 0.095 0.116 0.134 0.147 0.178 0.197  ||  -0.683 -0.443 -0.195 0.001 0.146 0.239 0.427 0.531    || dis=0.02 || select=7/8
008/019-th : 0.045 0.057 0.077 0.120 0.136 0.169 0.193 0.202  ||  -0.893 -0.660 -0.353 0.087 0.208 0.425 0.561 0.608    || dis=0.01 || select=7/8
009/019-th : 0.091 0.095 0.104 0.121 0.116 0.148 0.153 0.172  ||  -0.297 -0.245 -0.162 -0.008 -0.052 0.192 0.229 0.344  || dis=0.02 || select=7/8
010/019-th : 0.098 0.103 0.117 0.126 0.131 0.131 0.149 0.145  ||  -0.232 -0.182 -0.057 0.020 0.056 0.057 0.184 0.155    || dis=0.00 || select=6/8
011/019-th : 0.096 0.090 0.109 0.113 0.125 0.137 0.161 0.169  ||  -0.242 -0.300 -0.111 -0.079 0.022 0.115 0.276 0.328   || dis=0.01 || select=7/8
012/019-th : 0.110 0.115 0.115 0.120 0.128 0.129 0.138 0.145  ||  -0.122 -0.083 -0.080 -0.040 0.029 0.036 0.106 0.149   || dis=0.01 || select=7/8
013/019-th : 0.031 0.039 0.049 0.069 0.082 0.126 0.240 0.365  ||  -1.058 -0.836 -0.605 -0.259 -0.079 0.346 0.992 1.411  || dis=0.12 || select=7/8
014/019-th : 0.045 0.053 0.069 0.087 0.115 0.160 0.217 0.254  ||  -0.851 -0.685 -0.431 -0.201 0.082 0.414 0.719 0.875   || dis=0.04 || select=7/8
015/019-th : 0.029 0.030 0.041 0.055 0.090 0.119 0.239 0.396  ||  -1.061 -1.001 -0.692 -0.403 0.081 0.364 1.061 1.566   || dis=0.16 || select=7/8
016/019-th : 0.055 0.073 0.097 0.124 0.133 0.159 0.184 0.174  ||  -0.748 -0.465 -0.183 0.069 0.137 0.316 0.461 0.407    || dis=0.01 || select=6/8
017/019-th : 0.120 0.114 0.121 0.124 0.124 0.125 0.134 0.138  ||  -0.040 -0.093 -0.034 -0.003 -0.004 -0.001 0.073 0.103  || dis=0.00 || select=7/8
018/019-th : 0.085 0.102 0.116 0.125 0.128 0.131 0.142 0.171  ||  -0.368 -0.181 -0.057 0.018 0.042 0.068 0.142 0.331    || dis=0.03 || select=7/8
[epoch=245/600] FLOP : 28.15 MB, ratio : 0.6897, Expected-ratio : 0.7000, Discrepancy : 0.063
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:51:41] [epoch=245/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.789 (1.789)  Prec@1 44.92 (44.92) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:51:47] [epoch=245/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.787 (2.321)  Prec@1 43.45 (37.18) Prec@5 88.10 (81.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.18 Prec@5 81.16 Error@1 62.82 Error@5 18.84 Loss:2.321
***[2020-01-29 07:51:47]*** VALID [epoch=245/600] loss = 2.321205, accuracy@1 = 37.18, accuracy@5 = 81.16 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:51:47]*** start epoch=246/600 Time Left: [03:08:08], LR=[0.063950 ~ 0.063950], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=246, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.233528209796112, FLOP=40.81
[Search] : epoch=246/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:51:47] [epoch=246/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.706 (0.706)  Prec@1 73.44 (73.44) Prec@5 98.44 (98.44) Acls-loss 0.910 (0.910) FLOP-Loss 0.000 (0.000) Arch-Loss 0.910 (0.910)
**TRAIN** [2020-01-29 07:52:12] [epoch=246/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.833 (0.796)  Prec@1 66.67 (72.87) Prec@5 97.62 (97.89) Acls-loss 0.848 (0.827) FLOP-Loss 0.000 (0.000) Arch-Loss 0.848 (0.827)
 **TRAIN** Prec@1 72.87 Prec@5 97.89 Error@1 27.13 Error@5 2.11 Base-Loss:0.796, Arch-Loss=0.827
***[2020-01-29 07:52:12]*** TRAIN [epoch=246/600] base-loss = 0.796049, arch-loss = 0.826758, accuracy-1 = 72.87, accuracy-5 = 97.89
[epoch=246/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 11, 16, 16, 16, 12, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.82272)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.204 0.356  ||  0.2400 -0.5301 0.0264  || discrepancy=0.08 || select=0/3
001/003-th : 0.365 0.146 0.489  ||  0.0627 -0.8555 0.3565  || discrepancy=0.12 || select=2/3
002/003-th : 0.026 0.121 0.853  ||  -1.8190 -0.2992 1.6569  || discrepancy=0.73 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.080 0.092 0.112 0.137 0.157 0.177 0.193  ||  -0.782 -0.373 -0.235 -0.029 0.169 0.302 0.424 0.510   || dis=0.02 || select=7/8
001/019-th : 0.126 0.129 0.128 0.126 0.125 0.125 0.121 0.120  ||  0.007 0.031 0.022 0.010 -0.001 -0.001 -0.034 -0.043   || dis=0.00 || select=1/8
002/019-th : 0.118 0.126 0.128 0.129 0.131 0.130 0.123 0.115  ||  -0.055 0.009 0.026 0.033 0.050 0.039 -0.011 -0.077    || dis=0.00 || select=4/8
003/019-th : 0.110 0.114 0.124 0.128 0.126 0.133 0.131 0.135  ||  -0.125 -0.085 -0.006 0.031 0.014 0.066 0.053 0.082    || dis=0.00 || select=7/8
004/019-th : 0.110 0.116 0.118 0.118 0.134 0.132 0.135 0.138  ||  -0.127 -0.070 -0.058 -0.055 0.068 0.056 0.079 0.100   || dis=0.00 || select=7/8
005/019-th : 0.111 0.117 0.126 0.120 0.129 0.134 0.128 0.136  ||  -0.120 -0.070 0.004 -0.044 0.031 0.072 0.021 0.085    || dis=0.00 || select=7/8
006/019-th : 0.117 0.115 0.114 0.120 0.132 0.136 0.132 0.135  ||  -0.063 -0.082 -0.089 -0.039 0.057 0.087 0.058 0.079   || dis=0.00 || select=5/8
007/019-th : 0.058 0.073 0.095 0.113 0.134 0.146 0.181 0.200  ||  -0.682 -0.461 -0.196 -0.023 0.147 0.234 0.452 0.549   || dis=0.02 || select=7/8
008/019-th : 0.045 0.056 0.077 0.119 0.135 0.167 0.196 0.206  ||  -0.901 -0.673 -0.360 0.080 0.204 0.422 0.582 0.627    || dis=0.01 || select=7/8
009/019-th : 0.090 0.094 0.104 0.121 0.117 0.146 0.155 0.174  ||  -0.305 -0.257 -0.156 -0.011 -0.044 0.179 0.241 0.355  || dis=0.02 || select=7/8
010/019-th : 0.098 0.102 0.115 0.126 0.132 0.134 0.148 0.145  ||  -0.231 -0.190 -0.069 0.017 0.066 0.079 0.176 0.157    || dis=0.00 || select=6/8
011/019-th : 0.094 0.089 0.109 0.113 0.125 0.139 0.159 0.171  ||  -0.257 -0.309 -0.115 -0.074 0.030 0.130 0.269 0.339   || dis=0.01 || select=7/8
012/019-th : 0.109 0.112 0.114 0.120 0.129 0.131 0.138 0.146  ||  -0.129 -0.104 -0.086 -0.038 0.036 0.055 0.105 0.159   || dis=0.01 || select=7/8
013/019-th : 0.031 0.038 0.049 0.067 0.081 0.127 0.239 0.367  ||  -1.063 -0.839 -0.595 -0.277 -0.089 0.359 0.993 1.421  || dis=0.13 || select=7/8
014/019-th : 0.041 0.053 0.069 0.087 0.114 0.159 0.222 0.255  ||  -0.929 -0.681 -0.416 -0.183 0.086 0.414 0.749 0.888   || dis=0.03 || select=7/8
015/019-th : 0.029 0.030 0.041 0.055 0.088 0.117 0.241 0.399  ||  -1.054 -1.012 -0.692 -0.407 0.072 0.354 1.075 1.581   || dis=0.16 || select=7/8
016/019-th : 0.054 0.072 0.095 0.124 0.132 0.160 0.187 0.175  ||  -0.755 -0.470 -0.201 0.068 0.134 0.326 0.476 0.412    || dis=0.01 || select=6/8
017/019-th : 0.118 0.113 0.118 0.124 0.126 0.125 0.136 0.139  ||  -0.051 -0.099 -0.053 -0.003 0.008 0.004 0.090 0.109   || dis=0.00 || select=7/8
018/019-th : 0.084 0.101 0.118 0.125 0.128 0.131 0.142 0.171  ||  -0.378 -0.190 -0.042 0.018 0.043 0.067 0.149 0.331    || dis=0.03 || select=7/8
[epoch=246/600] FLOP : 27.82 MB, ratio : 0.6817, Expected-ratio : 0.7000, Discrepancy : 0.064
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:52:12] [epoch=246/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.168 (2.168)  Prec@1 26.56 (26.56) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:52:18] [epoch=246/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.671 (2.245)  Prec@1 48.81 (40.02) Prec@5 83.93 (83.23) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.02 Prec@5 83.23 Error@1 59.98 Error@5 16.77 Loss:2.245
***[2020-01-29 07:52:18]*** VALID [epoch=246/600] loss = 2.245302, accuracy@1 = 40.02, accuracy@5 = 83.23 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:52:18]*** start epoch=247/600 Time Left: [03:07:35], LR=[0.063698 ~ 0.063698], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=247, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.22120008579646, FLOP=40.81
[Search] : epoch=247/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:52:19] [epoch=247/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.814 (0.814)  Prec@1 71.88 (71.88) Prec@5 97.27 (97.27) Acls-loss 0.909 (0.909) FLOP-Loss 0.000 (0.000) Arch-Loss 0.909 (0.909)
**TRAIN** [2020-01-29 07:52:43] [epoch=247/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 0.701 (0.808)  Prec@1 75.00 (72.30) Prec@5 98.21 (97.83) Acls-loss 0.811 (0.840) FLOP-Loss 0.000 (0.000) Arch-Loss 0.811 (0.840)
 **TRAIN** Prec@1 72.30 Prec@5 97.83 Error@1 27.70 Error@5 2.17 Base-Loss:0.808, Arch-Loss=0.840
***[2020-01-29 07:52:43]*** TRAIN [epoch=247/600] base-loss = 0.808363, arch-loss = 0.839608, accuracy-1 = 72.30, accuracy-5 = 97.83
[epoch=247/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 12, 16, 16, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.22208)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.203 0.360  ||  0.2319 -0.5360 0.0374  || discrepancy=0.08 || select=0/3
001/003-th : 0.361 0.144 0.494  ||  0.0545 -0.8644 0.3679  || discrepancy=0.13 || select=2/3
002/003-th : 0.026 0.117 0.857  ||  -1.8243 -0.3208 1.6736  || discrepancy=0.74 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.078 0.090 0.112 0.141 0.154 0.176 0.197  ||  -0.783 -0.393 -0.252 -0.031 0.198 0.287 0.424 0.532   || dis=0.02 || select=7/8
001/019-th : 0.125 0.128 0.125 0.125 0.125 0.128 0.122 0.122  ||  0.000 0.023 0.001 0.001 -0.000 0.019 -0.027 -0.029    || dis=0.00 || select=1/8
002/019-th : 0.117 0.123 0.126 0.129 0.132 0.132 0.125 0.116  ||  -0.066 -0.010 0.007 0.031 0.059 0.059 0.004 -0.067    || dis=0.00 || select=5/8
003/019-th : 0.108 0.114 0.122 0.129 0.127 0.133 0.132 0.135  ||  -0.138 -0.087 -0.015 0.036 0.022 0.067 0.061 0.087    || dis=0.00 || select=7/8
004/019-th : 0.110 0.115 0.117 0.118 0.134 0.133 0.136 0.138  ||  -0.126 -0.084 -0.066 -0.055 0.072 0.067 0.084 0.101   || dis=0.00 || select=7/8
005/019-th : 0.109 0.116 0.125 0.120 0.130 0.135 0.129 0.137  ||  -0.132 -0.078 -0.002 -0.038 0.036 0.076 0.032 0.092   || dis=0.00 || select=7/8
006/019-th : 0.116 0.113 0.113 0.121 0.130 0.137 0.133 0.137  ||  -0.074 -0.095 -0.102 -0.028 0.046 0.094 0.063 0.095   || dis=0.00 || select=7/8
007/019-th : 0.058 0.073 0.093 0.111 0.132 0.146 0.182 0.204  ||  -0.686 -0.452 -0.212 -0.036 0.138 0.235 0.458 0.569   || dis=0.02 || select=7/8
008/019-th : 0.044 0.056 0.076 0.120 0.135 0.168 0.197 0.205  ||  -0.902 -0.675 -0.371 0.088 0.209 0.427 0.586 0.624    || dis=0.01 || select=7/8
009/019-th : 0.088 0.094 0.105 0.120 0.116 0.145 0.157 0.175  ||  -0.328 -0.261 -0.149 -0.014 -0.044 0.178 0.255 0.367  || dis=0.02 || select=7/8
010/019-th : 0.097 0.102 0.112 0.128 0.133 0.135 0.148 0.145  ||  -0.243 -0.188 -0.099 0.037 0.075 0.088 0.179 0.159    || dis=0.00 || select=6/8
011/019-th : 0.093 0.088 0.106 0.115 0.124 0.140 0.161 0.173  ||  -0.263 -0.320 -0.140 -0.060 0.020 0.141 0.280 0.353   || dis=0.01 || select=7/8
012/019-th : 0.109 0.111 0.114 0.118 0.128 0.130 0.141 0.148  ||  -0.131 -0.116 -0.089 -0.055 0.027 0.044 0.125 0.174   || dis=0.01 || select=7/8
013/019-th : 0.030 0.037 0.049 0.067 0.081 0.124 0.242 0.369  ||  -1.076 -0.857 -0.587 -0.277 -0.081 0.345 1.010 1.433  || dis=0.13 || select=7/8
014/019-th : 0.041 0.053 0.068 0.087 0.111 0.160 0.220 0.260  ||  -0.940 -0.676 -0.429 -0.180 0.063 0.430 0.748 0.912   || dis=0.04 || select=7/8
015/019-th : 0.028 0.030 0.042 0.054 0.087 0.116 0.240 0.404  ||  -1.074 -1.015 -0.675 -0.409 0.058 0.354 1.075 1.597   || dis=0.16 || select=7/8
016/019-th : 0.055 0.072 0.095 0.123 0.130 0.162 0.188 0.174  ||  -0.748 -0.474 -0.196 0.061 0.117 0.336 0.485 0.407    || dis=0.01 || select=6/8
017/019-th : 0.118 0.112 0.118 0.124 0.125 0.125 0.137 0.140  ||  -0.054 -0.106 -0.052 -0.002 0.001 0.003 0.091 0.119   || dis=0.00 || select=7/8
018/019-th : 0.084 0.102 0.118 0.124 0.127 0.131 0.142 0.172  ||  -0.383 -0.187 -0.041 0.010 0.039 0.069 0.146 0.340    || dis=0.03 || select=7/8
[epoch=247/600] FLOP : 28.22 MB, ratio : 0.6915, Expected-ratio : 0.7000, Discrepancy : 0.065
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:52:44] [epoch=247/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.740 (1.740)  Prec@1 41.02 (41.02) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:52:50] [epoch=247/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.167 (2.369)  Prec@1 32.74 (39.14) Prec@5 77.98 (82.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.14 Prec@5 82.58 Error@1 60.86 Error@5 17.42 Loss:2.369
***[2020-01-29 07:52:50]*** VALID [epoch=247/600] loss = 2.368778, accuracy@1 = 39.14, accuracy@5 = 82.58 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:52:50]*** start epoch=248/600 Time Left: [03:07:03], LR=[0.063446 ~ 0.063446], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=248, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.2088535605074013, FLOP=40.81
[Search] : epoch=248/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:52:50] [epoch=248/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.748 (0.748)  Prec@1 73.05 (73.05) Prec@5 98.05 (98.05) Acls-loss 0.928 (0.928) FLOP-Loss 0.000 (0.000) Arch-Loss 0.928 (0.928)
**TRAIN** [2020-01-29 07:53:15] [epoch=248/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.697 (0.801)  Prec@1 75.60 (72.74) Prec@5 98.81 (97.89) Acls-loss 0.736 (0.870) FLOP-Loss 0.000 (0.084) Arch-Loss 0.736 (1.038)
 **TRAIN** Prec@1 72.74 Prec@5 97.89 Error@1 27.26 Error@5 2.11 Base-Loss:0.801, Arch-Loss=1.038
***[2020-01-29 07:53:15]*** TRAIN [epoch=248/600] base-loss = 0.800871, arch-loss = 1.038191, accuracy-1 = 72.74, accuracy-5 = 97.89
[epoch=248/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 12, 16, 16, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.22208)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.439 0.204 0.357  ||  0.2386 -0.5285 0.0310  || discrepancy=0.08 || select=0/3
001/003-th : 0.364 0.142 0.494  ||  0.0600 -0.8804 0.3674  || discrepancy=0.13 || select=2/3
002/003-th : 0.026 0.117 0.857  ||  -1.8195 -0.3192 1.6732  || discrepancy=0.74 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.077 0.093 0.110 0.142 0.155 0.173 0.197  ||  -0.767 -0.407 -0.220 -0.051 0.201 0.289 0.401 0.533   || dis=0.02 || select=7/8
001/019-th : 0.126 0.128 0.126 0.125 0.123 0.128 0.122 0.121  ||  0.008 0.022 0.008 0.000 -0.020 0.022 -0.023 -0.038    || dis=0.00 || select=1/8
002/019-th : 0.118 0.124 0.125 0.129 0.132 0.132 0.124 0.115  ||  -0.057 -0.002 0.003 0.034 0.058 0.061 -0.003 -0.078   || dis=0.00 || select=5/8
003/019-th : 0.109 0.114 0.122 0.128 0.127 0.133 0.132 0.134  ||  -0.127 -0.082 -0.020 0.031 0.025 0.067 0.061 0.076    || dis=0.00 || select=7/8
004/019-th : 0.110 0.115 0.117 0.117 0.133 0.136 0.135 0.138  ||  -0.126 -0.083 -0.066 -0.060 0.063 0.086 0.081 0.100   || dis=0.00 || select=7/8
005/019-th : 0.110 0.117 0.122 0.122 0.129 0.134 0.129 0.137  ||  -0.125 -0.067 -0.028 -0.024 0.028 0.070 0.033 0.095   || dis=0.00 || select=7/8
006/019-th : 0.116 0.113 0.114 0.122 0.128 0.136 0.134 0.138  ||  -0.072 -0.102 -0.089 -0.023 0.027 0.083 0.068 0.100   || dis=0.00 || select=7/8
007/019-th : 0.058 0.073 0.093 0.111 0.133 0.146 0.183 0.204  ||  -0.689 -0.459 -0.212 -0.039 0.146 0.237 0.461 0.572   || dis=0.02 || select=7/8
008/019-th : 0.045 0.055 0.075 0.119 0.136 0.167 0.198 0.205  ||  -0.895 -0.685 -0.372 0.086 0.214 0.420 0.592 0.627    || dis=0.01 || select=7/8
009/019-th : 0.089 0.092 0.104 0.121 0.117 0.144 0.157 0.176  ||  -0.312 -0.274 -0.153 -0.008 -0.041 0.171 0.253 0.369  || dis=0.02 || select=7/8
010/019-th : 0.097 0.104 0.113 0.128 0.134 0.135 0.147 0.143  ||  -0.246 -0.177 -0.092 0.035 0.079 0.088 0.175 0.148    || dis=0.00 || select=6/8
011/019-th : 0.095 0.090 0.104 0.114 0.126 0.139 0.159 0.172  ||  -0.245 -0.306 -0.157 -0.063 0.035 0.129 0.269 0.346   || dis=0.01 || select=7/8
012/019-th : 0.109 0.112 0.114 0.118 0.127 0.131 0.143 0.146  ||  -0.136 -0.109 -0.084 -0.052 0.023 0.051 0.138 0.159   || dis=0.00 || select=7/8
013/019-th : 0.030 0.038 0.049 0.067 0.081 0.124 0.244 0.368  ||  -1.091 -0.850 -0.594 -0.275 -0.080 0.346 1.023 1.432  || dis=0.12 || select=7/8
014/019-th : 0.039 0.053 0.068 0.087 0.111 0.162 0.220 0.260  ||  -0.973 -0.676 -0.422 -0.174 0.068 0.446 0.753 0.919   || dis=0.04 || select=7/8
015/019-th : 0.026 0.030 0.042 0.054 0.086 0.117 0.238 0.406  ||  -1.137 -0.992 -0.654 -0.405 0.055 0.363 1.073 1.608   || dis=0.17 || select=7/8
016/019-th : 0.055 0.072 0.097 0.125 0.134 0.161 0.183 0.172  ||  -0.743 -0.477 -0.175 0.074 0.144 0.329 0.456 0.395    || dis=0.01 || select=6/8
017/019-th : 0.119 0.112 0.118 0.124 0.128 0.124 0.135 0.139  ||  -0.042 -0.103 -0.054 -0.006 0.023 -0.003 0.081 0.110  || dis=0.00 || select=7/8
018/019-th : 0.085 0.103 0.118 0.125 0.128 0.129 0.142 0.171  ||  -0.370 -0.177 -0.041 0.017 0.042 0.050 0.147 0.330    || dis=0.03 || select=7/8
[epoch=248/600] FLOP : 28.22 MB, ratio : 0.6915, Expected-ratio : 0.7000, Discrepancy : 0.065
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:53:16] [epoch=248/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.425 (1.425)  Prec@1 50.78 (50.78) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:53:22] [epoch=248/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.962 (2.161)  Prec@1 47.62 (40.67) Prec@5 89.29 (84.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.67 Prec@5 84.30 Error@1 59.33 Error@5 15.70 Loss:2.161
***[2020-01-29 07:53:22]*** VALID [epoch=248/600] loss = 2.160559, accuracy@1 = 40.67, accuracy@5 = 84.30 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:53:22]*** start epoch=249/600 Time Left: [03:06:31], LR=[0.063194 ~ 0.063194], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=249, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.196488972415164, FLOP=40.81
[Search] : epoch=249/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:53:22] [epoch=249/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.875 (0.875)  Prec@1 72.27 (72.27) Prec@5 97.27 (97.27) Acls-loss 0.747 (0.747) FLOP-Loss 0.000 (0.000) Arch-Loss 0.747 (0.747)
**TRAIN** [2020-01-29 07:53:48] [epoch=249/600][097/098] Time 0.27 (0.27) Data 0.00 (0.00) Base-Loss 0.787 (0.783)  Prec@1 76.79 (73.31) Prec@5 98.81 (98.05) Acls-loss 0.849 (0.828) FLOP-Loss 0.000 (0.084) Arch-Loss 0.849 (0.996)
 **TRAIN** Prec@1 73.31 Prec@5 98.05 Error@1 26.69 Error@5 1.95 Base-Loss:0.783, Arch-Loss=0.996
***[2020-01-29 07:53:48]*** TRAIN [epoch=249/600] base-loss = 0.783031, arch-loss = 0.995796, accuracy-1 = 73.31, accuracy-5 = 98.05
[epoch=249/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 11, 12, 16, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.1504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.202 0.354  ||  0.2496 -0.5362 0.0226  || discrepancy=0.09 || select=0/3
001/003-th : 0.365 0.140 0.495  ||  0.0636 -0.8957 0.3685  || discrepancy=0.13 || select=2/3
002/003-th : 0.025 0.114 0.861  ||  -1.8447 -0.3255 1.6970  || discrepancy=0.75 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.077 0.095 0.111 0.140 0.153 0.173 0.197  ||  -0.764 -0.412 -0.200 -0.039 0.190 0.276 0.401 0.528   || dis=0.02 || select=7/8
001/019-th : 0.128 0.128 0.127 0.125 0.123 0.128 0.121 0.120  ||  0.021 0.024 0.011 -0.007 -0.020 0.017 -0.032 -0.042   || dis=0.00 || select=1/8
002/019-th : 0.118 0.124 0.126 0.129 0.132 0.131 0.124 0.115  ||  -0.051 -0.004 0.009 0.039 0.060 0.054 -0.006 -0.082   || dis=0.00 || select=4/8
003/019-th : 0.112 0.114 0.123 0.127 0.129 0.133 0.131 0.133  ||  -0.107 -0.091 -0.014 0.023 0.034 0.066 0.049 0.065    || dis=0.00 || select=5/8
004/019-th : 0.112 0.116 0.118 0.119 0.129 0.135 0.134 0.136  ||  -0.110 -0.071 -0.054 -0.045 0.036 0.075 0.073 0.089   || dis=0.00 || select=7/8
005/019-th : 0.111 0.117 0.122 0.124 0.127 0.134 0.128 0.137  ||  -0.123 -0.069 -0.024 -0.010 0.018 0.073 0.024 0.095   || dis=0.00 || select=7/8
006/019-th : 0.117 0.114 0.116 0.122 0.129 0.134 0.132 0.136  ||  -0.064 -0.091 -0.076 -0.022 0.035 0.075 0.054 0.090   || dis=0.00 || select=7/8
007/019-th : 0.058 0.073 0.092 0.111 0.137 0.145 0.181 0.204  ||  -0.684 -0.455 -0.229 -0.036 0.172 0.229 0.451 0.569   || dis=0.02 || select=7/8
008/019-th : 0.045 0.055 0.075 0.120 0.137 0.167 0.197 0.203  ||  -0.892 -0.682 -0.378 0.095 0.225 0.421 0.586 0.617    || dis=0.01 || select=7/8
009/019-th : 0.091 0.093 0.105 0.120 0.117 0.144 0.155 0.175  ||  -0.294 -0.271 -0.151 -0.013 -0.044 0.170 0.243 0.361  || dis=0.02 || select=7/8
010/019-th : 0.096 0.104 0.112 0.128 0.135 0.135 0.145 0.144  ||  -0.247 -0.175 -0.094 0.038 0.089 0.092 0.159 0.150    || dis=0.00 || select=6/8
011/019-th : 0.095 0.091 0.106 0.113 0.126 0.137 0.159 0.172  ||  -0.246 -0.293 -0.139 -0.073 0.036 0.116 0.262 0.342   || dis=0.01 || select=7/8
012/019-th : 0.108 0.111 0.115 0.117 0.129 0.131 0.142 0.146  ||  -0.139 -0.109 -0.081 -0.062 0.040 0.055 0.136 0.157   || dis=0.00 || select=7/8
013/019-th : 0.029 0.037 0.048 0.067 0.081 0.123 0.244 0.371  ||  -1.091 -0.852 -0.593 -0.270 -0.081 0.336 1.022 1.442  || dis=0.13 || select=7/8
014/019-th : 0.039 0.053 0.068 0.087 0.111 0.163 0.220 0.259  ||  -0.977 -0.677 -0.415 -0.175 0.069 0.451 0.754 0.916   || dis=0.04 || select=7/8
015/019-th : 0.026 0.030 0.042 0.054 0.086 0.117 0.236 0.410  ||  -1.135 -1.004 -0.655 -0.407 0.057 0.368 1.067 1.620   || dis=0.17 || select=7/8
016/019-th : 0.055 0.073 0.099 0.125 0.136 0.163 0.180 0.171  ||  -0.745 -0.465 -0.163 0.070 0.155 0.336 0.436 0.387    || dis=0.01 || select=6/8
017/019-th : 0.119 0.114 0.117 0.126 0.128 0.125 0.133 0.138  ||  -0.044 -0.090 -0.060 0.015 0.026 0.001 0.068 0.101    || dis=0.01 || select=7/8
018/019-th : 0.087 0.103 0.117 0.126 0.128 0.129 0.143 0.169  ||  -0.347 -0.179 -0.050 0.023 0.039 0.047 0.150 0.317    || dis=0.03 || select=7/8
[epoch=249/600] FLOP : 28.15 MB, ratio : 0.6897, Expected-ratio : 0.7000, Discrepancy : 0.066
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:53:49] [epoch=249/600][000/098] Time 0.40 (0.40) Data 0.30 (0.30) Loss 2.402 (2.402)  Prec@1 39.45 (39.45) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:53:55] [epoch=249/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.478 (2.285)  Prec@1 42.26 (41.10) Prec@5 88.69 (84.15) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.10 Prec@5 84.15 Error@1 58.90 Error@5 15.85 Loss:2.285
***[2020-01-29 07:53:55]*** VALID [epoch=249/600] loss = 2.285423, accuracy@1 = 41.10, accuracy@5 = 84.15 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:53:56]*** start epoch=250/600 Time Left: [03:06:02], LR=[0.062941 ~ 0.062941], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=250, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.1841066605011763, FLOP=40.81
[Search] : epoch=250/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:53:56] [epoch=250/600][000/098] Time 0.76 (0.76) Data 0.36 (0.36) Base-Loss 0.711 (0.711)  Prec@1 77.34 (77.34) Prec@5 98.05 (98.05) Acls-loss 0.926 (0.926) FLOP-Loss 0.000 (0.000) Arch-Loss 0.926 (0.926)
**TRAIN** [2020-01-29 07:54:21] [epoch=250/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.720 (0.806)  Prec@1 72.62 (72.41) Prec@5 98.81 (97.97) Acls-loss 0.848 (0.820) FLOP-Loss 0.000 (0.056) Arch-Loss 0.848 (0.932)
 **TRAIN** Prec@1 72.41 Prec@5 97.97 Error@1 27.59 Error@5 2.03 Base-Loss:0.806, Arch-Loss=0.932
***[2020-01-29 07:54:21]*** TRAIN [epoch=250/600] base-loss = 0.805681, arch-loss = 0.931805, accuracy-1 = 72.41, accuracy-5 = 97.97
[epoch=250/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 12, 16, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.705984)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.201 0.353  ||  0.2533 -0.5404 0.0209  || discrepancy=0.09 || select=0/3
001/003-th : 0.365 0.140 0.495  ||  0.0643 -0.8917 0.3696  || discrepancy=0.13 || select=2/3
002/003-th : 0.024 0.112 0.864  ||  -1.8658 -0.3289 1.7169  || discrepancy=0.75 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.077 0.097 0.113 0.140 0.151 0.174 0.195  ||  -0.773 -0.409 -0.183 -0.026 0.185 0.266 0.406 0.519   || dis=0.02 || select=7/8
001/019-th : 0.128 0.128 0.128 0.125 0.124 0.127 0.121 0.120  ||  0.024 0.019 0.020 -0.002 -0.013 0.013 -0.037 -0.043   || dis=0.00 || select=0/8
002/019-th : 0.117 0.124 0.126 0.130 0.131 0.133 0.124 0.115  ||  -0.059 -0.009 0.008 0.041 0.053 0.063 -0.002 -0.077   || dis=0.00 || select=5/8
003/019-th : 0.111 0.115 0.122 0.128 0.129 0.133 0.129 0.132  ||  -0.112 -0.080 -0.018 0.033 0.035 0.069 0.041 0.061    || dis=0.00 || select=5/8
004/019-th : 0.112 0.116 0.118 0.119 0.129 0.136 0.134 0.137  ||  -0.109 -0.075 -0.055 -0.048 0.033 0.083 0.074 0.090   || dis=0.00 || select=7/8
005/019-th : 0.110 0.116 0.122 0.124 0.128 0.134 0.128 0.138  ||  -0.127 -0.071 -0.025 -0.003 0.023 0.071 0.024 0.098   || dis=0.00 || select=7/8
006/019-th : 0.118 0.114 0.117 0.122 0.128 0.133 0.132 0.136  ||  -0.057 -0.090 -0.060 -0.027 0.023 0.063 0.057 0.088   || dis=0.00 || select=7/8
007/019-th : 0.059 0.072 0.093 0.112 0.135 0.144 0.180 0.206  ||  -0.675 -0.475 -0.217 -0.031 0.159 0.224 0.443 0.582   || dis=0.03 || select=7/8
008/019-th : 0.045 0.056 0.075 0.118 0.136 0.169 0.197 0.204  ||  -0.882 -0.674 -0.384 0.076 0.212 0.434 0.588 0.619    || dis=0.01 || select=7/8
009/019-th : 0.091 0.094 0.106 0.120 0.116 0.145 0.155 0.175  ||  -0.290 -0.263 -0.144 -0.020 -0.054 0.170 0.237 0.361  || dis=0.02 || select=7/8
010/019-th : 0.097 0.102 0.112 0.128 0.133 0.136 0.146 0.145  ||  -0.243 -0.187 -0.100 0.037 0.077 0.099 0.166 0.159    || dis=0.00 || select=6/8
011/019-th : 0.096 0.091 0.106 0.114 0.127 0.136 0.156 0.172  ||  -0.240 -0.293 -0.140 -0.067 0.041 0.111 0.247 0.345   || dis=0.02 || select=7/8
012/019-th : 0.108 0.110 0.115 0.117 0.131 0.131 0.143 0.146  ||  -0.140 -0.123 -0.078 -0.063 0.056 0.051 0.138 0.159   || dis=0.00 || select=7/8
013/019-th : 0.029 0.038 0.049 0.067 0.081 0.123 0.243 0.370  ||  -1.109 -0.843 -0.589 -0.272 -0.076 0.342 1.021 1.441  || dis=0.13 || select=7/8
014/019-th : 0.039 0.053 0.069 0.087 0.110 0.160 0.221 0.261  ||  -0.977 -0.673 -0.408 -0.176 0.062 0.434 0.758 0.925   || dis=0.04 || select=7/8
015/019-th : 0.026 0.029 0.043 0.054 0.085 0.117 0.237 0.409  ||  -1.151 -1.023 -0.633 -0.399 0.050 0.369 1.078 1.620   || dis=0.17 || select=7/8
016/019-th : 0.055 0.073 0.099 0.125 0.136 0.162 0.179 0.171  ||  -0.751 -0.461 -0.161 0.076 0.158 0.330 0.434 0.386    || dis=0.01 || select=6/8
017/019-th : 0.119 0.114 0.116 0.126 0.130 0.124 0.134 0.137  ||  -0.045 -0.088 -0.069 0.014 0.041 -0.001 0.077 0.093   || dis=0.00 || select=7/8
018/019-th : 0.086 0.103 0.117 0.126 0.129 0.129 0.143 0.168  ||  -0.355 -0.173 -0.048 0.026 0.047 0.047 0.151 0.312    || dis=0.03 || select=7/8
[epoch=250/600] FLOP : 27.71 MB, ratio : 0.6788, Expected-ratio : 0.7000, Discrepancy : 0.066
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:54:21] [epoch=250/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.722 (2.722)  Prec@1 19.14 (19.14) Prec@5 63.67 (63.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:54:27] [epoch=250/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.816 (2.371)  Prec@1 43.45 (37.61) Prec@5 77.98 (80.69) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.61 Prec@5 80.69 Error@1 62.39 Error@5 19.31 Loss:2.371
***[2020-01-29 07:54:27]*** VALID [epoch=250/600] loss = 2.371373, accuracy@1 = 37.61, accuracy@5 = 80.69 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:54:27]*** start epoch=251/600 Time Left: [03:05:30], LR=[0.062688 ~ 0.062688], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=251, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.1717069642327744, FLOP=40.81
[Search] : epoch=251/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:54:28] [epoch=251/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.778 (0.778)  Prec@1 75.39 (75.39) Prec@5 97.66 (97.66) Acls-loss 0.795 (0.795) FLOP-Loss 0.000 (0.000) Arch-Loss 0.795 (0.795)
**TRAIN** [2020-01-29 07:54:53] [epoch=251/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.670 (0.778)  Prec@1 79.76 (73.46) Prec@5 98.81 (97.96) Acls-loss 0.820 (0.830) FLOP-Loss 0.000 (0.000) Arch-Loss 0.820 (0.830)
 **TRAIN** Prec@1 73.46 Prec@5 97.96 Error@1 26.54 Error@5 2.04 Base-Loss:0.778, Arch-Loss=0.830
***[2020-01-29 07:54:53]*** TRAIN [epoch=251/600] base-loss = 0.777613, arch-loss = 0.829812, accuracy-1 = 73.46, accuracy-5 = 97.96
[epoch=251/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 12, 12, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.353152)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.439 0.199 0.361  ||  0.2372 -0.5537 0.0413  || discrepancy=0.08 || select=0/3
001/003-th : 0.359 0.140 0.501  ||  0.0515 -0.8877 0.3835  || discrepancy=0.14 || select=2/3
002/003-th : 0.023 0.109 0.868  ||  -1.8765 -0.3437 1.7345  || discrepancy=0.76 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.077 0.095 0.110 0.140 0.153 0.175 0.197  ||  -0.773 -0.406 -0.203 -0.047 0.187 0.277 0.413 0.532   || dis=0.02 || select=7/8
001/019-th : 0.128 0.128 0.125 0.124 0.124 0.127 0.121 0.123  ||  0.020 0.020 -0.007 -0.012 -0.015 0.013 -0.035 -0.023  || dis=0.00 || select=1/8
002/019-th : 0.116 0.123 0.124 0.131 0.131 0.133 0.125 0.116  ||  -0.072 -0.010 -0.001 0.052 0.051 0.070 0.005 -0.070   || dis=0.00 || select=5/8
003/019-th : 0.110 0.113 0.122 0.127 0.132 0.133 0.130 0.133  ||  -0.118 -0.095 -0.021 0.024 0.061 0.072 0.046 0.068    || dis=0.00 || select=5/8
004/019-th : 0.112 0.115 0.117 0.120 0.130 0.135 0.134 0.137  ||  -0.111 -0.082 -0.064 -0.041 0.044 0.079 0.073 0.095   || dis=0.00 || select=7/8
005/019-th : 0.110 0.117 0.123 0.123 0.128 0.133 0.129 0.138  ||  -0.126 -0.070 -0.017 -0.017 0.022 0.066 0.029 0.098   || dis=0.01 || select=7/8
006/019-th : 0.116 0.114 0.117 0.120 0.128 0.133 0.134 0.138  ||  -0.071 -0.094 -0.063 -0.039 0.026 0.061 0.069 0.101   || dis=0.00 || select=7/8
007/019-th : 0.058 0.072 0.092 0.111 0.135 0.142 0.181 0.209  ||  -0.682 -0.473 -0.226 -0.039 0.161 0.214 0.456 0.597   || dis=0.03 || select=7/8
008/019-th : 0.045 0.055 0.074 0.118 0.136 0.168 0.199 0.204  ||  -0.883 -0.693 -0.384 0.080 0.217 0.428 0.600 0.625    || dis=0.00 || select=7/8
009/019-th : 0.090 0.094 0.105 0.119 0.116 0.143 0.158 0.176  ||  -0.305 -0.263 -0.146 -0.023 -0.048 0.158 0.258 0.365  || dis=0.02 || select=7/8
010/019-th : 0.096 0.102 0.110 0.128 0.134 0.137 0.146 0.147  ||  -0.250 -0.188 -0.118 0.032 0.078 0.104 0.169 0.173    || dis=0.00 || select=7/8
011/019-th : 0.095 0.091 0.106 0.115 0.125 0.136 0.155 0.177  ||  -0.253 -0.296 -0.140 -0.058 0.020 0.111 0.242 0.371   || dis=0.02 || select=7/8
012/019-th : 0.107 0.109 0.114 0.116 0.131 0.134 0.143 0.147  ||  -0.152 -0.133 -0.089 -0.072 0.053 0.074 0.142 0.171   || dis=0.00 || select=7/8
013/019-th : 0.028 0.037 0.048 0.066 0.082 0.124 0.241 0.375  ||  -1.143 -0.844 -0.595 -0.280 -0.063 0.358 1.020 1.462  || dis=0.13 || select=7/8
014/019-th : 0.038 0.053 0.069 0.087 0.110 0.160 0.221 0.262  ||  -0.990 -0.675 -0.409 -0.176 0.063 0.440 0.763 0.933   || dis=0.04 || select=7/8
015/019-th : 0.025 0.029 0.042 0.054 0.084 0.119 0.235 0.410  ||  -1.159 -1.009 -0.648 -0.395 0.038 0.390 1.070 1.625   || dis=0.17 || select=7/8
016/019-th : 0.054 0.073 0.098 0.124 0.139 0.160 0.178 0.174  ||  -0.766 -0.467 -0.170 0.070 0.180 0.322 0.430 0.407    || dis=0.00 || select=6/8
017/019-th : 0.118 0.110 0.114 0.124 0.134 0.125 0.136 0.139  ||  -0.053 -0.117 -0.087 -0.002 0.074 0.005 0.093 0.111   || dis=0.00 || select=7/8
018/019-th : 0.085 0.104 0.117 0.125 0.128 0.129 0.144 0.168  ||  -0.363 -0.168 -0.049 0.018 0.043 0.048 0.162 0.314    || dis=0.02 || select=7/8
[epoch=251/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.067
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:54:53] [epoch=251/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.104 (2.104)  Prec@1 33.20 (33.20) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:54:59] [epoch=251/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.440 (2.129)  Prec@1 50.00 (39.32) Prec@5 88.10 (82.35) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.32 Prec@5 82.35 Error@1 60.68 Error@5 17.65 Loss:2.129
***[2020-01-29 07:54:59]*** VALID [epoch=251/600] loss = 2.128972, accuracy@1 = 39.32, accuracy@5 = 82.35 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:54:59]*** start epoch=252/600 Time Left: [03:04:58], LR=[0.062434 ~ 0.062434], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=252, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.1592902235538953, FLOP=40.81
[Search] : epoch=252/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:55:00] [epoch=252/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.739 (0.739)  Prec@1 82.81 (82.81) Prec@5 96.09 (96.09) Acls-loss 0.813 (0.813) FLOP-Loss 0.000 (0.000) Arch-Loss 0.813 (0.813)
**TRAIN** [2020-01-29 07:55:25] [epoch=252/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.904 (0.789)  Prec@1 69.05 (73.09) Prec@5 97.02 (97.97) Acls-loss 0.678 (0.834) FLOP-Loss 0.000 (0.056) Arch-Loss 0.678 (0.946)
 **TRAIN** Prec@1 73.09 Prec@5 97.97 Error@1 26.91 Error@5 2.03 Base-Loss:0.789, Arch-Loss=0.946
***[2020-01-29 07:55:25]*** TRAIN [epoch=252/600] base-loss = 0.789056, arch-loss = 0.946130, accuracy-1 = 73.09, accuracy-5 = 97.97
[epoch=252/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.837056)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.197 0.363  ||  0.2380 -0.5655 0.0442  || discrepancy=0.08 || select=0/3
001/003-th : 0.361 0.142 0.497  ||  0.0580 -0.8749 0.3777  || discrepancy=0.14 || select=2/3
002/003-th : 0.023 0.107 0.870  ||  -1.8860 -0.3459 1.7459  || discrepancy=0.76 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.076 0.094 0.108 0.139 0.153 0.177 0.199  ||  -0.757 -0.419 -0.209 -0.066 0.184 0.280 0.423 0.540   || dis=0.02 || select=7/8
001/019-th : 0.128 0.128 0.126 0.125 0.123 0.127 0.120 0.123  ||  0.019 0.017 0.004 -0.006 -0.022 0.011 -0.042 -0.017   || dis=0.00 || select=0/8
002/019-th : 0.116 0.124 0.125 0.132 0.130 0.133 0.125 0.116  ||  -0.070 -0.005 0.003 0.055 0.046 0.066 0.003 -0.075    || dis=0.00 || select=5/8
003/019-th : 0.111 0.114 0.122 0.128 0.131 0.133 0.129 0.133  ||  -0.114 -0.089 -0.018 0.026 0.050 0.064 0.039 0.068    || dis=0.00 || select=7/8
004/019-th : 0.112 0.115 0.117 0.121 0.131 0.134 0.134 0.137  ||  -0.109 -0.082 -0.068 -0.033 0.050 0.071 0.071 0.094   || dis=0.00 || select=7/8
005/019-th : 0.111 0.116 0.123 0.123 0.129 0.133 0.128 0.137  ||  -0.121 -0.071 -0.013 -0.018 0.034 0.066 0.023 0.091   || dis=0.00 || select=7/8
006/019-th : 0.115 0.114 0.117 0.121 0.129 0.131 0.135 0.138  ||  -0.081 -0.093 -0.061 -0.033 0.033 0.051 0.076 0.102   || dis=0.00 || select=7/8
007/019-th : 0.059 0.071 0.093 0.110 0.134 0.143 0.180 0.211  ||  -0.674 -0.486 -0.208 -0.048 0.150 0.214 0.447 0.608   || dis=0.03 || select=7/8
008/019-th : 0.044 0.055 0.075 0.117 0.136 0.167 0.201 0.205  ||  -0.900 -0.694 -0.374 0.070 0.222 0.426 0.611 0.630    || dis=0.00 || select=7/8
009/019-th : 0.090 0.093 0.106 0.119 0.118 0.142 0.156 0.176  ||  -0.306 -0.269 -0.138 -0.025 -0.031 0.156 0.245 0.367  || dis=0.02 || select=7/8
010/019-th : 0.098 0.103 0.109 0.127 0.133 0.137 0.145 0.148  ||  -0.238 -0.182 -0.123 0.026 0.070 0.104 0.157 0.182    || dis=0.00 || select=7/8
011/019-th : 0.096 0.091 0.107 0.115 0.124 0.135 0.155 0.176  ||  -0.242 -0.291 -0.131 -0.059 0.014 0.103 0.235 0.368   || dis=0.02 || select=7/8
012/019-th : 0.107 0.109 0.115 0.117 0.129 0.134 0.142 0.147  ||  -0.151 -0.131 -0.078 -0.058 0.039 0.075 0.132 0.170   || dis=0.01 || select=7/8
013/019-th : 0.027 0.037 0.049 0.064 0.081 0.124 0.240 0.376  ||  -1.149 -0.858 -0.570 -0.295 -0.062 0.360 1.022 1.470  || dis=0.14 || select=7/8
014/019-th : 0.038 0.053 0.068 0.086 0.109 0.161 0.221 0.265  ||  -0.985 -0.674 -0.422 -0.177 0.054 0.444 0.762 0.943   || dis=0.04 || select=7/8
015/019-th : 0.025 0.029 0.043 0.053 0.083 0.119 0.239 0.410  ||  -1.158 -1.022 -0.630 -0.420 0.030 0.395 1.089 1.630   || dis=0.17 || select=7/8
016/019-th : 0.055 0.073 0.098 0.123 0.136 0.160 0.178 0.176  ||  -0.752 -0.460 -0.169 0.060 0.158 0.317 0.428 0.415    || dis=0.00 || select=6/8
017/019-th : 0.118 0.110 0.115 0.123 0.136 0.125 0.135 0.138  ||  -0.054 -0.119 -0.076 -0.013 0.089 0.008 0.087 0.106   || dis=0.00 || select=7/8
018/019-th : 0.085 0.105 0.117 0.125 0.128 0.129 0.144 0.167  ||  -0.366 -0.156 -0.049 0.019 0.038 0.049 0.159 0.310    || dis=0.02 || select=7/8
[epoch=252/600] FLOP : 27.84 MB, ratio : 0.6821, Expected-ratio : 0.7000, Discrepancy : 0.067
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:55:25] [epoch=252/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.459 (2.459)  Prec@1 37.11 (37.11) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:55:31] [epoch=252/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.617 (2.243)  Prec@1 29.17 (35.14) Prec@5 77.38 (79.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.14 Prec@5 79.07 Error@1 64.86 Error@5 20.93 Loss:2.243
***[2020-01-29 07:55:31]*** VALID [epoch=252/600] loss = 2.243089, accuracy@1 = 35.14, accuracy@5 = 79.07 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:55:31]*** start epoch=253/600 Time Left: [03:04:26], LR=[0.062181 ~ 0.062181], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=253, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.1468567788757555, FLOP=40.81
[Search] : epoch=253/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:55:32] [epoch=253/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.846 (0.846)  Prec@1 72.27 (72.27) Prec@5 96.88 (96.88) Acls-loss 0.930 (0.930) FLOP-Loss 0.000 (0.000) Arch-Loss 0.930 (0.930)
**TRAIN** [2020-01-29 07:55:56] [epoch=253/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.886 (0.785)  Prec@1 72.02 (73.10) Prec@5 97.62 (97.91) Acls-loss 0.817 (0.819) FLOP-Loss 0.000 (0.056) Arch-Loss 0.817 (0.932)
 **TRAIN** Prec@1 73.10 Prec@5 97.91 Error@1 26.90 Error@5 2.09 Base-Loss:0.785, Arch-Loss=0.932
***[2020-01-29 07:55:56]*** TRAIN [epoch=253/600] base-loss = 0.785383, arch-loss = 0.932064, accuracy-1 = 73.10, accuracy-5 = 97.91
[epoch=253/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 12, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.199 0.360  ||  0.2417 -0.5528 0.0405  || discrepancy=0.08 || select=0/3
001/003-th : 0.361 0.141 0.498  ||  0.0587 -0.8831 0.3807  || discrepancy=0.14 || select=2/3
002/003-th : 0.022 0.105 0.873  ||  -1.9023 -0.3526 1.7641  || discrepancy=0.77 || select=2/3
-----------------------------------------------
000/019-th : 0.055 0.075 0.093 0.109 0.138 0.152 0.178 0.199  ||  -0.739 -0.436 -0.214 -0.057 0.175 0.272 0.432 0.541   || dis=0.02 || select=7/8
001/019-th : 0.127 0.128 0.124 0.126 0.124 0.127 0.120 0.123  ||  0.015 0.019 -0.010 0.005 -0.013 0.015 -0.041 -0.017   || dis=0.00 || select=1/8
002/019-th : 0.118 0.125 0.123 0.131 0.130 0.133 0.125 0.116  ||  -0.060 0.000 -0.013 0.048 0.039 0.065 0.001 -0.075    || dis=0.00 || select=5/8
003/019-th : 0.111 0.115 0.123 0.128 0.130 0.131 0.129 0.133  ||  -0.110 -0.080 -0.010 0.027 0.045 0.053 0.033 0.063    || dis=0.00 || select=7/8
004/019-th : 0.112 0.115 0.118 0.120 0.130 0.132 0.136 0.137  ||  -0.109 -0.080 -0.059 -0.036 0.039 0.057 0.083 0.095   || dis=0.00 || select=7/8
005/019-th : 0.113 0.117 0.123 0.123 0.127 0.135 0.127 0.136  ||  -0.105 -0.069 -0.020 -0.017 0.017 0.079 0.016 0.083   || dis=0.00 || select=7/8
006/019-th : 0.114 0.112 0.119 0.121 0.130 0.132 0.135 0.138  ||  -0.089 -0.106 -0.042 -0.030 0.039 0.054 0.078 0.099   || dis=0.00 || select=7/8
007/019-th : 0.059 0.070 0.092 0.108 0.135 0.143 0.180 0.212  ||  -0.667 -0.489 -0.225 -0.059 0.163 0.218 0.448 0.614   || dis=0.03 || select=7/8
008/019-th : 0.043 0.053 0.074 0.116 0.138 0.168 0.201 0.206  ||  -0.923 -0.707 -0.381 0.066 0.244 0.440 0.620 0.643    || dis=0.00 || select=7/8
009/019-th : 0.090 0.092 0.106 0.116 0.118 0.146 0.155 0.178  ||  -0.301 -0.280 -0.139 -0.052 -0.030 0.179 0.241 0.380  || dis=0.02 || select=7/8
010/019-th : 0.099 0.103 0.112 0.125 0.134 0.135 0.145 0.148  ||  -0.228 -0.188 -0.103 0.012 0.081 0.090 0.158 0.177    || dis=0.00 || select=7/8
011/019-th : 0.094 0.091 0.108 0.113 0.124 0.138 0.155 0.176  ||  -0.257 -0.294 -0.125 -0.072 0.017 0.122 0.241 0.369   || dis=0.02 || select=7/8
012/019-th : 0.105 0.109 0.115 0.119 0.128 0.135 0.142 0.147  ||  -0.163 -0.129 -0.080 -0.041 0.032 0.081 0.133 0.170   || dis=0.01 || select=7/8
013/019-th : 0.028 0.036 0.049 0.064 0.080 0.122 0.243 0.377  ||  -1.141 -0.870 -0.570 -0.298 -0.069 0.352 1.038 1.477  || dis=0.13 || select=7/8
014/019-th : 0.038 0.052 0.066 0.085 0.110 0.161 0.222 0.264  ||  -0.988 -0.685 -0.438 -0.187 0.071 0.452 0.773 0.946   || dis=0.04 || select=7/8
015/019-th : 0.026 0.029 0.043 0.053 0.083 0.119 0.236 0.412  ||  -1.145 -1.033 -0.634 -0.423 0.037 0.398 1.080 1.637   || dis=0.18 || select=7/8
016/019-th : 0.055 0.072 0.098 0.125 0.136 0.161 0.176 0.177  ||  -0.754 -0.472 -0.166 0.072 0.157 0.324 0.417 0.420    || dis=0.00 || select=7/8
017/019-th : 0.118 0.109 0.115 0.123 0.133 0.128 0.136 0.138  ||  -0.049 -0.131 -0.081 -0.007 0.070 0.026 0.088 0.108   || dis=0.00 || select=7/8
018/019-th : 0.086 0.104 0.117 0.125 0.128 0.129 0.143 0.168  ||  -0.358 -0.165 -0.047 0.020 0.044 0.046 0.150 0.314    || dis=0.03 || select=7/8
[epoch=253/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.068
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:55:56] [epoch=253/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.720 (2.720)  Prec@1 32.03 (32.03) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:56:03] [epoch=253/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 1.699 (2.406)  Prec@1 44.05 (38.67) Prec@5 89.88 (83.73) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.67 Prec@5 83.73 Error@1 61.33 Error@5 16.27 Loss:2.406
***[2020-01-29 07:56:03]*** VALID [epoch=253/600] loss = 2.406226, accuracy@1 = 38.67, accuracy@5 = 83.73 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:56:03]*** start epoch=254/600 Time Left: [03:03:54], LR=[0.061927 ~ 0.061927], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=254, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.1344069710675235, FLOP=40.81
[Search] : epoch=254/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:56:03] [epoch=254/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.722 (0.722)  Prec@1 74.61 (74.61) Prec@5 98.44 (98.44) Acls-loss 0.666 (0.666) FLOP-Loss 0.000 (0.000) Arch-Loss 0.666 (0.666)
**TRAIN** [2020-01-29 07:56:28] [epoch=254/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.181 (0.792)  Prec@1 55.36 (72.73) Prec@5 95.24 (97.85) Acls-loss 0.953 (0.827) FLOP-Loss 0.000 (0.084) Arch-Loss 0.953 (0.996)
 **TRAIN** Prec@1 72.73 Prec@5 97.85 Error@1 27.27 Error@5 2.15 Base-Loss:0.792, Arch-Loss=0.996
***[2020-01-29 07:56:28]*** TRAIN [epoch=254/600] base-loss = 0.792369, arch-loss = 0.996088, accuracy-1 = 72.73, accuracy-5 = 97.85
[epoch=254/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.726464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.442 0.199 0.359  ||  0.2450 -0.5523 0.0388  || discrepancy=0.08 || select=0/3
001/003-th : 0.363 0.141 0.496  ||  0.0658 -0.8814 0.3760  || discrepancy=0.13 || select=2/3
002/003-th : 0.022 0.105 0.873  ||  -1.9084 -0.3459 1.7693  || discrepancy=0.77 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.094 0.111 0.140 0.151 0.178 0.198  ||  -0.759 -0.451 -0.201 -0.043 0.191 0.272 0.435 0.540   || dis=0.02 || select=7/8
001/019-th : 0.128 0.127 0.126 0.125 0.123 0.127 0.120 0.123  ||  0.021 0.013 0.005 -0.006 -0.020 0.014 -0.041 -0.017   || dis=0.00 || select=0/8
002/019-th : 0.119 0.127 0.124 0.131 0.129 0.131 0.124 0.115  ||  -0.050 0.018 -0.009 0.050 0.032 0.047 -0.007 -0.084   || dis=0.00 || select=3/8
003/019-th : 0.112 0.114 0.122 0.129 0.129 0.129 0.129 0.134  ||  -0.103 -0.086 -0.019 0.037 0.032 0.036 0.038 0.072    || dis=0.01 || select=7/8
004/019-th : 0.113 0.115 0.117 0.122 0.129 0.131 0.137 0.136  ||  -0.103 -0.082 -0.067 -0.024 0.034 0.051 0.096 0.086   || dis=0.00 || select=6/8
005/019-th : 0.113 0.117 0.125 0.121 0.126 0.134 0.127 0.135  ||  -0.098 -0.069 -0.001 -0.029 0.010 0.071 0.018 0.079   || dis=0.00 || select=7/8
006/019-th : 0.114 0.113 0.120 0.120 0.129 0.132 0.134 0.138  ||  -0.090 -0.102 -0.037 -0.035 0.034 0.058 0.073 0.102   || dis=0.00 || select=7/8
007/019-th : 0.059 0.070 0.093 0.109 0.137 0.144 0.179 0.210  ||  -0.674 -0.489 -0.214 -0.055 0.172 0.225 0.444 0.601   || dis=0.03 || select=7/8
008/019-th : 0.043 0.052 0.074 0.115 0.139 0.168 0.204 0.206  ||  -0.925 -0.724 -0.382 0.065 0.250 0.440 0.637 0.645    || dis=0.00 || select=7/8
009/019-th : 0.090 0.093 0.107 0.115 0.118 0.146 0.154 0.177  ||  -0.303 -0.272 -0.129 -0.053 -0.031 0.181 0.238 0.373  || dis=0.02 || select=7/8
010/019-th : 0.099 0.102 0.112 0.125 0.135 0.135 0.144 0.148  ||  -0.225 -0.191 -0.100 0.010 0.088 0.087 0.152 0.179    || dis=0.00 || select=7/8
011/019-th : 0.096 0.090 0.109 0.114 0.123 0.138 0.155 0.175  ||  -0.242 -0.300 -0.118 -0.066 0.004 0.123 0.241 0.359   || dis=0.02 || select=7/8
012/019-th : 0.106 0.110 0.115 0.119 0.129 0.135 0.141 0.146  ||  -0.162 -0.120 -0.080 -0.040 0.035 0.081 0.128 0.164   || dis=0.01 || select=7/8
013/019-th : 0.028 0.036 0.047 0.064 0.080 0.122 0.239 0.384  ||  -1.134 -0.869 -0.594 -0.296 -0.069 0.357 1.025 1.499  || dis=0.15 || select=7/8
014/019-th : 0.038 0.052 0.066 0.086 0.111 0.160 0.223 0.265  ||  -0.989 -0.686 -0.444 -0.181 0.078 0.445 0.775 0.947   || dis=0.04 || select=7/8
015/019-th : 0.025 0.028 0.043 0.053 0.083 0.121 0.239 0.408  ||  -1.156 -1.035 -0.635 -0.417 0.030 0.409 1.093 1.627   || dis=0.17 || select=7/8
016/019-th : 0.055 0.073 0.097 0.128 0.137 0.162 0.172 0.176  ||  -0.753 -0.461 -0.179 0.093 0.167 0.332 0.394 0.414    || dis=0.00 || select=7/8
017/019-th : 0.118 0.109 0.116 0.126 0.131 0.127 0.135 0.137  ||  -0.052 -0.128 -0.065 0.016 0.052 0.023 0.083 0.100    || dis=0.00 || select=7/8
018/019-th : 0.086 0.104 0.117 0.126 0.130 0.131 0.141 0.165  ||  -0.351 -0.165 -0.050 0.030 0.055 0.065 0.138 0.296    || dis=0.02 || select=7/8
[epoch=254/600] FLOP : 27.73 MB, ratio : 0.6794, Expected-ratio : 0.7000, Discrepancy : 0.068
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:56:28] [epoch=254/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.000 (2.000)  Prec@1 30.08 (30.08) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:56:34] [epoch=254/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.737 (2.209)  Prec@1 38.69 (37.44) Prec@5 81.55 (81.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.44 Prec@5 81.18 Error@1 62.56 Error@5 18.82 Loss:2.209
***[2020-01-29 07:56:34]*** VALID [epoch=254/600] loss = 2.209498, accuracy@1 = 37.44, accuracy@5 = 81.18 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:56:35]*** start epoch=255/600 Time Left: [03:03:22], LR=[0.061672 ~ 0.061672], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=255, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.121941141446969, FLOP=40.81
[Search] : epoch=255/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:56:35] [epoch=255/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.750 (0.750)  Prec@1 73.05 (73.05) Prec@5 98.05 (98.05) Acls-loss 0.747 (0.747) FLOP-Loss 0.000 (0.000) Arch-Loss 0.747 (0.747)
**TRAIN** [2020-01-29 07:57:00] [epoch=255/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.862 (0.800)  Prec@1 70.24 (72.79) Prec@5 96.43 (97.81) Acls-loss 0.875 (0.828) FLOP-Loss 0.000 (0.028) Arch-Loss 0.875 (0.885)
 **TRAIN** Prec@1 72.79 Prec@5 97.81 Error@1 27.21 Error@5 2.19 Base-Loss:0.800, Arch-Loss=0.885
***[2020-01-29 07:57:00]*** TRAIN [epoch=255/600] base-loss = 0.799745, arch-loss = 0.884578, accuracy-1 = 72.79, accuracy-5 = 97.81
[epoch=255/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.886208)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.198 0.361  ||  0.2436 -0.5573 0.0428  || discrepancy=0.08 || select=0/3
001/003-th : 0.361 0.140 0.499  ||  0.0598 -0.8880 0.3850  || discrepancy=0.14 || select=2/3
002/003-th : 0.021 0.102 0.877  ||  -1.9198 -0.3643 1.7892  || discrepancy=0.78 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.092 0.107 0.138 0.154 0.180 0.200  ||  -0.761 -0.443 -0.220 -0.074 0.184 0.294 0.447 0.554   || dis=0.02 || select=7/8
001/019-th : 0.128 0.127 0.125 0.124 0.125 0.126 0.121 0.124  ||  0.016 0.011 -0.002 -0.009 -0.007 0.006 -0.035 -0.011  || dis=0.00 || select=0/8
002/019-th : 0.118 0.125 0.124 0.133 0.128 0.133 0.124 0.116  ||  -0.055 -0.000 -0.010 0.061 0.024 0.062 -0.006 -0.074  || dis=0.00 || select=5/8
003/019-th : 0.112 0.114 0.120 0.130 0.131 0.129 0.130 0.134  ||  -0.110 -0.092 -0.033 0.044 0.049 0.038 0.039 0.077    || dis=0.00 || select=7/8
004/019-th : 0.112 0.113 0.118 0.120 0.130 0.133 0.138 0.136  ||  -0.111 -0.098 -0.053 -0.036 0.039 0.065 0.099 0.090   || dis=0.00 || select=6/8
005/019-th : 0.113 0.117 0.125 0.120 0.125 0.134 0.130 0.135  ||  -0.098 -0.068 -0.000 -0.038 -0.002 0.072 0.037 0.078  || dis=0.00 || select=7/8
006/019-th : 0.113 0.111 0.120 0.120 0.130 0.134 0.134 0.139  ||  -0.099 -0.115 -0.039 -0.036 0.044 0.074 0.070 0.108   || dis=0.01 || select=7/8
007/019-th : 0.057 0.069 0.092 0.108 0.136 0.145 0.181 0.211  ||  -0.693 -0.501 -0.217 -0.057 0.175 0.239 0.458 0.610   || dis=0.03 || select=7/8
008/019-th : 0.042 0.053 0.074 0.115 0.138 0.169 0.204 0.205  ||  -0.934 -0.717 -0.379 0.063 0.247 0.450 0.637 0.640    || dis=0.00 || select=7/8
009/019-th : 0.090 0.092 0.107 0.114 0.117 0.147 0.157 0.176  ||  -0.301 -0.274 -0.132 -0.063 -0.039 0.189 0.255 0.370  || dis=0.02 || select=7/8
010/019-th : 0.097 0.101 0.113 0.126 0.133 0.136 0.146 0.147  ||  -0.238 -0.201 -0.086 0.018 0.075 0.092 0.165 0.176    || dis=0.00 || select=7/8
011/019-th : 0.095 0.089 0.108 0.114 0.122 0.142 0.154 0.175  ||  -0.248 -0.314 -0.117 -0.065 0.002 0.153 0.234 0.359   || dis=0.02 || select=7/8
012/019-th : 0.105 0.109 0.115 0.118 0.130 0.135 0.141 0.146  ||  -0.170 -0.128 -0.072 -0.050 0.048 0.084 0.131 0.166   || dis=0.01 || select=7/8
013/019-th : 0.026 0.036 0.048 0.063 0.082 0.121 0.236 0.388  ||  -1.185 -0.854 -0.583 -0.304 -0.040 0.348 1.020 1.517  || dis=0.15 || select=7/8
014/019-th : 0.038 0.051 0.065 0.084 0.109 0.159 0.223 0.272  ||  -0.981 -0.699 -0.455 -0.199 0.066 0.440 0.782 0.978   || dis=0.05 || select=7/8
015/019-th : 0.025 0.028 0.042 0.052 0.085 0.120 0.237 0.411  ||  -1.152 -1.061 -0.632 -0.422 0.056 0.410 1.086 1.637   || dis=0.17 || select=7/8
016/019-th : 0.054 0.072 0.098 0.126 0.136 0.162 0.173 0.178  ||  -0.760 -0.473 -0.174 0.084 0.160 0.334 0.398 0.430    || dis=0.01 || select=7/8
017/019-th : 0.116 0.109 0.116 0.125 0.132 0.127 0.136 0.139  ||  -0.069 -0.132 -0.064 0.011 0.060 0.026 0.089 0.111    || dis=0.00 || select=7/8
018/019-th : 0.086 0.105 0.116 0.125 0.128 0.132 0.141 0.166  ||  -0.358 -0.154 -0.053 0.018 0.045 0.070 0.138 0.304    || dis=0.03 || select=7/8
[epoch=255/600] FLOP : 27.89 MB, ratio : 0.6833, Expected-ratio : 0.7000, Discrepancy : 0.069
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:57:00] [epoch=255/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 2.497 (2.497)  Prec@1 28.12 (28.12) Prec@5 76.17 (76.17) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:57:06] [epoch=255/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.380 (2.518)  Prec@1 29.76 (36.52) Prec@5 82.14 (81.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.52 Prec@5 81.60 Error@1 63.48 Error@5 18.40 Loss:2.518
***[2020-01-29 07:57:06]*** VALID [epoch=255/600] loss = 2.517890, accuracy@1 = 36.52, accuracy@5 = 81.60 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:57:06]*** start epoch=256/600 Time Left: [03:02:50], LR=[0.061418 ~ 0.061418], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=256, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.109459631771107, FLOP=40.81
[Search] : epoch=256/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:57:07] [epoch=256/600][000/098] Time 0.74 (0.74) Data 0.34 (0.34) Base-Loss 0.807 (0.807)  Prec@1 75.39 (75.39) Prec@5 98.05 (98.05) Acls-loss 0.930 (0.930) FLOP-Loss 0.000 (0.000) Arch-Loss 0.930 (0.930)
**TRAIN** [2020-01-29 07:57:31] [epoch=256/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.856 (0.788)  Prec@1 67.26 (73.39) Prec@5 97.62 (97.87) Acls-loss 0.785 (0.824) FLOP-Loss 0.000 (0.056) Arch-Loss 0.785 (0.937)
 **TRAIN** Prec@1 73.39 Prec@5 97.87 Error@1 26.61 Error@5 2.13 Base-Loss:0.788, Arch-Loss=0.937
***[2020-01-29 07:57:31]*** TRAIN [epoch=256/600] base-loss = 0.788013, arch-loss = 0.936927, accuracy-1 = 73.39, accuracy-5 = 97.87
[epoch=256/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 16, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.079296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.200 0.357  ||  0.2510 -0.5457 0.0353  || discrepancy=0.09 || select=0/3
001/003-th : 0.360 0.139 0.501  ||  0.0593 -0.8960 0.3892  || discrepancy=0.14 || select=2/3
002/003-th : 0.021 0.100 0.879  ||  -1.9189 -0.3759 1.7977  || discrepancy=0.78 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.075 0.094 0.107 0.139 0.154 0.179 0.199  ||  -0.772 -0.436 -0.203 -0.070 0.185 0.291 0.443 0.547   || dis=0.02 || select=7/8
001/019-th : 0.128 0.127 0.125 0.125 0.124 0.127 0.121 0.124  ||  0.018 0.010 -0.001 -0.004 -0.008 0.013 -0.037 -0.015  || dis=0.00 || select=0/8
002/019-th : 0.119 0.124 0.123 0.133 0.127 0.133 0.124 0.117  ||  -0.049 -0.005 -0.017 0.065 0.015 0.063 -0.010 -0.069  || dis=0.00 || select=3/8
003/019-th : 0.111 0.115 0.123 0.129 0.130 0.128 0.130 0.135  ||  -0.116 -0.078 -0.015 0.031 0.041 0.024 0.041 0.080    || dis=0.01 || select=7/8
004/019-th : 0.112 0.113 0.119 0.121 0.129 0.134 0.138 0.135  ||  -0.108 -0.096 -0.048 -0.031 0.031 0.071 0.100 0.081   || dis=0.00 || select=6/8
005/019-th : 0.112 0.116 0.125 0.122 0.125 0.134 0.131 0.135  ||  -0.108 -0.073 -0.003 -0.023 0.002 0.067 0.046 0.080   || dis=0.00 || select=7/8
006/019-th : 0.113 0.112 0.119 0.122 0.130 0.134 0.133 0.137  ||  -0.094 -0.108 -0.041 -0.021 0.046 0.077 0.063 0.094   || dis=0.00 || select=7/8
007/019-th : 0.057 0.068 0.093 0.109 0.135 0.145 0.181 0.211  ||  -0.700 -0.513 -0.208 -0.044 0.169 0.241 0.460 0.611   || dis=0.03 || select=7/8
008/019-th : 0.043 0.053 0.073 0.112 0.137 0.169 0.205 0.206  ||  -0.925 -0.703 -0.390 0.040 0.240 0.449 0.643 0.648    || dis=0.00 || select=7/8
009/019-th : 0.091 0.093 0.108 0.114 0.115 0.147 0.157 0.175  ||  -0.286 -0.271 -0.123 -0.064 -0.060 0.190 0.254 0.364  || dis=0.02 || select=7/8
010/019-th : 0.097 0.100 0.112 0.126 0.135 0.138 0.147 0.146  ||  -0.241 -0.215 -0.095 0.020 0.086 0.110 0.174 0.167    || dis=0.00 || select=6/8
011/019-th : 0.096 0.090 0.108 0.115 0.122 0.143 0.153 0.172  ||  -0.238 -0.307 -0.121 -0.056 0.002 0.156 0.227 0.344   || dis=0.02 || select=7/8
012/019-th : 0.104 0.109 0.115 0.120 0.132 0.134 0.140 0.146  ||  -0.177 -0.130 -0.076 -0.035 0.067 0.082 0.121 0.166   || dis=0.01 || select=7/8
013/019-th : 0.025 0.036 0.047 0.063 0.082 0.120 0.234 0.392  ||  -1.217 -0.856 -0.584 -0.295 -0.027 0.350 1.017 1.532  || dis=0.16 || select=7/8
014/019-th : 0.038 0.050 0.064 0.083 0.109 0.156 0.225 0.274  ||  -0.974 -0.706 -0.465 -0.201 0.066 0.428 0.791 0.990   || dis=0.05 || select=7/8
015/019-th : 0.025 0.028 0.042 0.053 0.084 0.121 0.234 0.414  ||  -1.162 -1.053 -0.637 -0.417 0.055 0.416 1.074 1.646   || dis=0.18 || select=7/8
016/019-th : 0.055 0.072 0.096 0.127 0.138 0.160 0.172 0.178  ||  -0.740 -0.476 -0.188 0.092 0.174 0.323 0.393 0.426    || dis=0.01 || select=7/8
017/019-th : 0.116 0.108 0.116 0.125 0.132 0.127 0.138 0.137  ||  -0.066 -0.137 -0.066 0.010 0.063 0.025 0.103 0.100    || dis=0.00 || select=6/8
018/019-th : 0.085 0.106 0.116 0.124 0.129 0.131 0.140 0.168  ||  -0.364 -0.151 -0.054 0.011 0.049 0.068 0.131 0.314    || dis=0.03 || select=7/8
[epoch=256/600] FLOP : 27.08 MB, ratio : 0.6635, Expected-ratio : 0.7000, Discrepancy : 0.070
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:57:32] [epoch=256/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.960 (1.960)  Prec@1 34.77 (34.77) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:57:38] [epoch=256/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.101 (2.085)  Prec@1 36.31 (37.44) Prec@5 76.19 (80.88) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.44 Prec@5 80.88 Error@1 62.56 Error@5 19.12 Loss:2.085
***[2020-01-29 07:57:38]*** VALID [epoch=256/600] loss = 2.084715, accuracy@1 = 37.44, accuracy@5 = 80.88 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:57:38]*** start epoch=257/600 Time Left: [03:02:17], LR=[0.061163 ~ 0.061163], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=257, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.0969627842268315, FLOP=40.81
[Search] : epoch=257/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:57:39] [epoch=257/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.806 (0.806)  Prec@1 73.83 (73.83) Prec@5 98.44 (98.44) Acls-loss 0.872 (0.872) FLOP-Loss 0.000 (0.000) Arch-Loss 0.872 (0.872)
**TRAIN** [2020-01-29 07:58:05] [epoch=257/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.830 (0.805)  Prec@1 73.21 (72.75) Prec@5 99.40 (97.88) Acls-loss 0.678 (0.827) FLOP-Loss 0.000 (0.056) Arch-Loss 0.678 (0.939)
 **TRAIN** Prec@1 72.75 Prec@5 97.88 Error@1 27.25 Error@5 2.12 Base-Loss:0.805, Arch-Loss=0.939
***[2020-01-29 07:58:05]*** TRAIN [epoch=257/600] base-loss = 0.804887, arch-loss = 0.939432, accuracy-1 = 72.75, accuracy-5 = 97.88
[epoch=257/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 16, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.086912)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.442 0.200 0.357  ||  0.2506 -0.5427 0.0370  || discrepancy=0.09 || select=0/3
001/003-th : 0.359 0.135 0.505  ||  0.0571 -0.9200 0.3974  || discrepancy=0.15 || select=2/3
002/003-th : 0.020 0.097 0.883  ||  -1.9453 -0.3872 1.8251  || discrepancy=0.79 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.093 0.107 0.140 0.155 0.178 0.199  ||  -0.764 -0.445 -0.209 -0.075 0.197 0.298 0.438 0.547   || dis=0.02 || select=7/8
001/019-th : 0.127 0.128 0.124 0.126 0.125 0.128 0.120 0.123  ||  0.016 0.019 -0.007 0.003 -0.005 0.019 -0.040 -0.020   || dis=0.00 || select=5/8
002/019-th : 0.120 0.125 0.124 0.134 0.125 0.133 0.122 0.116  ||  -0.038 0.003 -0.004 0.070 0.003 0.060 -0.027 -0.074   || dis=0.00 || select=3/8
003/019-th : 0.112 0.115 0.122 0.128 0.129 0.128 0.129 0.136  ||  -0.109 -0.084 -0.023 0.025 0.033 0.029 0.036 0.089    || dis=0.01 || select=7/8
004/019-th : 0.112 0.113 0.118 0.118 0.131 0.135 0.138 0.136  ||  -0.109 -0.096 -0.055 -0.053 0.047 0.076 0.100 0.086   || dis=0.00 || select=6/8
005/019-th : 0.113 0.116 0.124 0.123 0.125 0.133 0.131 0.135  ||  -0.103 -0.074 -0.005 -0.018 0.001 0.065 0.049 0.076   || dis=0.00 || select=7/8
006/019-th : 0.113 0.111 0.118 0.124 0.131 0.133 0.132 0.137  ||  -0.094 -0.111 -0.054 -0.004 0.055 0.069 0.063 0.094   || dis=0.00 || select=7/8
007/019-th : 0.057 0.068 0.092 0.108 0.135 0.146 0.181 0.212  ||  -0.690 -0.515 -0.213 -0.053 0.166 0.245 0.457 0.617   || dis=0.03 || select=7/8
008/019-th : 0.042 0.053 0.074 0.112 0.139 0.170 0.205 0.205  ||  -0.934 -0.711 -0.381 0.039 0.256 0.457 0.641 0.641    || dis=0.00 || select=6/8
009/019-th : 0.093 0.093 0.109 0.112 0.113 0.147 0.157 0.176  ||  -0.273 -0.272 -0.114 -0.081 -0.070 0.189 0.256 0.368  || dis=0.02 || select=7/8
010/019-th : 0.097 0.100 0.111 0.126 0.135 0.139 0.147 0.145  ||  -0.240 -0.212 -0.102 0.021 0.092 0.119 0.172 0.160    || dis=0.00 || select=6/8
011/019-th : 0.097 0.091 0.107 0.115 0.124 0.141 0.155 0.171  ||  -0.235 -0.295 -0.130 -0.063 0.014 0.145 0.240 0.334   || dis=0.02 || select=7/8
012/019-th : 0.103 0.110 0.114 0.118 0.133 0.133 0.141 0.148  ||  -0.181 -0.122 -0.082 -0.052 0.070 0.069 0.126 0.177   || dis=0.01 || select=7/8
013/019-th : 0.025 0.036 0.047 0.063 0.083 0.118 0.235 0.393  ||  -1.207 -0.853 -0.595 -0.301 -0.017 0.337 1.022 1.537  || dis=0.16 || select=7/8
014/019-th : 0.038 0.050 0.065 0.083 0.108 0.154 0.229 0.274  ||  -0.978 -0.711 -0.455 -0.207 0.062 0.413 0.810 0.992   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.041 0.052 0.082 0.121 0.236 0.416  ||  -1.200 -1.055 -0.653 -0.406 0.046 0.431 1.097 1.664   || dis=0.18 || select=7/8
016/019-th : 0.055 0.072 0.097 0.126 0.140 0.159 0.173 0.178  ||  -0.754 -0.476 -0.178 0.085 0.186 0.314 0.396 0.429    || dis=0.01 || select=7/8
017/019-th : 0.116 0.109 0.116 0.125 0.133 0.127 0.138 0.136  ||  -0.065 -0.127 -0.071 0.006 0.066 0.026 0.109 0.090    || dis=0.00 || select=6/8
018/019-th : 0.084 0.104 0.118 0.124 0.130 0.132 0.141 0.167  ||  -0.375 -0.163 -0.038 0.013 0.056 0.072 0.141 0.306    || dis=0.03 || select=7/8
[epoch=257/600] FLOP : 28.09 MB, ratio : 0.6882, Expected-ratio : 0.7000, Discrepancy : 0.070
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:58:05] [epoch=257/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.288 (2.288)  Prec@1 26.56 (26.56) Prec@5 76.56 (76.56) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:58:11] [epoch=257/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.309 (2.374)  Prec@1 23.81 (36.88) Prec@5 70.24 (80.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.88 Prec@5 80.94 Error@1 63.12 Error@5 19.06 Loss:2.374
***[2020-01-29 07:58:11]*** VALID [epoch=257/600] loss = 2.373726, accuracy@1 = 36.88, accuracy@5 = 80.94 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:58:11]*** start epoch=258/600 Time Left: [03:01:47], LR=[0.060907 ~ 0.060907], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=258, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.08445094142153, FLOP=40.81
[Search] : epoch=258/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:58:12] [epoch=258/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.653 (0.653)  Prec@1 78.52 (78.52) Prec@5 98.83 (98.83) Acls-loss 0.895 (0.895) FLOP-Loss 0.000 (0.000) Arch-Loss 0.895 (0.895)
**TRAIN** [2020-01-29 07:58:37] [epoch=258/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.732 (0.761)  Prec@1 73.21 (74.26) Prec@5 98.81 (98.02) Acls-loss 0.940 (0.830) FLOP-Loss 0.000 (0.028) Arch-Loss 0.940 (0.887)
 **TRAIN** Prec@1 74.26 Prec@5 98.02 Error@1 25.74 Error@5 1.98 Base-Loss:0.761, Arch-Loss=0.887
***[2020-01-29 07:58:37]*** TRAIN [epoch=258/600] base-loss = 0.761430, arch-loss = 0.886919, accuracy-1 = 74.26, accuracy-5 = 98.02
[epoch=258/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 12, 16, 14, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.755136)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.203 0.359  ||  0.2421 -0.5245 0.0448  || discrepancy=0.08 || select=0/3
001/003-th : 0.356 0.132 0.512  ||  0.0484 -0.9420 0.4113  || discrepancy=0.16 || select=2/3
002/003-th : 0.020 0.095 0.885  ||  -1.9578 -0.3893 1.8388  || discrepancy=0.79 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.074 0.093 0.107 0.139 0.157 0.179 0.197  ||  -0.771 -0.437 -0.211 -0.069 0.186 0.309 0.442 0.539   || dis=0.02 || select=7/8
001/019-th : 0.126 0.128 0.124 0.125 0.126 0.127 0.121 0.123  ||  0.009 0.019 -0.009 -0.001 0.009 0.018 -0.037 -0.017   || dis=0.00 || select=1/8
002/019-th : 0.119 0.125 0.124 0.132 0.127 0.134 0.122 0.117  ||  -0.047 -0.001 -0.010 0.056 0.012 0.067 -0.024 -0.064  || dis=0.00 || select=5/8
003/019-th : 0.112 0.115 0.119 0.126 0.131 0.131 0.130 0.136  ||  -0.108 -0.081 -0.047 0.012 0.047 0.048 0.040 0.087    || dis=0.01 || select=7/8
004/019-th : 0.111 0.113 0.116 0.118 0.132 0.136 0.138 0.135  ||  -0.111 -0.093 -0.070 -0.050 0.060 0.087 0.103 0.078   || dis=0.00 || select=6/8
005/019-th : 0.113 0.116 0.124 0.121 0.123 0.134 0.132 0.136  ||  -0.098 -0.074 -0.007 -0.029 -0.014 0.065 0.057 0.081  || dis=0.00 || select=7/8
006/019-th : 0.113 0.112 0.117 0.125 0.131 0.133 0.132 0.138  ||  -0.100 -0.108 -0.064 0.000 0.050 0.070 0.057 0.106    || dis=0.01 || select=7/8
007/019-th : 0.057 0.069 0.090 0.106 0.135 0.146 0.182 0.214  ||  -0.694 -0.504 -0.232 -0.071 0.170 0.246 0.465 0.629   || dis=0.03 || select=7/8
008/019-th : 0.042 0.053 0.073 0.110 0.137 0.172 0.207 0.207  ||  -0.940 -0.714 -0.384 0.020 0.243 0.469 0.654 0.657    || dis=0.00 || select=7/8
009/019-th : 0.092 0.092 0.109 0.111 0.114 0.146 0.159 0.176  ||  -0.279 -0.274 -0.111 -0.091 -0.063 0.184 0.269 0.370  || dis=0.02 || select=7/8
010/019-th : 0.096 0.099 0.111 0.126 0.136 0.139 0.149 0.146  ||  -0.255 -0.221 -0.104 0.019 0.099 0.117 0.187 0.166    || dis=0.00 || select=6/8
011/019-th : 0.097 0.090 0.108 0.113 0.124 0.142 0.156 0.171  ||  -0.232 -0.303 -0.122 -0.079 0.013 0.150 0.246 0.336   || dis=0.02 || select=7/8
012/019-th : 0.102 0.109 0.114 0.119 0.133 0.132 0.143 0.149  ||  -0.195 -0.130 -0.084 -0.045 0.069 0.062 0.140 0.185   || dis=0.01 || select=7/8
013/019-th : 0.025 0.035 0.047 0.062 0.083 0.117 0.235 0.396  ||  -1.198 -0.869 -0.591 -0.300 -0.021 0.328 1.024 1.548  || dis=0.16 || select=7/8
014/019-th : 0.038 0.050 0.064 0.083 0.109 0.154 0.228 0.274  ||  -0.974 -0.717 -0.468 -0.206 0.070 0.419 0.810 0.994   || dis=0.05 || select=7/8
015/019-th : 0.023 0.027 0.041 0.052 0.081 0.121 0.236 0.418  ||  -1.205 -1.054 -0.653 -0.409 0.036 0.433 1.103 1.674   || dis=0.18 || select=7/8
016/019-th : 0.055 0.072 0.095 0.127 0.138 0.160 0.174 0.179  ||  -0.747 -0.480 -0.203 0.094 0.173 0.319 0.405 0.435    || dis=0.01 || select=7/8
017/019-th : 0.116 0.108 0.115 0.124 0.133 0.128 0.139 0.137  ||  -0.069 -0.136 -0.073 0.001 0.065 0.027 0.111 0.102    || dis=0.00 || select=6/8
018/019-th : 0.084 0.102 0.121 0.126 0.130 0.133 0.140 0.166  ||  -0.381 -0.187 -0.013 0.025 0.057 0.081 0.135 0.304    || dis=0.03 || select=7/8
[epoch=258/600] FLOP : 27.76 MB, ratio : 0.6801, Expected-ratio : 0.7000, Discrepancy : 0.071
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:58:37] [epoch=258/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.506 (2.506)  Prec@1 25.00 (25.00) Prec@5 84.38 (84.38) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:58:44] [epoch=258/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.286 (2.140)  Prec@1 51.19 (39.03) Prec@5 95.24 (82.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.03 Prec@5 82.43 Error@1 60.97 Error@5 17.57 Loss:2.140
***[2020-01-29 07:58:44]*** VALID [epoch=258/600] loss = 2.139978, accuracy@1 = 39.03, accuracy@5 = 82.43 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:58:44]*** start epoch=259/600 Time Left: [03:01:17], LR=[0.060652 ~ 0.060652], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=259, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.071924446373693, FLOP=40.81
[Search] : epoch=259/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:58:45] [epoch=259/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.852 (0.852)  Prec@1 68.75 (68.75) Prec@5 97.27 (97.27) Acls-loss 0.920 (0.920) FLOP-Loss 0.000 (0.000) Arch-Loss 0.920 (0.920)
**TRAIN** [2020-01-29 07:59:09] [epoch=259/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.847 (0.792)  Prec@1 72.02 (72.85) Prec@5 98.21 (97.80) Acls-loss 0.674 (0.824) FLOP-Loss -2.753 (0.066) Arch-Loss -4.832 (0.956)
 **TRAIN** Prec@1 72.85 Prec@5 97.80 Error@1 27.15 Error@5 2.20 Base-Loss:0.792, Arch-Loss=0.956
***[2020-01-29 07:59:09]*** TRAIN [epoch=259/600] base-loss = 0.791715, arch-loss = 0.956430, accuracy-1 = 72.85, accuracy-5 = 97.80
[epoch=259/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 12, 16, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.209792)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.199 0.361  ||  0.2441 -0.5464 0.0473  || discrepancy=0.08 || select=0/3
001/003-th : 0.357 0.134 0.509  ||  0.0526 -0.9261 0.4072  || discrepancy=0.15 || select=2/3
002/003-th : 0.020 0.096 0.884  ||  -1.9527 -0.3842 1.8368  || discrepancy=0.79 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.094 0.107 0.137 0.155 0.178 0.201  ||  -0.756 -0.437 -0.207 -0.072 0.169 0.293 0.434 0.556   || dis=0.02 || select=7/8
001/019-th : 0.127 0.127 0.124 0.125 0.128 0.127 0.120 0.123  ||  0.015 0.012 -0.005 -0.000 0.020 0.016 -0.043 -0.018   || dis=0.00 || select=4/8
002/019-th : 0.120 0.125 0.125 0.132 0.125 0.133 0.123 0.117  ||  -0.043 -0.003 0.001 0.057 0.001 0.062 -0.021 -0.067   || dis=0.00 || select=5/8
003/019-th : 0.110 0.115 0.120 0.127 0.130 0.133 0.130 0.134  ||  -0.124 -0.075 -0.034 0.018 0.047 0.070 0.041 0.075    || dis=0.00 || select=7/8
004/019-th : 0.112 0.113 0.116 0.117 0.135 0.135 0.138 0.134  ||  -0.105 -0.097 -0.067 -0.060 0.082 0.081 0.101 0.073   || dis=0.00 || select=6/8
005/019-th : 0.114 0.117 0.124 0.123 0.123 0.133 0.132 0.135  ||  -0.091 -0.070 -0.009 -0.020 -0.018 0.062 0.054 0.074  || dis=0.00 || select=7/8
006/019-th : 0.112 0.111 0.116 0.124 0.130 0.134 0.133 0.141  ||  -0.105 -0.118 -0.075 -0.004 0.045 0.069 0.063 0.124   || dis=0.01 || select=7/8
007/019-th : 0.057 0.069 0.090 0.106 0.134 0.147 0.182 0.214  ||  -0.695 -0.496 -0.243 -0.074 0.164 0.256 0.466 0.631   || dis=0.03 || select=7/8
008/019-th : 0.042 0.053 0.073 0.110 0.134 0.172 0.208 0.208  ||  -0.933 -0.702 -0.393 0.025 0.220 0.466 0.657 0.656    || dis=0.00 || select=6/8
009/019-th : 0.093 0.092 0.108 0.111 0.116 0.146 0.158 0.176  ||  -0.272 -0.274 -0.123 -0.088 -0.046 0.182 0.262 0.366  || dis=0.02 || select=7/8
010/019-th : 0.095 0.100 0.112 0.126 0.134 0.140 0.149 0.146  ||  -0.259 -0.214 -0.100 0.018 0.082 0.124 0.188 0.166    || dis=0.00 || select=6/8
011/019-th : 0.098 0.090 0.110 0.113 0.124 0.140 0.155 0.169  ||  -0.224 -0.303 -0.104 -0.074 0.019 0.137 0.235 0.326   || dis=0.01 || select=7/8
012/019-th : 0.104 0.110 0.115 0.119 0.134 0.131 0.141 0.147  ||  -0.180 -0.122 -0.079 -0.042 0.081 0.054 0.128 0.171   || dis=0.01 || select=7/8
013/019-th : 0.025 0.035 0.045 0.063 0.082 0.116 0.229 0.404  ||  -1.197 -0.869 -0.619 -0.287 -0.021 0.330 1.009 1.574  || dis=0.18 || select=7/8
014/019-th : 0.038 0.049 0.064 0.082 0.111 0.157 0.226 0.273  ||  -0.983 -0.722 -0.459 -0.215 0.087 0.434 0.799 0.991   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.041 0.052 0.082 0.120 0.235 0.418  ||  -1.193 -1.055 -0.642 -0.413 0.040 0.421 1.095 1.670   || dis=0.18 || select=7/8
016/019-th : 0.055 0.073 0.096 0.126 0.139 0.159 0.171 0.181  ||  -0.742 -0.466 -0.195 0.083 0.174 0.312 0.388 0.440    || dis=0.01 || select=7/8
017/019-th : 0.115 0.110 0.117 0.123 0.133 0.127 0.138 0.136  ||  -0.077 -0.117 -0.055 -0.011 0.073 0.021 0.104 0.095   || dis=0.00 || select=6/8
018/019-th : 0.085 0.102 0.120 0.125 0.132 0.133 0.139 0.164  ||  -0.362 -0.185 -0.024 0.020 0.074 0.084 0.128 0.291    || dis=0.02 || select=7/8
[epoch=259/600] FLOP : 28.21 MB, ratio : 0.6912, Expected-ratio : 0.7000, Discrepancy : 0.071
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:59:09] [epoch=259/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.577 (1.577)  Prec@1 55.86 (55.86) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:59:15] [epoch=259/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.447 (1.987)  Prec@1 57.74 (41.69) Prec@5 96.43 (83.41) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.69 Prec@5 83.41 Error@1 58.31 Error@5 16.59 Loss:1.987
***[2020-01-29 07:59:15]*** VALID [epoch=259/600] loss = 1.987107, accuracy@1 = 41.69, accuracy@5 = 83.41 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:59:15]*** start epoch=260/600 Time Left: [03:00:44], LR=[0.060396 ~ 0.060396], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=260, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.0593836425035104, FLOP=40.81
[Search] : epoch=260/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:59:16] [epoch=260/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.811 (0.811)  Prec@1 71.88 (71.88) Prec@5 98.83 (98.83) Acls-loss 0.877 (0.877) FLOP-Loss 0.000 (0.000) Arch-Loss 0.877 (0.877)
**TRAIN** [2020-01-29 07:59:42] [epoch=260/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.797 (0.781)  Prec@1 70.83 (73.52) Prec@5 99.40 (97.99) Acls-loss 0.797 (0.837) FLOP-Loss 0.000 (0.028) Arch-Loss 0.797 (0.894)
 **TRAIN** Prec@1 73.52 Prec@5 97.99 Error@1 26.48 Error@5 2.01 Base-Loss:0.781, Arch-Loss=0.894
***[2020-01-29 07:59:42]*** TRAIN [epoch=260/600] base-loss = 0.780935, arch-loss = 0.893572, accuracy-1 = 73.52, accuracy-5 = 97.99
[epoch=260/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.856512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.198 0.365  ||  0.2377 -0.5562 0.0565  || discrepancy=0.07 || select=0/3
001/003-th : 0.353 0.133 0.513  ||  0.0444 -0.9305 0.4175  || discrepancy=0.16 || select=2/3
002/003-th : 0.020 0.094 0.886  ||  -1.9595 -0.3909 1.8485  || discrepancy=0.79 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.074 0.095 0.107 0.136 0.154 0.179 0.202  ||  -0.768 -0.447 -0.196 -0.072 0.168 0.294 0.441 0.561   || dis=0.02 || select=7/8
001/019-th : 0.126 0.125 0.124 0.124 0.129 0.128 0.120 0.123  ||  0.009 0.001 -0.010 -0.005 0.032 0.027 -0.038 -0.012   || dis=0.00 || select=4/8
002/019-th : 0.118 0.125 0.124 0.133 0.126 0.133 0.123 0.117  ||  -0.054 0.001 -0.009 0.061 0.006 0.061 -0.012 -0.062   || dis=0.00 || select=3/8
003/019-th : 0.109 0.114 0.120 0.127 0.130 0.133 0.132 0.136  ||  -0.134 -0.092 -0.040 0.022 0.040 0.069 0.060 0.089    || dis=0.00 || select=7/8
004/019-th : 0.111 0.112 0.118 0.117 0.133 0.135 0.139 0.135  ||  -0.114 -0.106 -0.055 -0.063 0.070 0.082 0.111 0.080   || dis=0.00 || select=6/8
005/019-th : 0.114 0.115 0.123 0.122 0.124 0.133 0.134 0.136  ||  -0.091 -0.082 -0.020 -0.029 -0.011 0.062 0.065 0.083  || dis=0.00 || select=7/8
006/019-th : 0.111 0.110 0.115 0.124 0.131 0.133 0.134 0.141  ||  -0.114 -0.122 -0.076 -0.004 0.047 0.064 0.075 0.127   || dis=0.01 || select=7/8
007/019-th : 0.055 0.069 0.090 0.105 0.134 0.148 0.181 0.217  ||  -0.720 -0.505 -0.231 -0.080 0.165 0.264 0.467 0.647   || dis=0.04 || select=7/8
008/019-th : 0.043 0.054 0.072 0.109 0.133 0.168 0.212 0.209  ||  -0.926 -0.697 -0.409 0.013 0.214 0.447 0.678 0.666    || dis=0.00 || select=6/8
009/019-th : 0.091 0.092 0.107 0.113 0.115 0.143 0.161 0.178  ||  -0.288 -0.278 -0.130 -0.069 -0.058 0.162 0.278 0.380  || dis=0.02 || select=7/8
010/019-th : 0.095 0.099 0.111 0.126 0.135 0.139 0.149 0.146  ||  -0.265 -0.216 -0.107 0.022 0.091 0.123 0.188 0.171    || dis=0.00 || select=6/8
011/019-th : 0.097 0.089 0.110 0.115 0.125 0.139 0.155 0.171  ||  -0.231 -0.316 -0.106 -0.062 0.021 0.131 0.236 0.336   || dis=0.02 || select=7/8
012/019-th : 0.101 0.109 0.114 0.119 0.135 0.132 0.142 0.147  ||  -0.202 -0.127 -0.078 -0.042 0.086 0.068 0.140 0.173   || dis=0.01 || select=7/8
013/019-th : 0.025 0.034 0.045 0.061 0.082 0.118 0.234 0.401  ||  -1.202 -0.893 -0.620 -0.315 -0.016 0.352 1.038 1.576  || dis=0.17 || select=7/8
014/019-th : 0.038 0.048 0.062 0.081 0.112 0.158 0.226 0.276  ||  -0.985 -0.741 -0.483 -0.217 0.101 0.446 0.805 1.006   || dis=0.05 || select=7/8
015/019-th : 0.024 0.028 0.041 0.052 0.082 0.118 0.235 0.419  ||  -1.196 -1.049 -0.643 -0.407 0.040 0.409 1.095 1.674   || dis=0.18 || select=7/8
016/019-th : 0.055 0.071 0.097 0.126 0.138 0.160 0.172 0.182  ||  -0.750 -0.490 -0.185 0.079 0.171 0.319 0.391 0.452    || dis=0.01 || select=7/8
017/019-th : 0.114 0.110 0.115 0.121 0.132 0.130 0.139 0.139  ||  -0.086 -0.118 -0.079 -0.024 0.058 0.043 0.114 0.111   || dis=0.00 || select=6/8
018/019-th : 0.085 0.101 0.120 0.125 0.132 0.134 0.140 0.165  ||  -0.369 -0.193 -0.024 0.018 0.075 0.086 0.132 0.298    || dis=0.02 || select=7/8
[epoch=260/600] FLOP : 27.86 MB, ratio : 0.6825, Expected-ratio : 0.7000, Discrepancy : 0.072
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 07:59:42] [epoch=260/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.127 (2.127)  Prec@1 32.81 (32.81) Prec@5 76.56 (76.56) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 07:59:48] [epoch=260/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.400 (2.275)  Prec@1 30.95 (36.42) Prec@5 69.64 (80.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.42 Prec@5 80.26 Error@1 63.58 Error@5 19.74 Loss:2.275
***[2020-01-29 07:59:48]*** VALID [epoch=260/600] loss = 2.274555, accuracy@1 = 36.42, accuracy@5 = 80.26 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 07:59:48]*** start epoch=261/600 Time Left: [03:00:13], LR=[0.060139 ~ 0.060139], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=261, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.046828873623456, FLOP=40.81
[Search] : epoch=261/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 07:59:49] [epoch=261/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.832 (0.832)  Prec@1 69.14 (69.14) Prec@5 98.83 (98.83) Acls-loss 0.674 (0.674) FLOP-Loss 0.000 (0.000) Arch-Loss 0.674 (0.674)
**TRAIN** [2020-01-29 08:00:14] [epoch=261/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.922 (0.783)  Prec@1 69.64 (73.24) Prec@5 97.62 (97.88) Acls-loss 1.010 (0.828) FLOP-Loss 0.000 (0.113) Arch-Loss 1.010 (1.054)
 **TRAIN** Prec@1 73.24 Prec@5 97.88 Error@1 26.76 Error@5 2.12 Base-Loss:0.783, Arch-Loss=1.054
***[2020-01-29 08:00:14]*** TRAIN [epoch=261/600] base-loss = 0.783333, arch-loss = 1.054052, accuracy-1 = 73.24, accuracy-5 = 97.88
[epoch=261/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 16, 32, 28, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.856512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.196 0.361  ||  0.2515 -0.5659 0.0450  || discrepancy=0.08 || select=0/3
001/003-th : 0.357 0.136 0.506  ||  0.0561 -0.9068 0.4051  || discrepancy=0.15 || select=2/3
002/003-th : 0.019 0.094 0.887  ||  -1.9729 -0.3870 1.8598  || discrepancy=0.79 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.094 0.109 0.136 0.156 0.175 0.201  ||  -0.752 -0.443 -0.206 -0.059 0.166 0.300 0.419 0.557   || dis=0.03 || select=7/8
001/019-th : 0.128 0.126 0.124 0.126 0.129 0.126 0.119 0.122  ||  0.028 0.007 -0.008 0.005 0.033 0.010 -0.048 -0.025    || dis=0.00 || select=4/8
002/019-th : 0.121 0.126 0.126 0.133 0.123 0.132 0.123 0.116  ||  -0.034 0.008 0.004 0.058 -0.015 0.054 -0.020 -0.076   || dis=0.00 || select=3/8
003/019-th : 0.109 0.113 0.120 0.130 0.129 0.133 0.131 0.135  ||  -0.134 -0.092 -0.039 0.045 0.038 0.069 0.056 0.080    || dis=0.00 || select=7/8
004/019-th : 0.112 0.112 0.117 0.117 0.133 0.136 0.138 0.134  ||  -0.105 -0.105 -0.061 -0.062 0.070 0.089 0.106 0.074   || dis=0.00 || select=6/8
005/019-th : 0.116 0.117 0.123 0.122 0.122 0.134 0.131 0.135  ||  -0.078 -0.070 -0.019 -0.024 -0.023 0.072 0.044 0.075  || dis=0.00 || select=7/8
006/019-th : 0.112 0.110 0.116 0.123 0.129 0.134 0.134 0.141  ||  -0.103 -0.125 -0.069 -0.015 0.036 0.073 0.071 0.124   || dis=0.01 || select=7/8
007/019-th : 0.055 0.069 0.090 0.104 0.136 0.149 0.179 0.217  ||  -0.723 -0.496 -0.231 -0.089 0.180 0.272 0.453 0.643   || dis=0.04 || select=7/8
008/019-th : 0.043 0.053 0.072 0.110 0.135 0.168 0.211 0.209  ||  -0.915 -0.714 -0.404 0.020 0.223 0.447 0.673 0.662    || dis=0.00 || select=6/8
009/019-th : 0.091 0.092 0.106 0.114 0.117 0.142 0.159 0.177  ||  -0.285 -0.277 -0.138 -0.063 -0.037 0.157 0.269 0.376  || dis=0.02 || select=7/8
010/019-th : 0.094 0.101 0.113 0.126 0.135 0.136 0.149 0.147  ||  -0.271 -0.203 -0.091 0.019 0.090 0.097 0.190 0.172    || dis=0.00 || select=6/8
011/019-th : 0.097 0.091 0.110 0.115 0.123 0.141 0.153 0.169  ||  -0.227 -0.298 -0.101 -0.062 0.008 0.141 0.226 0.324   || dis=0.02 || select=7/8
012/019-th : 0.102 0.111 0.115 0.120 0.134 0.132 0.141 0.145  ||  -0.194 -0.112 -0.075 -0.031 0.081 0.061 0.132 0.160   || dis=0.00 || select=7/8
013/019-th : 0.025 0.033 0.045 0.060 0.083 0.116 0.235 0.401  ||  -1.190 -0.910 -0.611 -0.317 -0.001 0.334 1.042 1.576  || dis=0.17 || select=7/8
014/019-th : 0.037 0.048 0.062 0.080 0.110 0.157 0.230 0.275  ||  -1.002 -0.729 -0.479 -0.229 0.089 0.449 0.827 1.008   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.041 0.052 0.082 0.119 0.235 0.420  ||  -1.194 -1.050 -0.647 -0.410 0.042 0.415 1.094 1.676   || dis=0.18 || select=7/8
016/019-th : 0.056 0.071 0.098 0.125 0.140 0.158 0.171 0.181  ||  -0.734 -0.488 -0.173 0.071 0.184 0.303 0.386 0.443    || dis=0.01 || select=7/8
017/019-th : 0.115 0.110 0.115 0.124 0.131 0.129 0.138 0.137  ||  -0.075 -0.120 -0.074 -0.003 0.055 0.040 0.102 0.099   || dis=0.00 || select=6/8
018/019-th : 0.085 0.103 0.120 0.123 0.133 0.132 0.140 0.163  ||  -0.369 -0.172 -0.021 0.006 0.085 0.073 0.134 0.286    || dis=0.02 || select=7/8
[epoch=261/600] FLOP : 27.86 MB, ratio : 0.6825, Expected-ratio : 0.7000, Discrepancy : 0.072
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:00:14] [epoch=261/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.226 (1.226)  Prec@1 59.38 (59.38) Prec@5 94.92 (94.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:00:20] [epoch=261/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.814 (2.119)  Prec@1 51.79 (38.68) Prec@5 91.67 (82.24) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.68 Prec@5 82.24 Error@1 61.32 Error@5 17.76 Loss:2.119
***[2020-01-29 08:00:20]*** VALID [epoch=261/600] loss = 2.119082, accuracy@1 = 38.68, accuracy@5 = 82.24 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:00:20]*** start epoch=262/600 Time Left: [02:59:42], LR=[0.059883 ~ 0.059883], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=262, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.0342604839288594, FLOP=40.81
[Search] : epoch=262/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:00:21] [epoch=262/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.942 (0.942)  Prec@1 66.80 (66.80) Prec@5 97.66 (97.66) Acls-loss 0.841 (0.841) FLOP-Loss 0.000 (0.000) Arch-Loss 0.841 (0.841)
**TRAIN** [2020-01-29 08:00:45] [epoch=262/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.701 (0.788)  Prec@1 72.62 (73.03) Prec@5 99.40 (97.95) Acls-loss 0.896 (0.841) FLOP-Loss 0.000 (0.085) Arch-Loss 0.896 (1.011)
 **TRAIN** Prec@1 73.03 Prec@5 97.95 Error@1 26.97 Error@5 2.05 Base-Loss:0.788, Arch-Loss=1.011
***[2020-01-29 08:00:46]*** TRAIN [epoch=262/600] base-loss = 0.787510, arch-loss = 1.010570, accuracy-1 = 73.03, accuracy-5 = 97.95
[epoch=262/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 16, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.079296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.195 0.360  ||  0.2550 -0.5683 0.0431  || discrepancy=0.09 || select=0/3
001/003-th : 0.358 0.137 0.505  ||  0.0587 -0.9008 0.4036  || discrepancy=0.15 || select=2/3
002/003-th : 0.019 0.093 0.889  ||  -1.9825 -0.3894 1.8713  || discrepancy=0.80 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.075 0.092 0.108 0.135 0.153 0.180 0.204  ||  -0.769 -0.429 -0.226 -0.060 0.157 0.288 0.445 0.571   || dis=0.02 || select=7/8
001/019-th : 0.129 0.125 0.126 0.125 0.128 0.126 0.119 0.121  ||  0.030 0.001 0.011 0.004 0.023 0.010 -0.048 -0.028     || dis=0.00 || select=0/8
002/019-th : 0.120 0.127 0.126 0.135 0.123 0.133 0.121 0.116  ||  -0.040 0.013 0.008 0.074 -0.017 0.066 -0.030 -0.077   || dis=0.00 || select=3/8
003/019-th : 0.109 0.113 0.121 0.128 0.130 0.132 0.133 0.135  ||  -0.136 -0.098 -0.027 0.033 0.044 0.057 0.066 0.082    || dis=0.00 || select=7/8
004/019-th : 0.112 0.114 0.119 0.116 0.132 0.136 0.137 0.133  ||  -0.101 -0.088 -0.045 -0.069 0.060 0.090 0.098 0.063   || dis=0.00 || select=6/8
005/019-th : 0.116 0.118 0.122 0.121 0.125 0.133 0.131 0.133  ||  -0.074 -0.056 -0.022 -0.034 -0.002 0.065 0.047 0.060  || dis=0.00 || select=5/8
006/019-th : 0.112 0.110 0.116 0.122 0.130 0.133 0.136 0.140  ||  -0.103 -0.121 -0.068 -0.021 0.042 0.066 0.088 0.114   || dis=0.00 || select=7/8
007/019-th : 0.056 0.069 0.091 0.104 0.137 0.150 0.178 0.216  ||  -0.712 -0.507 -0.228 -0.093 0.186 0.279 0.448 0.640   || dis=0.04 || select=7/8
008/019-th : 0.043 0.051 0.073 0.107 0.135 0.168 0.210 0.212  ||  -0.911 -0.743 -0.385 0.001 0.233 0.449 0.673 0.679    || dis=0.00 || select=7/8
009/019-th : 0.091 0.092 0.106 0.117 0.118 0.139 0.160 0.177  ||  -0.292 -0.276 -0.138 -0.040 -0.034 0.136 0.272 0.375  || dis=0.02 || select=7/8
010/019-th : 0.095 0.102 0.113 0.126 0.134 0.135 0.149 0.146  ||  -0.265 -0.191 -0.091 0.018 0.085 0.091 0.191 0.165    || dis=0.00 || select=6/8
011/019-th : 0.097 0.092 0.112 0.116 0.124 0.140 0.152 0.168  ||  -0.231 -0.289 -0.093 -0.056 0.016 0.133 0.217 0.317   || dis=0.02 || select=7/8
012/019-th : 0.103 0.112 0.115 0.122 0.133 0.129 0.141 0.145  ||  -0.187 -0.100 -0.072 -0.014 0.070 0.040 0.132 0.154   || dis=0.00 || select=7/8
013/019-th : 0.025 0.033 0.044 0.060 0.083 0.113 0.237 0.405  ||  -1.207 -0.917 -0.618 -0.313 0.005 0.320 1.056 1.594   || dis=0.17 || select=7/8
014/019-th : 0.037 0.048 0.063 0.080 0.109 0.159 0.230 0.275  ||  -1.001 -0.741 -0.471 -0.232 0.085 0.459 0.830 1.006   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.041 0.052 0.080 0.121 0.234 0.421  ||  -1.185 -1.055 -0.643 -0.409 0.019 0.428 1.092 1.678   || dis=0.19 || select=7/8
016/019-th : 0.056 0.071 0.098 0.124 0.143 0.158 0.170 0.180  ||  -0.733 -0.488 -0.173 0.064 0.210 0.306 0.381 0.437    || dis=0.01 || select=7/8
017/019-th : 0.116 0.111 0.115 0.125 0.131 0.128 0.137 0.136  ||  -0.072 -0.109 -0.076 0.005 0.050 0.033 0.101 0.093    || dis=0.00 || select=6/8
018/019-th : 0.085 0.104 0.120 0.124 0.134 0.132 0.139 0.162  ||  -0.368 -0.164 -0.020 0.013 0.086 0.074 0.123 0.282    || dis=0.02 || select=7/8
[epoch=262/600] FLOP : 27.08 MB, ratio : 0.6635, Expected-ratio : 0.7000, Discrepancy : 0.072
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:00:46] [epoch=262/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.438 (2.438)  Prec@1 24.61 (24.61) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:00:52] [epoch=262/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.805 (2.181)  Prec@1 25.00 (38.06) Prec@5 72.02 (81.92) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.06 Prec@5 81.92 Error@1 61.94 Error@5 18.08 Loss:2.181
***[2020-01-29 08:00:52]*** VALID [epoch=262/600] loss = 2.181246, accuracy@1 = 38.06, accuracy@5 = 81.92 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:00:52]*** start epoch=263/600 Time Left: [02:59:10], LR=[0.059626 ~ 0.059626], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=263, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.0216788179884735, FLOP=40.81
[Search] : epoch=263/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:00:53] [epoch=263/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.781 (0.781)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 0.919 (0.919) FLOP-Loss 0.000 (0.000) Arch-Loss 0.919 (0.919)
**TRAIN** [2020-01-29 08:01:17] [epoch=263/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.768 (0.786)  Prec@1 72.62 (73.18) Prec@5 98.81 (97.90) Acls-loss 0.732 (0.807) FLOP-Loss 0.000 (0.028) Arch-Loss 0.732 (0.863)
 **TRAIN** Prec@1 73.18 Prec@5 97.90 Error@1 26.82 Error@5 2.10 Base-Loss:0.786, Arch-Loss=0.863
***[2020-01-29 08:01:17]*** TRAIN [epoch=263/600] base-loss = 0.785844, arch-loss = 0.863380, accuracy-1 = 73.18, accuracy-5 = 97.90
[epoch=263/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.23904)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.195 0.362  ||  0.2510 -0.5725 0.0490  || discrepancy=0.08 || select=0/3
001/003-th : 0.357 0.138 0.506  ||  0.0572 -0.8937 0.4060  || discrepancy=0.15 || select=2/3
002/003-th : 0.018 0.089 0.893  ||  -2.0026 -0.4074 1.8974  || discrepancy=0.80 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.075 0.091 0.109 0.136 0.154 0.179 0.202  ||  -0.770 -0.427 -0.233 -0.053 0.168 0.294 0.440 0.564   || dis=0.02 || select=7/8
001/019-th : 0.129 0.125 0.126 0.125 0.127 0.128 0.119 0.121  ||  0.031 -0.003 0.010 -0.003 0.016 0.026 -0.048 -0.029   || dis=0.00 || select=0/8
002/019-th : 0.119 0.126 0.127 0.132 0.125 0.133 0.122 0.116  ||  -0.047 0.009 0.015 0.059 0.000 0.062 -0.027 -0.072    || dis=0.00 || select=5/8
003/019-th : 0.106 0.114 0.120 0.129 0.132 0.132 0.132 0.135  ||  -0.156 -0.087 -0.030 0.041 0.059 0.061 0.060 0.086    || dis=0.00 || select=7/8
004/019-th : 0.112 0.115 0.119 0.116 0.133 0.133 0.138 0.133  ||  -0.105 -0.081 -0.049 -0.068 0.066 0.067 0.105 0.066   || dis=0.01 || select=6/8
005/019-th : 0.115 0.118 0.124 0.123 0.124 0.133 0.131 0.132  ||  -0.081 -0.059 -0.008 -0.013 -0.010 0.061 0.047 0.058  || dis=0.00 || select=5/8
006/019-th : 0.113 0.111 0.115 0.122 0.130 0.132 0.137 0.141  ||  -0.102 -0.119 -0.079 -0.024 0.042 0.053 0.094 0.121   || dis=0.00 || select=7/8
007/019-th : 0.056 0.067 0.089 0.104 0.138 0.150 0.180 0.216  ||  -0.700 -0.531 -0.241 -0.091 0.197 0.278 0.463 0.641   || dis=0.04 || select=7/8
008/019-th : 0.043 0.051 0.071 0.106 0.135 0.171 0.211 0.213  ||  -0.910 -0.738 -0.415 -0.014 0.231 0.467 0.681 0.688   || dis=0.00 || select=7/8
009/019-th : 0.091 0.092 0.105 0.116 0.118 0.141 0.161 0.177  ||  -0.291 -0.279 -0.151 -0.046 -0.033 0.146 0.284 0.374  || dis=0.02 || select=7/8
010/019-th : 0.094 0.102 0.114 0.126 0.133 0.135 0.149 0.147  ||  -0.271 -0.192 -0.080 0.019 0.077 0.091 0.185 0.172    || dis=0.00 || select=6/8
011/019-th : 0.097 0.093 0.113 0.115 0.124 0.139 0.150 0.168  ||  -0.233 -0.278 -0.080 -0.060 0.016 0.129 0.205 0.316   || dis=0.02 || select=7/8
012/019-th : 0.102 0.110 0.116 0.123 0.132 0.130 0.142 0.144  ||  -0.191 -0.115 -0.069 -0.004 0.065 0.047 0.140 0.152   || dis=0.00 || select=7/8
013/019-th : 0.024 0.032 0.045 0.060 0.081 0.113 0.235 0.409  ||  -1.213 -0.925 -0.610 -0.308 -0.008 0.321 1.053 1.608  || dis=0.17 || select=7/8
014/019-th : 0.037 0.048 0.063 0.080 0.110 0.158 0.228 0.277  ||  -0.991 -0.749 -0.469 -0.227 0.086 0.450 0.817 1.014   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.041 0.053 0.080 0.121 0.234 0.420  ||  -1.194 -1.060 -0.643 -0.396 0.017 0.432 1.093 1.679   || dis=0.19 || select=7/8
016/019-th : 0.056 0.071 0.097 0.124 0.143 0.158 0.170 0.181  ||  -0.724 -0.490 -0.186 0.062 0.207 0.305 0.382 0.443    || dis=0.01 || select=7/8
017/019-th : 0.116 0.112 0.115 0.125 0.130 0.128 0.137 0.137  ||  -0.072 -0.105 -0.075 0.001 0.044 0.031 0.099 0.096    || dis=0.00 || select=6/8
018/019-th : 0.084 0.104 0.119 0.125 0.135 0.131 0.140 0.162  ||  -0.376 -0.161 -0.031 0.016 0.099 0.070 0.131 0.279    || dis=0.02 || select=7/8
[epoch=263/600] FLOP : 27.24 MB, ratio : 0.6674, Expected-ratio : 0.7000, Discrepancy : 0.072
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:01:18] [epoch=263/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.362 (2.362)  Prec@1 38.67 (38.67) Prec@5 75.39 (75.39) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:01:24] [epoch=263/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.619 (2.215)  Prec@1 53.57 (37.90) Prec@5 93.45 (80.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.90 Prec@5 80.94 Error@1 62.10 Error@5 19.06 Loss:2.215
***[2020-01-29 08:01:24]*** VALID [epoch=263/600] loss = 2.215039, accuracy@1 = 37.90, accuracy@5 = 80.94 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:01:24]*** start epoch=264/600 Time Left: [02:58:37], LR=[0.059369 ~ 0.059369], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=264, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=3.009084220735026, FLOP=40.81
[Search] : epoch=264/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:01:24] [epoch=264/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.825 (0.825)  Prec@1 72.66 (72.66) Prec@5 97.66 (97.66) Acls-loss 0.878 (0.878) FLOP-Loss 0.000 (0.000) Arch-Loss 0.878 (0.878)
**TRAIN** [2020-01-29 08:01:49] [epoch=264/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.841 (0.778)  Prec@1 71.43 (73.35) Prec@5 97.02 (98.07) Acls-loss 0.750 (0.831) FLOP-Loss 0.000 (0.057) Arch-Loss 0.750 (0.944)
 **TRAIN** Prec@1 73.35 Prec@5 98.07 Error@1 26.65 Error@5 1.93 Base-Loss:0.778, Arch-Loss=0.944
***[2020-01-29 08:01:49]*** TRAIN [epoch=264/600] base-loss = 0.778099, arch-loss = 0.944130, accuracy-1 = 73.35, accuracy-5 = 98.07
[epoch=264/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.067008)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.194 0.363  ||  0.2502 -0.5728 0.0512  || discrepancy=0.08 || select=0/3
001/003-th : 0.356 0.137 0.507  ||  0.0555 -0.9003 0.4100  || discrepancy=0.15 || select=2/3
002/003-th : 0.018 0.089 0.893  ||  -1.9927 -0.4108 1.8960  || discrepancy=0.80 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.093 0.108 0.134 0.153 0.180 0.203  ||  -0.765 -0.436 -0.211 -0.060 0.155 0.286 0.445 0.566   || dis=0.02 || select=7/8
001/019-th : 0.128 0.124 0.126 0.126 0.126 0.128 0.120 0.122  ||  0.028 -0.010 0.008 0.009 0.009 0.026 -0.044 -0.024    || dis=0.00 || select=0/8
002/019-th : 0.118 0.126 0.126 0.131 0.127 0.133 0.122 0.116  ||  -0.052 0.010 0.014 0.052 0.021 0.068 -0.026 -0.075    || dis=0.00 || select=5/8
003/019-th : 0.105 0.115 0.121 0.129 0.132 0.131 0.131 0.136  ||  -0.168 -0.074 -0.027 0.040 0.058 0.052 0.058 0.092    || dis=0.00 || select=7/8
004/019-th : 0.113 0.115 0.119 0.116 0.133 0.132 0.139 0.133  ||  -0.100 -0.079 -0.044 -0.070 0.061 0.055 0.109 0.064   || dis=0.01 || select=6/8
005/019-th : 0.113 0.117 0.126 0.124 0.125 0.131 0.130 0.132  ||  -0.096 -0.062 0.009 -0.004 0.003 0.053 0.045 0.060    || dis=0.00 || select=7/8
006/019-th : 0.113 0.111 0.116 0.120 0.129 0.133 0.137 0.141  ||  -0.098 -0.118 -0.073 -0.038 0.034 0.067 0.091 0.119   || dis=0.00 || select=7/8
007/019-th : 0.055 0.066 0.089 0.105 0.137 0.153 0.182 0.213  ||  -0.714 -0.538 -0.239 -0.079 0.190 0.299 0.473 0.631   || dis=0.03 || select=7/8
008/019-th : 0.043 0.051 0.070 0.105 0.137 0.171 0.210 0.214  ||  -0.920 -0.734 -0.428 -0.016 0.251 0.468 0.674 0.696   || dis=0.00 || select=7/8
009/019-th : 0.090 0.092 0.106 0.117 0.116 0.138 0.163 0.177  ||  -0.301 -0.275 -0.138 -0.036 -0.045 0.129 0.292 0.374  || dis=0.01 || select=7/8
010/019-th : 0.095 0.102 0.114 0.125 0.134 0.135 0.149 0.147  ||  -0.266 -0.193 -0.079 0.008 0.080 0.092 0.186 0.171    || dis=0.00 || select=6/8
011/019-th : 0.097 0.093 0.113 0.117 0.123 0.138 0.150 0.168  ||  -0.238 -0.272 -0.082 -0.042 -0.000 0.122 0.205 0.318  || dis=0.02 || select=7/8
012/019-th : 0.103 0.110 0.116 0.123 0.131 0.129 0.144 0.144  ||  -0.183 -0.123 -0.069 -0.005 0.059 0.039 0.153 0.149   || dis=0.00 || select=6/8
013/019-th : 0.025 0.032 0.044 0.059 0.079 0.114 0.237 0.410  ||  -1.195 -0.929 -0.613 -0.324 -0.031 0.336 1.065 1.613  || dis=0.17 || select=7/8
014/019-th : 0.037 0.048 0.061 0.080 0.110 0.157 0.226 0.280  ||  -0.987 -0.745 -0.502 -0.223 0.097 0.449 0.815 1.029   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.041 0.053 0.079 0.121 0.230 0.424  ||  -1.192 -1.052 -0.647 -0.389 0.007 0.435 1.076 1.688   || dis=0.19 || select=7/8
016/019-th : 0.057 0.072 0.095 0.125 0.144 0.158 0.170 0.179  ||  -0.711 -0.483 -0.202 0.070 0.216 0.307 0.381 0.431    || dis=0.01 || select=7/8
017/019-th : 0.117 0.113 0.115 0.125 0.128 0.128 0.137 0.137  ||  -0.066 -0.096 -0.083 0.001 0.027 0.030 0.094 0.098    || dis=0.00 || select=7/8
018/019-th : 0.086 0.104 0.118 0.125 0.136 0.131 0.139 0.160  ||  -0.350 -0.162 -0.035 0.018 0.104 0.064 0.125 0.266    || dis=0.02 || select=7/8
[epoch=264/600] FLOP : 27.07 MB, ratio : 0.6632, Expected-ratio : 0.7000, Discrepancy : 0.072
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:01:49] [epoch=264/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.204 (1.204)  Prec@1 64.84 (64.84) Prec@5 96.88 (96.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:01:56] [epoch=264/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.490 (2.223)  Prec@1 45.83 (39.90) Prec@5 86.31 (83.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.90 Prec@5 83.26 Error@1 60.10 Error@5 16.74 Loss:2.223
***[2020-01-29 08:01:56]*** VALID [epoch=264/600] loss = 2.222591, accuracy@1 = 39.90, accuracy@5 = 83.26 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:01:56]*** start epoch=265/600 Time Left: [02:58:06], LR=[0.059112 ~ 0.059112], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=265, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.996477037455762, FLOP=40.81
[Search] : epoch=265/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:01:56] [epoch=265/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.704 (0.704)  Prec@1 77.34 (77.34) Prec@5 98.05 (98.05) Acls-loss 0.800 (0.800) FLOP-Loss 0.000 (0.000) Arch-Loss 0.800 (0.800)
**TRAIN** [2020-01-29 08:02:21] [epoch=265/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.668 (0.792)  Prec@1 75.60 (72.87) Prec@5 99.40 (97.96) Acls-loss 0.877 (0.825) FLOP-Loss 0.000 (0.057) Arch-Loss 0.877 (0.938)
 **TRAIN** Prec@1 72.87 Prec@5 97.96 Error@1 27.13 Error@5 2.04 Base-Loss:0.792, Arch-Loss=0.938
***[2020-01-29 08:02:21]*** TRAIN [epoch=265/600] base-loss = 0.791691, arch-loss = 0.937992, accuracy-1 = 72.87, accuracy-5 = 97.96
[epoch=265/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 12, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.550912)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.442 0.195 0.363  ||  0.2498 -0.5674 0.0523  || discrepancy=0.08 || select=0/3
001/003-th : 0.356 0.134 0.510  ||  0.0541 -0.9216 0.4159  || discrepancy=0.15 || select=2/3
002/003-th : 0.018 0.087 0.895  ||  -2.0076 -0.4153 1.9121  || discrepancy=0.81 || select=2/3
-----------------------------------------------
000/019-th : 0.054 0.074 0.093 0.107 0.134 0.157 0.179 0.202  ||  -0.757 -0.446 -0.216 -0.070 0.156 0.312 0.441 0.564   || dis=0.02 || select=7/8
001/019-th : 0.129 0.124 0.128 0.125 0.125 0.128 0.120 0.122  ||  0.027 -0.008 0.021 -0.002 -0.000 0.023 -0.042 -0.025  || dis=0.00 || select=0/8
002/019-th : 0.119 0.125 0.127 0.130 0.127 0.133 0.122 0.116  ||  -0.047 0.002 0.020 0.044 0.020 0.066 -0.020 -0.076    || dis=0.00 || select=5/8
003/019-th : 0.104 0.116 0.122 0.129 0.131 0.131 0.131 0.135  ||  -0.173 -0.066 -0.020 0.039 0.057 0.054 0.055 0.088    || dis=0.00 || select=7/8
004/019-th : 0.113 0.115 0.119 0.117 0.132 0.132 0.140 0.133  ||  -0.100 -0.085 -0.047 -0.062 0.054 0.056 0.112 0.066   || dis=0.01 || select=6/8
005/019-th : 0.113 0.117 0.124 0.124 0.126 0.133 0.131 0.132  ||  -0.095 -0.066 -0.003 -0.004 0.008 0.066 0.050 0.057   || dis=0.00 || select=5/8
006/019-th : 0.113 0.110 0.115 0.119 0.131 0.135 0.136 0.141  ||  -0.095 -0.126 -0.077 -0.051 0.046 0.077 0.088 0.123   || dis=0.00 || select=7/8
007/019-th : 0.056 0.066 0.089 0.105 0.137 0.152 0.181 0.214  ||  -0.706 -0.546 -0.245 -0.076 0.192 0.294 0.471 0.638   || dis=0.03 || select=7/8
008/019-th : 0.043 0.051 0.068 0.105 0.136 0.168 0.214 0.215  ||  -0.915 -0.742 -0.443 -0.012 0.244 0.455 0.698 0.701   || dis=0.00 || select=7/8
009/019-th : 0.090 0.093 0.104 0.118 0.116 0.138 0.163 0.177  ||  -0.298 -0.272 -0.154 -0.028 -0.048 0.128 0.295 0.374  || dis=0.01 || select=7/8
010/019-th : 0.096 0.103 0.114 0.123 0.132 0.135 0.149 0.148  ||  -0.253 -0.188 -0.082 -0.006 0.063 0.088 0.185 0.179   || dis=0.00 || select=6/8
011/019-th : 0.097 0.092 0.112 0.116 0.124 0.137 0.155 0.168  ||  -0.235 -0.287 -0.091 -0.054 0.013 0.111 0.236 0.317   || dis=0.01 || select=7/8
012/019-th : 0.102 0.110 0.115 0.123 0.131 0.131 0.145 0.143  ||  -0.194 -0.122 -0.070 -0.010 0.058 0.053 0.161 0.147   || dis=0.00 || select=6/8
013/019-th : 0.025 0.032 0.044 0.060 0.078 0.115 0.238 0.408  ||  -1.197 -0.926 -0.615 -0.311 -0.047 0.340 1.069 1.608  || dis=0.17 || select=7/8
014/019-th : 0.038 0.048 0.061 0.081 0.111 0.158 0.225 0.280  ||  -0.984 -0.741 -0.505 -0.219 0.100 0.450 0.805 1.026   || dis=0.06 || select=7/8
015/019-th : 0.024 0.027 0.041 0.054 0.079 0.120 0.229 0.426  ||  -1.183 -1.064 -0.646 -0.379 0.009 0.423 1.072 1.692   || dis=0.20 || select=7/8
016/019-th : 0.056 0.072 0.094 0.127 0.143 0.158 0.171 0.178  ||  -0.726 -0.483 -0.206 0.094 0.211 0.306 0.387 0.430    || dis=0.01 || select=7/8
017/019-th : 0.115 0.114 0.114 0.124 0.128 0.131 0.137 0.137  ||  -0.079 -0.090 -0.091 -0.002 0.028 0.049 0.099 0.097   || dis=0.00 || select=6/8
018/019-th : 0.086 0.105 0.118 0.125 0.136 0.132 0.138 0.160  ||  -0.352 -0.156 -0.036 0.019 0.100 0.074 0.118 0.264    || dis=0.02 || select=7/8
[epoch=265/600] FLOP : 26.55 MB, ratio : 0.6505, Expected-ratio : 0.7000, Discrepancy : 0.073
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:02:21] [epoch=265/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.362 (2.362)  Prec@1 24.22 (24.22) Prec@5 69.14 (69.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:02:27] [epoch=265/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.519 (2.490)  Prec@1 45.83 (37.03) Prec@5 94.64 (80.36) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.03 Prec@5 80.36 Error@1 62.97 Error@5 19.64 Loss:2.490
***[2020-01-29 08:02:27]*** VALID [epoch=265/600] loss = 2.490487, accuracy@1 = 37.03, accuracy@5 = 80.36 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:02:27]*** start epoch=266/600 Time Left: [02:57:33], LR=[0.058854 ~ 0.058854], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=266, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.9838576137829795, FLOP=40.81
[Search] : epoch=266/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:02:28] [epoch=266/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.822 (0.822)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 0.788 (0.788) FLOP-Loss 0.000 (0.000) Arch-Loss 0.788 (0.788)
**TRAIN** [2020-01-29 08:02:52] [epoch=266/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.591 (0.759)  Prec@1 79.17 (73.90) Prec@5 98.81 (98.22) Acls-loss 0.921 (0.827) FLOP-Loss 0.000 (0.028) Arch-Loss 0.921 (0.884)
 **TRAIN** Prec@1 73.90 Prec@5 98.22 Error@1 26.10 Error@5 1.78 Base-Loss:0.759, Arch-Loss=0.884
***[2020-01-29 08:02:52]*** TRAIN [epoch=266/600] base-loss = 0.759061, arch-loss = 0.883664, accuracy-1 = 73.90, accuracy-5 = 98.22
[epoch=266/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 12, 16, 32, 32, 32, 32, 32, 28, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.140736)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.441 0.193 0.365  ||  0.2467 -0.5781 0.0581  || discrepancy=0.08 || select=0/3
001/003-th : 0.353 0.135 0.512  ||  0.0487 -0.9143 0.4218  || discrepancy=0.16 || select=2/3
002/003-th : 0.017 0.085 0.898  ||  -2.0258 -0.4235 1.9324  || discrepancy=0.81 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.072 0.091 0.106 0.135 0.158 0.184 0.201  ||  -0.761 -0.464 -0.229 -0.080 0.166 0.321 0.474 0.562   || dis=0.02 || select=7/8
001/019-th : 0.128 0.123 0.128 0.125 0.125 0.127 0.120 0.123  ||  0.026 -0.017 0.023 0.003 -0.001 0.018 -0.038 -0.019   || dis=0.00 || select=0/8
002/019-th : 0.118 0.125 0.127 0.130 0.128 0.133 0.123 0.116  ||  -0.052 0.002 0.021 0.040 0.024 0.065 -0.014 -0.076    || dis=0.00 || select=5/8
003/019-th : 0.104 0.116 0.122 0.128 0.130 0.131 0.132 0.137  ||  -0.179 -0.072 -0.017 0.034 0.049 0.051 0.062 0.099    || dis=0.01 || select=7/8
004/019-th : 0.113 0.115 0.118 0.116 0.131 0.134 0.140 0.134  ||  -0.103 -0.083 -0.055 -0.074 0.052 0.071 0.113 0.070   || dis=0.01 || select=6/8
005/019-th : 0.113 0.115 0.124 0.122 0.127 0.135 0.131 0.132  ||  -0.099 -0.076 -0.005 -0.018 0.022 0.078 0.054 0.059   || dis=0.00 || select=5/8
006/019-th : 0.113 0.110 0.115 0.117 0.132 0.133 0.136 0.143  ||  -0.102 -0.123 -0.083 -0.063 0.056 0.063 0.088 0.139   || dis=0.01 || select=7/8
007/019-th : 0.055 0.065 0.090 0.106 0.135 0.150 0.182 0.217  ||  -0.722 -0.550 -0.229 -0.070 0.179 0.282 0.475 0.651   || dis=0.04 || select=7/8
008/019-th : 0.042 0.051 0.068 0.105 0.136 0.169 0.214 0.215  ||  -0.938 -0.732 -0.444 -0.011 0.249 0.463 0.698 0.703   || dis=0.00 || select=7/8
009/019-th : 0.091 0.093 0.104 0.117 0.116 0.136 0.165 0.177  ||  -0.294 -0.271 -0.156 -0.036 -0.045 0.109 0.307 0.377  || dis=0.01 || select=7/8
010/019-th : 0.096 0.103 0.111 0.123 0.131 0.136 0.150 0.150  ||  -0.254 -0.187 -0.106 -0.006 0.058 0.097 0.189 0.190   || dis=0.00 || select=7/8
011/019-th : 0.097 0.093 0.112 0.113 0.125 0.138 0.154 0.168  ||  -0.229 -0.279 -0.089 -0.078 0.017 0.120 0.229 0.317   || dis=0.01 || select=7/8
012/019-th : 0.101 0.110 0.115 0.122 0.132 0.130 0.147 0.143  ||  -0.207 -0.122 -0.072 -0.014 0.068 0.053 0.170 0.148   || dis=0.00 || select=6/8
013/019-th : 0.024 0.032 0.044 0.060 0.078 0.114 0.238 0.410  ||  -1.203 -0.936 -0.619 -0.308 -0.043 0.340 1.070 1.616  || dis=0.17 || select=7/8
014/019-th : 0.038 0.047 0.059 0.081 0.109 0.158 0.225 0.282  ||  -0.978 -0.749 -0.522 -0.214 0.089 0.457 0.810 1.038   || dis=0.06 || select=7/8
015/019-th : 0.024 0.027 0.041 0.053 0.081 0.120 0.230 0.425  ||  -1.172 -1.063 -0.657 -0.399 0.029 0.426 1.076 1.689   || dis=0.19 || select=7/8
016/019-th : 0.055 0.071 0.095 0.127 0.142 0.160 0.170 0.179  ||  -0.744 -0.484 -0.199 0.092 0.204 0.321 0.385 0.435    || dis=0.01 || select=7/8
017/019-th : 0.115 0.114 0.113 0.124 0.125 0.132 0.139 0.138  ||  -0.082 -0.088 -0.099 -0.005 0.004 0.059 0.112 0.100   || dis=0.00 || select=6/8
018/019-th : 0.086 0.105 0.119 0.123 0.136 0.133 0.140 0.160  ||  -0.358 -0.160 -0.033 0.001 0.101 0.079 0.131 0.266    || dis=0.02 || select=7/8
[epoch=266/600] FLOP : 27.14 MB, ratio : 0.6650, Expected-ratio : 0.7000, Discrepancy : 0.073
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:02:52] [epoch=266/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.024 (2.024)  Prec@1 35.16 (35.16) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:02:58] [epoch=266/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.307 (2.245)  Prec@1 36.31 (36.57) Prec@5 79.17 (80.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.57 Prec@5 80.43 Error@1 63.43 Error@5 19.57 Loss:2.245
***[2020-01-29 08:02:59]*** VALID [epoch=266/600] loss = 2.245062, accuracy@1 = 36.57, accuracy@5 = 80.43 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:02:59]*** start epoch=267/600 Time Left: [02:57:01], LR=[0.058596 ~ 0.058596], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=267, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.9712262956845534, FLOP=40.81
[Search] : epoch=267/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:02:59] [epoch=267/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.687 (0.687)  Prec@1 77.34 (77.34) Prec@5 99.22 (99.22) Acls-loss 0.890 (0.890) FLOP-Loss 0.000 (0.000) Arch-Loss 0.890 (0.890)
**TRAIN** [2020-01-29 08:03:24] [epoch=267/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.810 (0.782)  Prec@1 72.02 (73.33) Prec@5 99.40 (97.91) Acls-loss 0.754 (0.815) FLOP-Loss -2.765 (0.038) Arch-Loss -4.777 (0.892)
 **TRAIN** Prec@1 73.33 Prec@5 97.91 Error@1 26.67 Error@5 2.09 Base-Loss:0.782, Arch-Loss=0.892
***[2020-01-29 08:03:24]*** TRAIN [epoch=267/600] base-loss = 0.782498, arch-loss = 0.891858, accuracy-1 = 73.33, accuracy-5 = 97.91
[epoch=267/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 12, 16, 14, 12, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.615296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.195 0.366  ||  0.2447 -0.5686 0.0603  || discrepancy=0.07 || select=0/3
001/003-th : 0.352 0.133 0.515  ||  0.0463 -0.9229 0.4271  || discrepancy=0.16 || select=2/3
002/003-th : 0.017 0.085 0.898  ||  -2.0132 -0.4298 1.9305  || discrepancy=0.81 || select=2/3
-----------------------------------------------
000/019-th : 0.053 0.073 0.091 0.105 0.136 0.155 0.187 0.200  ||  -0.776 -0.444 -0.229 -0.086 0.172 0.301 0.490 0.559   || dis=0.01 || select=7/8
001/019-th : 0.128 0.123 0.127 0.125 0.125 0.129 0.119 0.124  ||  0.025 -0.020 0.017 0.002 -0.004 0.027 -0.046 -0.010   || dis=0.00 || select=5/8
002/019-th : 0.118 0.124 0.127 0.129 0.127 0.132 0.125 0.118  ||  -0.060 -0.007 0.019 0.033 0.014 0.058 -0.002 -0.061   || dis=0.00 || select=5/8
003/019-th : 0.104 0.116 0.120 0.129 0.129 0.131 0.132 0.139  ||  -0.178 -0.072 -0.034 0.034 0.038 0.051 0.058 0.112    || dis=0.01 || select=7/8
004/019-th : 0.113 0.115 0.116 0.115 0.130 0.136 0.140 0.135  ||  -0.096 -0.083 -0.073 -0.082 0.041 0.084 0.112 0.077   || dis=0.00 || select=6/8
005/019-th : 0.111 0.114 0.121 0.124 0.128 0.135 0.132 0.134  ||  -0.113 -0.084 -0.026 -0.001 0.030 0.082 0.058 0.074   || dis=0.00 || select=5/8
006/019-th : 0.113 0.111 0.115 0.118 0.132 0.132 0.137 0.143  ||  -0.103 -0.121 -0.079 -0.061 0.052 0.054 0.094 0.138   || dis=0.01 || select=7/8
007/019-th : 0.056 0.065 0.089 0.106 0.135 0.153 0.179 0.216  ||  -0.709 -0.551 -0.241 -0.067 0.178 0.300 0.459 0.647   || dis=0.04 || select=7/8
008/019-th : 0.042 0.052 0.069 0.105 0.133 0.169 0.216 0.216  ||  -0.939 -0.723 -0.438 -0.014 0.223 0.462 0.707 0.707   || dis=0.00 || select=7/8
009/019-th : 0.091 0.093 0.106 0.117 0.116 0.133 0.166 0.178  ||  -0.290 -0.267 -0.144 -0.039 -0.053 0.091 0.309 0.377  || dis=0.01 || select=7/8
010/019-th : 0.095 0.101 0.109 0.122 0.133 0.137 0.151 0.151  ||  -0.258 -0.198 -0.126 -0.015 0.076 0.103 0.202 0.198   || dis=0.00 || select=6/8
011/019-th : 0.098 0.093 0.112 0.112 0.124 0.137 0.154 0.169  ||  -0.225 -0.271 -0.093 -0.088 0.015 0.111 0.230 0.320   || dis=0.02 || select=7/8
012/019-th : 0.100 0.109 0.116 0.123 0.131 0.131 0.146 0.143  ||  -0.211 -0.126 -0.066 -0.005 0.059 0.061 0.168 0.149   || dis=0.00 || select=6/8
013/019-th : 0.024 0.032 0.044 0.060 0.076 0.113 0.237 0.413  ||  -1.215 -0.934 -0.607 -0.301 -0.067 0.336 1.075 1.630  || dis=0.18 || select=7/8
014/019-th : 0.038 0.046 0.058 0.079 0.109 0.159 0.229 0.282  ||  -0.970 -0.761 -0.540 -0.234 0.093 0.471 0.832 1.044   || dis=0.05 || select=7/8
015/019-th : 0.024 0.027 0.040 0.052 0.079 0.119 0.230 0.429  ||  -1.177 -1.076 -0.656 -0.395 0.017 0.423 1.084 1.707   || dis=0.20 || select=7/8
016/019-th : 0.055 0.071 0.096 0.126 0.143 0.158 0.171 0.179  ||  -0.744 -0.486 -0.189 0.086 0.209 0.309 0.388 0.435    || dis=0.01 || select=7/8
017/019-th : 0.115 0.114 0.112 0.124 0.126 0.132 0.141 0.138  ||  -0.079 -0.091 -0.106 -0.009 0.009 0.055 0.121 0.100   || dis=0.00 || select=6/8
018/019-th : 0.086 0.105 0.120 0.122 0.135 0.133 0.139 0.161  ||  -0.361 -0.160 -0.024 -0.006 0.097 0.079 0.127 0.269   || dis=0.02 || select=7/8
[epoch=267/600] FLOP : 28.62 MB, ratio : 0.7011, Expected-ratio : 0.7000, Discrepancy : 0.073
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:03:24] [epoch=267/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.563 (2.563)  Prec@1 29.69 (29.69) Prec@5 76.56 (76.56) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:03:30] [epoch=267/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.222 (2.296)  Prec@1 29.17 (36.76) Prec@5 75.00 (80.76) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.76 Prec@5 80.76 Error@1 63.24 Error@5 19.24 Loss:2.296
***[2020-01-29 08:03:30]*** VALID [epoch=267/600] loss = 2.296280, accuracy@1 = 36.76, accuracy@5 = 80.76 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:03:30]*** start epoch=268/600 Time Left: [02:56:28], LR=[0.058338 ~ 0.058338], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=268, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.958583429454451, FLOP=40.81
[Search] : epoch=268/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:03:31] [epoch=268/600][000/098] Time 0.76 (0.76) Data 0.34 (0.34) Base-Loss 0.738 (0.738)  Prec@1 74.22 (74.22) Prec@5 98.44 (98.44) Acls-loss 0.951 (0.951) FLOP-Loss 2.766 (2.766) Arch-Loss 6.484 (6.484)
**TRAIN** [2020-01-29 08:03:55] [epoch=268/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.675 (0.810)  Prec@1 78.57 (72.66) Prec@5 100.00 (97.83) Acls-loss 0.798 (0.832) FLOP-Loss 0.000 (0.028) Arch-Loss 0.798 (0.888)
 **TRAIN** Prec@1 72.66 Prec@5 97.83 Error@1 27.34 Error@5 2.17 Base-Loss:0.810, Arch-Loss=0.888
***[2020-01-29 08:03:55]*** TRAIN [epoch=268/600] base-loss = 0.810472, arch-loss = 0.888324, accuracy-1 = 72.66, accuracy-5 = 97.83
[epoch=268/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.99328)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.193 0.370  ||  0.2364 -0.5795 0.0710  || discrepancy=0.07 || select=0/3
001/003-th : 0.348 0.133 0.519  ||  0.0370 -0.9269 0.4378  || discrepancy=0.17 || select=2/3
002/003-th : 0.017 0.084 0.899  ||  -2.0096 -0.4367 1.9351  || discrepancy=0.82 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.072 0.091 0.104 0.137 0.155 0.189 0.200  ||  -0.783 -0.460 -0.227 -0.096 0.183 0.309 0.502 0.562   || dis=0.01 || select=7/8
001/019-th : 0.128 0.123 0.126 0.125 0.124 0.128 0.120 0.125  ||  0.025 -0.019 0.006 -0.002 -0.010 0.023 -0.043 -0.004  || dis=0.00 || select=0/8
002/019-th : 0.117 0.124 0.127 0.129 0.127 0.132 0.125 0.118  ||  -0.065 -0.010 0.015 0.032 0.016 0.058 0.002 -0.055    || dis=0.00 || select=5/8
003/019-th : 0.103 0.116 0.117 0.129 0.131 0.131 0.132 0.141  ||  -0.185 -0.073 -0.062 0.034 0.049 0.054 0.059 0.126    || dis=0.01 || select=7/8
004/019-th : 0.113 0.115 0.115 0.116 0.131 0.135 0.140 0.135  ||  -0.099 -0.083 -0.086 -0.075 0.050 0.080 0.117 0.078   || dis=0.01 || select=6/8
005/019-th : 0.110 0.115 0.121 0.124 0.127 0.135 0.132 0.135  ||  -0.126 -0.083 -0.026 -0.003 0.022 0.084 0.062 0.085   || dis=0.00 || select=7/8
006/019-th : 0.112 0.111 0.116 0.116 0.131 0.132 0.138 0.144  ||  -0.106 -0.120 -0.074 -0.071 0.048 0.057 0.098 0.140   || dis=0.01 || select=7/8
007/019-th : 0.056 0.066 0.088 0.104 0.134 0.155 0.180 0.217  ||  -0.700 -0.547 -0.255 -0.084 0.170 0.312 0.466 0.650   || dis=0.04 || select=7/8
008/019-th : 0.040 0.051 0.067 0.106 0.133 0.170 0.218 0.214  ||  -0.971 -0.724 -0.449 0.004 0.226 0.473 0.725 0.707    || dis=0.00 || select=6/8
009/019-th : 0.091 0.090 0.107 0.117 0.115 0.135 0.166 0.178  ||  -0.295 -0.297 -0.128 -0.041 -0.053 0.107 0.313 0.383  || dis=0.01 || select=7/8
010/019-th : 0.095 0.101 0.109 0.122 0.133 0.137 0.150 0.152  ||  -0.266 -0.199 -0.122 -0.011 0.073 0.103 0.195 0.206   || dis=0.00 || select=7/8
011/019-th : 0.097 0.094 0.109 0.113 0.125 0.136 0.156 0.170  ||  -0.234 -0.267 -0.115 -0.083 0.020 0.103 0.242 0.330   || dis=0.01 || select=7/8
012/019-th : 0.100 0.109 0.113 0.122 0.132 0.132 0.146 0.147  ||  -0.218 -0.131 -0.090 -0.013 0.067 0.062 0.163 0.171   || dis=0.00 || select=7/8
013/019-th : 0.024 0.032 0.044 0.059 0.075 0.112 0.237 0.419  ||  -1.216 -0.927 -0.613 -0.317 -0.075 0.334 1.080 1.650  || dis=0.18 || select=7/8
014/019-th : 0.038 0.046 0.057 0.078 0.108 0.159 0.228 0.286  ||  -0.959 -0.766 -0.552 -0.244 0.087 0.470 0.835 1.058   || dis=0.06 || select=7/8
015/019-th : 0.023 0.026 0.040 0.052 0.079 0.118 0.232 0.429  ||  -1.202 -1.078 -0.650 -0.397 0.016 0.423 1.100 1.713   || dis=0.20 || select=7/8
016/019-th : 0.055 0.071 0.096 0.125 0.143 0.159 0.172 0.178  ||  -0.752 -0.487 -0.184 0.074 0.211 0.318 0.398 0.432    || dis=0.01 || select=7/8
017/019-th : 0.113 0.113 0.113 0.123 0.126 0.132 0.141 0.139  ||  -0.093 -0.096 -0.098 -0.011 0.008 0.058 0.126 0.107   || dis=0.00 || select=6/8
018/019-th : 0.086 0.104 0.121 0.122 0.134 0.132 0.139 0.162  ||  -0.358 -0.166 -0.018 -0.008 0.086 0.074 0.124 0.279   || dis=0.02 || select=7/8
[epoch=268/600] FLOP : 26.99 MB, ratio : 0.6614, Expected-ratio : 0.7000, Discrepancy : 0.074
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:03:56] [epoch=268/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.779 (3.779)  Prec@1 34.77 (34.77) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:04:02] [epoch=268/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.646 (2.141)  Prec@1 36.90 (38.93) Prec@5 90.48 (82.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.93 Prec@5 82.65 Error@1 61.07 Error@5 17.35 Loss:2.141
***[2020-01-29 08:04:02]*** VALID [epoch=268/600] loss = 2.140851, accuracy@1 = 38.93, accuracy@5 = 82.65 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:04:02]*** start epoch=269/600 Time Left: [02:55:56], LR=[0.058080 ~ 0.058080], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=269, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.9459293617032354, FLOP=40.81
[Search] : epoch=269/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:04:02] [epoch=269/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.748 (0.748)  Prec@1 73.05 (73.05) Prec@5 97.27 (97.27) Acls-loss 0.925 (0.925) FLOP-Loss 0.000 (0.000) Arch-Loss 0.925 (0.925)
**TRAIN** [2020-01-29 08:04:27] [epoch=269/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.841 (0.787)  Prec@1 69.64 (72.81) Prec@5 98.81 (98.01) Acls-loss 0.974 (0.825) FLOP-Loss 0.000 (0.085) Arch-Loss 0.974 (0.995)
 **TRAIN** Prec@1 72.81 Prec@5 98.01 Error@1 27.19 Error@5 1.99 Base-Loss:0.787, Arch-Loss=0.995
***[2020-01-29 08:04:27]*** TRAIN [epoch=269/600] base-loss = 0.786654, arch-loss = 0.995437, accuracy-1 = 72.81, accuracy-5 = 98.01
[epoch=269/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 14, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.28352)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.195 0.367  ||  0.2427 -0.5696 0.0647  || discrepancy=0.07 || select=0/3
001/003-th : 0.348 0.133 0.519  ||  0.0380 -0.9242 0.4381  || discrepancy=0.17 || select=2/3
002/003-th : 0.017 0.083 0.899  ||  -2.0098 -0.4382 1.9398  || discrepancy=0.82 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.073 0.092 0.103 0.138 0.157 0.185 0.200  ||  -0.786 -0.448 -0.217 -0.106 0.191 0.318 0.481 0.559   || dis=0.02 || select=7/8
001/019-th : 0.127 0.123 0.127 0.129 0.124 0.127 0.119 0.124  ||  0.016 -0.014 0.018 0.030 -0.006 0.020 -0.046 -0.009   || dis=0.00 || select=3/8
002/019-th : 0.118 0.125 0.127 0.130 0.126 0.131 0.125 0.118  ||  -0.061 0.000 0.016 0.042 0.006 0.048 -0.004 -0.058    || dis=0.00 || select=5/8
003/019-th : 0.103 0.117 0.117 0.129 0.130 0.133 0.130 0.140  ||  -0.185 -0.057 -0.060 0.035 0.042 0.068 0.048 0.117    || dis=0.01 || select=7/8
004/019-th : 0.114 0.115 0.115 0.117 0.131 0.136 0.139 0.134  ||  -0.094 -0.081 -0.083 -0.067 0.046 0.084 0.110 0.073   || dis=0.00 || select=6/8
005/019-th : 0.109 0.116 0.122 0.125 0.130 0.133 0.132 0.134  ||  -0.135 -0.070 -0.018 0.003 0.043 0.069 0.060 0.078    || dis=0.00 || select=7/8
006/019-th : 0.113 0.111 0.116 0.117 0.133 0.133 0.137 0.141  ||  -0.102 -0.118 -0.074 -0.062 0.065 0.062 0.096 0.126   || dis=0.00 || select=7/8
007/019-th : 0.057 0.066 0.087 0.104 0.133 0.155 0.179 0.218  ||  -0.683 -0.544 -0.267 -0.087 0.163 0.315 0.454 0.655   || dis=0.04 || select=7/8
008/019-th : 0.040 0.052 0.068 0.105 0.132 0.172 0.217 0.213  ||  -0.978 -0.714 -0.439 -0.003 0.224 0.485 0.719 0.701   || dis=0.00 || select=6/8
009/019-th : 0.091 0.090 0.108 0.117 0.118 0.134 0.165 0.177  ||  -0.287 -0.305 -0.122 -0.038 -0.031 0.098 0.308 0.376  || dis=0.01 || select=7/8
010/019-th : 0.094 0.103 0.110 0.123 0.132 0.136 0.150 0.152  ||  -0.272 -0.188 -0.114 -0.002 0.065 0.095 0.193 0.204   || dis=0.00 || select=7/8
011/019-th : 0.097 0.095 0.108 0.113 0.125 0.136 0.156 0.171  ||  -0.238 -0.252 -0.126 -0.085 0.016 0.106 0.241 0.331   || dis=0.02 || select=7/8
012/019-th : 0.099 0.108 0.112 0.123 0.133 0.132 0.145 0.147  ||  -0.218 -0.137 -0.095 -0.006 0.072 0.067 0.159 0.173   || dis=0.00 || select=7/8
013/019-th : 0.024 0.032 0.043 0.059 0.075 0.112 0.237 0.418  ||  -1.227 -0.923 -0.616 -0.315 -0.063 0.331 1.081 1.650  || dis=0.18 || select=7/8
014/019-th : 0.038 0.046 0.058 0.078 0.108 0.159 0.228 0.286  ||  -0.967 -0.770 -0.542 -0.246 0.085 0.474 0.831 1.060   || dis=0.06 || select=7/8
015/019-th : 0.023 0.026 0.040 0.051 0.078 0.119 0.233 0.429  ||  -1.195 -1.084 -0.651 -0.411 0.013 0.431 1.107 1.715   || dis=0.20 || select=7/8
016/019-th : 0.054 0.071 0.096 0.125 0.143 0.159 0.173 0.179  ||  -0.758 -0.487 -0.186 0.074 0.212 0.318 0.404 0.434    || dis=0.01 || select=7/8
017/019-th : 0.113 0.114 0.113 0.122 0.127 0.131 0.141 0.139  ||  -0.094 -0.089 -0.100 -0.023 0.022 0.048 0.121 0.113   || dis=0.00 || select=6/8
018/019-th : 0.085 0.103 0.121 0.124 0.131 0.133 0.140 0.162  ||  -0.363 -0.176 -0.014 0.014 0.069 0.080 0.130 0.277    || dis=0.02 || select=7/8
[epoch=269/600] FLOP : 28.28 MB, ratio : 0.6930, Expected-ratio : 0.7000, Discrepancy : 0.074
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:04:27] [epoch=269/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.032 (2.032)  Prec@1 41.02 (41.02) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:04:33] [epoch=269/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.465 (2.414)  Prec@1 19.05 (35.81) Prec@5 76.19 (80.46) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.81 Prec@5 80.46 Error@1 64.19 Error@5 19.54 Loss:2.414
***[2020-01-29 08:04:33]*** VALID [epoch=269/600] loss = 2.413661, accuracy@1 = 35.81, accuracy@5 = 80.46 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:04:33]*** start epoch=270/600 Time Left: [02:55:24], LR=[0.057822 ~ 0.057822], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=270, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.9332644393485663, FLOP=40.81
[Search] : epoch=270/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:04:34] [epoch=270/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.788 (0.788)  Prec@1 72.66 (72.66) Prec@5 96.48 (96.48) Acls-loss 0.784 (0.784) FLOP-Loss 0.000 (0.000) Arch-Loss 0.784 (0.784)
**TRAIN** [2020-01-29 08:04:59] [epoch=270/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.900 (0.790)  Prec@1 71.43 (72.90) Prec@5 97.62 (97.91) Acls-loss 0.769 (0.824) FLOP-Loss 0.000 (0.057) Arch-Loss 0.769 (0.938)
 **TRAIN** Prec@1 72.90 Prec@5 97.91 Error@1 27.10 Error@5 2.09 Base-Loss:0.790, Arch-Loss=0.938
***[2020-01-29 08:04:59]*** TRAIN [epoch=270/600] base-loss = 0.790293, arch-loss = 0.937945, accuracy-1 = 72.90, accuracy-5 = 97.91
[epoch=270/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 14, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.28352)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.194 0.368  ||  0.2418 -0.5718 0.0670  || discrepancy=0.07 || select=0/3
001/003-th : 0.348 0.135 0.517  ||  0.0398 -0.9105 0.4363  || discrepancy=0.17 || select=2/3
002/003-th : 0.017 0.082 0.901  ||  -2.0360 -0.4367 1.9603  || discrepancy=0.82 || select=2/3
-----------------------------------------------
000/019-th : 0.052 0.073 0.093 0.104 0.139 0.154 0.185 0.200  ||  -0.791 -0.450 -0.207 -0.094 0.195 0.300 0.478 0.560   || dis=0.02 || select=7/8
001/019-th : 0.127 0.124 0.126 0.128 0.125 0.127 0.119 0.124  ||  0.018 -0.011 0.009 0.027 0.001 0.013 -0.046 -0.009    || dis=0.00 || select=3/8
002/019-th : 0.117 0.125 0.127 0.129 0.127 0.132 0.124 0.119  ||  -0.067 -0.004 0.017 0.030 0.017 0.052 -0.007 -0.049   || dis=0.00 || select=5/8
003/019-th : 0.103 0.118 0.118 0.129 0.128 0.133 0.131 0.140  ||  -0.186 -0.055 -0.055 0.039 0.030 0.064 0.055 0.114    || dis=0.01 || select=7/8
004/019-th : 0.113 0.114 0.115 0.119 0.129 0.136 0.140 0.133  ||  -0.095 -0.090 -0.081 -0.043 0.035 0.087 0.114 0.069   || dis=0.00 || select=6/8
005/019-th : 0.108 0.115 0.122 0.124 0.130 0.134 0.131 0.135  ||  -0.136 -0.079 -0.016 -0.004 0.046 0.074 0.056 0.085   || dis=0.00 || select=7/8
006/019-th : 0.112 0.110 0.116 0.118 0.131 0.135 0.136 0.141  ||  -0.103 -0.125 -0.071 -0.053 0.049 0.083 0.091 0.125   || dis=0.00 || select=7/8
007/019-th : 0.057 0.066 0.087 0.105 0.133 0.156 0.180 0.217  ||  -0.695 -0.540 -0.264 -0.075 0.156 0.319 0.460 0.649   || dis=0.04 || select=7/8
008/019-th : 0.039 0.052 0.068 0.105 0.131 0.173 0.216 0.215  ||  -0.991 -0.715 -0.442 -0.002 0.220 0.496 0.718 0.713   || dis=0.00 || select=6/8
009/019-th : 0.092 0.090 0.107 0.116 0.119 0.133 0.166 0.176  ||  -0.279 -0.306 -0.125 -0.043 -0.024 0.093 0.311 0.372  || dis=0.01 || select=7/8
010/019-th : 0.095 0.103 0.111 0.124 0.130 0.135 0.149 0.154  ||  -0.269 -0.186 -0.107 -0.002 0.049 0.084 0.187 0.215   || dis=0.01 || select=7/8
011/019-th : 0.097 0.094 0.107 0.115 0.124 0.138 0.155 0.171  ||  -0.237 -0.262 -0.133 -0.065 0.009 0.119 0.236 0.331   || dis=0.02 || select=7/8
012/019-th : 0.099 0.109 0.114 0.122 0.132 0.133 0.144 0.147  ||  -0.222 -0.126 -0.082 -0.012 0.066 0.069 0.151 0.170   || dis=0.00 || select=7/8
013/019-th : 0.023 0.032 0.043 0.058 0.075 0.111 0.236 0.421  ||  -1.236 -0.922 -0.611 -0.316 -0.070 0.331 1.082 1.660  || dis=0.18 || select=7/8
014/019-th : 0.038 0.045 0.058 0.079 0.108 0.157 0.230 0.286  ||  -0.970 -0.779 -0.540 -0.229 0.088 0.458 0.840 1.059   || dis=0.06 || select=7/8
015/019-th : 0.023 0.026 0.040 0.051 0.079 0.118 0.231 0.432  ||  -1.198 -1.084 -0.658 -0.419 0.031 0.425 1.099 1.727   || dis=0.20 || select=7/8
016/019-th : 0.055 0.072 0.096 0.123 0.144 0.158 0.174 0.179  ||  -0.752 -0.477 -0.193 0.058 0.218 0.311 0.404 0.436    || dis=0.01 || select=7/8
017/019-th : 0.113 0.114 0.114 0.119 0.128 0.131 0.142 0.139  ||  -0.101 -0.090 -0.088 -0.042 0.027 0.052 0.128 0.112   || dis=0.00 || select=6/8
018/019-th : 0.085 0.103 0.121 0.125 0.132 0.131 0.140 0.163  ||  -0.364 -0.174 -0.014 0.017 0.070 0.066 0.129 0.283    || dis=0.02 || select=7/8
[epoch=270/600] FLOP : 28.28 MB, ratio : 0.6930, Expected-ratio : 0.7000, Discrepancy : 0.075
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:04:59] [epoch=270/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.301 (2.301)  Prec@1 43.36 (43.36) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:05:05] [epoch=270/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.340 (2.254)  Prec@1 32.74 (37.54) Prec@5 78.57 (82.09) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.54 Prec@5 82.09 Error@1 62.46 Error@5 17.91 Loss:2.254
***[2020-01-29 08:05:05]*** VALID [epoch=270/600] loss = 2.254171, accuracy@1 = 37.54, accuracy@5 = 82.09 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:05:05]*** start epoch=271/600 Time Left: [02:54:52], LR=[0.057563 ~ 0.057563], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=271, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.920589009605688, FLOP=40.81
[Search] : epoch=271/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:05:06] [epoch=271/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.883 (0.883)  Prec@1 70.31 (70.31) Prec@5 97.66 (97.66) Acls-loss 0.700 (0.700) FLOP-Loss 0.000 (0.000) Arch-Loss 0.700 (0.700)
**TRAIN** [2020-01-29 08:05:30] [epoch=271/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.729 (0.781)  Prec@1 74.40 (73.14) Prec@5 100.00 (98.10) Acls-loss 0.800 (0.816) FLOP-Loss 0.000 (0.028) Arch-Loss 0.800 (0.873)
 **TRAIN** Prec@1 73.14 Prec@5 98.10 Error@1 26.86 Error@5 1.90 Base-Loss:0.781, Arch-Loss=0.873
***[2020-01-29 08:05:30]*** TRAIN [epoch=271/600] base-loss = 0.781409, arch-loss = 0.872596, accuracy-1 = 73.14, accuracy-5 = 98.10
[epoch=271/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.370112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.194 0.369  ||  0.2386 -0.5723 0.0716  || discrepancy=0.07 || select=0/3
001/003-th : 0.345 0.137 0.519  ||  0.0335 -0.8923 0.4415  || discrepancy=0.17 || select=2/3
002/003-th : 0.016 0.079 0.905  ||  -2.0522 -0.4503 1.9816  || discrepancy=0.83 || select=2/3
-----------------------------------------------
000/019-th : 0.051 0.071 0.095 0.102 0.138 0.153 0.187 0.203  ||  -0.812 -0.470 -0.186 -0.107 0.191 0.297 0.496 0.580   || dis=0.02 || select=7/8
001/019-th : 0.128 0.123 0.126 0.127 0.126 0.126 0.120 0.125  ||  0.020 -0.021 0.009 0.014 0.003 0.007 -0.040 -0.001    || dis=0.00 || select=0/8
002/019-th : 0.116 0.124 0.126 0.128 0.130 0.132 0.124 0.120  ||  -0.075 -0.006 0.010 0.026 0.036 0.053 -0.006 -0.042   || dis=0.00 || select=5/8
003/019-th : 0.104 0.117 0.117 0.128 0.127 0.134 0.133 0.140  ||  -0.184 -0.061 -0.059 0.029 0.022 0.072 0.064 0.116    || dis=0.01 || select=7/8
004/019-th : 0.113 0.113 0.114 0.119 0.128 0.137 0.141 0.135  ||  -0.098 -0.102 -0.087 -0.051 0.028 0.092 0.125 0.079   || dis=0.00 || select=6/8
005/019-th : 0.109 0.114 0.123 0.122 0.130 0.134 0.133 0.136  ||  -0.136 -0.089 -0.013 -0.018 0.047 0.072 0.066 0.088   || dis=0.00 || select=7/8
006/019-th : 0.112 0.109 0.114 0.118 0.133 0.135 0.137 0.142  ||  -0.108 -0.131 -0.085 -0.056 0.066 0.084 0.094 0.133   || dis=0.00 || select=7/8
007/019-th : 0.057 0.067 0.087 0.104 0.130 0.158 0.179 0.220  ||  -0.688 -0.528 -0.267 -0.092 0.133 0.328 0.454 0.661   || dis=0.04 || select=7/8
008/019-th : 0.040 0.051 0.068 0.105 0.131 0.172 0.215 0.218  ||  -0.983 -0.718 -0.442 -0.006 0.213 0.491 0.712 0.725   || dis=0.00 || select=7/8
009/019-th : 0.092 0.089 0.105 0.117 0.118 0.133 0.167 0.178  ||  -0.274 -0.308 -0.145 -0.040 -0.031 0.089 0.320 0.381  || dis=0.01 || select=7/8
010/019-th : 0.094 0.102 0.111 0.125 0.128 0.136 0.149 0.155  ||  -0.272 -0.192 -0.110 0.007 0.032 0.090 0.185 0.226    || dis=0.01 || select=7/8
011/019-th : 0.097 0.093 0.107 0.114 0.124 0.137 0.157 0.171  ||  -0.236 -0.272 -0.137 -0.070 0.014 0.114 0.248 0.335   || dis=0.01 || select=7/8
012/019-th : 0.099 0.109 0.112 0.124 0.133 0.131 0.144 0.147  ||  -0.226 -0.124 -0.096 0.001 0.075 0.060 0.153 0.175    || dis=0.00 || select=7/8
013/019-th : 0.023 0.031 0.043 0.058 0.074 0.112 0.234 0.425  ||  -1.250 -0.928 -0.615 -0.313 -0.070 0.339 1.077 1.676  || dis=0.19 || select=7/8
014/019-th : 0.038 0.046 0.058 0.079 0.108 0.155 0.228 0.288  ||  -0.968 -0.779 -0.544 -0.224 0.090 0.448 0.835 1.066   || dis=0.06 || select=7/8
015/019-th : 0.023 0.026 0.039 0.050 0.080 0.119 0.229 0.434  ||  -1.201 -1.082 -0.681 -0.419 0.038 0.439 1.095 1.735   || dis=0.20 || select=7/8
016/019-th : 0.055 0.071 0.095 0.123 0.145 0.159 0.172 0.180  ||  -0.751 -0.485 -0.193 0.056 0.221 0.317 0.397 0.442    || dis=0.01 || select=7/8
017/019-th : 0.112 0.112 0.115 0.119 0.129 0.130 0.142 0.140  ||  -0.104 -0.102 -0.082 -0.044 0.032 0.046 0.134 0.119   || dis=0.00 || select=6/8
018/019-th : 0.085 0.102 0.121 0.125 0.130 0.132 0.141 0.165  ||  -0.370 -0.188 -0.017 0.015 0.054 0.075 0.139 0.294    || dis=0.02 || select=7/8
[epoch=271/600] FLOP : 27.37 MB, ratio : 0.6706, Expected-ratio : 0.7000, Discrepancy : 0.076
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:05:31] [epoch=271/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.465 (3.465)  Prec@1 34.38 (34.38) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:05:37] [epoch=271/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.484 (2.147)  Prec@1 44.64 (38.44) Prec@5 84.52 (81.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.44 Prec@5 81.30 Error@1 61.56 Error@5 18.70 Loss:2.147
***[2020-01-29 08:05:37]*** VALID [epoch=271/600] loss = 2.147286, accuracy@1 = 38.44, accuracy@5 = 81.30 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:05:37]*** start epoch=272/600 Time Left: [02:54:20], LR=[0.057304 ~ 0.057304], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=272, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.907903419977909, FLOP=40.81
[Search] : epoch=272/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:05:38] [epoch=272/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.926 (0.926)  Prec@1 65.62 (65.62) Prec@5 98.05 (98.05) Acls-loss 0.700 (0.700) FLOP-Loss 0.000 (0.000) Arch-Loss 0.700 (0.700)
**TRAIN** [2020-01-29 08:06:02] [epoch=272/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.712 (0.787)  Prec@1 74.40 (73.08) Prec@5 97.62 (97.86) Acls-loss 0.747 (0.811) FLOP-Loss 0.000 (0.057) Arch-Loss 0.747 (0.924)
 **TRAIN** Prec@1 73.08 Prec@5 97.86 Error@1 26.92 Error@5 2.14 Base-Loss:0.787, Arch-Loss=0.924
***[2020-01-29 08:06:02]*** TRAIN [epoch=272/600] base-loss = 0.787233, arch-loss = 0.924387, accuracy-1 = 73.08, accuracy-5 = 97.86
[epoch=272/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 12, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.370112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.194 0.370  ||  0.2372 -0.5731 0.0743  || discrepancy=0.07 || select=0/3
001/003-th : 0.344 0.136 0.519  ||  0.0330 -0.8926 0.4435  || discrepancy=0.18 || select=2/3
002/003-th : 0.016 0.079 0.906  ||  -2.0668 -0.4498 1.9954  || discrepancy=0.83 || select=2/3
-----------------------------------------------
000/019-th : 0.051 0.070 0.095 0.101 0.138 0.153 0.187 0.206  ||  -0.809 -0.479 -0.180 -0.122 0.192 0.295 0.495 0.592   || dis=0.02 || select=7/8
001/019-th : 0.127 0.123 0.127 0.125 0.126 0.126 0.121 0.124  ||  0.018 -0.014 0.015 -0.003 0.006 0.004 -0.031 -0.006   || dis=0.00 || select=0/8
002/019-th : 0.116 0.124 0.126 0.128 0.131 0.131 0.124 0.120  ||  -0.071 -0.006 0.006 0.022 0.044 0.048 -0.007 -0.043   || dis=0.00 || select=5/8
003/019-th : 0.104 0.117 0.117 0.127 0.130 0.134 0.132 0.139  ||  -0.181 -0.060 -0.061 0.021 0.043 0.073 0.061 0.110    || dis=0.01 || select=7/8
004/019-th : 0.114 0.112 0.114 0.118 0.130 0.136 0.141 0.135  ||  -0.093 -0.105 -0.089 -0.056 0.045 0.089 0.120 0.080   || dis=0.00 || select=6/8
005/019-th : 0.109 0.114 0.121 0.122 0.131 0.134 0.133 0.136  ||  -0.135 -0.090 -0.025 -0.022 0.052 0.071 0.070 0.092   || dis=0.00 || select=7/8
006/019-th : 0.112 0.109 0.115 0.117 0.133 0.136 0.138 0.142  ||  -0.109 -0.133 -0.076 -0.065 0.063 0.088 0.100 0.129   || dis=0.00 || select=7/8
007/019-th : 0.056 0.066 0.087 0.103 0.131 0.155 0.181 0.222  ||  -0.704 -0.540 -0.267 -0.096 0.146 0.317 0.469 0.675   || dis=0.04 || select=7/8
008/019-th : 0.039 0.051 0.068 0.103 0.132 0.170 0.215 0.220  ||  -0.985 -0.719 -0.435 -0.021 0.225 0.477 0.713 0.732   || dis=0.01 || select=7/8
009/019-th : 0.090 0.090 0.106 0.117 0.117 0.135 0.167 0.178  ||  -0.299 -0.305 -0.136 -0.040 -0.035 0.107 0.319 0.385  || dis=0.01 || select=7/8
010/019-th : 0.095 0.103 0.112 0.125 0.130 0.136 0.148 0.152  ||  -0.265 -0.184 -0.101 0.011 0.045 0.092 0.178 0.205    || dis=0.00 || select=7/8
011/019-th : 0.095 0.093 0.107 0.117 0.123 0.134 0.157 0.173  ||  -0.249 -0.270 -0.136 -0.043 0.007 0.093 0.246 0.344   || dis=0.02 || select=7/8
012/019-th : 0.098 0.110 0.113 0.123 0.133 0.130 0.144 0.148  ||  -0.231 -0.122 -0.089 -0.005 0.069 0.050 0.155 0.182   || dis=0.00 || select=7/8
013/019-th : 0.023 0.032 0.043 0.058 0.074 0.110 0.235 0.426  ||  -1.256 -0.920 -0.616 -0.316 -0.072 0.330 1.084 1.682  || dis=0.19 || select=7/8
014/019-th : 0.037 0.045 0.058 0.080 0.108 0.155 0.227 0.289  ||  -0.986 -0.779 -0.530 -0.218 0.086 0.451 0.831 1.070   || dis=0.06 || select=7/8
015/019-th : 0.023 0.026 0.039 0.050 0.079 0.121 0.229 0.433  ||  -1.205 -1.083 -0.666 -0.434 0.032 0.454 1.094 1.732   || dis=0.20 || select=7/8
016/019-th : 0.054 0.073 0.095 0.124 0.143 0.158 0.171 0.182  ||  -0.760 -0.470 -0.199 0.063 0.209 0.311 0.389 0.452    || dis=0.01 || select=7/8
017/019-th : 0.112 0.112 0.115 0.119 0.129 0.130 0.143 0.141  ||  -0.103 -0.107 -0.082 -0.044 0.032 0.040 0.137 0.122   || dis=0.00 || select=6/8
018/019-th : 0.085 0.101 0.120 0.124 0.130 0.132 0.144 0.163  ||  -0.363 -0.195 -0.019 0.011 0.061 0.070 0.158 0.284    || dis=0.02 || select=7/8
[epoch=272/600] FLOP : 27.37 MB, ratio : 0.6706, Expected-ratio : 0.7000, Discrepancy : 0.076
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:06:03] [epoch=272/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.977 (2.977)  Prec@1 39.06 (39.06) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:06:09] [epoch=272/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.135 (2.187)  Prec@1 26.79 (36.30) Prec@5 77.38 (80.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.30 Prec@5 80.08 Error@1 63.70 Error@5 19.92 Loss:2.187
***[2020-01-29 08:06:09]*** VALID [epoch=272/600] loss = 2.186963, accuracy@1 = 36.30, accuracy@5 = 80.08 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:06:09]*** start epoch=273/600 Time Left: [02:53:48], LR=[0.057045 ~ 0.057045], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=273, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.895208018247078, FLOP=40.81
[Search] : epoch=273/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:06:09] [epoch=273/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.870 (0.870)  Prec@1 68.75 (68.75) Prec@5 97.27 (97.27) Acls-loss 0.607 (0.607) FLOP-Loss 0.000 (0.000) Arch-Loss 0.607 (0.607)
**TRAIN** [2020-01-29 08:06:34] [epoch=273/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.850 (0.778)  Prec@1 72.62 (73.45) Prec@5 97.02 (97.94) Acls-loss 0.892 (0.793) FLOP-Loss 0.000 (0.057) Arch-Loss 0.892 (0.907)
 **TRAIN** Prec@1 73.45 Prec@5 97.94 Error@1 26.55 Error@5 2.06 Base-Loss:0.778, Arch-Loss=0.907
***[2020-01-29 08:06:34]*** TRAIN [epoch=273/600] base-loss = 0.778325, arch-loss = 0.907289, accuracy-1 = 73.45, accuracy-5 = 97.94
[epoch=273/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.436 0.193 0.371  ||  0.2381 -0.5757 0.0750  || discrepancy=0.07 || select=0/3
001/003-th : 0.344 0.136 0.520  ||  0.0333 -0.8943 0.4451  || discrepancy=0.18 || select=2/3
002/003-th : 0.015 0.079 0.906  ||  -2.0725 -0.4449 2.0011  || discrepancy=0.83 || select=2/3
-----------------------------------------------
000/019-th : 0.051 0.071 0.095 0.101 0.138 0.153 0.186 0.205  ||  -0.810 -0.476 -0.177 -0.122 0.193 0.298 0.491 0.588   || dis=0.02 || select=7/8
001/019-th : 0.127 0.124 0.127 0.125 0.127 0.126 0.121 0.123  ||  0.014 -0.011 0.020 -0.001 0.018 0.008 -0.030 -0.012   || dis=0.00 || select=2/8
002/019-th : 0.117 0.125 0.126 0.129 0.129 0.130 0.125 0.120  ||  -0.067 -0.002 0.006 0.028 0.030 0.040 -0.002 -0.046   || dis=0.00 || select=5/8
003/019-th : 0.105 0.118 0.118 0.127 0.129 0.133 0.131 0.139  ||  -0.171 -0.056 -0.056 0.015 0.037 0.067 0.051 0.110    || dis=0.01 || select=7/8
004/019-th : 0.114 0.112 0.113 0.117 0.131 0.136 0.142 0.135  ||  -0.090 -0.106 -0.097 -0.064 0.050 0.083 0.127 0.083   || dis=0.01 || select=6/8
005/019-th : 0.109 0.115 0.122 0.124 0.131 0.132 0.132 0.136  ||  -0.130 -0.083 -0.023 -0.003 0.047 0.056 0.062 0.088   || dis=0.00 || select=7/8
006/019-th : 0.112 0.109 0.114 0.117 0.133 0.134 0.139 0.142  ||  -0.105 -0.131 -0.086 -0.064 0.067 0.075 0.109 0.128   || dis=0.00 || select=7/8
007/019-th : 0.056 0.066 0.087 0.103 0.130 0.156 0.178 0.224  ||  -0.703 -0.544 -0.266 -0.091 0.141 0.319 0.455 0.684   || dis=0.05 || select=7/8
008/019-th : 0.040 0.051 0.069 0.103 0.133 0.169 0.214 0.220  ||  -0.974 -0.726 -0.427 -0.025 0.231 0.467 0.706 0.734   || dis=0.01 || select=7/8
009/019-th : 0.091 0.089 0.106 0.115 0.117 0.136 0.166 0.180  ||  -0.294 -0.311 -0.133 -0.051 -0.034 0.110 0.310 0.395  || dis=0.01 || select=7/8
010/019-th : 0.095 0.103 0.112 0.124 0.129 0.136 0.147 0.153  ||  -0.260 -0.181 -0.105 0.004 0.042 0.095 0.173 0.210    || dis=0.01 || select=7/8
011/019-th : 0.096 0.094 0.108 0.115 0.124 0.134 0.158 0.171  ||  -0.239 -0.267 -0.128 -0.060 0.010 0.090 0.257 0.332   || dis=0.01 || select=7/8
012/019-th : 0.098 0.110 0.114 0.121 0.132 0.131 0.144 0.149  ||  -0.230 -0.116 -0.085 -0.023 0.064 0.054 0.152 0.183   || dis=0.01 || select=7/8
013/019-th : 0.022 0.031 0.042 0.057 0.073 0.110 0.233 0.431  ||  -1.253 -0.925 -0.619 -0.326 -0.078 0.335 1.086 1.699  || dis=0.20 || select=7/8
014/019-th : 0.037 0.046 0.058 0.080 0.109 0.154 0.227 0.288  ||  -0.997 -0.759 -0.531 -0.215 0.097 0.440 0.829 1.066   || dis=0.06 || select=7/8
015/019-th : 0.023 0.026 0.039 0.050 0.079 0.122 0.227 0.434  ||  -1.211 -1.079 -0.669 -0.429 0.034 0.462 1.083 1.733   || dis=0.21 || select=7/8
016/019-th : 0.055 0.073 0.096 0.123 0.144 0.157 0.173 0.179  ||  -0.748 -0.461 -0.192 0.057 0.216 0.301 0.396 0.435    || dis=0.01 || select=7/8
017/019-th : 0.111 0.112 0.115 0.122 0.127 0.131 0.141 0.140  ||  -0.111 -0.105 -0.079 -0.018 0.022 0.049 0.128 0.121   || dis=0.00 || select=6/8
018/019-th : 0.087 0.101 0.121 0.123 0.132 0.130 0.144 0.162  ||  -0.347 -0.192 -0.011 0.001 0.073 0.055 0.156 0.274    || dis=0.02 || select=7/8
[epoch=273/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.077
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:06:34] [epoch=273/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.602 (1.602)  Prec@1 49.61 (49.61) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:06:40] [epoch=273/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.216 (2.469)  Prec@1 27.98 (34.70) Prec@5 72.02 (80.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.70 Prec@5 80.10 Error@1 65.30 Error@5 19.90 Loss:2.469
***[2020-01-29 08:06:40]*** VALID [epoch=273/600] loss = 2.468959, accuracy@1 = 34.70, accuracy@5 = 80.10 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:06:40]*** start epoch=274/600 Time Left: [02:53:16], LR=[0.056786 ~ 0.056786], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=274, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.882503152464046, FLOP=40.81
[Search] : epoch=274/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:06:41] [epoch=274/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.716 (0.716)  Prec@1 74.61 (74.61) Prec@5 98.83 (98.83) Acls-loss 0.812 (0.812) FLOP-Loss 0.000 (0.000) Arch-Loss 0.812 (0.812)
**TRAIN** [2020-01-29 08:07:07] [epoch=274/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.708 (0.789)  Prec@1 78.57 (73.00) Prec@5 98.81 (97.95) Acls-loss 1.003 (0.816) FLOP-Loss 0.000 (0.142) Arch-Loss 1.003 (1.100)
 **TRAIN** Prec@1 73.00 Prec@5 97.95 Error@1 27.00 Error@5 2.05 Base-Loss:0.789, Arch-Loss=1.100
***[2020-01-29 08:07:07]*** TRAIN [epoch=274/600] base-loss = 0.788626, arch-loss = 1.100472, accuracy-1 = 73.00, accuracy-5 = 97.95
[epoch=274/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.193 0.364  ||  0.2549 -0.5728 0.0586  || discrepancy=0.08 || select=0/3
001/003-th : 0.349 0.137 0.514  ||  0.0464 -0.8894 0.4336  || discrepancy=0.17 || select=2/3
002/003-th : 0.015 0.077 0.908  ||  -2.0866 -0.4459 2.0154  || discrepancy=0.83 || select=2/3
-----------------------------------------------
000/019-th : 0.051 0.071 0.097 0.102 0.137 0.153 0.183 0.205  ||  -0.797 -0.480 -0.165 -0.113 0.184 0.295 0.473 0.586   || dis=0.02 || select=7/8
001/019-th : 0.128 0.125 0.128 0.127 0.126 0.125 0.119 0.122  ||  0.027 -0.001 0.027 0.018 0.007 0.002 -0.046 -0.026    || dis=0.00 || select=2/8
002/019-th : 0.119 0.126 0.128 0.129 0.128 0.129 0.123 0.118  ||  -0.054 0.009 0.023 0.029 0.020 0.031 -0.015 -0.058    || dis=0.00 || select=5/8
003/019-th : 0.107 0.118 0.119 0.130 0.128 0.132 0.129 0.137  ||  -0.153 -0.054 -0.047 0.040 0.027 0.058 0.034 0.097    || dis=0.01 || select=7/8
004/019-th : 0.115 0.115 0.115 0.119 0.130 0.134 0.138 0.133  ||  -0.082 -0.083 -0.080 -0.047 0.045 0.073 0.103 0.068   || dis=0.00 || select=6/8
005/019-th : 0.112 0.116 0.122 0.124 0.129 0.134 0.131 0.133  ||  -0.110 -0.074 -0.022 -0.007 0.034 0.072 0.054 0.065   || dis=0.00 || select=5/8
006/019-th : 0.114 0.111 0.115 0.118 0.132 0.133 0.138 0.141  ||  -0.092 -0.119 -0.083 -0.056 0.056 0.063 0.099 0.122   || dis=0.00 || select=7/8
007/019-th : 0.057 0.067 0.087 0.103 0.131 0.156 0.177 0.223  ||  -0.690 -0.531 -0.268 -0.098 0.142 0.318 0.445 0.677   || dis=0.05 || select=7/8
008/019-th : 0.040 0.050 0.070 0.105 0.134 0.168 0.214 0.219  ||  -0.965 -0.741 -0.420 -0.011 0.239 0.461 0.701 0.725   || dis=0.01 || select=7/8
009/019-th : 0.092 0.088 0.108 0.117 0.117 0.133 0.165 0.179  ||  -0.274 -0.321 -0.122 -0.035 -0.040 0.093 0.307 0.385  || dis=0.01 || select=7/8
010/019-th : 0.096 0.105 0.112 0.125 0.130 0.135 0.146 0.151  ||  -0.252 -0.170 -0.102 0.006 0.046 0.090 0.165 0.201    || dis=0.01 || select=7/8
011/019-th : 0.098 0.094 0.110 0.116 0.123 0.135 0.156 0.168  ||  -0.225 -0.266 -0.113 -0.052 0.003 0.095 0.243 0.315   || dis=0.01 || select=7/8
012/019-th : 0.099 0.111 0.114 0.122 0.132 0.131 0.144 0.146  ||  -0.224 -0.106 -0.079 -0.017 0.062 0.060 0.151 0.166   || dis=0.00 || select=7/8
013/019-th : 0.023 0.031 0.042 0.058 0.073 0.111 0.235 0.427  ||  -1.242 -0.940 -0.634 -0.305 -0.084 0.341 1.090 1.687  || dis=0.19 || select=7/8
014/019-th : 0.036 0.046 0.058 0.079 0.113 0.152 0.228 0.289  ||  -1.018 -0.758 -0.532 -0.229 0.133 0.433 0.835 1.073   || dis=0.06 || select=7/8
015/019-th : 0.022 0.026 0.039 0.050 0.080 0.124 0.230 0.428  ||  -1.254 -1.079 -0.666 -0.422 0.045 0.484 1.101 1.720   || dis=0.20 || select=7/8
016/019-th : 0.056 0.074 0.097 0.123 0.144 0.155 0.174 0.178  ||  -0.731 -0.457 -0.185 0.054 0.215 0.285 0.401 0.424    || dis=0.00 || select=7/8
017/019-th : 0.113 0.112 0.116 0.124 0.126 0.130 0.139 0.138  ||  -0.093 -0.103 -0.068 0.000 0.012 0.046 0.110 0.107    || dis=0.00 || select=6/8
018/019-th : 0.088 0.102 0.121 0.124 0.134 0.128 0.143 0.160  ||  -0.334 -0.187 -0.015 0.008 0.083 0.044 0.154 0.262    || dis=0.02 || select=7/8
[epoch=274/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.076
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:07:07] [epoch=274/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.873 (1.873)  Prec@1 49.22 (49.22) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:07:13] [epoch=274/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.140 (2.098)  Prec@1 41.07 (38.86) Prec@5 83.93 (82.57) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.86 Prec@5 82.57 Error@1 61.14 Error@5 17.43 Loss:2.098
***[2020-01-29 08:07:13]*** VALID [epoch=274/600] loss = 2.097754, accuracy@1 = 38.86, accuracy@5 = 82.57 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:07:13]*** start epoch=275/600 Time Left: [02:52:45], LR=[0.056526 ~ 0.056526], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=275, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.869789170939127, FLOP=40.81
[Search] : epoch=275/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:07:14] [epoch=275/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.818 (0.818)  Prec@1 74.61 (74.61) Prec@5 98.44 (98.44) Acls-loss 0.831 (0.831) FLOP-Loss 0.000 (0.000) Arch-Loss 0.831 (0.831)
**TRAIN** [2020-01-29 08:07:38] [epoch=275/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 0.649 (0.789)  Prec@1 77.38 (73.29) Prec@5 98.21 (98.02) Acls-loss 0.838 (0.807) FLOP-Loss 0.000 (0.085) Arch-Loss 0.838 (0.977)
 **TRAIN** Prec@1 73.29 Prec@5 98.02 Error@1 26.71 Error@5 1.98 Base-Loss:0.789, Arch-Loss=0.977
***[2020-01-29 08:07:38]*** TRAIN [epoch=275/600] base-loss = 0.789176, arch-loss = 0.976782, accuracy-1 = 73.29, accuracy-5 = 98.02
[epoch=275/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.197 0.359  ||  0.2616 -0.5521 0.0506  || discrepancy=0.09 || select=0/3
001/003-th : 0.351 0.137 0.512  ||  0.0513 -0.8858 0.4300  || discrepancy=0.16 || select=2/3
002/003-th : 0.015 0.076 0.909  ||  -2.0868 -0.4527 2.0227  || discrepancy=0.83 || select=2/3
-----------------------------------------------
000/019-th : 0.051 0.071 0.095 0.101 0.139 0.153 0.184 0.205  ||  -0.802 -0.474 -0.180 -0.122 0.199 0.297 0.479 0.589   || dis=0.02 || select=7/8
001/019-th : 0.127 0.126 0.132 0.126 0.125 0.124 0.118 0.121  ||  0.020 0.010 0.057 0.013 0.005 -0.004 -0.055 -0.031    || dis=0.01 || select=2/8
002/019-th : 0.119 0.127 0.128 0.127 0.128 0.129 0.123 0.119  ||  -0.050 0.011 0.019 0.014 0.017 0.029 -0.015 -0.054    || dis=0.00 || select=5/8
003/019-th : 0.109 0.120 0.120 0.127 0.127 0.131 0.128 0.137  ||  -0.139 -0.043 -0.036 0.019 0.017 0.049 0.026 0.093    || dis=0.01 || select=7/8
004/019-th : 0.115 0.115 0.115 0.118 0.131 0.134 0.138 0.134  ||  -0.082 -0.082 -0.080 -0.051 0.051 0.074 0.100 0.069   || dis=0.00 || select=6/8
005/019-th : 0.112 0.118 0.123 0.123 0.127 0.134 0.131 0.132  ||  -0.104 -0.059 -0.013 -0.016 0.014 0.072 0.047 0.059   || dis=0.00 || select=5/8
006/019-th : 0.115 0.112 0.116 0.117 0.130 0.134 0.136 0.139  ||  -0.081 -0.104 -0.069 -0.059 0.043 0.068 0.085 0.110   || dis=0.00 || select=7/8
007/019-th : 0.057 0.067 0.088 0.102 0.131 0.157 0.174 0.224  ||  -0.687 -0.531 -0.255 -0.110 0.143 0.323 0.429 0.680   || dis=0.05 || select=7/8
008/019-th : 0.041 0.050 0.071 0.105 0.134 0.167 0.212 0.221  ||  -0.959 -0.743 -0.404 -0.012 0.229 0.451 0.692 0.731   || dis=0.01 || select=7/8
009/019-th : 0.092 0.088 0.106 0.119 0.117 0.134 0.164 0.178  ||  -0.277 -0.320 -0.133 -0.017 -0.036 0.101 0.303 0.381  || dis=0.01 || select=7/8
010/019-th : 0.096 0.104 0.112 0.124 0.131 0.136 0.146 0.152  ||  -0.253 -0.173 -0.101 -0.003 0.052 0.090 0.167 0.204   || dis=0.01 || select=7/8
011/019-th : 0.098 0.095 0.111 0.116 0.124 0.135 0.155 0.167  ||  -0.228 -0.252 -0.102 -0.057 0.012 0.094 0.232 0.307   || dis=0.01 || select=7/8
012/019-th : 0.099 0.112 0.116 0.119 0.133 0.131 0.144 0.145  ||  -0.223 -0.100 -0.066 -0.037 0.069 0.056 0.151 0.160   || dis=0.00 || select=7/8
013/019-th : 0.023 0.031 0.042 0.059 0.073 0.111 0.233 0.429  ||  -1.250 -0.948 -0.635 -0.293 -0.082 0.341 1.085 1.693  || dis=0.20 || select=7/8
014/019-th : 0.036 0.046 0.057 0.078 0.114 0.152 0.231 0.287  ||  -1.019 -0.760 -0.541 -0.238 0.149 0.431 0.851 1.069   || dis=0.06 || select=7/8
015/019-th : 0.021 0.026 0.039 0.050 0.078 0.124 0.229 0.433  ||  -1.268 -1.089 -0.670 -0.407 0.025 0.493 1.103 1.742   || dis=0.20 || select=7/8
016/019-th : 0.056 0.074 0.098 0.123 0.145 0.152 0.175 0.179  ||  -0.732 -0.455 -0.176 0.052 0.217 0.264 0.405 0.427    || dis=0.00 || select=7/8
017/019-th : 0.114 0.111 0.117 0.124 0.128 0.129 0.138 0.137  ||  -0.088 -0.109 -0.059 -0.002 0.033 0.040 0.107 0.100   || dis=0.00 || select=6/8
018/019-th : 0.088 0.102 0.121 0.123 0.134 0.129 0.144 0.160  ||  -0.334 -0.189 -0.020 -0.003 0.085 0.050 0.157 0.265   || dis=0.02 || select=7/8
[epoch=275/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.077
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:07:39] [epoch=275/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.275 (1.275)  Prec@1 57.81 (57.81) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:07:45] [epoch=275/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.737 (2.288)  Prec@1 20.24 (36.63) Prec@5 76.79 (80.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.63 Prec@5 80.58 Error@1 63.37 Error@5 19.42 Loss:2.288
***[2020-01-29 08:07:45]*** VALID [epoch=275/600] loss = 2.287931, accuracy@1 = 36.63, accuracy@5 = 80.58 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:07:45]*** start epoch=276/600 Time Left: [02:52:13], LR=[0.056267 ~ 0.056267], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=276, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.857066422232546, FLOP=40.81
[Search] : epoch=276/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:07:46] [epoch=276/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.839 (0.839)  Prec@1 73.05 (73.05) Prec@5 97.66 (97.66) Acls-loss 0.983 (0.983) FLOP-Loss 0.000 (0.000) Arch-Loss 0.983 (0.983)
**TRAIN** [2020-01-29 08:08:10] [epoch=276/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.766 (0.801)  Prec@1 73.81 (72.62) Prec@5 98.21 (97.82) Acls-loss 0.862 (0.841) FLOP-Loss 0.000 (0.000) Arch-Loss 0.862 (0.841)
 **TRAIN** Prec@1 72.62 Prec@5 97.82 Error@1 27.38 Error@5 2.18 Base-Loss:0.801, Arch-Loss=0.841
***[2020-01-29 08:08:10]*** TRAIN [epoch=276/600] base-loss = 0.801437, arch-loss = 0.840584, accuracy-1 = 72.62, accuracy-5 = 97.82
[epoch=276/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.198 0.364  ||  0.2488 -0.5435 0.0639  || discrepancy=0.07 || select=0/3
001/003-th : 0.349 0.139 0.512  ||  0.0478 -0.8695 0.4329  || discrepancy=0.16 || select=2/3
002/003-th : 0.014 0.073 0.913  ||  -2.1102 -0.4711 2.0519  || discrepancy=0.84 || select=2/3
-----------------------------------------------
000/019-th : 0.051 0.071 0.093 0.100 0.137 0.153 0.187 0.207  ||  -0.798 -0.475 -0.202 -0.128 0.189 0.299 0.497 0.599   || dis=0.02 || select=7/8
001/019-th : 0.126 0.124 0.131 0.126 0.127 0.125 0.120 0.123  ||  0.008 -0.006 0.048 0.012 0.017 0.002 -0.041 -0.017    || dis=0.00 || select=2/8
002/019-th : 0.117 0.125 0.126 0.127 0.129 0.131 0.124 0.120  ||  -0.064 0.000 0.005 0.012 0.027 0.048 -0.007 -0.042    || dis=0.00 || select=5/8
003/019-th : 0.108 0.118 0.119 0.124 0.128 0.132 0.133 0.137  ||  -0.144 -0.056 -0.046 -0.004 0.028 0.052 0.059 0.094   || dis=0.00 || select=7/8
004/019-th : 0.114 0.114 0.114 0.118 0.134 0.134 0.138 0.135  ||  -0.089 -0.089 -0.089 -0.051 0.070 0.073 0.099 0.077   || dis=0.00 || select=6/8
005/019-th : 0.113 0.117 0.123 0.122 0.127 0.134 0.131 0.134  ||  -0.104 -0.065 -0.019 -0.024 0.013 0.073 0.047 0.072   || dis=0.00 || select=5/8
006/019-th : 0.114 0.111 0.116 0.119 0.129 0.133 0.136 0.141  ||  -0.086 -0.116 -0.074 -0.050 0.035 0.062 0.090 0.124   || dis=0.00 || select=7/8
007/019-th : 0.056 0.065 0.088 0.101 0.133 0.154 0.175 0.227  ||  -0.702 -0.552 -0.251 -0.109 0.164 0.309 0.435 0.697   || dis=0.05 || select=7/8
008/019-th : 0.040 0.049 0.071 0.103 0.132 0.165 0.216 0.223  ||  -0.962 -0.765 -0.401 -0.022 0.224 0.447 0.715 0.746   || dis=0.01 || select=7/8
009/019-th : 0.091 0.086 0.107 0.119 0.117 0.135 0.167 0.178  ||  -0.287 -0.348 -0.125 -0.018 -0.031 0.108 0.322 0.386  || dis=0.01 || select=7/8
010/019-th : 0.095 0.104 0.111 0.123 0.130 0.136 0.148 0.153  ||  -0.261 -0.176 -0.108 -0.004 0.048 0.097 0.176 0.209   || dis=0.01 || select=7/8
011/019-th : 0.097 0.094 0.111 0.115 0.126 0.135 0.154 0.168  ||  -0.237 -0.263 -0.103 -0.062 0.029 0.100 0.226 0.317   || dis=0.01 || select=7/8
012/019-th : 0.099 0.112 0.116 0.119 0.134 0.131 0.144 0.146  ||  -0.222 -0.102 -0.066 -0.041 0.077 0.053 0.148 0.162   || dis=0.00 || select=7/8
013/019-th : 0.023 0.030 0.041 0.059 0.072 0.111 0.234 0.430  ||  -1.248 -0.969 -0.640 -0.291 -0.087 0.346 1.095 1.702  || dis=0.20 || select=7/8
014/019-th : 0.035 0.046 0.056 0.076 0.115 0.152 0.231 0.288  ||  -1.018 -0.765 -0.557 -0.249 0.155 0.438 0.857 1.078   || dis=0.06 || select=7/8
015/019-th : 0.021 0.026 0.039 0.051 0.078 0.122 0.228 0.436  ||  -1.276 -1.084 -0.672 -0.399 0.027 0.478 1.105 1.751   || dis=0.21 || select=7/8
016/019-th : 0.055 0.073 0.097 0.122 0.142 0.155 0.174 0.182  ||  -0.753 -0.461 -0.185 0.049 0.201 0.285 0.405 0.448    || dis=0.01 || select=7/8
017/019-th : 0.113 0.110 0.115 0.122 0.130 0.130 0.141 0.139  ||  -0.095 -0.126 -0.077 -0.021 0.048 0.048 0.125 0.115   || dis=0.00 || select=6/8
018/019-th : 0.085 0.100 0.121 0.122 0.135 0.129 0.145 0.163  ||  -0.370 -0.208 -0.010 -0.003 0.094 0.050 0.166 0.285   || dis=0.02 || select=7/8
[epoch=276/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.077
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:08:10] [epoch=276/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.169 (3.169)  Prec@1 33.20 (33.20) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:08:17] [epoch=276/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.824 (2.458)  Prec@1 49.40 (36.32) Prec@5 88.69 (80.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.32 Prec@5 80.13 Error@1 63.68 Error@5 19.87 Loss:2.458
***[2020-01-29 08:08:17]*** VALID [epoch=276/600] loss = 2.458416, accuracy@1 = 36.32, accuracy@5 = 80.13 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:08:17]*** start epoch=277/600 Time Left: [02:51:41], LR=[0.056007 ~ 0.056007], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=277, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.8443352551448857, FLOP=40.81
[Search] : epoch=277/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:08:17] [epoch=277/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.772 (0.772)  Prec@1 72.27 (72.27) Prec@5 97.66 (97.66) Acls-loss 0.922 (0.922) FLOP-Loss 0.000 (0.000) Arch-Loss 0.922 (0.922)
**TRAIN** [2020-01-29 08:08:42] [epoch=277/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.661 (0.784)  Prec@1 76.79 (73.47) Prec@5 99.40 (98.06) Acls-loss 0.717 (0.826) FLOP-Loss 0.000 (0.000) Arch-Loss 0.717 (0.826)
 **TRAIN** Prec@1 73.47 Prec@5 98.06 Error@1 26.53 Error@5 1.94 Base-Loss:0.784, Arch-Loss=0.826
***[2020-01-29 08:08:42]*** TRAIN [epoch=277/600] base-loss = 0.783552, arch-loss = 0.825971, accuracy-1 = 73.47, accuracy-5 = 98.06
[epoch=277/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.434 0.200 0.366  ||  0.2410 -0.5351 0.0721  || discrepancy=0.07 || select=0/3
001/003-th : 0.344 0.137 0.520  ||  0.0352 -0.8859 0.4487  || discrepancy=0.18 || select=2/3
002/003-th : 0.014 0.072 0.913  ||  -2.1047 -0.4791 2.0558  || discrepancy=0.84 || select=2/3
-----------------------------------------------
000/019-th : 0.050 0.071 0.092 0.101 0.136 0.151 0.186 0.212  ||  -0.815 -0.469 -0.210 -0.117 0.177 0.287 0.494 0.625   || dis=0.03 || select=7/8
001/019-th : 0.124 0.123 0.130 0.126 0.125 0.127 0.121 0.124  ||  -0.003 -0.011 0.042 0.010 0.006 0.020 -0.032 -0.009   || dis=0.00 || select=2/8
002/019-th : 0.116 0.123 0.125 0.128 0.128 0.132 0.125 0.122  ||  -0.073 -0.020 -0.003 0.018 0.023 0.054 0.002 -0.024   || dis=0.00 || select=5/8
003/019-th : 0.108 0.117 0.119 0.122 0.130 0.131 0.135 0.138  ||  -0.146 -0.068 -0.046 -0.025 0.040 0.050 0.077 0.099   || dis=0.00 || select=7/8
004/019-th : 0.111 0.113 0.113 0.118 0.133 0.136 0.140 0.136  ||  -0.112 -0.099 -0.096 -0.050 0.064 0.087 0.119 0.089   || dis=0.00 || select=6/8
005/019-th : 0.110 0.115 0.122 0.125 0.128 0.133 0.132 0.135  ||  -0.124 -0.081 -0.017 0.001 0.026 0.068 0.057 0.078    || dis=0.00 || select=7/8
006/019-th : 0.114 0.110 0.114 0.120 0.129 0.132 0.137 0.144  ||  -0.088 -0.126 -0.094 -0.037 0.029 0.053 0.095 0.141   || dis=0.01 || select=7/8
007/019-th : 0.054 0.065 0.086 0.101 0.134 0.154 0.176 0.229  ||  -0.727 -0.554 -0.267 -0.109 0.176 0.317 0.446 0.712   || dis=0.05 || select=7/8
008/019-th : 0.040 0.049 0.069 0.103 0.132 0.167 0.217 0.224  ||  -0.961 -0.757 -0.430 -0.028 0.225 0.457 0.721 0.753   || dis=0.01 || select=7/8
009/019-th : 0.091 0.084 0.106 0.118 0.119 0.133 0.168 0.182  ||  -0.290 -0.360 -0.133 -0.027 -0.018 0.093 0.329 0.405  || dis=0.01 || select=7/8
010/019-th : 0.094 0.102 0.110 0.123 0.131 0.140 0.146 0.154  ||  -0.273 -0.190 -0.119 -0.007 0.058 0.128 0.167 0.220   || dis=0.01 || select=7/8
011/019-th : 0.096 0.092 0.109 0.116 0.128 0.135 0.156 0.169  ||  -0.244 -0.282 -0.115 -0.056 0.047 0.098 0.240 0.321   || dis=0.01 || select=7/8
012/019-th : 0.098 0.111 0.114 0.117 0.135 0.133 0.144 0.148  ||  -0.238 -0.106 -0.081 -0.056 0.088 0.068 0.151 0.178   || dis=0.00 || select=7/8
013/019-th : 0.023 0.029 0.041 0.058 0.072 0.111 0.235 0.431  ||  -1.225 -0.988 -0.640 -0.292 -0.090 0.346 1.098 1.704  || dis=0.20 || select=7/8
014/019-th : 0.035 0.045 0.056 0.074 0.112 0.157 0.233 0.288  ||  -1.018 -0.769 -0.554 -0.281 0.138 0.472 0.870 1.083   || dis=0.05 || select=7/8
015/019-th : 0.021 0.026 0.038 0.051 0.076 0.120 0.229 0.440  ||  -1.284 -1.075 -0.677 -0.396 0.018 0.464 1.114 1.767   || dis=0.21 || select=7/8
016/019-th : 0.054 0.073 0.096 0.122 0.143 0.155 0.177 0.180  ||  -0.758 -0.470 -0.186 0.049 0.209 0.286 0.422 0.441    || dis=0.00 || select=7/8
017/019-th : 0.112 0.108 0.115 0.122 0.130 0.129 0.143 0.141  ||  -0.101 -0.138 -0.078 -0.014 0.042 0.038 0.138 0.125   || dis=0.00 || select=6/8
018/019-th : 0.084 0.099 0.121 0.125 0.132 0.130 0.145 0.163  ||  -0.375 -0.212 -0.010 0.017 0.076 0.058 0.164 0.288    || dis=0.02 || select=7/8
[epoch=277/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.078
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:08:42] [epoch=277/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.567 (2.567)  Prec@1 44.14 (44.14) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:08:48] [epoch=277/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.496 (2.141)  Prec@1 50.60 (40.73) Prec@5 88.10 (83.11) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.73 Prec@5 83.11 Error@1 59.27 Error@5 16.89 Loss:2.141
***[2020-01-29 08:08:48]*** VALID [epoch=277/600] loss = 2.141429, accuracy@1 = 40.73, accuracy@5 = 83.11 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:08:48]*** start epoch=278/600 Time Left: [02:51:09], LR=[0.055747 ~ 0.055747], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=278, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.8315960187075238, FLOP=40.81
[Search] : epoch=278/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:08:49] [epoch=278/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.837 (0.837)  Prec@1 69.53 (69.53) Prec@5 97.27 (97.27) Acls-loss 0.813 (0.813) FLOP-Loss 0.000 (0.000) Arch-Loss 0.813 (0.813)
**TRAIN** [2020-01-29 08:09:13] [epoch=278/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.885 (0.765)  Prec@1 70.24 (74.07) Prec@5 98.21 (98.00) Acls-loss 0.822 (0.816) FLOP-Loss 0.000 (0.000) Arch-Loss 0.822 (0.816)
 **TRAIN** Prec@1 74.07 Prec@5 98.00 Error@1 25.93 Error@5 2.00 Base-Loss:0.765, Arch-Loss=0.816
***[2020-01-29 08:09:13]*** TRAIN [epoch=278/600] base-loss = 0.765019, arch-loss = 0.815866, accuracy-1 = 74.07, accuracy-5 = 98.00
[epoch=278/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.402304)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.430 0.201 0.370  ||  0.2322 -0.5292 0.0815  || discrepancy=0.06 || select=0/3
001/003-th : 0.337 0.135 0.527  ||  0.0196 -0.8942 0.4664  || discrepancy=0.19 || select=2/3
002/003-th : 0.014 0.072 0.914  ||  -2.1100 -0.4824 2.0652  || discrepancy=0.84 || select=2/3
-----------------------------------------------
000/019-th : 0.049 0.070 0.092 0.100 0.134 0.152 0.189 0.213  ||  -0.828 -0.486 -0.203 -0.127 0.173 0.298 0.513 0.634   || dis=0.02 || select=7/8
001/019-th : 0.124 0.122 0.129 0.126 0.124 0.127 0.123 0.125  ||  -0.007 -0.023 0.035 0.010 -0.004 0.017 -0.017 0.001   || dis=0.00 || select=2/8
002/019-th : 0.115 0.122 0.124 0.127 0.128 0.134 0.127 0.124  ||  -0.085 -0.029 -0.007 0.013 0.020 0.065 0.015 -0.014   || dis=0.01 || select=5/8
003/019-th : 0.108 0.116 0.119 0.121 0.130 0.133 0.135 0.138  ||  -0.144 -0.071 -0.049 -0.028 0.042 0.063 0.075 0.099   || dis=0.00 || select=7/8
004/019-th : 0.110 0.112 0.114 0.118 0.132 0.135 0.141 0.138  ||  -0.124 -0.105 -0.091 -0.053 0.057 0.082 0.127 0.101   || dis=0.00 || select=6/8
005/019-th : 0.109 0.114 0.122 0.125 0.126 0.135 0.134 0.135  ||  -0.135 -0.089 -0.021 0.007 0.016 0.081 0.071 0.081    || dis=0.00 || select=7/8
006/019-th : 0.112 0.109 0.112 0.121 0.130 0.132 0.136 0.146  ||  -0.104 -0.130 -0.104 -0.030 0.044 0.059 0.090 0.154   || dis=0.01 || select=7/8
007/019-th : 0.053 0.065 0.085 0.099 0.134 0.152 0.178 0.233  ||  -0.746 -0.550 -0.276 -0.123 0.182 0.305 0.465 0.733   || dis=0.06 || select=7/8
008/019-th : 0.040 0.049 0.067 0.102 0.129 0.167 0.220 0.225  ||  -0.957 -0.765 -0.451 -0.027 0.206 0.467 0.741 0.764   || dis=0.01 || select=7/8
009/019-th : 0.090 0.083 0.106 0.118 0.119 0.131 0.171 0.182  ||  -0.298 -0.374 -0.130 -0.026 -0.018 0.082 0.349 0.411  || dis=0.01 || select=7/8
010/019-th : 0.093 0.102 0.109 0.124 0.130 0.140 0.146 0.155  ||  -0.281 -0.191 -0.125 0.001 0.055 0.126 0.171 0.228    || dis=0.01 || select=7/8
011/019-th : 0.095 0.090 0.108 0.115 0.130 0.136 0.155 0.172  ||  -0.251 -0.303 -0.123 -0.064 0.060 0.107 0.239 0.343   || dis=0.02 || select=7/8
012/019-th : 0.097 0.110 0.113 0.115 0.136 0.135 0.144 0.151  ||  -0.243 -0.115 -0.092 -0.078 0.090 0.083 0.149 0.196   || dis=0.01 || select=7/8
013/019-th : 0.023 0.029 0.041 0.057 0.071 0.110 0.239 0.431  ||  -1.216 -0.992 -0.647 -0.312 -0.096 0.343 1.123 1.712  || dis=0.19 || select=7/8
014/019-th : 0.035 0.045 0.055 0.072 0.113 0.159 0.231 0.290  ||  -1.026 -0.771 -0.560 -0.297 0.147 0.492 0.867 1.092   || dis=0.06 || select=7/8
015/019-th : 0.021 0.026 0.038 0.050 0.075 0.119 0.232 0.440  ||  -1.286 -1.065 -0.680 -0.400 0.000 0.462 1.130 1.773   || dis=0.21 || select=7/8
016/019-th : 0.055 0.071 0.096 0.122 0.141 0.157 0.176 0.183  ||  -0.750 -0.489 -0.187 0.049 0.193 0.299 0.416 0.454    || dis=0.01 || select=7/8
017/019-th : 0.111 0.107 0.113 0.122 0.128 0.131 0.144 0.142  ||  -0.114 -0.144 -0.091 -0.015 0.034 0.056 0.151 0.134   || dis=0.00 || select=6/8
018/019-th : 0.084 0.099 0.122 0.125 0.133 0.131 0.144 0.163  ||  -0.383 -0.216 -0.004 0.022 0.078 0.067 0.160 0.287    || dis=0.02 || select=7/8
[epoch=278/600] FLOP : 28.40 MB, ratio : 0.6959, Expected-ratio : 0.7000, Discrepancy : 0.079
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:09:14] [epoch=278/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.846 (1.846)  Prec@1 50.78 (50.78) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:09:20] [epoch=278/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.686 (2.106)  Prec@1 45.83 (38.74) Prec@5 82.14 (82.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.74 Prec@5 82.42 Error@1 61.26 Error@5 17.58 Loss:2.106
***[2020-01-29 08:09:20]*** VALID [epoch=278/600] loss = 2.105912, accuracy@1 = 38.74, accuracy@5 = 82.42 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:09:20]*** start epoch=279/600 Time Left: [02:50:36], LR=[0.055487 ~ 0.055487], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=279, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.818849062173061, FLOP=40.81
[Search] : epoch=279/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:09:21] [epoch=279/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.595 (0.595)  Prec@1 77.73 (77.73) Prec@5 98.44 (98.44) Acls-loss 0.901 (0.901) FLOP-Loss 0.000 (0.000) Arch-Loss 0.901 (0.901)
**TRAIN** [2020-01-29 08:09:45] [epoch=279/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.755 (0.775)  Prec@1 77.98 (73.42) Prec@5 97.62 (98.04) Acls-loss 0.758 (0.824) FLOP-Loss 2.787 (0.104) Arch-Loss 6.331 (1.032)
 **TRAIN** Prec@1 73.42 Prec@5 98.04 Error@1 26.58 Error@5 1.96 Base-Loss:0.775, Arch-Loss=1.032
***[2020-01-29 08:09:45]*** TRAIN [epoch=279/600] base-loss = 0.775211, arch-loss = 1.032461, accuracy-1 = 73.42, accuracy-5 = 98.04
[epoch=279/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.660352)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.430 0.204 0.366  ||  0.2367 -0.5118 0.0756  || discrepancy=0.06 || select=0/3
001/003-th : 0.339 0.136 0.525  ||  0.0249 -0.8884 0.4623  || discrepancy=0.19 || select=2/3
002/003-th : 0.014 0.072 0.913  ||  -2.1077 -0.4716 2.0630  || discrepancy=0.84 || select=2/3
-----------------------------------------------
000/019-th : 0.049 0.070 0.094 0.100 0.135 0.149 0.188 0.214  ||  -0.828 -0.479 -0.189 -0.128 0.175 0.275 0.508 0.637   || dis=0.03 || select=7/8
001/019-th : 0.126 0.123 0.128 0.128 0.123 0.126 0.122 0.125  ||  0.009 -0.019 0.021 0.023 -0.020 0.005 -0.024 -0.001   || dis=0.00 || select=3/8
002/019-th : 0.115 0.121 0.125 0.128 0.129 0.131 0.127 0.123  ||  -0.082 -0.035 0.002 0.022 0.031 0.048 0.013 -0.014    || dis=0.00 || select=5/8
003/019-th : 0.109 0.117 0.121 0.120 0.130 0.133 0.134 0.136  ||  -0.135 -0.065 -0.030 -0.040 0.043 0.062 0.067 0.086   || dis=0.00 || select=7/8
004/019-th : 0.110 0.113 0.114 0.118 0.134 0.135 0.141 0.137  ||  -0.123 -0.098 -0.092 -0.053 0.071 0.080 0.124 0.093   || dis=0.00 || select=6/8
005/019-th : 0.108 0.116 0.124 0.125 0.127 0.134 0.132 0.134  ||  -0.140 -0.070 -0.008 0.003 0.018 0.077 0.062 0.073    || dis=0.00 || select=5/8
006/019-th : 0.112 0.110 0.113 0.123 0.130 0.131 0.136 0.145  ||  -0.105 -0.122 -0.097 -0.009 0.043 0.047 0.084 0.148   || dis=0.01 || select=7/8
007/019-th : 0.053 0.065 0.085 0.099 0.133 0.153 0.178 0.233  ||  -0.748 -0.539 -0.279 -0.124 0.171 0.311 0.465 0.734   || dis=0.06 || select=7/8
008/019-th : 0.040 0.048 0.068 0.102 0.128 0.165 0.223 0.225  ||  -0.955 -0.783 -0.438 -0.024 0.199 0.457 0.757 0.766   || dis=0.00 || select=7/8
009/019-th : 0.090 0.084 0.107 0.119 0.117 0.132 0.170 0.180  ||  -0.299 -0.360 -0.124 -0.015 -0.029 0.089 0.340 0.398  || dis=0.01 || select=7/8
010/019-th : 0.095 0.102 0.110 0.122 0.131 0.142 0.145 0.154  ||  -0.268 -0.195 -0.115 -0.009 0.056 0.140 0.160 0.218   || dis=0.01 || select=7/8
011/019-th : 0.097 0.090 0.109 0.115 0.129 0.134 0.155 0.172  ||  -0.233 -0.308 -0.118 -0.065 0.053 0.094 0.240 0.341   || dis=0.02 || select=7/8
012/019-th : 0.098 0.111 0.112 0.115 0.135 0.136 0.142 0.150  ||  -0.231 -0.110 -0.099 -0.076 0.088 0.093 0.133 0.193   || dis=0.01 || select=7/8
013/019-th : 0.023 0.029 0.041 0.057 0.069 0.109 0.239 0.433  ||  -1.210 -0.988 -0.646 -0.312 -0.112 0.343 1.126 1.720  || dis=0.19 || select=7/8
014/019-th : 0.035 0.045 0.056 0.072 0.112 0.158 0.232 0.290  ||  -1.020 -0.772 -0.547 -0.301 0.142 0.483 0.867 1.090   || dis=0.06 || select=7/8
015/019-th : 0.021 0.026 0.037 0.049 0.076 0.119 0.230 0.442  ||  -1.275 -1.053 -0.711 -0.422 0.022 0.468 1.128 1.780   || dis=0.21 || select=7/8
016/019-th : 0.056 0.071 0.099 0.122 0.141 0.156 0.174 0.182  ||  -0.737 -0.490 -0.165 0.045 0.194 0.294 0.402 0.447    || dis=0.01 || select=7/8
017/019-th : 0.111 0.109 0.115 0.123 0.128 0.130 0.143 0.141  ||  -0.110 -0.131 -0.080 -0.012 0.034 0.046 0.141 0.125   || dis=0.00 || select=6/8
018/019-th : 0.085 0.101 0.122 0.126 0.130 0.131 0.144 0.161  ||  -0.366 -0.196 -0.008 0.028 0.061 0.066 0.159 0.271    || dis=0.02 || select=7/8
[epoch=279/600] FLOP : 28.66 MB, ratio : 0.7022, Expected-ratio : 0.7000, Discrepancy : 0.078
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:09:45] [epoch=279/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.529 (2.529)  Prec@1 23.05 (23.05) Prec@5 75.78 (75.78) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:09:52] [epoch=279/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.688 (2.141)  Prec@1 60.12 (42.03) Prec@5 93.45 (84.71) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.03 Prec@5 84.71 Error@1 57.97 Error@5 15.29 Loss:2.141
***[2020-01-29 08:09:52]*** VALID [epoch=279/600] loss = 2.140956, accuracy@1 = 42.03, accuracy@5 = 84.71 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:09:52]*** start epoch=280/600 Time Left: [02:50:04], LR=[0.055226 ~ 0.055226], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=280, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.8060947350057512, FLOP=40.81
[Search] : epoch=280/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:09:53] [epoch=280/600][000/098] Time 0.75 (0.75) Data 0.36 (0.36) Base-Loss 0.944 (0.944)  Prec@1 63.67 (63.67) Prec@5 96.09 (96.09) Acls-loss 0.864 (0.864) FLOP-Loss 2.784 (2.784) Arch-Loss 6.433 (6.433)
**TRAIN** [2020-01-29 08:10:18] [epoch=280/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.689 (0.805)  Prec@1 79.76 (72.30) Prec@5 98.81 (97.87) Acls-loss 0.833 (0.832) FLOP-Loss 0.000 (0.142) Arch-Loss 0.833 (1.117)
 **TRAIN** Prec@1 72.30 Prec@5 97.87 Error@1 27.70 Error@5 2.13 Base-Loss:0.805, Arch-Loss=1.117
***[2020-01-29 08:10:18]*** TRAIN [epoch=280/600] base-loss = 0.804733, arch-loss = 1.116569, accuracy-1 = 72.30, accuracy-5 = 97.87
[epoch=280/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.025472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.439 0.203 0.358  ||  0.2582 -0.5113 0.0546  || discrepancy=0.08 || select=0/3
001/003-th : 0.347 0.136 0.517  ||  0.0451 -0.8904 0.4452  || discrepancy=0.17 || select=2/3
002/003-th : 0.014 0.072 0.914  ||  -2.1215 -0.4666 2.0754  || discrepancy=0.84 || select=2/3
-----------------------------------------------
000/019-th : 0.049 0.069 0.097 0.100 0.137 0.149 0.190 0.210  ||  -0.841 -0.494 -0.158 -0.123 0.188 0.277 0.519 0.617   || dis=0.02 || select=7/8
001/019-th : 0.128 0.124 0.129 0.126 0.123 0.126 0.120 0.123  ||  0.023 -0.008 0.033 0.011 -0.014 0.007 -0.043 -0.016   || dis=0.00 || select=2/8
002/019-th : 0.117 0.123 0.128 0.129 0.127 0.131 0.124 0.121  ||  -0.065 -0.017 0.026 0.030 0.016 0.043 -0.007 -0.036   || dis=0.00 || select=5/8
003/019-th : 0.111 0.118 0.124 0.121 0.130 0.131 0.130 0.134  ||  -0.116 -0.057 -0.008 -0.029 0.040 0.049 0.040 0.073   || dis=0.00 || select=7/8
004/019-th : 0.112 0.115 0.117 0.117 0.132 0.134 0.138 0.135  ||  -0.106 -0.077 -0.066 -0.065 0.058 0.071 0.103 0.082   || dis=0.00 || select=6/8
005/019-th : 0.107 0.117 0.125 0.128 0.126 0.134 0.131 0.132  ||  -0.146 -0.064 0.005 0.027 0.017 0.078 0.053 0.059     || dis=0.00 || select=5/8
006/019-th : 0.113 0.114 0.114 0.125 0.130 0.129 0.134 0.141  ||  -0.095 -0.091 -0.091 0.002 0.044 0.037 0.074 0.124    || dis=0.01 || select=7/8
007/019-th : 0.054 0.066 0.085 0.100 0.134 0.150 0.179 0.232  ||  -0.731 -0.538 -0.278 -0.116 0.177 0.290 0.463 0.723   || dis=0.05 || select=7/8
008/019-th : 0.041 0.048 0.068 0.102 0.126 0.165 0.227 0.224  ||  -0.950 -0.783 -0.427 -0.027 0.184 0.453 0.772 0.759   || dis=0.00 || select=6/8
009/019-th : 0.092 0.085 0.107 0.122 0.118 0.129 0.167 0.179  ||  -0.275 -0.352 -0.123 0.004 -0.027 0.064 0.319 0.390   || dis=0.01 || select=7/8
010/019-th : 0.097 0.102 0.112 0.124 0.130 0.142 0.142 0.150  ||  -0.247 -0.188 -0.095 0.006 0.050 0.139 0.140 0.196    || dis=0.01 || select=7/8
011/019-th : 0.099 0.090 0.110 0.114 0.129 0.134 0.153 0.170  ||  -0.212 -0.302 -0.109 -0.067 0.053 0.094 0.222 0.328   || dis=0.02 || select=7/8
012/019-th : 0.100 0.113 0.113 0.118 0.135 0.135 0.140 0.147  ||  -0.218 -0.092 -0.092 -0.049 0.082 0.088 0.118 0.170   || dis=0.01 || select=7/8
013/019-th : 0.024 0.029 0.041 0.056 0.069 0.109 0.240 0.432  ||  -1.194 -0.971 -0.647 -0.324 -0.116 0.341 1.126 1.716  || dis=0.19 || select=7/8
014/019-th : 0.035 0.045 0.056 0.072 0.113 0.158 0.235 0.286  ||  -1.013 -0.774 -0.550 -0.304 0.151 0.483 0.879 1.077   || dis=0.05 || select=7/8
015/019-th : 0.021 0.026 0.037 0.049 0.076 0.118 0.234 0.440  ||  -1.287 -1.057 -0.700 -0.410 0.020 0.456 1.144 1.774   || dis=0.21 || select=7/8
016/019-th : 0.056 0.071 0.100 0.123 0.140 0.158 0.172 0.180  ||  -0.724 -0.488 -0.156 0.051 0.181 0.304 0.392 0.435    || dis=0.01 || select=7/8
017/019-th : 0.111 0.111 0.115 0.126 0.130 0.128 0.140 0.139  ||  -0.108 -0.115 -0.077 0.014 0.046 0.030 0.123 0.112    || dis=0.00 || select=6/8
018/019-th : 0.087 0.101 0.122 0.127 0.130 0.129 0.143 0.161  ||  -0.342 -0.198 -0.008 0.033 0.059 0.050 0.151 0.268    || dis=0.02 || select=7/8
[epoch=280/600] FLOP : 28.03 MB, ratio : 0.6867, Expected-ratio : 0.7000, Discrepancy : 0.078
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:10:18] [epoch=280/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 4.914 (4.914)  Prec@1 31.64 (31.64) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:10:25] [epoch=280/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.288 (2.279)  Prec@1 26.79 (38.80) Prec@5 75.60 (82.91) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.80 Prec@5 82.91 Error@1 61.20 Error@5 17.09 Loss:2.279
***[2020-01-29 08:10:25]*** VALID [epoch=280/600] loss = 2.279168, accuracy@1 = 38.80, accuracy@5 = 82.91 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:10:25]*** start epoch=281/600 Time Left: [02:49:34], LR=[0.054966 ~ 0.054966], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=281, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.793333386871916, FLOP=40.81
[Search] : epoch=281/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:10:25] [epoch=281/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.743 (0.743)  Prec@1 75.00 (75.00) Prec@5 97.66 (97.66) Acls-loss 0.679 (0.679) FLOP-Loss 0.000 (0.000) Arch-Loss 0.679 (0.679)
**TRAIN** [2020-01-29 08:10:50] [epoch=281/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.650 (0.772)  Prec@1 77.98 (73.87) Prec@5 99.40 (98.08) Acls-loss 0.760 (0.805) FLOP-Loss 0.000 (0.000) Arch-Loss 0.760 (0.805)
 **TRAIN** Prec@1 73.87 Prec@5 98.08 Error@1 26.13 Error@5 1.92 Base-Loss:0.772, Arch-Loss=0.805
***[2020-01-29 08:10:50]*** TRAIN [epoch=281/600] base-loss = 0.771621, arch-loss = 0.804854, accuracy-1 = 73.87, accuracy-5 = 98.08
[epoch=281/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.541568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.435 0.201 0.364  ||  0.2471 -0.5232 0.0687  || discrepancy=0.07 || select=0/3
001/003-th : 0.342 0.134 0.524  ||  0.0336 -0.9060 0.4602  || discrepancy=0.18 || select=2/3
002/003-th : 0.013 0.068 0.918  ||  -2.1291 -0.4987 2.0997  || discrepancy=0.85 || select=2/3
-----------------------------------------------
000/019-th : 0.048 0.068 0.095 0.099 0.136 0.151 0.190 0.212  ||  -0.845 -0.509 -0.170 -0.128 0.191 0.294 0.524 0.630   || dis=0.02 || select=7/8
001/019-th : 0.126 0.123 0.128 0.127 0.123 0.127 0.121 0.124  ||  0.011 -0.015 0.025 0.017 -0.012 0.017 -0.035 -0.008   || dis=0.00 || select=2/8
002/019-th : 0.117 0.122 0.127 0.129 0.126 0.132 0.126 0.122  ||  -0.069 -0.029 0.013 0.030 0.004 0.051 0.004 -0.024    || dis=0.00 || select=5/8
003/019-th : 0.111 0.117 0.123 0.120 0.130 0.131 0.132 0.136  ||  -0.118 -0.067 -0.016 -0.044 0.037 0.050 0.057 0.083   || dis=0.00 || select=7/8
004/019-th : 0.111 0.114 0.117 0.117 0.133 0.134 0.138 0.136  ||  -0.117 -0.084 -0.065 -0.066 0.069 0.074 0.106 0.087   || dis=0.00 || select=6/8
005/019-th : 0.108 0.117 0.123 0.130 0.126 0.133 0.131 0.133  ||  -0.144 -0.064 -0.008 0.042 0.013 0.070 0.049 0.064    || dis=0.00 || select=5/8
006/019-th : 0.113 0.111 0.113 0.123 0.131 0.130 0.136 0.143  ||  -0.100 -0.111 -0.098 -0.010 0.051 0.044 0.085 0.135   || dis=0.01 || select=7/8
007/019-th : 0.054 0.065 0.083 0.100 0.132 0.152 0.182 0.233  ||  -0.725 -0.552 -0.299 -0.114 0.161 0.304 0.488 0.731   || dis=0.05 || select=7/8
008/019-th : 0.039 0.048 0.068 0.101 0.126 0.165 0.228 0.225  ||  -0.981 -0.776 -0.425 -0.031 0.187 0.460 0.784 0.768   || dis=0.00 || select=6/8
009/019-th : 0.091 0.085 0.107 0.120 0.118 0.129 0.169 0.181  ||  -0.282 -0.354 -0.125 -0.010 -0.026 0.061 0.330 0.401  || dis=0.01 || select=7/8
010/019-th : 0.097 0.103 0.110 0.123 0.129 0.142 0.145 0.152  ||  -0.244 -0.187 -0.117 -0.006 0.038 0.135 0.161 0.206   || dis=0.01 || select=7/8
011/019-th : 0.099 0.089 0.110 0.114 0.129 0.136 0.153 0.170  ||  -0.216 -0.313 -0.108 -0.067 0.054 0.103 0.226 0.330   || dis=0.02 || select=7/8
012/019-th : 0.099 0.111 0.111 0.117 0.135 0.137 0.141 0.148  ||  -0.219 -0.112 -0.110 -0.057 0.089 0.102 0.131 0.178   || dis=0.01 || select=7/8
013/019-th : 0.024 0.029 0.040 0.056 0.069 0.108 0.241 0.434  ||  -1.188 -0.964 -0.664 -0.329 -0.118 0.334 1.136 1.724  || dis=0.19 || select=7/8
014/019-th : 0.035 0.045 0.056 0.072 0.114 0.159 0.232 0.287  ||  -1.022 -0.780 -0.550 -0.300 0.159 0.493 0.870 1.082   || dis=0.05 || select=7/8
015/019-th : 0.020 0.026 0.037 0.049 0.073 0.116 0.232 0.446  ||  -1.294 -1.048 -0.693 -0.411 -0.007 0.453 1.144 1.796  || dis=0.21 || select=7/8
016/019-th : 0.055 0.071 0.098 0.124 0.138 0.158 0.173 0.182  ||  -0.743 -0.491 -0.167 0.065 0.175 0.305 0.401 0.446    || dis=0.01 || select=7/8
017/019-th : 0.111 0.109 0.114 0.126 0.130 0.130 0.140 0.141  ||  -0.113 -0.126 -0.086 0.012 0.043 0.043 0.121 0.128    || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.121 0.126 0.130 0.131 0.143 0.165  ||  -0.351 -0.217 -0.013 0.021 0.055 0.061 0.150 0.292    || dis=0.02 || select=7/8
[epoch=281/600] FLOP : 28.54 MB, ratio : 0.6993, Expected-ratio : 0.7000, Discrepancy : 0.079
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:10:50] [epoch=281/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 1.848 (1.848)  Prec@1 50.39 (50.39) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:10:56] [epoch=281/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.439 (2.160)  Prec@1 30.95 (36.74) Prec@5 77.98 (81.86) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.74 Prec@5 81.86 Error@1 63.26 Error@5 18.14 Loss:2.160
***[2020-01-29 08:10:56]*** VALID [epoch=281/600] loss = 2.159950, accuracy@1 = 36.74, accuracy@5 = 81.86 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:10:56]*** start epoch=282/600 Time Left: [02:49:02], LR=[0.054705 ~ 0.054705], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=282, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.780565367630361, FLOP=40.81
[Search] : epoch=282/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:10:57] [epoch=282/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.716 (0.716)  Prec@1 74.61 (74.61) Prec@5 99.22 (99.22) Acls-loss 0.980 (0.980) FLOP-Loss 0.000 (0.000) Arch-Loss 0.980 (0.980)
**TRAIN** [2020-01-29 08:11:22] [epoch=282/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.752 (0.765)  Prec@1 77.38 (73.72) Prec@5 96.43 (98.05) Acls-loss 0.969 (0.810) FLOP-Loss 0.000 (0.029) Arch-Loss 0.969 (0.867)
 **TRAIN** Prec@1 73.72 Prec@5 98.05 Error@1 26.28 Error@5 1.95 Base-Loss:0.765, Arch-Loss=0.867
***[2020-01-29 08:11:22]*** TRAIN [epoch=282/600] base-loss = 0.765090, arch-loss = 0.866786, accuracy-1 = 73.72, accuracy-5 = 98.05
[epoch=282/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 14, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.541568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.430 0.198 0.371  ||  0.2335 -0.5403 0.0862  || discrepancy=0.06 || select=0/3
001/003-th : 0.340 0.132 0.528  ||  0.0287 -0.9147 0.4681  || discrepancy=0.19 || select=2/3
002/003-th : 0.013 0.067 0.919  ||  -2.1258 -0.5092 2.1062  || discrepancy=0.85 || select=2/3
-----------------------------------------------
000/019-th : 0.049 0.067 0.092 0.098 0.134 0.156 0.190 0.213  ||  -0.839 -0.514 -0.200 -0.133 0.176 0.328 0.527 0.640   || dis=0.02 || select=7/8
001/019-th : 0.126 0.123 0.128 0.125 0.124 0.127 0.121 0.125  ||  0.010 -0.018 0.023 0.002 -0.009 0.019 -0.033 -0.000   || dis=0.00 || select=2/8
002/019-th : 0.115 0.121 0.125 0.128 0.127 0.134 0.126 0.124  ||  -0.082 -0.030 0.000 0.024 0.012 0.068 0.003 -0.012    || dis=0.01 || select=5/8
003/019-th : 0.107 0.117 0.122 0.123 0.129 0.130 0.134 0.136  ||  -0.149 -0.061 -0.022 -0.013 0.037 0.041 0.075 0.088   || dis=0.00 || select=7/8
004/019-th : 0.110 0.114 0.116 0.115 0.134 0.132 0.140 0.139  ||  -0.127 -0.092 -0.068 -0.078 0.070 0.059 0.114 0.111   || dis=0.00 || select=6/8
005/019-th : 0.107 0.115 0.124 0.129 0.127 0.133 0.131 0.133  ||  -0.151 -0.075 -0.005 0.039 0.025 0.068 0.053 0.071    || dis=0.00 || select=7/8
006/019-th : 0.111 0.109 0.113 0.122 0.131 0.132 0.138 0.144  ||  -0.114 -0.133 -0.098 -0.017 0.047 0.059 0.100 0.147   || dis=0.01 || select=7/8
007/019-th : 0.052 0.064 0.084 0.100 0.132 0.155 0.184 0.230  ||  -0.763 -0.561 -0.288 -0.109 0.167 0.329 0.499 0.726   || dis=0.05 || select=7/8
008/019-th : 0.039 0.048 0.068 0.101 0.124 0.163 0.229 0.228  ||  -0.983 -0.779 -0.427 -0.026 0.175 0.451 0.787 0.783   || dis=0.00 || select=6/8
009/019-th : 0.090 0.084 0.105 0.121 0.118 0.128 0.168 0.185  ||  -0.292 -0.365 -0.140 0.002 -0.025 0.056 0.327 0.425   || dis=0.02 || select=7/8
010/019-th : 0.097 0.101 0.108 0.121 0.131 0.143 0.145 0.154  ||  -0.244 -0.200 -0.134 -0.017 0.057 0.145 0.161 0.217   || dis=0.01 || select=7/8
011/019-th : 0.098 0.089 0.109 0.116 0.131 0.134 0.152 0.171  ||  -0.217 -0.321 -0.116 -0.057 0.067 0.091 0.220 0.337   || dis=0.02 || select=7/8
012/019-th : 0.099 0.110 0.110 0.118 0.135 0.136 0.143 0.148  ||  -0.222 -0.116 -0.118 -0.048 0.085 0.095 0.145 0.180   || dis=0.01 || select=7/8
013/019-th : 0.024 0.029 0.040 0.055 0.068 0.108 0.238 0.439  ||  -1.178 -0.973 -0.666 -0.333 -0.124 0.336 1.130 1.742  || dis=0.20 || select=7/8
014/019-th : 0.035 0.045 0.056 0.071 0.115 0.158 0.231 0.289  ||  -1.017 -0.775 -0.557 -0.310 0.165 0.487 0.868 1.089   || dis=0.06 || select=7/8
015/019-th : 0.020 0.025 0.037 0.049 0.073 0.116 0.228 0.452  ||  -1.288 -1.060 -0.699 -0.403 -0.013 0.456 1.130 1.815  || dis=0.22 || select=7/8
016/019-th : 0.055 0.071 0.099 0.123 0.138 0.158 0.173 0.182  ||  -0.740 -0.492 -0.166 0.057 0.174 0.309 0.396 0.451    || dis=0.01 || select=7/8
017/019-th : 0.111 0.110 0.113 0.125 0.130 0.130 0.140 0.142  ||  -0.110 -0.125 -0.091 0.007 0.042 0.046 0.118 0.131    || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.120 0.127 0.129 0.131 0.146 0.163  ||  -0.357 -0.222 -0.019 0.030 0.048 0.065 0.170 0.286    || dis=0.02 || select=7/8
[epoch=282/600] FLOP : 28.54 MB, ratio : 0.6993, Expected-ratio : 0.7000, Discrepancy : 0.079
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:11:22] [epoch=282/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 2.201 (2.201)  Prec@1 45.31 (45.31) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:11:28] [epoch=282/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.831 (2.255)  Prec@1 24.40 (37.73) Prec@5 80.36 (82.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.73 Prec@5 82.07 Error@1 62.27 Error@5 17.93 Loss:2.255
***[2020-01-29 08:11:28]*** VALID [epoch=282/600] loss = 2.255355, accuracy@1 = 37.73, accuracy@5 = 82.07 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:11:28]*** start epoch=283/600 Time Left: [02:48:30], LR=[0.054445 ~ 0.054445], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=283, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.7677910273227826, FLOP=40.81
[Search] : epoch=283/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:11:29] [epoch=283/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.763 (0.763)  Prec@1 75.78 (75.78) Prec@5 99.22 (99.22) Acls-loss 0.794 (0.794) FLOP-Loss 0.000 (0.000) Arch-Loss 0.794 (0.794)
**TRAIN** [2020-01-29 08:11:54] [epoch=283/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.015 (0.809)  Prec@1 64.88 (72.29) Prec@5 95.83 (97.81) Acls-loss 0.916 (0.851) FLOP-Loss 0.000 (0.000) Arch-Loss 0.916 (0.851)
 **TRAIN** Prec@1 72.29 Prec@5 97.81 Error@1 27.71 Error@5 2.19 Base-Loss:0.809, Arch-Loss=0.851
***[2020-01-29 08:11:54]*** TRAIN [epoch=283/600] base-loss = 0.808931, arch-loss = 0.850674, accuracy-1 = 72.29, accuracy-5 = 97.81
[epoch=283/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 16, 16, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.541568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.423 0.199 0.377  ||  0.2182 -0.5346 0.1023  || discrepancy=0.05 || select=0/3
001/003-th : 0.331 0.129 0.539  ||  0.0072 -0.9333 0.4934  || discrepancy=0.21 || select=2/3
002/003-th : 0.013 0.067 0.919  ||  -2.1175 -0.5124 2.1057  || discrepancy=0.85 || select=2/3
-----------------------------------------------
000/019-th : 0.047 0.066 0.091 0.095 0.133 0.157 0.190 0.221  ||  -0.856 -0.520 -0.205 -0.164 0.171 0.339 0.532 0.681   || dis=0.03 || select=7/8
001/019-th : 0.125 0.122 0.128 0.126 0.125 0.127 0.120 0.127  ||  0.004 -0.025 0.024 0.005 0.002 0.014 -0.038 0.012     || dis=0.00 || select=2/8
002/019-th : 0.113 0.120 0.125 0.128 0.128 0.133 0.126 0.125  ||  -0.097 -0.037 0.001 0.027 0.021 0.065 0.011 0.000     || dis=0.01 || select=5/8
003/019-th : 0.107 0.117 0.122 0.122 0.130 0.131 0.135 0.136  ||  -0.156 -0.064 -0.019 -0.023 0.043 0.051 0.079 0.090   || dis=0.00 || select=7/8
004/019-th : 0.108 0.111 0.117 0.116 0.134 0.133 0.140 0.141  ||  -0.139 -0.116 -0.064 -0.068 0.070 0.067 0.115 0.125   || dis=0.00 || select=7/8
005/019-th : 0.105 0.114 0.123 0.129 0.127 0.134 0.133 0.135  ||  -0.167 -0.084 -0.006 0.036 0.020 0.074 0.067 0.084    || dis=0.00 || select=7/8
006/019-th : 0.110 0.108 0.113 0.121 0.131 0.131 0.140 0.146  ||  -0.126 -0.144 -0.095 -0.027 0.049 0.052 0.120 0.157   || dis=0.01 || select=7/8
007/019-th : 0.051 0.063 0.083 0.100 0.131 0.156 0.184 0.233  ||  -0.772 -0.569 -0.294 -0.110 0.163 0.338 0.502 0.742   || dis=0.05 || select=7/8
008/019-th : 0.039 0.047 0.067 0.101 0.123 0.162 0.233 0.230  ||  -0.979 -0.798 -0.442 -0.027 0.169 0.445 0.810 0.797   || dis=0.00 || select=6/8
009/019-th : 0.089 0.084 0.104 0.120 0.119 0.129 0.167 0.188  ||  -0.305 -0.364 -0.154 -0.007 -0.015 0.067 0.324 0.440  || dis=0.02 || select=7/8
010/019-th : 0.095 0.100 0.108 0.118 0.128 0.145 0.146 0.159  ||  -0.260 -0.209 -0.135 -0.045 0.037 0.157 0.167 0.254   || dis=0.01 || select=7/8
011/019-th : 0.097 0.089 0.107 0.114 0.131 0.136 0.153 0.173  ||  -0.226 -0.320 -0.132 -0.071 0.073 0.109 0.222 0.348   || dis=0.02 || select=7/8
012/019-th : 0.099 0.109 0.109 0.118 0.135 0.136 0.145 0.150  ||  -0.227 -0.132 -0.128 -0.050 0.083 0.097 0.158 0.192   || dis=0.01 || select=7/8
013/019-th : 0.022 0.028 0.040 0.055 0.069 0.107 0.233 0.446  ||  -1.257 -0.994 -0.649 -0.323 -0.099 0.347 1.123 1.772  || dis=0.21 || select=7/8
014/019-th : 0.033 0.044 0.055 0.070 0.116 0.159 0.234 0.290  ||  -1.064 -0.785 -0.558 -0.320 0.186 0.504 0.891 1.104   || dis=0.06 || select=7/8
015/019-th : 0.020 0.026 0.037 0.049 0.073 0.114 0.229 0.454  ||  -1.319 -1.041 -0.689 -0.401 -0.010 0.440 1.139 1.824  || dis=0.23 || select=7/8
016/019-th : 0.056 0.071 0.098 0.123 0.137 0.158 0.173 0.184  ||  -0.737 -0.498 -0.173 0.059 0.164 0.308 0.400 0.459    || dis=0.01 || select=7/8
017/019-th : 0.111 0.108 0.113 0.123 0.130 0.131 0.141 0.143  ||  -0.116 -0.135 -0.094 -0.010 0.043 0.056 0.128 0.141   || dis=0.00 || select=7/8
018/019-th : 0.083 0.098 0.119 0.128 0.128 0.131 0.147 0.165  ||  -0.385 -0.224 -0.030 0.041 0.046 0.068 0.185 0.299    || dis=0.02 || select=7/8
[epoch=283/600] FLOP : 28.54 MB, ratio : 0.6993, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:11:54] [epoch=283/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.772 (2.772)  Prec@1 31.25 (31.25) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:12:00] [epoch=283/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.614 (2.447)  Prec@1 17.86 (34.33) Prec@5 63.69 (79.27) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.33 Prec@5 79.27 Error@1 65.67 Error@5 20.73 Loss:2.447
***[2020-01-29 08:12:00]*** VALID [epoch=283/600] loss = 2.446751, accuracy@1 = 34.33, accuracy@5 = 79.27 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:12:00]*** start epoch=284/600 Time Left: [02:47:58], LR=[0.054184 ~ 0.054184], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=284, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.7550107161641737, FLOP=40.81
[Search] : epoch=284/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:12:01] [epoch=284/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.670 (0.670)  Prec@1 78.52 (78.52) Prec@5 98.83 (98.83) Acls-loss 0.725 (0.725) FLOP-Loss 0.000 (0.000) Arch-Loss 0.725 (0.725)
**TRAIN** [2020-01-29 08:12:25] [epoch=284/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 0.813 (0.782)  Prec@1 71.43 (73.36) Prec@5 98.21 (97.93) Acls-loss 0.822 (0.820) FLOP-Loss 2.796 (0.105) Arch-Loss 6.413 (1.030)
 **TRAIN** Prec@1 73.36 Prec@5 97.93 Error@1 26.64 Error@5 2.07 Base-Loss:0.782, Arch-Loss=1.030
***[2020-01-29 08:12:25]*** TRAIN [epoch=284/600] base-loss = 0.781538, arch-loss = 1.029522, accuracy-1 = 73.36, accuracy-5 = 97.93
[epoch=284/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 12, 14, 14, 16, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.541568)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.427 0.200 0.373  ||  0.2284 -0.5312 0.0927  || discrepancy=0.05 || select=0/3
001/003-th : 0.334 0.131 0.536  ||  0.0146 -0.9243 0.4869  || discrepancy=0.20 || select=2/3
002/003-th : 0.013 0.065 0.922  ||  -2.1398 -0.5233 2.1315  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.046 0.067 0.091 0.097 0.133 0.157 0.189 0.221  ||  -0.885 -0.508 -0.206 -0.139 0.177 0.343 0.525 0.682   || dis=0.03 || select=7/8
001/019-th : 0.126 0.122 0.128 0.126 0.124 0.127 0.120 0.125  ||  0.010 -0.021 0.028 0.010 -0.006 0.020 -0.044 0.002    || dis=0.00 || select=2/8
002/019-th : 0.115 0.122 0.126 0.129 0.126 0.133 0.126 0.123  ||  -0.086 -0.021 0.005 0.033 0.008 0.060 0.007 -0.016    || dis=0.00 || select=5/8
003/019-th : 0.108 0.118 0.123 0.120 0.129 0.131 0.135 0.135  ||  -0.142 -0.057 -0.015 -0.035 0.036 0.051 0.079 0.079   || dis=0.00 || select=6/8
004/019-th : 0.108 0.110 0.118 0.117 0.133 0.134 0.139 0.139  ||  -0.138 -0.123 -0.049 -0.057 0.071 0.077 0.115 0.110   || dis=0.00 || select=6/8
005/019-th : 0.103 0.115 0.125 0.129 0.129 0.133 0.133 0.134  ||  -0.189 -0.073 0.005 0.043 0.036 0.073 0.067 0.076     || dis=0.00 || select=7/8
006/019-th : 0.112 0.109 0.114 0.120 0.132 0.131 0.137 0.144  ||  -0.105 -0.133 -0.092 -0.033 0.061 0.052 0.097 0.146   || dis=0.01 || select=7/8
007/019-th : 0.052 0.064 0.084 0.099 0.130 0.154 0.185 0.233  ||  -0.766 -0.557 -0.284 -0.119 0.155 0.326 0.506 0.738   || dis=0.05 || select=7/8
008/019-th : 0.039 0.047 0.067 0.101 0.122 0.163 0.231 0.231  ||  -0.977 -0.795 -0.438 -0.029 0.164 0.452 0.801 0.799   || dis=0.00 || select=6/8
009/019-th : 0.089 0.085 0.103 0.120 0.120 0.131 0.165 0.187  ||  -0.306 -0.351 -0.161 -0.009 -0.010 0.079 0.310 0.438  || dis=0.02 || select=7/8
010/019-th : 0.095 0.100 0.110 0.119 0.128 0.143 0.147 0.157  ||  -0.259 -0.209 -0.114 -0.037 0.037 0.143 0.173 0.241   || dis=0.01 || select=7/8
011/019-th : 0.098 0.089 0.105 0.114 0.131 0.136 0.155 0.171  ||  -0.220 -0.314 -0.148 -0.072 0.071 0.111 0.238 0.339   || dis=0.02 || select=7/8
012/019-th : 0.100 0.109 0.111 0.117 0.135 0.133 0.145 0.149  ||  -0.216 -0.128 -0.107 -0.054 0.083 0.073 0.156 0.186   || dis=0.00 || select=7/8
013/019-th : 0.021 0.028 0.040 0.055 0.068 0.106 0.233 0.449  ||  -1.269 -0.987 -0.644 -0.318 -0.109 0.343 1.126 1.783  || dis=0.22 || select=7/8
014/019-th : 0.032 0.044 0.056 0.069 0.115 0.160 0.235 0.289  ||  -1.098 -0.773 -0.534 -0.324 0.184 0.512 0.899 1.105   || dis=0.05 || select=7/8
015/019-th : 0.020 0.026 0.037 0.048 0.072 0.113 0.230 0.455  ||  -1.319 -1.040 -0.682 -0.417 -0.010 0.437 1.146 1.830  || dis=0.23 || select=7/8
016/019-th : 0.056 0.071 0.098 0.123 0.139 0.159 0.173 0.183  ||  -0.732 -0.499 -0.175 0.056 0.176 0.311 0.399 0.453    || dis=0.01 || select=7/8
017/019-th : 0.112 0.109 0.114 0.122 0.131 0.129 0.141 0.143  ||  -0.108 -0.131 -0.087 -0.021 0.049 0.036 0.126 0.142   || dis=0.00 || select=7/8
018/019-th : 0.085 0.098 0.120 0.127 0.128 0.130 0.147 0.165  ||  -0.369 -0.228 -0.019 0.036 0.042 0.058 0.178 0.297    || dis=0.02 || select=7/8
[epoch=284/600] FLOP : 28.54 MB, ratio : 0.6993, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:12:26] [epoch=284/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.516 (1.516)  Prec@1 53.52 (53.52) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:12:32] [epoch=284/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.141 (2.281)  Prec@1 32.14 (41.07) Prec@5 79.17 (83.69) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.07 Prec@5 83.69 Error@1 58.93 Error@5 16.31 Loss:2.281
***[2020-01-29 08:12:32]*** VALID [epoch=284/600] loss = 2.281300, accuracy@1 = 41.07, accuracy@5 = 83.69 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:12:32]*** start epoch=285/600 Time Left: [02:47:25], LR=[0.053923 ~ 0.053923], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=285, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.742224784533221, FLOP=40.81
[Search] : epoch=285/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:12:32] [epoch=285/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.753 (0.753)  Prec@1 73.44 (73.44) Prec@5 98.05 (98.05) Acls-loss 0.891 (0.891) FLOP-Loss 0.000 (0.000) Arch-Loss 0.891 (0.891)
**TRAIN** [2020-01-29 08:12:57] [epoch=285/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.623 (0.773)  Prec@1 80.95 (73.67) Prec@5 96.43 (98.02) Acls-loss 0.996 (0.820) FLOP-Loss 0.000 (0.228) Arch-Loss 0.996 (1.277)
 **TRAIN** Prec@1 73.67 Prec@5 98.02 Error@1 26.33 Error@5 1.98 Base-Loss:0.773, Arch-Loss=1.277
***[2020-01-29 08:12:57]*** TRAIN [epoch=285/600] base-loss = 0.773448, arch-loss = 1.276658, accuracy-1 = 73.67, accuracy-5 = 98.02
[epoch=285/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 11, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.271232)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.198 0.358  ||  0.2681 -0.5375 0.0545  || discrepancy=0.09 || select=0/3
001/003-th : 0.348 0.133 0.519  ||  0.0519 -0.9132 0.4520  || discrepancy=0.17 || select=2/3
002/003-th : 0.013 0.066 0.922  ||  -2.1364 -0.5145 2.1293  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.046 0.066 0.091 0.098 0.133 0.159 0.187 0.220  ||  -0.881 -0.520 -0.204 -0.130 0.176 0.354 0.517 0.680   || dis=0.03 || select=7/8
001/019-th : 0.130 0.126 0.132 0.128 0.123 0.124 0.116 0.120  ||  0.041 0.007 0.055 0.028 -0.014 -0.005 -0.073 -0.036   || dis=0.00 || select=2/8
002/019-th : 0.117 0.127 0.129 0.132 0.124 0.131 0.122 0.118  ||  -0.065 0.015 0.031 0.058 -0.008 0.046 -0.021 -0.053   || dis=0.00 || select=3/8
003/019-th : 0.113 0.121 0.125 0.122 0.127 0.130 0.132 0.130  ||  -0.103 -0.033 -0.001 -0.025 0.019 0.043 0.054 0.040   || dis=0.00 || select=6/8
004/019-th : 0.111 0.113 0.122 0.121 0.135 0.133 0.133 0.132  ||  -0.115 -0.093 -0.017 -0.022 0.088 0.067 0.073 0.060   || dis=0.00 || select=4/8
005/019-th : 0.102 0.118 0.127 0.132 0.126 0.133 0.132 0.130  ||  -0.192 -0.051 0.025 0.066 0.017 0.068 0.067 0.047     || dis=0.00 || select=5/8
006/019-th : 0.117 0.112 0.118 0.121 0.131 0.127 0.132 0.141  ||  -0.062 -0.107 -0.051 -0.031 0.053 0.019 0.056 0.123   || dis=0.01 || select=7/8
007/019-th : 0.053 0.065 0.084 0.102 0.130 0.155 0.184 0.227  ||  -0.748 -0.548 -0.289 -0.091 0.146 0.328 0.495 0.707   || dis=0.04 || select=7/8
008/019-th : 0.040 0.048 0.068 0.102 0.124 0.165 0.228 0.227  ||  -0.969 -0.783 -0.432 -0.026 0.174 0.458 0.782 0.780   || dis=0.00 || select=6/8
009/019-th : 0.091 0.088 0.104 0.119 0.120 0.131 0.165 0.183  ||  -0.288 -0.320 -0.155 -0.016 -0.014 0.073 0.308 0.409  || dis=0.02 || select=7/8
010/019-th : 0.098 0.103 0.112 0.121 0.128 0.142 0.143 0.153  ||  -0.232 -0.182 -0.103 -0.026 0.036 0.136 0.145 0.213   || dis=0.01 || select=7/8
011/019-th : 0.100 0.091 0.107 0.116 0.131 0.134 0.153 0.168  ||  -0.205 -0.292 -0.134 -0.054 0.069 0.091 0.220 0.313   || dis=0.02 || select=7/8
012/019-th : 0.103 0.111 0.114 0.121 0.134 0.131 0.141 0.145  ||  -0.184 -0.109 -0.083 -0.029 0.079 0.051 0.129 0.156   || dis=0.00 || select=7/8
013/019-th : 0.021 0.028 0.040 0.055 0.068 0.108 0.233 0.445  ||  -1.267 -0.996 -0.640 -0.313 -0.103 0.351 1.122 1.769  || dis=0.21 || select=7/8
014/019-th : 0.031 0.046 0.057 0.071 0.115 0.160 0.234 0.286  ||  -1.120 -0.736 -0.529 -0.308 0.185 0.513 0.891 1.092   || dis=0.05 || select=7/8
015/019-th : 0.020 0.026 0.037 0.048 0.073 0.113 0.232 0.451  ||  -1.317 -1.027 -0.683 -0.424 -0.006 0.430 1.155 1.819  || dis=0.22 || select=7/8
016/019-th : 0.057 0.073 0.101 0.125 0.139 0.156 0.171 0.178  ||  -0.716 -0.473 -0.147 0.072 0.175 0.292 0.380 0.421    || dis=0.01 || select=7/8
017/019-th : 0.112 0.114 0.118 0.124 0.131 0.127 0.137 0.139  ||  -0.102 -0.091 -0.053 -0.005 0.048 0.020 0.094 0.108   || dis=0.00 || select=7/8
018/019-th : 0.087 0.100 0.122 0.127 0.127 0.132 0.145 0.160  ||  -0.349 -0.208 -0.003 0.037 0.033 0.071 0.164 0.267    || dis=0.02 || select=7/8
[epoch=285/600] FLOP : 28.27 MB, ratio : 0.6927, Expected-ratio : 0.7000, Discrepancy : 0.080
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:12:58] [epoch=285/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.160 (2.160)  Prec@1 38.28 (38.28) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:13:04] [epoch=285/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.653 (2.166)  Prec@1 44.64 (38.53) Prec@5 94.05 (83.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.53 Prec@5 83.06 Error@1 61.47 Error@5 16.94 Loss:2.166
***[2020-01-29 08:13:04]*** VALID [epoch=285/600] loss = 2.165905, accuracy@1 = 38.53, accuracy@5 = 83.06 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:13:04]*** start epoch=286/600 Time Left: [02:46:54], LR=[0.053662 ~ 0.053662], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=286, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.729433582962698, FLOP=40.81
[Search] : epoch=286/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:13:05] [epoch=286/600][000/098] Time 0.74 (0.74) Data 0.36 (0.36) Base-Loss 0.717 (0.717)  Prec@1 76.95 (76.95) Prec@5 98.83 (98.83) Acls-loss 0.891 (0.891) FLOP-Loss 0.000 (0.000) Arch-Loss 0.891 (0.891)
**TRAIN** [2020-01-29 08:13:29] [epoch=286/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.699 (0.774)  Prec@1 74.40 (73.65) Prec@5 99.40 (98.13) Acls-loss 0.670 (0.827) FLOP-Loss 0.000 (0.000) Arch-Loss 0.670 (0.827)
 **TRAIN** Prec@1 73.65 Prec@5 98.13 Error@1 26.35 Error@5 1.87 Base-Loss:0.774, Arch-Loss=0.827
***[2020-01-29 08:13:29]*** TRAIN [epoch=286/600] base-loss = 0.773741, arch-loss = 0.827173, accuracy-1 = 73.65, accuracy-5 = 98.13
[epoch=286/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 11, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.271232)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.198 0.364  ||  0.2542 -0.5381 0.0699  || discrepancy=0.07 || select=0/3
001/003-th : 0.341 0.131 0.528  ||  0.0356 -0.9223 0.4706  || discrepancy=0.19 || select=2/3
002/003-th : 0.013 0.064 0.923  ||  -2.1378 -0.5246 2.1392  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.047 0.065 0.090 0.098 0.134 0.158 0.186 0.222  ||  -0.869 -0.537 -0.210 -0.128 0.184 0.347 0.511 0.688   || dis=0.04 || select=7/8
001/019-th : 0.129 0.125 0.132 0.128 0.122 0.124 0.118 0.121  ||  0.030 0.001 0.055 0.028 -0.022 -0.006 -0.057 -0.028   || dis=0.00 || select=2/8
002/019-th : 0.116 0.125 0.128 0.131 0.126 0.130 0.124 0.120  ||  -0.076 -0.002 0.025 0.051 0.012 0.043 -0.007 -0.040   || dis=0.00 || select=3/8
003/019-th : 0.112 0.120 0.123 0.122 0.128 0.131 0.132 0.131  ||  -0.110 -0.041 -0.018 -0.019 0.028 0.049 0.059 0.050   || dis=0.00 || select=6/8
004/019-th : 0.110 0.113 0.122 0.117 0.136 0.134 0.135 0.133  ||  -0.122 -0.094 -0.017 -0.062 0.089 0.076 0.085 0.071   || dis=0.00 || select=4/8
005/019-th : 0.102 0.113 0.125 0.133 0.126 0.134 0.134 0.132  ||  -0.193 -0.089 0.008 0.070 0.020 0.081 0.080 0.062     || dis=0.00 || select=5/8
006/019-th : 0.115 0.111 0.118 0.120 0.134 0.129 0.132 0.141  ||  -0.077 -0.117 -0.056 -0.033 0.076 0.033 0.061 0.124   || dis=0.01 || select=7/8
007/019-th : 0.053 0.064 0.083 0.102 0.129 0.153 0.184 0.231  ||  -0.740 -0.562 -0.296 -0.090 0.143 0.317 0.497 0.726   || dis=0.05 || select=7/8
008/019-th : 0.040 0.048 0.068 0.102 0.122 0.164 0.228 0.228  ||  -0.967 -0.776 -0.430 -0.027 0.160 0.453 0.783 0.782   || dis=0.00 || select=6/8
009/019-th : 0.089 0.088 0.103 0.118 0.119 0.134 0.166 0.183  ||  -0.310 -0.320 -0.165 -0.024 -0.019 0.103 0.318 0.414  || dis=0.02 || select=7/8
010/019-th : 0.097 0.101 0.111 0.118 0.129 0.143 0.146 0.155  ||  -0.247 -0.201 -0.108 -0.044 0.042 0.145 0.169 0.227   || dis=0.01 || select=7/8
011/019-th : 0.098 0.093 0.107 0.117 0.130 0.134 0.154 0.167  ||  -0.222 -0.275 -0.133 -0.047 0.063 0.087 0.227 0.310   || dis=0.01 || select=7/8
012/019-th : 0.102 0.111 0.113 0.118 0.134 0.133 0.142 0.147  ||  -0.194 -0.114 -0.095 -0.049 0.075 0.073 0.133 0.171   || dis=0.01 || select=7/8
013/019-th : 0.021 0.027 0.039 0.055 0.068 0.105 0.234 0.452  ||  -1.265 -1.034 -0.644 -0.312 -0.099 0.338 1.141 1.798  || dis=0.22 || select=7/8
014/019-th : 0.031 0.046 0.055 0.070 0.114 0.159 0.235 0.290  ||  -1.139 -0.732 -0.544 -0.302 0.176 0.514 0.903 1.114   || dis=0.05 || select=7/8
015/019-th : 0.019 0.026 0.036 0.047 0.071 0.111 0.228 0.462  ||  -1.311 -1.038 -0.690 -0.434 -0.022 0.430 1.152 1.857  || dis=0.23 || select=7/8
016/019-th : 0.057 0.073 0.100 0.124 0.136 0.156 0.174 0.180  ||  -0.721 -0.475 -0.152 0.063 0.154 0.291 0.400 0.434    || dis=0.01 || select=7/8
017/019-th : 0.112 0.113 0.117 0.123 0.130 0.128 0.136 0.141  ||  -0.108 -0.099 -0.061 -0.007 0.044 0.029 0.092 0.123   || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.122 0.126 0.130 0.131 0.146 0.160  ||  -0.354 -0.213 -0.003 0.027 0.057 0.064 0.172 0.265    || dis=0.01 || select=7/8
[epoch=286/600] FLOP : 28.27 MB, ratio : 0.6927, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:13:29] [epoch=286/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.490 (2.490)  Prec@1 23.83 (23.83) Prec@5 70.70 (70.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:13:35] [epoch=286/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.764 (2.158)  Prec@1 39.29 (34.34) Prec@5 83.33 (78.50) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.34 Prec@5 78.50 Error@1 65.66 Error@5 21.50 Loss:2.158
***[2020-01-29 08:13:36]*** VALID [epoch=286/600] loss = 2.157658, accuracy@1 = 34.34, accuracy@5 = 78.50 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:13:36]*** start epoch=287/600 Time Left: [02:46:22], LR=[0.053401 ~ 0.053401], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=287, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.7166374621298583, FLOP=40.81
[Search] : epoch=287/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:13:36] [epoch=287/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.850 (0.850)  Prec@1 71.48 (71.48) Prec@5 97.66 (97.66) Acls-loss 0.860 (0.860) FLOP-Loss 0.000 (0.000) Arch-Loss 0.860 (0.860)
**TRAIN** [2020-01-29 08:14:01] [epoch=287/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.728 (0.773)  Prec@1 76.19 (73.84) Prec@5 98.21 (98.03) Acls-loss 0.956 (0.816) FLOP-Loss 0.000 (0.171) Arch-Loss 0.956 (1.158)
 **TRAIN** Prec@1 73.84 Prec@5 98.03 Error@1 26.16 Error@5 1.97 Base-Loss:0.773, Arch-Loss=1.158
***[2020-01-29 08:14:01]*** TRAIN [epoch=287/600] base-loss = 0.773476, arch-loss = 1.157673, accuracy-1 = 73.84, accuracy-5 = 98.03
[epoch=287/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 11, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.271232)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.196 0.356  ||  0.2769 -0.5462 0.0491  || discrepancy=0.09 || select=0/3
001/003-th : 0.349 0.133 0.517  ||  0.0566 -0.9055 0.4499  || discrepancy=0.17 || select=2/3
002/003-th : 0.012 0.063 0.925  ||  -2.1644 -0.5219 2.1626  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.048 0.065 0.090 0.099 0.133 0.159 0.187 0.220  ||  -0.852 -0.547 -0.214 -0.119 0.178 0.351 0.513 0.677   || dis=0.03 || select=7/8
001/019-th : 0.131 0.127 0.135 0.129 0.121 0.122 0.116 0.120  ||  0.046 0.014 0.076 0.034 -0.034 -0.022 -0.074 -0.044   || dis=0.00 || select=2/8
002/019-th : 0.119 0.127 0.129 0.133 0.125 0.128 0.122 0.117  ||  -0.050 0.017 0.031 0.060 0.005 0.027 -0.026 -0.062    || dis=0.00 || select=3/8
003/019-th : 0.114 0.122 0.124 0.124 0.127 0.130 0.131 0.128  ||  -0.089 -0.026 -0.007 -0.009 0.019 0.038 0.047 0.025   || dis=0.00 || select=6/8
004/019-th : 0.113 0.116 0.123 0.117 0.134 0.133 0.132 0.131  ||  -0.099 -0.069 -0.011 -0.057 0.077 0.067 0.063 0.053   || dis=0.00 || select=4/8
005/019-th : 0.103 0.116 0.126 0.133 0.124 0.134 0.133 0.130  ||  -0.182 -0.070 0.015 0.069 0.001 0.078 0.070 0.049     || dis=0.00 || select=5/8
006/019-th : 0.117 0.113 0.116 0.122 0.135 0.128 0.130 0.139  ||  -0.061 -0.100 -0.067 -0.019 0.080 0.029 0.043 0.111   || dis=0.00 || select=7/8
007/019-th : 0.055 0.065 0.085 0.103 0.129 0.153 0.180 0.230  ||  -0.725 -0.546 -0.284 -0.090 0.139 0.307 0.470 0.717   || dis=0.05 || select=7/8
008/019-th : 0.039 0.050 0.067 0.104 0.123 0.165 0.227 0.226  ||  -0.990 -0.746 -0.442 -0.009 0.167 0.457 0.777 0.770   || dis=0.00 || select=6/8
009/019-th : 0.089 0.089 0.101 0.117 0.120 0.134 0.165 0.185  ||  -0.305 -0.310 -0.183 -0.033 -0.006 0.101 0.308 0.424  || dis=0.02 || select=7/8
010/019-th : 0.098 0.102 0.112 0.120 0.129 0.141 0.146 0.151  ||  -0.232 -0.189 -0.099 -0.028 0.046 0.130 0.165 0.200   || dis=0.01 || select=7/8
011/019-th : 0.099 0.095 0.108 0.119 0.129 0.133 0.153 0.165  ||  -0.217 -0.256 -0.132 -0.034 0.050 0.082 0.221 0.297   || dis=0.01 || select=7/8
012/019-th : 0.104 0.114 0.115 0.119 0.133 0.132 0.138 0.145  ||  -0.174 -0.089 -0.081 -0.043 0.067 0.062 0.108 0.155   || dis=0.01 || select=7/8
013/019-th : 0.022 0.027 0.039 0.055 0.067 0.106 0.237 0.448  ||  -1.241 -1.033 -0.648 -0.316 -0.112 0.342 1.150 1.786  || dis=0.21 || select=7/8
014/019-th : 0.031 0.047 0.056 0.069 0.114 0.160 0.234 0.289  ||  -1.140 -0.715 -0.531 -0.318 0.178 0.516 0.898 1.107   || dis=0.05 || select=7/8
015/019-th : 0.020 0.026 0.036 0.046 0.071 0.112 0.228 0.461  ||  -1.309 -1.020 -0.702 -0.446 -0.012 0.441 1.147 1.853  || dis=0.23 || select=7/8
016/019-th : 0.058 0.074 0.101 0.124 0.139 0.156 0.173 0.177  ||  -0.705 -0.459 -0.151 0.057 0.171 0.285 0.392 0.414    || dis=0.00 || select=7/8
017/019-th : 0.115 0.115 0.119 0.124 0.128 0.127 0.134 0.139  ||  -0.083 -0.080 -0.043 -0.008 0.022 0.021 0.068 0.107   || dis=0.01 || select=7/8
018/019-th : 0.088 0.099 0.123 0.127 0.129 0.131 0.144 0.160  ||  -0.337 -0.213 -0.001 0.034 0.053 0.061 0.156 0.262    || dis=0.02 || select=7/8
[epoch=287/600] FLOP : 28.27 MB, ratio : 0.6927, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:14:01] [epoch=287/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.626 (1.626)  Prec@1 41.80 (41.80) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:14:08] [epoch=287/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.361 (2.125)  Prec@1 70.83 (36.30) Prec@5 97.02 (80.79) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.30 Prec@5 80.79 Error@1 63.70 Error@5 19.21 Loss:2.125
***[2020-01-29 08:14:08]*** VALID [epoch=287/600] loss = 2.125025, accuracy@1 = 36.30, accuracy@5 = 80.79 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:14:08]*** start epoch=288/600 Time Left: [02:45:50], LR=[0.053140 ~ 0.053140], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=288, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.7038367728468184, FLOP=40.81
[Search] : epoch=288/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:14:08] [epoch=288/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.872 (0.872)  Prec@1 69.14 (69.14) Prec@5 98.05 (98.05) Acls-loss 0.617 (0.617) FLOP-Loss 0.000 (0.000) Arch-Loss 0.617 (0.617)
**TRAIN** [2020-01-29 08:14:33] [epoch=288/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.817 (0.751)  Prec@1 67.86 (74.30) Prec@5 97.62 (98.22) Acls-loss 0.920 (0.804) FLOP-Loss 0.000 (0.170) Arch-Loss 0.920 (1.145)
 **TRAIN** Prec@1 74.30 Prec@5 98.22 Error@1 25.70 Error@5 1.78 Base-Loss:0.751, Arch-Loss=1.145
***[2020-01-29 08:14:33]*** TRAIN [epoch=288/600] base-loss = 0.751138, arch-loss = 1.144577, accuracy-1 = 74.30, accuracy-5 = 98.22
[epoch=288/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 11, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.271232)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.458 0.194 0.348  ||  0.3013 -0.5603 0.0274  || discrepancy=0.11 || select=0/3
001/003-th : 0.354 0.134 0.512  ||  0.0703 -0.9052 0.4386  || discrepancy=0.16 || select=2/3
002/003-th : 0.012 0.065 0.922  ||  -2.1535 -0.5017 2.1493  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.047 0.066 0.091 0.099 0.136 0.159 0.183 0.219  ||  -0.866 -0.525 -0.208 -0.117 0.193 0.352 0.492 0.672   || dis=0.04 || select=7/8
001/019-th : 0.133 0.129 0.134 0.130 0.122 0.120 0.114 0.118  ||  0.059 0.034 0.072 0.037 -0.026 -0.042 -0.090 -0.055   || dis=0.00 || select=2/8
002/019-th : 0.122 0.130 0.131 0.133 0.126 0.124 0.120 0.115  ||  -0.027 0.039 0.048 0.064 0.007 -0.003 -0.042 -0.086   || dis=0.00 || select=3/8
003/019-th : 0.118 0.125 0.125 0.124 0.125 0.126 0.129 0.128  ||  -0.060 -0.003 0.000 -0.007 -0.002 0.003 0.027 0.019   || dis=0.00 || select=6/8
004/019-th : 0.113 0.116 0.123 0.119 0.134 0.133 0.133 0.128  ||  -0.091 -0.066 -0.012 -0.043 0.075 0.071 0.068 0.030   || dis=0.00 || select=4/8
005/019-th : 0.106 0.117 0.127 0.132 0.125 0.133 0.132 0.128  ||  -0.156 -0.059 0.019 0.057 0.008 0.067 0.056 0.030     || dis=0.00 || select=5/8
006/019-th : 0.119 0.114 0.117 0.123 0.133 0.127 0.130 0.138  ||  -0.044 -0.087 -0.065 -0.014 0.064 0.017 0.039 0.101   || dis=0.01 || select=7/8
007/019-th : 0.055 0.064 0.083 0.102 0.129 0.153 0.183 0.231  ||  -0.709 -0.564 -0.297 -0.097 0.139 0.312 0.486 0.720   || dis=0.05 || select=7/8
008/019-th : 0.039 0.050 0.067 0.105 0.125 0.165 0.225 0.224  ||  -0.979 -0.735 -0.442 -0.004 0.172 0.452 0.762 0.759   || dis=0.00 || select=6/8
009/019-th : 0.089 0.089 0.101 0.118 0.124 0.135 0.160 0.184  ||  -0.305 -0.304 -0.181 -0.027 0.022 0.105 0.277 0.417   || dis=0.02 || select=7/8
010/019-th : 0.100 0.103 0.112 0.119 0.131 0.140 0.144 0.149  ||  -0.211 -0.181 -0.096 -0.036 0.060 0.123 0.153 0.187   || dis=0.01 || select=7/8
011/019-th : 0.101 0.096 0.109 0.116 0.126 0.133 0.155 0.164  ||  -0.196 -0.243 -0.122 -0.053 0.023 0.082 0.231 0.289   || dis=0.01 || select=7/8
012/019-th : 0.106 0.115 0.115 0.120 0.134 0.131 0.137 0.143  ||  -0.161 -0.080 -0.076 -0.031 0.077 0.052 0.095 0.139   || dis=0.01 || select=7/8
013/019-th : 0.022 0.027 0.039 0.055 0.068 0.106 0.233 0.450  ||  -1.234 -1.030 -0.648 -0.316 -0.104 0.342 1.132 1.788  || dis=0.22 || select=7/8
014/019-th : 0.031 0.048 0.056 0.070 0.115 0.165 0.232 0.282  ||  -1.132 -0.698 -0.534 -0.314 0.181 0.544 0.882 1.079   || dis=0.05 || select=7/8
015/019-th : 0.020 0.026 0.036 0.046 0.074 0.112 0.226 0.460  ||  -1.296 -1.033 -0.712 -0.454 0.020 0.440 1.138 1.850   || dis=0.23 || select=7/8
016/019-th : 0.059 0.075 0.102 0.126 0.139 0.153 0.173 0.174  ||  -0.686 -0.447 -0.139 0.075 0.168 0.264 0.387 0.392    || dis=0.00 || select=7/8
017/019-th : 0.116 0.117 0.122 0.125 0.127 0.124 0.133 0.136  ||  -0.071 -0.062 -0.025 -0.000 0.018 -0.008 0.064 0.089  || dis=0.00 || select=7/8
018/019-th : 0.088 0.102 0.125 0.129 0.130 0.130 0.140 0.156  ||  -0.331 -0.189 0.016 0.048 0.055 0.059 0.132 0.240     || dis=0.02 || select=7/8
[epoch=288/600] FLOP : 28.27 MB, ratio : 0.6927, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:14:33] [epoch=288/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.562 (2.562)  Prec@1 28.12 (28.12) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:14:39] [epoch=288/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.150 (2.384)  Prec@1 37.50 (38.97) Prec@5 82.74 (82.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.97 Prec@5 82.66 Error@1 61.03 Error@5 17.34 Loss:2.384
***[2020-01-29 08:14:39]*** VALID [epoch=288/600] loss = 2.383953, accuracy@1 = 38.97, accuracy@5 = 82.66 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:14:40]*** start epoch=289/600 Time Left: [02:45:18], LR=[0.052878 ~ 0.052878], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=289, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.6910318660509405, FLOP=40.81
[Search] : epoch=289/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:14:40] [epoch=289/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.553 (0.553)  Prec@1 80.86 (80.86) Prec@5 98.44 (98.44) Acls-loss 0.687 (0.687) FLOP-Loss 0.000 (0.000) Arch-Loss 0.687 (0.687)
**TRAIN** [2020-01-29 08:15:05] [epoch=289/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.695 (0.746)  Prec@1 75.60 (74.73) Prec@5 98.21 (98.11) Acls-loss 0.707 (0.834) FLOP-Loss 0.000 (0.226) Arch-Loss 0.707 (1.287)
 **TRAIN** Prec@1 74.73 Prec@5 98.11 Error@1 25.27 Error@5 1.89 Base-Loss:0.746, Arch-Loss=1.287
***[2020-01-29 08:15:05]*** TRAIN [epoch=289/600] base-loss = 0.746143, arch-loss = 1.286555, accuracy-1 = 74.73, accuracy-5 = 98.11
[epoch=289/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 4, 9, 8, 12, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.677312)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.468 0.191 0.341  ||  0.3239 -0.5735 0.0072  || discrepancy=0.13 || select=0/3
001/003-th : 0.363 0.133 0.504  ||  0.0924 -0.9095 0.4197  || discrepancy=0.14 || select=2/3
002/003-th : 0.013 0.067 0.920  ||  -2.1503 -0.4794 2.1408  || discrepancy=0.85 || select=2/3
-----------------------------------------------
000/019-th : 0.047 0.067 0.092 0.102 0.139 0.156 0.179 0.218  ||  -0.864 -0.520 -0.195 -0.094 0.213 0.330 0.467 0.662   || dis=0.04 || select=7/8
001/019-th : 0.137 0.134 0.136 0.129 0.120 0.118 0.112 0.115  ||  0.088 0.066 0.085 0.034 -0.044 -0.060 -0.114 -0.081   || dis=0.00 || select=0/8
002/019-th : 0.125 0.133 0.133 0.134 0.124 0.122 0.117 0.112  ||  -0.000 0.066 0.063 0.074 -0.010 -0.020 -0.065 -0.113  || dis=0.00 || select=3/8
003/019-th : 0.120 0.126 0.128 0.125 0.127 0.123 0.127 0.124  ||  -0.039 0.008 0.019 -0.002 0.018 -0.021 0.011 -0.007   || dis=0.00 || select=2/8
004/019-th : 0.116 0.118 0.124 0.119 0.131 0.135 0.131 0.126  ||  -0.070 -0.051 -0.003 -0.045 0.054 0.082 0.054 0.011   || dis=0.00 || select=5/8
005/019-th : 0.109 0.120 0.129 0.131 0.123 0.132 0.130 0.126  ||  -0.134 -0.039 0.036 0.048 -0.016 0.056 0.042 0.015    || dis=0.00 || select=5/8
006/019-th : 0.122 0.116 0.118 0.122 0.131 0.126 0.129 0.135  ||  -0.018 -0.070 -0.054 -0.018 0.052 0.008 0.033 0.078   || dis=0.00 || select=7/8
007/019-th : 0.056 0.064 0.085 0.104 0.131 0.153 0.179 0.228  ||  -0.705 -0.565 -0.283 -0.080 0.150 0.305 0.463 0.706   || dis=0.05 || select=7/8
008/019-th : 0.039 0.052 0.069 0.106 0.126 0.162 0.223 0.223  ||  -0.984 -0.717 -0.421 0.008 0.174 0.430 0.747 0.747    || dis=0.00 || select=7/8
009/019-th : 0.090 0.093 0.102 0.119 0.122 0.135 0.159 0.180  ||  -0.297 -0.269 -0.178 -0.020 0.002 0.106 0.272 0.396   || dis=0.02 || select=7/8
010/019-th : 0.102 0.106 0.112 0.120 0.129 0.139 0.144 0.147  ||  -0.193 -0.157 -0.097 -0.029 0.043 0.118 0.149 0.169   || dis=0.00 || select=7/8
011/019-th : 0.101 0.098 0.112 0.118 0.124 0.132 0.153 0.161  ||  -0.196 -0.229 -0.097 -0.038 0.011 0.075 0.220 0.272   || dis=0.01 || select=7/8
012/019-th : 0.108 0.117 0.117 0.120 0.131 0.130 0.136 0.141  ||  -0.145 -0.058 -0.063 -0.033 0.054 0.044 0.088 0.124   || dis=0.00 || select=7/8
013/019-th : 0.022 0.027 0.041 0.056 0.070 0.108 0.230 0.448  ||  -1.256 -1.032 -0.627 -0.308 -0.078 0.353 1.108 1.775  || dis=0.22 || select=7/8
014/019-th : 0.031 0.048 0.057 0.071 0.116 0.166 0.234 0.277  ||  -1.147 -0.696 -0.514 -0.309 0.192 0.546 0.889 1.060   || dis=0.04 || select=7/8
015/019-th : 0.020 0.025 0.035 0.047 0.073 0.112 0.228 0.459  ||  -1.295 -1.048 -0.715 -0.431 0.013 0.433 1.145 1.847   || dis=0.23 || select=7/8
016/019-th : 0.060 0.077 0.104 0.131 0.140 0.151 0.169 0.168  ||  -0.669 -0.427 -0.122 0.108 0.174 0.252 0.365 0.357    || dis=0.00 || select=6/8
017/019-th : 0.120 0.121 0.124 0.126 0.124 0.121 0.131 0.134  ||  -0.041 -0.035 -0.012 0.011 -0.007 -0.034 0.044 0.066  || dis=0.00 || select=7/8
018/019-th : 0.090 0.104 0.126 0.128 0.133 0.129 0.138 0.152  ||  -0.308 -0.166 0.024 0.039 0.076 0.050 0.113 0.215     || dis=0.01 || select=7/8
[epoch=289/600] FLOP : 27.68 MB, ratio : 0.6781, Expected-ratio : 0.7000, Discrepancy : 0.080
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:15:05] [epoch=289/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.443 (1.443)  Prec@1 47.27 (47.27) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:15:11] [epoch=289/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.963 (2.254)  Prec@1 34.52 (36.14) Prec@5 86.31 (81.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.14 Prec@5 81.08 Error@1 63.86 Error@5 18.92 Loss:2.254
***[2020-01-29 08:15:11]*** VALID [epoch=289/600] loss = 2.253542, accuracy@1 = 36.14, accuracy@5 = 81.08 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:15:11]*** start epoch=290/600 Time Left: [02:44:46], LR=[0.052617 ~ 0.052617], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=290, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.678223092795213, FLOP=40.81
[Search] : epoch=290/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:15:12] [epoch=290/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.777 (0.777)  Prec@1 72.27 (72.27) Prec@5 98.44 (98.44) Acls-loss 0.925 (0.925) FLOP-Loss 0.000 (0.000) Arch-Loss 0.925 (0.925)
**TRAIN** [2020-01-29 08:15:36] [epoch=290/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.884 (0.775)  Prec@1 71.43 (73.58) Prec@5 97.02 (98.11) Acls-loss 0.829 (0.827) FLOP-Loss 0.000 (0.028) Arch-Loss 0.829 (0.884)
 **TRAIN** Prec@1 73.58 Prec@5 98.11 Error@1 26.42 Error@5 1.89 Base-Loss:0.775, Arch-Loss=0.884
***[2020-01-29 08:15:36]*** TRAIN [epoch=290/600] base-loss = 0.775396, arch-loss = 0.883978, accuracy-1 = 73.58, accuracy-5 = 98.11
[epoch=290/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 8, 12, 9, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.138112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.463 0.194 0.343  ||  0.3150 -0.5537 0.0148  || discrepancy=0.12 || select=0/3
001/003-th : 0.361 0.132 0.507  ||  0.0881 -0.9171 0.4266  || discrepancy=0.15 || select=2/3
002/003-th : 0.012 0.065 0.922  ||  -2.1520 -0.4929 2.1520  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.047 0.067 0.092 0.101 0.136 0.156 0.180 0.222  ||  -0.873 -0.519 -0.196 -0.105 0.192 0.330 0.475 0.685   || dis=0.04 || select=7/8
001/019-th : 0.134 0.136 0.134 0.128 0.121 0.119 0.112 0.116  ||  0.066 0.082 0.073 0.021 -0.029 -0.048 -0.112 -0.072   || dis=0.00 || select=1/8
002/019-th : 0.123 0.131 0.133 0.135 0.125 0.122 0.118 0.113  ||  -0.012 0.052 0.064 0.083 0.003 -0.020 -0.059 -0.102   || dis=0.00 || select=3/8
003/019-th : 0.118 0.126 0.130 0.125 0.127 0.121 0.128 0.126  ||  -0.061 0.006 0.039 0.001 0.011 -0.037 0.025 0.005     || dis=0.00 || select=2/8
004/019-th : 0.115 0.117 0.123 0.119 0.133 0.134 0.133 0.126  ||  -0.076 -0.057 -0.011 -0.047 0.071 0.072 0.068 0.012   || dis=0.00 || select=5/8
005/019-th : 0.104 0.120 0.130 0.131 0.127 0.131 0.131 0.127  ||  -0.175 -0.035 0.043 0.056 0.019 0.053 0.051 0.020     || dis=0.00 || select=3/8
006/019-th : 0.121 0.115 0.119 0.123 0.130 0.126 0.131 0.135  ||  -0.028 -0.083 -0.047 -0.011 0.039 0.008 0.047 0.083   || dis=0.00 || select=7/8
007/019-th : 0.056 0.064 0.085 0.104 0.130 0.152 0.180 0.230  ||  -0.693 -0.572 -0.283 -0.081 0.140 0.298 0.466 0.713   || dis=0.05 || select=7/8
008/019-th : 0.039 0.051 0.069 0.105 0.127 0.165 0.220 0.225  ||  -0.993 -0.731 -0.426 -0.002 0.189 0.454 0.741 0.760   || dis=0.01 || select=7/8
009/019-th : 0.089 0.093 0.103 0.119 0.122 0.133 0.159 0.183  ||  -0.316 -0.265 -0.168 -0.024 0.005 0.093 0.268 0.411   || dis=0.02 || select=7/8
010/019-th : 0.103 0.105 0.111 0.119 0.128 0.141 0.145 0.148  ||  -0.188 -0.161 -0.108 -0.039 0.035 0.125 0.156 0.175   || dis=0.00 || select=7/8
011/019-th : 0.101 0.096 0.113 0.118 0.127 0.130 0.153 0.162  ||  -0.194 -0.246 -0.088 -0.039 0.031 0.056 0.222 0.275   || dis=0.01 || select=7/8
012/019-th : 0.107 0.115 0.117 0.122 0.131 0.131 0.137 0.140  ||  -0.149 -0.080 -0.056 -0.016 0.056 0.051 0.100 0.117   || dis=0.00 || select=7/8
013/019-th : 0.021 0.027 0.039 0.054 0.069 0.105 0.228 0.457  ||  -1.249 -1.028 -0.644 -0.323 -0.085 0.342 1.113 1.810  || dis=0.23 || select=7/8
014/019-th : 0.030 0.048 0.056 0.069 0.115 0.167 0.237 0.278  ||  -1.149 -0.694 -0.531 -0.325 0.189 0.558 0.907 1.067   || dis=0.04 || select=7/8
015/019-th : 0.020 0.024 0.035 0.048 0.073 0.109 0.231 0.459  ||  -1.286 -1.087 -0.717 -0.413 0.012 0.419 1.168 1.853   || dis=0.23 || select=7/8
016/019-th : 0.060 0.077 0.103 0.130 0.141 0.152 0.170 0.168  ||  -0.678 -0.424 -0.135 0.104 0.180 0.259 0.370 0.360    || dis=0.00 || select=6/8
017/019-th : 0.118 0.119 0.121 0.127 0.125 0.122 0.134 0.134  ||  -0.057 -0.048 -0.031 0.015 0.003 -0.025 0.070 0.072   || dis=0.00 || select=7/8
018/019-th : 0.089 0.103 0.127 0.128 0.132 0.131 0.138 0.152  ||  -0.317 -0.175 0.033 0.038 0.073 0.063 0.117 0.212     || dis=0.01 || select=7/8
[epoch=290/600] FLOP : 28.14 MB, ratio : 0.6894, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:15:37] [epoch=290/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.890 (1.890)  Prec@1 38.67 (38.67) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:15:43] [epoch=290/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.556 (2.427)  Prec@1 57.14 (38.34) Prec@5 84.52 (82.12) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.34 Prec@5 82.12 Error@1 61.66 Error@5 17.88 Loss:2.427
***[2020-01-29 08:15:43]*** VALID [epoch=290/600] loss = 2.426990, accuracy@1 = 38.34, accuracy@5 = 82.12 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:15:43]*** start epoch=291/600 Time Left: [02:44:14], LR=[0.052355 ~ 0.052355], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=291, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.6654108042386246, FLOP=40.81
[Search] : epoch=291/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:15:44] [epoch=291/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.829 (0.829)  Prec@1 68.36 (68.36) Prec@5 98.05 (98.05) Acls-loss 0.860 (0.860) FLOP-Loss 0.000 (0.000) Arch-Loss 0.860 (0.860)
**TRAIN** [2020-01-29 08:16:09] [epoch=291/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.841 (0.788)  Prec@1 74.40 (72.93) Prec@5 98.21 (97.84) Acls-loss 0.830 (0.819) FLOP-Loss 0.000 (0.141) Arch-Loss 0.830 (1.102)
 **TRAIN** Prec@1 72.93 Prec@5 97.84 Error@1 27.07 Error@5 2.16 Base-Loss:0.788, Arch-Loss=1.102
***[2020-01-29 08:16:09]*** TRAIN [epoch=291/600] base-loss = 0.788488, arch-loss = 1.101981, accuracy-1 = 72.93, accuracy-5 = 97.84
[epoch=291/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 8, 14, 14, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 57, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.65024)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.470 0.191 0.339  ||  0.3296 -0.5683 0.0030  || discrepancy=0.13 || select=0/3
001/003-th : 0.366 0.133 0.501  ||  0.1008 -0.9079 0.4148  || discrepancy=0.14 || select=2/3
002/003-th : 0.013 0.067 0.920  ||  -2.1424 -0.4794 2.1426  || discrepancy=0.85 || select=2/3
-----------------------------------------------
000/019-th : 0.045 0.066 0.092 0.102 0.135 0.159 0.181 0.219  ||  -0.902 -0.521 -0.188 -0.093 0.194 0.355 0.482 0.677   || dis=0.04 || select=7/8
001/019-th : 0.132 0.136 0.135 0.128 0.124 0.120 0.111 0.114  ||  0.060 0.085 0.082 0.031 -0.007 -0.039 -0.113 -0.086   || dis=0.00 || select=1/8
002/019-th : 0.124 0.130 0.134 0.137 0.125 0.122 0.116 0.112  ||  -0.001 0.047 0.074 0.098 0.005 -0.023 -0.073 -0.108   || dis=0.00 || select=3/8
003/019-th : 0.117 0.127 0.131 0.125 0.126 0.121 0.128 0.125  ||  -0.065 0.016 0.043 0.003 0.010 -0.032 0.024 -0.003    || dis=0.00 || select=2/8
004/019-th : 0.117 0.118 0.123 0.120 0.132 0.132 0.134 0.125  ||  -0.063 -0.053 -0.015 -0.037 0.061 0.058 0.072 0.003   || dis=0.00 || select=6/8
005/019-th : 0.104 0.119 0.131 0.130 0.127 0.130 0.132 0.127  ||  -0.181 -0.041 0.054 0.049 0.023 0.043 0.064 0.020     || dis=0.00 || select=6/8
006/019-th : 0.122 0.116 0.120 0.123 0.128 0.125 0.132 0.134  ||  -0.026 -0.076 -0.042 -0.011 0.029 0.001 0.060 0.072   || dis=0.00 || select=7/8
007/019-th : 0.055 0.064 0.086 0.103 0.129 0.151 0.181 0.231  ||  -0.718 -0.570 -0.271 -0.086 0.140 0.296 0.478 0.723   || dis=0.05 || select=7/8
008/019-th : 0.038 0.050 0.069 0.103 0.126 0.167 0.222 0.224  ||  -1.008 -0.735 -0.418 -0.013 0.190 0.468 0.753 0.761   || dis=0.00 || select=7/8
009/019-th : 0.089 0.095 0.104 0.117 0.122 0.134 0.157 0.181  ||  -0.311 -0.249 -0.156 -0.036 0.002 0.100 0.257 0.399   || dis=0.02 || select=7/8
010/019-th : 0.104 0.106 0.111 0.119 0.130 0.140 0.143 0.146  ||  -0.173 -0.157 -0.110 -0.038 0.049 0.125 0.142 0.164   || dis=0.00 || select=7/8
011/019-th : 0.103 0.098 0.112 0.119 0.126 0.130 0.152 0.160  ||  -0.182 -0.227 -0.091 -0.034 0.024 0.052 0.210 0.263   || dis=0.01 || select=7/8
012/019-th : 0.108 0.115 0.119 0.124 0.131 0.131 0.135 0.137  ||  -0.138 -0.076 -0.045 -0.002 0.055 0.057 0.088 0.098   || dis=0.00 || select=7/8
013/019-th : 0.021 0.027 0.039 0.054 0.069 0.104 0.226 0.461  ||  -1.265 -1.012 -0.637 -0.324 -0.080 0.329 1.107 1.821  || dis=0.24 || select=7/8
014/019-th : 0.031 0.048 0.057 0.069 0.116 0.166 0.234 0.279  ||  -1.135 -0.696 -0.523 -0.331 0.189 0.551 0.892 1.068   || dis=0.05 || select=7/8
015/019-th : 0.020 0.024 0.036 0.047 0.073 0.112 0.232 0.457  ||  -1.277 -1.097 -0.709 -0.417 0.006 0.436 1.168 1.847   || dis=0.23 || select=7/8
016/019-th : 0.060 0.077 0.104 0.132 0.140 0.155 0.167 0.165  ||  -0.667 -0.419 -0.123 0.115 0.178 0.276 0.353 0.338    || dis=0.00 || select=6/8
017/019-th : 0.118 0.122 0.122 0.130 0.124 0.121 0.132 0.132  ||  -0.055 -0.025 -0.025 0.037 -0.008 -0.031 0.057 0.056  || dis=0.00 || select=6/8
018/019-th : 0.090 0.104 0.127 0.130 0.132 0.130 0.136 0.151  ||  -0.307 -0.171 0.033 0.060 0.070 0.055 0.102 0.207     || dis=0.01 || select=7/8
[epoch=291/600] FLOP : 27.65 MB, ratio : 0.6775, Expected-ratio : 0.7000, Discrepancy : 0.081
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:16:09] [epoch=291/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.272 (2.272)  Prec@1 39.06 (39.06) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:16:15] [epoch=291/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.831 (2.220)  Prec@1 39.29 (35.98) Prec@5 80.95 (81.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.98 Prec@5 81.08 Error@1 64.02 Error@5 18.92 Loss:2.220
***[2020-01-29 08:16:15]*** VALID [epoch=291/600] loss = 2.220497, accuracy@1 = 35.98, accuracy@5 = 81.08 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:16:15]*** start epoch=292/600 Time Left: [02:43:42], LR=[0.052094 ~ 0.052094], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=292, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.6525953516365393, FLOP=40.81
[Search] : epoch=292/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:16:16] [epoch=292/600][000/098] Time 0.76 (0.76) Data 0.35 (0.35) Base-Loss 0.618 (0.618)  Prec@1 78.91 (78.91) Prec@5 99.22 (99.22) Acls-loss 0.886 (0.886) FLOP-Loss 0.000 (0.000) Arch-Loss 0.886 (0.886)
**TRAIN** [2020-01-29 08:16:42] [epoch=292/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 1.043 (0.781)  Prec@1 64.29 (73.35) Prec@5 96.43 (98.03) Acls-loss 0.997 (0.822) FLOP-Loss 0.000 (0.000) Arch-Loss 0.997 (0.822)
 **TRAIN** Prec@1 73.35 Prec@5 98.03 Error@1 26.65 Error@5 1.97 Base-Loss:0.781, Arch-Loss=0.822
***[2020-01-29 08:16:42]*** TRAIN [epoch=292/600] base-loss = 0.780808, arch-loss = 0.822163, accuracy-1 = 73.35, accuracy-5 = 98.03
[epoch=292/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 14, 14, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.294336)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.461 0.195 0.344  ||  0.3115 -0.5491 0.0202  || discrepancy=0.12 || select=0/3
001/003-th : 0.362 0.132 0.506  ||  0.0926 -0.9184 0.4257  || discrepancy=0.14 || select=2/3
002/003-th : 0.012 0.065 0.922  ||  -2.1500 -0.4923 2.1578  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.045 0.066 0.092 0.100 0.135 0.159 0.181 0.222  ||  -0.901 -0.521 -0.197 -0.106 0.190 0.353 0.486 0.692   || dis=0.04 || select=7/8
001/019-th : 0.131 0.133 0.133 0.128 0.125 0.122 0.113 0.115  ||  0.051 0.068 0.063 0.026 0.008 -0.021 -0.100 -0.076    || dis=0.00 || select=1/8
002/019-th : 0.122 0.129 0.133 0.137 0.128 0.124 0.116 0.112  ||  -0.021 0.036 0.068 0.095 0.030 -0.000 -0.067 -0.102   || dis=0.00 || select=3/8
003/019-th : 0.114 0.126 0.131 0.124 0.126 0.122 0.131 0.126  ||  -0.089 0.012 0.045 -0.009 0.012 -0.026 0.045 0.009    || dis=0.00 || select=6/8
004/019-th : 0.115 0.117 0.122 0.119 0.133 0.133 0.135 0.126  ||  -0.075 -0.064 -0.019 -0.042 0.063 0.066 0.083 0.010   || dis=0.00 || select=6/8
005/019-th : 0.103 0.118 0.131 0.129 0.128 0.129 0.133 0.128  ||  -0.184 -0.050 0.053 0.035 0.029 0.042 0.071 0.031     || dis=0.00 || select=6/8
006/019-th : 0.121 0.115 0.119 0.121 0.129 0.124 0.134 0.137  ||  -0.035 -0.082 -0.051 -0.029 0.036 -0.006 0.071 0.089  || dis=0.00 || select=7/8
007/019-th : 0.054 0.062 0.084 0.102 0.129 0.150 0.183 0.234  ||  -0.722 -0.585 -0.282 -0.092 0.145 0.294 0.493 0.740   || dis=0.05 || select=7/8
008/019-th : 0.038 0.050 0.068 0.104 0.126 0.168 0.223 0.223  ||  -1.011 -0.744 -0.424 -0.003 0.191 0.476 0.759 0.758   || dis=0.00 || select=6/8
009/019-th : 0.086 0.094 0.103 0.116 0.123 0.135 0.160 0.184  ||  -0.345 -0.259 -0.167 -0.039 0.016 0.109 0.275 0.417   || dis=0.02 || select=7/8
010/019-th : 0.103 0.104 0.109 0.119 0.129 0.145 0.142 0.148  ||  -0.184 -0.176 -0.125 -0.040 0.045 0.161 0.141 0.178   || dis=0.00 || select=7/8
011/019-th : 0.102 0.096 0.110 0.119 0.126 0.130 0.153 0.164  ||  -0.189 -0.243 -0.109 -0.032 0.021 0.059 0.220 0.288   || dis=0.01 || select=7/8
012/019-th : 0.108 0.114 0.118 0.123 0.132 0.132 0.136 0.138  ||  -0.141 -0.081 -0.051 -0.010 0.064 0.059 0.090 0.103   || dis=0.00 || select=7/8
013/019-th : 0.021 0.027 0.039 0.053 0.068 0.102 0.222 0.469  ||  -1.253 -1.021 -0.647 -0.339 -0.080 0.321 1.103 1.851  || dis=0.25 || select=7/8
014/019-th : 0.031 0.046 0.057 0.069 0.114 0.164 0.237 0.282  ||  -1.132 -0.722 -0.523 -0.320 0.177 0.538 0.907 1.084   || dis=0.04 || select=7/8
015/019-th : 0.019 0.023 0.035 0.047 0.072 0.109 0.233 0.462  ||  -1.310 -1.115 -0.717 -0.414 0.019 0.430 1.188 1.872   || dis=0.23 || select=7/8
016/019-th : 0.059 0.076 0.103 0.131 0.138 0.157 0.167 0.168  ||  -0.683 -0.431 -0.126 0.111 0.165 0.290 0.351 0.361    || dis=0.00 || select=7/8
017/019-th : 0.116 0.120 0.120 0.130 0.125 0.124 0.133 0.132  ||  -0.069 -0.039 -0.034 0.042 0.001 -0.002 0.064 0.059   || dis=0.00 || select=6/8
018/019-th : 0.090 0.101 0.124 0.131 0.133 0.131 0.139 0.152  ||  -0.314 -0.198 0.009 0.064 0.083 0.061 0.121 0.216     || dis=0.01 || select=7/8
[epoch=292/600] FLOP : 27.29 MB, ratio : 0.6688, Expected-ratio : 0.7000, Discrepancy : 0.082
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:16:43] [epoch=292/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 3.217 (3.217)  Prec@1 16.80 (16.80) Prec@5 56.25 (56.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:16:49] [epoch=292/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.435 (2.365)  Prec@1 38.10 (39.76) Prec@5 79.17 (82.83) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.76 Prec@5 82.83 Error@1 60.24 Error@5 17.17 Loss:2.365
***[2020-01-29 08:16:49]*** VALID [epoch=292/600] loss = 2.364992, accuracy@1 = 39.76, accuracy@5 = 82.83 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:16:49]*** start epoch=293/600 Time Left: [02:43:13], LR=[0.051832 ~ 0.051832], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=293, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.6397770863310632, FLOP=40.81
[Search] : epoch=293/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:16:50] [epoch=293/600][000/098] Time 0.65 (0.65) Data 0.38 (0.38) Base-Loss 0.936 (0.936)  Prec@1 66.80 (66.80) Prec@5 96.88 (96.88) Acls-loss 0.752 (0.752) FLOP-Loss 0.000 (0.000) Arch-Loss 0.752 (0.752)
**TRAIN** [2020-01-29 08:17:14] [epoch=293/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.566 (0.766)  Prec@1 78.57 (74.16) Prec@5 98.21 (97.95) Acls-loss 0.627 (0.829) FLOP-Loss 0.000 (0.000) Arch-Loss 0.627 (0.829)
 **TRAIN** Prec@1 74.16 Prec@5 97.95 Error@1 25.84 Error@5 2.05 Base-Loss:0.766, Arch-Loss=0.829
***[2020-01-29 08:17:14]*** TRAIN [epoch=293/600] base-loss = 0.766166, arch-loss = 0.829121, accuracy-1 = 74.16, accuracy-5 = 97.95
[epoch=293/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 14, 14, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 57, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.76128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.453 0.195 0.352  ||  0.2923 -0.5508 0.0414  || discrepancy=0.10 || select=0/3
001/003-th : 0.357 0.131 0.513  ||  0.0791 -0.9253 0.4414  || discrepancy=0.16 || select=2/3
002/003-th : 0.012 0.063 0.925  ||  -2.1619 -0.5128 2.1798  || discrepancy=0.86 || select=2/3
-----------------------------------------------
000/019-th : 0.045 0.065 0.091 0.100 0.134 0.159 0.180 0.226  ||  -0.902 -0.532 -0.203 -0.109 0.187 0.357 0.485 0.710   || dis=0.05 || select=7/8
001/019-th : 0.128 0.132 0.132 0.127 0.127 0.122 0.115 0.117  ||  0.031 0.061 0.058 0.022 0.020 -0.023 -0.076 -0.065    || dis=0.00 || select=1/8
002/019-th : 0.119 0.128 0.133 0.137 0.130 0.124 0.118 0.113  ||  -0.040 0.028 0.067 0.097 0.045 -0.003 -0.053 -0.093   || dis=0.00 || select=3/8
003/019-th : 0.112 0.124 0.131 0.123 0.129 0.122 0.131 0.128  ||  -0.104 -0.006 0.047 -0.014 0.030 -0.020 0.048 0.025   || dis=0.00 || select=6/8
004/019-th : 0.114 0.115 0.121 0.120 0.129 0.135 0.138 0.128  ||  -0.091 -0.082 -0.025 -0.038 0.037 0.077 0.104 0.028   || dis=0.00 || select=6/8
005/019-th : 0.102 0.118 0.131 0.128 0.129 0.129 0.133 0.130  ||  -0.199 -0.054 0.056 0.029 0.039 0.040 0.071 0.048     || dis=0.00 || select=6/8
006/019-th : 0.118 0.114 0.118 0.120 0.130 0.125 0.136 0.139  ||  -0.056 -0.088 -0.055 -0.043 0.039 0.002 0.085 0.106   || dis=0.00 || select=7/8
007/019-th : 0.053 0.061 0.083 0.102 0.128 0.152 0.183 0.237  ||  -0.736 -0.595 -0.290 -0.086 0.138 0.313 0.497 0.755   || dis=0.05 || select=7/8
008/019-th : 0.038 0.049 0.067 0.103 0.127 0.170 0.223 0.223  ||  -1.012 -0.746 -0.439 -0.007 0.198 0.488 0.762 0.761   || dis=0.00 || select=6/8
009/019-th : 0.085 0.093 0.102 0.114 0.123 0.136 0.161 0.185  ||  -0.353 -0.263 -0.171 -0.056 0.020 0.115 0.285 0.427   || dis=0.02 || select=7/8
010/019-th : 0.101 0.103 0.110 0.118 0.129 0.145 0.143 0.150  ||  -0.199 -0.186 -0.114 -0.046 0.039 0.162 0.143 0.194   || dis=0.01 || select=7/8
011/019-th : 0.100 0.096 0.110 0.118 0.125 0.130 0.155 0.166  ||  -0.205 -0.249 -0.110 -0.042 0.021 0.060 0.233 0.301   || dis=0.01 || select=7/8
012/019-th : 0.107 0.113 0.117 0.123 0.131 0.132 0.137 0.140  ||  -0.145 -0.096 -0.063 -0.013 0.052 0.061 0.101 0.121   || dis=0.00 || select=7/8
013/019-th : 0.021 0.027 0.037 0.051 0.068 0.100 0.222 0.474  ||  -1.249 -1.007 -0.675 -0.355 -0.069 0.310 1.112 1.871  || dis=0.25 || select=7/8
014/019-th : 0.031 0.046 0.056 0.068 0.113 0.162 0.238 0.287  ||  -1.129 -0.727 -0.533 -0.329 0.172 0.530 0.915 1.103   || dis=0.05 || select=7/8
015/019-th : 0.018 0.023 0.035 0.047 0.072 0.108 0.228 0.470  ||  -1.382 -1.116 -0.692 -0.409 0.024 0.435 1.178 1.903   || dis=0.24 || select=7/8
016/019-th : 0.058 0.076 0.101 0.127 0.140 0.160 0.170 0.170  ||  -0.706 -0.437 -0.150 0.083 0.179 0.312 0.375 0.373    || dis=0.00 || select=6/8
017/019-th : 0.115 0.119 0.119 0.128 0.125 0.126 0.134 0.135  ||  -0.078 -0.047 -0.049 0.023 0.005 0.010 0.073 0.077    || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.123 0.131 0.132 0.132 0.140 0.155  ||  -0.332 -0.208 -0.001 0.063 0.069 0.070 0.133 0.235    || dis=0.01 || select=7/8
[epoch=293/600] FLOP : 27.76 MB, ratio : 0.6802, Expected-ratio : 0.7000, Discrepancy : 0.083
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:17:15] [epoch=293/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.142 (2.142)  Prec@1 33.59 (33.59) Prec@5 77.34 (77.34) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:17:21] [epoch=293/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.871 (2.384)  Prec@1 30.95 (33.29) Prec@5 74.40 (79.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.29 Prec@5 79.42 Error@1 66.71 Error@5 20.58 Loss:2.384
***[2020-01-29 08:17:21]*** VALID [epoch=293/600] loss = 2.383636, accuracy@1 = 33.29, accuracy@5 = 79.42 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:17:21]*** start epoch=294/600 Time Left: [02:42:41], LR=[0.051571 ~ 0.051571], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=294, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.6269563597414147, FLOP=40.81
[Search] : epoch=294/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:17:22] [epoch=294/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.783 (0.783)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.812 (0.812) FLOP-Loss 0.000 (0.000) Arch-Loss 0.812 (0.812)
**TRAIN** [2020-01-29 08:17:46] [epoch=294/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.811 (0.791)  Prec@1 75.60 (73.02) Prec@5 98.21 (97.93) Acls-loss 0.878 (0.823) FLOP-Loss 0.000 (0.028) Arch-Loss 0.878 (0.880)
 **TRAIN** Prec@1 73.02 Prec@5 97.93 Error@1 26.98 Error@5 2.07 Base-Loss:0.791, Arch-Loss=0.880
***[2020-01-29 08:17:46]*** TRAIN [epoch=294/600] base-loss = 0.791276, arch-loss = 0.880044, accuracy-1 = 73.02, accuracy-5 = 97.93
[epoch=294/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 14, 14, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.810432)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.194 0.356  ||  0.2846 -0.5583 0.0517  || discrepancy=0.09 || select=0/3
001/003-th : 0.355 0.128 0.517  ||  0.0747 -0.9422 0.4500  || discrepancy=0.16 || select=2/3
002/003-th : 0.012 0.061 0.927  ||  -2.1644 -0.5234 2.1904  || discrepancy=0.87 || select=2/3
-----------------------------------------------
000/019-th : 0.046 0.065 0.091 0.099 0.132 0.155 0.184 0.229  ||  -0.886 -0.540 -0.199 -0.120 0.173 0.332 0.502 0.720   || dis=0.05 || select=7/8
001/019-th : 0.128 0.132 0.131 0.127 0.127 0.122 0.115 0.118  ||  0.030 0.055 0.049 0.017 0.023 -0.019 -0.076 -0.057    || dis=0.00 || select=1/8
002/019-th : 0.118 0.126 0.131 0.136 0.130 0.125 0.119 0.114  ||  -0.049 0.019 0.056 0.094 0.044 0.009 -0.039 -0.087    || dis=0.01 || select=3/8
003/019-th : 0.111 0.122 0.129 0.123 0.130 0.125 0.131 0.129  ||  -0.115 -0.021 0.032 -0.010 0.039 0.004 0.047 0.037    || dis=0.00 || select=6/8
004/019-th : 0.113 0.114 0.120 0.119 0.132 0.134 0.138 0.129  ||  -0.094 -0.088 -0.034 -0.045 0.058 0.076 0.099 0.037   || dis=0.00 || select=6/8
005/019-th : 0.102 0.117 0.129 0.126 0.129 0.131 0.133 0.132  ||  -0.194 -0.061 0.040 0.014 0.039 0.053 0.069 0.060     || dis=0.00 || select=6/8
006/019-th : 0.117 0.114 0.116 0.118 0.133 0.127 0.136 0.139  ||  -0.067 -0.090 -0.075 -0.051 0.063 0.017 0.088 0.110   || dis=0.00 || select=7/8
007/019-th : 0.051 0.061 0.083 0.102 0.128 0.151 0.187 0.237  ||  -0.766 -0.596 -0.292 -0.083 0.144 0.314 0.525 0.762   || dis=0.05 || select=7/8
008/019-th : 0.038 0.049 0.066 0.106 0.127 0.170 0.223 0.221  ||  -1.006 -0.748 -0.457 0.019 0.201 0.487 0.759 0.751    || dis=0.00 || select=6/8
009/019-th : 0.085 0.092 0.102 0.113 0.123 0.138 0.161 0.185  ||  -0.352 -0.274 -0.168 -0.065 0.015 0.131 0.289 0.428   || dis=0.02 || select=7/8
010/019-th : 0.100 0.104 0.109 0.119 0.127 0.146 0.145 0.150  ||  -0.216 -0.176 -0.123 -0.035 0.027 0.164 0.157 0.194   || dis=0.00 || select=7/8
011/019-th : 0.101 0.096 0.108 0.118 0.126 0.130 0.156 0.165  ||  -0.199 -0.242 -0.124 -0.039 0.027 0.055 0.240 0.295   || dis=0.01 || select=7/8
012/019-th : 0.108 0.111 0.117 0.123 0.132 0.132 0.137 0.141  ||  -0.142 -0.111 -0.062 -0.012 0.059 0.058 0.095 0.129   || dis=0.00 || select=7/8
013/019-th : 0.021 0.027 0.037 0.050 0.068 0.100 0.219 0.478  ||  -1.246 -1.004 -0.671 -0.375 -0.064 0.316 1.103 1.882  || dis=0.26 || select=7/8
014/019-th : 0.030 0.046 0.056 0.067 0.113 0.164 0.235 0.289  ||  -1.140 -0.728 -0.532 -0.342 0.174 0.546 0.910 1.114   || dis=0.05 || select=7/8
015/019-th : 0.017 0.023 0.035 0.047 0.072 0.109 0.228 0.470  ||  -1.418 -1.122 -0.680 -0.403 0.031 0.446 1.184 1.907   || dis=0.24 || select=7/8
016/019-th : 0.057 0.075 0.100 0.125 0.142 0.159 0.171 0.172  ||  -0.724 -0.448 -0.155 0.071 0.194 0.312 0.381 0.392    || dis=0.00 || select=7/8
017/019-th : 0.114 0.119 0.119 0.126 0.127 0.127 0.134 0.135  ||  -0.092 -0.049 -0.043 0.013 0.017 0.016 0.076 0.080    || dis=0.00 || select=7/8
018/019-th : 0.088 0.100 0.123 0.127 0.130 0.134 0.140 0.159  ||  -0.333 -0.209 -0.003 0.031 0.057 0.086 0.130 0.255    || dis=0.02 || select=7/8
[epoch=294/600] FLOP : 27.81 MB, ratio : 0.6814, Expected-ratio : 0.7000, Discrepancy : 0.084
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:17:46] [epoch=294/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.305 (2.305)  Prec@1 48.44 (48.44) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:17:52] [epoch=294/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.435 (2.712)  Prec@1 42.86 (34.20) Prec@5 78.57 (80.27) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.20 Prec@5 80.27 Error@1 65.80 Error@5 19.73 Loss:2.712
***[2020-01-29 08:17:52]*** VALID [epoch=294/600] loss = 2.711747, accuracy@1 = 34.20, accuracy@5 = 80.27 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:17:52]*** start epoch=295/600 Time Left: [02:42:08], LR=[0.051309 ~ 0.051309], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=295, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.61413352335429, FLOP=40.81
[Search] : epoch=295/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:17:53] [epoch=295/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.824 (0.824)  Prec@1 69.92 (69.92) Prec@5 98.83 (98.83) Acls-loss 0.816 (0.816) FLOP-Loss 0.000 (0.000) Arch-Loss 0.816 (0.816)
**TRAIN** [2020-01-29 08:18:17] [epoch=295/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.849 (0.809)  Prec@1 66.67 (72.22) Prec@5 98.21 (97.90) Acls-loss 0.743 (0.814) FLOP-Loss 0.000 (0.057) Arch-Loss 0.743 (0.928)
 **TRAIN** Prec@1 72.22 Prec@5 97.90 Error@1 27.78 Error@5 2.10 Base-Loss:0.809, Arch-Loss=0.928
***[2020-01-29 08:18:17]*** TRAIN [epoch=295/600] base-loss = 0.809332, arch-loss = 0.927585, accuracy-1 = 72.22, accuracy-5 = 97.90
[epoch=295/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 14, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.271232)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.448 0.194 0.358  ||  0.2810 -0.5576 0.0566  || discrepancy=0.09 || select=0/3
001/003-th : 0.352 0.128 0.519  ||  0.0694 -0.9420 0.4570  || discrepancy=0.17 || select=2/3
002/003-th : 0.012 0.061 0.928  ||  -2.1640 -0.5315 2.1976  || discrepancy=0.87 || select=2/3
-----------------------------------------------
000/019-th : 0.044 0.065 0.090 0.098 0.136 0.157 0.183 0.227  ||  -0.929 -0.528 -0.207 -0.118 0.209 0.351 0.503 0.719   || dis=0.04 || select=7/8
001/019-th : 0.128 0.131 0.131 0.127 0.128 0.121 0.116 0.118  ||  0.026 0.052 0.054 0.020 0.032 -0.029 -0.074 -0.053    || dis=0.00 || select=2/8
002/019-th : 0.118 0.127 0.132 0.135 0.128 0.126 0.120 0.114  ||  -0.053 0.019 0.064 0.082 0.031 0.016 -0.038 -0.084    || dis=0.00 || select=3/8
003/019-th : 0.111 0.121 0.129 0.121 0.131 0.125 0.131 0.130  ||  -0.117 -0.028 0.035 -0.029 0.052 -0.000 0.053 0.044   || dis=0.00 || select=6/8
004/019-th : 0.114 0.115 0.118 0.119 0.131 0.134 0.138 0.130  ||  -0.091 -0.083 -0.052 -0.044 0.053 0.074 0.102 0.043   || dis=0.00 || select=6/8
005/019-th : 0.103 0.118 0.128 0.126 0.128 0.131 0.133 0.132  ||  -0.189 -0.055 0.031 0.012 0.032 0.054 0.064 0.062     || dis=0.00 || select=6/8
006/019-th : 0.117 0.114 0.115 0.118 0.132 0.127 0.137 0.140  ||  -0.067 -0.090 -0.083 -0.060 0.058 0.018 0.093 0.118   || dis=0.00 || select=7/8
007/019-th : 0.051 0.061 0.082 0.102 0.127 0.153 0.189 0.235  ||  -0.774 -0.594 -0.294 -0.080 0.140 0.324 0.535 0.756   || dis=0.05 || select=7/8
008/019-th : 0.038 0.049 0.066 0.106 0.124 0.171 0.223 0.222  ||  -1.010 -0.746 -0.454 0.019 0.179 0.494 0.763 0.759    || dis=0.00 || select=6/8
009/019-th : 0.084 0.090 0.102 0.113 0.123 0.139 0.163 0.185  ||  -0.358 -0.291 -0.164 -0.065 0.017 0.144 0.299 0.426   || dis=0.02 || select=7/8
010/019-th : 0.099 0.104 0.110 0.119 0.128 0.146 0.145 0.150  ||  -0.226 -0.169 -0.121 -0.039 0.033 0.166 0.160 0.191   || dis=0.00 || select=7/8
011/019-th : 0.100 0.097 0.108 0.116 0.125 0.129 0.158 0.166  ||  -0.203 -0.238 -0.129 -0.054 0.020 0.052 0.253 0.304   || dis=0.01 || select=7/8
012/019-th : 0.107 0.110 0.116 0.124 0.131 0.133 0.137 0.142  ||  -0.153 -0.118 -0.065 -0.001 0.050 0.069 0.097 0.135   || dis=0.00 || select=7/8
013/019-th : 0.020 0.027 0.037 0.050 0.069 0.101 0.222 0.474  ||  -1.274 -1.000 -0.668 -0.375 -0.056 0.328 1.112 1.872  || dis=0.25 || select=7/8
014/019-th : 0.030 0.045 0.056 0.068 0.112 0.163 0.236 0.290  ||  -1.144 -0.746 -0.518 -0.332 0.168 0.543 0.912 1.118   || dis=0.05 || select=7/8
015/019-th : 0.017 0.023 0.035 0.047 0.070 0.111 0.229 0.469  ||  -1.423 -1.127 -0.676 -0.401 0.007 0.468 1.190 1.910   || dis=0.24 || select=7/8
016/019-th : 0.057 0.075 0.100 0.125 0.140 0.161 0.169 0.173  ||  -0.717 -0.442 -0.159 0.072 0.180 0.321 0.371 0.394    || dis=0.00 || select=7/8
017/019-th : 0.115 0.117 0.120 0.125 0.127 0.128 0.134 0.135  ||  -0.083 -0.059 -0.039 0.001 0.021 0.028 0.071 0.078    || dis=0.00 || select=7/8
018/019-th : 0.089 0.100 0.123 0.126 0.131 0.131 0.141 0.158  ||  -0.324 -0.212 0.004 0.025 0.066 0.065 0.134 0.253     || dis=0.02 || select=7/8
[epoch=295/600] FLOP : 28.27 MB, ratio : 0.6927, Expected-ratio : 0.7000, Discrepancy : 0.083
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:18:18] [epoch=295/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.073 (2.073)  Prec@1 26.95 (26.95) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:18:24] [epoch=295/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.227 (2.041)  Prec@1 29.17 (38.90) Prec@5 75.00 (82.85) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.90 Prec@5 82.85 Error@1 61.10 Error@5 17.15 Loss:2.041
***[2020-01-29 08:18:24]*** VALID [epoch=295/600] loss = 2.041390, accuracy@1 = 38.90, accuracy@5 = 82.85 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:18:25]*** start epoch=296/600 Time Left: [02:41:37], LR=[0.051047 ~ 0.051047], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=296, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.601308928714225, FLOP=40.81
[Search] : epoch=296/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:18:25] [epoch=296/600][000/098] Time 0.68 (0.68) Data 0.39 (0.39) Base-Loss 0.774 (0.774)  Prec@1 76.95 (76.95) Prec@5 98.05 (98.05) Acls-loss 0.882 (0.882) FLOP-Loss 0.000 (0.000) Arch-Loss 0.882 (0.882)
**TRAIN** [2020-01-29 08:18:50] [epoch=296/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.753 (0.788)  Prec@1 71.43 (72.85) Prec@5 99.40 (97.92) Acls-loss 0.767 (0.828) FLOP-Loss 0.000 (0.085) Arch-Loss 0.767 (0.999)
 **TRAIN** Prec@1 72.85 Prec@5 97.92 Error@1 27.15 Error@5 2.08 Base-Loss:0.788, Arch-Loss=0.999
***[2020-01-29 08:18:51]*** TRAIN [epoch=296/600] base-loss = 0.788218, arch-loss = 0.999383, accuracy-1 = 72.85, accuracy-5 = 97.92
[epoch=296/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 14, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.18112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.191 0.359  ||  0.2838 -0.5732 0.0575  || discrepancy=0.09 || select=0/3
001/003-th : 0.354 0.127 0.519  ||  0.0735 -0.9521 0.4567  || discrepancy=0.17 || select=2/3
002/003-th : 0.011 0.058 0.931  ||  -2.2013 -0.5472 2.2377  || discrepancy=0.87 || select=2/3
-----------------------------------------------
000/019-th : 0.044 0.066 0.089 0.097 0.136 0.157 0.186 0.225  ||  -0.924 -0.516 -0.213 -0.127 0.204 0.348 0.518 0.712   || dis=0.04 || select=7/8
001/019-th : 0.128 0.130 0.131 0.124 0.131 0.122 0.116 0.117  ||  0.027 0.046 0.053 -0.000 0.051 -0.016 -0.068 -0.061   || dis=0.00 || select=2/8
002/019-th : 0.119 0.128 0.133 0.132 0.127 0.126 0.120 0.115  ||  -0.047 0.026 0.066 0.059 0.019 0.009 -0.036 -0.083    || dis=0.00 || select=2/8
003/019-th : 0.111 0.122 0.130 0.121 0.131 0.125 0.132 0.129  ||  -0.112 -0.022 0.038 -0.031 0.045 -0.001 0.054 0.037   || dis=0.00 || select=6/8
004/019-th : 0.113 0.114 0.117 0.119 0.131 0.135 0.139 0.131  ||  -0.095 -0.087 -0.063 -0.050 0.051 0.077 0.108 0.052   || dis=0.00 || select=6/8
005/019-th : 0.104 0.118 0.128 0.125 0.128 0.133 0.133 0.131  ||  -0.183 -0.053 0.028 0.004 0.029 0.065 0.066 0.053     || dis=0.00 || select=6/8
006/019-th : 0.116 0.114 0.115 0.117 0.132 0.126 0.138 0.142  ||  -0.076 -0.087 -0.084 -0.061 0.056 0.009 0.097 0.129   || dis=0.00 || select=7/8
007/019-th : 0.051 0.058 0.082 0.105 0.126 0.155 0.189 0.235  ||  -0.773 -0.643 -0.289 -0.051 0.134 0.342 0.541 0.758   || dis=0.05 || select=7/8
008/019-th : 0.038 0.049 0.066 0.107 0.124 0.170 0.226 0.220  ||  -1.016 -0.749 -0.451 0.026 0.177 0.495 0.776 0.749    || dis=0.01 || select=6/8
009/019-th : 0.084 0.089 0.103 0.115 0.122 0.140 0.163 0.184  ||  -0.362 -0.303 -0.163 -0.049 0.012 0.150 0.300 0.425   || dis=0.02 || select=7/8
010/019-th : 0.098 0.106 0.109 0.121 0.127 0.144 0.144 0.151  ||  -0.236 -0.156 -0.128 -0.018 0.030 0.152 0.154 0.198   || dis=0.01 || select=7/8
011/019-th : 0.100 0.096 0.108 0.115 0.124 0.129 0.160 0.167  ||  -0.200 -0.243 -0.127 -0.068 0.014 0.051 0.265 0.309   || dis=0.01 || select=7/8
012/019-th : 0.107 0.111 0.116 0.123 0.129 0.134 0.137 0.142  ||  -0.150 -0.117 -0.067 -0.006 0.040 0.078 0.100 0.134   || dis=0.00 || select=7/8
013/019-th : 0.020 0.027 0.037 0.050 0.069 0.101 0.220 0.475  ||  -1.268 -1.002 -0.671 -0.368 -0.058 0.323 1.108 1.877  || dis=0.26 || select=7/8
014/019-th : 0.030 0.045 0.055 0.069 0.112 0.163 0.235 0.291  ||  -1.139 -0.751 -0.543 -0.319 0.171 0.546 0.911 1.124   || dis=0.06 || select=7/8
015/019-th : 0.017 0.023 0.036 0.047 0.069 0.111 0.229 0.469  ||  -1.431 -1.126 -0.668 -0.387 -0.007 0.465 1.192 1.909  || dis=0.24 || select=7/8
016/019-th : 0.057 0.074 0.098 0.124 0.141 0.161 0.171 0.174  ||  -0.718 -0.457 -0.169 0.064 0.190 0.323 0.382 0.401    || dis=0.00 || select=7/8
017/019-th : 0.115 0.116 0.120 0.126 0.128 0.127 0.134 0.134  ||  -0.077 -0.070 -0.039 0.013 0.030 0.017 0.072 0.074    || dis=0.00 || select=7/8
018/019-th : 0.087 0.099 0.121 0.127 0.133 0.130 0.142 0.162  ||  -0.349 -0.219 -0.019 0.031 0.077 0.059 0.143 0.277    || dis=0.02 || select=7/8
[epoch=296/600] FLOP : 28.18 MB, ratio : 0.6905, Expected-ratio : 0.7000, Discrepancy : 0.084
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:18:51] [epoch=296/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.979 (3.979)  Prec@1 33.98 (33.98) Prec@5 75.39 (75.39) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:18:57] [epoch=296/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.107 (2.353)  Prec@1 29.76 (37.30) Prec@5 72.62 (80.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.30 Prec@5 80.84 Error@1 62.70 Error@5 19.16 Loss:2.353
***[2020-01-29 08:18:57]*** VALID [epoch=296/600] loss = 2.353428, accuracy@1 = 37.30, accuracy@5 = 80.84 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:18:57]*** start epoch=297/600 Time Left: [02:41:05], LR=[0.050785 ~ 0.050785], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=297, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.588482927413961, FLOP=40.81
[Search] : epoch=297/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:18:58] [epoch=297/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.607 (0.607)  Prec@1 77.73 (77.73) Prec@5 99.61 (99.61) Acls-loss 0.875 (0.875) FLOP-Loss 0.000 (0.000) Arch-Loss 0.875 (0.875)
**TRAIN** [2020-01-29 08:19:23] [epoch=297/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.714 (0.753)  Prec@1 74.40 (74.45) Prec@5 98.21 (97.99) Acls-loss 0.942 (0.820) FLOP-Loss 0.000 (0.057) Arch-Loss 0.942 (0.934)
 **TRAIN** Prec@1 74.45 Prec@5 97.99 Error@1 25.55 Error@5 2.01 Base-Loss:0.753, Arch-Loss=0.934
***[2020-01-29 08:19:23]*** TRAIN [epoch=297/600] base-loss = 0.752789, arch-loss = 0.934048, accuracy-1 = 74.45, accuracy-5 = 97.99
[epoch=297/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 8, 11, 14, 14, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.328576)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.193 0.360  ||  0.2796 -0.5600 0.0611  || discrepancy=0.09 || select=0/3
001/003-th : 0.352 0.126 0.522  ||  0.0700 -0.9569 0.4628  || discrepancy=0.17 || select=2/3
002/003-th : 0.011 0.056 0.933  ||  -2.2107 -0.5588 2.2540  || discrepancy=0.88 || select=2/3
-----------------------------------------------
000/019-th : 0.044 0.066 0.090 0.097 0.136 0.156 0.186 0.224  ||  -0.919 -0.511 -0.203 -0.134 0.205 0.339 0.517 0.706   || dis=0.04 || select=7/8
001/019-th : 0.129 0.129 0.130 0.125 0.131 0.122 0.117 0.117  ||  0.032 0.038 0.040 0.007 0.055 -0.024 -0.060 -0.062    || dis=0.00 || select=4/8
002/019-th : 0.118 0.128 0.133 0.131 0.127 0.126 0.121 0.116  ||  -0.052 0.025 0.063 0.053 0.020 0.012 -0.034 -0.076    || dis=0.00 || select=2/8
003/019-th : 0.111 0.122 0.130 0.119 0.132 0.125 0.130 0.130  ||  -0.117 -0.020 0.038 -0.044 0.060 0.002 0.045 0.045    || dis=0.00 || select=4/8
004/019-th : 0.114 0.114 0.117 0.118 0.131 0.136 0.138 0.133  ||  -0.095 -0.088 -0.065 -0.059 0.046 0.089 0.100 0.061   || dis=0.00 || select=6/8
005/019-th : 0.104 0.119 0.128 0.125 0.127 0.133 0.133 0.132  ||  -0.178 -0.048 0.031 -0.000 0.020 0.061 0.062 0.055    || dis=0.00 || select=6/8
006/019-th : 0.116 0.114 0.115 0.118 0.131 0.127 0.137 0.142  ||  -0.077 -0.090 -0.083 -0.054 0.047 0.018 0.091 0.132   || dis=0.00 || select=7/8
007/019-th : 0.051 0.057 0.081 0.103 0.127 0.154 0.192 0.235  ||  -0.764 -0.656 -0.298 -0.068 0.145 0.342 0.557 0.763   || dis=0.04 || select=7/8
008/019-th : 0.037 0.050 0.066 0.105 0.125 0.168 0.226 0.224  ||  -1.032 -0.737 -0.451 0.014 0.187 0.480 0.777 0.767    || dis=0.00 || select=6/8
009/019-th : 0.084 0.089 0.104 0.115 0.121 0.139 0.164 0.184  ||  -0.366 -0.306 -0.148 -0.047 0.003 0.143 0.308 0.422   || dis=0.02 || select=7/8
010/019-th : 0.098 0.105 0.108 0.121 0.128 0.144 0.145 0.153  ||  -0.235 -0.166 -0.134 -0.025 0.031 0.151 0.158 0.210   || dis=0.01 || select=7/8
011/019-th : 0.100 0.097 0.107 0.114 0.124 0.129 0.162 0.168  ||  -0.207 -0.239 -0.135 -0.075 0.013 0.049 0.280 0.312   || dis=0.01 || select=7/8
012/019-th : 0.106 0.109 0.118 0.125 0.129 0.133 0.138 0.142  ||  -0.157 -0.130 -0.053 0.004 0.037 0.070 0.107 0.135    || dis=0.00 || select=7/8
013/019-th : 0.021 0.027 0.037 0.049 0.068 0.100 0.221 0.479  ||  -1.261 -0.993 -0.680 -0.382 -0.065 0.320 1.115 1.890  || dis=0.26 || select=7/8
014/019-th : 0.030 0.043 0.055 0.069 0.112 0.162 0.235 0.294  ||  -1.154 -0.771 -0.545 -0.306 0.176 0.542 0.918 1.140   || dis=0.06 || select=7/8
015/019-th : 0.016 0.022 0.036 0.047 0.069 0.109 0.224 0.476  ||  -1.439 -1.126 -0.662 -0.385 -0.003 0.457 1.173 1.929  || dis=0.25 || select=7/8
016/019-th : 0.056 0.073 0.098 0.126 0.141 0.161 0.171 0.174  ||  -0.731 -0.463 -0.170 0.079 0.192 0.325 0.383 0.402    || dis=0.00 || select=7/8
017/019-th : 0.114 0.115 0.118 0.127 0.129 0.129 0.134 0.134  ||  -0.084 -0.081 -0.056 0.021 0.038 0.041 0.077 0.073    || dis=0.00 || select=6/8
018/019-th : 0.087 0.099 0.120 0.127 0.132 0.130 0.142 0.162  ||  -0.342 -0.216 -0.021 0.033 0.068 0.056 0.142 0.278    || dis=0.02 || select=7/8
[epoch=297/600] FLOP : 28.33 MB, ratio : 0.6941, Expected-ratio : 0.7000, Discrepancy : 0.084
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:19:24] [epoch=297/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.712 (2.712)  Prec@1 38.67 (38.67) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:19:30] [epoch=297/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.257 (2.399)  Prec@1 58.33 (36.14) Prec@5 95.24 (80.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.14 Prec@5 80.28 Error@1 63.86 Error@5 19.72 Loss:2.399
***[2020-01-29 08:19:30]*** VALID [epoch=297/600] loss = 2.398593, accuracy@1 = 36.14, accuracy@5 = 80.28 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:19:30]*** start epoch=298/600 Time Left: [02:40:35], LR=[0.050524 ~ 0.050524], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=298, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.5756558710848028, FLOP=40.81
[Search] : epoch=298/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:19:31] [epoch=298/600][000/098] Time 0.75 (0.75) Data 0.37 (0.37) Base-Loss 0.721 (0.721)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44) Acls-loss 0.623 (0.623) FLOP-Loss 0.000 (0.000) Arch-Loss 0.623 (0.623)
**TRAIN** [2020-01-29 08:19:55] [epoch=298/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.679 (0.783)  Prec@1 75.00 (72.98) Prec@5 98.81 (98.05) Acls-loss 0.852 (0.822) FLOP-Loss 0.000 (0.114) Arch-Loss 0.852 (1.050)
 **TRAIN** Prec@1 72.98 Prec@5 98.05 Error@1 27.02 Error@5 1.95 Base-Loss:0.783, Arch-Loss=1.050
***[2020-01-29 08:19:55]*** TRAIN [epoch=298/600] base-loss = 0.782784, arch-loss = 1.050375, accuracy-1 = 72.98, accuracy-5 = 98.05
[epoch=298/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 8, 14, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.665024)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.451 0.192 0.357  ||  0.2891 -0.5648 0.0534  || discrepancy=0.09 || select=0/3
001/003-th : 0.354 0.126 0.520  ||  0.0762 -0.9590 0.4592  || discrepancy=0.17 || select=2/3
002/003-th : 0.011 0.056 0.934  ||  -2.2122 -0.5593 2.2594  || discrepancy=0.88 || select=2/3
-----------------------------------------------
000/019-th : 0.044 0.067 0.088 0.097 0.136 0.154 0.187 0.227  ||  -0.922 -0.501 -0.229 -0.135 0.204 0.333 0.526 0.721   || dis=0.04 || select=7/8
001/019-th : 0.129 0.132 0.132 0.125 0.129 0.121 0.117 0.116  ||  0.034 0.055 0.059 0.004 0.036 -0.033 -0.065 -0.070    || dis=0.00 || select=2/8
002/019-th : 0.120 0.127 0.134 0.131 0.126 0.127 0.121 0.115  ||  -0.042 0.022 0.072 0.051 0.007 0.016 -0.034 -0.084    || dis=0.00 || select=2/8
003/019-th : 0.111 0.123 0.131 0.120 0.130 0.126 0.129 0.130  ||  -0.118 -0.014 0.047 -0.037 0.042 0.012 0.034 0.043    || dis=0.00 || select=2/8
004/019-th : 0.115 0.115 0.117 0.116 0.131 0.137 0.137 0.133  ||  -0.081 -0.086 -0.065 -0.070 0.045 0.089 0.094 0.060   || dis=0.00 || select=6/8
005/019-th : 0.103 0.121 0.131 0.124 0.127 0.133 0.131 0.130  ||  -0.188 -0.031 0.049 -0.003 0.020 0.070 0.051 0.043    || dis=0.00 || select=5/8
006/019-th : 0.116 0.114 0.114 0.118 0.130 0.129 0.136 0.143  ||  -0.076 -0.093 -0.088 -0.053 0.044 0.029 0.083 0.137   || dis=0.01 || select=7/8
007/019-th : 0.051 0.055 0.080 0.101 0.129 0.154 0.191 0.239  ||  -0.755 -0.685 -0.306 -0.080 0.164 0.347 0.558 0.782   || dis=0.05 || select=7/8
008/019-th : 0.037 0.050 0.066 0.106 0.125 0.171 0.224 0.222  ||  -1.033 -0.724 -0.456 0.017 0.183 0.495 0.768 0.758    || dis=0.00 || select=6/8
009/019-th : 0.085 0.090 0.105 0.115 0.120 0.140 0.164 0.182  ||  -0.354 -0.299 -0.137 -0.054 -0.004 0.146 0.303 0.410  || dis=0.02 || select=7/8
010/019-th : 0.098 0.104 0.108 0.121 0.127 0.145 0.145 0.153  ||  -0.237 -0.168 -0.131 -0.025 0.027 0.157 0.156 0.211   || dis=0.01 || select=7/8
011/019-th : 0.101 0.097 0.107 0.114 0.124 0.129 0.163 0.165  ||  -0.194 -0.236 -0.140 -0.070 0.008 0.054 0.283 0.298   || dis=0.00 || select=7/8
012/019-th : 0.107 0.110 0.119 0.126 0.129 0.132 0.136 0.142  ||  -0.146 -0.122 -0.047 0.011 0.035 0.058 0.092 0.133    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.036 0.049 0.067 0.099 0.214 0.488  ||  -1.267 -1.001 -0.685 -0.373 -0.065 0.322 1.092 1.916  || dis=0.27 || select=7/8
014/019-th : 0.030 0.043 0.055 0.069 0.112 0.160 0.231 0.300  ||  -1.146 -0.775 -0.541 -0.306 0.172 0.533 0.898 1.159   || dis=0.07 || select=7/8
015/019-th : 0.017 0.023 0.036 0.047 0.069 0.108 0.225 0.476  ||  -1.433 -1.117 -0.658 -0.396 -0.003 0.446 1.176 1.928  || dis=0.25 || select=7/8
016/019-th : 0.056 0.074 0.099 0.125 0.140 0.161 0.171 0.175  ||  -0.728 -0.460 -0.166 0.067 0.181 0.322 0.386 0.409    || dis=0.00 || select=7/8
017/019-th : 0.115 0.113 0.118 0.128 0.127 0.131 0.134 0.134  ||  -0.077 -0.092 -0.051 0.026 0.023 0.056 0.072 0.072    || dis=0.00 || select=6/8
018/019-th : 0.087 0.100 0.120 0.127 0.133 0.131 0.142 0.160  ||  -0.342 -0.211 -0.027 0.034 0.082 0.063 0.144 0.264    || dis=0.02 || select=7/8
[epoch=298/600] FLOP : 27.67 MB, ratio : 0.6778, Expected-ratio : 0.7000, Discrepancy : 0.086
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:19:55] [epoch=298/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.548 (2.548)  Prec@1 25.00 (25.00) Prec@5 66.80 (66.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:20:02] [epoch=298/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 1.804 (2.218)  Prec@1 42.26 (38.27) Prec@5 89.29 (81.44) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.27 Prec@5 81.44 Error@1 61.73 Error@5 18.56 Loss:2.218
***[2020-01-29 08:20:02]*** VALID [epoch=298/600] loss = 2.217677, accuracy@1 = 38.27, accuracy@5 = 81.44 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:20:03]*** start epoch=299/600 Time Left: [02:40:03], LR=[0.050262 ~ 0.050262], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=299, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.562828111386978, FLOP=40.81
[Search] : epoch=299/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:20:03] [epoch=299/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.682 (0.682)  Prec@1 73.83 (73.83) Prec@5 98.05 (98.05) Acls-loss 0.846 (0.846) FLOP-Loss 0.000 (0.000) Arch-Loss 0.846 (0.846)
**TRAIN** [2020-01-29 08:20:28] [epoch=299/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.954 (0.801)  Prec@1 63.10 (72.88) Prec@5 97.02 (97.88) Acls-loss 0.820 (0.821) FLOP-Loss 0.000 (0.000) Arch-Loss 0.820 (0.821)
 **TRAIN** Prec@1 72.88 Prec@5 97.88 Error@1 27.12 Error@5 2.12 Base-Loss:0.801, Arch-Loss=0.821
***[2020-01-29 08:20:28]*** TRAIN [epoch=299/600] base-loss = 0.800613, arch-loss = 0.821215, accuracy-1 = 72.88, accuracy-5 = 97.88
[epoch=299/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 12, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.041856)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.191 0.364  ||  0.2731 -0.5735 0.0726  || discrepancy=0.08 || select=0/3
001/003-th : 0.348 0.128 0.524  ||  0.0628 -0.9400 0.4707  || discrepancy=0.18 || select=2/3
002/003-th : 0.010 0.054 0.936  ||  -2.2162 -0.5840 2.2769  || discrepancy=0.88 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.066 0.087 0.096 0.134 0.157 0.186 0.231  ||  -0.938 -0.511 -0.240 -0.131 0.198 0.356 0.526 0.740   || dis=0.05 || select=7/8
001/019-th : 0.126 0.129 0.131 0.126 0.129 0.121 0.118 0.118  ||  0.014 0.037 0.052 0.015 0.037 -0.025 -0.050 -0.049    || dis=0.00 || select=2/8
002/019-th : 0.118 0.125 0.134 0.130 0.129 0.127 0.121 0.115  ||  -0.051 0.003 0.071 0.045 0.033 0.021 -0.028 -0.076    || dis=0.00 || select=2/8
003/019-th : 0.110 0.121 0.129 0.120 0.130 0.125 0.131 0.133  ||  -0.126 -0.028 0.035 -0.039 0.044 0.003 0.051 0.061    || dis=0.00 || select=7/8
004/019-th : 0.113 0.113 0.118 0.117 0.129 0.139 0.138 0.134  ||  -0.097 -0.103 -0.060 -0.066 0.031 0.105 0.102 0.073   || dis=0.00 || select=5/8
005/019-th : 0.101 0.121 0.129 0.124 0.129 0.133 0.131 0.131  ||  -0.203 -0.024 0.040 -0.003 0.037 0.066 0.052 0.053    || dis=0.00 || select=5/8
006/019-th : 0.114 0.111 0.111 0.120 0.131 0.130 0.138 0.145  ||  -0.094 -0.115 -0.112 -0.042 0.049 0.042 0.102 0.152   || dis=0.01 || select=7/8
007/019-th : 0.046 0.054 0.081 0.101 0.129 0.155 0.190 0.243  ||  -0.843 -0.694 -0.279 -0.060 0.184 0.364 0.566 0.812   || dis=0.05 || select=7/8
008/019-th : 0.037 0.051 0.066 0.105 0.124 0.173 0.221 0.222  ||  -1.033 -0.712 -0.453 0.010 0.178 0.505 0.755 0.756    || dis=0.00 || select=7/8
009/019-th : 0.084 0.089 0.106 0.113 0.119 0.139 0.165 0.185  ||  -0.361 -0.301 -0.134 -0.069 -0.015 0.139 0.315 0.427  || dis=0.02 || select=7/8
010/019-th : 0.096 0.102 0.106 0.117 0.130 0.146 0.146 0.157  ||  -0.248 -0.194 -0.154 -0.051 0.050 0.166 0.167 0.243   || dis=0.01 || select=7/8
011/019-th : 0.098 0.098 0.107 0.115 0.123 0.131 0.163 0.167  ||  -0.228 -0.227 -0.138 -0.067 0.006 0.066 0.283 0.309   || dis=0.00 || select=7/8
012/019-th : 0.107 0.110 0.117 0.126 0.129 0.131 0.137 0.143  ||  -0.153 -0.121 -0.058 0.016 0.034 0.052 0.095 0.142    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.036 0.049 0.066 0.098 0.212 0.492  ||  -1.267 -1.012 -0.683 -0.371 -0.072 0.318 1.091 1.933  || dis=0.28 || select=7/8
014/019-th : 0.030 0.043 0.055 0.069 0.111 0.159 0.231 0.303  ||  -1.148 -0.790 -0.540 -0.310 0.171 0.529 0.904 1.174   || dis=0.07 || select=7/8
015/019-th : 0.016 0.022 0.035 0.045 0.069 0.106 0.226 0.480  ||  -1.441 -1.115 -0.670 -0.410 0.003 0.435 1.196 1.947   || dis=0.25 || select=7/8
016/019-th : 0.055 0.074 0.098 0.123 0.136 0.162 0.172 0.180  ||  -0.743 -0.455 -0.177 0.056 0.155 0.328 0.392 0.439    || dis=0.01 || select=7/8
017/019-th : 0.112 0.113 0.118 0.125 0.128 0.132 0.137 0.135  ||  -0.107 -0.094 -0.049 0.009 0.027 0.064 0.098 0.083    || dis=0.00 || select=6/8
018/019-th : 0.086 0.097 0.117 0.127 0.134 0.134 0.143 0.162  ||  -0.351 -0.238 -0.049 0.035 0.086 0.089 0.153 0.277    || dis=0.02 || select=7/8
[epoch=299/600] FLOP : 28.04 MB, ratio : 0.6871, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:20:28] [epoch=299/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.427 (2.427)  Prec@1 30.47 (30.47) Prec@5 68.36 (68.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:20:35] [epoch=299/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.754 (2.233)  Prec@1 45.24 (40.23) Prec@5 85.12 (83.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.23 Prec@5 83.16 Error@1 59.77 Error@5 16.84 Loss:2.233
***[2020-01-29 08:20:35]*** VALID [epoch=299/600] loss = 2.232682, accuracy@1 = 40.23, accuracy@5 = 83.16 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:20:35]*** start epoch=300/600 Time Left: [02:39:32], LR=[0.050000 ~ 0.050000], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=300, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.5500000000000003, FLOP=40.81
[Search] : epoch=300/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:20:35] [epoch=300/600][000/098] Time 0.65 (0.65) Data 0.38 (0.38) Base-Loss 0.791 (0.791)  Prec@1 74.61 (74.61) Prec@5 97.27 (97.27) Acls-loss 0.784 (0.784) FLOP-Loss 0.000 (0.000) Arch-Loss 0.784 (0.784)
**TRAIN** [2020-01-29 08:21:00] [epoch=300/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.714 (0.760)  Prec@1 76.19 (73.81) Prec@5 97.62 (98.00) Acls-loss 0.872 (0.814) FLOP-Loss 0.000 (0.086) Arch-Loss 0.872 (0.985)
 **TRAIN** Prec@1 73.81 Prec@5 98.00 Error@1 26.19 Error@5 2.00 Base-Loss:0.760, Arch-Loss=0.985
***[2020-01-29 08:21:00]*** TRAIN [epoch=300/600] base-loss = 0.760493, arch-loss = 0.985260, accuracy-1 = 73.81, accuracy-5 = 98.00
[epoch=300/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 8, 16, 14, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.328576)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.192 0.361  ||  0.2797 -0.5648 0.0659  || discrepancy=0.09 || select=0/3
001/003-th : 0.348 0.128 0.524  ||  0.0627 -0.9404 0.4728  || discrepancy=0.18 || select=2/3
002/003-th : 0.010 0.052 0.938  ||  -2.2348 -0.5996 2.3023  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.066 0.087 0.098 0.133 0.155 0.189 0.229  ||  -0.944 -0.514 -0.234 -0.118 0.192 0.346 0.539 0.735   || dis=0.04 || select=7/8
001/019-th : 0.128 0.128 0.129 0.126 0.130 0.122 0.117 0.120  ||  0.023 0.029 0.037 0.014 0.040 -0.024 -0.060 -0.041    || dis=0.00 || select=4/8
002/019-th : 0.119 0.126 0.133 0.131 0.128 0.127 0.122 0.115  ||  -0.045 0.013 0.064 0.050 0.024 0.015 -0.024 -0.085    || dis=0.00 || select=2/8
003/019-th : 0.110 0.119 0.129 0.121 0.129 0.125 0.131 0.134  ||  -0.125 -0.044 0.037 -0.029 0.033 0.003 0.051 0.072    || dis=0.00 || select=7/8
004/019-th : 0.114 0.113 0.119 0.119 0.128 0.136 0.137 0.133  ||  -0.093 -0.095 -0.049 -0.047 0.027 0.087 0.096 0.067   || dis=0.00 || select=6/8
005/019-th : 0.102 0.123 0.129 0.124 0.130 0.133 0.130 0.130  ||  -0.201 -0.012 0.040 -0.003 0.042 0.064 0.045 0.042    || dis=0.00 || select=5/8
006/019-th : 0.114 0.112 0.112 0.122 0.131 0.130 0.137 0.142  ||  -0.091 -0.107 -0.102 -0.017 0.047 0.042 0.094 0.132   || dis=0.00 || select=7/8
007/019-th : 0.045 0.054 0.081 0.102 0.129 0.156 0.191 0.242  ||  -0.867 -0.688 -0.283 -0.047 0.182 0.372 0.578 0.812   || dis=0.05 || select=7/8
008/019-th : 0.038 0.052 0.067 0.105 0.126 0.173 0.220 0.219  ||  -1.023 -0.694 -0.447 0.006 0.188 0.500 0.740 0.737    || dis=0.00 || select=6/8
009/019-th : 0.085 0.088 0.108 0.112 0.120 0.139 0.165 0.184  ||  -0.350 -0.321 -0.116 -0.071 -0.009 0.138 0.312 0.420  || dis=0.02 || select=7/8
010/019-th : 0.096 0.100 0.105 0.117 0.132 0.145 0.148 0.157  ||  -0.246 -0.214 -0.159 -0.049 0.068 0.159 0.180 0.242   || dis=0.01 || select=7/8
011/019-th : 0.097 0.096 0.107 0.117 0.124 0.133 0.162 0.164  ||  -0.227 -0.246 -0.138 -0.045 0.010 0.086 0.281 0.296   || dis=0.00 || select=7/8
012/019-th : 0.107 0.110 0.117 0.126 0.131 0.130 0.136 0.143  ||  -0.147 -0.118 -0.063 0.011 0.051 0.048 0.089 0.139    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.036 0.049 0.067 0.098 0.209 0.495  ||  -1.282 -0.993 -0.683 -0.372 -0.064 0.322 1.073 1.937  || dis=0.29 || select=7/8
014/019-th : 0.029 0.043 0.055 0.069 0.112 0.157 0.231 0.305  ||  -1.163 -0.787 -0.530 -0.311 0.180 0.516 0.903 1.182   || dis=0.07 || select=7/8
015/019-th : 0.016 0.023 0.035 0.045 0.069 0.108 0.227 0.477  ||  -1.433 -1.112 -0.669 -0.430 0.002 0.454 1.198 1.940   || dis=0.25 || select=7/8
016/019-th : 0.055 0.074 0.097 0.124 0.136 0.160 0.174 0.180  ||  -0.747 -0.456 -0.180 0.062 0.159 0.321 0.400 0.438    || dis=0.01 || select=7/8
017/019-th : 0.109 0.113 0.119 0.127 0.127 0.133 0.137 0.136  ||  -0.127 -0.095 -0.042 0.021 0.022 0.067 0.101 0.089    || dis=0.00 || select=6/8
018/019-th : 0.085 0.097 0.119 0.126 0.134 0.133 0.143 0.163  ||  -0.371 -0.234 -0.033 0.030 0.085 0.084 0.155 0.285    || dis=0.02 || select=7/8
[epoch=300/600] FLOP : 28.33 MB, ratio : 0.6941, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:21:01] [epoch=300/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.069 (2.069)  Prec@1 42.97 (42.97) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:21:07] [epoch=300/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.866 (2.263)  Prec@1 55.36 (38.40) Prec@5 94.64 (81.22) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.40 Prec@5 81.22 Error@1 61.60 Error@5 18.78 Loss:2.263
***[2020-01-29 08:21:07]*** VALID [epoch=300/600] loss = 2.263318, accuracy@1 = 38.40, accuracy@5 = 81.22 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:21:07]*** start epoch=301/600 Time Left: [02:39:00], LR=[0.049738 ~ 0.049738], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=301, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.537171888613022, FLOP=40.81
[Search] : epoch=301/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:21:08] [epoch=301/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.695 (0.695)  Prec@1 74.61 (74.61) Prec@5 98.44 (98.44) Acls-loss 0.837 (0.837) FLOP-Loss 0.000 (0.000) Arch-Loss 0.837 (0.837)
**TRAIN** [2020-01-29 08:21:33] [epoch=301/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.667 (0.760)  Prec@1 76.79 (74.28) Prec@5 99.40 (98.12) Acls-loss 0.776 (0.813) FLOP-Loss 0.000 (0.057) Arch-Loss 0.776 (0.927)
 **TRAIN** Prec@1 74.28 Prec@5 98.12 Error@1 25.72 Error@5 1.88 Base-Loss:0.760, Arch-Loss=0.927
***[2020-01-29 08:21:33]*** TRAIN [epoch=301/600] base-loss = 0.760434, arch-loss = 0.926933, accuracy-1 = 74.28, accuracy-5 = 98.12
[epoch=301/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 8, 16, 14, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.328576)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.195 0.362  ||  0.2739 -0.5468 0.0703  || discrepancy=0.08 || select=0/3
001/003-th : 0.346 0.128 0.526  ||  0.0593 -0.9379 0.4776  || discrepancy=0.18 || select=2/3
002/003-th : 0.010 0.052 0.937  ||  -2.2205 -0.5915 2.2919  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.065 0.085 0.097 0.135 0.156 0.187 0.231  ||  -0.937 -0.518 -0.251 -0.121 0.206 0.348 0.534 0.741   || dis=0.04 || select=7/8
001/019-th : 0.124 0.130 0.128 0.127 0.131 0.122 0.118 0.120  ||  -0.005 0.046 0.031 0.022 0.048 -0.016 -0.055 -0.036   || dis=0.00 || select=4/8
002/019-th : 0.118 0.124 0.134 0.132 0.130 0.126 0.122 0.115  ||  -0.055 -0.001 0.072 0.057 0.042 0.015 -0.018 -0.083   || dis=0.00 || select=2/8
003/019-th : 0.110 0.119 0.131 0.121 0.128 0.125 0.131 0.135  ||  -0.125 -0.051 0.045 -0.028 0.024 0.003 0.045 0.081    || dis=0.00 || select=7/8
004/019-th : 0.113 0.113 0.119 0.119 0.128 0.136 0.138 0.133  ||  -0.099 -0.101 -0.046 -0.048 0.030 0.089 0.104 0.065   || dis=0.00 || select=6/8
005/019-th : 0.101 0.122 0.127 0.124 0.130 0.135 0.130 0.131  ||  -0.203 -0.022 0.024 -0.001 0.042 0.086 0.043 0.050    || dis=0.00 || select=5/8
006/019-th : 0.113 0.111 0.114 0.122 0.129 0.129 0.138 0.143  ||  -0.095 -0.111 -0.093 -0.020 0.035 0.038 0.100 0.139   || dis=0.00 || select=7/8
007/019-th : 0.044 0.054 0.081 0.103 0.128 0.158 0.191 0.242  ||  -0.883 -0.686 -0.285 -0.039 0.178 0.391 0.577 0.814   || dis=0.05 || select=7/8
008/019-th : 0.037 0.051 0.068 0.105 0.126 0.174 0.220 0.219  ||  -1.039 -0.711 -0.425 0.001 0.191 0.512 0.745 0.740    || dis=0.00 || select=6/8
009/019-th : 0.086 0.085 0.106 0.111 0.121 0.140 0.165 0.185  ||  -0.335 -0.346 -0.127 -0.079 0.004 0.147 0.312 0.428   || dis=0.02 || select=7/8
010/019-th : 0.094 0.099 0.105 0.118 0.133 0.145 0.148 0.158  ||  -0.270 -0.216 -0.161 -0.038 0.074 0.164 0.186 0.247   || dis=0.01 || select=7/8
011/019-th : 0.098 0.096 0.106 0.116 0.124 0.134 0.161 0.165  ||  -0.220 -0.241 -0.143 -0.057 0.013 0.088 0.274 0.300   || dis=0.00 || select=7/8
012/019-th : 0.107 0.110 0.116 0.126 0.131 0.131 0.137 0.142  ||  -0.150 -0.118 -0.068 0.017 0.054 0.051 0.096 0.133    || dis=0.00 || select=7/8
013/019-th : 0.020 0.027 0.036 0.049 0.066 0.099 0.209 0.495  ||  -1.289 -0.978 -0.693 -0.370 -0.082 0.333 1.080 1.940  || dis=0.29 || select=7/8
014/019-th : 0.029 0.043 0.055 0.069 0.111 0.159 0.232 0.303  ||  -1.178 -0.784 -0.536 -0.302 0.175 0.531 0.912 1.178   || dis=0.07 || select=7/8
015/019-th : 0.016 0.023 0.035 0.044 0.070 0.107 0.227 0.478  ||  -1.447 -1.102 -0.681 -0.431 0.018 0.449 1.201 1.944   || dis=0.25 || select=7/8
016/019-th : 0.055 0.073 0.097 0.124 0.138 0.161 0.172 0.180  ||  -0.749 -0.462 -0.184 0.067 0.174 0.324 0.394 0.436    || dis=0.01 || select=7/8
017/019-th : 0.108 0.113 0.121 0.125 0.126 0.133 0.138 0.136  ||  -0.136 -0.097 -0.027 0.011 0.019 0.066 0.105 0.094    || dis=0.00 || select=6/8
018/019-th : 0.085 0.098 0.122 0.125 0.134 0.132 0.143 0.161  ||  -0.364 -0.230 -0.003 0.021 0.086 0.073 0.150 0.274    || dis=0.02 || select=7/8
[epoch=301/600] FLOP : 28.33 MB, ratio : 0.6941, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:21:33] [epoch=301/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.759 (2.759)  Prec@1 17.19 (17.19) Prec@5 69.92 (69.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:21:39] [epoch=301/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.259 (2.135)  Prec@1 55.95 (36.96) Prec@5 95.24 (80.56) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.96 Prec@5 80.56 Error@1 63.04 Error@5 19.44 Loss:2.135
***[2020-01-29 08:21:40]*** VALID [epoch=301/600] loss = 2.135081, accuracy@1 = 36.96, accuracy@5 = 80.56 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:21:40]*** start epoch=302/600 Time Left: [02:38:29], LR=[0.049476 ~ 0.049476], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=302, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.5243441289151987, FLOP=40.81
[Search] : epoch=302/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:21:40] [epoch=302/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.655 (0.655)  Prec@1 75.00 (75.00) Prec@5 98.05 (98.05) Acls-loss 0.888 (0.888) FLOP-Loss 0.000 (0.000) Arch-Loss 0.888 (0.888)
**TRAIN** [2020-01-29 08:22:05] [epoch=302/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.911 (0.783)  Prec@1 67.26 (72.98) Prec@5 96.43 (97.98) Acls-loss 0.799 (0.803) FLOP-Loss 0.000 (0.086) Arch-Loss 0.799 (0.975)
 **TRAIN** Prec@1 72.98 Prec@5 97.98 Error@1 27.02 Error@5 2.02 Base-Loss:0.783, Arch-Loss=0.975
***[2020-01-29 08:22:05]*** TRAIN [epoch=302/600] base-loss = 0.782973, arch-loss = 0.974906, accuracy-1 = 72.98, accuracy-5 = 97.98
[epoch=302/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 8, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.599488)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.197 0.360  ||  0.2764 -0.5344 0.0668  || discrepancy=0.08 || select=0/3
001/003-th : 0.347 0.128 0.525  ||  0.0627 -0.9347 0.4757  || discrepancy=0.18 || select=2/3
002/003-th : 0.010 0.051 0.939  ||  -2.2400 -0.5949 2.3127  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.066 0.086 0.096 0.134 0.155 0.187 0.233  ||  -0.934 -0.516 -0.241 -0.132 0.200 0.340 0.530 0.749   || dis=0.05 || select=7/8
001/019-th : 0.123 0.131 0.128 0.129 0.131 0.121 0.117 0.119  ||  -0.008 0.056 0.033 0.041 0.051 -0.024 -0.064 -0.041   || dis=0.00 || select=1/8
002/019-th : 0.119 0.125 0.135 0.132 0.128 0.125 0.122 0.114  ||  -0.045 0.003 0.085 0.058 0.031 0.003 -0.021 -0.092    || dis=0.00 || select=2/8
003/019-th : 0.111 0.118 0.131 0.122 0.128 0.126 0.129 0.135  ||  -0.115 -0.060 0.049 -0.023 0.021 0.013 0.032 0.081    || dis=0.00 || select=7/8
004/019-th : 0.112 0.115 0.119 0.119 0.127 0.136 0.139 0.133  ||  -0.106 -0.083 -0.049 -0.044 0.015 0.087 0.110 0.064   || dis=0.00 || select=6/8
005/019-th : 0.101 0.120 0.126 0.125 0.130 0.134 0.131 0.133  ||  -0.205 -0.038 0.012 0.009 0.047 0.073 0.051 0.067     || dis=0.00 || select=5/8
006/019-th : 0.113 0.111 0.115 0.121 0.132 0.128 0.137 0.142  ||  -0.096 -0.112 -0.082 -0.025 0.060 0.028 0.093 0.134   || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.080 0.103 0.128 0.159 0.189 0.241  ||  -0.880 -0.676 -0.293 -0.036 0.177 0.397 0.568 0.808   || dis=0.05 || select=7/8
008/019-th : 0.037 0.052 0.070 0.105 0.127 0.171 0.218 0.220  ||  -1.051 -0.692 -0.408 0.003 0.193 0.492 0.734 0.744    || dis=0.00 || select=7/8
009/019-th : 0.086 0.087 0.107 0.111 0.122 0.138 0.164 0.185  ||  -0.337 -0.332 -0.121 -0.083 0.007 0.136 0.307 0.423   || dis=0.02 || select=7/8
010/019-th : 0.094 0.100 0.105 0.118 0.131 0.144 0.151 0.157  ||  -0.268 -0.208 -0.164 -0.042 0.064 0.153 0.206 0.243   || dis=0.01 || select=7/8
011/019-th : 0.097 0.098 0.107 0.116 0.125 0.133 0.162 0.163  ||  -0.230 -0.227 -0.139 -0.056 0.020 0.086 0.278 0.285   || dis=0.00 || select=7/8
012/019-th : 0.107 0.111 0.116 0.128 0.131 0.128 0.137 0.142  ||  -0.147 -0.109 -0.070 0.029 0.052 0.029 0.097 0.130    || dis=0.00 || select=7/8
013/019-th : 0.020 0.027 0.036 0.050 0.065 0.100 0.206 0.497  ||  -1.288 -0.988 -0.687 -0.353 -0.085 0.339 1.061 1.941  || dis=0.29 || select=7/8
014/019-th : 0.029 0.042 0.055 0.070 0.112 0.159 0.231 0.303  ||  -1.182 -0.798 -0.532 -0.291 0.184 0.532 0.906 1.178   || dis=0.07 || select=7/8
015/019-th : 0.016 0.023 0.035 0.045 0.068 0.107 0.227 0.480  ||  -1.442 -1.100 -0.674 -0.427 -0.001 0.450 1.199 1.948  || dis=0.25 || select=7/8
016/019-th : 0.054 0.073 0.097 0.124 0.139 0.159 0.175 0.180  ||  -0.763 -0.458 -0.183 0.064 0.177 0.314 0.408 0.439    || dis=0.01 || select=7/8
017/019-th : 0.109 0.112 0.121 0.126 0.125 0.133 0.137 0.136  ||  -0.128 -0.104 -0.023 0.016 0.007 0.072 0.102 0.091    || dis=0.00 || select=6/8
018/019-th : 0.085 0.097 0.123 0.126 0.132 0.133 0.144 0.161  ||  -0.367 -0.237 0.000 0.024 0.073 0.078 0.160 0.275     || dis=0.02 || select=7/8
[epoch=302/600] FLOP : 27.60 MB, ratio : 0.6762, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:22:06] [epoch=302/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.955 (1.955)  Prec@1 44.14 (44.14) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:22:12] [epoch=302/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.944 (2.353)  Prec@1 39.29 (36.23) Prec@5 82.14 (81.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.23 Prec@5 81.13 Error@1 63.77 Error@5 18.87 Loss:2.353
***[2020-01-29 08:22:12]*** VALID [epoch=302/600] loss = 2.353119, accuracy@1 = 36.23, accuracy@5 = 81.13 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:22:12]*** start epoch=303/600 Time Left: [02:37:57], LR=[0.049215 ~ 0.049215], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=303, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.51151707258604, FLOP=40.81
[Search] : epoch=303/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:22:13] [epoch=303/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.690 (0.690)  Prec@1 75.00 (75.00) Prec@5 98.83 (98.83) Acls-loss 1.143 (1.143) FLOP-Loss 0.000 (0.000) Arch-Loss 1.143 (1.143)
**TRAIN** [2020-01-29 08:22:37] [epoch=303/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.647 (0.775)  Prec@1 78.57 (73.47) Prec@5 99.40 (97.95) Acls-loss 0.983 (0.809) FLOP-Loss 0.000 (0.114) Arch-Loss 0.983 (1.038)
 **TRAIN** Prec@1 73.47 Prec@5 97.95 Error@1 26.53 Error@5 2.05 Base-Loss:0.775, Arch-Loss=1.038
***[2020-01-29 08:22:37]*** TRAIN [epoch=303/600] base-loss = 0.775015, arch-loss = 1.037558, accuracy-1 = 73.47, accuracy-5 = 97.95
[epoch=303/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 8, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.599488)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.448 0.195 0.357  ||  0.2871 -0.5466 0.0590  || discrepancy=0.09 || select=0/3
001/003-th : 0.350 0.132 0.518  ||  0.0717 -0.9040 0.4639  || discrepancy=0.17 || select=2/3
002/003-th : 0.010 0.051 0.939  ||  -2.2385 -0.5929 2.3148  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.042 0.065 0.087 0.095 0.135 0.153 0.190 0.232  ||  -0.961 -0.524 -0.226 -0.140 0.213 0.333 0.554 0.752   || dis=0.04 || select=7/8
001/019-th : 0.123 0.132 0.130 0.130 0.131 0.121 0.116 0.118  ||  -0.007 0.061 0.043 0.048 0.053 -0.027 -0.071 -0.049   || dis=0.00 || select=1/8
002/019-th : 0.120 0.124 0.135 0.134 0.129 0.125 0.120 0.113  ||  -0.033 -0.001 0.081 0.073 0.035 0.007 -0.037 -0.099   || dis=0.00 || select=2/8
003/019-th : 0.112 0.118 0.132 0.123 0.127 0.126 0.128 0.134  ||  -0.105 -0.060 0.053 -0.017 0.015 0.012 0.028 0.072    || dis=0.00 || select=7/8
004/019-th : 0.113 0.116 0.118 0.120 0.128 0.133 0.139 0.133  ||  -0.097 -0.070 -0.052 -0.043 0.025 0.062 0.105 0.062   || dis=0.01 || select=6/8
005/019-th : 0.102 0.120 0.125 0.125 0.131 0.135 0.131 0.132  ||  -0.197 -0.037 0.009 0.001 0.050 0.080 0.050 0.058     || dis=0.00 || select=5/8
006/019-th : 0.114 0.112 0.114 0.121 0.130 0.129 0.137 0.143  ||  -0.088 -0.104 -0.088 -0.031 0.043 0.032 0.092 0.137   || dis=0.01 || select=7/8
007/019-th : 0.045 0.055 0.081 0.104 0.128 0.160 0.189 0.239  ||  -0.878 -0.673 -0.287 -0.037 0.175 0.396 0.566 0.800   || dis=0.05 || select=7/8
008/019-th : 0.037 0.052 0.070 0.104 0.128 0.171 0.219 0.221  ||  -1.053 -0.699 -0.400 -0.007 0.199 0.489 0.739 0.746   || dis=0.00 || select=7/8
009/019-th : 0.086 0.088 0.107 0.111 0.122 0.137 0.165 0.183  ||  -0.345 -0.319 -0.118 -0.081 0.009 0.127 0.314 0.417   || dis=0.02 || select=7/8
010/019-th : 0.096 0.100 0.106 0.119 0.130 0.141 0.150 0.158  ||  -0.253 -0.207 -0.154 -0.032 0.055 0.133 0.194 0.246   || dis=0.01 || select=7/8
011/019-th : 0.096 0.099 0.106 0.116 0.124 0.132 0.161 0.164  ||  -0.242 -0.211 -0.140 -0.054 0.014 0.078 0.275 0.290   || dis=0.00 || select=7/8
012/019-th : 0.108 0.113 0.117 0.127 0.134 0.128 0.134 0.140  ||  -0.136 -0.098 -0.062 0.021 0.074 0.026 0.077 0.119    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.035 0.049 0.065 0.098 0.211 0.495  ||  -1.283 -0.989 -0.694 -0.365 -0.088 0.325 1.091 1.943  || dis=0.28 || select=7/8
014/019-th : 0.029 0.041 0.055 0.069 0.112 0.159 0.232 0.303  ||  -1.177 -0.814 -0.523 -0.296 0.187 0.535 0.912 1.178   || dis=0.07 || select=7/8
015/019-th : 0.016 0.023 0.034 0.045 0.070 0.106 0.221 0.485  ||  -1.436 -1.081 -0.697 -0.428 0.018 0.441 1.174 1.959   || dis=0.26 || select=7/8
016/019-th : 0.055 0.074 0.095 0.124 0.137 0.160 0.175 0.179  ||  -0.754 -0.447 -0.197 0.068 0.168 0.320 0.410 0.432    || dis=0.00 || select=7/8
017/019-th : 0.109 0.113 0.122 0.126 0.125 0.133 0.136 0.136  ||  -0.128 -0.098 -0.015 0.012 0.009 0.067 0.094 0.091    || dis=0.00 || select=6/8
018/019-th : 0.086 0.098 0.123 0.126 0.130 0.134 0.144 0.159  ||  -0.355 -0.222 -0.001 0.023 0.060 0.085 0.159 0.258    || dis=0.02 || select=7/8
[epoch=303/600] FLOP : 27.60 MB, ratio : 0.6762, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:22:38] [epoch=303/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.709 (1.709)  Prec@1 40.62 (40.62) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:22:44] [epoch=303/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.066 (2.116)  Prec@1 33.33 (40.30) Prec@5 76.19 (83.59) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.30 Prec@5 83.59 Error@1 59.70 Error@5 16.41 Loss:2.116
***[2020-01-29 08:22:44]*** VALID [epoch=303/600] loss = 2.115698, accuracy@1 = 40.30, accuracy@5 = 83.59 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:22:44]*** start epoch=304/600 Time Left: [02:37:26], LR=[0.048953 ~ 0.048953], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=304, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.498691071285776, FLOP=40.81
[Search] : epoch=304/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:22:45] [epoch=304/600][000/098] Time 0.76 (0.76) Data 0.35 (0.35) Base-Loss 0.760 (0.760)  Prec@1 75.39 (75.39) Prec@5 98.05 (98.05) Acls-loss 0.802 (0.802) FLOP-Loss 0.000 (0.000) Arch-Loss 0.802 (0.802)
**TRAIN** [2020-01-29 08:23:10] [epoch=304/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.938 (0.763)  Prec@1 67.86 (73.64) Prec@5 97.62 (98.16) Acls-loss 0.733 (0.812) FLOP-Loss 0.000 (0.114) Arch-Loss 0.733 (1.040)
 **TRAIN** Prec@1 73.64 Prec@5 98.16 Error@1 26.36 Error@5 1.84 Base-Loss:0.763, Arch-Loss=1.040
***[2020-01-29 08:23:10]*** TRAIN [epoch=304/600] base-loss = 0.763204, arch-loss = 1.040218, accuracy-1 = 73.64, accuracy-5 = 98.16
[epoch=304/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 8, 16, 14, 12, 16, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.222656)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.451 0.195 0.354  ||  0.2946 -0.5416 0.0517  || discrepancy=0.10 || select=0/3
001/003-th : 0.352 0.131 0.517  ||  0.0779 -0.9145 0.4614  || discrepancy=0.17 || select=2/3
002/003-th : 0.010 0.051 0.939  ||  -2.2340 -0.5954 2.3166  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.041 0.064 0.087 0.095 0.136 0.151 0.194 0.231  ||  -0.971 -0.529 -0.224 -0.139 0.217 0.327 0.574 0.748   || dis=0.04 || select=7/8
001/019-th : 0.124 0.132 0.130 0.131 0.132 0.120 0.115 0.117  ||  -0.002 0.062 0.049 0.051 0.059 -0.034 -0.072 -0.060   || dis=0.00 || select=1/8
002/019-th : 0.121 0.126 0.136 0.136 0.129 0.123 0.118 0.111  ||  -0.025 0.012 0.089 0.089 0.037 -0.007 -0.047 -0.115   || dis=0.00 || select=2/8
003/019-th : 0.114 0.118 0.132 0.123 0.127 0.126 0.128 0.132  ||  -0.091 -0.057 0.053 -0.012 0.020 0.007 0.022 0.059    || dis=0.00 || select=7/8
004/019-th : 0.114 0.117 0.118 0.119 0.129 0.133 0.138 0.131  ||  -0.088 -0.064 -0.058 -0.045 0.032 0.064 0.102 0.052   || dis=0.01 || select=6/8
005/019-th : 0.103 0.118 0.127 0.126 0.130 0.134 0.131 0.132  ||  -0.187 -0.056 0.020 0.009 0.045 0.077 0.048 0.056     || dis=0.00 || select=5/8
006/019-th : 0.115 0.112 0.115 0.121 0.132 0.128 0.138 0.140  ||  -0.078 -0.107 -0.083 -0.028 0.055 0.025 0.099 0.119   || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.080 0.103 0.128 0.160 0.191 0.240  ||  -0.887 -0.671 -0.296 -0.040 0.178 0.400 0.577 0.804   || dis=0.05 || select=7/8
008/019-th : 0.037 0.052 0.069 0.106 0.129 0.172 0.218 0.218  ||  -1.048 -0.708 -0.413 0.011 0.213 0.497 0.734 0.734    || dis=0.00 || select=6/8
009/019-th : 0.087 0.088 0.107 0.110 0.124 0.138 0.163 0.182  ||  -0.333 -0.313 -0.122 -0.093 0.020 0.133 0.301 0.409   || dis=0.02 || select=7/8
010/019-th : 0.096 0.099 0.106 0.121 0.129 0.142 0.151 0.157  ||  -0.248 -0.220 -0.153 -0.022 0.042 0.142 0.206 0.239   || dis=0.01 || select=7/8
011/019-th : 0.098 0.100 0.107 0.116 0.124 0.133 0.160 0.163  ||  -0.230 -0.200 -0.140 -0.055 0.008 0.077 0.263 0.287   || dis=0.00 || select=7/8
012/019-th : 0.109 0.112 0.118 0.125 0.133 0.128 0.135 0.141  ||  -0.133 -0.103 -0.056 0.008 0.064 0.027 0.082 0.123    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.035 0.049 0.065 0.096 0.212 0.496  ||  -1.283 -0.987 -0.698 -0.359 -0.082 0.309 1.096 1.948  || dis=0.28 || select=7/8
014/019-th : 0.029 0.041 0.055 0.071 0.112 0.160 0.229 0.303  ||  -1.178 -0.814 -0.531 -0.277 0.183 0.541 0.899 1.178   || dis=0.07 || select=7/8
015/019-th : 0.016 0.023 0.034 0.045 0.069 0.104 0.221 0.487  ||  -1.448 -1.088 -0.693 -0.407 0.015 0.424 1.179 1.968   || dis=0.27 || select=7/8
016/019-th : 0.055 0.073 0.095 0.128 0.138 0.159 0.173 0.177  ||  -0.741 -0.463 -0.197 0.098 0.175 0.314 0.399 0.421    || dis=0.00 || select=7/8
017/019-th : 0.109 0.114 0.121 0.125 0.125 0.135 0.136 0.134  ||  -0.132 -0.082 -0.022 0.008 0.007 0.081 0.095 0.078    || dis=0.00 || select=6/8
018/019-th : 0.085 0.099 0.124 0.128 0.131 0.133 0.142 0.157  ||  -0.363 -0.212 0.013 0.046 0.063 0.083 0.143 0.249     || dis=0.02 || select=7/8
[epoch=304/600] FLOP : 27.22 MB, ratio : 0.6670, Expected-ratio : 0.7000, Discrepancy : 0.087
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:23:11] [epoch=304/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.070 (3.070)  Prec@1 27.73 (27.73) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:23:17] [epoch=304/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.182 (2.318)  Prec@1 39.88 (39.97) Prec@5 84.52 (83.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.97 Prec@5 83.65 Error@1 60.03 Error@5 16.35 Loss:2.318
***[2020-01-29 08:23:17]*** VALID [epoch=304/600] loss = 2.318438, accuracy@1 = 39.97, accuracy@5 = 83.65 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:23:17]*** start epoch=305/600 Time Left: [02:36:55], LR=[0.048691 ~ 0.048691], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=305, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.4858664766457115, FLOP=40.81
[Search] : epoch=305/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:23:18] [epoch=305/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.874 (0.874)  Prec@1 68.36 (68.36) Prec@5 97.27 (97.27) Acls-loss 0.800 (0.800) FLOP-Loss 0.000 (0.000) Arch-Loss 0.800 (0.800)
**TRAIN** [2020-01-29 08:23:43] [epoch=305/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.733 (0.758)  Prec@1 72.62 (74.01) Prec@5 98.21 (98.17) Acls-loss 0.820 (0.790) FLOP-Loss 0.000 (0.057) Arch-Loss 0.820 (0.905)
 **TRAIN** Prec@1 74.01 Prec@5 98.17 Error@1 25.99 Error@5 1.83 Base-Loss:0.758, Arch-Loss=0.905
***[2020-01-29 08:23:43]*** TRAIN [epoch=305/600] base-loss = 0.758263, arch-loss = 0.904513, accuracy-1 = 74.01, accuracy-5 = 98.17
[epoch=305/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.671168)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.198 0.354  ||  0.2892 -0.5250 0.0557  || discrepancy=0.09 || select=0/3
001/003-th : 0.351 0.131 0.518  ||  0.0744 -0.9088 0.4655  || discrepancy=0.17 || select=2/3
002/003-th : 0.010 0.049 0.941  ||  -2.2467 -0.6153 2.3390  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.042 0.063 0.087 0.094 0.136 0.151 0.197 0.230  ||  -0.956 -0.545 -0.232 -0.151 0.221 0.323 0.593 0.745   || dis=0.03 || select=7/8
001/019-th : 0.124 0.132 0.131 0.129 0.131 0.121 0.116 0.117  ||  -0.002 0.061 0.052 0.036 0.053 -0.023 -0.068 -0.062   || dis=0.00 || select=1/8
002/019-th : 0.119 0.125 0.135 0.136 0.130 0.125 0.119 0.110  ||  -0.038 0.005 0.088 0.095 0.051 0.007 -0.039 -0.119    || dis=0.00 || select=3/8
003/019-th : 0.114 0.116 0.130 0.124 0.130 0.126 0.126 0.134  ||  -0.091 -0.071 0.038 -0.005 0.039 0.011 0.009 0.073    || dis=0.00 || select=7/8
004/019-th : 0.114 0.117 0.117 0.118 0.129 0.134 0.138 0.132  ||  -0.087 -0.063 -0.064 -0.058 0.031 0.071 0.102 0.059   || dis=0.00 || select=6/8
005/019-th : 0.103 0.117 0.127 0.124 0.131 0.135 0.132 0.132  ||  -0.193 -0.059 0.019 -0.006 0.055 0.080 0.057 0.058    || dis=0.00 || select=5/8
006/019-th : 0.115 0.112 0.114 0.123 0.131 0.127 0.139 0.140  ||  -0.083 -0.106 -0.092 -0.016 0.051 0.021 0.108 0.119   || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.078 0.102 0.129 0.160 0.191 0.241  ||  -0.881 -0.669 -0.314 -0.053 0.184 0.405 0.579 0.813   || dis=0.05 || select=7/8
008/019-th : 0.036 0.050 0.069 0.105 0.130 0.172 0.217 0.220  ||  -1.049 -0.731 -0.418 0.006 0.221 0.505 0.737 0.750    || dis=0.00 || select=7/8
009/019-th : 0.087 0.087 0.105 0.113 0.124 0.137 0.162 0.186  ||  -0.333 -0.326 -0.138 -0.072 0.021 0.125 0.290 0.429   || dis=0.02 || select=7/8
010/019-th : 0.096 0.098 0.106 0.122 0.130 0.142 0.150 0.157  ||  -0.247 -0.232 -0.153 -0.010 0.054 0.141 0.194 0.240   || dis=0.01 || select=7/8
011/019-th : 0.097 0.096 0.107 0.117 0.125 0.137 0.159 0.163  ||  -0.231 -0.247 -0.138 -0.043 0.019 0.113 0.259 0.289   || dis=0.00 || select=7/8
012/019-th : 0.109 0.112 0.116 0.127 0.132 0.128 0.135 0.142  ||  -0.133 -0.107 -0.071 0.022 0.059 0.029 0.081 0.129    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.035 0.049 0.062 0.097 0.210 0.502  ||  -1.273 -0.994 -0.689 -0.361 -0.126 0.323 1.097 1.968  || dis=0.29 || select=7/8
014/019-th : 0.029 0.041 0.055 0.071 0.111 0.160 0.227 0.307  ||  -1.168 -0.829 -0.533 -0.273 0.172 0.544 0.892 1.194   || dis=0.08 || select=7/8
015/019-th : 0.016 0.022 0.034 0.045 0.067 0.104 0.224 0.488  ||  -1.447 -1.110 -0.688 -0.403 -0.010 0.435 1.197 1.977  || dis=0.26 || select=7/8
016/019-th : 0.056 0.072 0.093 0.128 0.139 0.161 0.173 0.178  ||  -0.723 -0.474 -0.227 0.094 0.179 0.328 0.400 0.426    || dis=0.01 || select=7/8
017/019-th : 0.109 0.112 0.121 0.124 0.126 0.134 0.138 0.136  ||  -0.126 -0.101 -0.029 0.000 0.012 0.075 0.103 0.092    || dis=0.00 || select=6/8
018/019-th : 0.085 0.100 0.124 0.130 0.130 0.132 0.141 0.159  ||  -0.370 -0.204 0.008 0.056 0.056 0.074 0.141 0.258     || dis=0.02 || select=7/8
[epoch=305/600] FLOP : 27.67 MB, ratio : 0.6780, Expected-ratio : 0.7000, Discrepancy : 0.089
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:23:43] [epoch=305/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.568 (1.568)  Prec@1 44.92 (44.92) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:23:50] [epoch=305/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.926 (2.312)  Prec@1 28.57 (36.07) Prec@5 72.62 (79.69) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.07 Prec@5 79.69 Error@1 63.93 Error@5 20.31 Loss:2.312
***[2020-01-29 08:23:50]*** VALID [epoch=305/600] loss = 2.311760, accuracy@1 = 36.07, accuracy@5 = 79.69 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:23:50]*** start epoch=306/600 Time Left: [02:36:24], LR=[0.048429 ~ 0.048429], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=306, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.473043640258586, FLOP=40.81
[Search] : epoch=306/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:23:50] [epoch=306/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.675 (0.675)  Prec@1 75.00 (75.00) Prec@5 99.22 (99.22) Acls-loss 0.852 (0.852) FLOP-Loss 0.000 (0.000) Arch-Loss 0.852 (0.852)
**TRAIN** [2020-01-29 08:24:15] [epoch=306/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.846 (0.758)  Prec@1 70.83 (74.16) Prec@5 98.21 (97.96) Acls-loss 0.791 (0.822) FLOP-Loss 0.000 (0.171) Arch-Loss 0.791 (1.165)
 **TRAIN** Prec@1 74.16 Prec@5 97.96 Error@1 25.84 Error@5 2.04 Base-Loss:0.758, Arch-Loss=1.165
***[2020-01-29 08:24:16]*** TRAIN [epoch=306/600] base-loss = 0.758200, arch-loss = 1.164697, accuracy-1 = 74.16, accuracy-5 = 97.96
[epoch=306/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.187264)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.455 0.196 0.349  ||  0.3070 -0.5371 0.0404  || discrepancy=0.11 || select=0/3
001/003-th : 0.361 0.132 0.506  ||  0.1019 -0.9010 0.4398  || discrepancy=0.15 || select=2/3
002/003-th : 0.009 0.048 0.942  ||  -2.2504 -0.6190 2.3478  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.042 0.064 0.088 0.093 0.138 0.148 0.199 0.228  ||  -0.966 -0.527 -0.219 -0.158 0.235 0.302 0.601 0.734   || dis=0.03 || select=7/8
001/019-th : 0.124 0.133 0.133 0.131 0.132 0.119 0.114 0.113  ||  0.002 0.076 0.073 0.059 0.062 -0.037 -0.080 -0.088    || dis=0.00 || select=1/8
002/019-th : 0.122 0.125 0.137 0.137 0.128 0.124 0.117 0.110  ||  -0.021 0.008 0.098 0.099 0.027 -0.001 -0.057 -0.119   || dis=0.00 || select=3/8
003/019-th : 0.116 0.117 0.130 0.126 0.129 0.125 0.124 0.132  ||  -0.073 -0.062 0.044 0.006 0.035 -0.000 -0.004 0.058   || dis=0.00 || select=7/8
004/019-th : 0.115 0.120 0.118 0.119 0.129 0.133 0.136 0.130  ||  -0.078 -0.040 -0.055 -0.050 0.030 0.066 0.085 0.042   || dis=0.00 || select=6/8
005/019-th : 0.105 0.117 0.127 0.125 0.131 0.134 0.131 0.130  ||  -0.170 -0.060 0.018 0.006 0.053 0.070 0.047 0.043     || dis=0.00 || select=5/8
006/019-th : 0.118 0.114 0.115 0.122 0.129 0.127 0.138 0.138  ||  -0.058 -0.093 -0.084 -0.022 0.032 0.020 0.100 0.103   || dis=0.00 || select=7/8
007/019-th : 0.044 0.054 0.079 0.101 0.129 0.163 0.188 0.242  ||  -0.883 -0.676 -0.304 -0.055 0.183 0.419 0.564 0.816   || dis=0.05 || select=7/8
008/019-th : 0.037 0.051 0.067 0.106 0.130 0.173 0.214 0.223  ||  -1.041 -0.718 -0.437 0.012 0.220 0.508 0.716 0.758    || dis=0.01 || select=7/8
009/019-th : 0.087 0.089 0.105 0.112 0.125 0.136 0.159 0.187  ||  -0.326 -0.311 -0.142 -0.076 0.032 0.114 0.271 0.433   || dis=0.03 || select=7/8
010/019-th : 0.099 0.099 0.108 0.120 0.132 0.141 0.147 0.153  ||  -0.222 -0.215 -0.128 -0.025 0.071 0.131 0.176 0.215   || dis=0.01 || select=7/8
011/019-th : 0.098 0.096 0.107 0.117 0.126 0.137 0.158 0.162  ||  -0.225 -0.247 -0.134 -0.050 0.029 0.110 0.257 0.281   || dis=0.00 || select=7/8
012/019-th : 0.112 0.114 0.116 0.127 0.133 0.127 0.133 0.138  ||  -0.107 -0.086 -0.069 0.019 0.065 0.019 0.069 0.105    || dis=0.01 || select=7/8
013/019-th : 0.020 0.026 0.035 0.050 0.061 0.099 0.211 0.498  ||  -1.265 -1.005 -0.691 -0.350 -0.136 0.337 1.099 1.955  || dis=0.29 || select=7/8
014/019-th : 0.029 0.041 0.056 0.071 0.111 0.159 0.227 0.305  ||  -1.167 -0.818 -0.514 -0.280 0.175 0.531 0.887 1.183   || dis=0.08 || select=7/8
015/019-th : 0.016 0.022 0.034 0.045 0.067 0.105 0.222 0.489  ||  -1.437 -1.104 -0.686 -0.411 -0.016 0.439 1.189 1.978  || dis=0.27 || select=7/8
016/019-th : 0.057 0.072 0.094 0.129 0.140 0.160 0.171 0.176  ||  -0.721 -0.474 -0.210 0.107 0.186 0.320 0.386 0.417    || dis=0.00 || select=7/8
017/019-th : 0.112 0.113 0.121 0.127 0.125 0.133 0.135 0.135  ||  -0.106 -0.096 -0.030 0.020 0.008 0.066 0.079 0.083    || dis=0.00 || select=7/8
018/019-th : 0.086 0.100 0.123 0.131 0.131 0.132 0.142 0.155  ||  -0.355 -0.201 0.002 0.066 0.063 0.070 0.148 0.235     || dis=0.01 || select=7/8
[epoch=306/600] FLOP : 28.19 MB, ratio : 0.6906, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:24:16] [epoch=306/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.323 (2.323)  Prec@1 33.59 (33.59) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:24:22] [epoch=306/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.848 (2.360)  Prec@1 31.55 (37.77) Prec@5 83.33 (81.11) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.77 Prec@5 81.11 Error@1 62.23 Error@5 18.89 Loss:2.360
***[2020-01-29 08:24:22]*** VALID [epoch=306/600] loss = 2.360136, accuracy@1 = 37.77, accuracy@5 = 81.11 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:24:22]*** start epoch=307/600 Time Left: [02:35:52], LR=[0.048168 ~ 0.048168], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=307, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.460222913668937, FLOP=40.81
[Search] : epoch=307/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:24:23] [epoch=307/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.701 (0.701)  Prec@1 74.22 (74.22) Prec@5 98.05 (98.05) Acls-loss 1.010 (1.010) FLOP-Loss 0.000 (0.000) Arch-Loss 1.010 (1.010)
**TRAIN** [2020-01-29 08:24:48] [epoch=307/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.877 (0.798)  Prec@1 67.86 (73.23) Prec@5 97.62 (97.78) Acls-loss 0.923 (0.804) FLOP-Loss 0.000 (0.142) Arch-Loss 0.923 (1.089)
 **TRAIN** Prec@1 73.23 Prec@5 97.78 Error@1 26.77 Error@5 2.22 Base-Loss:0.798, Arch-Loss=1.089
***[2020-01-29 08:24:48]*** TRAIN [epoch=307/600] base-loss = 0.798429, arch-loss = 1.089292, accuracy-1 = 73.23, accuracy-5 = 97.78
[epoch=307/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 12, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.461 0.198 0.342  ||  0.3222 -0.5239 0.0238  || discrepancy=0.12 || select=0/3
001/003-th : 0.369 0.130 0.501  ||  0.1199 -0.9200 0.4274  || discrepancy=0.13 || select=2/3
002/003-th : 0.009 0.048 0.943  ||  -2.2614 -0.6209 2.3614  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.041 0.065 0.089 0.094 0.137 0.148 0.198 0.228  ||  -0.974 -0.517 -0.208 -0.154 0.226 0.300 0.594 0.734   || dis=0.03 || select=7/8
001/019-th : 0.125 0.135 0.136 0.133 0.128 0.120 0.112 0.112  ||  0.013 0.085 0.092 0.069 0.032 -0.034 -0.096 -0.101    || dis=0.00 || select=2/8
002/019-th : 0.123 0.127 0.139 0.139 0.127 0.121 0.115 0.109  ||  -0.009 0.025 0.114 0.114 0.019 -0.024 -0.073 -0.133   || dis=0.00 || select=3/8
003/019-th : 0.116 0.119 0.130 0.125 0.130 0.124 0.125 0.130  ||  -0.076 -0.045 0.043 0.003 0.044 -0.004 -0.002 0.044   || dis=0.00 || select=7/8
004/019-th : 0.118 0.121 0.120 0.119 0.130 0.129 0.134 0.130  ||  -0.057 -0.032 -0.042 -0.045 0.038 0.035 0.067 0.037   || dis=0.00 || select=6/8
005/019-th : 0.108 0.118 0.125 0.126 0.128 0.133 0.130 0.131  ||  -0.146 -0.055 -0.001 0.009 0.028 0.060 0.043 0.051    || dis=0.00 || select=5/8
006/019-th : 0.119 0.115 0.117 0.123 0.127 0.126 0.137 0.136  ||  -0.044 -0.078 -0.066 -0.013 0.019 0.007 0.091 0.089   || dis=0.00 || select=6/8
007/019-th : 0.044 0.055 0.079 0.102 0.129 0.163 0.188 0.240  ||  -0.898 -0.667 -0.298 -0.045 0.186 0.420 0.562 0.808   || dis=0.05 || select=7/8
008/019-th : 0.036 0.052 0.068 0.107 0.127 0.173 0.212 0.225  ||  -1.067 -0.688 -0.430 0.025 0.196 0.506 0.707 0.767    || dis=0.01 || select=7/8
009/019-th : 0.089 0.089 0.106 0.112 0.127 0.135 0.157 0.185  ||  -0.315 -0.305 -0.132 -0.077 0.045 0.105 0.259 0.420   || dis=0.03 || select=7/8
010/019-th : 0.099 0.101 0.111 0.121 0.132 0.139 0.147 0.149  ||  -0.216 -0.202 -0.109 -0.015 0.071 0.123 0.172 0.189   || dis=0.00 || select=7/8
011/019-th : 0.098 0.096 0.106 0.118 0.128 0.137 0.158 0.160  ||  -0.221 -0.245 -0.146 -0.041 0.043 0.113 0.254 0.267   || dis=0.00 || select=7/8
012/019-th : 0.113 0.114 0.115 0.129 0.133 0.126 0.133 0.137  ||  -0.097 -0.084 -0.077 0.037 0.067 0.011 0.065 0.097    || dis=0.00 || select=7/8
013/019-th : 0.020 0.026 0.035 0.049 0.060 0.099 0.212 0.498  ||  -1.252 -0.991 -0.694 -0.357 -0.153 0.340 1.101 1.957  || dis=0.29 || select=7/8
014/019-th : 0.029 0.041 0.056 0.069 0.113 0.159 0.229 0.304  ||  -1.182 -0.811 -0.517 -0.295 0.193 0.535 0.898 1.181   || dis=0.07 || select=7/8
015/019-th : 0.016 0.022 0.034 0.044 0.065 0.105 0.225 0.488  ||  -1.453 -1.100 -0.670 -0.415 -0.033 0.440 1.205 1.981  || dis=0.26 || select=7/8
016/019-th : 0.056 0.072 0.095 0.131 0.140 0.161 0.169 0.175  ||  -0.722 -0.477 -0.200 0.117 0.189 0.326 0.376 0.409    || dis=0.01 || select=7/8
017/019-th : 0.114 0.113 0.122 0.127 0.124 0.132 0.134 0.134  ||  -0.088 -0.098 -0.019 0.020 -0.000 0.057 0.072 0.074   || dis=0.00 || select=7/8
018/019-th : 0.086 0.101 0.123 0.133 0.131 0.132 0.141 0.154  ||  -0.353 -0.198 0.005 0.081 0.063 0.071 0.138 0.227     || dis=0.01 || select=7/8
[epoch=307/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.088
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:24:49] [epoch=307/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.578 (2.578)  Prec@1 29.69 (29.69) Prec@5 71.09 (71.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:24:55] [epoch=307/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.408 (2.483)  Prec@1 29.76 (34.87) Prec@5 74.40 (79.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.87 Prec@5 79.13 Error@1 65.13 Error@5 20.87 Loss:2.483
***[2020-01-29 08:24:55]*** VALID [epoch=307/600] loss = 2.483293, accuracy@1 = 34.87, accuracy@5 = 79.13 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:24:55]*** start epoch=308/600 Time Left: [02:35:21], LR=[0.047906 ~ 0.047906], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=308, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.4474046483634617, FLOP=40.81
[Search] : epoch=308/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:24:56] [epoch=308/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.804 (0.804)  Prec@1 70.70 (70.70) Prec@5 97.27 (97.27) Acls-loss 0.722 (0.722) FLOP-Loss 0.000 (0.000) Arch-Loss 0.722 (0.722)
**TRAIN** [2020-01-29 08:25:20] [epoch=308/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.791 (0.810)  Prec@1 74.40 (72.44) Prec@5 98.81 (97.66) Acls-loss 0.775 (0.828) FLOP-Loss 0.000 (0.000) Arch-Loss 0.775 (0.828)
 **TRAIN** Prec@1 72.44 Prec@5 97.66 Error@1 27.56 Error@5 2.34 Base-Loss:0.810, Arch-Loss=0.828
***[2020-01-29 08:25:20]*** TRAIN [epoch=308/600] base-loss = 0.809797, arch-loss = 0.828281, accuracy-1 = 72.44, accuracy-5 = 97.66
[epoch=308/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 8, 14, 12, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.454 0.199 0.346  ||  0.3089 -0.5145 0.0370  || discrepancy=0.11 || select=0/3
001/003-th : 0.363 0.130 0.508  ||  0.1063 -0.9235 0.4425  || discrepancy=0.15 || select=2/3
002/003-th : 0.009 0.048 0.943  ||  -2.2515 -0.6215 2.3583  || discrepancy=0.89 || select=2/3
-----------------------------------------------
000/019-th : 0.041 0.065 0.088 0.093 0.138 0.146 0.200 0.229  ||  -0.982 -0.524 -0.211 -0.161 0.234 0.294 0.608 0.742   || dis=0.03 || select=7/8
001/019-th : 0.124 0.132 0.133 0.131 0.132 0.120 0.114 0.113  ||  0.006 0.061 0.074 0.057 0.063 -0.028 -0.082 -0.087    || dis=0.00 || select=2/8
002/019-th : 0.122 0.125 0.136 0.137 0.129 0.123 0.117 0.111  ||  -0.023 0.009 0.089 0.099 0.035 -0.012 -0.062 -0.110   || dis=0.00 || select=3/8
003/019-th : 0.114 0.116 0.133 0.122 0.130 0.127 0.127 0.132  ||  -0.091 -0.074 0.063 -0.022 0.046 0.019 0.016 0.058    || dis=0.00 || select=2/8
004/019-th : 0.116 0.121 0.119 0.119 0.130 0.128 0.136 0.131  ||  -0.071 -0.033 -0.052 -0.045 0.041 0.026 0.084 0.045   || dis=0.01 || select=6/8
005/019-th : 0.106 0.117 0.125 0.126 0.128 0.133 0.133 0.132  ||  -0.163 -0.061 -0.001 0.014 0.026 0.062 0.061 0.058    || dis=0.00 || select=5/8
006/019-th : 0.117 0.113 0.117 0.122 0.127 0.127 0.138 0.138  ||  -0.062 -0.096 -0.065 -0.018 0.021 0.019 0.102 0.102   || dis=0.00 || select=6/8
007/019-th : 0.043 0.055 0.078 0.101 0.129 0.163 0.186 0.245  ||  -0.914 -0.664 -0.308 -0.051 0.193 0.425 0.554 0.830   || dis=0.06 || select=7/8
008/019-th : 0.036 0.051 0.067 0.106 0.126 0.174 0.214 0.226  ||  -1.066 -0.704 -0.442 0.022 0.193 0.514 0.724 0.776    || dis=0.01 || select=7/8
009/019-th : 0.087 0.088 0.105 0.112 0.128 0.134 0.159 0.187  ||  -0.328 -0.317 -0.142 -0.078 0.054 0.100 0.274 0.432   || dis=0.03 || select=7/8
010/019-th : 0.097 0.099 0.110 0.122 0.134 0.140 0.149 0.150  ||  -0.240 -0.220 -0.112 -0.009 0.081 0.127 0.188 0.198   || dis=0.00 || select=7/8
011/019-th : 0.097 0.096 0.106 0.116 0.129 0.137 0.157 0.162  ||  -0.233 -0.248 -0.140 -0.053 0.053 0.111 0.252 0.282   || dis=0.01 || select=7/8
012/019-th : 0.111 0.114 0.115 0.126 0.131 0.129 0.136 0.139  ||  -0.117 -0.087 -0.082 0.013 0.049 0.033 0.090 0.107    || dis=0.00 || select=7/8
013/019-th : 0.020 0.026 0.034 0.049 0.059 0.098 0.212 0.501  ||  -1.252 -0.982 -0.708 -0.353 -0.167 0.337 1.109 1.968  || dis=0.29 || select=7/8
014/019-th : 0.028 0.042 0.054 0.069 0.109 0.158 0.230 0.311  ||  -1.193 -0.801 -0.543 -0.291 0.166 0.536 0.911 1.212   || dis=0.08 || select=7/8
015/019-th : 0.015 0.022 0.034 0.044 0.065 0.102 0.226 0.491  ||  -1.473 -1.094 -0.672 -0.420 -0.029 0.427 1.223 1.999  || dis=0.27 || select=7/8
016/019-th : 0.056 0.072 0.095 0.130 0.140 0.161 0.168 0.177  ||  -0.722 -0.479 -0.198 0.114 0.186 0.326 0.368 0.418    || dis=0.01 || select=7/8
017/019-th : 0.111 0.112 0.122 0.127 0.124 0.133 0.136 0.135  ||  -0.114 -0.104 -0.015 0.022 -0.005 0.069 0.088 0.083   || dis=0.00 || select=6/8
018/019-th : 0.086 0.101 0.122 0.133 0.131 0.134 0.140 0.153  ||  -0.359 -0.191 -0.002 0.083 0.070 0.087 0.133 0.219    || dis=0.01 || select=7/8
[epoch=308/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.089
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:25:21] [epoch=308/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.092 (2.092)  Prec@1 32.81 (32.81) Prec@5 70.70 (70.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:25:27] [epoch=308/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.132 (2.242)  Prec@1 41.07 (39.20) Prec@5 82.14 (82.12) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.20 Prec@5 82.12 Error@1 60.80 Error@5 17.88 Loss:2.242
***[2020-01-29 08:25:27]*** VALID [epoch=308/600] loss = 2.242126, accuracy@1 = 39.20, accuracy@5 = 82.12 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:25:27]*** start epoch=309/600 Time Left: [02:34:49], LR=[0.047645 ~ 0.047645], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=309, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.434589195761376, FLOP=40.81
[Search] : epoch=309/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:25:28] [epoch=309/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.781 (0.781)  Prec@1 72.27 (72.27) Prec@5 99.61 (99.61) Acls-loss 0.784 (0.784) FLOP-Loss 0.000 (0.000) Arch-Loss 0.784 (0.784)
**TRAIN** [2020-01-29 08:25:53] [epoch=309/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.755 (0.764)  Prec@1 77.38 (73.92) Prec@5 95.83 (97.95) Acls-loss 0.720 (0.816) FLOP-Loss 0.000 (0.029) Arch-Loss 0.720 (0.873)
 **TRAIN** Prec@1 73.92 Prec@5 97.95 Error@1 26.08 Error@5 2.05 Base-Loss:0.764, Arch-Loss=0.873
***[2020-01-29 08:25:53]*** TRAIN [epoch=309/600] base-loss = 0.764386, arch-loss = 0.872689, accuracy-1 = 73.92, accuracy-5 = 97.95
[epoch=309/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 12, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.131968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.450 0.202 0.347  ||  0.3026 -0.4971 0.0416  || discrepancy=0.10 || select=0/3
001/003-th : 0.358 0.130 0.512  ||  0.0957 -0.9138 0.4528  || discrepancy=0.15 || select=2/3
002/003-th : 0.009 0.047 0.944  ||  -2.2612 -0.6252 2.3715  || discrepancy=0.90 || select=2/3
-----------------------------------------------
000/019-th : 0.041 0.063 0.089 0.093 0.137 0.146 0.199 0.232  ||  -0.988 -0.542 -0.196 -0.160 0.231 0.291 0.605 0.756   || dis=0.03 || select=7/8
001/019-th : 0.124 0.131 0.132 0.132 0.131 0.120 0.115 0.115  ||  0.003 0.054 0.064 0.061 0.053 -0.037 -0.074 -0.074    || dis=0.00 || select=2/8
002/019-th : 0.119 0.124 0.136 0.136 0.130 0.124 0.118 0.113  ||  -0.041 -0.001 0.087 0.092 0.048 -0.002 -0.053 -0.098  || dis=0.00 || select=3/8
003/019-th : 0.113 0.116 0.132 0.120 0.131 0.128 0.126 0.134  ||  -0.097 -0.075 0.057 -0.037 0.050 0.028 0.013 0.071    || dis=0.00 || select=7/8
004/019-th : 0.114 0.119 0.118 0.118 0.131 0.130 0.138 0.132  ||  -0.088 -0.047 -0.059 -0.054 0.051 0.038 0.098 0.056   || dis=0.01 || select=6/8
005/019-th : 0.106 0.118 0.123 0.126 0.128 0.135 0.132 0.133  ||  -0.163 -0.059 -0.016 0.009 0.024 0.079 0.055 0.065    || dis=0.00 || select=5/8
006/019-th : 0.117 0.112 0.116 0.122 0.128 0.128 0.138 0.140  ||  -0.064 -0.110 -0.070 -0.023 0.025 0.023 0.098 0.116   || dis=0.00 || select=7/8
007/019-th : 0.043 0.055 0.079 0.101 0.130 0.162 0.184 0.247  ||  -0.915 -0.662 -0.303 -0.055 0.195 0.418 0.545 0.839   || dis=0.06 || select=7/8
008/019-th : 0.036 0.050 0.067 0.104 0.126 0.174 0.213 0.230  ||  -1.062 -0.731 -0.441 0.007 0.201 0.520 0.723 0.800    || dis=0.02 || select=7/8
009/019-th : 0.084 0.088 0.105 0.111 0.127 0.136 0.163 0.186  ||  -0.360 -0.317 -0.139 -0.084 0.053 0.119 0.300 0.433   || dis=0.02 || select=7/8
010/019-th : 0.096 0.099 0.107 0.123 0.134 0.140 0.150 0.151  ||  -0.247 -0.217 -0.138 -0.004 0.087 0.127 0.196 0.205   || dis=0.00 || select=7/8
011/019-th : 0.093 0.097 0.107 0.114 0.131 0.138 0.155 0.165  ||  -0.268 -0.233 -0.136 -0.072 0.069 0.123 0.241 0.299   || dis=0.01 || select=7/8
012/019-th : 0.110 0.113 0.113 0.125 0.133 0.129 0.136 0.140  ||  -0.121 -0.094 -0.094 0.006 0.066 0.034 0.091 0.115    || dis=0.00 || select=7/8
013/019-th : 0.019 0.026 0.034 0.050 0.059 0.098 0.210 0.503  ||  -1.279 -0.981 -0.714 -0.334 -0.161 0.339 1.102 1.976  || dis=0.29 || select=7/8
014/019-th : 0.027 0.041 0.053 0.069 0.107 0.155 0.234 0.314  ||  -1.237 -0.797 -0.542 -0.279 0.156 0.526 0.941 1.233   || dis=0.08 || select=7/8
015/019-th : 0.015 0.022 0.034 0.043 0.065 0.101 0.224 0.496  ||  -1.468 -1.096 -0.681 -0.422 -0.026 0.420 1.219 2.012  || dis=0.27 || select=7/8
016/019-th : 0.056 0.072 0.095 0.131 0.139 0.159 0.170 0.177  ||  -0.726 -0.480 -0.199 0.119 0.182 0.316 0.380 0.420    || dis=0.01 || select=7/8
017/019-th : 0.109 0.111 0.124 0.124 0.123 0.135 0.138 0.137  ||  -0.135 -0.113 -0.002 0.001 -0.007 0.082 0.102 0.096   || dis=0.00 || select=6/8
018/019-th : 0.085 0.100 0.121 0.134 0.133 0.134 0.140 0.153  ||  -0.364 -0.202 -0.016 0.093 0.080 0.087 0.134 0.225    || dis=0.01 || select=7/8
[epoch=309/600] FLOP : 28.13 MB, ratio : 0.6893, Expected-ratio : 0.7000, Discrepancy : 0.090
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:25:53] [epoch=309/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.291 (1.291)  Prec@1 55.86 (55.86) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:25:59] [epoch=309/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.605 (2.335)  Prec@1 29.17 (36.86) Prec@5 72.62 (81.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.86 Prec@5 81.06 Error@1 63.14 Error@5 18.94 Loss:2.335
***[2020-01-29 08:25:59]*** VALID [epoch=309/600] loss = 2.334912, accuracy@1 = 36.86, accuracy@5 = 81.06 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:25:59]*** start epoch=310/600 Time Left: [02:34:18], LR=[0.047383 ~ 0.047383], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=310, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.4217769072047877, FLOP=40.81
[Search] : epoch=310/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:26:00] [epoch=310/600][000/098] Time 0.77 (0.77) Data 0.37 (0.37) Base-Loss 1.055 (1.055)  Prec@1 62.11 (62.11) Prec@5 96.88 (96.88) Acls-loss 0.742 (0.742) FLOP-Loss 0.000 (0.000) Arch-Loss 0.742 (0.742)
**TRAIN** [2020-01-29 08:26:25] [epoch=310/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.807 (0.762)  Prec@1 72.02 (73.97) Prec@5 97.62 (98.08) Acls-loss 0.768 (0.816) FLOP-Loss 0.000 (0.086) Arch-Loss 0.768 (0.988)
 **TRAIN** Prec@1 73.97 Prec@5 98.08 Error@1 26.03 Error@5 1.92 Base-Loss:0.762, Arch-Loss=0.988
***[2020-01-29 08:26:25]*** TRAIN [epoch=310/600] base-loss = 0.761826, arch-loss = 0.987921, accuracy-1 = 73.97, accuracy-5 = 98.08
[epoch=310/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 8, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.42688)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.452 0.203 0.345  ||  0.3065 -0.4917 0.0377  || discrepancy=0.11 || select=0/3
001/003-th : 0.357 0.129 0.513  ||  0.0947 -0.9210 0.4567  || discrepancy=0.16 || select=2/3
002/003-th : 0.009 0.046 0.945  ||  -2.2687 -0.6388 2.3874  || discrepancy=0.90 || select=2/3
-----------------------------------------------
000/019-th : 0.040 0.063 0.091 0.091 0.137 0.146 0.198 0.235  ||  -1.000 -0.548 -0.182 -0.172 0.234 0.296 0.598 0.770   || dis=0.04 || select=7/8
001/019-th : 0.126 0.132 0.132 0.132 0.131 0.118 0.114 0.115  ||  0.014 0.062 0.064 0.057 0.050 -0.049 -0.087 -0.075    || dis=0.00 || select=2/8
002/019-th : 0.119 0.124 0.136 0.134 0.132 0.125 0.118 0.112  ||  -0.042 -0.005 0.087 0.077 0.063 0.003 -0.049 -0.101   || dis=0.00 || select=2/8
003/019-th : 0.113 0.116 0.134 0.122 0.131 0.127 0.125 0.133  ||  -0.096 -0.075 0.073 -0.021 0.049 0.016 0.000 0.067    || dis=0.00 || select=2/8
004/019-th : 0.114 0.118 0.119 0.120 0.132 0.127 0.137 0.133  ||  -0.090 -0.055 -0.051 -0.037 0.053 0.021 0.091 0.065   || dis=0.00 || select=6/8
005/019-th : 0.105 0.118 0.123 0.126 0.127 0.135 0.132 0.133  ||  -0.168 -0.054 -0.017 0.012 0.019 0.082 0.054 0.068    || dis=0.00 || select=5/8
006/019-th : 0.117 0.112 0.117 0.121 0.127 0.126 0.139 0.141  ||  -0.063 -0.111 -0.064 -0.028 0.015 0.012 0.107 0.122   || dis=0.00 || select=7/8
007/019-th : 0.043 0.055 0.079 0.101 0.130 0.161 0.184 0.247  ||  -0.904 -0.669 -0.298 -0.061 0.195 0.411 0.546 0.837   || dis=0.06 || select=7/8
008/019-th : 0.035 0.050 0.067 0.105 0.127 0.176 0.212 0.229  ||  -1.072 -0.725 -0.441 0.011 0.202 0.533 0.718 0.794    || dis=0.02 || select=7/8
009/019-th : 0.085 0.089 0.104 0.109 0.128 0.137 0.162 0.187  ||  -0.353 -0.302 -0.151 -0.106 0.058 0.123 0.292 0.440   || dis=0.02 || select=7/8
010/019-th : 0.096 0.099 0.108 0.121 0.134 0.140 0.152 0.151  ||  -0.251 -0.217 -0.134 -0.015 0.082 0.125 0.210 0.206   || dis=0.00 || select=6/8
011/019-th : 0.093 0.098 0.108 0.114 0.131 0.137 0.156 0.164  ||  -0.274 -0.222 -0.127 -0.074 0.066 0.113 0.244 0.296   || dis=0.01 || select=7/8
012/019-th : 0.110 0.113 0.113 0.124 0.133 0.129 0.136 0.141  ||  -0.126 -0.097 -0.096 -0.001 0.063 0.038 0.092 0.126   || dis=0.00 || select=7/8
013/019-th : 0.019 0.026 0.033 0.049 0.059 0.097 0.208 0.508  ||  -1.290 -0.994 -0.728 -0.337 -0.152 0.344 1.104 1.996  || dis=0.30 || select=7/8
014/019-th : 0.027 0.041 0.053 0.068 0.106 0.153 0.239 0.312  ||  -1.237 -0.797 -0.535 -0.289 0.148 0.517 0.962 1.229   || dis=0.07 || select=7/8
015/019-th : 0.015 0.022 0.032 0.043 0.064 0.100 0.223 0.500  ||  -1.456 -1.092 -0.708 -0.423 -0.029 0.419 1.220 2.027  || dis=0.28 || select=7/8
016/019-th : 0.056 0.073 0.095 0.131 0.140 0.158 0.171 0.176  ||  -0.724 -0.471 -0.203 0.119 0.188 0.306 0.384 0.413    || dis=0.00 || select=7/8
017/019-th : 0.109 0.113 0.121 0.123 0.124 0.136 0.137 0.137  ||  -0.131 -0.097 -0.023 -0.009 -0.001 0.089 0.096 0.097  || dis=0.00 || select=7/8
018/019-th : 0.085 0.099 0.121 0.134 0.134 0.135 0.140 0.153  ||  -0.371 -0.210 -0.014 0.088 0.088 0.097 0.136 0.223    || dis=0.01 || select=7/8
[epoch=310/600] FLOP : 28.43 MB, ratio : 0.6965, Expected-ratio : 0.7000, Discrepancy : 0.091
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:26:25] [epoch=310/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 6.580 (6.580)  Prec@1 16.02 (16.02) Prec@5 67.19 (67.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:26:31] [epoch=310/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.243 (2.443)  Prec@1 19.05 (39.36) Prec@5 74.40 (82.57) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.36 Prec@5 82.57 Error@1 60.64 Error@5 17.43 Loss:2.443
***[2020-01-29 08:26:31]*** VALID [epoch=310/600] loss = 2.442716, accuracy@1 = 39.36, accuracy@5 = 82.57 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:26:31]*** start epoch=311/600 Time Left: [02:33:46], LR=[0.047122 ~ 0.047122], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=311, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.4089681339490605, FLOP=40.81
[Search] : epoch=311/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:26:32] [epoch=311/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.586 (0.586)  Prec@1 80.86 (80.86) Prec@5 99.61 (99.61) Acls-loss 0.619 (0.619) FLOP-Loss 0.000 (0.000) Arch-Loss 0.619 (0.619)
**TRAIN** [2020-01-29 08:26:57] [epoch=311/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.708 (0.773)  Prec@1 74.40 (73.78) Prec@5 98.81 (98.13) Acls-loss 0.857 (0.815) FLOP-Loss 0.000 (0.057) Arch-Loss 0.857 (0.929)
 **TRAIN** Prec@1 73.78 Prec@5 98.13 Error@1 26.22 Error@5 1.87 Base-Loss:0.773, Arch-Loss=0.929
***[2020-01-29 08:26:57]*** TRAIN [epoch=311/600] base-loss = 0.772726, arch-loss = 0.928944, accuracy-1 = 73.78, accuracy-5 = 98.13
[epoch=311/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.42688)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.452 0.202 0.346  ||  0.3066 -0.4996 0.0398  || discrepancy=0.11 || select=0/3
001/003-th : 0.354 0.128 0.518  ||  0.0867 -0.9339 0.4682  || discrepancy=0.16 || select=2/3
002/003-th : 0.009 0.044 0.947  ||  -2.2680 -0.6602 2.4003  || discrepancy=0.90 || select=2/3
-----------------------------------------------
000/019-th : 0.040 0.063 0.092 0.092 0.135 0.145 0.197 0.237  ||  -0.994 -0.550 -0.172 -0.167 0.218 0.286 0.592 0.777   || dis=0.04 || select=7/8
001/019-th : 0.125 0.132 0.133 0.132 0.130 0.119 0.114 0.115  ||  0.008 0.062 0.069 0.060 0.048 -0.044 -0.086 -0.076    || dis=0.00 || select=2/8
002/019-th : 0.120 0.123 0.134 0.132 0.133 0.125 0.120 0.114  ||  -0.038 -0.012 0.072 0.059 0.066 0.002 -0.041 -0.090   || dis=0.00 || select=2/8
003/019-th : 0.111 0.116 0.134 0.122 0.129 0.127 0.127 0.135  ||  -0.116 -0.071 0.074 -0.023 0.033 0.019 0.017 0.078    || dis=0.00 || select=7/8
004/019-th : 0.115 0.118 0.118 0.122 0.129 0.128 0.136 0.134  ||  -0.085 -0.057 -0.057 -0.026 0.036 0.028 0.087 0.068   || dis=0.00 || select=6/8
005/019-th : 0.106 0.117 0.122 0.127 0.125 0.136 0.131 0.136  ||  -0.163 -0.062 -0.025 0.017 -0.003 0.089 0.050 0.083   || dis=0.00 || select=5/8
006/019-th : 0.117 0.111 0.117 0.124 0.128 0.124 0.138 0.140  ||  -0.060 -0.114 -0.065 -0.009 0.025 -0.004 0.104 0.118  || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.080 0.100 0.130 0.161 0.182 0.248  ||  -0.892 -0.665 -0.295 -0.067 0.190 0.405 0.532 0.841   || dis=0.07 || select=7/8
008/019-th : 0.035 0.051 0.067 0.103 0.128 0.177 0.212 0.227  ||  -1.077 -0.715 -0.435 -0.001 0.210 0.536 0.716 0.785   || dis=0.02 || select=7/8
009/019-th : 0.083 0.088 0.104 0.108 0.128 0.135 0.163 0.191  ||  -0.369 -0.313 -0.148 -0.107 0.058 0.116 0.302 0.459   || dis=0.03 || select=7/8
010/019-th : 0.096 0.098 0.109 0.119 0.133 0.141 0.153 0.150  ||  -0.248 -0.225 -0.123 -0.031 0.078 0.137 0.221 0.200   || dis=0.00 || select=6/8
011/019-th : 0.093 0.098 0.107 0.113 0.131 0.136 0.157 0.165  ||  -0.278 -0.218 -0.135 -0.075 0.073 0.109 0.247 0.297   || dis=0.01 || select=7/8
012/019-th : 0.109 0.114 0.113 0.125 0.133 0.127 0.138 0.141  ||  -0.133 -0.093 -0.099 0.006 0.063 0.023 0.102 0.127    || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.032 0.049 0.059 0.096 0.207 0.512  ||  -1.295 -0.993 -0.754 -0.329 -0.151 0.340 1.109 2.014  || dis=0.31 || select=7/8
014/019-th : 0.026 0.041 0.054 0.068 0.104 0.152 0.240 0.315  ||  -1.239 -0.800 -0.527 -0.298 0.135 0.511 0.971 1.243   || dis=0.08 || select=7/8
015/019-th : 0.015 0.022 0.032 0.043 0.063 0.101 0.224 0.501  ||  -1.471 -1.092 -0.718 -0.428 -0.035 0.432 1.233 2.039  || dis=0.28 || select=7/8
016/019-th : 0.055 0.072 0.093 0.131 0.140 0.160 0.173 0.176  ||  -0.750 -0.472 -0.221 0.126 0.193 0.323 0.399 0.417    || dis=0.00 || select=7/8
017/019-th : 0.109 0.113 0.120 0.123 0.123 0.137 0.136 0.139  ||  -0.134 -0.094 -0.038 -0.011 -0.007 0.096 0.092 0.112  || dis=0.00 || select=7/8
018/019-th : 0.085 0.099 0.120 0.131 0.134 0.137 0.141 0.154  ||  -0.369 -0.211 -0.022 0.071 0.086 0.111 0.139 0.227    || dis=0.01 || select=7/8
[epoch=311/600] FLOP : 28.43 MB, ratio : 0.6965, Expected-ratio : 0.7000, Discrepancy : 0.092
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:26:57] [epoch=311/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.507 (2.507)  Prec@1 23.83 (23.83) Prec@5 69.53 (69.53) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:27:03] [epoch=311/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.476 (2.421)  Prec@1 50.60 (34.30) Prec@5 94.05 (78.48) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.30 Prec@5 78.48 Error@1 65.70 Error@5 21.52 Loss:2.421
***[2020-01-29 08:27:03]*** VALID [epoch=311/600] loss = 2.420668, accuracy@1 = 34.30, accuracy@5 = 78.48 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:27:04]*** start epoch=312/600 Time Left: [02:33:14], LR=[0.046860 ~ 0.046860], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=312, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.3961632271531825, FLOP=40.81
[Search] : epoch=312/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:27:04] [epoch=312/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.946 (0.946)  Prec@1 64.84 (64.84) Prec@5 96.09 (96.09) Acls-loss 0.917 (0.917) FLOP-Loss 0.000 (0.000) Arch-Loss 0.917 (0.917)
**TRAIN** [2020-01-29 08:27:29] [epoch=312/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.682 (0.763)  Prec@1 76.19 (74.03) Prec@5 98.81 (98.09) Acls-loss 0.866 (0.799) FLOP-Loss 0.000 (0.029) Arch-Loss 0.866 (0.857)
 **TRAIN** Prec@1 74.03 Prec@5 98.09 Error@1 25.97 Error@5 1.91 Base-Loss:0.763, Arch-Loss=0.857
***[2020-01-29 08:27:29]*** TRAIN [epoch=312/600] base-loss = 0.762583, arch-loss = 0.856581, accuracy-1 = 74.03, accuracy-5 = 98.09
[epoch=312/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 14, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.42688)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.452 0.200 0.348  ||  0.3048 -0.5111 0.0445  || discrepancy=0.10 || select=0/3
001/003-th : 0.350 0.127 0.523  ||  0.0772 -0.9394 0.4799  || discrepancy=0.17 || select=2/3
002/003-th : 0.009 0.044 0.948  ||  -2.2736 -0.6672 2.4119  || discrepancy=0.90 || select=2/3
-----------------------------------------------
000/019-th : 0.040 0.063 0.091 0.092 0.134 0.145 0.197 0.238  ||  -0.997 -0.549 -0.176 -0.167 0.211 0.289 0.596 0.782   || dis=0.04 || select=7/8
001/019-th : 0.123 0.131 0.133 0.131 0.131 0.121 0.114 0.116  ||  -0.005 0.056 0.069 0.058 0.051 -0.023 -0.086 -0.070   || dis=0.00 || select=2/8
002/019-th : 0.118 0.122 0.135 0.132 0.133 0.124 0.121 0.115  ||  -0.051 -0.021 0.078 0.057 0.066 -0.003 -0.028 -0.081  || dis=0.00 || select=2/8
003/019-th : 0.109 0.115 0.133 0.123 0.129 0.129 0.127 0.135  ||  -0.131 -0.079 0.067 -0.014 0.035 0.036 0.022 0.083    || dis=0.00 || select=7/8
004/019-th : 0.113 0.117 0.121 0.122 0.130 0.129 0.134 0.134  ||  -0.102 -0.063 -0.032 -0.023 0.043 0.036 0.076 0.072   || dis=0.00 || select=6/8
005/019-th : 0.104 0.117 0.120 0.126 0.127 0.138 0.132 0.136  ||  -0.180 -0.064 -0.033 0.013 0.017 0.105 0.056 0.086    || dis=0.00 || select=5/8
006/019-th : 0.117 0.111 0.119 0.123 0.127 0.123 0.139 0.140  ||  -0.066 -0.112 -0.048 -0.010 0.021 -0.010 0.111 0.115  || dis=0.00 || select=7/8
007/019-th : 0.043 0.055 0.082 0.101 0.127 0.161 0.182 0.249  ||  -0.905 -0.674 -0.268 -0.060 0.174 0.409 0.531 0.844   || dis=0.07 || select=7/8
008/019-th : 0.035 0.050 0.066 0.102 0.127 0.177 0.212 0.230  ||  -1.077 -0.721 -0.440 -0.011 0.211 0.540 0.720 0.799   || dis=0.02 || select=7/8
009/019-th : 0.083 0.088 0.101 0.109 0.128 0.138 0.163 0.190  ||  -0.374 -0.314 -0.172 -0.100 0.064 0.139 0.303 0.458   || dis=0.03 || select=7/8
010/019-th : 0.094 0.098 0.108 0.118 0.133 0.142 0.155 0.151  ||  -0.265 -0.227 -0.130 -0.039 0.079 0.147 0.230 0.209   || dis=0.00 || select=6/8
011/019-th : 0.092 0.096 0.108 0.113 0.133 0.138 0.156 0.164  ||  -0.281 -0.236 -0.122 -0.078 0.083 0.123 0.245 0.292   || dis=0.01 || select=7/8
012/019-th : 0.109 0.113 0.113 0.122 0.134 0.128 0.139 0.144  ||  -0.137 -0.101 -0.101 -0.022 0.072 0.024 0.109 0.142   || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.032 0.048 0.058 0.097 0.205 0.517  ||  -1.285 -0.991 -0.754 -0.352 -0.157 0.352 1.102 2.028  || dis=0.31 || select=7/8
014/019-th : 0.027 0.041 0.054 0.067 0.103 0.153 0.242 0.313  ||  -1.233 -0.800 -0.520 -0.303 0.119 0.518 0.979 1.236   || dis=0.07 || select=7/8
015/019-th : 0.015 0.022 0.031 0.042 0.062 0.100 0.222 0.506  ||  -1.469 -1.082 -0.722 -0.444 -0.050 0.434 1.235 2.058  || dis=0.28 || select=7/8
016/019-th : 0.055 0.071 0.093 0.130 0.140 0.163 0.173 0.175  ||  -0.751 -0.488 -0.214 0.119 0.190 0.342 0.405 0.413    || dis=0.00 || select=7/8
017/019-th : 0.106 0.111 0.118 0.123 0.124 0.135 0.140 0.142  ||  -0.157 -0.108 -0.046 -0.010 0.002 0.086 0.119 0.132   || dis=0.00 || select=7/8
018/019-th : 0.084 0.098 0.118 0.133 0.132 0.137 0.141 0.156  ||  -0.372 -0.218 -0.040 0.084 0.077 0.110 0.140 0.242    || dis=0.02 || select=7/8
[epoch=312/600] FLOP : 28.43 MB, ratio : 0.6965, Expected-ratio : 0.7000, Discrepancy : 0.093
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:27:30] [epoch=312/600][000/098] Time 0.39 (0.39) Data 0.31 (0.31) Loss 2.454 (2.454)  Prec@1 49.61 (49.61) Prec@5 90.23 (90.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:27:36] [epoch=312/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.901 (2.285)  Prec@1 38.69 (37.09) Prec@5 85.12 (80.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.09 Prec@5 80.62 Error@1 62.91 Error@5 19.38 Loss:2.285
***[2020-01-29 08:27:36]*** VALID [epoch=312/600] loss = 2.284728, accuracy@1 = 37.09, accuracy@5 = 80.62 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:27:36]*** start epoch=313/600 Time Left: [02:32:43], LR=[0.046599 ~ 0.046599], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=313, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.383362537870143, FLOP=40.81
[Search] : epoch=313/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:27:36] [epoch=313/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.865 (0.865)  Prec@1 66.41 (66.41) Prec@5 96.88 (96.88) Acls-loss 0.881 (0.881) FLOP-Loss 0.000 (0.000) Arch-Loss 0.881 (0.881)
**TRAIN** [2020-01-29 08:28:01] [epoch=313/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.887 (0.750)  Prec@1 69.64 (74.18) Prec@5 97.62 (98.12) Acls-loss 0.820 (0.818) FLOP-Loss 2.788 (0.219) Arch-Loss 6.396 (1.256)
 **TRAIN** Prec@1 74.18 Prec@5 98.12 Error@1 25.82 Error@5 1.88 Base-Loss:0.750, Arch-Loss=1.256
***[2020-01-29 08:28:02]*** TRAIN [epoch=313/600] base-loss = 0.750067, arch-loss = 1.256305, accuracy-1 = 74.18, accuracy-5 = 98.12
[epoch=313/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 8, 16, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.463 0.195 0.342  ||  0.3285 -0.5350 0.0253  || discrepancy=0.12 || select=0/3
001/003-th : 0.359 0.126 0.515  ||  0.1010 -0.9450 0.4602  || discrepancy=0.16 || select=2/3
002/003-th : 0.009 0.043 0.948  ||  -2.2750 -0.6707 2.4188  || discrepancy=0.90 || select=2/3
-----------------------------------------------
000/019-th : 0.041 0.062 0.093 0.094 0.133 0.144 0.195 0.239  ||  -0.982 -0.558 -0.159 -0.153 0.199 0.275 0.580 0.783   || dis=0.04 || select=7/8
001/019-th : 0.125 0.134 0.135 0.135 0.129 0.119 0.111 0.112  ||  0.010 0.082 0.084 0.091 0.045 -0.038 -0.111 -0.102    || dis=0.00 || select=3/8
002/019-th : 0.120 0.123 0.137 0.135 0.130 0.123 0.119 0.112  ||  -0.037 -0.007 0.100 0.085 0.047 -0.014 -0.042 -0.106  || dis=0.00 || select=2/8
003/019-th : 0.110 0.117 0.136 0.124 0.128 0.129 0.124 0.132  ||  -0.121 -0.063 0.086 -0.006 0.028 0.038 0.000 0.059    || dis=0.00 || select=2/8
004/019-th : 0.114 0.118 0.121 0.123 0.129 0.130 0.132 0.133  ||  -0.092 -0.052 -0.028 -0.010 0.033 0.040 0.055 0.064   || dis=0.00 || select=7/8
005/019-th : 0.106 0.118 0.124 0.128 0.127 0.135 0.129 0.134  ||  -0.164 -0.056 -0.007 0.028 0.019 0.077 0.031 0.069    || dis=0.00 || select=5/8
006/019-th : 0.120 0.112 0.119 0.124 0.127 0.122 0.137 0.138  ||  -0.035 -0.105 -0.048 -0.003 0.019 -0.022 0.095 0.101  || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.081 0.100 0.129 0.164 0.180 0.246  ||  -0.887 -0.668 -0.277 -0.072 0.186 0.422 0.515 0.829   || dis=0.07 || select=7/8
008/019-th : 0.035 0.051 0.068 0.104 0.130 0.174 0.212 0.227  ||  -1.083 -0.714 -0.421 0.003 0.222 0.520 0.713 0.781    || dis=0.02 || select=7/8
009/019-th : 0.084 0.088 0.101 0.110 0.128 0.139 0.161 0.189  ||  -0.356 -0.312 -0.176 -0.089 0.058 0.141 0.292 0.449   || dis=0.03 || select=7/8
010/019-th : 0.095 0.099 0.108 0.119 0.134 0.143 0.153 0.149  ||  -0.253 -0.217 -0.129 -0.036 0.086 0.152 0.221 0.189   || dis=0.00 || select=6/8
011/019-th : 0.094 0.098 0.110 0.115 0.131 0.138 0.153 0.161  ||  -0.265 -0.220 -0.112 -0.066 0.069 0.122 0.223 0.274   || dis=0.01 || select=7/8
012/019-th : 0.111 0.114 0.116 0.122 0.133 0.126 0.138 0.141  ||  -0.116 -0.094 -0.074 -0.021 0.065 0.011 0.098 0.122   || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.032 0.048 0.058 0.100 0.204 0.513  ||  -1.270 -1.006 -0.753 -0.354 -0.168 0.383 1.094 2.014  || dis=0.31 || select=7/8
014/019-th : 0.027 0.041 0.054 0.068 0.104 0.151 0.243 0.312  ||  -1.227 -0.800 -0.524 -0.295 0.129 0.503 0.979 1.228   || dis=0.07 || select=7/8
015/019-th : 0.014 0.022 0.032 0.041 0.062 0.101 0.221 0.507  ||  -1.496 -1.095 -0.705 -0.444 -0.035 0.449 1.231 2.063  || dis=0.29 || select=7/8
016/019-th : 0.055 0.072 0.093 0.131 0.142 0.161 0.169 0.175  ||  -0.741 -0.476 -0.215 0.125 0.206 0.331 0.380 0.411    || dis=0.01 || select=7/8
017/019-th : 0.108 0.113 0.121 0.123 0.124 0.134 0.137 0.139  ||  -0.141 -0.092 -0.025 -0.010 -0.001 0.079 0.099 0.109  || dis=0.00 || select=7/8
018/019-th : 0.085 0.099 0.118 0.134 0.130 0.136 0.144 0.155  ||  -0.366 -0.211 -0.038 0.085 0.057 0.100 0.158 0.235    || dis=0.01 || select=7/8
[epoch=313/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.093
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:28:02] [epoch=313/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 6.310 (6.310)  Prec@1 14.45 (14.45) Prec@5 57.03 (57.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:28:08] [epoch=313/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.158 (2.321)  Prec@1 55.36 (37.29) Prec@5 93.45 (80.46) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.29 Prec@5 80.46 Error@1 62.71 Error@5 19.54 Loss:2.321
***[2020-01-29 08:28:08]*** VALID [epoch=313/600] loss = 2.320568, accuracy@1 = 37.29, accuracy@5 = 80.46 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:28:08]*** start epoch=314/600 Time Left: [02:32:11], LR=[0.046338 ~ 0.046338], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=314, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.370566417037303, FLOP=40.81
[Search] : epoch=314/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:28:09] [epoch=314/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 1.062 (1.062)  Prec@1 66.41 (66.41) Prec@5 95.70 (95.70) Acls-loss 0.862 (0.862) FLOP-Loss 2.786 (2.786) Arch-Loss 6.434 (6.434)
**TRAIN** [2020-01-29 08:28:33] [epoch=314/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.701 (0.760)  Prec@1 75.00 (74.39) Prec@5 97.62 (98.07) Acls-loss 0.893 (0.808) FLOP-Loss 0.000 (0.142) Arch-Loss 0.893 (1.093)
 **TRAIN** Prec@1 74.39 Prec@5 98.07 Error@1 25.61 Error@5 1.93 Base-Loss:0.760, Arch-Loss=1.093
***[2020-01-29 08:28:33]*** TRAIN [epoch=314/600] base-loss = 0.760038, arch-loss = 1.092731, accuracy-1 = 74.39, accuracy-5 = 98.07
[epoch=314/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 8, 12, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.42688)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.469 0.193 0.338  ||  0.3415 -0.5471 0.0149  || discrepancy=0.13 || select=0/3
001/003-th : 0.364 0.125 0.511  ||  0.1121 -0.9556 0.4530  || discrepancy=0.15 || select=2/3
002/003-th : 0.008 0.043 0.949  ||  -2.3000 -0.6621 2.4386  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.041 0.063 0.094 0.096 0.135 0.142 0.192 0.236  ||  -0.975 -0.546 -0.155 -0.134 0.206 0.262 0.563 0.769   || dis=0.04 || select=7/8
001/019-th : 0.125 0.133 0.136 0.135 0.130 0.119 0.112 0.111  ||  0.014 0.076 0.092 0.085 0.047 -0.041 -0.104 -0.111    || dis=0.00 || select=2/8
002/019-th : 0.122 0.126 0.140 0.135 0.129 0.120 0.118 0.111  ||  -0.019 0.009 0.116 0.082 0.031 -0.035 -0.055 -0.118   || dis=0.01 || select=2/8
003/019-th : 0.111 0.118 0.138 0.124 0.127 0.129 0.123 0.131  ||  -0.117 -0.054 0.100 0.000 0.017 0.034 -0.014 0.053    || dis=0.01 || select=2/8
004/019-th : 0.115 0.119 0.121 0.125 0.128 0.131 0.130 0.131  ||  -0.084 -0.042 -0.031 0.001 0.026 0.054 0.046 0.048    || dis=0.00 || select=5/8
005/019-th : 0.107 0.119 0.124 0.128 0.126 0.134 0.129 0.132  ||  -0.151 -0.047 -0.007 0.021 0.012 0.067 0.035 0.058    || dis=0.00 || select=5/8
006/019-th : 0.122 0.115 0.118 0.125 0.128 0.120 0.135 0.137  ||  -0.025 -0.084 -0.056 0.001 0.025 -0.037 0.083 0.095   || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.083 0.098 0.133 0.163 0.182 0.243  ||  -0.883 -0.677 -0.262 -0.093 0.215 0.415 0.525 0.816   || dis=0.06 || select=7/8
008/019-th : 0.036 0.051 0.068 0.105 0.131 0.174 0.211 0.224  ||  -1.073 -0.719 -0.418 0.012 0.229 0.517 0.709 0.765    || dis=0.01 || select=7/8
009/019-th : 0.084 0.089 0.101 0.112 0.128 0.137 0.159 0.188  ||  -0.358 -0.303 -0.175 -0.071 0.060 0.131 0.280 0.444   || dis=0.03 || select=7/8
010/019-th : 0.096 0.100 0.109 0.120 0.133 0.144 0.152 0.145  ||  -0.245 -0.211 -0.118 -0.025 0.075 0.160 0.214 0.168   || dis=0.01 || select=6/8
011/019-th : 0.095 0.100 0.111 0.115 0.130 0.139 0.149 0.161  ||  -0.261 -0.200 -0.103 -0.065 0.057 0.123 0.196 0.273   || dis=0.01 || select=7/8
012/019-th : 0.113 0.113 0.116 0.122 0.134 0.125 0.137 0.141  ||  -0.099 -0.096 -0.077 -0.022 0.070 -0.001 0.093 0.122  || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.032 0.047 0.058 0.099 0.206 0.514  ||  -1.267 -1.001 -0.748 -0.378 -0.160 0.375 1.104 2.019  || dis=0.31 || select=7/8
014/019-th : 0.027 0.041 0.054 0.069 0.105 0.148 0.244 0.312  ||  -1.218 -0.800 -0.529 -0.284 0.134 0.483 0.979 1.225   || dis=0.07 || select=7/8
015/019-th : 0.015 0.021 0.032 0.041 0.062 0.101 0.223 0.506  ||  -1.490 -1.100 -0.708 -0.449 -0.042 0.450 1.242 2.061  || dis=0.28 || select=7/8
016/019-th : 0.055 0.072 0.095 0.132 0.143 0.160 0.169 0.175  ||  -0.741 -0.474 -0.198 0.125 0.206 0.320 0.373 0.409    || dis=0.01 || select=7/8
017/019-th : 0.110 0.114 0.121 0.125 0.124 0.133 0.137 0.137  ||  -0.121 -0.091 -0.027 0.004 -0.007 0.064 0.094 0.097   || dis=0.00 || select=7/8
018/019-th : 0.086 0.100 0.120 0.133 0.130 0.136 0.142 0.155  ||  -0.358 -0.209 -0.026 0.082 0.055 0.101 0.144 0.231    || dis=0.01 || select=7/8
[epoch=314/600] FLOP : 28.43 MB, ratio : 0.6965, Expected-ratio : 0.7000, Discrepancy : 0.093
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:28:34] [epoch=314/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.305 (2.305)  Prec@1 30.08 (30.08) Prec@5 70.70 (70.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:28:40] [epoch=314/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.498 (2.428)  Prec@1 43.45 (35.02) Prec@5 88.10 (80.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.02 Prec@5 80.14 Error@1 64.98 Error@5 19.86 Loss:2.428
***[2020-01-29 08:28:40]*** VALID [epoch=314/600] loss = 2.427954, accuracy@1 = 35.02, accuracy@5 = 80.14 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:28:40]*** start epoch=315/600 Time Left: [02:31:39], LR=[0.046077 ~ 0.046077], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=315, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.3577752154667806, FLOP=40.81
[Search] : epoch=315/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:28:41] [epoch=315/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.687 (0.687)  Prec@1 74.22 (74.22) Prec@5 98.83 (98.83) Acls-loss 1.036 (1.036) FLOP-Loss 0.000 (0.000) Arch-Loss 1.036 (1.036)
**TRAIN** [2020-01-29 08:29:06] [epoch=315/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.784 (0.761)  Prec@1 73.21 (74.09) Prec@5 98.81 (98.06) Acls-loss 0.777 (0.789) FLOP-Loss 0.000 (0.341) Arch-Loss 0.777 (1.470)
 **TRAIN** Prec@1 74.09 Prec@5 98.06 Error@1 25.91 Error@5 1.94 Base-Loss:0.761, Arch-Loss=1.470
***[2020-01-29 08:29:06]*** TRAIN [epoch=315/600] base-loss = 0.760737, arch-loss = 1.470258, accuracy-1 = 74.09, accuracy-5 = 98.06
[epoch=315/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 8, 8, 12, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.984512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.488 0.188 0.324  ||  0.3839 -0.5680 -0.0246  || discrepancy=0.16 || select=0/3
001/003-th : 0.381 0.126 0.492  ||  0.1561 -0.9484 0.4115  || discrepancy=0.11 || select=2/3
002/003-th : 0.008 0.043 0.949  ||  -2.2927 -0.6608 2.4367  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.064 0.095 0.100 0.137 0.143 0.190 0.229  ||  -0.945 -0.547 -0.151 -0.102 0.214 0.263 0.544 0.730   || dis=0.04 || select=7/8
001/019-th : 0.129 0.138 0.137 0.138 0.128 0.116 0.107 0.106  ||  0.046 0.114 0.102 0.108 0.038 -0.059 -0.142 -0.151    || dis=0.00 || select=1/8
002/019-th : 0.128 0.131 0.141 0.137 0.126 0.117 0.113 0.107  ||  0.028 0.054 0.123 0.094 0.014 -0.066 -0.102 -0.153    || dis=0.00 || select=2/8
003/019-th : 0.114 0.121 0.141 0.124 0.126 0.127 0.120 0.127  ||  -0.086 -0.030 0.127 -0.005 0.013 0.018 -0.041 0.018   || dis=0.01 || select=2/8
004/019-th : 0.118 0.124 0.123 0.126 0.126 0.130 0.127 0.127  ||  -0.054 -0.008 -0.016 0.014 0.015 0.040 0.017 0.016    || dis=0.00 || select=5/8
005/019-th : 0.111 0.120 0.126 0.128 0.125 0.133 0.127 0.130  ||  -0.120 -0.038 0.005 0.019 -0.004 0.063 0.014 0.039    || dis=0.00 || select=5/8
006/019-th : 0.126 0.118 0.121 0.125 0.125 0.120 0.132 0.132  ||  0.014 -0.057 -0.031 0.004 0.001 -0.035 0.055 0.060    || dis=0.00 || select=7/8
007/019-th : 0.045 0.056 0.085 0.099 0.134 0.160 0.184 0.236  ||  -0.868 -0.660 -0.241 -0.088 0.211 0.389 0.532 0.780   || dis=0.05 || select=7/8
008/019-th : 0.036 0.051 0.070 0.108 0.135 0.175 0.207 0.217  ||  -1.064 -0.712 -0.403 0.031 0.254 0.514 0.680 0.728    || dis=0.01 || select=7/8
009/019-th : 0.084 0.092 0.104 0.113 0.131 0.136 0.156 0.183  ||  -0.359 -0.270 -0.148 -0.065 0.078 0.120 0.252 0.413   || dis=0.03 || select=7/8
010/019-th : 0.100 0.102 0.112 0.122 0.132 0.143 0.148 0.140  ||  -0.210 -0.186 -0.092 -0.012 0.068 0.150 0.185 0.129   || dis=0.01 || select=6/8
011/019-th : 0.098 0.106 0.113 0.115 0.128 0.135 0.149 0.157  ||  -0.233 -0.151 -0.087 -0.069 0.040 0.092 0.187 0.241   || dis=0.01 || select=7/8
012/019-th : 0.116 0.118 0.119 0.123 0.133 0.123 0.134 0.135  ||  -0.073 -0.058 -0.049 -0.015 0.064 -0.013 0.068 0.082  || dis=0.00 || select=7/8
013/019-th : 0.019 0.026 0.032 0.046 0.058 0.101 0.210 0.508  ||  -1.262 -0.980 -0.747 -0.395 -0.168 0.384 1.121 2.003  || dis=0.30 || select=7/8
014/019-th : 0.028 0.042 0.055 0.070 0.107 0.151 0.245 0.303  ||  -1.205 -0.788 -0.525 -0.282 0.146 0.491 0.976 1.186   || dis=0.06 || select=7/8
015/019-th : 0.015 0.022 0.032 0.041 0.062 0.102 0.229 0.499  ||  -1.478 -1.101 -0.707 -0.460 -0.046 0.452 1.262 2.041  || dis=0.27 || select=7/8
016/019-th : 0.056 0.073 0.099 0.133 0.146 0.158 0.163 0.171  ||  -0.730 -0.463 -0.162 0.132 0.230 0.307 0.340 0.383    || dis=0.01 || select=7/8
017/019-th : 0.114 0.119 0.124 0.125 0.124 0.129 0.131 0.134  ||  -0.088 -0.049 -0.008 0.000 -0.004 0.037 0.049 0.068   || dis=0.00 || select=7/8
018/019-th : 0.086 0.102 0.123 0.135 0.133 0.133 0.137 0.150  ||  -0.352 -0.184 0.005 0.094 0.077 0.083 0.112 0.204     || dis=0.01 || select=7/8
[epoch=315/600] FLOP : 27.98 MB, ratio : 0.6857, Expected-ratio : 0.7000, Discrepancy : 0.091
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:29:06] [epoch=315/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.042 (2.042)  Prec@1 30.86 (30.86) Prec@5 79.69 (79.69) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:29:13] [epoch=315/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.276 (2.147)  Prec@1 50.60 (37.30) Prec@5 95.83 (81.97) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.30 Prec@5 81.97 Error@1 62.70 Error@5 18.03 Loss:2.147
***[2020-01-29 08:29:13]*** VALID [epoch=315/600] loss = 2.147412, accuracy@1 = 37.30, accuracy@5 = 81.97 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:29:13]*** start epoch=316/600 Time Left: [02:31:08], LR=[0.045816 ~ 0.045816], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=316, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.3449892838358277, FLOP=40.81
[Search] : epoch=316/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:29:14] [epoch=316/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.837 (0.837)  Prec@1 71.88 (71.88) Prec@5 97.27 (97.27) Acls-loss 0.896 (0.896) FLOP-Loss 0.000 (0.000) Arch-Loss 0.896 (0.896)
**TRAIN** [2020-01-29 08:29:39] [epoch=316/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.931 (0.777)  Prec@1 68.45 (73.47) Prec@5 97.62 (97.88) Acls-loss 0.903 (0.815) FLOP-Loss 0.000 (0.085) Arch-Loss 0.903 (0.985)
 **TRAIN** Prec@1 73.47 Prec@5 97.88 Error@1 26.53 Error@5 2.12 Base-Loss:0.777, Arch-Loss=0.985
***[2020-01-29 08:29:39]*** TRAIN [epoch=316/600] base-loss = 0.776825, arch-loss = 0.984985, accuracy-1 = 73.47, accuracy-5 = 97.88
[epoch=316/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 8, 8, 11, 12, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.984512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.489 0.186 0.325  ||  0.3854 -0.5786 -0.0234  || discrepancy=0.16 || select=0/3
001/003-th : 0.377 0.127 0.496  ||  0.1459 -0.9416 0.4218  || discrepancy=0.12 || select=2/3
002/003-th : 0.008 0.043 0.949  ||  -2.2936 -0.6630 2.4425  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.064 0.095 0.098 0.135 0.144 0.191 0.229  ||  -0.938 -0.542 -0.149 -0.115 0.202 0.268 0.546 0.730   || dis=0.04 || select=7/8
001/019-th : 0.129 0.138 0.137 0.137 0.128 0.117 0.108 0.106  ||  0.042 0.110 0.106 0.106 0.038 -0.049 -0.137 -0.156    || dis=0.00 || select=1/8
002/019-th : 0.128 0.131 0.140 0.138 0.125 0.118 0.114 0.107  ||  0.026 0.048 0.114 0.104 -0.000 -0.059 -0.087 -0.156   || dis=0.00 || select=2/8
003/019-th : 0.115 0.120 0.137 0.125 0.126 0.130 0.120 0.127  ||  -0.084 -0.034 0.097 0.001 0.009 0.045 -0.038 0.020    || dis=0.01 || select=2/8
004/019-th : 0.118 0.123 0.123 0.124 0.130 0.128 0.127 0.128  ||  -0.058 -0.016 -0.011 -0.006 0.043 0.026 0.019 0.025   || dis=0.00 || select=4/8
005/019-th : 0.111 0.121 0.126 0.125 0.124 0.134 0.127 0.131  ||  -0.121 -0.031 0.005 0.001 -0.006 0.069 0.014 0.045    || dis=0.00 || select=5/8
006/019-th : 0.126 0.118 0.118 0.125 0.124 0.123 0.131 0.134  ||  0.010 -0.057 -0.053 0.002 -0.007 -0.016 0.049 0.071   || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.084 0.098 0.135 0.160 0.185 0.238  ||  -0.895 -0.670 -0.243 -0.089 0.229 0.395 0.542 0.794   || dis=0.05 || select=7/8
008/019-th : 0.036 0.051 0.070 0.108 0.133 0.176 0.209 0.218  ||  -1.060 -0.724 -0.400 0.032 0.239 0.518 0.691 0.733    || dis=0.01 || select=7/8
009/019-th : 0.085 0.092 0.104 0.112 0.129 0.138 0.156 0.183  ||  -0.352 -0.273 -0.149 -0.076 0.067 0.131 0.257 0.411   || dis=0.03 || select=7/8
010/019-th : 0.099 0.104 0.113 0.121 0.129 0.145 0.148 0.141  ||  -0.224 -0.172 -0.083 -0.019 0.043 0.164 0.183 0.136   || dis=0.00 || select=6/8
011/019-th : 0.097 0.105 0.112 0.116 0.127 0.135 0.150 0.158  ||  -0.242 -0.157 -0.095 -0.060 0.032 0.090 0.197 0.251   || dis=0.01 || select=7/8
012/019-th : 0.116 0.118 0.118 0.122 0.129 0.124 0.136 0.136  ||  -0.072 -0.055 -0.055 -0.021 0.031 -0.009 0.083 0.086  || dis=0.00 || select=7/8
013/019-th : 0.020 0.026 0.033 0.046 0.057 0.099 0.211 0.508  ||  -1.252 -0.984 -0.740 -0.389 -0.180 0.371 1.127 2.005  || dis=0.30 || select=7/8
014/019-th : 0.028 0.042 0.054 0.070 0.107 0.151 0.244 0.304  ||  -1.203 -0.783 -0.536 -0.277 0.143 0.490 0.971 1.192   || dis=0.06 || select=7/8
015/019-th : 0.015 0.021 0.031 0.040 0.061 0.101 0.228 0.502  ||  -1.480 -1.101 -0.715 -0.463 -0.054 0.451 1.268 2.057  || dis=0.27 || select=7/8
016/019-th : 0.055 0.075 0.098 0.133 0.143 0.159 0.165 0.172  ||  -0.746 -0.440 -0.172 0.130 0.207 0.311 0.350 0.390    || dis=0.01 || select=7/8
017/019-th : 0.113 0.118 0.124 0.126 0.124 0.128 0.133 0.134  ||  -0.096 -0.054 -0.006 0.007 -0.006 0.028 0.061 0.072   || dis=0.00 || select=7/8
018/019-th : 0.086 0.101 0.124 0.133 0.134 0.133 0.137 0.150  ||  -0.351 -0.193 0.015 0.084 0.089 0.082 0.114 0.201     || dis=0.01 || select=7/8
[epoch=316/600] FLOP : 27.98 MB, ratio : 0.6857, Expected-ratio : 0.7000, Discrepancy : 0.091
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:29:40] [epoch=316/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.581 (1.581)  Prec@1 50.39 (50.39) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:29:46] [epoch=316/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.266 (2.583)  Prec@1 24.40 (34.95) Prec@5 72.62 (79.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.95 Prec@5 79.53 Error@1 65.05 Error@5 20.47 Loss:2.583
***[2020-01-29 08:29:46]*** VALID [epoch=316/600] loss = 2.583287, accuracy@1 = 34.95, accuracy@5 = 79.53 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:29:46]*** start epoch=317/600 Time Left: [02:30:37], LR=[0.045555 ~ 0.045555], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=317, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.332208972677219, FLOP=40.81
[Search] : epoch=317/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:29:47] [epoch=317/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.784 (0.784)  Prec@1 72.66 (72.66) Prec@5 96.48 (96.48) Acls-loss 0.915 (0.915) FLOP-Loss 0.000 (0.000) Arch-Loss 0.915 (0.915)
**TRAIN** [2020-01-29 08:30:11] [epoch=317/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.878 (0.796)  Prec@1 69.64 (72.86) Prec@5 95.83 (97.86) Acls-loss 0.719 (0.816) FLOP-Loss 0.000 (0.028) Arch-Loss 0.719 (0.873)
 **TRAIN** Prec@1 72.86 Prec@5 97.86 Error@1 27.14 Error@5 2.14 Base-Loss:0.796, Arch-Loss=0.873
***[2020-01-29 08:30:11]*** TRAIN [epoch=317/600] base-loss = 0.795977, arch-loss = 0.872999, accuracy-1 = 72.86, accuracy-5 = 97.86
[epoch=317/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 8, 11, 16, 16, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.056192)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.483 0.190 0.327  ||  0.3746 -0.5571 -0.0145  || discrepancy=0.16 || select=0/3
001/003-th : 0.369 0.127 0.504  ||  0.1290 -0.9394 0.4391  || discrepancy=0.14 || select=2/3
002/003-th : 0.008 0.042 0.950  ||  -2.2963 -0.6707 2.4520  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.064 0.092 0.096 0.134 0.146 0.193 0.232  ||  -0.937 -0.544 -0.177 -0.137 0.200 0.280 0.562 0.747   || dis=0.04 || select=7/8
001/019-th : 0.128 0.137 0.134 0.135 0.131 0.118 0.110 0.107  ||  0.035 0.102 0.083 0.084 0.056 -0.047 -0.116 -0.147    || dis=0.00 || select=1/8
002/019-th : 0.126 0.130 0.138 0.140 0.125 0.119 0.115 0.108  ||  0.014 0.042 0.101 0.114 0.001 -0.049 -0.079 -0.146    || dis=0.00 || select=3/8
003/019-th : 0.111 0.120 0.135 0.125 0.129 0.132 0.121 0.128  ||  -0.114 -0.035 0.084 0.003 0.035 0.059 -0.029 0.029    || dis=0.00 || select=2/8
004/019-th : 0.116 0.124 0.122 0.123 0.130 0.128 0.128 0.130  ||  -0.075 -0.009 -0.022 -0.015 0.042 0.029 0.024 0.041   || dis=0.00 || select=4/8
005/019-th : 0.111 0.121 0.123 0.126 0.125 0.132 0.129 0.133  ||  -0.124 -0.036 -0.017 0.007 0.000 0.054 0.026 0.061    || dis=0.00 || select=7/8
006/019-th : 0.126 0.117 0.118 0.124 0.125 0.123 0.133 0.134  ||  0.006 -0.065 -0.059 -0.006 0.004 -0.016 0.064 0.071   || dis=0.00 || select=7/8
007/019-th : 0.044 0.055 0.084 0.098 0.136 0.159 0.188 0.237  ||  -0.901 -0.672 -0.246 -0.095 0.235 0.392 0.561 0.792   || dis=0.05 || select=7/8
008/019-th : 0.036 0.050 0.070 0.109 0.133 0.176 0.208 0.219  ||  -1.067 -0.738 -0.403 0.040 0.243 0.521 0.693 0.742    || dis=0.01 || select=7/8
009/019-th : 0.084 0.091 0.105 0.112 0.129 0.137 0.158 0.184  ||  -0.360 -0.287 -0.143 -0.072 0.068 0.122 0.266 0.420   || dis=0.03 || select=7/8
010/019-th : 0.096 0.103 0.113 0.121 0.129 0.146 0.148 0.144  ||  -0.247 -0.177 -0.091 -0.016 0.043 0.172 0.183 0.154   || dis=0.00 || select=6/8
011/019-th : 0.095 0.105 0.110 0.116 0.127 0.134 0.152 0.160  ||  -0.254 -0.161 -0.108 -0.060 0.035 0.083 0.211 0.265   || dis=0.01 || select=7/8
012/019-th : 0.116 0.116 0.118 0.121 0.128 0.127 0.136 0.138  ||  -0.079 -0.070 -0.060 -0.029 0.025 0.013 0.088 0.098   || dis=0.00 || select=7/8
013/019-th : 0.020 0.026 0.032 0.047 0.057 0.100 0.211 0.508  ||  -1.241 -0.984 -0.755 -0.381 -0.186 0.375 1.127 2.004  || dis=0.30 || select=7/8
014/019-th : 0.027 0.042 0.054 0.070 0.106 0.152 0.242 0.307  ||  -1.211 -0.786 -0.535 -0.281 0.141 0.501 0.964 1.205   || dis=0.07 || select=7/8
015/019-th : 0.014 0.021 0.031 0.040 0.059 0.099 0.224 0.511  ||  -1.500 -1.082 -0.716 -0.459 -0.071 0.447 1.262 2.087  || dis=0.29 || select=7/8
016/019-th : 0.055 0.074 0.096 0.130 0.143 0.161 0.165 0.175  ||  -0.751 -0.447 -0.188 0.113 0.204 0.326 0.353 0.410    || dis=0.01 || select=7/8
017/019-th : 0.111 0.118 0.124 0.124 0.126 0.130 0.133 0.134  ||  -0.119 -0.054 -0.003 -0.004 0.013 0.042 0.068 0.076   || dis=0.00 || select=7/8
018/019-th : 0.085 0.101 0.122 0.132 0.136 0.135 0.139 0.150  ||  -0.370 -0.192 -0.001 0.074 0.102 0.100 0.126 0.201    || dis=0.01 || select=7/8
[epoch=317/600] FLOP : 28.06 MB, ratio : 0.6874, Expected-ratio : 0.7000, Discrepancy : 0.092
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:30:12] [epoch=317/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.279 (2.279)  Prec@1 19.92 (19.92) Prec@5 65.23 (65.23) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:30:18] [epoch=317/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.454 (2.329)  Prec@1 54.17 (38.15) Prec@5 89.29 (80.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.15 Prec@5 80.40 Error@1 61.85 Error@5 19.60 Loss:2.329
***[2020-01-29 08:30:18]*** VALID [epoch=317/600] loss = 2.329135, accuracy@1 = 38.15, accuracy@5 = 80.40 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:30:18]*** start epoch=318/600 Time Left: [02:30:05], LR=[0.045295 ~ 0.045295], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=318, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.31943463236964, FLOP=40.81
[Search] : epoch=318/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:30:18] [epoch=318/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.766 (0.766)  Prec@1 72.27 (72.27) Prec@5 99.61 (99.61) Acls-loss 0.793 (0.793) FLOP-Loss 0.000 (0.000) Arch-Loss 0.793 (0.793)
**TRAIN** [2020-01-29 08:30:42] [epoch=318/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.807 (0.770)  Prec@1 72.02 (73.85) Prec@5 95.83 (97.98) Acls-loss 0.787 (0.818) FLOP-Loss 0.000 (0.028) Arch-Loss 0.787 (0.875)
 **TRAIN** Prec@1 73.85 Prec@5 97.98 Error@1 26.15 Error@5 2.02 Base-Loss:0.770, Arch-Loss=0.875
***[2020-01-29 08:30:42]*** TRAIN [epoch=318/600] base-loss = 0.770072, arch-loss = 0.875172, accuracy-1 = 73.85, accuracy-5 = 97.98
[epoch=318/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 12, 16, 16, 16, 32, 32, 32, 28, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.368064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.478 0.193 0.329  ||  0.3658 -0.5385 -0.0073  || discrepancy=0.15 || select=0/3
001/003-th : 0.365 0.127 0.507  ||  0.1204 -0.9327 0.4478  || discrepancy=0.14 || select=2/3
002/003-th : 0.008 0.041 0.951  ||  -2.2930 -0.6918 2.4629  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.062 0.090 0.097 0.135 0.146 0.195 0.231  ||  -0.942 -0.562 -0.192 -0.127 0.211 0.291 0.579 0.745   || dis=0.04 || select=7/8
001/019-th : 0.125 0.136 0.131 0.136 0.132 0.121 0.111 0.107  ||  0.014 0.098 0.062 0.097 0.064 -0.019 -0.109 -0.141    || dis=0.00 || select=1/8
002/019-th : 0.124 0.129 0.137 0.138 0.127 0.121 0.115 0.108  ||  -0.004 0.034 0.099 0.103 0.023 -0.028 -0.076 -0.138   || dis=0.00 || select=3/8
003/019-th : 0.110 0.117 0.133 0.126 0.130 0.133 0.122 0.130  ||  -0.125 -0.058 0.068 0.016 0.043 0.071 -0.020 0.044    || dis=0.00 || select=5/8
004/019-th : 0.115 0.124 0.121 0.122 0.129 0.128 0.130 0.131  ||  -0.083 -0.007 -0.034 -0.021 0.032 0.023 0.040 0.051   || dis=0.00 || select=7/8
005/019-th : 0.108 0.121 0.126 0.126 0.125 0.132 0.129 0.134  ||  -0.150 -0.033 0.005 0.011 0.000 0.056 0.032 0.066     || dis=0.00 || select=7/8
006/019-th : 0.124 0.116 0.117 0.123 0.127 0.123 0.135 0.135  ||  -0.003 -0.071 -0.068 -0.012 0.014 -0.012 0.076 0.076  || dis=0.00 || select=7/8
007/019-th : 0.043 0.055 0.084 0.097 0.137 0.159 0.188 0.236  ||  -0.920 -0.670 -0.241 -0.096 0.248 0.394 0.564 0.792   || dis=0.05 || select=7/8
008/019-th : 0.036 0.050 0.070 0.107 0.134 0.173 0.209 0.222  ||  -1.073 -0.742 -0.401 0.028 0.252 0.510 0.700 0.758    || dis=0.01 || select=7/8
009/019-th : 0.083 0.091 0.104 0.111 0.130 0.136 0.158 0.187  ||  -0.380 -0.281 -0.144 -0.084 0.077 0.118 0.269 0.438   || dis=0.03 || select=7/8
010/019-th : 0.094 0.102 0.113 0.121 0.130 0.147 0.148 0.144  ||  -0.265 -0.184 -0.086 -0.018 0.057 0.180 0.187 0.157   || dis=0.00 || select=6/8
011/019-th : 0.096 0.104 0.110 0.117 0.126 0.134 0.152 0.161  ||  -0.252 -0.168 -0.114 -0.053 0.026 0.085 0.213 0.271   || dis=0.01 || select=7/8
012/019-th : 0.115 0.116 0.116 0.122 0.128 0.126 0.139 0.138  ||  -0.085 -0.071 -0.073 -0.028 0.022 0.011 0.103 0.102   || dis=0.00 || select=6/8
013/019-th : 0.019 0.025 0.031 0.047 0.057 0.100 0.212 0.508  ||  -1.254 -0.999 -0.775 -0.375 -0.173 0.383 1.135 2.007  || dis=0.30 || select=7/8
014/019-th : 0.028 0.042 0.054 0.068 0.107 0.150 0.241 0.310  ||  -1.204 -0.787 -0.541 -0.297 0.151 0.491 0.964 1.216   || dis=0.07 || select=7/8
015/019-th : 0.014 0.022 0.031 0.040 0.058 0.099 0.224 0.512  ||  -1.509 -1.065 -0.724 -0.462 -0.078 0.451 1.268 2.093  || dis=0.29 || select=7/8
016/019-th : 0.055 0.073 0.096 0.129 0.143 0.163 0.167 0.174  ||  -0.755 -0.460 -0.189 0.104 0.211 0.340 0.362 0.407    || dis=0.01 || select=7/8
017/019-th : 0.110 0.118 0.123 0.125 0.125 0.127 0.134 0.137  ||  -0.124 -0.054 -0.010 0.001 0.007 0.023 0.073 0.094    || dis=0.00 || select=7/8
018/019-th : 0.086 0.100 0.120 0.132 0.134 0.137 0.137 0.154  ||  -0.360 -0.200 -0.020 0.069 0.088 0.107 0.112 0.228    || dis=0.02 || select=7/8
[epoch=318/600] FLOP : 27.37 MB, ratio : 0.6706, Expected-ratio : 0.7000, Discrepancy : 0.092
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:30:43] [epoch=318/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 1.762 (1.762)  Prec@1 45.31 (45.31) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:30:49] [epoch=318/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.391 (2.174)  Prec@1 52.98 (38.70) Prec@5 92.26 (81.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.70 Prec@5 81.53 Error@1 61.30 Error@5 18.47 Loss:2.174
***[2020-01-29 08:30:49]*** VALID [epoch=318/600] loss = 2.174081, accuracy@1 = 38.70, accuracy@5 = 81.53 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:30:49]*** start epoch=319/600 Time Left: [02:29:32], LR=[0.045034 ~ 0.045034], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=319, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.306666613128085, FLOP=40.81
[Search] : epoch=319/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:30:49] [epoch=319/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.678 (0.678)  Prec@1 76.17 (76.17) Prec@5 98.44 (98.44) Acls-loss 0.940 (0.940) FLOP-Loss 0.000 (0.000) Arch-Loss 0.940 (0.940)
**TRAIN** [2020-01-29 08:31:13] [epoch=319/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.888 (0.748)  Prec@1 71.43 (74.53) Prec@5 97.62 (98.18) Acls-loss 0.732 (0.804) FLOP-Loss 0.000 (0.312) Arch-Loss 0.732 (1.429)
 **TRAIN** Prec@1 74.53 Prec@5 98.18 Error@1 25.47 Error@5 1.82 Base-Loss:0.748, Arch-Loss=1.429
***[2020-01-29 08:31:13]*** TRAIN [epoch=319/600] base-loss = 0.747889, arch-loss = 1.429107, accuracy-1 = 74.53, accuracy-5 = 98.18
[epoch=319/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 6, 9, 8, 14, 12, 14, 32, 32, 32, 28, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.892352)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.495 0.185 0.320  ||  0.4002 -0.5808 -0.0354  || discrepancy=0.17 || select=0/3
001/003-th : 0.378 0.130 0.492  ||  0.1531 -0.9183 0.4157  || discrepancy=0.11 || select=2/3
002/003-th : 0.008 0.042 0.950  ||  -2.2849 -0.6743 2.4534  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.063 0.092 0.098 0.135 0.150 0.195 0.225  ||  -0.935 -0.559 -0.182 -0.116 0.208 0.311 0.572 0.716   || dis=0.03 || select=7/8
001/019-th : 0.129 0.140 0.133 0.139 0.128 0.119 0.108 0.104  ||  0.046 0.127 0.075 0.122 0.037 -0.041 -0.137 -0.174    || dis=0.00 || select=1/8
002/019-th : 0.128 0.131 0.140 0.141 0.126 0.118 0.111 0.105  ||  0.030 0.055 0.120 0.127 0.011 -0.053 -0.112 -0.167    || dis=0.00 || select=3/8
003/019-th : 0.112 0.121 0.136 0.127 0.130 0.129 0.119 0.127  ||  -0.103 -0.031 0.086 0.019 0.042 0.040 -0.045 0.021    || dis=0.01 || select=2/8
004/019-th : 0.119 0.127 0.123 0.124 0.126 0.125 0.128 0.127  ||  -0.046 0.016 -0.011 -0.006 0.008 0.004 0.027 0.015    || dis=0.00 || select=6/8
005/019-th : 0.110 0.123 0.126 0.127 0.125 0.132 0.125 0.131  ||  -0.128 -0.014 0.008 0.013 0.001 0.052 0.003 0.048     || dis=0.00 || select=5/8
006/019-th : 0.127 0.119 0.117 0.125 0.125 0.120 0.135 0.132  ||  0.017 -0.050 -0.062 0.001 0.000 -0.039 0.076 0.057    || dis=0.00 || select=6/8
007/019-th : 0.043 0.056 0.085 0.099 0.139 0.161 0.186 0.231  ||  -0.921 -0.652 -0.234 -0.085 0.254 0.403 0.546 0.762   || dis=0.05 || select=7/8
008/019-th : 0.036 0.049 0.071 0.107 0.134 0.174 0.209 0.220  ||  -1.066 -0.761 -0.381 0.024 0.256 0.514 0.699 0.751    || dis=0.01 || select=7/8
009/019-th : 0.084 0.094 0.107 0.112 0.129 0.135 0.155 0.184  ||  -0.363 -0.255 -0.125 -0.078 0.066 0.108 0.245 0.415   || dis=0.03 || select=7/8
010/019-th : 0.095 0.104 0.117 0.122 0.129 0.146 0.146 0.141  ||  -0.257 -0.165 -0.052 -0.009 0.047 0.169 0.170 0.133   || dis=0.00 || select=6/8
011/019-th : 0.099 0.106 0.113 0.119 0.128 0.131 0.148 0.156  ||  -0.222 -0.150 -0.091 -0.038 0.040 0.063 0.182 0.238   || dis=0.01 || select=7/8
012/019-th : 0.118 0.119 0.119 0.123 0.125 0.125 0.135 0.135  ||  -0.061 -0.048 -0.047 -0.012 -0.003 -0.000 0.079 0.080  || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.032 0.047 0.057 0.102 0.213 0.506  ||  -1.254 -1.005 -0.770 -0.380 -0.179 0.399 1.137 2.002  || dis=0.29 || select=7/8
014/019-th : 0.028 0.043 0.054 0.071 0.109 0.152 0.239 0.304  ||  -1.194 -0.773 -0.551 -0.267 0.164 0.492 0.946 1.184   || dis=0.07 || select=7/8
015/019-th : 0.014 0.022 0.031 0.041 0.058 0.100 0.227 0.507  ||  -1.509 -1.064 -0.711 -0.445 -0.085 0.449 1.271 2.074  || dis=0.28 || select=7/8
016/019-th : 0.057 0.076 0.098 0.131 0.146 0.160 0.161 0.171  ||  -0.721 -0.430 -0.177 0.118 0.226 0.316 0.319 0.383    || dis=0.01 || select=7/8
017/019-th : 0.114 0.123 0.124 0.127 0.124 0.124 0.130 0.134  ||  -0.093 -0.018 -0.004 0.013 -0.003 -0.006 0.043 0.068  || dis=0.00 || select=7/8
018/019-th : 0.087 0.101 0.122 0.135 0.134 0.135 0.136 0.150  ||  -0.348 -0.191 -0.006 0.092 0.089 0.096 0.099 0.203    || dis=0.01 || select=7/8
[epoch=319/600] FLOP : 27.89 MB, ratio : 0.6834, Expected-ratio : 0.7000, Discrepancy : 0.091
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:31:14] [epoch=319/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.550 (2.550)  Prec@1 13.28 (13.28) Prec@5 62.50 (62.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:31:20] [epoch=319/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.576 (2.400)  Prec@1 51.79 (36.97) Prec@5 89.29 (79.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.97 Prec@5 79.80 Error@1 63.03 Error@5 20.20 Loss:2.400
***[2020-01-29 08:31:20]*** VALID [epoch=319/600] loss = 2.399780, accuracy@1 = 36.97, accuracy@5 = 79.80 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:31:20]*** start epoch=320/600 Time Left: [02:29:00], LR=[0.044774 ~ 0.044774], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=320, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2939052649942497, FLOP=40.81
[Search] : epoch=320/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:31:20] [epoch=320/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.707 (0.707)  Prec@1 76.56 (76.56) Prec@5 98.83 (98.83) Acls-loss 1.068 (1.068) FLOP-Loss 0.000 (0.000) Arch-Loss 1.068 (1.068)
**TRAIN** [2020-01-29 08:31:44] [epoch=320/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.610 (0.757)  Prec@1 78.57 (74.44) Prec@5 97.62 (98.11) Acls-loss 0.715 (0.811) FLOP-Loss 0.000 (0.141) Arch-Loss 0.715 (1.094)
 **TRAIN** Prec@1 74.44 Prec@5 98.11 Error@1 25.56 Error@5 1.89 Base-Loss:0.757, Arch-Loss=1.094
***[2020-01-29 08:31:45]*** TRAIN [epoch=320/600] base-loss = 0.756692, arch-loss = 1.093896, accuracy-1 = 74.44, accuracy-5 = 98.11
[epoch=320/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 11, 11, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.992704)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.500 0.182 0.318  ||  0.4110 -0.5983 -0.0427  || discrepancy=0.18 || select=0/3
001/003-th : 0.383 0.129 0.488  ||  0.1640 -0.9231 0.4072  || discrepancy=0.10 || select=2/3
002/003-th : 0.008 0.042 0.949  ||  -2.2787 -0.6602 2.4466  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.043 0.063 0.091 0.099 0.138 0.151 0.193 0.222  ||  -0.936 -0.560 -0.192 -0.100 0.227 0.317 0.566 0.703   || dis=0.03 || select=7/8
001/019-th : 0.130 0.140 0.134 0.140 0.128 0.118 0.106 0.102  ||  0.055 0.128 0.084 0.128 0.039 -0.040 -0.148 -0.187    || dis=0.00 || select=3/8
002/019-th : 0.128 0.132 0.142 0.141 0.126 0.117 0.111 0.104  ||  0.029 0.065 0.136 0.127 0.012 -0.059 -0.115 -0.177    || dis=0.00 || select=2/8
003/019-th : 0.112 0.119 0.132 0.127 0.132 0.131 0.119 0.129  ||  -0.102 -0.043 0.056 0.019 0.062 0.049 -0.048 0.033    || dis=0.00 || select=4/8
004/019-th : 0.120 0.127 0.124 0.124 0.128 0.124 0.128 0.125  ||  -0.035 0.015 -0.008 -0.005 0.026 -0.009 0.024 0.004   || dis=0.00 || select=4/8
005/019-th : 0.110 0.124 0.127 0.126 0.125 0.131 0.125 0.131  ||  -0.126 -0.006 0.016 0.003 -0.001 0.044 0.001 0.048    || dis=0.00 || select=7/8
006/019-th : 0.128 0.118 0.119 0.125 0.125 0.120 0.133 0.132  ||  0.022 -0.053 -0.045 0.000 0.002 -0.037 0.063 0.054    || dis=0.00 || select=6/8
007/019-th : 0.042 0.056 0.085 0.101 0.141 0.162 0.183 0.230  ||  -0.946 -0.649 -0.233 -0.066 0.273 0.407 0.531 0.759   || dis=0.05 || select=7/8
008/019-th : 0.035 0.049 0.071 0.106 0.136 0.176 0.212 0.215  ||  -1.094 -0.752 -0.371 0.021 0.271 0.528 0.717 0.731    || dis=0.00 || select=7/8
009/019-th : 0.085 0.095 0.108 0.111 0.130 0.138 0.154 0.181  ||  -0.359 -0.249 -0.119 -0.091 0.067 0.128 0.238 0.403   || dis=0.03 || select=7/8
010/019-th : 0.097 0.105 0.118 0.122 0.130 0.146 0.144 0.140  ||  -0.244 -0.163 -0.043 -0.012 0.052 0.169 0.154 0.126   || dis=0.00 || select=5/8
011/019-th : 0.101 0.107 0.113 0.116 0.130 0.132 0.147 0.155  ||  -0.202 -0.143 -0.087 -0.064 0.052 0.064 0.176 0.225   || dis=0.01 || select=7/8
012/019-th : 0.118 0.120 0.122 0.125 0.123 0.124 0.134 0.134  ||  -0.054 -0.042 -0.024 -0.001 -0.018 -0.012 0.068 0.073  || dis=0.00 || select=7/8
013/019-th : 0.020 0.025 0.032 0.047 0.058 0.102 0.210 0.506  ||  -1.254 -1.015 -0.761 -0.368 -0.171 0.401 1.117 2.000  || dis=0.30 || select=7/8
014/019-th : 0.029 0.043 0.054 0.071 0.110 0.154 0.237 0.302  ||  -1.177 -0.772 -0.544 -0.272 0.162 0.502 0.932 1.174   || dis=0.07 || select=7/8
015/019-th : 0.014 0.022 0.031 0.041 0.059 0.100 0.223 0.510  ||  -1.514 -1.068 -0.714 -0.432 -0.082 0.452 1.256 2.082  || dis=0.29 || select=7/8
016/019-th : 0.056 0.077 0.098 0.131 0.147 0.160 0.161 0.170  ||  -0.734 -0.415 -0.174 0.117 0.233 0.315 0.324 0.374    || dis=0.01 || select=7/8
017/019-th : 0.114 0.124 0.127 0.127 0.125 0.122 0.129 0.132  ||  -0.087 -0.005 0.019 0.013 0.000 -0.026 0.030 0.057    || dis=0.00 || select=7/8
018/019-th : 0.088 0.102 0.124 0.136 0.134 0.133 0.136 0.149  ||  -0.338 -0.189 0.007 0.103 0.086 0.078 0.101 0.191     || dis=0.01 || select=7/8
[epoch=320/600] FLOP : 27.99 MB, ratio : 0.6859, Expected-ratio : 0.7000, Discrepancy : 0.090
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:31:45] [epoch=320/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.561 (1.561)  Prec@1 51.95 (51.95) Prec@5 90.62 (90.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:31:51] [epoch=320/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.137 (2.314)  Prec@1 44.05 (37.16) Prec@5 83.93 (80.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.16 Prec@5 80.18 Error@1 62.84 Error@5 19.82 Loss:2.314
***[2020-01-29 08:31:51]*** VALID [epoch=320/600] loss = 2.313508, accuracy@1 = 37.16, accuracy@5 = 80.18 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:31:51]*** start epoch=321/600 Time Left: [02:28:27], LR=[0.044513 ~ 0.044513], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=321, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2811509378269395, FLOP=40.81
[Search] : epoch=321/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:31:52] [epoch=321/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.790 (0.790)  Prec@1 71.48 (71.48) Prec@5 97.66 (97.66) Acls-loss 0.646 (0.646) FLOP-Loss 0.000 (0.000) Arch-Loss 0.646 (0.646)
**TRAIN** [2020-01-29 08:32:15] [epoch=321/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.757 (0.768)  Prec@1 73.81 (73.97) Prec@5 99.40 (98.00) Acls-loss 0.864 (0.811) FLOP-Loss 0.000 (0.000) Arch-Loss 0.864 (0.811)
 **TRAIN** Prec@1 73.97 Prec@5 98.00 Error@1 26.03 Error@5 2.00 Base-Loss:0.768, Arch-Loss=0.811
***[2020-01-29 08:32:16]*** TRAIN [epoch=321/600] base-loss = 0.767900, arch-loss = 0.810560, accuracy-1 = 73.97, accuracy-5 = 98.00
[epoch=321/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 11, 11, 16, 16, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.255872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.490 0.186 0.323  ||  0.3917 -0.5750 -0.0251  || discrepancy=0.17 || select=0/3
001/003-th : 0.376 0.131 0.493  ||  0.1497 -0.9064 0.4198  || discrepancy=0.12 || select=2/3
002/003-th : 0.008 0.042 0.950  ||  -2.2784 -0.6657 2.4528  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.042 0.063 0.090 0.098 0.136 0.151 0.194 0.227  ||  -0.959 -0.557 -0.193 -0.110 0.216 0.321 0.573 0.729   || dis=0.03 || select=7/8
001/019-th : 0.128 0.139 0.132 0.141 0.129 0.121 0.107 0.104  ||  0.036 0.117 0.070 0.132 0.043 -0.022 -0.140 -0.169    || dis=0.00 || select=3/8
002/019-th : 0.124 0.130 0.140 0.141 0.128 0.120 0.113 0.105  ||  -0.000 0.050 0.119 0.127 0.032 -0.033 -0.095 -0.162   || dis=0.00 || select=3/8
003/019-th : 0.111 0.118 0.130 0.126 0.132 0.131 0.120 0.131  ||  -0.115 -0.051 0.044 0.011 0.059 0.054 -0.033 0.052    || dis=0.00 || select=4/8
004/019-th : 0.118 0.124 0.123 0.123 0.130 0.123 0.130 0.128  ||  -0.053 -0.010 -0.019 -0.016 0.044 -0.013 0.044 0.028  || dis=0.00 || select=4/8
005/019-th : 0.108 0.123 0.127 0.124 0.126 0.132 0.128 0.132  ||  -0.143 -0.018 0.014 -0.010 0.006 0.056 0.025 0.057    || dis=0.00 || select=7/8
006/019-th : 0.125 0.116 0.119 0.126 0.123 0.122 0.134 0.135  ||  0.002 -0.070 -0.051 0.010 -0.013 -0.027 0.070 0.076   || dis=0.00 || select=7/8
007/019-th : 0.041 0.056 0.085 0.100 0.140 0.163 0.184 0.231  ||  -0.958 -0.644 -0.228 -0.076 0.264 0.419 0.537 0.766   || dis=0.05 || select=7/8
008/019-th : 0.034 0.048 0.070 0.105 0.134 0.178 0.215 0.216  ||  -1.109 -0.765 -0.383 0.021 0.262 0.549 0.738 0.743    || dis=0.00 || select=7/8
009/019-th : 0.085 0.093 0.105 0.110 0.128 0.138 0.155 0.186  ||  -0.357 -0.260 -0.139 -0.097 0.059 0.130 0.244 0.427   || dis=0.03 || select=7/8
010/019-th : 0.096 0.104 0.115 0.122 0.131 0.147 0.142 0.143  ||  -0.249 -0.173 -0.072 -0.009 0.061 0.176 0.145 0.149   || dis=0.00 || select=5/8
011/019-th : 0.100 0.106 0.111 0.115 0.130 0.132 0.150 0.156  ||  -0.207 -0.151 -0.103 -0.073 0.052 0.065 0.198 0.233   || dis=0.01 || select=7/8
012/019-th : 0.116 0.119 0.121 0.123 0.125 0.125 0.134 0.137  ||  -0.071 -0.047 -0.032 -0.020 -0.002 -0.002 0.069 0.091  || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.031 0.047 0.057 0.105 0.204 0.511  ||  -1.253 -1.020 -0.777 -0.372 -0.172 0.428 1.096 2.014  || dis=0.31 || select=7/8
014/019-th : 0.028 0.041 0.053 0.070 0.107 0.155 0.240 0.305  ||  -1.198 -0.798 -0.548 -0.275 0.147 0.523 0.958 1.198   || dis=0.07 || select=7/8
015/019-th : 0.014 0.021 0.031 0.041 0.058 0.097 0.218 0.519  ||  -1.523 -1.077 -0.721 -0.417 -0.075 0.438 1.242 2.110  || dis=0.30 || select=7/8
016/019-th : 0.056 0.077 0.096 0.129 0.147 0.160 0.162 0.173  ||  -0.738 -0.420 -0.190 0.103 0.233 0.318 0.330 0.393    || dis=0.01 || select=7/8
017/019-th : 0.114 0.122 0.126 0.126 0.125 0.121 0.132 0.134  ||  -0.093 -0.023 0.005 0.011 0.000 -0.033 0.057 0.072    || dis=0.00 || select=7/8
018/019-th : 0.087 0.100 0.122 0.137 0.134 0.133 0.138 0.149  ||  -0.342 -0.203 -0.004 0.108 0.088 0.078 0.118 0.193    || dis=0.01 || select=7/8
[epoch=321/600] FLOP : 28.26 MB, ratio : 0.6923, Expected-ratio : 0.7000, Discrepancy : 0.092
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:32:16] [epoch=321/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 3.955 (3.955)  Prec@1 31.64 (31.64) Prec@5 69.53 (69.53) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:32:22] [epoch=321/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.835 (2.579)  Prec@1 39.88 (36.07) Prec@5 86.90 (79.74) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.07 Prec@5 79.74 Error@1 63.93 Error@5 20.26 Loss:2.579
***[2020-01-29 08:32:22]*** VALID [epoch=321/600] loss = 2.578655, accuracy@1 = 36.07, accuracy@5 = 79.74 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:32:22]*** start epoch=322/600 Time Left: [02:27:54], LR=[0.044253 ~ 0.044253], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=322, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2684039812924772, FLOP=40.81
[Search] : epoch=322/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:32:23] [epoch=322/600][000/098] Time 0.74 (0.74) Data 0.36 (0.36) Base-Loss 0.742 (0.742)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.756 (0.756) FLOP-Loss 0.000 (0.000) Arch-Loss 0.756 (0.756)
**TRAIN** [2020-01-29 08:32:47] [epoch=322/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.804 (0.771)  Prec@1 77.38 (73.70) Prec@5 97.62 (98.03) Acls-loss 0.964 (0.819) FLOP-Loss 0.000 (0.000) Arch-Loss 0.964 (0.819)
 **TRAIN** Prec@1 73.70 Prec@5 98.03 Error@1 26.30 Error@5 1.97 Base-Loss:0.771, Arch-Loss=0.819
***[2020-01-29 08:32:47]*** TRAIN [epoch=322/600] base-loss = 0.770897, arch-loss = 0.819044, accuracy-1 = 73.70, accuracy-5 = 98.03
[epoch=322/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.462272)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.484 0.189 0.327  ||  0.3788 -0.5594 -0.0131  || discrepancy=0.16 || select=0/3
001/003-th : 0.369 0.133 0.498  ||  0.1338 -0.8841 0.4331  || discrepancy=0.13 || select=2/3
002/003-th : 0.008 0.042 0.950  ||  -2.2723 -0.6682 2.4535  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.040 0.063 0.090 0.098 0.136 0.150 0.196 0.227  ||  -0.990 -0.553 -0.185 -0.110 0.222 0.323 0.587 0.733   || dis=0.03 || select=7/8
001/019-th : 0.127 0.135 0.129 0.139 0.132 0.121 0.109 0.107  ||  0.029 0.091 0.044 0.120 0.063 -0.019 -0.125 -0.145    || dis=0.00 || select=3/8
002/019-th : 0.122 0.129 0.136 0.140 0.130 0.121 0.115 0.107  ||  -0.016 0.036 0.092 0.121 0.047 -0.021 -0.079 -0.145   || dis=0.00 || select=3/8
003/019-th : 0.109 0.117 0.129 0.126 0.132 0.131 0.123 0.133  ||  -0.131 -0.060 0.040 0.010 0.057 0.051 -0.014 0.068    || dis=0.00 || select=7/8
004/019-th : 0.118 0.123 0.121 0.121 0.131 0.125 0.132 0.130  ||  -0.060 -0.019 -0.030 -0.030 0.046 0.002 0.053 0.037   || dis=0.00 || select=6/8
005/019-th : 0.107 0.120 0.125 0.124 0.125 0.134 0.131 0.134  ||  -0.159 -0.040 0.002 -0.005 0.004 0.069 0.046 0.074    || dis=0.00 || select=7/8
006/019-th : 0.124 0.115 0.118 0.122 0.124 0.124 0.136 0.136  ||  -0.010 -0.082 -0.055 -0.020 -0.007 -0.004 0.087 0.083  || dis=0.00 || select=6/8
007/019-th : 0.041 0.056 0.085 0.098 0.138 0.162 0.186 0.233  ||  -0.965 -0.642 -0.225 -0.085 0.253 0.416 0.550 0.779   || dis=0.05 || select=7/8
008/019-th : 0.034 0.048 0.070 0.104 0.133 0.177 0.217 0.217  ||  -1.105 -0.769 -0.384 0.008 0.261 0.546 0.749 0.746    || dis=0.00 || select=6/8
009/019-th : 0.084 0.092 0.104 0.111 0.127 0.140 0.156 0.186  ||  -0.366 -0.278 -0.151 -0.082 0.052 0.149 0.254 0.431   || dis=0.03 || select=7/8
010/019-th : 0.096 0.103 0.113 0.121 0.130 0.148 0.144 0.144  ||  -0.251 -0.176 -0.089 -0.017 0.057 0.183 0.158 0.157   || dis=0.00 || select=5/8
011/019-th : 0.098 0.105 0.110 0.114 0.131 0.133 0.151 0.157  ||  -0.231 -0.157 -0.109 -0.080 0.062 0.079 0.205 0.244   || dis=0.01 || select=7/8
012/019-th : 0.115 0.118 0.120 0.121 0.125 0.127 0.136 0.139  ||  -0.086 -0.060 -0.043 -0.035 -0.002 0.016 0.084 0.106  || dis=0.00 || select=7/8
013/019-th : 0.019 0.025 0.031 0.046 0.056 0.105 0.204 0.514  ||  -1.273 -1.003 -0.780 -0.382 -0.188 0.436 1.105 2.028  || dis=0.31 || select=7/8
014/019-th : 0.028 0.041 0.053 0.069 0.104 0.151 0.243 0.311  ||  -1.196 -0.803 -0.540 -0.283 0.125 0.497 0.975 1.221   || dis=0.07 || select=7/8
015/019-th : 0.013 0.021 0.030 0.041 0.058 0.095 0.216 0.525  ||  -1.531 -1.072 -0.744 -0.422 -0.065 0.428 1.245 2.134  || dis=0.31 || select=7/8
016/019-th : 0.056 0.075 0.095 0.126 0.148 0.159 0.166 0.174  ||  -0.740 -0.433 -0.201 0.080 0.242 0.314 0.354 0.405    || dis=0.01 || select=7/8
017/019-th : 0.113 0.121 0.125 0.124 0.125 0.122 0.135 0.136  ||  -0.103 -0.035 0.001 -0.010 0.002 -0.020 0.075 0.083   || dis=0.00 || select=7/8
018/019-th : 0.086 0.099 0.122 0.136 0.133 0.135 0.139 0.150  ||  -0.354 -0.217 -0.005 0.101 0.082 0.095 0.128 0.202    || dis=0.01 || select=7/8
[epoch=322/600] FLOP : 27.46 MB, ratio : 0.6729, Expected-ratio : 0.7000, Discrepancy : 0.092
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:32:47] [epoch=322/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.741 (2.741)  Prec@1 35.94 (35.94) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:32:53] [epoch=322/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.677 (2.411)  Prec@1 47.62 (36.26) Prec@5 89.88 (80.88) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.26 Prec@5 80.88 Error@1 63.74 Error@5 19.12 Loss:2.411
***[2020-01-29 08:32:53]*** VALID [epoch=322/600] loss = 2.410518, accuracy@1 = 36.26, accuracy@5 = 80.88 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:32:53]*** start epoch=323/600 Time Left: [02:27:22], LR=[0.043993 ~ 0.043993], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=323, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.255664744855115, FLOP=40.81
[Search] : epoch=323/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:32:54] [epoch=323/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.856 (0.856)  Prec@1 70.31 (70.31) Prec@5 98.05 (98.05) Acls-loss 0.721 (0.721) FLOP-Loss 0.000 (0.000) Arch-Loss 0.721 (0.721)
**TRAIN** [2020-01-29 08:33:18] [epoch=323/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.779 (0.779)  Prec@1 76.19 (73.77) Prec@5 97.02 (97.94) Acls-loss 0.795 (0.827) FLOP-Loss 0.000 (0.000) Arch-Loss 0.795 (0.827)
 **TRAIN** Prec@1 73.77 Prec@5 97.94 Error@1 26.23 Error@5 2.06 Base-Loss:0.779, Arch-Loss=0.827
***[2020-01-29 08:33:18]*** TRAIN [epoch=323/600] base-loss = 0.778796, arch-loss = 0.826526, accuracy-1 = 73.77, accuracy-5 = 97.94
[epoch=323/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.092032)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.480 0.187 0.333  ||  0.3673 -0.5731 0.0024  || discrepancy=0.15 || select=0/3
001/003-th : 0.359 0.134 0.507  ||  0.1106 -0.8772 0.4557  || discrepancy=0.15 || select=2/3
002/003-th : 0.008 0.041 0.951  ||  -2.2994 -0.6658 2.4776  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.040 0.062 0.090 0.097 0.135 0.149 0.199 0.228  ||  -1.007 -0.555 -0.186 -0.114 0.216 0.321 0.606 0.745   || dis=0.03 || select=7/8
001/019-th : 0.125 0.133 0.129 0.137 0.133 0.124 0.111 0.109  ||  0.008 0.071 0.039 0.104 0.072 -0.001 -0.108 -0.123    || dis=0.00 || select=3/8
002/019-th : 0.119 0.127 0.134 0.138 0.132 0.123 0.117 0.108  ||  -0.041 0.025 0.080 0.109 0.063 -0.005 -0.055 -0.134   || dis=0.00 || select=3/8
003/019-th : 0.108 0.112 0.128 0.125 0.133 0.133 0.124 0.136  ||  -0.140 -0.104 0.030 0.008 0.070 0.066 0.001 0.094     || dis=0.00 || select=7/8
004/019-th : 0.116 0.120 0.120 0.119 0.133 0.127 0.135 0.131  ||  -0.074 -0.037 -0.044 -0.046 0.059 0.014 0.076 0.046   || dis=0.00 || select=6/8
005/019-th : 0.107 0.119 0.125 0.122 0.125 0.135 0.132 0.135  ||  -0.154 -0.046 0.001 -0.021 -0.001 0.076 0.053 0.078   || dis=0.00 || select=7/8
006/019-th : 0.123 0.113 0.116 0.121 0.125 0.125 0.139 0.138  ||  -0.020 -0.097 -0.077 -0.030 -0.001 -0.001 0.107 0.100  || dis=0.00 || select=6/8
007/019-th : 0.040 0.055 0.085 0.097 0.139 0.160 0.186 0.236  ||  -0.977 -0.654 -0.228 -0.090 0.267 0.408 0.558 0.796   || dis=0.05 || select=7/8
008/019-th : 0.034 0.047 0.069 0.103 0.132 0.177 0.218 0.220  ||  -1.110 -0.777 -0.393 0.003 0.253 0.549 0.757 0.766    || dis=0.00 || select=7/8
009/019-th : 0.083 0.090 0.103 0.113 0.127 0.139 0.158 0.188  ||  -0.376 -0.295 -0.160 -0.067 0.050 0.140 0.269 0.447   || dis=0.03 || select=7/8
010/019-th : 0.095 0.102 0.111 0.120 0.131 0.151 0.145 0.146  ||  -0.264 -0.190 -0.107 -0.028 0.062 0.206 0.166 0.172   || dis=0.01 || select=5/8
011/019-th : 0.097 0.104 0.109 0.113 0.131 0.133 0.153 0.160  ||  -0.239 -0.171 -0.120 -0.082 0.062 0.076 0.220 0.261   || dis=0.01 || select=7/8
012/019-th : 0.114 0.115 0.118 0.120 0.127 0.129 0.137 0.141  ||  -0.095 -0.082 -0.061 -0.040 0.017 0.029 0.092 0.121   || dis=0.00 || select=7/8
013/019-th : 0.019 0.024 0.030 0.046 0.054 0.103 0.200 0.523  ||  -1.262 -1.005 -0.799 -0.370 -0.206 0.428 1.096 2.056  || dis=0.32 || select=7/8
014/019-th : 0.027 0.041 0.053 0.068 0.103 0.151 0.244 0.313  ||  -1.204 -0.799 -0.542 -0.298 0.117 0.507 0.984 1.232   || dis=0.07 || select=7/8
015/019-th : 0.013 0.021 0.029 0.041 0.056 0.095 0.212 0.533  ||  -1.551 -1.062 -0.753 -0.408 -0.094 0.440 1.238 2.161  || dis=0.32 || select=7/8
016/019-th : 0.056 0.074 0.095 0.123 0.146 0.163 0.167 0.177  ||  -0.737 -0.445 -0.205 0.060 0.227 0.336 0.360 0.418    || dis=0.01 || select=7/8
017/019-th : 0.112 0.117 0.123 0.122 0.127 0.123 0.136 0.139  ||  -0.109 -0.062 -0.012 -0.021 0.017 -0.016 0.088 0.107  || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.122 0.134 0.132 0.136 0.140 0.152  ||  -0.361 -0.223 -0.004 0.087 0.073 0.101 0.134 0.215    || dis=0.01 || select=7/8
[epoch=323/600] FLOP : 28.09 MB, ratio : 0.6883, Expected-ratio : 0.7000, Discrepancy : 0.095
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:33:19] [epoch=323/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.966 (1.966)  Prec@1 37.50 (37.50) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:33:25] [epoch=323/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.895 (2.287)  Prec@1 35.71 (38.46) Prec@5 86.31 (81.37) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.46 Prec@5 81.37 Error@1 61.54 Error@5 18.63 Loss:2.287
***[2020-01-29 08:33:25]*** VALID [epoch=323/600] loss = 2.287086, accuracy@1 = 38.46, accuracy@5 = 81.37 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:33:25]*** start epoch=324/600 Time Left: [02:26:50], LR=[0.043733 ~ 0.043733], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=324, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2429335777674546, FLOP=40.81
[Search] : epoch=324/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:33:25] [epoch=324/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 1.062 (1.062)  Prec@1 64.84 (64.84) Prec@5 97.27 (97.27) Acls-loss 0.703 (0.703) FLOP-Loss 0.000 (0.000) Arch-Loss 0.703 (0.703)
**TRAIN** [2020-01-29 08:33:50] [epoch=324/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.667 (0.765)  Prec@1 74.40 (73.72) Prec@5 98.21 (98.07) Acls-loss 0.628 (0.792) FLOP-Loss 0.000 (0.000) Arch-Loss 0.628 (0.792)
 **TRAIN** Prec@1 73.72 Prec@5 98.07 Error@1 26.28 Error@5 1.93 Base-Loss:0.765, Arch-Loss=0.792
***[2020-01-29 08:33:50]*** TRAIN [epoch=324/600] base-loss = 0.764951, arch-loss = 0.792304, accuracy-1 = 73.72, accuracy-5 = 98.07
[epoch=324/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.462272)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.474 0.191 0.335  ||  0.3565 -0.5538 0.0113  || discrepancy=0.14 || select=0/3
001/003-th : 0.352 0.133 0.515  ||  0.0923 -0.8781 0.4748  || discrepancy=0.16 || select=2/3
002/003-th : 0.008 0.041 0.951  ||  -2.2920 -0.6730 2.4787  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.091 0.096 0.134 0.149 0.199 0.232  ||  -1.013 -0.570 -0.174 -0.124 0.211 0.320 0.608 0.765   || dis=0.03 || select=7/8
001/019-th : 0.124 0.131 0.126 0.137 0.133 0.123 0.114 0.112  ||  -0.001 0.052 0.016 0.101 0.073 -0.005 -0.085 -0.101   || dis=0.00 || select=3/8
002/019-th : 0.118 0.125 0.134 0.136 0.132 0.125 0.120 0.111  ||  -0.054 0.008 0.072 0.087 0.062 0.008 -0.037 -0.115    || dis=0.00 || select=3/8
003/019-th : 0.107 0.111 0.127 0.123 0.136 0.133 0.127 0.137  ||  -0.147 -0.115 0.020 -0.007 0.093 0.066 0.023 0.096    || dis=0.00 || select=7/8
004/019-th : 0.114 0.119 0.121 0.119 0.132 0.128 0.136 0.133  ||  -0.094 -0.051 -0.035 -0.050 0.057 0.022 0.082 0.064   || dis=0.00 || select=6/8
005/019-th : 0.106 0.119 0.124 0.121 0.125 0.135 0.133 0.137  ||  -0.163 -0.050 -0.003 -0.034 0.001 0.079 0.060 0.096   || dis=0.00 || select=7/8
006/019-th : 0.121 0.112 0.115 0.121 0.125 0.125 0.142 0.139  ||  -0.033 -0.112 -0.083 -0.031 -0.000 0.000 0.127 0.109  || dis=0.00 || select=6/8
007/019-th : 0.040 0.054 0.084 0.096 0.139 0.162 0.188 0.237  ||  -0.968 -0.677 -0.233 -0.103 0.266 0.422 0.572 0.804   || dis=0.05 || select=7/8
008/019-th : 0.034 0.046 0.069 0.100 0.130 0.176 0.223 0.222  ||  -1.098 -0.790 -0.397 -0.022 0.242 0.544 0.783 0.779   || dis=0.00 || select=6/8
009/019-th : 0.083 0.089 0.103 0.112 0.127 0.138 0.158 0.190  ||  -0.377 -0.300 -0.159 -0.069 0.052 0.132 0.273 0.454   || dis=0.03 || select=7/8
010/019-th : 0.094 0.101 0.109 0.120 0.131 0.152 0.146 0.148  ||  -0.269 -0.198 -0.123 -0.028 0.063 0.212 0.169 0.185   || dis=0.00 || select=5/8
011/019-th : 0.096 0.101 0.108 0.114 0.130 0.134 0.154 0.163  ||  -0.252 -0.192 -0.129 -0.078 0.058 0.085 0.225 0.284   || dis=0.01 || select=7/8
012/019-th : 0.112 0.114 0.117 0.121 0.128 0.127 0.138 0.144  ||  -0.113 -0.093 -0.067 -0.036 0.022 0.019 0.102 0.140   || dis=0.01 || select=7/8
013/019-th : 0.019 0.024 0.029 0.045 0.054 0.099 0.199 0.530  ||  -1.265 -1.000 -0.811 -0.380 -0.200 0.408 1.104 2.081  || dis=0.33 || select=7/8
014/019-th : 0.027 0.040 0.053 0.067 0.100 0.150 0.244 0.318  ||  -1.208 -0.812 -0.529 -0.309 0.100 0.501 0.992 1.255   || dis=0.07 || select=7/8
015/019-th : 0.013 0.021 0.029 0.040 0.055 0.096 0.208 0.538  ||  -1.571 -1.072 -0.749 -0.413 -0.096 0.459 1.232 2.181  || dis=0.33 || select=7/8
016/019-th : 0.055 0.074 0.094 0.123 0.144 0.163 0.168 0.178  ||  -0.740 -0.452 -0.214 0.059 0.217 0.338 0.371 0.428    || dis=0.01 || select=7/8
017/019-th : 0.111 0.115 0.123 0.123 0.126 0.124 0.138 0.141  ||  -0.118 -0.085 -0.015 -0.015 0.006 -0.006 0.103 0.121  || dis=0.00 || select=7/8
018/019-th : 0.085 0.097 0.123 0.132 0.131 0.138 0.141 0.152  ||  -0.363 -0.230 -0.001 0.076 0.063 0.117 0.141 0.215    || dis=0.01 || select=7/8
[epoch=324/600] FLOP : 27.46 MB, ratio : 0.6729, Expected-ratio : 0.7000, Discrepancy : 0.096
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:33:50] [epoch=324/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.740 (1.740)  Prec@1 48.05 (48.05) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:33:56] [epoch=324/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.811 (2.580)  Prec@1 38.10 (32.57) Prec@5 85.71 (78.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.57 Prec@5 78.26 Error@1 67.43 Error@5 21.74 Loss:2.580
***[2020-01-29 08:33:56]*** VALID [epoch=324/600] loss = 2.579740, accuracy@1 = 32.57, accuracy@5 = 78.26 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:33:56]*** start epoch=325/600 Time Left: [02:26:17], LR=[0.043474 ~ 0.043474], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=325, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2302108290608746, FLOP=40.81
[Search] : epoch=325/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:33:57] [epoch=325/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.828 (0.828)  Prec@1 71.48 (71.48) Prec@5 99.22 (99.22) Acls-loss 0.939 (0.939) FLOP-Loss 0.000 (0.000) Arch-Loss 0.939 (0.939)
**TRAIN** [2020-01-29 08:34:21] [epoch=325/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.749 (0.791)  Prec@1 73.21 (72.97) Prec@5 97.62 (97.98) Acls-loss 0.867 (0.805) FLOP-Loss 0.000 (0.000) Arch-Loss 0.867 (0.805)
 **TRAIN** Prec@1 72.97 Prec@5 97.98 Error@1 27.03 Error@5 2.02 Base-Loss:0.791, Arch-Loss=0.805
***[2020-01-29 08:34:21]*** TRAIN [epoch=325/600] base-loss = 0.791374, arch-loss = 0.805249, accuracy-1 = 72.97, accuracy-5 = 97.98
[epoch=325/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.923072)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.467 0.193 0.340  ||  0.3428 -0.5440 0.0248  || discrepancy=0.13 || select=0/3
001/003-th : 0.347 0.134 0.519  ||  0.0821 -0.8717 0.4849  || discrepancy=0.17 || select=2/3
002/003-th : 0.008 0.039 0.953  ||  -2.2934 -0.7046 2.4974  || discrepancy=0.91 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.060 0.090 0.094 0.132 0.150 0.197 0.238  ||  -1.019 -0.581 -0.184 -0.132 0.206 0.329 0.607 0.793   || dis=0.04 || select=7/8
001/019-th : 0.121 0.129 0.126 0.134 0.136 0.124 0.117 0.114  ||  -0.024 0.039 0.016 0.082 0.091 -0.003 -0.061 -0.084   || dis=0.00 || select=4/8
002/019-th : 0.116 0.123 0.129 0.135 0.134 0.128 0.122 0.112  ||  -0.067 -0.009 0.036 0.083 0.075 0.030 -0.015 -0.103   || dis=0.00 || select=3/8
003/019-th : 0.106 0.110 0.123 0.123 0.136 0.134 0.128 0.139  ||  -0.159 -0.117 -0.011 -0.005 0.092 0.078 0.033 0.115   || dis=0.00 || select=7/8
004/019-th : 0.112 0.117 0.119 0.118 0.132 0.127 0.138 0.136  ||  -0.108 -0.066 -0.050 -0.056 0.059 0.018 0.100 0.089   || dis=0.00 || select=6/8
005/019-th : 0.103 0.117 0.124 0.120 0.127 0.136 0.133 0.141  ||  -0.194 -0.066 -0.006 -0.034 0.019 0.085 0.067 0.124   || dis=0.00 || select=7/8
006/019-th : 0.120 0.111 0.115 0.116 0.125 0.125 0.146 0.141  ||  -0.041 -0.116 -0.082 -0.071 -0.000 0.000 0.158 0.120  || dis=0.01 || select=6/8
007/019-th : 0.040 0.054 0.084 0.095 0.138 0.162 0.188 0.239  ||  -0.970 -0.676 -0.230 -0.113 0.261 0.424 0.571 0.813   || dis=0.05 || select=7/8
008/019-th : 0.034 0.046 0.067 0.099 0.129 0.175 0.225 0.225  ||  -1.106 -0.783 -0.413 -0.029 0.235 0.546 0.794 0.794   || dis=0.00 || select=6/8
009/019-th : 0.080 0.088 0.103 0.112 0.128 0.138 0.159 0.192  ||  -0.403 -0.314 -0.157 -0.066 0.060 0.139 0.280 0.471   || dis=0.03 || select=7/8
010/019-th : 0.094 0.101 0.109 0.120 0.130 0.151 0.146 0.150  ||  -0.266 -0.199 -0.125 -0.029 0.054 0.201 0.172 0.196   || dis=0.00 || select=5/8
011/019-th : 0.094 0.098 0.106 0.117 0.130 0.133 0.155 0.166  ||  -0.270 -0.220 -0.142 -0.050 0.062 0.084 0.235 0.304   || dis=0.01 || select=7/8
012/019-th : 0.111 0.112 0.117 0.120 0.129 0.130 0.138 0.143  ||  -0.120 -0.107 -0.062 -0.036 0.031 0.038 0.104 0.136   || dis=0.00 || select=7/8
013/019-th : 0.018 0.024 0.029 0.045 0.054 0.097 0.201 0.531  ||  -1.272 -0.988 -0.822 -0.379 -0.204 0.394 1.118 2.091  || dis=0.33 || select=7/8
014/019-th : 0.027 0.040 0.054 0.066 0.097 0.147 0.244 0.326  ||  -1.210 -0.811 -0.519 -0.312 0.068 0.490 0.993 1.284   || dis=0.08 || select=7/8
015/019-th : 0.012 0.021 0.029 0.040 0.054 0.095 0.207 0.542  ||  -1.585 -1.064 -0.734 -0.419 -0.107 0.453 1.235 2.195  || dis=0.34 || select=7/8
016/019-th : 0.055 0.073 0.093 0.124 0.144 0.161 0.169 0.182  ||  -0.754 -0.468 -0.221 0.066 0.216 0.331 0.378 0.450    || dis=0.01 || select=7/8
017/019-th : 0.110 0.113 0.123 0.123 0.125 0.124 0.139 0.142  ||  -0.121 -0.094 -0.014 -0.013 0.000 -0.005 0.109 0.130  || dis=0.00 || select=7/8
018/019-th : 0.084 0.097 0.121 0.134 0.131 0.138 0.141 0.155  ||  -0.378 -0.233 -0.015 0.086 0.064 0.121 0.137 0.232    || dis=0.01 || select=7/8
[epoch=325/600] FLOP : 27.92 MB, ratio : 0.6842, Expected-ratio : 0.7000, Discrepancy : 0.098
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:34:21] [epoch=325/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.154 (1.154)  Prec@1 60.16 (60.16) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:34:27] [epoch=325/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.667 (2.119)  Prec@1 57.74 (39.38) Prec@5 92.26 (81.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.38 Prec@5 81.31 Error@1 60.62 Error@5 18.69 Loss:2.119
***[2020-01-29 08:34:27]*** VALID [epoch=325/600] loss = 2.118782, accuracy@1 = 39.38, accuracy@5 = 81.31 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:34:27]*** start epoch=326/600 Time Left: [02:25:45], LR=[0.043214 ~ 0.043214], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=326, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2174968475359544, FLOP=40.81
[Search] : epoch=326/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:34:28] [epoch=326/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.757 (0.757)  Prec@1 74.61 (74.61) Prec@5 98.44 (98.44) Acls-loss 0.930 (0.930) FLOP-Loss 0.000 (0.000) Arch-Loss 0.930 (0.930)
**TRAIN** [2020-01-29 08:34:52] [epoch=326/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 0.798 (0.774)  Prec@1 72.62 (73.90) Prec@5 98.21 (98.06) Acls-loss 0.616 (0.816) FLOP-Loss 0.000 (0.000) Arch-Loss 0.616 (0.816)
 **TRAIN** Prec@1 73.90 Prec@5 98.06 Error@1 26.10 Error@5 1.94 Base-Loss:0.774, Arch-Loss=0.816
***[2020-01-29 08:34:52]*** TRAIN [epoch=326/600] base-loss = 0.773907, arch-loss = 0.816134, accuracy-1 = 73.90, accuracy-5 = 98.06
[epoch=326/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.552832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.462 0.193 0.346  ||  0.3291 -0.5442 0.0403  || discrepancy=0.12 || select=0/3
001/003-th : 0.339 0.134 0.527  ||  0.0629 -0.8666 0.5040  || discrepancy=0.19 || select=2/3
002/003-th : 0.008 0.037 0.956  ||  -2.3142 -0.7305 2.5289  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.089 0.093 0.132 0.149 0.196 0.240  ||  -1.013 -0.567 -0.187 -0.151 0.201 0.326 0.598 0.802   || dis=0.04 || select=7/8
001/019-th : 0.117 0.127 0.125 0.133 0.139 0.125 0.118 0.115  ||  -0.051 0.027 0.011 0.074 0.117 0.013 -0.043 -0.073    || dis=0.01 || select=4/8
002/019-th : 0.115 0.120 0.127 0.135 0.133 0.132 0.124 0.113  ||  -0.075 -0.033 0.022 0.086 0.068 0.059 -0.000 -0.093   || dis=0.00 || select=3/8
003/019-th : 0.104 0.109 0.123 0.124 0.136 0.134 0.130 0.140  ||  -0.173 -0.127 -0.009 -0.001 0.096 0.075 0.052 0.119   || dis=0.00 || select=7/8
004/019-th : 0.110 0.116 0.118 0.118 0.133 0.127 0.140 0.138  ||  -0.123 -0.076 -0.053 -0.060 0.063 0.015 0.116 0.101   || dis=0.00 || select=6/8
005/019-th : 0.101 0.114 0.121 0.119 0.128 0.136 0.134 0.146  ||  -0.211 -0.084 -0.026 -0.043 0.029 0.092 0.075 0.157   || dis=0.01 || select=7/8
006/019-th : 0.118 0.109 0.114 0.115 0.127 0.125 0.148 0.142  ||  -0.053 -0.132 -0.090 -0.079 0.019 0.003 0.169 0.130   || dis=0.01 || select=6/8
007/019-th : 0.040 0.054 0.084 0.094 0.136 0.160 0.190 0.242  ||  -0.972 -0.678 -0.228 -0.118 0.249 0.414 0.583 0.828   || dis=0.05 || select=7/8
008/019-th : 0.032 0.046 0.068 0.097 0.128 0.176 0.226 0.226  ||  -1.148 -0.783 -0.392 -0.036 0.239 0.556 0.808 0.809   || dis=0.00 || select=7/8
009/019-th : 0.078 0.087 0.103 0.112 0.126 0.140 0.157 0.197  ||  -0.432 -0.317 -0.146 -0.071 0.051 0.156 0.274 0.497   || dis=0.04 || select=7/8
010/019-th : 0.093 0.101 0.108 0.119 0.132 0.151 0.147 0.150  ||  -0.279 -0.199 -0.128 -0.033 0.068 0.202 0.177 0.198   || dis=0.00 || select=5/8
011/019-th : 0.092 0.098 0.106 0.115 0.129 0.134 0.156 0.169  ||  -0.285 -0.227 -0.141 -0.063 0.055 0.092 0.243 0.325   || dis=0.01 || select=7/8
012/019-th : 0.109 0.112 0.117 0.118 0.130 0.132 0.139 0.144  ||  -0.133 -0.111 -0.068 -0.051 0.040 0.057 0.107 0.144   || dis=0.00 || select=7/8
013/019-th : 0.018 0.024 0.029 0.044 0.054 0.096 0.202 0.533  ||  -1.272 -1.000 -0.822 -0.398 -0.187 0.383 1.132 2.100  || dis=0.33 || select=7/8
014/019-th : 0.026 0.039 0.054 0.065 0.095 0.146 0.244 0.331  ||  -1.222 -0.821 -0.512 -0.318 0.057 0.487 1.001 1.307   || dis=0.09 || select=7/8
015/019-th : 0.012 0.020 0.029 0.039 0.054 0.094 0.204 0.547  ||  -1.576 -1.097 -0.729 -0.421 -0.099 0.454 1.225 2.211  || dis=0.34 || select=7/8
016/019-th : 0.054 0.071 0.092 0.123 0.142 0.162 0.171 0.185  ||  -0.762 -0.482 -0.229 0.060 0.204 0.337 0.389 0.471    || dis=0.01 || select=7/8
017/019-th : 0.109 0.111 0.121 0.121 0.124 0.126 0.143 0.145  ||  -0.136 -0.115 -0.030 -0.025 -0.003 0.010 0.135 0.152  || dis=0.00 || select=7/8
018/019-th : 0.083 0.096 0.119 0.132 0.131 0.138 0.143 0.158  ||  -0.393 -0.243 -0.030 0.071 0.066 0.118 0.158 0.256    || dis=0.02 || select=7/8
[epoch=326/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.100
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:34:53] [epoch=326/600][000/098] Time 0.35 (0.35) Data 0.28 (0.28) Loss 1.514 (1.514)  Prec@1 52.34 (52.34) Prec@5 92.19 (92.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:34:59] [epoch=326/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.644 (2.254)  Prec@1 39.29 (37.66) Prec@5 82.74 (81.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.66 Prec@5 81.14 Error@1 62.34 Error@5 18.86 Loss:2.254
***[2020-01-29 08:34:59]*** VALID [epoch=326/600] loss = 2.254361, accuracy@1 = 37.66, accuracy@5 = 81.14 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:34:59]*** start epoch=327/600 Time Left: [02:25:12], LR=[0.042955 ~ 0.042955], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=327, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.2047919817529227, FLOP=40.81
[Search] : epoch=327/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:34:59] [epoch=327/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.707 (0.707)  Prec@1 75.00 (75.00) Prec@5 98.83 (98.83) Acls-loss 0.891 (0.891) FLOP-Loss 0.000 (0.000) Arch-Loss 0.891 (0.891)
**TRAIN** [2020-01-29 08:35:24] [epoch=327/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.844 (0.757)  Prec@1 69.64 (74.24) Prec@5 97.62 (98.08) Acls-loss 0.960 (0.795) FLOP-Loss 0.000 (0.086) Arch-Loss 0.960 (0.968)
 **TRAIN** Prec@1 74.24 Prec@5 98.08 Error@1 25.76 Error@5 1.92 Base-Loss:0.757, Arch-Loss=0.968
***[2020-01-29 08:35:24]*** TRAIN [epoch=327/600] base-loss = 0.757403, arch-loss = 0.968065, accuracy-1 = 74.24, accuracy-5 = 98.08
[epoch=327/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.923072)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.461 0.191 0.348  ||  0.3278 -0.5550 0.0450  || discrepancy=0.11 || select=0/3
001/003-th : 0.337 0.133 0.530  ||  0.0583 -0.8752 0.5116  || discrepancy=0.19 || select=2/3
002/003-th : 0.007 0.036 0.957  ||  -2.3251 -0.7385 2.5451  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.089 0.092 0.131 0.150 0.195 0.243  ||  -1.024 -0.570 -0.185 -0.152 0.198 0.331 0.596 0.815   || dis=0.05 || select=7/8
001/019-th : 0.118 0.129 0.126 0.132 0.138 0.125 0.118 0.115  ||  -0.048 0.038 0.020 0.063 0.107 0.009 -0.050 -0.074    || dis=0.01 || select=4/8
002/019-th : 0.117 0.122 0.128 0.135 0.132 0.130 0.122 0.113  ||  -0.064 -0.021 0.031 0.084 0.058 0.040 -0.016 -0.093   || dis=0.00 || select=3/8
003/019-th : 0.103 0.110 0.122 0.126 0.135 0.135 0.131 0.138  ||  -0.185 -0.120 -0.014 0.019 0.090 0.090 0.058 0.106    || dis=0.00 || select=7/8
004/019-th : 0.110 0.115 0.120 0.118 0.133 0.127 0.140 0.137  ||  -0.123 -0.078 -0.037 -0.058 0.064 0.016 0.118 0.090   || dis=0.00 || select=6/8
005/019-th : 0.102 0.115 0.121 0.118 0.128 0.137 0.134 0.145  ||  -0.204 -0.079 -0.032 -0.051 0.030 0.095 0.075 0.152   || dis=0.01 || select=7/8
006/019-th : 0.117 0.109 0.115 0.114 0.126 0.128 0.148 0.142  ||  -0.067 -0.133 -0.078 -0.086 0.013 0.028 0.169 0.130   || dis=0.01 || select=6/8
007/019-th : 0.041 0.053 0.086 0.094 0.134 0.161 0.188 0.244  ||  -0.960 -0.698 -0.207 -0.116 0.233 0.419 0.571 0.834   || dis=0.06 || select=7/8
008/019-th : 0.031 0.046 0.067 0.098 0.130 0.178 0.225 0.224  ||  -1.162 -0.779 -0.402 -0.030 0.258 0.572 0.806 0.800   || dis=0.00 || select=6/8
009/019-th : 0.077 0.088 0.106 0.111 0.125 0.139 0.158 0.196  ||  -0.438 -0.309 -0.127 -0.073 0.041 0.150 0.277 0.493   || dis=0.04 || select=7/8
010/019-th : 0.092 0.100 0.109 0.120 0.132 0.150 0.147 0.149  ||  -0.285 -0.202 -0.125 -0.028 0.075 0.202 0.178 0.194   || dis=0.00 || select=5/8
011/019-th : 0.092 0.097 0.107 0.115 0.131 0.135 0.154 0.170  ||  -0.289 -0.237 -0.137 -0.064 0.066 0.102 0.228 0.331   || dis=0.02 || select=7/8
012/019-th : 0.109 0.112 0.114 0.118 0.131 0.132 0.138 0.146  ||  -0.133 -0.106 -0.090 -0.057 0.048 0.060 0.101 0.156   || dis=0.01 || select=7/8
013/019-th : 0.018 0.024 0.029 0.043 0.054 0.097 0.200 0.535  ||  -1.277 -0.994 -0.822 -0.409 -0.189 0.399 1.122 2.108  || dis=0.34 || select=7/8
014/019-th : 0.027 0.039 0.054 0.065 0.094 0.148 0.243 0.330  ||  -1.210 -0.823 -0.517 -0.317 0.052 0.497 0.997 1.302   || dis=0.09 || select=7/8
015/019-th : 0.012 0.020 0.029 0.039 0.055 0.095 0.204 0.546  ||  -1.571 -1.104 -0.730 -0.434 -0.090 0.460 1.224 2.210  || dis=0.34 || select=7/8
016/019-th : 0.055 0.072 0.091 0.124 0.141 0.162 0.169 0.186  ||  -0.749 -0.481 -0.237 0.068 0.199 0.336 0.381 0.473    || dis=0.02 || select=7/8
017/019-th : 0.109 0.112 0.119 0.120 0.126 0.125 0.142 0.147  ||  -0.133 -0.107 -0.047 -0.039 0.010 0.005 0.128 0.165   || dis=0.01 || select=7/8
018/019-th : 0.083 0.097 0.119 0.132 0.132 0.137 0.143 0.158  ||  -0.390 -0.238 -0.033 0.072 0.078 0.111 0.151 0.254    || dis=0.02 || select=7/8
[epoch=327/600] FLOP : 27.92 MB, ratio : 0.6842, Expected-ratio : 0.7000, Discrepancy : 0.101
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:35:24] [epoch=327/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.373 (2.373)  Prec@1 17.19 (17.19) Prec@5 68.36 (68.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:35:30] [epoch=327/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.693 (2.418)  Prec@1 27.98 (33.68) Prec@5 72.62 (78.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.68 Prec@5 78.10 Error@1 66.32 Error@5 21.90 Loss:2.418
***[2020-01-29 08:35:30]*** VALID [epoch=327/600] loss = 2.417944, accuracy@1 = 33.68, accuracy@5 = 78.10 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:35:30]*** start epoch=328/600 Time Left: [02:24:40], LR=[0.042696 ~ 0.042696], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=328, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.192096580022092, FLOP=40.81
[Search] : epoch=328/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:35:31] [epoch=328/600][000/098] Time 0.73 (0.73) Data 0.35 (0.35) Base-Loss 0.752 (0.752)  Prec@1 69.92 (69.92) Prec@5 99.22 (99.22) Acls-loss 0.681 (0.681) FLOP-Loss 0.000 (0.000) Arch-Loss 0.681 (0.681)
**TRAIN** [2020-01-29 08:35:55] [epoch=328/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.696 (0.758)  Prec@1 74.40 (73.89) Prec@5 98.81 (97.95) Acls-loss 1.030 (0.799) FLOP-Loss 0.000 (0.258) Arch-Loss 1.030 (1.316)
 **TRAIN** Prec@1 73.89 Prec@5 97.95 Error@1 26.11 Error@5 2.05 Base-Loss:0.758, Arch-Loss=1.316
***[2020-01-29 08:35:55]*** TRAIN [epoch=328/600] base-loss = 0.758478, arch-loss = 1.316183, accuracy-1 = 73.89, accuracy-5 = 97.95
[epoch=328/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 11, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.923072)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.474 0.189 0.337  ||  0.3582 -0.5600 0.0152  || discrepancy=0.14 || select=0/3
001/003-th : 0.348 0.135 0.518  ||  0.0859 -0.8621 0.4841  || discrepancy=0.17 || select=2/3
002/003-th : 0.007 0.037 0.956  ||  -2.3202 -0.7243 2.5395  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.091 0.092 0.133 0.148 0.195 0.242  ||  -1.013 -0.570 -0.173 -0.162 0.208 0.318 0.593 0.807   || dis=0.05 || select=7/8
001/019-th : 0.120 0.132 0.130 0.133 0.135 0.123 0.115 0.112  ||  -0.031 0.063 0.048 0.071 0.086 -0.008 -0.075 -0.097   || dis=0.00 || select=4/8
002/019-th : 0.121 0.125 0.131 0.137 0.132 0.127 0.118 0.110  ||  -0.026 0.001 0.051 0.099 0.058 0.019 -0.054 -0.127    || dis=0.01 || select=3/8
003/019-th : 0.103 0.112 0.124 0.129 0.136 0.132 0.129 0.134  ||  -0.183 -0.100 0.003 0.042 0.098 0.069 0.041 0.079     || dis=0.00 || select=4/8
004/019-th : 0.112 0.119 0.122 0.118 0.132 0.127 0.137 0.132  ||  -0.103 -0.044 -0.025 -0.056 0.061 0.021 0.093 0.057   || dis=0.01 || select=6/8
005/019-th : 0.104 0.118 0.123 0.119 0.127 0.134 0.132 0.142  ||  -0.181 -0.052 -0.016 -0.047 0.016 0.074 0.059 0.130   || dis=0.01 || select=7/8
006/019-th : 0.120 0.112 0.118 0.116 0.125 0.126 0.143 0.139  ||  -0.041 -0.110 -0.052 -0.070 0.001 0.010 0.139 0.111   || dis=0.00 || select=6/8
007/019-th : 0.041 0.054 0.086 0.095 0.137 0.162 0.185 0.240  ||  -0.945 -0.689 -0.215 -0.115 0.250 0.419 0.554 0.812   || dis=0.05 || select=7/8
008/019-th : 0.031 0.047 0.067 0.099 0.132 0.179 0.224 0.220  ||  -1.168 -0.765 -0.408 -0.019 0.272 0.573 0.800 0.781   || dis=0.00 || select=6/8
009/019-th : 0.078 0.089 0.108 0.115 0.124 0.138 0.155 0.193  ||  -0.436 -0.303 -0.104 -0.042 0.036 0.137 0.255 0.476   || dis=0.04 || select=7/8
010/019-th : 0.093 0.103 0.110 0.120 0.131 0.148 0.146 0.148  ||  -0.276 -0.179 -0.114 -0.025 0.064 0.187 0.171 0.184   || dis=0.00 || select=5/8
011/019-th : 0.095 0.098 0.109 0.117 0.130 0.134 0.150 0.167  ||  -0.259 -0.223 -0.122 -0.045 0.053 0.087 0.202 0.306   || dis=0.02 || select=7/8
012/019-th : 0.112 0.115 0.115 0.118 0.131 0.133 0.136 0.141  ||  -0.108 -0.085 -0.082 -0.057 0.047 0.063 0.086 0.126   || dis=0.00 || select=7/8
013/019-th : 0.018 0.024 0.028 0.044 0.054 0.096 0.199 0.537  ||  -1.271 -0.985 -0.833 -0.398 -0.191 0.389 1.118 2.111  || dis=0.34 || select=7/8
014/019-th : 0.027 0.039 0.054 0.066 0.096 0.148 0.241 0.329  ||  -1.214 -0.831 -0.509 -0.303 0.066 0.496 0.986 1.296   || dis=0.09 || select=7/8
015/019-th : 0.013 0.020 0.029 0.038 0.056 0.096 0.204 0.545  ||  -1.564 -1.088 -0.726 -0.455 -0.081 0.463 1.218 2.201  || dis=0.34 || select=7/8
016/019-th : 0.057 0.073 0.093 0.125 0.143 0.160 0.167 0.182  ||  -0.715 -0.465 -0.225 0.074 0.207 0.318 0.361 0.445    || dis=0.01 || select=7/8
017/019-th : 0.110 0.114 0.121 0.124 0.125 0.123 0.140 0.143  ||  -0.123 -0.087 -0.029 -0.009 0.001 -0.011 0.114 0.134  || dis=0.00 || select=7/8
018/019-th : 0.084 0.099 0.123 0.132 0.131 0.135 0.140 0.156  ||  -0.383 -0.214 -0.001 0.070 0.068 0.097 0.133 0.239    || dis=0.02 || select=7/8
[epoch=328/600] FLOP : 27.92 MB, ratio : 0.6842, Expected-ratio : 0.7000, Discrepancy : 0.101
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:35:55] [epoch=328/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.629 (2.629)  Prec@1 25.00 (25.00) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:36:01] [epoch=328/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.921 (2.476)  Prec@1 42.86 (35.19) Prec@5 89.88 (79.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.19 Prec@5 79.06 Error@1 64.81 Error@5 20.94 Loss:2.476
***[2020-01-29 08:36:01]*** VALID [epoch=328/600] loss = 2.476484, accuracy@1 = 35.19, accuracy@5 = 79.06 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:36:01]*** start epoch=329/600 Time Left: [02:24:07], LR=[0.042437 ~ 0.042437], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=329, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.179410990394313, FLOP=40.81
[Search] : epoch=329/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:36:02] [epoch=329/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.882 (0.882)  Prec@1 69.92 (69.92) Prec@5 98.05 (98.05) Acls-loss 0.922 (0.922) FLOP-Loss 0.000 (0.000) Arch-Loss 0.922 (0.922)
**TRAIN** [2020-01-29 08:36:26] [epoch=329/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.683 (0.762)  Prec@1 76.19 (74.25) Prec@5 98.21 (98.02) Acls-loss 0.801 (0.807) FLOP-Loss 0.000 (0.200) Arch-Loss 0.801 (1.207)
 **TRAIN** Prec@1 74.25 Prec@5 98.02 Error@1 25.75 Error@5 1.98 Base-Loss:0.762, Arch-Loss=1.207
***[2020-01-29 08:36:26]*** TRAIN [epoch=329/600] base-loss = 0.761615, arch-loss = 1.207458, accuracy-1 = 74.25, accuracy-5 = 98.02
[epoch=329/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 11, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.231872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.483 0.185 0.331  ||  0.3776 -0.5801 -0.0002  || discrepancy=0.15 || select=0/3
001/003-th : 0.355 0.135 0.510  ||  0.1053 -0.8631 0.4669  || discrepancy=0.16 || select=2/3
002/003-th : 0.007 0.036 0.957  ||  -2.3205 -0.7336 2.5477  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.091 0.092 0.134 0.148 0.195 0.240  ||  -1.017 -0.574 -0.167 -0.159 0.221 0.316 0.591 0.802   || dis=0.04 || select=7/8
001/019-th : 0.123 0.133 0.133 0.133 0.133 0.121 0.114 0.110  ||  -0.011 0.072 0.074 0.070 0.073 -0.022 -0.087 -0.120   || dis=0.00 || select=2/8
002/019-th : 0.124 0.127 0.131 0.139 0.131 0.125 0.116 0.107  ||  -0.004 0.021 0.055 0.110 0.053 0.003 -0.070 -0.152    || dis=0.01 || select=3/8
003/019-th : 0.104 0.113 0.125 0.130 0.137 0.130 0.129 0.133  ||  -0.176 -0.089 0.007 0.047 0.101 0.047 0.037 0.070     || dis=0.00 || select=4/8
004/019-th : 0.114 0.120 0.122 0.121 0.130 0.127 0.135 0.131  ||  -0.090 -0.035 -0.024 -0.032 0.040 0.021 0.080 0.046   || dis=0.00 || select=6/8
005/019-th : 0.106 0.118 0.125 0.120 0.127 0.132 0.131 0.140  ||  -0.166 -0.053 0.004 -0.040 0.016 0.055 0.048 0.117    || dis=0.01 || select=7/8
006/019-th : 0.121 0.114 0.120 0.116 0.124 0.125 0.142 0.137  ||  -0.028 -0.088 -0.035 -0.071 -0.006 0.003 0.127 0.094  || dis=0.00 || select=6/8
007/019-th : 0.041 0.055 0.087 0.097 0.138 0.163 0.180 0.239  ||  -0.960 -0.673 -0.206 -0.098 0.255 0.424 0.523 0.806   || dis=0.06 || select=7/8
008/019-th : 0.032 0.047 0.068 0.099 0.130 0.178 0.225 0.221  ||  -1.160 -0.757 -0.402 -0.026 0.251 0.568 0.801 0.782   || dis=0.00 || select=6/8
009/019-th : 0.078 0.091 0.111 0.117 0.124 0.137 0.153 0.191  ||  -0.438 -0.285 -0.084 -0.030 0.033 0.129 0.237 0.460   || dis=0.04 || select=7/8
010/019-th : 0.096 0.104 0.110 0.120 0.130 0.148 0.144 0.148  ||  -0.255 -0.167 -0.114 -0.026 0.054 0.182 0.155 0.182   || dis=0.00 || select=5/8
011/019-th : 0.097 0.100 0.111 0.118 0.129 0.132 0.149 0.164  ||  -0.234 -0.213 -0.106 -0.046 0.048 0.071 0.189 0.289   || dis=0.02 || select=7/8
012/019-th : 0.114 0.116 0.115 0.120 0.129 0.131 0.135 0.140  ||  -0.091 -0.071 -0.079 -0.042 0.032 0.051 0.076 0.115   || dis=0.01 || select=7/8
013/019-th : 0.018 0.025 0.028 0.043 0.053 0.096 0.197 0.541  ||  -1.266 -0.966 -0.828 -0.413 -0.208 0.395 1.111 2.122  || dis=0.34 || select=7/8
014/019-th : 0.026 0.039 0.054 0.067 0.099 0.146 0.241 0.328  ||  -1.225 -0.846 -0.510 -0.295 0.095 0.487 0.987 1.297   || dis=0.09 || select=7/8
015/019-th : 0.013 0.021 0.029 0.038 0.056 0.097 0.206 0.540  ||  -1.553 -1.079 -0.734 -0.466 -0.073 0.466 1.223 2.187  || dis=0.33 || select=7/8
016/019-th : 0.057 0.073 0.092 0.126 0.146 0.158 0.167 0.179  ||  -0.709 -0.460 -0.233 0.080 0.229 0.309 0.362 0.430    || dis=0.01 || select=7/8
017/019-th : 0.112 0.115 0.123 0.123 0.125 0.124 0.138 0.140  ||  -0.112 -0.078 -0.016 -0.016 -0.002 -0.003 0.102 0.118  || dis=0.00 || select=7/8
018/019-th : 0.084 0.101 0.123 0.132 0.130 0.135 0.140 0.155  ||  -0.383 -0.196 0.001 0.069 0.059 0.097 0.134 0.230     || dis=0.01 || select=7/8
[epoch=329/600] FLOP : 27.23 MB, ratio : 0.6672, Expected-ratio : 0.7000, Discrepancy : 0.101
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:36:26] [epoch=329/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.126 (3.126)  Prec@1 30.47 (30.47) Prec@5 73.83 (73.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:36:32] [epoch=329/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.638 (2.489)  Prec@1 30.36 (33.09) Prec@5 73.21 (77.95) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.09 Prec@5 77.95 Error@1 66.91 Error@5 22.05 Loss:2.489
***[2020-01-29 08:36:32]*** VALID [epoch=329/600] loss = 2.488593, accuracy@1 = 33.09, accuracy@5 = 77.95 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:36:32]*** start epoch=330/600 Time Left: [02:23:35], LR=[0.042178 ~ 0.042178], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=330, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.1667355606514342, FLOP=40.81
[Search] : epoch=330/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:36:33] [epoch=330/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.922 (0.922)  Prec@1 67.58 (67.58) Prec@5 96.48 (96.48) Acls-loss 0.848 (0.848) FLOP-Loss 0.000 (0.000) Arch-Loss 0.848 (0.848)
**TRAIN** [2020-01-29 08:36:57] [epoch=330/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.633 (0.766)  Prec@1 77.98 (74.01) Prec@5 99.40 (98.12) Acls-loss 0.736 (0.805) FLOP-Loss 0.000 (0.057) Arch-Loss 0.736 (0.919)
 **TRAIN** Prec@1 74.01 Prec@5 98.12 Error@1 25.99 Error@5 1.88 Base-Loss:0.766, Arch-Loss=0.919
***[2020-01-29 08:36:57]*** TRAIN [epoch=330/600] base-loss = 0.766279, arch-loss = 0.918935, accuracy-1 = 74.01, accuracy-5 = 98.12
[epoch=330/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 11, 14, 16, 14, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.10944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.483 0.184 0.333  ||  0.3764 -0.5898 0.0039  || discrepancy=0.15 || select=0/3
001/003-th : 0.352 0.135 0.512  ||  0.0988 -0.8579 0.4734  || discrepancy=0.16 || select=2/3
002/003-th : 0.007 0.036 0.957  ||  -2.3161 -0.7326 2.5479  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.092 0.092 0.134 0.150 0.191 0.242  ||  -1.027 -0.574 -0.157 -0.155 0.220 0.328 0.571 0.808   || dis=0.05 || select=7/8
001/019-th : 0.121 0.134 0.134 0.133 0.133 0.120 0.114 0.111  ||  -0.026 0.078 0.082 0.070 0.075 -0.031 -0.087 -0.108   || dis=0.00 || select=2/8
002/019-th : 0.123 0.127 0.131 0.141 0.131 0.124 0.116 0.107  ||  -0.013 0.024 0.052 0.124 0.055 -0.001 -0.064 -0.151   || dis=0.01 || select=3/8
003/019-th : 0.103 0.113 0.123 0.128 0.138 0.131 0.131 0.133  ||  -0.186 -0.091 -0.007 0.037 0.108 0.053 0.056 0.075    || dis=0.01 || select=4/8
004/019-th : 0.112 0.120 0.119 0.120 0.133 0.128 0.135 0.132  ||  -0.104 -0.034 -0.047 -0.039 0.063 0.029 0.081 0.057   || dis=0.00 || select=6/8
005/019-th : 0.106 0.118 0.125 0.120 0.128 0.132 0.132 0.140  ||  -0.168 -0.055 -0.001 -0.036 0.022 0.054 0.058 0.114   || dis=0.01 || select=7/8
006/019-th : 0.119 0.114 0.120 0.116 0.123 0.126 0.144 0.138  ||  -0.043 -0.090 -0.035 -0.074 -0.011 0.007 0.142 0.098  || dis=0.01 || select=6/8
007/019-th : 0.040 0.055 0.085 0.095 0.137 0.162 0.181 0.246  ||  -0.967 -0.664 -0.224 -0.116 0.250 0.420 0.529 0.837   || dis=0.07 || select=7/8
008/019-th : 0.031 0.047 0.067 0.099 0.128 0.177 0.228 0.223  ||  -1.165 -0.767 -0.406 -0.015 0.241 0.561 0.817 0.793   || dis=0.01 || select=6/8
009/019-th : 0.077 0.090 0.111 0.116 0.124 0.136 0.153 0.192  ||  -0.440 -0.288 -0.076 -0.038 0.030 0.126 0.239 0.467   || dis=0.04 || select=7/8
010/019-th : 0.096 0.102 0.109 0.120 0.129 0.147 0.145 0.151  ||  -0.248 -0.187 -0.121 -0.029 0.046 0.176 0.162 0.199   || dis=0.00 || select=7/8
011/019-th : 0.099 0.099 0.109 0.117 0.132 0.130 0.149 0.166  ||  -0.224 -0.216 -0.124 -0.052 0.068 0.051 0.189 0.299   || dis=0.02 || select=7/8
012/019-th : 0.114 0.114 0.115 0.120 0.128 0.131 0.136 0.141  ||  -0.092 -0.087 -0.082 -0.038 0.028 0.048 0.089 0.122   || dis=0.00 || select=7/8
013/019-th : 0.018 0.024 0.028 0.042 0.052 0.093 0.188 0.555  ||  -1.264 -0.959 -0.816 -0.419 -0.212 0.375 1.081 2.164  || dis=0.37 || select=7/8
014/019-th : 0.026 0.038 0.053 0.065 0.098 0.147 0.246 0.327  ||  -1.228 -0.843 -0.530 -0.313 0.093 0.497 1.013 1.299   || dis=0.08 || select=7/8
015/019-th : 0.013 0.021 0.029 0.038 0.055 0.096 0.204 0.545  ||  -1.545 -1.070 -0.747 -0.472 -0.085 0.465 1.220 2.203  || dis=0.34 || select=7/8
016/019-th : 0.058 0.074 0.090 0.125 0.145 0.160 0.167 0.181  ||  -0.697 -0.459 -0.256 0.076 0.222 0.321 0.359 0.440    || dis=0.01 || select=7/8
017/019-th : 0.111 0.116 0.123 0.122 0.124 0.123 0.138 0.142  ||  -0.115 -0.070 -0.017 -0.020 -0.006 -0.016 0.101 0.128  || dis=0.00 || select=7/8
018/019-th : 0.083 0.102 0.122 0.133 0.129 0.134 0.139 0.157  ||  -0.388 -0.183 -0.011 0.081 0.049 0.084 0.126 0.247    || dis=0.02 || select=7/8
[epoch=330/600] FLOP : 28.11 MB, ratio : 0.6887, Expected-ratio : 0.7000, Discrepancy : 0.103
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:36:58] [epoch=330/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.664 (1.664)  Prec@1 50.39 (50.39) Prec@5 92.19 (92.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:37:04] [epoch=330/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.556 (2.349)  Prec@1 29.76 (37.16) Prec@5 73.21 (80.75) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.16 Prec@5 80.75 Error@1 62.84 Error@5 19.25 Loss:2.349
***[2020-01-29 08:37:04]*** VALID [epoch=330/600] loss = 2.349021, accuracy@1 = 37.16, accuracy@5 = 80.75 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:37:04]*** start epoch=331/600 Time Left: [02:23:03], LR=[0.041920 ~ 0.041920], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=331, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.1540706382967656, FLOP=40.81
[Search] : epoch=331/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:37:05] [epoch=331/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.731 (0.731)  Prec@1 73.05 (73.05) Prec@5 98.83 (98.83) Acls-loss 0.749 (0.749) FLOP-Loss 0.000 (0.000) Arch-Loss 0.749 (0.749)
**TRAIN** [2020-01-29 08:37:29] [epoch=331/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.849 (0.778)  Prec@1 76.79 (73.44) Prec@5 97.02 (97.89) Acls-loss 0.917 (0.794) FLOP-Loss 0.000 (0.029) Arch-Loss 0.917 (0.851)
 **TRAIN** Prec@1 73.44 Prec@5 97.89 Error@1 26.56 Error@5 2.11 Base-Loss:0.778, Arch-Loss=0.851
***[2020-01-29 08:37:29]*** TRAIN [epoch=331/600] base-loss = 0.778142, arch-loss = 0.851310, accuracy-1 = 73.44, accuracy-5 = 97.89
[epoch=331/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 28, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.10944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.478 0.183 0.340  ||  0.3626 -0.5994 0.0214  || discrepancy=0.14 || select=0/3
001/003-th : 0.348 0.135 0.516  ||  0.0893 -0.8556 0.4835  || discrepancy=0.17 || select=2/3
002/003-th : 0.007 0.036 0.957  ||  -2.3124 -0.7344 2.5499  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.091 0.091 0.135 0.149 0.192 0.243  ||  -1.022 -0.570 -0.168 -0.166 0.223 0.324 0.576 0.815   || dis=0.05 || select=7/8
001/019-th : 0.120 0.134 0.134 0.131 0.134 0.120 0.115 0.112  ||  -0.036 0.075 0.081 0.058 0.078 -0.031 -0.073 -0.101   || dis=0.00 || select=2/8
002/019-th : 0.121 0.127 0.131 0.140 0.132 0.124 0.117 0.108  ||  -0.028 0.020 0.055 0.116 0.063 -0.000 -0.061 -0.138   || dis=0.01 || select=3/8
003/019-th : 0.103 0.112 0.123 0.128 0.136 0.128 0.133 0.136  ||  -0.182 -0.103 -0.009 0.032 0.094 0.032 0.070 0.094    || dis=0.00 || select=7/8
004/019-th : 0.112 0.118 0.118 0.120 0.132 0.129 0.138 0.134  ||  -0.112 -0.056 -0.059 -0.039 0.055 0.032 0.100 0.074   || dis=0.00 || select=6/8
005/019-th : 0.106 0.117 0.123 0.120 0.128 0.132 0.133 0.140  ||  -0.164 -0.064 -0.011 -0.040 0.026 0.059 0.066 0.115   || dis=0.01 || select=7/8
006/019-th : 0.118 0.113 0.119 0.115 0.125 0.126 0.145 0.138  ||  -0.054 -0.097 -0.045 -0.081 0.002 0.012 0.154 0.103   || dis=0.01 || select=6/8
007/019-th : 0.040 0.054 0.084 0.094 0.137 0.160 0.183 0.249  ||  -0.972 -0.680 -0.230 -0.122 0.259 0.411 0.545 0.855   || dis=0.07 || select=7/8
008/019-th : 0.031 0.046 0.066 0.098 0.128 0.176 0.229 0.226  ||  -1.182 -0.772 -0.414 -0.020 0.247 0.565 0.828 0.818   || dis=0.00 || select=6/8
009/019-th : 0.077 0.089 0.113 0.115 0.122 0.135 0.154 0.194  ||  -0.446 -0.297 -0.062 -0.040 0.018 0.115 0.246 0.478   || dis=0.04 || select=7/8
010/019-th : 0.095 0.103 0.109 0.122 0.130 0.147 0.145 0.149  ||  -0.259 -0.183 -0.120 -0.010 0.054 0.173 0.160 0.192   || dis=0.00 || select=7/8
011/019-th : 0.098 0.099 0.110 0.118 0.130 0.129 0.148 0.168  ||  -0.231 -0.220 -0.111 -0.043 0.053 0.046 0.185 0.311   || dis=0.02 || select=7/8
012/019-th : 0.111 0.115 0.116 0.119 0.129 0.132 0.137 0.142  ||  -0.117 -0.084 -0.075 -0.048 0.032 0.060 0.096 0.127   || dis=0.00 || select=7/8
013/019-th : 0.018 0.024 0.028 0.042 0.051 0.092 0.186 0.557  ||  -1.249 -0.959 -0.809 -0.418 -0.214 0.370 1.068 2.168  || dis=0.37 || select=7/8
014/019-th : 0.026 0.038 0.052 0.064 0.096 0.144 0.251 0.329  ||  -1.238 -0.843 -0.526 -0.331 0.079 0.489 1.041 1.314   || dis=0.08 || select=7/8
015/019-th : 0.013 0.021 0.028 0.038 0.056 0.096 0.203 0.545  ||  -1.542 -1.076 -0.752 -0.466 -0.077 0.468 1.214 2.200  || dis=0.34 || select=7/8
016/019-th : 0.057 0.073 0.090 0.124 0.144 0.161 0.169 0.183  ||  -0.720 -0.463 -0.258 0.067 0.213 0.329 0.376 0.454    || dis=0.01 || select=7/8
017/019-th : 0.109 0.113 0.121 0.123 0.124 0.122 0.142 0.145  ||  -0.134 -0.094 -0.028 -0.010 -0.009 -0.019 0.131 0.149  || dis=0.00 || select=7/8
018/019-th : 0.082 0.102 0.121 0.134 0.128 0.135 0.141 0.157  ||  -0.406 -0.184 -0.016 0.091 0.044 0.093 0.139 0.248    || dis=0.02 || select=7/8
[epoch=331/600] FLOP : 28.11 MB, ratio : 0.6887, Expected-ratio : 0.7000, Discrepancy : 0.103
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:37:29] [epoch=331/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.706 (2.706)  Prec@1 21.88 (21.88) Prec@5 67.97 (67.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:37:35] [epoch=331/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 3.093 (2.568)  Prec@1 27.98 (35.89) Prec@5 66.67 (79.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.89 Prec@5 79.04 Error@1 64.11 Error@5 20.96 Loss:2.568
***[2020-01-29 08:37:35]*** VALID [epoch=331/600] loss = 2.568380, accuracy@1 = 35.89, accuracy@5 = 79.04 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:37:35]*** start epoch=332/600 Time Left: [02:22:30], LR=[0.041662 ~ 0.041662], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=332, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.14141657054555, FLOP=40.81
[Search] : epoch=332/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:37:36] [epoch=332/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.851 (0.851)  Prec@1 66.02 (66.02) Prec@5 98.05 (98.05) Acls-loss 0.777 (0.777) FLOP-Loss 0.000 (0.000) Arch-Loss 0.777 (0.777)
**TRAIN** [2020-01-29 08:38:00] [epoch=332/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.707 (0.744)  Prec@1 75.00 (74.56) Prec@5 97.02 (97.95) Acls-loss 0.821 (0.790) FLOP-Loss 0.000 (0.057) Arch-Loss 0.821 (0.905)
 **TRAIN** Prec@1 74.56 Prec@5 97.95 Error@1 25.44 Error@5 2.05 Base-Loss:0.744, Arch-Loss=0.905
***[2020-01-29 08:38:01]*** TRAIN [epoch=332/600] base-loss = 0.743874, arch-loss = 0.904806, accuracy-1 = 74.56, accuracy-5 = 97.95
[epoch=332/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 11, 14, 16, 14, 32, 28, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.923072)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.470 0.184 0.346  ||  0.3445 -0.5920 0.0403  || discrepancy=0.12 || select=0/3
001/003-th : 0.346 0.133 0.520  ||  0.0850 -0.8687 0.4913  || discrepancy=0.17 || select=2/3
002/003-th : 0.008 0.036 0.956  ||  -2.2991 -0.7311 2.5423  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.089 0.090 0.135 0.148 0.194 0.245  ||  -1.009 -0.565 -0.190 -0.182 0.225 0.317 0.587 0.822   || dis=0.05 || select=7/8
001/019-th : 0.119 0.132 0.132 0.130 0.135 0.121 0.117 0.114  ||  -0.039 0.064 0.064 0.043 0.085 -0.026 -0.062 -0.089   || dis=0.00 || select=4/8
002/019-th : 0.121 0.125 0.133 0.140 0.132 0.124 0.117 0.109  ||  -0.030 0.005 0.067 0.118 0.061 -0.001 -0.059 -0.133   || dis=0.01 || select=3/8
003/019-th : 0.102 0.113 0.123 0.126 0.138 0.128 0.133 0.137  ||  -0.200 -0.091 -0.007 0.018 0.106 0.032 0.070 0.100    || dis=0.00 || select=4/8
004/019-th : 0.112 0.118 0.114 0.119 0.131 0.130 0.139 0.136  ||  -0.108 -0.055 -0.088 -0.046 0.049 0.039 0.105 0.086   || dis=0.00 || select=6/8
005/019-th : 0.107 0.118 0.122 0.121 0.129 0.131 0.132 0.139  ||  -0.154 -0.058 -0.026 -0.032 0.036 0.052 0.059 0.110   || dis=0.01 || select=7/8
006/019-th : 0.116 0.112 0.120 0.116 0.125 0.127 0.144 0.140  ||  -0.067 -0.110 -0.042 -0.073 0.004 0.020 0.145 0.118   || dis=0.00 || select=6/8
007/019-th : 0.039 0.054 0.083 0.094 0.134 0.161 0.182 0.254  ||  -0.996 -0.671 -0.243 -0.117 0.244 0.425 0.545 0.879   || dis=0.07 || select=7/8
008/019-th : 0.031 0.046 0.066 0.099 0.124 0.177 0.231 0.227  ||  -1.177 -0.782 -0.413 -0.009 0.217 0.570 0.840 0.820   || dis=0.00 || select=6/8
009/019-th : 0.076 0.089 0.110 0.115 0.122 0.136 0.153 0.199  ||  -0.452 -0.297 -0.084 -0.044 0.013 0.122 0.242 0.504   || dis=0.05 || select=7/8
010/019-th : 0.093 0.103 0.107 0.121 0.133 0.150 0.146 0.148  ||  -0.281 -0.177 -0.136 -0.019 0.074 0.196 0.168 0.186   || dis=0.00 || select=5/8
011/019-th : 0.098 0.098 0.110 0.117 0.131 0.129 0.149 0.169  ||  -0.232 -0.226 -0.112 -0.052 0.062 0.044 0.188 0.316   || dis=0.02 || select=7/8
012/019-th : 0.111 0.113 0.115 0.118 0.131 0.132 0.138 0.143  ||  -0.119 -0.102 -0.081 -0.054 0.046 0.060 0.099 0.139   || dis=0.00 || select=7/8
013/019-th : 0.018 0.024 0.028 0.042 0.050 0.090 0.189 0.559  ||  -1.243 -0.966 -0.824 -0.415 -0.229 0.359 1.094 2.181  || dis=0.37 || select=7/8
014/019-th : 0.026 0.038 0.051 0.064 0.096 0.142 0.254 0.329  ||  -1.231 -0.840 -0.544 -0.328 0.079 0.475 1.054 1.312   || dis=0.08 || select=7/8
015/019-th : 0.013 0.020 0.028 0.039 0.055 0.095 0.201 0.549  ||  -1.556 -1.083 -0.751 -0.442 -0.078 0.456 1.207 2.215  || dis=0.35 || select=7/8
016/019-th : 0.056 0.074 0.090 0.122 0.142 0.161 0.172 0.184  ||  -0.731 -0.452 -0.259 0.052 0.201 0.327 0.393 0.461    || dis=0.01 || select=7/8
017/019-th : 0.109 0.112 0.122 0.121 0.122 0.125 0.142 0.146  ||  -0.132 -0.108 -0.022 -0.026 -0.018 0.004 0.129 0.157  || dis=0.00 || select=7/8
018/019-th : 0.082 0.102 0.120 0.134 0.128 0.135 0.142 0.157  ||  -0.406 -0.188 -0.020 0.092 0.042 0.095 0.150 0.245    || dis=0.02 || select=7/8
[epoch=332/600] FLOP : 27.92 MB, ratio : 0.6842, Expected-ratio : 0.7000, Discrepancy : 0.103
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:38:01] [epoch=332/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.695 (2.695)  Prec@1 29.30 (29.30) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:38:07] [epoch=332/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.305 (2.224)  Prec@1 21.43 (36.44) Prec@5 79.17 (80.63) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.44 Prec@5 80.63 Error@1 63.56 Error@5 19.37 Loss:2.224
***[2020-01-29 08:38:07]*** VALID [epoch=332/600] loss = 2.224297, accuracy@1 = 36.44, accuracy@5 = 80.63 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:38:07]*** start epoch=333/600 Time Left: [02:21:58], LR=[0.041404 ~ 0.041404], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=333, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.1287737043154467, FLOP=40.81
[Search] : epoch=333/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:38:08] [epoch=333/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.693 (0.693)  Prec@1 76.17 (76.17) Prec@5 98.44 (98.44) Acls-loss 0.799 (0.799) FLOP-Loss 0.000 (0.000) Arch-Loss 0.799 (0.799)
**TRAIN** [2020-01-29 08:38:32] [epoch=333/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.445 (0.774)  Prec@1 57.74 (73.68) Prec@5 93.45 (98.07) Acls-loss 0.736 (0.834) FLOP-Loss 0.000 (0.000) Arch-Loss 0.736 (0.834)
 **TRAIN** Prec@1 73.68 Prec@5 98.07 Error@1 26.32 Error@5 1.93 Base-Loss:0.774, Arch-Loss=0.834
***[2020-01-29 08:38:32]*** TRAIN [epoch=333/600] base-loss = 0.774196, arch-loss = 0.834206, accuracy-1 = 73.68, accuracy-5 = 98.07
[epoch=333/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 29.175424)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.460 0.187 0.354  ||  0.3232 -0.5769 0.0609  || discrepancy=0.11 || select=0/3
001/003-th : 0.339 0.135 0.527  ||  0.0664 -0.8562 0.5084  || discrepancy=0.19 || select=2/3
002/003-th : 0.008 0.036 0.956  ||  -2.2999 -0.7263 2.5450  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.061 0.086 0.089 0.134 0.148 0.197 0.246  ||  -1.009 -0.558 -0.219 -0.186 0.221 0.320 0.608 0.828   || dis=0.05 || select=7/8
001/019-th : 0.117 0.130 0.131 0.130 0.134 0.123 0.120 0.115  ||  -0.061 0.048 0.056 0.045 0.077 -0.009 -0.035 -0.072   || dis=0.00 || select=4/8
002/019-th : 0.120 0.122 0.129 0.138 0.132 0.127 0.119 0.111  ||  -0.036 -0.016 0.039 0.105 0.059 0.023 -0.041 -0.116   || dis=0.01 || select=3/8
003/019-th : 0.100 0.114 0.123 0.124 0.135 0.130 0.135 0.139  ||  -0.218 -0.080 -0.005 -0.003 0.088 0.044 0.084 0.114   || dis=0.00 || select=7/8
004/019-th : 0.111 0.116 0.115 0.120 0.130 0.131 0.140 0.137  ||  -0.116 -0.071 -0.084 -0.044 0.040 0.045 0.115 0.094   || dis=0.00 || select=6/8
005/019-th : 0.106 0.117 0.123 0.121 0.129 0.131 0.133 0.140  ||  -0.165 -0.068 -0.011 -0.028 0.034 0.046 0.067 0.117   || dis=0.01 || select=7/8
006/019-th : 0.115 0.112 0.119 0.115 0.126 0.128 0.144 0.141  ||  -0.081 -0.108 -0.046 -0.077 0.015 0.026 0.145 0.125   || dis=0.00 || select=6/8
007/019-th : 0.039 0.053 0.081 0.093 0.132 0.158 0.186 0.258  ||  -0.997 -0.677 -0.253 -0.124 0.232 0.413 0.571 0.899   || dis=0.07 || select=7/8
008/019-th : 0.031 0.045 0.066 0.098 0.122 0.175 0.232 0.232  ||  -1.177 -0.792 -0.415 -0.014 0.202 0.562 0.846 0.848   || dis=0.00 || select=7/8
009/019-th : 0.076 0.088 0.109 0.114 0.123 0.135 0.156 0.200  ||  -0.454 -0.307 -0.099 -0.050 0.024 0.119 0.262 0.510   || dis=0.04 || select=7/8
010/019-th : 0.093 0.101 0.107 0.122 0.132 0.150 0.147 0.150  ||  -0.285 -0.196 -0.142 -0.012 0.067 0.198 0.175 0.199   || dis=0.00 || select=7/8
011/019-th : 0.096 0.098 0.111 0.117 0.130 0.129 0.149 0.170  ||  -0.244 -0.232 -0.100 -0.049 0.052 0.044 0.192 0.326   || dis=0.02 || select=7/8
012/019-th : 0.109 0.111 0.114 0.119 0.129 0.135 0.138 0.145  ||  -0.131 -0.117 -0.090 -0.048 0.037 0.081 0.102 0.153   || dis=0.01 || select=7/8
013/019-th : 0.018 0.023 0.027 0.040 0.049 0.087 0.189 0.566  ||  -1.218 -0.993 -0.822 -0.432 -0.233 0.333 1.110 2.207  || dis=0.38 || select=7/8
014/019-th : 0.024 0.038 0.050 0.061 0.094 0.142 0.257 0.334  ||  -1.273 -0.822 -0.558 -0.346 0.075 0.491 1.084 1.346   || dis=0.08 || select=7/8
015/019-th : 0.013 0.020 0.028 0.038 0.054 0.091 0.200 0.557  ||  -1.549 -1.105 -0.748 -0.448 -0.090 0.437 1.223 2.245  || dis=0.36 || select=7/8
016/019-th : 0.056 0.073 0.088 0.121 0.141 0.161 0.174 0.186  ||  -0.730 -0.465 -0.278 0.042 0.198 0.331 0.410 0.475    || dis=0.01 || select=7/8
017/019-th : 0.107 0.111 0.120 0.120 0.123 0.125 0.145 0.148  ||  -0.148 -0.115 -0.034 -0.036 -0.016 0.005 0.153 0.173  || dis=0.00 || select=7/8
018/019-th : 0.081 0.103 0.120 0.133 0.127 0.135 0.143 0.158  ||  -0.420 -0.176 -0.020 0.080 0.038 0.095 0.157 0.252    || dis=0.02 || select=7/8
[epoch=333/600] FLOP : 29.18 MB, ratio : 0.7149, Expected-ratio : 0.7000, Discrepancy : 0.103
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:38:33] [epoch=333/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.663 (1.663)  Prec@1 41.02 (41.02) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:38:39] [epoch=333/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.753 (2.451)  Prec@1 25.00 (35.50) Prec@5 69.05 (79.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.50 Prec@5 79.16 Error@1 64.50 Error@5 20.84 Loss:2.451
***[2020-01-29 08:38:39]*** VALID [epoch=333/600] loss = 2.450681, accuracy@1 = 35.50, accuracy@5 = 79.16 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:38:39]*** start epoch=334/600 Time Left: [02:21:26], LR=[0.041146 ~ 0.041146], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=334, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.1161423862170214, FLOP=40.81
[Search] : epoch=334/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:38:39] [epoch=334/600][000/098] Time 0.75 (0.75) Data 0.35 (0.35) Base-Loss 0.730 (0.730)  Prec@1 75.78 (75.78) Prec@5 98.05 (98.05) Acls-loss 0.861 (0.861) FLOP-Loss 2.814 (2.814) Arch-Loss 6.488 (6.488)
**TRAIN** [2020-01-29 08:39:04] [epoch=334/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.773 (0.752)  Prec@1 73.81 (74.08) Prec@5 97.62 (98.05) Acls-loss 0.653 (0.806) FLOP-Loss 0.000 (0.201) Arch-Loss 0.653 (1.209)
 **TRAIN** Prec@1 74.08 Prec@5 98.05 Error@1 25.92 Error@5 1.95 Base-Loss:0.752, Arch-Loss=1.209
***[2020-01-29 08:39:04]*** TRAIN [epoch=334/600] base-loss = 0.752283, arch-loss = 1.208518, accuracy-1 = 74.08, accuracy-5 = 98.05
[epoch=334/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.470 0.186 0.344  ||  0.3477 -0.5811 0.0371  || discrepancy=0.13 || select=0/3
001/003-th : 0.347 0.136 0.517  ||  0.0894 -0.8487 0.4860  || discrepancy=0.17 || select=2/3
002/003-th : 0.007 0.036 0.957  ||  -2.3088 -0.7267 2.5563  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.062 0.086 0.090 0.134 0.150 0.197 0.242  ||  -1.015 -0.545 -0.222 -0.172 0.219 0.330 0.605 0.811   || dis=0.04 || select=7/8
001/019-th : 0.117 0.131 0.134 0.131 0.133 0.122 0.118 0.113  ||  -0.054 0.057 0.081 0.057 0.075 -0.013 -0.052 -0.092   || dis=0.00 || select=2/8
002/019-th : 0.122 0.125 0.132 0.138 0.129 0.127 0.117 0.109  ||  -0.018 0.007 0.056 0.103 0.038 0.022 -0.062 -0.135    || dis=0.01 || select=3/8
003/019-th : 0.101 0.118 0.123 0.125 0.134 0.130 0.132 0.136  ||  -0.202 -0.048 -0.008 0.007 0.077 0.044 0.060 0.093    || dis=0.00 || select=7/8
004/019-th : 0.114 0.117 0.115 0.121 0.127 0.130 0.139 0.137  ||  -0.093 -0.069 -0.081 -0.032 0.018 0.037 0.103 0.091   || dis=0.00 || select=6/8
005/019-th : 0.107 0.118 0.126 0.122 0.129 0.130 0.131 0.138  ||  -0.157 -0.055 0.008 -0.018 0.031 0.040 0.047 0.101    || dis=0.01 || select=7/8
006/019-th : 0.118 0.112 0.121 0.116 0.124 0.128 0.143 0.138  ||  -0.055 -0.105 -0.027 -0.074 -0.004 0.031 0.135 0.103  || dis=0.00 || select=6/8
007/019-th : 0.039 0.054 0.084 0.092 0.134 0.158 0.183 0.256  ||  -1.002 -0.662 -0.226 -0.130 0.239 0.403 0.553 0.889   || dis=0.07 || select=7/8
008/019-th : 0.031 0.045 0.066 0.100 0.120 0.171 0.232 0.236  ||  -1.171 -0.798 -0.408 0.001 0.184 0.543 0.844 0.861    || dis=0.00 || select=7/8
009/019-th : 0.077 0.088 0.109 0.118 0.124 0.136 0.153 0.196  ||  -0.442 -0.312 -0.096 -0.021 0.028 0.123 0.242 0.490   || dis=0.04 || select=7/8
010/019-th : 0.095 0.103 0.109 0.123 0.130 0.148 0.144 0.148  ||  -0.260 -0.178 -0.118 -0.004 0.055 0.185 0.153 0.180   || dis=0.00 || select=5/8
011/019-th : 0.099 0.098 0.112 0.118 0.128 0.127 0.149 0.170  ||  -0.221 -0.230 -0.099 -0.042 0.034 0.031 0.192 0.320   || dis=0.02 || select=7/8
012/019-th : 0.111 0.113 0.113 0.121 0.128 0.134 0.136 0.144  ||  -0.113 -0.101 -0.095 -0.029 0.025 0.074 0.086 0.142   || dis=0.01 || select=7/8
013/019-th : 0.018 0.023 0.028 0.041 0.050 0.087 0.190 0.563  ||  -1.221 -0.989 -0.818 -0.426 -0.225 0.327 1.111 2.196  || dis=0.37 || select=7/8
014/019-th : 0.024 0.038 0.050 0.063 0.094 0.144 0.256 0.331  ||  -1.288 -0.825 -0.560 -0.322 0.082 0.505 1.079 1.335   || dis=0.08 || select=7/8
015/019-th : 0.013 0.020 0.028 0.038 0.054 0.092 0.201 0.555  ||  -1.546 -1.110 -0.735 -0.449 -0.094 0.442 1.224 2.238  || dis=0.35 || select=7/8
016/019-th : 0.056 0.073 0.089 0.121 0.143 0.161 0.171 0.185  ||  -0.721 -0.460 -0.265 0.040 0.211 0.328 0.391 0.466    || dis=0.01 || select=7/8
017/019-th : 0.109 0.113 0.120 0.121 0.124 0.124 0.142 0.146  ||  -0.133 -0.099 -0.037 -0.028 -0.009 -0.002 0.133 0.159  || dis=0.00 || select=7/8
018/019-th : 0.081 0.105 0.122 0.134 0.125 0.137 0.142 0.155  ||  -0.419 -0.159 -0.008 0.091 0.021 0.109 0.145 0.233    || dis=0.01 || select=7/8
[epoch=334/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.103
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:39:04] [epoch=334/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.393 (2.393)  Prec@1 44.53 (44.53) Prec@5 78.91 (78.91) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:39:10] [epoch=334/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 5.955 (2.575)  Prec@1 28.57 (33.46) Prec@5 86.31 (79.73) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.46 Prec@5 79.73 Error@1 66.54 Error@5 20.27 Loss:2.575
***[2020-01-29 08:39:10]*** VALID [epoch=334/600] loss = 2.574894, accuracy@1 = 33.46, accuracy@5 = 79.73 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:39:10]*** start epoch=335/600 Time Left: [02:20:54], LR=[0.040888 ~ 0.040888], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=335, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.103522962544239, FLOP=40.81
[Search] : epoch=335/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:39:11] [epoch=335/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.979 (0.979)  Prec@1 66.02 (66.02) Prec@5 97.27 (97.27) Acls-loss 0.726 (0.726) FLOP-Loss 0.000 (0.000) Arch-Loss 0.726 (0.726)
**TRAIN** [2020-01-29 08:39:35] [epoch=335/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.675 (0.780)  Prec@1 77.98 (73.40) Prec@5 99.40 (98.10) Acls-loss 0.769 (0.840) FLOP-Loss 0.000 (0.000) Arch-Loss 0.769 (0.840)
 **TRAIN** Prec@1 73.40 Prec@5 98.10 Error@1 26.60 Error@5 1.90 Base-Loss:0.780, Arch-Loss=0.840
***[2020-01-29 08:39:35]*** TRAIN [epoch=335/600] base-loss = 0.780322, arch-loss = 0.840102, accuracy-1 = 73.40, accuracy-5 = 98.10
[epoch=335/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 16, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.552832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.459 0.187 0.354  ||  0.3238 -0.5754 0.0623  || discrepancy=0.11 || select=0/3
001/003-th : 0.336 0.135 0.529  ||  0.0611 -0.8544 0.5158  || discrepancy=0.19 || select=2/3
002/003-th : 0.007 0.035 0.958  ||  -2.3083 -0.7411 2.5658  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.037 0.060 0.083 0.090 0.135 0.149 0.197 0.249  ||  -1.049 -0.567 -0.251 -0.160 0.240 0.335 0.616 0.853   || dis=0.05 || select=7/8
001/019-th : 0.115 0.129 0.131 0.131 0.133 0.125 0.120 0.115  ||  -0.078 0.044 0.059 0.053 0.071 0.013 -0.028 -0.072    || dis=0.00 || select=4/8
002/019-th : 0.119 0.124 0.133 0.137 0.128 0.129 0.119 0.111  ||  -0.044 -0.004 0.062 0.095 0.026 0.033 -0.045 -0.112   || dis=0.00 || select=3/8
003/019-th : 0.102 0.115 0.122 0.125 0.134 0.129 0.134 0.139  ||  -0.199 -0.074 -0.016 0.003 0.076 0.035 0.077 0.111    || dis=0.01 || select=7/8
004/019-th : 0.112 0.115 0.113 0.119 0.127 0.131 0.141 0.142  ||  -0.113 -0.081 -0.098 -0.049 0.011 0.046 0.117 0.126   || dis=0.00 || select=7/8
005/019-th : 0.106 0.116 0.125 0.122 0.128 0.132 0.134 0.138  ||  -0.166 -0.073 0.001 -0.021 0.029 0.055 0.069 0.106    || dis=0.00 || select=7/8
006/019-th : 0.115 0.111 0.121 0.115 0.125 0.128 0.145 0.140  ||  -0.079 -0.114 -0.028 -0.078 0.003 0.025 0.152 0.119   || dis=0.00 || select=6/8
007/019-th : 0.039 0.054 0.083 0.090 0.133 0.157 0.182 0.263  ||  -1.002 -0.655 -0.238 -0.155 0.234 0.402 0.552 0.919   || dis=0.08 || select=7/8
008/019-th : 0.030 0.045 0.066 0.097 0.119 0.171 0.235 0.238  ||  -1.182 -0.800 -0.406 -0.024 0.179 0.547 0.864 0.875   || dis=0.00 || select=7/8
009/019-th : 0.076 0.087 0.106 0.116 0.125 0.136 0.153 0.202  ||  -0.452 -0.323 -0.120 -0.029 0.040 0.126 0.243 0.523   || dis=0.05 || select=7/8
010/019-th : 0.092 0.100 0.108 0.123 0.132 0.150 0.147 0.149  ||  -0.287 -0.206 -0.132 -0.001 0.073 0.196 0.176 0.193   || dis=0.00 || select=5/8
011/019-th : 0.096 0.097 0.110 0.119 0.128 0.130 0.150 0.170  ||  -0.245 -0.236 -0.111 -0.030 0.037 0.055 0.199 0.324   || dis=0.02 || select=7/8
012/019-th : 0.111 0.110 0.112 0.120 0.125 0.138 0.138 0.147  ||  -0.119 -0.129 -0.103 -0.039 -0.001 0.099 0.102 0.165  || dis=0.01 || select=7/8
013/019-th : 0.018 0.023 0.027 0.041 0.049 0.084 0.185 0.573  ||  -1.238 -1.007 -0.824 -0.403 -0.222 0.315 1.098 2.229  || dis=0.39 || select=7/8
014/019-th : 0.024 0.038 0.049 0.061 0.093 0.144 0.256 0.335  ||  -1.294 -0.816 -0.570 -0.342 0.074 0.513 1.089 1.358   || dis=0.08 || select=7/8
015/019-th : 0.013 0.019 0.028 0.038 0.053 0.092 0.203 0.555  ||  -1.547 -1.116 -0.751 -0.446 -0.108 0.449 1.239 2.246  || dis=0.35 || select=7/8
016/019-th : 0.056 0.072 0.089 0.120 0.143 0.160 0.175 0.185  ||  -0.724 -0.476 -0.267 0.038 0.210 0.327 0.411 0.470    || dis=0.01 || select=7/8
017/019-th : 0.108 0.111 0.117 0.121 0.124 0.126 0.145 0.148  ||  -0.143 -0.110 -0.060 -0.026 -0.007 0.014 0.149 0.170  || dis=0.00 || select=7/8
018/019-th : 0.080 0.104 0.121 0.131 0.128 0.136 0.143 0.157  ||  -0.428 -0.163 -0.013 0.064 0.043 0.105 0.154 0.246    || dis=0.01 || select=7/8
[epoch=335/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.105
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:39:35] [epoch=335/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.247 (1.247)  Prec@1 63.28 (63.28) Prec@5 96.48 (96.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:39:41] [epoch=335/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.189 (2.447)  Prec@1 29.17 (37.48) Prec@5 69.05 (80.86) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.48 Prec@5 80.86 Error@1 62.52 Error@5 19.14 Loss:2.447
***[2020-01-29 08:39:41]*** VALID [epoch=335/600] loss = 2.447157, accuracy@1 = 37.48, accuracy@5 = 80.86 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:39:41]*** start epoch=336/600 Time Left: [02:20:21], LR=[0.040631 ~ 0.040631], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=336, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.090915779264974, FLOP=40.81
[Search] : epoch=336/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:39:42] [epoch=336/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.659 (0.659)  Prec@1 77.73 (77.73) Prec@5 99.22 (99.22) Acls-loss 0.902 (0.902) FLOP-Loss 0.000 (0.000) Arch-Loss 0.902 (0.902)
**TRAIN** [2020-01-29 08:40:06] [epoch=336/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.702 (0.763)  Prec@1 75.60 (73.75) Prec@5 98.21 (98.12) Acls-loss 0.871 (0.789) FLOP-Loss 0.000 (0.115) Arch-Loss 0.871 (1.019)
 **TRAIN** Prec@1 73.75 Prec@5 98.12 Error@1 26.25 Error@5 1.88 Base-Loss:0.763, Arch-Loss=1.019
***[2020-01-29 08:40:06]*** TRAIN [epoch=336/600] base-loss = 0.762522, arch-loss = 1.019113, accuracy-1 = 73.75, accuracy-5 = 98.12
[epoch=336/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 16, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.552832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.459 0.190 0.351  ||  0.3257 -0.5547 0.0573  || discrepancy=0.11 || select=0/3
001/003-th : 0.338 0.135 0.527  ||  0.0664 -0.8490 0.5108  || discrepancy=0.19 || select=2/3
002/003-th : 0.007 0.034 0.958  ||  -2.3088 -0.7546 2.5758  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.037 0.060 0.082 0.090 0.137 0.152 0.198 0.245  ||  -1.048 -0.570 -0.258 -0.166 0.253 0.358 0.622 0.837   || dis=0.05 || select=7/8
001/019-th : 0.115 0.130 0.130 0.130 0.132 0.125 0.122 0.115  ||  -0.076 0.050 0.051 0.045 0.065 0.008 -0.021 -0.072    || dis=0.00 || select=4/8
002/019-th : 0.120 0.125 0.134 0.137 0.126 0.129 0.119 0.110  ||  -0.039 0.003 0.069 0.098 0.013 0.037 -0.050 -0.122    || dis=0.00 || select=3/8
003/019-th : 0.102 0.117 0.123 0.126 0.134 0.128 0.132 0.138  ||  -0.196 -0.062 -0.012 0.013 0.077 0.029 0.058 0.107    || dis=0.00 || select=7/8
004/019-th : 0.112 0.117 0.113 0.119 0.128 0.132 0.139 0.140  ||  -0.114 -0.066 -0.099 -0.050 0.027 0.055 0.108 0.112   || dis=0.00 || select=7/8
005/019-th : 0.105 0.117 0.126 0.124 0.127 0.132 0.132 0.137  ||  -0.172 -0.060 0.012 -0.006 0.023 0.057 0.060 0.094    || dis=0.01 || select=7/8
006/019-th : 0.115 0.112 0.122 0.115 0.126 0.126 0.146 0.138  ||  -0.075 -0.107 -0.023 -0.082 0.013 0.014 0.159 0.106   || dis=0.01 || select=6/8
007/019-th : 0.037 0.054 0.084 0.090 0.131 0.157 0.184 0.262  ||  -1.026 -0.655 -0.224 -0.150 0.226 0.409 0.565 0.919   || dis=0.08 || select=7/8
008/019-th : 0.030 0.044 0.066 0.095 0.118 0.170 0.235 0.242  ||  -1.189 -0.806 -0.402 -0.039 0.180 0.543 0.868 0.896   || dis=0.01 || select=7/8
009/019-th : 0.077 0.086 0.104 0.116 0.125 0.138 0.153 0.202  ||  -0.444 -0.330 -0.141 -0.029 0.046 0.141 0.243 0.523   || dis=0.05 || select=7/8
010/019-th : 0.092 0.099 0.108 0.122 0.133 0.150 0.147 0.148  ||  -0.288 -0.213 -0.126 -0.005 0.082 0.199 0.177 0.189   || dis=0.00 || select=5/8
011/019-th : 0.097 0.098 0.110 0.120 0.128 0.130 0.148 0.170  ||  -0.234 -0.232 -0.111 -0.026 0.039 0.052 0.185 0.320   || dis=0.02 || select=7/8
012/019-th : 0.111 0.110 0.113 0.122 0.125 0.137 0.137 0.146  ||  -0.119 -0.127 -0.100 -0.024 0.000 0.094 0.098 0.160   || dis=0.01 || select=7/8
013/019-th : 0.018 0.022 0.027 0.041 0.049 0.083 0.186 0.574  ||  -1.239 -1.007 -0.813 -0.409 -0.231 0.301 1.108 2.236  || dis=0.39 || select=7/8
014/019-th : 0.024 0.038 0.048 0.060 0.091 0.148 0.257 0.334  ||  -1.289 -0.817 -0.581 -0.355 0.054 0.543 1.097 1.357   || dis=0.08 || select=7/8
015/019-th : 0.012 0.019 0.027 0.038 0.053 0.093 0.203 0.555  ||  -1.552 -1.115 -0.762 -0.448 -0.099 0.456 1.239 2.245  || dis=0.35 || select=7/8
016/019-th : 0.057 0.071 0.089 0.120 0.144 0.161 0.173 0.184  ||  -0.712 -0.485 -0.259 0.036 0.218 0.332 0.399 0.463    || dis=0.01 || select=7/8
017/019-th : 0.108 0.112 0.117 0.122 0.123 0.126 0.146 0.147  ||  -0.145 -0.104 -0.064 -0.023 -0.012 0.009 0.156 0.168  || dis=0.00 || select=7/8
018/019-th : 0.080 0.106 0.121 0.131 0.126 0.136 0.143 0.157  ||  -0.427 -0.149 -0.011 0.063 0.028 0.102 0.151 0.248    || dis=0.01 || select=7/8
[epoch=336/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.105
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:40:06] [epoch=336/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.610 (1.610)  Prec@1 47.66 (47.66) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:40:12] [epoch=336/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.210 (2.172)  Prec@1 32.14 (39.13) Prec@5 71.43 (81.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.13 Prec@5 81.72 Error@1 60.87 Error@5 18.28 Loss:2.172
***[2020-01-29 08:40:12]*** VALID [epoch=336/600] loss = 2.171731, accuracy@1 = 39.13, accuracy@5 = 81.72 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:40:12]*** start epoch=337/600 Time Left: [02:19:49], LR=[0.040374 ~ 0.040374], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=337, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.0783211820115275, FLOP=40.81
[Search] : epoch=337/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:40:13] [epoch=337/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.904 (0.904)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 0.827 (0.827) FLOP-Loss 0.000 (0.000) Arch-Loss 0.827 (0.827)
**TRAIN** [2020-01-29 08:40:37] [epoch=337/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.688 (0.758)  Prec@1 74.40 (73.92) Prec@5 100.00 (98.11) Acls-loss 0.656 (0.822) FLOP-Loss 0.000 (0.115) Arch-Loss 0.656 (1.052)
 **TRAIN** Prec@1 73.92 Prec@5 98.11 Error@1 26.08 Error@5 1.89 Base-Loss:0.758, Arch-Loss=1.052
***[2020-01-29 08:40:37]*** TRAIN [epoch=337/600] base-loss = 0.758066, arch-loss = 1.052287, accuracy-1 = 73.92, accuracy-5 = 98.11
[epoch=337/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.458 0.188 0.354  ||  0.3213 -0.5671 0.0654  || discrepancy=0.10 || select=0/3
001/003-th : 0.340 0.135 0.525  ||  0.0726 -0.8488 0.5061  || discrepancy=0.18 || select=2/3
002/003-th : 0.007 0.035 0.957  ||  -2.2950 -0.7411 2.5633  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.037 0.060 0.080 0.090 0.137 0.153 0.198 0.244  ||  -1.045 -0.568 -0.276 -0.163 0.258 0.366 0.625 0.834   || dis=0.05 || select=7/8
001/019-th : 0.117 0.131 0.133 0.129 0.130 0.125 0.122 0.115  ||  -0.064 0.050 0.065 0.034 0.048 0.006 -0.021 -0.080    || dis=0.00 || select=2/8
002/019-th : 0.120 0.124 0.134 0.139 0.127 0.129 0.118 0.110  ||  -0.040 -0.004 0.074 0.108 0.022 0.035 -0.055 -0.121   || dis=0.01 || select=3/8
003/019-th : 0.103 0.115 0.122 0.128 0.133 0.131 0.131 0.138  ||  -0.188 -0.080 -0.021 0.033 0.065 0.049 0.051 0.108    || dis=0.01 || select=7/8
004/019-th : 0.111 0.117 0.113 0.122 0.130 0.130 0.139 0.140  ||  -0.121 -0.069 -0.101 -0.026 0.038 0.043 0.104 0.112   || dis=0.00 || select=7/8
005/019-th : 0.104 0.118 0.125 0.125 0.127 0.133 0.132 0.137  ||  -0.180 -0.052 0.007 0.002 0.019 0.066 0.057 0.094     || dis=0.00 || select=7/8
006/019-th : 0.116 0.112 0.120 0.115 0.128 0.126 0.145 0.138  ||  -0.073 -0.101 -0.037 -0.082 0.027 0.017 0.155 0.102   || dis=0.01 || select=6/8
007/019-th : 0.037 0.054 0.084 0.090 0.129 0.158 0.185 0.262  ||  -1.026 -0.659 -0.222 -0.153 0.214 0.416 0.573 0.920   || dis=0.08 || select=7/8
008/019-th : 0.029 0.044 0.066 0.094 0.120 0.171 0.232 0.243  ||  -1.212 -0.808 -0.392 -0.045 0.199 0.555 0.859 0.904   || dis=0.01 || select=7/8
009/019-th : 0.076 0.084 0.104 0.117 0.127 0.138 0.153 0.201  ||  -0.447 -0.356 -0.134 -0.024 0.065 0.145 0.247 0.522   || dis=0.05 || select=7/8
010/019-th : 0.092 0.100 0.110 0.122 0.133 0.149 0.146 0.148  ||  -0.289 -0.205 -0.112 -0.009 0.078 0.195 0.171 0.186   || dis=0.00 || select=5/8
011/019-th : 0.095 0.098 0.108 0.120 0.128 0.129 0.152 0.169  ||  -0.253 -0.222 -0.132 -0.020 0.041 0.051 0.215 0.318   || dis=0.02 || select=7/8
012/019-th : 0.110 0.110 0.115 0.122 0.125 0.137 0.135 0.146  ||  -0.123 -0.121 -0.084 -0.023 0.003 0.092 0.083 0.160   || dis=0.01 || select=7/8
013/019-th : 0.017 0.022 0.027 0.040 0.049 0.084 0.185 0.576  ||  -1.258 -1.019 -0.805 -0.426 -0.227 0.317 1.111 2.245  || dis=0.39 || select=7/8
014/019-th : 0.023 0.037 0.048 0.060 0.090 0.148 0.258 0.336  ||  -1.297 -0.839 -0.570 -0.356 0.055 0.545 1.103 1.368   || dis=0.08 || select=7/8
015/019-th : 0.012 0.019 0.028 0.037 0.052 0.091 0.204 0.556  ||  -1.573 -1.111 -0.751 -0.450 -0.108 0.449 1.255 2.255  || dis=0.35 || select=7/8
016/019-th : 0.057 0.071 0.089 0.121 0.146 0.161 0.173 0.184  ||  -0.715 -0.490 -0.267 0.042 0.231 0.329 0.400 0.466    || dis=0.01 || select=7/8
017/019-th : 0.108 0.112 0.117 0.122 0.122 0.126 0.146 0.147  ||  -0.142 -0.110 -0.061 -0.018 -0.024 0.008 0.162 0.169  || dis=0.00 || select=7/8
018/019-th : 0.080 0.106 0.123 0.132 0.128 0.135 0.139 0.157  ||  -0.424 -0.149 0.004 0.070 0.040 0.096 0.127 0.246     || dis=0.02 || select=7/8
[epoch=337/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.104
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:40:38] [epoch=337/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.635 (1.635)  Prec@1 60.94 (60.94) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:40:44] [epoch=337/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.319 (2.285)  Prec@1 23.81 (37.63) Prec@5 71.43 (81.48) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.63 Prec@5 81.48 Error@1 62.37 Error@5 18.52 Loss:2.285
***[2020-01-29 08:40:44]*** VALID [epoch=337/600] loss = 2.284641, accuracy@1 = 37.63, accuracy@5 = 81.48 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:40:44]*** start epoch=338/600 Time Left: [02:19:17], LR=[0.040117 ~ 0.040117], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=338, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.065739516071141, FLOP=40.81
[Search] : epoch=338/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:40:44] [epoch=338/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.751 (0.751)  Prec@1 76.56 (76.56) Prec@5 98.44 (98.44) Acls-loss 0.823 (0.823) FLOP-Loss 0.000 (0.000) Arch-Loss 0.823 (0.823)
**TRAIN** [2020-01-29 08:41:09] [epoch=338/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.747 (0.774)  Prec@1 72.62 (73.52) Prec@5 97.62 (97.95) Acls-loss 0.787 (0.811) FLOP-Loss 0.000 (0.000) Arch-Loss 0.787 (0.811)
 **TRAIN** Prec@1 73.52 Prec@5 97.95 Error@1 26.48 Error@5 2.05 Base-Loss:0.774, Arch-Loss=0.811
***[2020-01-29 08:41:09]*** TRAIN [epoch=338/600] base-loss = 0.773924, arch-loss = 0.811047, accuracy-1 = 73.52, accuracy-5 = 97.95
[epoch=338/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.449 0.188 0.363  ||  0.3012 -0.5697 0.0880  || discrepancy=0.09 || select=0/3
001/003-th : 0.330 0.135 0.535  ||  0.0481 -0.8484 0.5309  || discrepancy=0.21 || select=2/3
002/003-th : 0.007 0.034 0.959  ||  -2.3050 -0.7573 2.5818  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.060 0.081 0.088 0.136 0.153 0.199 0.246  ||  -1.034 -0.566 -0.275 -0.189 0.248 0.366 0.629 0.842   || dis=0.05 || select=7/8
001/019-th : 0.115 0.130 0.131 0.127 0.130 0.126 0.124 0.117  ||  -0.077 0.047 0.053 0.022 0.041 0.011 -0.003 -0.065    || dis=0.00 || select=2/8
002/019-th : 0.116 0.123 0.132 0.139 0.129 0.129 0.119 0.112  ||  -0.065 -0.010 0.062 0.110 0.040 0.040 -0.042 -0.106   || dis=0.01 || select=3/8
003/019-th : 0.100 0.113 0.121 0.128 0.134 0.131 0.133 0.140  ||  -0.211 -0.092 -0.027 0.035 0.075 0.057 0.067 0.121    || dis=0.01 || select=7/8
004/019-th : 0.107 0.115 0.111 0.120 0.130 0.134 0.142 0.142  ||  -0.151 -0.079 -0.115 -0.038 0.039 0.070 0.127 0.127   || dis=0.00 || select=6/8
005/019-th : 0.100 0.117 0.126 0.124 0.128 0.133 0.133 0.138  ||  -0.213 -0.054 0.015 -0.002 0.035 0.069 0.072 0.107    || dis=0.01 || select=7/8
006/019-th : 0.114 0.112 0.117 0.114 0.126 0.128 0.149 0.140  ||  -0.087 -0.108 -0.059 -0.088 0.011 0.028 0.178 0.116   || dis=0.01 || select=6/8
007/019-th : 0.037 0.054 0.083 0.088 0.130 0.159 0.188 0.261  ||  -1.041 -0.653 -0.231 -0.163 0.220 0.422 0.592 0.921   || dis=0.07 || select=7/8
008/019-th : 0.028 0.044 0.066 0.094 0.119 0.171 0.231 0.247  ||  -1.237 -0.801 -0.388 -0.038 0.194 0.555 0.857 0.925   || dis=0.02 || select=7/8
009/019-th : 0.076 0.084 0.101 0.114 0.125 0.139 0.157 0.204  ||  -0.450 -0.346 -0.165 -0.043 0.049 0.156 0.274 0.536   || dis=0.05 || select=7/8
010/019-th : 0.090 0.098 0.109 0.120 0.133 0.152 0.147 0.151  ||  -0.313 -0.225 -0.122 -0.018 0.084 0.217 0.180 0.209   || dis=0.00 || select=5/8
011/019-th : 0.094 0.099 0.105 0.120 0.126 0.133 0.154 0.170  ||  -0.264 -0.216 -0.153 -0.020 0.024 0.078 0.227 0.326   || dis=0.02 || select=7/8
012/019-th : 0.110 0.109 0.113 0.121 0.125 0.137 0.137 0.149  ||  -0.125 -0.138 -0.097 -0.030 -0.001 0.092 0.092 0.181  || dis=0.01 || select=7/8
013/019-th : 0.017 0.021 0.027 0.039 0.049 0.083 0.186 0.577  ||  -1.256 -1.051 -0.794 -0.434 -0.220 0.319 1.120 2.252  || dis=0.39 || select=7/8
014/019-th : 0.023 0.037 0.047 0.059 0.089 0.145 0.254 0.345  ||  -1.305 -0.836 -0.584 -0.359 0.049 0.540 1.100 1.406   || dis=0.09 || select=7/8
015/019-th : 0.012 0.019 0.027 0.037 0.052 0.092 0.202 0.559  ||  -1.588 -1.119 -0.754 -0.441 -0.115 0.466 1.249 2.267  || dis=0.36 || select=7/8
016/019-th : 0.056 0.070 0.087 0.119 0.146 0.161 0.172 0.190  ||  -0.727 -0.502 -0.286 0.029 0.239 0.336 0.398 0.497    || dis=0.02 || select=7/8
017/019-th : 0.105 0.111 0.116 0.123 0.120 0.127 0.148 0.150  ||  -0.168 -0.117 -0.071 -0.011 -0.032 0.020 0.176 0.189  || dis=0.00 || select=7/8
018/019-th : 0.080 0.104 0.122 0.131 0.129 0.136 0.140 0.158  ||  -0.430 -0.168 -0.007 0.070 0.047 0.107 0.134 0.254    || dis=0.02 || select=7/8
[epoch=338/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.106
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:41:09] [epoch=338/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.954 (1.954)  Prec@1 36.72 (36.72) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:41:15] [epoch=338/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 5.068 (2.342)  Prec@1 27.38 (36.97) Prec@5 68.45 (80.46) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.97 Prec@5 80.46 Error@1 63.03 Error@5 19.54 Loss:2.342
***[2020-01-29 08:41:15]*** VALID [epoch=338/600] loss = 2.342157, accuracy@1 = 36.97, accuracy@5 = 80.46 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:41:15]*** start epoch=339/600 Time Left: [02:18:44], LR=[0.039861 ~ 0.039861], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=339, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.053171126376545, FLOP=40.81
[Search] : epoch=339/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:41:16] [epoch=339/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.689 (0.689)  Prec@1 75.78 (75.78) Prec@5 98.05 (98.05) Acls-loss 0.916 (0.916) FLOP-Loss 0.000 (0.000) Arch-Loss 0.916 (0.916)
**TRAIN** [2020-01-29 08:41:40] [epoch=339/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.777 (0.745)  Prec@1 75.60 (74.63) Prec@5 95.83 (98.15) Acls-loss 0.887 (0.771) FLOP-Loss 0.000 (0.000) Arch-Loss 0.887 (0.771)
 **TRAIN** Prec@1 74.63 Prec@5 98.15 Error@1 25.37 Error@5 1.85 Base-Loss:0.745, Arch-Loss=0.771
***[2020-01-29 08:41:40]*** TRAIN [epoch=339/600] base-loss = 0.745056, arch-loss = 0.770577, accuracy-1 = 74.63, accuracy-5 = 98.15
[epoch=339/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 16, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.552832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.189 0.369  ||  0.2867 -0.5660 0.1035  || discrepancy=0.07 || select=0/3
001/003-th : 0.327 0.134 0.539  ||  0.0409 -0.8533 0.5401  || discrepancy=0.21 || select=2/3
002/003-th : 0.007 0.033 0.959  ||  -2.3071 -0.7644 2.5904  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.059 0.080 0.086 0.133 0.152 0.200 0.252  ||  -1.024 -0.584 -0.277 -0.203 0.230 0.362 0.638 0.869   || dis=0.05 || select=7/8
001/019-th : 0.113 0.128 0.130 0.126 0.131 0.127 0.126 0.119  ||  -0.095 0.032 0.042 0.012 0.049 0.024 0.017 -0.048     || dis=0.00 || select=4/8
002/019-th : 0.115 0.121 0.133 0.137 0.131 0.131 0.120 0.112  ||  -0.079 -0.023 0.065 0.097 0.051 0.056 -0.030 -0.100   || dis=0.00 || select=3/8
003/019-th : 0.098 0.113 0.120 0.127 0.133 0.131 0.135 0.143  ||  -0.239 -0.092 -0.029 0.022 0.070 0.056 0.087 0.145    || dis=0.01 || select=7/8
004/019-th : 0.106 0.115 0.112 0.120 0.130 0.133 0.142 0.143  ||  -0.162 -0.083 -0.107 -0.041 0.039 0.067 0.132 0.134   || dis=0.00 || select=7/8
005/019-th : 0.100 0.117 0.126 0.122 0.128 0.134 0.135 0.138  ||  -0.218 -0.061 0.015 -0.013 0.035 0.074 0.086 0.109    || dis=0.00 || select=7/8
006/019-th : 0.113 0.111 0.117 0.115 0.127 0.127 0.149 0.140  ||  -0.100 -0.118 -0.058 -0.075 0.024 0.024 0.181 0.120   || dis=0.01 || select=6/8
007/019-th : 0.037 0.054 0.082 0.088 0.128 0.157 0.189 0.264  ||  -1.041 -0.660 -0.238 -0.159 0.212 0.417 0.601 0.934   || dis=0.08 || select=7/8
008/019-th : 0.028 0.043 0.065 0.095 0.118 0.170 0.229 0.252  ||  -1.259 -0.809 -0.405 -0.019 0.195 0.559 0.860 0.956   || dis=0.02 || select=7/8
009/019-th : 0.076 0.083 0.100 0.115 0.127 0.138 0.157 0.205  ||  -0.445 -0.362 -0.175 -0.038 0.061 0.149 0.279 0.542   || dis=0.05 || select=7/8
010/019-th : 0.089 0.097 0.107 0.121 0.134 0.152 0.148 0.151  ||  -0.321 -0.230 -0.132 -0.010 0.090 0.215 0.189 0.209   || dis=0.00 || select=5/8
011/019-th : 0.093 0.099 0.104 0.118 0.126 0.134 0.154 0.171  ||  -0.271 -0.216 -0.160 -0.035 0.028 0.089 0.231 0.334   || dis=0.02 || select=7/8
012/019-th : 0.109 0.108 0.113 0.122 0.125 0.137 0.135 0.151  ||  -0.134 -0.142 -0.098 -0.023 0.007 0.095 0.083 0.189   || dis=0.01 || select=7/8
013/019-th : 0.017 0.021 0.027 0.039 0.048 0.084 0.188 0.576  ||  -1.253 -1.057 -0.792 -0.450 -0.223 0.327 1.133 2.253  || dis=0.39 || select=7/8
014/019-th : 0.023 0.037 0.047 0.059 0.088 0.143 0.253 0.350  ||  -1.305 -0.833 -0.588 -0.365 0.048 0.528 1.100 1.425   || dis=0.10 || select=7/8
015/019-th : 0.012 0.019 0.027 0.036 0.050 0.091 0.197 0.568  ||  -1.579 -1.116 -0.754 -0.451 -0.128 0.460 1.235 2.296  || dis=0.37 || select=7/8
016/019-th : 0.056 0.070 0.086 0.117 0.146 0.161 0.173 0.191  ||  -0.725 -0.504 -0.295 0.019 0.240 0.334 0.408 0.504    || dis=0.02 || select=7/8
017/019-th : 0.104 0.110 0.114 0.121 0.123 0.128 0.149 0.152  ||  -0.179 -0.119 -0.089 -0.028 -0.012 0.033 0.180 0.201  || dis=0.00 || select=7/8
018/019-th : 0.079 0.103 0.121 0.132 0.132 0.134 0.139 0.160  ||  -0.443 -0.171 -0.013 0.075 0.072 0.093 0.127 0.267    || dis=0.02 || select=7/8
[epoch=339/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.108
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:41:40] [epoch=339/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.914 (1.914)  Prec@1 39.84 (39.84) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:41:47] [epoch=339/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.409 (2.362)  Prec@1 22.02 (35.00) Prec@5 76.79 (80.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.00 Prec@5 80.65 Error@1 65.00 Error@5 19.35 Loss:2.362
***[2020-01-29 08:41:47]*** VALID [epoch=339/600] loss = 2.361514, accuracy@1 = 35.00, accuracy@5 = 80.65 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:41:47]*** start epoch=340/600 Time Left: [02:18:12], LR=[0.039604 ~ 0.039604], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=340, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.04061635749649, FLOP=40.81
[Search] : epoch=340/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:41:47] [epoch=340/600][000/098] Time 0.76 (0.76) Data 0.37 (0.37) Base-Loss 0.633 (0.633)  Prec@1 78.91 (78.91) Prec@5 98.83 (98.83) Acls-loss 0.762 (0.762) FLOP-Loss 0.000 (0.000) Arch-Loss 0.762 (0.762)
**TRAIN** [2020-01-29 08:42:12] [epoch=340/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.684 (0.741)  Prec@1 77.98 (74.67) Prec@5 98.21 (98.18) Acls-loss 0.709 (0.800) FLOP-Loss 0.000 (0.116) Arch-Loss 0.709 (1.032)
 **TRAIN** Prec@1 74.67 Prec@5 98.18 Error@1 25.33 Error@5 1.82 Base-Loss:0.741, Arch-Loss=1.032
***[2020-01-29 08:42:12]*** TRAIN [epoch=340/600] base-loss = 0.741430, arch-loss = 1.032134, accuracy-1 = 74.67, accuracy-5 = 98.18
[epoch=340/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.190 0.365  ||  0.2919 -0.5549 0.0969  || discrepancy=0.08 || select=0/3
001/003-th : 0.331 0.133 0.536  ||  0.0505 -0.8613 0.5338  || discrepancy=0.21 || select=2/3
002/003-th : 0.007 0.034 0.959  ||  -2.3150 -0.7561 2.5974  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.059 0.080 0.087 0.131 0.154 0.197 0.254  ||  -1.016 -0.579 -0.280 -0.198 0.212 0.373 0.620 0.873   || dis=0.06 || select=7/8
001/019-th : 0.112 0.126 0.131 0.126 0.129 0.130 0.127 0.119  ||  -0.101 0.015 0.050 0.011 0.038 0.047 0.026 -0.046     || dis=0.00 || select=2/8
002/019-th : 0.115 0.123 0.132 0.135 0.131 0.133 0.120 0.112  ||  -0.077 -0.012 0.058 0.086 0.050 0.067 -0.036 -0.103   || dis=0.00 || select=3/8
003/019-th : 0.098 0.112 0.123 0.126 0.133 0.132 0.134 0.142  ||  -0.231 -0.097 -0.011 0.017 0.068 0.064 0.075 0.136    || dis=0.01 || select=7/8
004/019-th : 0.107 0.113 0.113 0.120 0.130 0.134 0.143 0.141  ||  -0.155 -0.094 -0.102 -0.039 0.041 0.071 0.135 0.126   || dis=0.00 || select=6/8
005/019-th : 0.100 0.118 0.125 0.123 0.129 0.134 0.134 0.137  ||  -0.216 -0.049 0.007 -0.007 0.037 0.075 0.078 0.103    || dis=0.00 || select=7/8
006/019-th : 0.113 0.109 0.118 0.116 0.128 0.128 0.149 0.139  ||  -0.095 -0.127 -0.049 -0.071 0.031 0.028 0.182 0.108   || dis=0.01 || select=6/8
007/019-th : 0.036 0.054 0.084 0.091 0.128 0.156 0.187 0.263  ||  -1.064 -0.649 -0.217 -0.134 0.208 0.408 0.589 0.930   || dis=0.08 || select=7/8
008/019-th : 0.027 0.043 0.065 0.097 0.119 0.167 0.228 0.254  ||  -1.283 -0.811 -0.391 0.004 0.208 0.543 0.855 0.966    || dis=0.03 || select=7/8
009/019-th : 0.077 0.081 0.100 0.114 0.124 0.139 0.157 0.209  ||  -0.439 -0.378 -0.176 -0.038 0.041 0.156 0.279 0.563   || dis=0.05 || select=7/8
010/019-th : 0.090 0.096 0.109 0.124 0.133 0.152 0.146 0.150  ||  -0.313 -0.240 -0.118 0.008 0.084 0.214 0.175 0.205    || dis=0.00 || select=5/8
011/019-th : 0.093 0.100 0.105 0.118 0.126 0.133 0.155 0.169  ||  -0.273 -0.200 -0.155 -0.038 0.027 0.084 0.236 0.322   || dis=0.01 || select=7/8
012/019-th : 0.109 0.109 0.113 0.123 0.124 0.137 0.135 0.149  ||  -0.131 -0.134 -0.093 -0.014 -0.001 0.097 0.082 0.178  || dis=0.01 || select=7/8
013/019-th : 0.017 0.021 0.027 0.039 0.049 0.083 0.187 0.576  ||  -1.249 -1.069 -0.801 -0.435 -0.210 0.317 1.129 2.254  || dis=0.39 || select=7/8
014/019-th : 0.022 0.037 0.047 0.057 0.089 0.140 0.254 0.354  ||  -1.324 -0.825 -0.574 -0.387 0.060 0.515 1.109 1.442   || dis=0.10 || select=7/8
015/019-th : 0.012 0.018 0.027 0.036 0.049 0.090 0.193 0.574  ||  -1.578 -1.129 -0.751 -0.445 -0.137 0.465 1.224 2.315  || dis=0.38 || select=7/8
016/019-th : 0.057 0.070 0.086 0.119 0.147 0.159 0.173 0.189  ||  -0.711 -0.504 -0.296 0.035 0.241 0.321 0.407 0.492    || dis=0.02 || select=7/8
017/019-th : 0.103 0.112 0.115 0.121 0.122 0.128 0.148 0.151  ||  -0.183 -0.106 -0.079 -0.025 -0.015 0.027 0.176 0.194  || dis=0.00 || select=7/8
018/019-th : 0.078 0.104 0.122 0.132 0.133 0.134 0.138 0.160  ||  -0.452 -0.167 -0.007 0.078 0.081 0.088 0.119 0.271    || dis=0.02 || select=7/8
[epoch=340/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.108
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:42:13] [epoch=340/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 4.774 (4.774)  Prec@1 27.73 (27.73) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:42:19] [epoch=340/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.296 (2.529)  Prec@1 25.60 (34.22) Prec@5 70.24 (78.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.22 Prec@5 78.10 Error@1 65.78 Error@5 21.90 Loss:2.529
***[2020-01-29 08:42:19]*** VALID [epoch=340/600] loss = 2.529008, accuracy@1 = 34.22, accuracy@5 = 78.10 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:42:19]*** start epoch=341/600 Time Left: [02:17:40], LR=[0.039348 ~ 0.039348], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=341, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.0280755536263078, FLOP=40.81
[Search] : epoch=341/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:42:19] [epoch=341/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.688 (0.688)  Prec@1 76.95 (76.95) Prec@5 98.83 (98.83) Acls-loss 0.750 (0.750) FLOP-Loss 0.000 (0.000) Arch-Loss 0.750 (0.750)
**TRAIN** [2020-01-29 08:42:44] [epoch=341/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.735 (0.752)  Prec@1 76.79 (74.32) Prec@5 98.21 (98.02) Acls-loss 0.940 (0.813) FLOP-Loss 0.000 (0.000) Arch-Loss 0.940 (0.813)
 **TRAIN** Prec@1 74.32 Prec@5 98.02 Error@1 25.68 Error@5 1.98 Base-Loss:0.752, Arch-Loss=0.813
***[2020-01-29 08:42:44]*** TRAIN [epoch=341/600] base-loss = 0.752415, arch-loss = 0.812773, accuracy-1 = 74.32, accuracy-5 = 98.02
[epoch=341/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.552832)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.438 0.190 0.372  ||  0.2766 -0.5560 0.1142  || discrepancy=0.07 || select=0/3
001/003-th : 0.322 0.130 0.548  ||  0.0282 -0.8751 0.5593  || discrepancy=0.23 || select=2/3
002/003-th : 0.007 0.033 0.960  ||  -2.3165 -0.7651 2.6060  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.037 0.059 0.080 0.086 0.130 0.154 0.197 0.258  ||  -1.043 -0.585 -0.278 -0.201 0.210 0.383 0.627 0.896   || dis=0.06 || select=7/8
001/019-th : 0.111 0.123 0.130 0.125 0.134 0.129 0.129 0.120  ||  -0.112 -0.012 0.046 0.005 0.074 0.040 0.040 -0.030    || dis=0.00 || select=4/8
002/019-th : 0.114 0.121 0.131 0.134 0.132 0.132 0.122 0.114  ||  -0.090 -0.024 0.050 0.073 0.057 0.060 -0.016 -0.086   || dis=0.00 || select=3/8
003/019-th : 0.097 0.109 0.121 0.125 0.132 0.136 0.133 0.146  ||  -0.241 -0.124 -0.024 0.014 0.068 0.094 0.076 0.163    || dis=0.01 || select=7/8
004/019-th : 0.105 0.112 0.113 0.119 0.129 0.136 0.143 0.143  ||  -0.173 -0.108 -0.094 -0.042 0.033 0.088 0.142 0.138   || dis=0.00 || select=6/8
005/019-th : 0.100 0.118 0.124 0.124 0.128 0.133 0.135 0.139  ||  -0.215 -0.053 -0.002 -0.002 0.032 0.066 0.080 0.115   || dis=0.00 || select=7/8
006/019-th : 0.112 0.109 0.115 0.116 0.129 0.129 0.150 0.140  ||  -0.106 -0.130 -0.082 -0.071 0.034 0.038 0.190 0.122   || dis=0.01 || select=6/8
007/019-th : 0.035 0.054 0.084 0.090 0.125 0.156 0.186 0.269  ||  -1.071 -0.648 -0.214 -0.136 0.189 0.408 0.586 0.954   || dis=0.08 || select=7/8
008/019-th : 0.027 0.043 0.065 0.097 0.119 0.165 0.226 0.258  ||  -1.284 -0.809 -0.400 0.005 0.210 0.532 0.850 0.983    || dis=0.03 || select=7/8
009/019-th : 0.077 0.079 0.098 0.114 0.122 0.138 0.161 0.210  ||  -0.426 -0.401 -0.187 -0.038 0.029 0.151 0.310 0.574   || dis=0.05 || select=7/8
010/019-th : 0.090 0.094 0.109 0.123 0.133 0.154 0.144 0.153  ||  -0.311 -0.261 -0.117 0.003 0.085 0.227 0.164 0.223    || dis=0.00 || select=5/8
011/019-th : 0.092 0.099 0.104 0.117 0.125 0.134 0.159 0.170  ||  -0.281 -0.210 -0.161 -0.049 0.018 0.093 0.261 0.331   || dis=0.01 || select=7/8
012/019-th : 0.107 0.108 0.111 0.120 0.126 0.139 0.138 0.151  ||  -0.154 -0.143 -0.113 -0.033 0.013 0.111 0.105 0.193   || dis=0.01 || select=7/8
013/019-th : 0.017 0.021 0.027 0.039 0.049 0.083 0.186 0.578  ||  -1.257 -1.073 -0.804 -0.438 -0.200 0.316 1.129 2.262  || dis=0.39 || select=7/8
014/019-th : 0.022 0.036 0.046 0.056 0.089 0.138 0.254 0.360  ||  -1.322 -0.823 -0.599 -0.402 0.065 0.510 1.117 1.466   || dis=0.11 || select=7/8
015/019-th : 0.012 0.018 0.026 0.035 0.048 0.089 0.188 0.586  ||  -1.570 -1.136 -0.766 -0.468 -0.153 0.473 1.220 2.359  || dis=0.40 || select=7/8
016/019-th : 0.056 0.069 0.086 0.119 0.146 0.158 0.176 0.191  ||  -0.725 -0.511 -0.290 0.032 0.234 0.313 0.421 0.505    || dis=0.02 || select=7/8
017/019-th : 0.102 0.109 0.113 0.121 0.124 0.130 0.150 0.152  ||  -0.197 -0.127 -0.096 -0.024 -0.003 0.046 0.192 0.204  || dis=0.00 || select=7/8
018/019-th : 0.078 0.102 0.121 0.131 0.133 0.133 0.139 0.163  ||  -0.450 -0.180 -0.012 0.066 0.085 0.080 0.125 0.287    || dis=0.02 || select=7/8
[epoch=341/600] FLOP : 28.55 MB, ratio : 0.6996, Expected-ratio : 0.7000, Discrepancy : 0.111
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:42:45] [epoch=341/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.836 (1.836)  Prec@1 49.61 (49.61) Prec@5 88.67 (88.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:42:51] [epoch=341/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.450 (2.299)  Prec@1 27.38 (39.36) Prec@5 76.79 (82.01) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.36 Prec@5 82.01 Error@1 60.64 Error@5 17.99 Loss:2.299
***[2020-01-29 08:42:51]*** VALID [epoch=341/600] loss = 2.299463, accuracy@1 = 39.36, accuracy@5 = 82.01 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:42:51]*** start epoch=342/600 Time Left: [02:17:09], LR=[0.039093 ~ 0.039093], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=342, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.0155490585784714, FLOP=40.81
[Search] : epoch=342/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:42:52] [epoch=342/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.754 (0.754)  Prec@1 74.61 (74.61) Prec@5 98.83 (98.83) Acls-loss 0.787 (0.787) FLOP-Loss 0.000 (0.000) Arch-Loss 0.787 (0.787)
**TRAIN** [2020-01-29 08:43:16] [epoch=342/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.869 (0.766)  Prec@1 72.62 (73.84) Prec@5 97.02 (98.06) Acls-loss 0.856 (0.784) FLOP-Loss 0.000 (0.174) Arch-Loss 0.856 (1.133)
 **TRAIN** Prec@1 73.84 Prec@5 98.06 Error@1 26.16 Error@5 1.94 Base-Loss:0.766, Arch-Loss=1.133
***[2020-01-29 08:43:16]*** TRAIN [epoch=342/600] base-loss = 0.765883, arch-loss = 1.133090, accuracy-1 = 73.84, accuracy-5 = 98.06
[epoch=342/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.445 0.190 0.365  ||  0.2939 -0.5564 0.0972  || discrepancy=0.08 || select=0/3
001/003-th : 0.331 0.133 0.536  ||  0.0533 -0.8600 0.5337  || discrepancy=0.21 || select=2/3
002/003-th : 0.007 0.033 0.960  ||  -2.3183 -0.7671 2.6121  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.037 0.060 0.080 0.086 0.131 0.153 0.196 0.257  ||  -1.040 -0.562 -0.275 -0.207 0.213 0.371 0.618 0.889   || dis=0.06 || select=7/8
001/019-th : 0.113 0.126 0.133 0.125 0.132 0.128 0.126 0.118  ||  -0.096 0.012 0.070 0.007 0.059 0.029 0.016 -0.054     || dis=0.00 || select=2/8
002/019-th : 0.116 0.124 0.134 0.134 0.131 0.129 0.120 0.112  ||  -0.074 -0.003 0.072 0.075 0.053 0.037 -0.033 -0.105   || dis=0.00 || select=3/8
003/019-th : 0.098 0.109 0.123 0.128 0.131 0.135 0.133 0.143  ||  -0.231 -0.128 -0.010 0.033 0.060 0.088 0.073 0.143    || dis=0.01 || select=7/8
004/019-th : 0.104 0.113 0.116 0.120 0.129 0.134 0.143 0.140  ||  -0.175 -0.099 -0.066 -0.040 0.038 0.077 0.141 0.119   || dis=0.00 || select=6/8
005/019-th : 0.101 0.120 0.126 0.124 0.128 0.132 0.133 0.135  ||  -0.208 -0.033 0.019 0.002 0.031 0.061 0.071 0.084     || dis=0.00 || select=7/8
006/019-th : 0.114 0.110 0.115 0.117 0.130 0.128 0.148 0.137  ||  -0.085 -0.122 -0.074 -0.060 0.046 0.030 0.176 0.098   || dis=0.01 || select=6/8
007/019-th : 0.036 0.053 0.085 0.090 0.126 0.156 0.185 0.269  ||  -1.054 -0.669 -0.198 -0.140 0.193 0.405 0.574 0.951   || dis=0.08 || select=7/8
008/019-th : 0.027 0.042 0.063 0.096 0.120 0.163 0.230 0.259  ||  -1.274 -0.834 -0.420 0.000 0.219 0.529 0.870 0.990    || dis=0.03 || select=7/8
009/019-th : 0.078 0.079 0.100 0.114 0.122 0.137 0.162 0.208  ||  -0.416 -0.404 -0.171 -0.040 0.026 0.143 0.313 0.565   || dis=0.05 || select=7/8
010/019-th : 0.092 0.095 0.113 0.120 0.133 0.151 0.143 0.153  ||  -0.286 -0.255 -0.087 -0.023 0.079 0.210 0.151 0.223   || dis=0.00 || select=7/8
011/019-th : 0.093 0.099 0.105 0.119 0.124 0.134 0.158 0.167  ||  -0.272 -0.213 -0.158 -0.026 0.015 0.091 0.257 0.312   || dis=0.01 || select=7/8
012/019-th : 0.109 0.110 0.113 0.121 0.128 0.136 0.136 0.148  ||  -0.134 -0.120 -0.098 -0.029 0.026 0.091 0.086 0.170   || dis=0.01 || select=7/8
013/019-th : 0.017 0.021 0.027 0.040 0.050 0.081 0.187 0.577  ||  -1.253 -1.079 -0.807 -0.422 -0.192 0.297 1.133 2.259  || dis=0.39 || select=7/8
014/019-th : 0.022 0.037 0.045 0.056 0.089 0.140 0.256 0.355  ||  -1.331 -0.812 -0.613 -0.392 0.066 0.520 1.125 1.452   || dis=0.10 || select=7/8
015/019-th : 0.012 0.018 0.026 0.035 0.048 0.090 0.189 0.582  ||  -1.562 -1.135 -0.763 -0.467 -0.155 0.477 1.221 2.345  || dis=0.39 || select=7/8
016/019-th : 0.056 0.071 0.088 0.119 0.144 0.161 0.175 0.186  ||  -0.723 -0.487 -0.276 0.033 0.220 0.331 0.416 0.476    || dis=0.01 || select=7/8
017/019-th : 0.104 0.110 0.114 0.122 0.121 0.130 0.149 0.150  ||  -0.178 -0.119 -0.082 -0.017 -0.026 0.044 0.183 0.190  || dis=0.00 || select=7/8
018/019-th : 0.079 0.103 0.121 0.130 0.137 0.129 0.139 0.162  ||  -0.442 -0.176 -0.011 0.060 0.116 0.052 0.127 0.279    || dis=0.02 || select=7/8
[epoch=342/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.109
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:43:16] [epoch=342/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.130 (2.130)  Prec@1 52.73 (52.73) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:43:22] [epoch=342/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.288 (2.534)  Prec@1 32.74 (34.78) Prec@5 76.19 (78.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.78 Prec@5 78.38 Error@1 65.22 Error@5 21.62 Loss:2.534
***[2020-01-29 08:43:22]*** VALID [epoch=342/600] loss = 2.533574, accuracy@1 = 34.78, accuracy@5 = 78.38 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:43:22]*** start epoch=343/600 Time Left: [02:16:36], LR=[0.038837 ~ 0.038837], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=343, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=2.0030372157731695, FLOP=40.81
[Search] : epoch=343/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:43:23] [epoch=343/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.739 (0.739)  Prec@1 74.61 (74.61) Prec@5 97.66 (97.66) Acls-loss 0.753 (0.753) FLOP-Loss 0.000 (0.000) Arch-Loss 0.753 (0.753)
**TRAIN** [2020-01-29 08:43:47] [epoch=343/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.696 (0.762)  Prec@1 76.19 (73.72) Prec@5 97.62 (98.07) Acls-loss 0.962 (0.804) FLOP-Loss 0.000 (0.087) Arch-Loss 0.962 (0.979)
 **TRAIN** Prec@1 73.72 Prec@5 98.07 Error@1 26.28 Error@5 1.93 Base-Loss:0.762, Arch-Loss=0.979
***[2020-01-29 08:43:47]*** TRAIN [epoch=343/600] base-loss = 0.761899, arch-loss = 0.978721, accuracy-1 = 73.72, accuracy-5 = 98.07
[epoch=343/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.192 0.365  ||  0.2906 -0.5442 0.0991  || discrepancy=0.08 || select=0/3
001/003-th : 0.329 0.132 0.539  ||  0.0465 -0.8646 0.5423  || discrepancy=0.21 || select=2/3
002/003-th : 0.007 0.033 0.960  ||  -2.3239 -0.7544 2.6159  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.061 0.080 0.084 0.131 0.156 0.196 0.256  ||  -1.033 -0.555 -0.281 -0.228 0.212 0.388 0.617 0.886   || dis=0.06 || select=7/8
001/019-th : 0.113 0.125 0.132 0.126 0.132 0.129 0.126 0.117  ||  -0.094 0.009 0.063 0.014 0.061 0.037 0.013 -0.057     || dis=0.00 || select=2/8
002/019-th : 0.115 0.125 0.132 0.136 0.133 0.129 0.120 0.111  ||  -0.075 0.002 0.057 0.087 0.068 0.038 -0.035 -0.113    || dis=0.00 || select=3/8
003/019-th : 0.098 0.108 0.122 0.127 0.131 0.135 0.136 0.143  ||  -0.233 -0.139 -0.012 0.028 0.056 0.089 0.092 0.148    || dis=0.01 || select=7/8
004/019-th : 0.104 0.112 0.118 0.118 0.129 0.136 0.144 0.139  ||  -0.178 -0.100 -0.055 -0.054 0.036 0.086 0.148 0.113   || dis=0.00 || select=6/8
005/019-th : 0.102 0.120 0.126 0.124 0.128 0.132 0.133 0.134  ||  -0.193 -0.036 0.013 -0.001 0.033 0.057 0.071 0.074    || dis=0.00 || select=7/8
006/019-th : 0.115 0.111 0.114 0.118 0.133 0.129 0.146 0.136  ||  -0.076 -0.117 -0.089 -0.055 0.066 0.038 0.161 0.088   || dis=0.01 || select=6/8
007/019-th : 0.036 0.053 0.085 0.090 0.128 0.153 0.185 0.271  ||  -1.064 -0.665 -0.204 -0.143 0.209 0.390 0.579 0.959   || dis=0.09 || select=7/8
008/019-th : 0.026 0.041 0.063 0.096 0.120 0.164 0.230 0.259  ||  -1.296 -0.840 -0.412 0.005 0.223 0.538 0.879 0.997    || dis=0.03 || select=7/8
009/019-th : 0.078 0.079 0.101 0.114 0.120 0.138 0.162 0.209  ||  -0.419 -0.403 -0.164 -0.043 0.014 0.151 0.310 0.566   || dis=0.05 || select=7/8
010/019-th : 0.091 0.095 0.112 0.123 0.134 0.151 0.145 0.150  ||  -0.302 -0.257 -0.089 0.006 0.087 0.207 0.165 0.205    || dis=0.00 || select=5/8
011/019-th : 0.093 0.100 0.104 0.118 0.125 0.136 0.154 0.168  ||  -0.271 -0.201 -0.163 -0.034 0.022 0.105 0.232 0.318   || dis=0.01 || select=7/8
012/019-th : 0.109 0.108 0.112 0.125 0.126 0.136 0.137 0.148  ||  -0.134 -0.144 -0.108 0.005 0.017 0.090 0.094 0.175    || dis=0.01 || select=7/8
013/019-th : 0.017 0.021 0.026 0.039 0.049 0.082 0.188 0.578  ||  -1.245 -1.070 -0.822 -0.438 -0.200 0.309 1.141 2.262  || dis=0.39 || select=7/8
014/019-th : 0.022 0.037 0.044 0.056 0.089 0.139 0.252 0.362  ||  -1.338 -0.809 -0.634 -0.391 0.074 0.523 1.116 1.479   || dis=0.11 || select=7/8
015/019-th : 0.011 0.018 0.026 0.033 0.048 0.088 0.188 0.587  ||  -1.573 -1.119 -0.756 -0.506 -0.144 0.467 1.228 2.365  || dis=0.40 || select=7/8
016/019-th : 0.056 0.071 0.088 0.118 0.145 0.160 0.176 0.186  ||  -0.723 -0.491 -0.276 0.024 0.231 0.325 0.422 0.479    || dis=0.01 || select=7/8
017/019-th : 0.103 0.110 0.114 0.124 0.121 0.131 0.147 0.150  ||  -0.190 -0.119 -0.081 0.001 -0.022 0.055 0.170 0.190   || dis=0.00 || select=7/8
018/019-th : 0.080 0.100 0.120 0.131 0.138 0.130 0.140 0.161  ||  -0.430 -0.199 -0.022 0.067 0.119 0.063 0.133 0.275    || dis=0.02 || select=7/8
[epoch=343/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.110
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:43:48] [epoch=343/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 4.508 (4.508)  Prec@1 32.42 (32.42) Prec@5 80.08 (80.08) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:43:54] [epoch=343/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.393 (2.226)  Prec@1 33.93 (38.35) Prec@5 75.60 (81.71) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.35 Prec@5 81.71 Error@1 61.65 Error@5 18.29 Loss:2.226
***[2020-01-29 08:43:54]*** VALID [epoch=343/600] loss = 2.226474, accuracy@1 = 38.35, accuracy@5 = 81.71 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:43:54]*** start epoch=344/600 Time Left: [02:16:04], LR=[0.038582 ~ 0.038582], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=344, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9905403682288936, FLOP=40.81
[Search] : epoch=344/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:43:55] [epoch=344/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.550 (0.550)  Prec@1 82.81 (82.81) Prec@5 99.61 (99.61) Acls-loss 0.802 (0.802) FLOP-Loss 0.000 (0.000) Arch-Loss 0.802 (0.802)
**TRAIN** [2020-01-29 08:44:19] [epoch=344/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.935 (0.756)  Prec@1 66.07 (74.61) Prec@5 98.81 (98.22) Acls-loss 1.129 (0.785) FLOP-Loss 0.000 (0.058) Arch-Loss 1.129 (0.902)
 **TRAIN** Prec@1 74.61 Prec@5 98.22 Error@1 25.39 Error@5 1.78 Base-Loss:0.756, Arch-Loss=0.902
***[2020-01-29 08:44:19]*** TRAIN [epoch=344/600] base-loss = 0.756238, arch-loss = 0.901533, accuracy-1 = 74.61, accuracy-5 = 98.22
[epoch=344/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.440 0.195 0.365  ||  0.2866 -0.5276 0.1010  || discrepancy=0.08 || select=0/3
001/003-th : 0.321 0.132 0.546  ||  0.0289 -0.8579 0.5594  || discrepancy=0.23 || select=2/3
002/003-th : 0.007 0.032 0.961  ||  -2.3192 -0.7700 2.6216  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.059 0.079 0.084 0.133 0.155 0.197 0.256  ||  -1.028 -0.580 -0.287 -0.229 0.231 0.385 0.626 0.888   || dis=0.06 || select=7/8
001/019-th : 0.111 0.125 0.132 0.126 0.132 0.129 0.125 0.119  ||  -0.108 0.006 0.063 0.015 0.060 0.042 0.010 -0.039     || dis=0.00 || select=2/8
002/019-th : 0.115 0.124 0.129 0.136 0.133 0.130 0.121 0.112  ||  -0.078 -0.003 0.033 0.087 0.068 0.044 -0.027 -0.104   || dis=0.00 || select=3/8
003/019-th : 0.098 0.108 0.122 0.128 0.131 0.136 0.134 0.143  ||  -0.228 -0.140 -0.011 0.031 0.054 0.094 0.083 0.144    || dis=0.01 || select=7/8
004/019-th : 0.105 0.112 0.116 0.116 0.130 0.135 0.147 0.140  ||  -0.169 -0.106 -0.072 -0.067 0.042 0.081 0.164 0.118   || dis=0.01 || select=6/8
005/019-th : 0.104 0.120 0.125 0.122 0.128 0.132 0.134 0.135  ||  -0.183 -0.036 0.000 -0.017 0.030 0.056 0.076 0.081    || dis=0.00 || select=7/8
006/019-th : 0.115 0.109 0.114 0.119 0.133 0.132 0.144 0.134  ||  -0.078 -0.124 -0.083 -0.038 0.072 0.061 0.148 0.075   || dis=0.01 || select=6/8
007/019-th : 0.036 0.053 0.084 0.088 0.126 0.154 0.184 0.274  ||  -1.056 -0.668 -0.208 -0.159 0.199 0.400 0.575 0.975   || dis=0.09 || select=7/8
008/019-th : 0.026 0.041 0.063 0.096 0.120 0.165 0.231 0.257  ||  -1.295 -0.844 -0.414 0.007 0.225 0.545 0.880 0.990    || dis=0.03 || select=7/8
009/019-th : 0.077 0.080 0.101 0.114 0.120 0.139 0.161 0.209  ||  -0.428 -0.397 -0.162 -0.042 0.008 0.158 0.305 0.567   || dis=0.05 || select=7/8
010/019-th : 0.090 0.095 0.110 0.125 0.133 0.150 0.144 0.152  ||  -0.310 -0.253 -0.105 0.024 0.082 0.202 0.161 0.219    || dis=0.00 || select=7/8
011/019-th : 0.094 0.101 0.104 0.117 0.125 0.136 0.155 0.168  ||  -0.267 -0.197 -0.160 -0.048 0.021 0.104 0.235 0.317   || dis=0.01 || select=7/8
012/019-th : 0.109 0.107 0.112 0.123 0.128 0.137 0.136 0.148  ||  -0.134 -0.146 -0.108 -0.012 0.031 0.097 0.093 0.175   || dis=0.01 || select=7/8
013/019-th : 0.017 0.020 0.026 0.038 0.049 0.081 0.185 0.584  ||  -1.249 -1.076 -0.833 -0.450 -0.191 0.306 1.139 2.288  || dis=0.40 || select=7/8
014/019-th : 0.021 0.037 0.044 0.056 0.087 0.138 0.251 0.366  ||  -1.343 -0.800 -0.636 -0.385 0.058 0.520 1.116 1.493   || dis=0.11 || select=7/8
015/019-th : 0.011 0.018 0.026 0.033 0.048 0.088 0.187 0.589  ||  -1.581 -1.111 -0.753 -0.505 -0.145 0.466 1.224 2.370  || dis=0.40 || select=7/8
016/019-th : 0.056 0.070 0.088 0.119 0.146 0.159 0.177 0.187  ||  -0.722 -0.502 -0.276 0.032 0.232 0.319 0.427 0.481    || dis=0.01 || select=7/8
017/019-th : 0.103 0.110 0.113 0.124 0.122 0.131 0.147 0.150  ||  -0.187 -0.122 -0.091 0.004 -0.016 0.056 0.169 0.191   || dis=0.00 || select=7/8
018/019-th : 0.080 0.100 0.121 0.130 0.138 0.130 0.141 0.162  ||  -0.432 -0.203 -0.016 0.057 0.119 0.057 0.138 0.281    || dis=0.02 || select=7/8
[epoch=344/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.112
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:44:20] [epoch=344/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.603 (1.603)  Prec@1 45.70 (45.70) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:44:26] [epoch=344/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.480 (2.249)  Prec@1 57.74 (36.57) Prec@5 92.86 (79.74) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.57 Prec@5 79.74 Error@1 63.43 Error@5 20.26 Loss:2.249
***[2020-01-29 08:44:26]*** VALID [epoch=344/600] loss = 2.248883, accuracy@1 = 36.57, accuracy@5 = 79.74 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:44:26]*** start epoch=345/600 Time Left: [02:15:32], LR=[0.038328 ~ 0.038328], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=345, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9780588585530328, FLOP=40.81
[Search] : epoch=345/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:44:26] [epoch=345/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.844 (0.844)  Prec@1 73.44 (73.44) Prec@5 97.66 (97.66) Acls-loss 0.854 (0.854) FLOP-Loss 0.000 (0.000) Arch-Loss 0.854 (0.854)
**TRAIN** [2020-01-29 08:44:51] [epoch=345/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.704 (0.775)  Prec@1 74.40 (73.41) Prec@5 98.81 (97.92) Acls-loss 0.691 (0.808) FLOP-Loss 0.000 (0.232) Arch-Loss 0.691 (1.272)
 **TRAIN** Prec@1 73.41 Prec@5 97.92 Error@1 26.59 Error@5 2.08 Base-Loss:0.775, Arch-Loss=1.272
***[2020-01-29 08:44:51]*** TRAIN [epoch=345/600] base-loss = 0.775150, arch-loss = 1.272417, accuracy-1 = 73.41, accuracy-5 = 97.92
[epoch=345/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 9, 16, 14, 14, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 29.175424)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.448 0.197 0.355  ||  0.3086 -0.5135 0.0762  || discrepancy=0.09 || select=0/3
001/003-th : 0.332 0.135 0.534  ||  0.0560 -0.8446 0.5322  || discrepancy=0.20 || select=2/3
002/003-th : 0.007 0.031 0.963  ||  -2.3187 -0.8059 2.6398  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.059 0.080 0.083 0.133 0.155 0.197 0.255  ||  -1.025 -0.581 -0.276 -0.237 0.231 0.385 0.625 0.884   || dis=0.06 || select=7/8
001/019-th : 0.113 0.127 0.131 0.129 0.131 0.129 0.122 0.117  ||  -0.091 0.022 0.057 0.037 0.058 0.039 -0.014 -0.059    || dis=0.00 || select=4/8
002/019-th : 0.117 0.127 0.132 0.137 0.133 0.127 0.118 0.110  ||  -0.058 0.018 0.057 0.097 0.065 0.021 -0.055 -0.124    || dis=0.00 || select=3/8
003/019-th : 0.100 0.109 0.125 0.129 0.131 0.135 0.132 0.139  ||  -0.215 -0.128 0.011 0.041 0.060 0.090 0.061 0.113     || dis=0.00 || select=7/8
004/019-th : 0.106 0.113 0.116 0.118 0.130 0.134 0.144 0.138  ||  -0.161 -0.094 -0.068 -0.053 0.048 0.072 0.149 0.105   || dis=0.01 || select=6/8
005/019-th : 0.105 0.121 0.126 0.123 0.127 0.132 0.134 0.131  ||  -0.167 -0.027 0.010 -0.012 0.019 0.056 0.072 0.053    || dis=0.00 || select=6/8
006/019-th : 0.115 0.111 0.116 0.122 0.132 0.131 0.141 0.133  ||  -0.072 -0.114 -0.063 -0.020 0.062 0.051 0.127 0.068   || dis=0.01 || select=6/8
007/019-th : 0.036 0.053 0.085 0.089 0.127 0.154 0.185 0.270  ||  -1.059 -0.666 -0.197 -0.150 0.203 0.397 0.577 0.955   || dis=0.09 || select=7/8
008/019-th : 0.026 0.040 0.065 0.096 0.120 0.166 0.230 0.258  ||  -1.312 -0.865 -0.384 0.008 0.230 0.555 0.884 0.996    || dis=0.03 || select=7/8
009/019-th : 0.079 0.082 0.100 0.114 0.122 0.138 0.159 0.206  ||  -0.413 -0.375 -0.171 -0.047 0.024 0.151 0.290 0.551   || dis=0.05 || select=7/8
010/019-th : 0.091 0.097 0.112 0.125 0.134 0.150 0.141 0.150  ||  -0.299 -0.235 -0.094 0.023 0.092 0.199 0.139 0.201    || dis=0.00 || select=7/8
011/019-th : 0.097 0.103 0.106 0.118 0.125 0.136 0.152 0.165  ||  -0.241 -0.180 -0.149 -0.042 0.019 0.098 0.210 0.293   || dis=0.01 || select=7/8
012/019-th : 0.112 0.109 0.112 0.124 0.129 0.135 0.134 0.145  ||  -0.100 -0.131 -0.100 -0.001 0.036 0.080 0.072 0.151   || dis=0.01 || select=7/8
013/019-th : 0.017 0.020 0.026 0.037 0.049 0.081 0.186 0.584  ||  -1.259 -1.074 -0.828 -0.457 -0.191 0.308 1.145 2.288  || dis=0.40 || select=7/8
014/019-th : 0.022 0.037 0.044 0.056 0.086 0.137 0.255 0.363  ||  -1.331 -0.794 -0.636 -0.382 0.044 0.507 1.129 1.483   || dis=0.11 || select=7/8
015/019-th : 0.011 0.017 0.025 0.032 0.047 0.086 0.188 0.593  ||  -1.600 -1.131 -0.762 -0.517 -0.143 0.469 1.246 2.394  || dis=0.40 || select=7/8
016/019-th : 0.056 0.071 0.089 0.121 0.147 0.160 0.175 0.181  ||  -0.723 -0.485 -0.260 0.044 0.240 0.325 0.415 0.451    || dis=0.01 || select=7/8
017/019-th : 0.104 0.111 0.114 0.127 0.123 0.129 0.146 0.146  ||  -0.180 -0.109 -0.085 0.027 -0.006 0.042 0.161 0.163   || dis=0.00 || select=7/8
018/019-th : 0.081 0.100 0.121 0.131 0.137 0.129 0.140 0.162  ||  -0.415 -0.207 -0.016 0.067 0.109 0.049 0.136 0.279    || dis=0.02 || select=7/8
[epoch=345/600] FLOP : 29.18 MB, ratio : 0.7149, Expected-ratio : 0.7000, Discrepancy : 0.110
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:44:51] [epoch=345/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.405 (1.405)  Prec@1 55.86 (55.86) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:44:57] [epoch=345/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.037 (2.370)  Prec@1 32.14 (35.69) Prec@5 77.38 (80.19) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.69 Prec@5 80.19 Error@1 64.31 Error@5 19.81 Loss:2.370
***[2020-01-29 08:44:57]*** VALID [epoch=345/600] loss = 2.369742, accuracy@1 = 35.69, accuracy@5 = 80.19 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:44:57]*** start epoch=346/600 Time Left: [02:15:00], LR=[0.038073 ~ 0.038073], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=346, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9655930289324774, FLOP=40.81
[Search] : epoch=346/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:44:58] [epoch=346/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.866 (0.866)  Prec@1 69.53 (69.53) Prec@5 96.09 (96.09) Acls-loss 0.714 (0.714) FLOP-Loss 2.828 (2.828) Arch-Loss 6.370 (6.370)
**TRAIN** [2020-01-29 08:45:22] [epoch=346/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.783 (0.740)  Prec@1 75.00 (74.72) Prec@5 97.62 (98.16) Acls-loss 1.017 (0.804) FLOP-Loss 0.000 (0.087) Arch-Loss 1.017 (0.978)
 **TRAIN** Prec@1 74.72 Prec@5 98.16 Error@1 25.28 Error@5 1.84 Base-Loss:0.740, Arch-Loss=0.978
***[2020-01-29 08:45:22]*** TRAIN [epoch=346/600] base-loss = 0.740076, arch-loss = 0.977963, accuracy-1 = 74.72, accuracy-5 = 98.16
[epoch=346/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 14, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.345536)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.447 0.195 0.358  ||  0.3052 -0.5221 0.0821  || discrepancy=0.09 || select=0/3
001/003-th : 0.334 0.135 0.531  ||  0.0629 -0.8432 0.5263  || discrepancy=0.20 || select=2/3
002/003-th : 0.007 0.030 0.963  ||  -2.3343 -0.8115 2.6588  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.060 0.080 0.083 0.134 0.155 0.194 0.255  ||  -1.021 -0.571 -0.282 -0.236 0.240 0.386 0.609 0.881   || dis=0.06 || select=7/8
001/019-th : 0.113 0.126 0.132 0.128 0.132 0.131 0.123 0.116  ||  -0.092 0.014 0.063 0.031 0.062 0.057 -0.009 -0.068    || dis=0.00 || select=2/8
002/019-th : 0.118 0.126 0.131 0.138 0.131 0.128 0.118 0.111  ||  -0.057 0.014 0.047 0.102 0.052 0.025 -0.053 -0.117    || dis=0.01 || select=3/8
003/019-th : 0.100 0.108 0.126 0.128 0.131 0.135 0.132 0.139  ||  -0.211 -0.135 0.018 0.033 0.059 0.087 0.064 0.115     || dis=0.00 || select=7/8
004/019-th : 0.106 0.113 0.117 0.118 0.131 0.132 0.145 0.137  ||  -0.160 -0.093 -0.059 -0.050 0.053 0.060 0.153 0.096   || dis=0.01 || select=6/8
005/019-th : 0.107 0.122 0.127 0.122 0.128 0.130 0.134 0.132  ||  -0.158 -0.019 0.016 -0.026 0.022 0.039 0.069 0.053    || dis=0.00 || select=6/8
006/019-th : 0.116 0.112 0.117 0.121 0.129 0.131 0.141 0.133  ||  -0.067 -0.101 -0.063 -0.028 0.042 0.052 0.127 0.068   || dis=0.01 || select=6/8
007/019-th : 0.036 0.053 0.086 0.089 0.126 0.154 0.186 0.270  ||  -1.053 -0.678 -0.190 -0.152 0.192 0.395 0.587 0.957   || dis=0.08 || select=7/8
008/019-th : 0.025 0.039 0.064 0.097 0.121 0.166 0.230 0.257  ||  -1.314 -0.880 -0.397 0.027 0.239 0.559 0.887 0.996    || dis=0.03 || select=7/8
009/019-th : 0.079 0.082 0.100 0.114 0.120 0.139 0.160 0.206  ||  -0.406 -0.378 -0.174 -0.043 0.008 0.157 0.296 0.549   || dis=0.05 || select=7/8
010/019-th : 0.091 0.097 0.115 0.126 0.135 0.149 0.139 0.148  ||  -0.298 -0.232 -0.067 0.025 0.097 0.192 0.123 0.190    || dis=0.00 || select=5/8
011/019-th : 0.098 0.103 0.105 0.118 0.126 0.135 0.151 0.164  ||  -0.227 -0.176 -0.155 -0.040 0.025 0.090 0.205 0.286   || dis=0.01 || select=7/8
012/019-th : 0.114 0.108 0.112 0.125 0.129 0.135 0.133 0.144  ||  -0.085 -0.142 -0.103 0.002 0.035 0.082 0.071 0.146    || dis=0.01 || select=7/8
013/019-th : 0.017 0.020 0.026 0.037 0.048 0.079 0.185 0.589  ||  -1.259 -1.080 -0.825 -0.462 -0.203 0.303 1.149 2.309  || dis=0.40 || select=7/8
014/019-th : 0.022 0.036 0.043 0.056 0.084 0.136 0.255 0.368  ||  -1.324 -0.827 -0.649 -0.371 0.032 0.512 1.141 1.505   || dis=0.11 || select=7/8
015/019-th : 0.011 0.017 0.025 0.032 0.047 0.087 0.184 0.597  ||  -1.602 -1.140 -0.762 -0.528 -0.126 0.477 1.231 2.408  || dis=0.41 || select=7/8
016/019-th : 0.056 0.070 0.088 0.121 0.146 0.161 0.175 0.183  ||  -0.724 -0.494 -0.269 0.050 0.234 0.333 0.416 0.458    || dis=0.01 || select=7/8
017/019-th : 0.102 0.112 0.113 0.127 0.125 0.130 0.146 0.145  ||  -0.198 -0.097 -0.090 0.030 0.010 0.048 0.163 0.159    || dis=0.00 || select=6/8
018/019-th : 0.081 0.098 0.120 0.132 0.139 0.128 0.139 0.164  ||  -0.415 -0.224 -0.021 0.072 0.124 0.041 0.129 0.294    || dis=0.02 || select=7/8
[epoch=346/600] FLOP : 27.35 MB, ratio : 0.6700, Expected-ratio : 0.7000, Discrepancy : 0.111
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:45:23] [epoch=346/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.361 (2.361)  Prec@1 32.81 (32.81) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:45:29] [epoch=346/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.732 (2.541)  Prec@1 59.52 (36.18) Prec@5 92.86 (80.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.18 Prec@5 80.84 Error@1 63.82 Error@5 19.16 Loss:2.541
***[2020-01-29 08:45:29]*** VALID [epoch=346/600] loss = 2.540679, accuracy@1 = 36.18, accuracy@5 = 80.84 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:45:29]*** start epoch=347/600 Time Left: [02:14:28], LR=[0.037819 ~ 0.037819], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=347, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.953143221124245, FLOP=40.81
[Search] : epoch=347/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:45:29] [epoch=347/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.734 (0.734)  Prec@1 75.00 (75.00) Prec@5 98.05 (98.05) Acls-loss 0.753 (0.753) FLOP-Loss 0.000 (0.000) Arch-Loss 0.753 (0.753)
**TRAIN** [2020-01-29 08:45:54] [epoch=347/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.753 (0.752)  Prec@1 76.19 (74.40) Prec@5 98.21 (98.12) Acls-loss 0.719 (0.787) FLOP-Loss 0.000 (0.058) Arch-Loss 0.719 (0.903)
 **TRAIN** Prec@1 74.40 Prec@5 98.12 Error@1 25.60 Error@5 1.88 Base-Loss:0.752, Arch-Loss=0.903
***[2020-01-29 08:45:54]*** TRAIN [epoch=347/600] base-loss = 0.751578, arch-loss = 0.903259, accuracy-1 = 74.40, accuracy-5 = 98.12
[epoch=347/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 12, 9, 16, 14, 14, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.267136)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.443 0.195 0.362  ||  0.2956 -0.5246 0.0934  || discrepancy=0.08 || select=0/3
001/003-th : 0.334 0.136 0.530  ||  0.0644 -0.8388 0.5253  || discrepancy=0.20 || select=2/3
002/003-th : 0.006 0.029 0.964  ||  -2.3417 -0.8170 2.6710  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.060 0.079 0.083 0.134 0.156 0.196 0.254  ||  -1.015 -0.565 -0.293 -0.244 0.235 0.391 0.618 0.879   || dis=0.06 || select=7/8
001/019-th : 0.111 0.124 0.131 0.130 0.131 0.132 0.124 0.118  ||  -0.110 -0.002 0.057 0.045 0.057 0.063 0.004 -0.050    || dis=0.00 || select=5/8
002/019-th : 0.117 0.125 0.129 0.136 0.132 0.130 0.121 0.110  ||  -0.060 0.002 0.037 0.090 0.057 0.041 -0.032 -0.121    || dis=0.00 || select=3/8
003/019-th : 0.097 0.108 0.125 0.129 0.129 0.138 0.132 0.142  ||  -0.240 -0.138 0.013 0.044 0.044 0.108 0.064 0.137     || dis=0.00 || select=7/8
004/019-th : 0.105 0.113 0.116 0.119 0.131 0.133 0.146 0.138  ||  -0.168 -0.095 -0.069 -0.047 0.049 0.065 0.159 0.103   || dis=0.01 || select=6/8
005/019-th : 0.107 0.121 0.128 0.121 0.125 0.130 0.135 0.133  ||  -0.152 -0.034 0.026 -0.030 -0.001 0.037 0.081 0.060   || dis=0.00 || select=6/8
006/019-th : 0.116 0.110 0.117 0.120 0.130 0.132 0.142 0.134  ||  -0.070 -0.120 -0.064 -0.038 0.046 0.063 0.131 0.075   || dis=0.01 || select=6/8
007/019-th : 0.036 0.052 0.084 0.089 0.124 0.153 0.190 0.271  ||  -1.061 -0.682 -0.202 -0.143 0.181 0.391 0.611 0.966   || dis=0.08 || select=7/8
008/019-th : 0.026 0.040 0.063 0.099 0.119 0.167 0.230 0.256  ||  -1.310 -0.877 -0.408 0.038 0.228 0.565 0.885 0.992    || dis=0.03 || select=7/8
009/019-th : 0.079 0.081 0.098 0.114 0.121 0.137 0.162 0.207  ||  -0.414 -0.378 -0.191 -0.038 0.016 0.146 0.311 0.558   || dis=0.04 || select=7/8
010/019-th : 0.091 0.097 0.115 0.124 0.136 0.148 0.142 0.147  ||  -0.294 -0.236 -0.069 0.012 0.103 0.186 0.144 0.183    || dis=0.00 || select=5/8
011/019-th : 0.099 0.100 0.105 0.119 0.127 0.135 0.151 0.165  ||  -0.221 -0.202 -0.161 -0.030 0.030 0.091 0.203 0.297   || dis=0.01 || select=7/8
012/019-th : 0.115 0.108 0.112 0.126 0.129 0.134 0.133 0.143  ||  -0.081 -0.137 -0.108 0.011 0.037 0.077 0.071 0.139    || dis=0.01 || select=7/8
013/019-th : 0.017 0.020 0.026 0.036 0.047 0.080 0.183 0.592  ||  -1.243 -1.081 -0.819 -0.469 -0.223 0.313 1.141 2.318  || dis=0.41 || select=7/8
014/019-th : 0.022 0.035 0.042 0.057 0.084 0.135 0.255 0.371  ||  -1.320 -0.832 -0.667 -0.357 0.029 0.510 1.141 1.516   || dis=0.12 || select=7/8
015/019-th : 0.011 0.017 0.025 0.031 0.046 0.084 0.179 0.606  ||  -1.598 -1.134 -0.772 -0.527 -0.135 0.465 1.218 2.437  || dis=0.43 || select=7/8
016/019-th : 0.056 0.069 0.088 0.121 0.144 0.162 0.176 0.184  ||  -0.726 -0.508 -0.273 0.048 0.225 0.341 0.422 0.471    || dis=0.01 || select=7/8
017/019-th : 0.101 0.111 0.112 0.130 0.124 0.129 0.147 0.146  ||  -0.203 -0.111 -0.098 0.048 0.001 0.042 0.176 0.169    || dis=0.00 || select=6/8
018/019-th : 0.081 0.096 0.121 0.132 0.137 0.128 0.140 0.164  ||  -0.411 -0.239 -0.013 0.075 0.114 0.046 0.135 0.293    || dis=0.02 || select=7/8
[epoch=347/600] FLOP : 28.27 MB, ratio : 0.6926, Expected-ratio : 0.7000, Discrepancy : 0.112
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:45:54] [epoch=347/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.359 (2.359)  Prec@1 19.92 (19.92) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:46:00] [epoch=347/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.236 (2.479)  Prec@1 24.40 (39.26) Prec@5 66.67 (82.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.26 Prec@5 82.54 Error@1 60.74 Error@5 17.46 Loss:2.479
***[2020-01-29 08:46:00]*** VALID [epoch=347/600] loss = 2.478847, accuracy@1 = 39.26, accuracy@5 = 82.54 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:46:00]*** start epoch=348/600 Time Left: [02:13:56], LR=[0.037566 ~ 0.037566], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=348, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9407097764461063, FLOP=40.81
[Search] : epoch=348/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:46:01] [epoch=348/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.757 (0.757)  Prec@1 72.66 (72.66) Prec@5 99.22 (99.22) Acls-loss 0.804 (0.804) FLOP-Loss 0.000 (0.000) Arch-Loss 0.804 (0.804)
**TRAIN** [2020-01-29 08:46:25] [epoch=348/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.782 (0.742)  Prec@1 72.02 (74.52) Prec@5 99.40 (98.19) Acls-loss 0.836 (0.808) FLOP-Loss 0.000 (0.145) Arch-Loss 0.836 (1.098)
 **TRAIN** Prec@1 74.52 Prec@5 98.19 Error@1 25.48 Error@5 1.81 Base-Loss:0.742, Arch-Loss=1.098
***[2020-01-29 08:46:25]*** TRAIN [epoch=348/600] base-loss = 0.741957, arch-loss = 1.098103, accuracy-1 = 74.52, accuracy-5 = 98.19
[epoch=348/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 14, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.444 0.194 0.362  ||  0.2979 -0.5286 0.0926  || discrepancy=0.08 || select=0/3
001/003-th : 0.337 0.138 0.526  ||  0.0709 -0.8232 0.5173  || discrepancy=0.19 || select=2/3
002/003-th : 0.006 0.029 0.964  ||  -2.3528 -0.8112 2.6817  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.038 0.060 0.078 0.082 0.132 0.155 0.199 0.255  ||  -1.018 -0.561 -0.300 -0.249 0.226 0.389 0.634 0.884   || dis=0.06 || select=7/8
001/019-th : 0.111 0.122 0.132 0.131 0.131 0.132 0.124 0.117  ||  -0.106 -0.015 0.064 0.061 0.054 0.061 0.005 -0.053    || dis=0.00 || select=2/8
002/019-th : 0.118 0.127 0.133 0.135 0.128 0.130 0.119 0.110  ||  -0.056 0.021 0.063 0.082 0.024 0.040 -0.047 -0.124    || dis=0.00 || select=3/8
003/019-th : 0.097 0.109 0.126 0.131 0.129 0.135 0.133 0.140  ||  -0.248 -0.125 0.022 0.059 0.039 0.091 0.073 0.123     || dis=0.01 || select=7/8
004/019-th : 0.106 0.115 0.115 0.119 0.130 0.132 0.144 0.139  ||  -0.164 -0.076 -0.076 -0.047 0.040 0.055 0.147 0.113   || dis=0.00 || select=6/8
005/019-th : 0.107 0.122 0.130 0.123 0.123 0.128 0.136 0.132  ||  -0.157 -0.022 0.043 -0.018 -0.014 0.023 0.083 0.054   || dis=0.00 || select=6/8
006/019-th : 0.117 0.110 0.116 0.119 0.129 0.133 0.142 0.134  ||  -0.061 -0.120 -0.067 -0.044 0.041 0.068 0.130 0.072   || dis=0.01 || select=6/8
007/019-th : 0.035 0.052 0.083 0.088 0.124 0.155 0.189 0.274  ||  -1.074 -0.674 -0.210 -0.160 0.186 0.412 0.607 0.978   || dis=0.09 || select=7/8
008/019-th : 0.025 0.040 0.063 0.098 0.118 0.164 0.233 0.259  ||  -1.333 -0.854 -0.403 0.033 0.218 0.546 0.900 1.006    || dis=0.03 || select=7/8
009/019-th : 0.079 0.081 0.098 0.116 0.120 0.138 0.162 0.206  ||  -0.410 -0.384 -0.193 -0.028 0.014 0.153 0.313 0.549   || dis=0.04 || select=7/8
010/019-th : 0.092 0.097 0.113 0.124 0.136 0.147 0.143 0.148  ||  -0.285 -0.239 -0.086 0.010 0.099 0.183 0.154 0.187    || dis=0.00 || select=7/8
011/019-th : 0.097 0.102 0.104 0.122 0.128 0.133 0.150 0.164  ||  -0.233 -0.184 -0.165 -0.004 0.038 0.078 0.198 0.286   || dis=0.01 || select=7/8
012/019-th : 0.116 0.109 0.112 0.127 0.130 0.133 0.131 0.143  ||  -0.068 -0.129 -0.109 0.018 0.047 0.067 0.049 0.137    || dis=0.01 || select=7/8
013/019-th : 0.017 0.020 0.025 0.036 0.046 0.081 0.183 0.594  ||  -1.243 -1.084 -0.847 -0.483 -0.227 0.334 1.151 2.330  || dis=0.41 || select=7/8
014/019-th : 0.022 0.035 0.042 0.057 0.083 0.134 0.252 0.375  ||  -1.307 -0.832 -0.663 -0.361 0.017 0.502 1.133 1.529   || dis=0.12 || select=7/8
015/019-th : 0.011 0.017 0.024 0.031 0.046 0.083 0.180 0.608  ||  -1.591 -1.138 -0.783 -0.525 -0.145 0.456 1.230 2.445  || dis=0.43 || select=7/8
016/019-th : 0.055 0.070 0.088 0.121 0.143 0.163 0.175 0.184  ||  -0.732 -0.501 -0.268 0.050 0.218 0.346 0.419 0.467    || dis=0.01 || select=7/8
017/019-th : 0.102 0.112 0.112 0.129 0.122 0.130 0.148 0.145  ||  -0.192 -0.101 -0.104 0.045 -0.011 0.046 0.176 0.161   || dis=0.00 || select=6/8
018/019-th : 0.081 0.097 0.120 0.134 0.137 0.128 0.138 0.165  ||  -0.408 -0.231 -0.022 0.089 0.113 0.041 0.117 0.299    || dis=0.03 || select=7/8
[epoch=348/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.112
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:46:25] [epoch=348/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.127 (1.127)  Prec@1 63.67 (63.67) Prec@5 96.88 (96.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:46:31] [epoch=348/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.489 (2.382)  Prec@1 55.95 (40.03) Prec@5 92.26 (83.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.03 Prec@5 83.30 Error@1 59.97 Error@5 16.70 Loss:2.382
***[2020-01-29 08:46:31]*** VALID [epoch=348/600] loss = 2.382121, accuracy@1 = 40.03, accuracy@5 = 83.30 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:46:32]*** start epoch=349/600 Time Left: [02:13:23], LR=[0.037312 ~ 0.037312], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=349, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9282930357672265, FLOP=40.81
[Search] : epoch=349/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:46:32] [epoch=349/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.987 (0.987)  Prec@1 69.53 (69.53) Prec@5 96.88 (96.88) Acls-loss 0.712 (0.712) FLOP-Loss 0.000 (0.000) Arch-Loss 0.712 (0.712)
**TRAIN** [2020-01-29 08:46:56] [epoch=349/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.854 (0.771)  Prec@1 67.26 (73.53) Prec@5 98.21 (98.08) Acls-loss 0.733 (0.788) FLOP-Loss 0.000 (0.058) Arch-Loss 0.733 (0.905)
 **TRAIN** Prec@1 73.53 Prec@5 98.08 Error@1 26.47 Error@5 1.92 Base-Loss:0.771, Arch-Loss=0.905
***[2020-01-29 08:46:56]*** TRAIN [epoch=349/600] base-loss = 0.770647, arch-loss = 0.904599, accuracy-1 = 73.53, accuracy-5 = 98.08
[epoch=349/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 14, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.198528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.442 0.192 0.366  ||  0.2922 -0.5421 0.1019  || discrepancy=0.08 || select=0/3
001/003-th : 0.334 0.138 0.528  ||  0.0649 -0.8200 0.5234  || discrepancy=0.19 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.3508 -0.8239 2.6886  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.039 0.059 0.077 0.082 0.133 0.153 0.198 0.258  ||  -1.002 -0.573 -0.310 -0.256 0.232 0.375 0.632 0.897   || dis=0.06 || select=7/8
001/019-th : 0.112 0.122 0.129 0.132 0.131 0.132 0.124 0.118  ||  -0.099 -0.016 0.039 0.067 0.054 0.064 0.003 -0.052    || dis=0.00 || select=3/8
002/019-th : 0.118 0.127 0.131 0.136 0.128 0.130 0.119 0.111  ||  -0.055 0.015 0.048 0.084 0.021 0.043 -0.046 -0.115    || dis=0.01 || select=3/8
003/019-th : 0.096 0.108 0.126 0.132 0.128 0.135 0.134 0.142  ||  -0.253 -0.134 0.020 0.062 0.033 0.088 0.081 0.135     || dis=0.01 || select=7/8
004/019-th : 0.105 0.114 0.113 0.119 0.130 0.132 0.144 0.142  ||  -0.166 -0.085 -0.095 -0.042 0.041 0.061 0.143 0.129   || dis=0.00 || select=6/8
005/019-th : 0.107 0.121 0.131 0.123 0.124 0.128 0.134 0.132  ||  -0.152 -0.030 0.048 -0.018 -0.010 0.024 0.074 0.055   || dis=0.00 || select=6/8
006/019-th : 0.116 0.110 0.118 0.117 0.128 0.134 0.143 0.135  ||  -0.068 -0.126 -0.057 -0.062 0.028 0.074 0.137 0.083   || dis=0.01 || select=6/8
007/019-th : 0.035 0.051 0.083 0.088 0.125 0.155 0.190 0.272  ||  -1.086 -0.690 -0.214 -0.151 0.202 0.417 0.619 0.976   || dis=0.08 || select=7/8
008/019-th : 0.025 0.040 0.062 0.097 0.116 0.162 0.238 0.260  ||  -1.331 -0.863 -0.411 0.025 0.208 0.544 0.925 1.014    || dis=0.02 || select=7/8
009/019-th : 0.079 0.082 0.098 0.115 0.121 0.138 0.163 0.205  ||  -0.414 -0.375 -0.195 -0.030 0.017 0.150 0.317 0.544   || dis=0.04 || select=7/8
010/019-th : 0.092 0.097 0.111 0.122 0.134 0.148 0.146 0.151  ||  -0.292 -0.241 -0.099 -0.004 0.087 0.186 0.170 0.206   || dis=0.00 || select=7/8
011/019-th : 0.096 0.103 0.104 0.122 0.125 0.133 0.151 0.166  ||  -0.244 -0.179 -0.166 -0.008 0.021 0.076 0.206 0.302   || dis=0.02 || select=7/8
012/019-th : 0.115 0.109 0.111 0.127 0.129 0.134 0.131 0.144  ||  -0.076 -0.133 -0.112 0.020 0.039 0.073 0.051 0.146    || dis=0.01 || select=7/8
013/019-th : 0.016 0.019 0.025 0.035 0.046 0.079 0.182 0.597  ||  -1.261 -1.094 -0.840 -0.495 -0.209 0.322 1.157 2.344  || dis=0.41 || select=7/8
014/019-th : 0.022 0.035 0.040 0.055 0.082 0.132 0.252 0.383  ||  -1.298 -0.844 -0.697 -0.369 0.020 0.495 1.145 1.562   || dis=0.13 || select=7/8
015/019-th : 0.011 0.017 0.024 0.031 0.045 0.081 0.174 0.619  ||  -1.595 -1.132 -0.785 -0.519 -0.150 0.446 1.207 2.477  || dis=0.45 || select=7/8
016/019-th : 0.055 0.071 0.088 0.122 0.142 0.164 0.173 0.184  ||  -0.732 -0.491 -0.271 0.059 0.208 0.351 0.408 0.468    || dis=0.01 || select=7/8
017/019-th : 0.101 0.111 0.111 0.128 0.125 0.130 0.147 0.146  ||  -0.204 -0.104 -0.104 0.036 0.008 0.048 0.175 0.167    || dis=0.00 || select=6/8
018/019-th : 0.082 0.096 0.118 0.135 0.137 0.128 0.139 0.164  ||  -0.407 -0.241 -0.033 0.097 0.114 0.045 0.130 0.295    || dis=0.02 || select=7/8
[epoch=349/600] FLOP : 28.20 MB, ratio : 0.6909, Expected-ratio : 0.7000, Discrepancy : 0.113
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:46:57] [epoch=349/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.697 (1.697)  Prec@1 37.89 (37.89) Prec@5 83.20 (83.20) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:47:03] [epoch=349/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.688 (2.117)  Prec@1 52.38 (39.20) Prec@5 85.12 (81.47) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.20 Prec@5 81.47 Error@1 60.80 Error@5 18.53 Loss:2.117
***[2020-01-29 08:47:03]*** VALID [epoch=349/600] loss = 2.117096, accuracy@1 = 39.20, accuracy@5 = 81.47 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:47:03]*** start epoch=350/600 Time Left: [02:12:51], LR=[0.037059 ~ 0.037059], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=350, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9158933394988242, FLOP=40.81
[Search] : epoch=350/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:47:03] [epoch=350/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.776 (0.776)  Prec@1 73.05 (73.05) Prec@5 97.66 (97.66) Acls-loss 0.648 (0.648) FLOP-Loss 0.000 (0.000) Arch-Loss 0.648 (0.648)
**TRAIN** [2020-01-29 08:47:28] [epoch=350/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.666 (0.769)  Prec@1 74.40 (73.83) Prec@5 98.81 (97.93) Acls-loss 0.827 (0.844) FLOP-Loss 0.000 (0.232) Arch-Loss 0.827 (1.309)
 **TRAIN** Prec@1 73.83 Prec@5 97.93 Error@1 26.17 Error@5 2.07 Base-Loss:0.769, Arch-Loss=1.309
***[2020-01-29 08:47:28]*** TRAIN [epoch=350/600] base-loss = 0.769434, arch-loss = 1.308695, accuracy-1 = 73.83, accuracy-5 = 97.93
[epoch=350/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 8, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.198528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.446 0.196 0.358  ||  0.3031 -0.5178 0.0852  || discrepancy=0.09 || select=0/3
001/003-th : 0.342 0.139 0.519  ||  0.0865 -0.8148 0.5027  || discrepancy=0.18 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3322 -0.8020 2.6678  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.035 0.061 0.082 0.080 0.131 0.154 0.197 0.261  ||  -1.094 -0.543 -0.238 -0.260 0.224 0.387 0.635 0.916   || dis=0.06 || select=7/8
001/019-th : 0.115 0.123 0.131 0.136 0.129 0.127 0.124 0.116  ||  -0.079 -0.005 0.054 0.091 0.039 0.021 -0.003 -0.069   || dis=0.01 || select=3/8
002/019-th : 0.120 0.129 0.133 0.137 0.125 0.131 0.116 0.109  ||  -0.037 0.034 0.066 0.092 0.006 0.048 -0.074 -0.139    || dis=0.00 || select=3/8
003/019-th : 0.098 0.110 0.127 0.134 0.126 0.133 0.133 0.138  ||  -0.232 -0.118 0.022 0.080 0.020 0.070 0.071 0.111     || dis=0.00 || select=7/8
004/019-th : 0.107 0.117 0.114 0.121 0.129 0.131 0.141 0.141  ||  -0.152 -0.067 -0.086 -0.033 0.033 0.046 0.127 0.121   || dis=0.00 || select=6/8
005/019-th : 0.109 0.123 0.132 0.123 0.125 0.128 0.131 0.128  ||  -0.132 -0.014 0.053 -0.013 0.004 0.024 0.047 0.026    || dis=0.00 || select=2/8
006/019-th : 0.120 0.112 0.120 0.119 0.126 0.131 0.140 0.133  ||  -0.039 -0.108 -0.041 -0.048 0.009 0.052 0.114 0.069   || dis=0.01 || select=6/8
007/019-th : 0.035 0.052 0.083 0.088 0.126 0.155 0.190 0.272  ||  -1.074 -0.688 -0.218 -0.154 0.201 0.409 0.615 0.975   || dis=0.08 || select=7/8
008/019-th : 0.025 0.040 0.062 0.097 0.117 0.163 0.237 0.259  ||  -1.326 -0.861 -0.418 0.026 0.217 0.543 0.920 1.006    || dis=0.02 || select=7/8
009/019-th : 0.081 0.083 0.098 0.116 0.121 0.136 0.164 0.201  ||  -0.391 -0.363 -0.191 -0.027 0.012 0.132 0.322 0.523   || dis=0.04 || select=7/8
010/019-th : 0.091 0.095 0.113 0.125 0.134 0.148 0.143 0.151  ||  -0.301 -0.251 -0.085 0.017 0.086 0.185 0.156 0.209    || dis=0.00 || select=7/8
011/019-th : 0.098 0.105 0.107 0.122 0.124 0.132 0.149 0.163  ||  -0.228 -0.158 -0.145 -0.010 0.011 0.068 0.193 0.279   || dis=0.01 || select=7/8
012/019-th : 0.117 0.111 0.113 0.126 0.130 0.132 0.129 0.142  ||  -0.059 -0.115 -0.097 0.013 0.042 0.061 0.033 0.131    || dis=0.01 || select=7/8
013/019-th : 0.016 0.019 0.024 0.034 0.045 0.078 0.185 0.598  ||  -1.282 -1.076 -0.863 -0.511 -0.222 0.328 1.185 2.359  || dis=0.41 || select=7/8
014/019-th : 0.022 0.034 0.039 0.054 0.082 0.130 0.255 0.385  ||  -1.290 -0.847 -0.716 -0.391 0.024 0.492 1.162 1.576   || dis=0.13 || select=7/8
015/019-th : 0.011 0.017 0.023 0.030 0.045 0.083 0.174 0.618  ||  -1.590 -1.140 -0.800 -0.530 -0.151 0.469 1.209 2.479  || dis=0.44 || select=7/8
016/019-th : 0.057 0.072 0.089 0.124 0.142 0.165 0.170 0.182  ||  -0.708 -0.472 -0.266 0.069 0.201 0.352 0.383 0.451    || dis=0.01 || select=7/8
017/019-th : 0.103 0.114 0.111 0.128 0.125 0.129 0.145 0.145  ||  -0.185 -0.082 -0.112 0.033 0.012 0.042 0.157 0.156    || dis=0.00 || select=6/8
018/019-th : 0.083 0.098 0.118 0.136 0.138 0.129 0.138 0.161  ||  -0.388 -0.226 -0.041 0.104 0.118 0.048 0.118 0.275    || dis=0.02 || select=7/8
[epoch=350/600] FLOP : 28.20 MB, ratio : 0.6909, Expected-ratio : 0.7000, Discrepancy : 0.112
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:47:28] [epoch=350/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.451 (3.451)  Prec@1 17.58 (17.58) Prec@5 61.33 (61.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:47:34] [epoch=350/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.677 (2.550)  Prec@1 20.24 (38.61) Prec@5 57.14 (81.25) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.61 Prec@5 81.25 Error@1 61.39 Error@5 18.75 Loss:2.550
***[2020-01-29 08:47:34]*** VALID [epoch=350/600] loss = 2.549981, accuracy@1 = 38.61, accuracy@5 = 81.25 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:47:34]*** start epoch=351/600 Time Left: [02:12:19], LR=[0.036806 ~ 0.036806], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=351, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.9035110275848373, FLOP=40.81
[Search] : epoch=351/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:47:35] [epoch=351/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.912 (0.912)  Prec@1 67.58 (67.58) Prec@5 98.83 (98.83) Acls-loss 0.712 (0.712) FLOP-Loss 0.000 (0.000) Arch-Loss 0.712 (0.712)
**TRAIN** [2020-01-29 08:47:59] [epoch=351/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.877 (0.759)  Prec@1 70.24 (74.25) Prec@5 97.62 (98.05) Acls-loss 1.656 (0.813) FLOP-Loss 0.000 (0.347) Arch-Loss 1.656 (1.507)
 **TRAIN** Prec@1 74.25 Prec@5 98.05 Error@1 25.75 Error@5 1.95 Base-Loss:0.759, Arch-Loss=1.507
***[2020-01-29 08:47:59]*** TRAIN [epoch=351/600] base-loss = 0.758674, arch-loss = 1.506953, accuracy-1 = 74.25, accuracy-5 = 98.05
[epoch=351/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 16, 14, 8, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.476608)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.457 0.195 0.348  ||  0.3306 -0.5186 0.0568  || discrepancy=0.11 || select=0/3
001/003-th : 0.358 0.138 0.504  ||  0.1248 -0.8259 0.4685  || discrepancy=0.15 || select=2/3
002/003-th : 0.007 0.031 0.963  ||  -2.3273 -0.7807 2.6584  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.061 0.083 0.082 0.132 0.156 0.195 0.258  ||  -1.110 -0.543 -0.232 -0.239 0.234 0.402 0.629 0.906   || dis=0.06 || select=7/8
001/019-th : 0.118 0.128 0.135 0.137 0.127 0.124 0.120 0.112  ||  -0.054 0.029 0.087 0.095 0.023 -0.002 -0.038 -0.101   || dis=0.00 || select=3/8
002/019-th : 0.124 0.133 0.138 0.138 0.122 0.127 0.113 0.105  ||  -0.009 0.065 0.102 0.102 -0.023 0.022 -0.100 -0.167   || dis=0.00 || select=2/8
003/019-th : 0.098 0.113 0.129 0.134 0.125 0.130 0.134 0.137  ||  -0.237 -0.094 0.042 0.080 0.011 0.045 0.074 0.096     || dis=0.00 || select=7/8
004/019-th : 0.110 0.119 0.117 0.120 0.127 0.130 0.140 0.137  ||  -0.126 -0.046 -0.064 -0.035 0.015 0.043 0.116 0.092   || dis=0.00 || select=6/8
005/019-th : 0.112 0.127 0.134 0.124 0.124 0.126 0.128 0.125  ||  -0.107 0.012 0.067 -0.009 -0.005 0.008 0.023 -0.000   || dis=0.01 || select=2/8
006/019-th : 0.125 0.115 0.120 0.121 0.127 0.128 0.135 0.129  ||  0.001 -0.076 -0.034 -0.027 0.016 0.030 0.080 0.034    || dis=0.01 || select=6/8
007/019-th : 0.035 0.051 0.084 0.090 0.127 0.155 0.191 0.266  ||  -1.085 -0.697 -0.198 -0.134 0.211 0.410 0.619 0.951   || dis=0.08 || select=7/8
008/019-th : 0.025 0.041 0.062 0.097 0.119 0.165 0.235 0.255  ||  -1.317 -0.851 -0.421 0.024 0.224 0.551 0.905 0.989    || dis=0.02 || select=7/8
009/019-th : 0.083 0.086 0.101 0.119 0.121 0.136 0.163 0.193  ||  -0.369 -0.337 -0.173 -0.007 0.011 0.124 0.306 0.477   || dis=0.03 || select=7/8
010/019-th : 0.092 0.096 0.116 0.128 0.132 0.149 0.140 0.147  ||  -0.288 -0.244 -0.056 0.037 0.069 0.191 0.133 0.182    || dis=0.00 || select=5/8
011/019-th : 0.101 0.108 0.108 0.123 0.125 0.129 0.147 0.158  ||  -0.200 -0.129 -0.132 -0.005 0.015 0.044 0.177 0.247   || dis=0.01 || select=7/8
012/019-th : 0.122 0.114 0.116 0.126 0.128 0.129 0.126 0.139  ||  -0.022 -0.091 -0.075 0.012 0.030 0.035 0.012 0.107    || dis=0.01 || select=7/8
013/019-th : 0.016 0.020 0.023 0.034 0.046 0.079 0.184 0.598  ||  -1.290 -1.065 -0.882 -0.505 -0.208 0.336 1.178 2.355  || dis=0.41 || select=7/8
014/019-th : 0.021 0.033 0.038 0.053 0.083 0.128 0.253 0.390  ||  -1.312 -0.866 -0.725 -0.391 0.050 0.489 1.167 1.601   || dis=0.14 || select=7/8
015/019-th : 0.011 0.017 0.024 0.031 0.045 0.083 0.176 0.614  ||  -1.598 -1.120 -0.791 -0.529 -0.143 0.460 1.212 2.464  || dis=0.44 || select=7/8
016/019-th : 0.057 0.075 0.092 0.127 0.141 0.161 0.167 0.180  ||  -0.706 -0.441 -0.235 0.087 0.195 0.322 0.361 0.437    || dis=0.01 || select=7/8
017/019-th : 0.107 0.116 0.112 0.127 0.126 0.128 0.142 0.141  ||  -0.145 -0.069 -0.102 0.025 0.012 0.034 0.133 0.128    || dis=0.00 || select=6/8
018/019-th : 0.085 0.100 0.121 0.134 0.138 0.128 0.136 0.158  ||  -0.363 -0.210 -0.015 0.087 0.117 0.039 0.103 0.251    || dis=0.02 || select=7/8
[epoch=351/600] FLOP : 27.48 MB, ratio : 0.6732, Expected-ratio : 0.7000, Discrepancy : 0.111
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:48:00] [epoch=351/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.779 (1.779)  Prec@1 43.36 (43.36) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:48:06] [epoch=351/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.225 (2.298)  Prec@1 17.86 (39.23) Prec@5 72.62 (83.50) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.23 Prec@5 83.50 Error@1 60.77 Error@5 16.50 Loss:2.298
***[2020-01-29 08:48:06]*** VALID [epoch=351/600] loss = 2.297678, accuracy@1 = 39.23, accuracy@5 = 83.50 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:48:06]*** start epoch=352/600 Time Left: [02:11:47], LR=[0.036554 ~ 0.036554], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=352, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8911464394925994, FLOP=40.81
[Search] : epoch=352/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:48:07] [epoch=352/600][000/098] Time 0.74 (0.74) Data 0.37 (0.37) Base-Loss 0.961 (0.961)  Prec@1 66.02 (66.02) Prec@5 97.27 (97.27) Acls-loss 0.585 (0.585) FLOP-Loss 0.000 (0.000) Arch-Loss 0.585 (0.585)
**TRAIN** [2020-01-29 08:48:31] [epoch=352/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.964 (0.801)  Prec@1 69.64 (72.85) Prec@5 96.43 (97.70) Acls-loss 0.793 (0.794) FLOP-Loss 0.000 (0.058) Arch-Loss 0.793 (0.909)
 **TRAIN** Prec@1 72.85 Prec@5 97.70 Error@1 27.15 Error@5 2.30 Base-Loss:0.801, Arch-Loss=0.909
***[2020-01-29 08:48:31]*** TRAIN [epoch=352/600] base-loss = 0.801259, arch-loss = 0.909369, accuracy-1 = 72.85, accuracy-5 = 97.70
[epoch=352/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 8, 16, 14, 8, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.0992)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.454 0.195 0.351  ||  0.3235 -0.5219 0.0657  || discrepancy=0.10 || select=0/3
001/003-th : 0.352 0.137 0.511  ||  0.1102 -0.8312 0.4844  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.031 0.963  ||  -2.3384 -0.7730 2.6677  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.060 0.081 0.081 0.131 0.155 0.195 0.263  ||  -1.110 -0.552 -0.245 -0.244 0.234 0.404 0.633 0.929   || dis=0.07 || select=7/8
001/019-th : 0.117 0.129 0.135 0.136 0.126 0.123 0.121 0.113  ||  -0.057 0.033 0.084 0.088 0.015 -0.008 -0.028 -0.099   || dis=0.00 || select=3/8
002/019-th : 0.122 0.133 0.137 0.137 0.123 0.127 0.114 0.106  ||  -0.021 0.068 0.098 0.097 -0.013 0.023 -0.090 -0.163   || dis=0.00 || select=2/8
003/019-th : 0.097 0.112 0.128 0.135 0.126 0.131 0.135 0.136  ||  -0.244 -0.098 0.031 0.086 0.017 0.052 0.082 0.095     || dis=0.00 || select=7/8
004/019-th : 0.110 0.118 0.118 0.120 0.126 0.130 0.141 0.138  ||  -0.128 -0.059 -0.059 -0.037 0.009 0.045 0.122 0.099   || dis=0.00 || select=6/8
005/019-th : 0.113 0.126 0.133 0.122 0.124 0.126 0.129 0.126  ||  -0.100 0.005 0.061 -0.026 -0.011 0.009 0.032 0.008    || dis=0.00 || select=2/8
006/019-th : 0.125 0.114 0.120 0.120 0.124 0.129 0.136 0.132  ||  -0.001 -0.087 -0.042 -0.041 -0.006 0.034 0.087 0.056  || dis=0.00 || select=6/8
007/019-th : 0.034 0.050 0.084 0.091 0.129 0.154 0.189 0.270  ||  -1.093 -0.717 -0.205 -0.120 0.229 0.404 0.613 0.967   || dis=0.08 || select=7/8
008/019-th : 0.026 0.041 0.061 0.097 0.118 0.164 0.238 0.255  ||  -1.313 -0.844 -0.435 0.021 0.218 0.546 0.918 0.986    || dis=0.02 || select=7/8
009/019-th : 0.082 0.085 0.101 0.120 0.121 0.136 0.162 0.194  ||  -0.380 -0.344 -0.167 0.003 0.008 0.129 0.300 0.483    || dis=0.03 || select=7/8
010/019-th : 0.091 0.095 0.115 0.128 0.131 0.148 0.141 0.150  ||  -0.297 -0.255 -0.064 0.045 0.066 0.185 0.141 0.198    || dis=0.00 || select=7/8
011/019-th : 0.101 0.108 0.108 0.123 0.125 0.130 0.147 0.158  ||  -0.204 -0.135 -0.131 -0.004 0.011 0.052 0.178 0.249   || dis=0.01 || select=7/8
012/019-th : 0.121 0.113 0.115 0.124 0.129 0.129 0.127 0.141  ||  -0.028 -0.098 -0.078 -0.006 0.036 0.033 0.016 0.123   || dis=0.01 || select=7/8
013/019-th : 0.015 0.019 0.023 0.033 0.045 0.080 0.182 0.602  ||  -1.317 -1.059 -0.885 -0.527 -0.209 0.356 1.180 2.376  || dis=0.42 || select=7/8
014/019-th : 0.020 0.033 0.038 0.053 0.082 0.126 0.252 0.396  ||  -1.341 -0.868 -0.715 -0.395 0.054 0.477 1.174 1.623   || dis=0.14 || select=7/8
015/019-th : 0.011 0.017 0.023 0.030 0.044 0.080 0.173 0.622  ||  -1.588 -1.119 -0.788 -0.536 -0.161 0.444 1.208 2.488  || dis=0.45 || select=7/8
016/019-th : 0.057 0.074 0.091 0.126 0.142 0.161 0.167 0.181  ||  -0.709 -0.450 -0.247 0.083 0.198 0.329 0.366 0.446    || dis=0.01 || select=7/8
017/019-th : 0.107 0.116 0.112 0.126 0.126 0.128 0.142 0.142  ||  -0.149 -0.070 -0.100 0.013 0.017 0.033 0.135 0.135    || dis=0.00 || select=6/8
018/019-th : 0.085 0.099 0.121 0.134 0.137 0.128 0.137 0.159  ||  -0.369 -0.218 -0.014 0.085 0.108 0.044 0.110 0.259    || dis=0.02 || select=7/8
[epoch=352/600] FLOP : 28.10 MB, ratio : 0.6885, Expected-ratio : 0.7000, Discrepancy : 0.113
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:48:31] [epoch=352/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 3.643 (3.643)  Prec@1 21.88 (21.88) Prec@5 63.67 (63.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:48:37] [epoch=352/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.572 (2.568)  Prec@1 54.17 (34.55) Prec@5 94.64 (79.22) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.55 Prec@5 79.22 Error@1 65.45 Error@5 20.78 Loss:2.568
***[2020-01-29 08:48:37]*** VALID [epoch=352/600] loss = 2.567602, accuracy@1 = 34.55, accuracy@5 = 79.22 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:48:37]*** start epoch=353/600 Time Left: [02:11:15], LR=[0.036302 ~ 0.036302], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=353, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8787999142035408, FLOP=40.81
[Search] : epoch=353/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:48:38] [epoch=353/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.636 (0.636)  Prec@1 75.78 (75.78) Prec@5 98.05 (98.05) Acls-loss 0.740 (0.740) FLOP-Loss 0.000 (0.000) Arch-Loss 0.740 (0.740)
**TRAIN** [2020-01-29 08:49:02] [epoch=353/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.708 (0.771)  Prec@1 71.43 (73.58) Prec@5 99.40 (98.13) Acls-loss 0.681 (0.793) FLOP-Loss 0.000 (0.231) Arch-Loss 0.681 (1.254)
 **TRAIN** Prec@1 73.58 Prec@5 98.13 Error@1 26.42 Error@5 1.87 Base-Loss:0.771, Arch-Loss=1.254
***[2020-01-29 08:49:02]*** TRAIN [epoch=353/600] base-loss = 0.770537, arch-loss = 1.254209, accuracy-1 = 73.58, accuracy-5 = 98.13
[epoch=353/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 9, 14, 8, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.464 0.192 0.344  ||  0.3466 -0.5380 0.0454  || discrepancy=0.12 || select=0/3
001/003-th : 0.360 0.139 0.502  ||  0.1315 -0.8234 0.4634  || discrepancy=0.14 || select=2/3
002/003-th : 0.006 0.030 0.963  ||  -2.3412 -0.7831 2.6773  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.059 0.082 0.082 0.132 0.158 0.194 0.259  ||  -1.109 -0.562 -0.235 -0.238 0.238 0.421 0.624 0.912   || dis=0.07 || select=7/8
001/019-th : 0.119 0.132 0.136 0.135 0.125 0.123 0.119 0.111  ||  -0.042 0.061 0.086 0.083 0.005 -0.015 -0.046 -0.118   || dis=0.00 || select=2/8
002/019-th : 0.125 0.135 0.137 0.138 0.123 0.126 0.113 0.104  ||  0.003 0.081 0.094 0.101 -0.015 0.011 -0.102 -0.183    || dis=0.00 || select=3/8
003/019-th : 0.099 0.113 0.129 0.135 0.126 0.129 0.135 0.134  ||  -0.229 -0.096 0.042 0.086 0.015 0.041 0.083 0.077     || dis=0.00 || select=3/8
004/019-th : 0.112 0.119 0.119 0.120 0.125 0.130 0.140 0.136  ||  -0.112 -0.051 -0.047 -0.040 -0.001 0.042 0.115 0.088  || dis=0.00 || select=6/8
005/019-th : 0.116 0.128 0.133 0.123 0.124 0.125 0.126 0.126  ||  -0.078 0.020 0.060 -0.022 -0.012 -0.007 0.003 0.004   || dis=0.01 || select=2/8
006/019-th : 0.126 0.117 0.120 0.118 0.125 0.128 0.135 0.131  ||  0.011 -0.064 -0.037 -0.054 -0.002 0.023 0.079 0.045   || dis=0.00 || select=6/8
007/019-th : 0.035 0.050 0.084 0.093 0.131 0.154 0.188 0.266  ||  -1.088 -0.720 -0.208 -0.102 0.240 0.401 0.602 0.952   || dis=0.08 || select=7/8
008/019-th : 0.026 0.041 0.061 0.096 0.120 0.164 0.238 0.254  ||  -1.302 -0.846 -0.443 0.008 0.230 0.545 0.917 0.981    || dis=0.02 || select=7/8
009/019-th : 0.082 0.086 0.102 0.121 0.119 0.135 0.163 0.192  ||  -0.378 -0.335 -0.158 0.008 -0.003 0.118 0.307 0.475   || dis=0.03 || select=7/8
010/019-th : 0.092 0.097 0.116 0.129 0.132 0.147 0.138 0.147  ||  -0.285 -0.235 -0.054 0.050 0.072 0.182 0.119 0.176    || dis=0.00 || select=5/8
011/019-th : 0.102 0.109 0.110 0.121 0.126 0.130 0.145 0.158  ||  -0.191 -0.125 -0.114 -0.022 0.019 0.047 0.158 0.244   || dis=0.01 || select=7/8
012/019-th : 0.123 0.115 0.118 0.124 0.128 0.129 0.125 0.140  ||  -0.013 -0.085 -0.060 -0.010 0.028 0.030 -0.002 0.112  || dis=0.01 || select=7/8
013/019-th : 0.015 0.019 0.023 0.033 0.046 0.078 0.183 0.603  ||  -1.332 -1.065 -0.873 -0.534 -0.196 0.342 1.187 2.382  || dis=0.42 || select=7/8
014/019-th : 0.020 0.033 0.038 0.053 0.083 0.125 0.252 0.396  ||  -1.354 -0.861 -0.724 -0.390 0.063 0.472 1.176 1.627   || dis=0.14 || select=7/8
015/019-th : 0.011 0.017 0.024 0.031 0.044 0.082 0.173 0.619  ||  -1.589 -1.116 -0.785 -0.528 -0.160 0.454 1.202 2.475  || dis=0.45 || select=7/8
016/019-th : 0.058 0.074 0.092 0.124 0.142 0.163 0.166 0.180  ||  -0.695 -0.453 -0.230 0.065 0.197 0.338 0.357 0.438    || dis=0.01 || select=7/8
017/019-th : 0.110 0.117 0.114 0.124 0.125 0.127 0.140 0.143  ||  -0.126 -0.060 -0.090 -0.005 0.005 0.020 0.116 0.137   || dis=0.00 || select=7/8
018/019-th : 0.086 0.098 0.123 0.132 0.136 0.128 0.136 0.160  ||  -0.356 -0.227 0.001 0.073 0.103 0.041 0.104 0.262     || dis=0.02 || select=7/8
[epoch=353/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.112
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:49:02] [epoch=353/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.617 (3.617)  Prec@1 19.53 (19.53) Prec@5 78.12 (78.12) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:49:08] [epoch=353/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 2.781 (2.323)  Prec@1 33.93 (37.80) Prec@5 93.45 (81.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.80 Prec@5 81.32 Error@1 62.20 Error@5 18.68 Loss:2.323
***[2020-01-29 08:49:08]*** VALID [epoch=353/600] loss = 2.322834, accuracy@1 = 37.80, accuracy@5 = 81.32 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:49:08]*** start epoch=354/600 Time Left: [02:10:42], LR=[0.036050 ~ 0.036050], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=354, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8664717902038888, FLOP=40.81
[Search] : epoch=354/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:49:09] [epoch=354/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.607 (0.607)  Prec@1 80.86 (80.86) Prec@5 98.83 (98.83) Acls-loss 0.857 (0.857) FLOP-Loss 0.000 (0.000) Arch-Loss 0.857 (0.857)
**TRAIN** [2020-01-29 08:49:33] [epoch=354/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.618 (0.733)  Prec@1 79.17 (74.73) Prec@5 99.40 (98.15) Acls-loss 0.623 (0.797) FLOP-Loss 0.000 (0.000) Arch-Loss 0.623 (0.797)
 **TRAIN** Prec@1 74.73 Prec@5 98.15 Error@1 25.27 Error@5 1.85 Base-Loss:0.733, Arch-Loss=0.797
***[2020-01-29 08:49:33]*** TRAIN [epoch=354/600] base-loss = 0.732774, arch-loss = 0.796733, accuracy-1 = 74.73, accuracy-5 = 98.15
[epoch=354/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 8, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.092032)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.460 0.191 0.348  ||  0.3363 -0.5405 0.0576  || discrepancy=0.11 || select=0/3
001/003-th : 0.352 0.139 0.508  ||  0.1130 -0.8134 0.4806  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.3483 -0.8066 2.6961  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.059 0.082 0.080 0.131 0.157 0.196 0.261  ||  -1.117 -0.561 -0.237 -0.252 0.236 0.421 0.640 0.925   || dis=0.07 || select=7/8
001/019-th : 0.116 0.132 0.133 0.135 0.126 0.126 0.120 0.113  ||  -0.066 0.058 0.071 0.078 0.009 0.011 -0.037 -0.100    || dis=0.00 || select=3/8
002/019-th : 0.124 0.133 0.134 0.138 0.123 0.129 0.114 0.106  ||  -0.008 0.065 0.075 0.098 -0.017 0.031 -0.088 -0.168   || dis=0.00 || select=3/8
003/019-th : 0.098 0.112 0.128 0.134 0.127 0.130 0.136 0.136  ||  -0.238 -0.104 0.035 0.077 0.021 0.044 0.090 0.092     || dis=0.00 || select=7/8
004/019-th : 0.110 0.116 0.120 0.119 0.125 0.129 0.141 0.140  ||  -0.124 -0.074 -0.037 -0.052 -0.001 0.034 0.123 0.115  || dis=0.00 || select=6/8
005/019-th : 0.114 0.125 0.131 0.120 0.126 0.127 0.128 0.129  ||  -0.096 -0.005 0.042 -0.040 0.005 0.011 0.025 0.030    || dis=0.00 || select=2/8
006/019-th : 0.124 0.116 0.118 0.119 0.126 0.128 0.138 0.131  ||  -0.005 -0.071 -0.054 -0.051 0.011 0.024 0.098 0.049   || dis=0.01 || select=6/8
007/019-th : 0.035 0.050 0.082 0.093 0.128 0.152 0.187 0.272  ||  -1.086 -0.714 -0.221 -0.099 0.218 0.394 0.601 0.972   || dis=0.09 || select=7/8
008/019-th : 0.026 0.040 0.061 0.097 0.118 0.168 0.236 0.254  ||  -1.295 -0.874 -0.445 0.020 0.219 0.572 0.912 0.984    || dis=0.02 || select=7/8
009/019-th : 0.080 0.085 0.100 0.119 0.121 0.135 0.166 0.195  ||  -0.404 -0.335 -0.179 -0.003 0.010 0.120 0.331 0.490   || dis=0.03 || select=7/8
010/019-th : 0.091 0.095 0.113 0.129 0.130 0.151 0.141 0.149  ||  -0.294 -0.260 -0.080 0.054 0.059 0.206 0.141 0.192    || dis=0.00 || select=5/8
011/019-th : 0.101 0.107 0.111 0.119 0.126 0.131 0.146 0.159  ||  -0.199 -0.146 -0.110 -0.036 0.018 0.062 0.169 0.254   || dis=0.01 || select=7/8
012/019-th : 0.119 0.112 0.117 0.124 0.128 0.130 0.126 0.143  ||  -0.044 -0.104 -0.065 -0.003 0.027 0.041 0.012 0.135   || dis=0.01 || select=7/8
013/019-th : 0.014 0.019 0.023 0.032 0.044 0.077 0.180 0.611  ||  -1.341 -1.082 -0.882 -0.531 -0.207 0.342 1.189 2.414  || dis=0.43 || select=7/8
014/019-th : 0.020 0.033 0.037 0.052 0.082 0.125 0.249 0.404  ||  -1.374 -0.863 -0.724 -0.399 0.057 0.482 1.172 1.656   || dis=0.16 || select=7/8
015/019-th : 0.011 0.017 0.023 0.030 0.044 0.080 0.175 0.620  ||  -1.589 -1.114 -0.816 -0.527 -0.160 0.444 1.225 2.489  || dis=0.45 || select=7/8
016/019-th : 0.058 0.073 0.091 0.123 0.140 0.164 0.168 0.183  ||  -0.697 -0.462 -0.244 0.061 0.184 0.348 0.367 0.452    || dis=0.01 || select=7/8
017/019-th : 0.108 0.114 0.113 0.122 0.127 0.129 0.143 0.144  ||  -0.139 -0.088 -0.094 -0.021 0.022 0.035 0.143 0.146   || dis=0.00 || select=7/8
018/019-th : 0.085 0.098 0.122 0.132 0.134 0.130 0.136 0.164  ||  -0.373 -0.232 -0.008 0.075 0.089 0.053 0.101 0.286    || dis=0.03 || select=7/8
[epoch=354/600] FLOP : 28.09 MB, ratio : 0.6883, Expected-ratio : 0.7000, Discrepancy : 0.115
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:49:34] [epoch=354/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.548 (2.548)  Prec@1 13.28 (13.28) Prec@5 61.72 (61.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:49:39] [epoch=354/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.929 (2.317)  Prec@1 29.76 (34.64) Prec@5 77.98 (79.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.64 Prec@5 79.54 Error@1 65.36 Error@5 20.46 Loss:2.317
***[2020-01-29 08:49:40]*** VALID [epoch=354/600] loss = 2.317185, accuracy@1 = 34.64, accuracy@5 = 79.54 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:49:40]*** start epoch=355/600 Time Left: [02:10:10], LR=[0.035799 ~ 0.035799], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=355, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8541624054753898, FLOP=40.81
[Search] : epoch=355/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:49:40] [epoch=355/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.657 (0.657)  Prec@1 78.91 (78.91) Prec@5 98.83 (98.83) Acls-loss 0.694 (0.694) FLOP-Loss 0.000 (0.000) Arch-Loss 0.694 (0.694)
**TRAIN** [2020-01-29 08:50:05] [epoch=355/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.825 (0.787)  Prec@1 74.40 (73.32) Prec@5 98.21 (97.83) Acls-loss 0.879 (0.778) FLOP-Loss 0.000 (0.000) Arch-Loss 0.879 (0.778)
 **TRAIN** Prec@1 73.32 Prec@5 97.83 Error@1 26.68 Error@5 2.17 Base-Loss:0.787, Arch-Loss=0.778
***[2020-01-29 08:50:05]*** TRAIN [epoch=355/600] base-loss = 0.787219, arch-loss = 0.777736, accuracy-1 = 73.32, accuracy-5 = 97.83
[epoch=355/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 16, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.092032)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.454 0.192 0.354  ||  0.3218 -0.5377 0.0731  || discrepancy=0.10 || select=0/3
001/003-th : 0.345 0.137 0.518  ||  0.0953 -0.8289 0.5012  || discrepancy=0.17 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.3357 -0.8230 2.6959  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.033 0.058 0.080 0.080 0.131 0.158 0.200 0.260  ||  -1.121 -0.575 -0.251 -0.255 0.242 0.433 0.665 0.930   || dis=0.06 || select=7/8
001/019-th : 0.113 0.130 0.134 0.134 0.128 0.127 0.121 0.115  ||  -0.098 0.046 0.073 0.079 0.027 0.021 -0.029 -0.076    || dis=0.00 || select=3/8
002/019-th : 0.122 0.131 0.133 0.137 0.124 0.130 0.116 0.107  ||  -0.025 0.051 0.065 0.093 -0.004 0.042 -0.074 -0.154   || dis=0.00 || select=3/8
003/019-th : 0.096 0.112 0.127 0.131 0.130 0.130 0.137 0.137  ||  -0.256 -0.100 0.021 0.058 0.044 0.049 0.101 0.104     || dis=0.00 || select=7/8
004/019-th : 0.109 0.114 0.118 0.118 0.125 0.133 0.142 0.140  ||  -0.133 -0.090 -0.051 -0.055 0.000 0.066 0.132 0.116   || dis=0.00 || select=6/8
005/019-th : 0.113 0.122 0.129 0.123 0.124 0.129 0.129 0.131  ||  -0.106 -0.022 0.030 -0.021 -0.007 0.034 0.032 0.042   || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.119 0.119 0.126 0.129 0.137 0.132  ||  -0.022 -0.076 -0.046 -0.050 0.011 0.037 0.096 0.057   || dis=0.01 || select=6/8
007/019-th : 0.035 0.050 0.081 0.093 0.129 0.150 0.186 0.275  ||  -1.082 -0.722 -0.236 -0.093 0.228 0.383 0.597 0.988   || dis=0.09 || select=7/8
008/019-th : 0.026 0.039 0.060 0.097 0.116 0.167 0.237 0.258  ||  -1.283 -0.894 -0.449 0.023 0.204 0.565 0.917 1.003    || dis=0.02 || select=7/8
009/019-th : 0.078 0.085 0.099 0.118 0.122 0.135 0.166 0.196  ||  -0.423 -0.334 -0.186 -0.006 0.026 0.125 0.331 0.498   || dis=0.03 || select=7/8
010/019-th : 0.090 0.093 0.112 0.129 0.133 0.152 0.142 0.149  ||  -0.307 -0.271 -0.088 0.049 0.079 0.217 0.150 0.194    || dis=0.00 || select=5/8
011/019-th : 0.099 0.106 0.111 0.118 0.123 0.133 0.148 0.162  ||  -0.220 -0.153 -0.108 -0.043 -0.002 0.078 0.180 0.273  || dis=0.01 || select=7/8
012/019-th : 0.116 0.110 0.116 0.123 0.129 0.131 0.130 0.145  ||  -0.073 -0.127 -0.075 -0.011 0.031 0.050 0.044 0.154   || dis=0.01 || select=7/8
013/019-th : 0.014 0.018 0.022 0.032 0.043 0.077 0.180 0.614  ||  -1.356 -1.076 -0.882 -0.528 -0.230 0.345 1.200 2.426  || dis=0.43 || select=7/8
014/019-th : 0.019 0.032 0.037 0.052 0.080 0.125 0.245 0.409  ||  -1.387 -0.860 -0.727 -0.396 0.049 0.491 1.162 1.676   || dis=0.16 || select=7/8
015/019-th : 0.010 0.017 0.022 0.030 0.042 0.079 0.176 0.624  ||  -1.585 -1.120 -0.833 -0.539 -0.178 0.439 1.247 2.512  || dis=0.45 || select=7/8
016/019-th : 0.056 0.073 0.090 0.125 0.139 0.164 0.167 0.184  ||  -0.719 -0.459 -0.248 0.072 0.184 0.349 0.365 0.463    || dis=0.02 || select=7/8
017/019-th : 0.107 0.112 0.110 0.120 0.129 0.131 0.144 0.147  ||  -0.148 -0.106 -0.117 -0.038 0.035 0.056 0.149 0.170   || dis=0.00 || select=7/8
018/019-th : 0.084 0.097 0.121 0.132 0.133 0.131 0.138 0.164  ||  -0.384 -0.232 -0.015 0.072 0.077 0.068 0.114 0.290    || dis=0.03 || select=7/8
[epoch=355/600] FLOP : 28.09 MB, ratio : 0.6883, Expected-ratio : 0.7000, Discrepancy : 0.116
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:50:05] [epoch=355/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 3.517 (3.517)  Prec@1 45.31 (45.31) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:50:11] [epoch=355/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.606 (2.269)  Prec@1 25.60 (38.83) Prec@5 72.02 (82.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.83 Prec@5 82.28 Error@1 61.17 Error@5 17.72 Loss:2.269
***[2020-01-29 08:50:11]*** VALID [epoch=355/600] loss = 2.269325, accuracy@1 = 38.83, accuracy@5 = 82.28 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:50:11]*** start epoch=356/600 Time Left: [02:09:38], LR=[0.035548 ~ 0.035548], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=356, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8418720974860443, FLOP=40.81
[Search] : epoch=356/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:50:12] [epoch=356/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.766 (0.766)  Prec@1 74.22 (74.22) Prec@5 97.66 (97.66) Acls-loss 0.706 (0.706) FLOP-Loss 0.000 (0.000) Arch-Loss 0.706 (0.706)
**TRAIN** [2020-01-29 08:50:36] [epoch=356/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.623 (0.747)  Prec@1 75.00 (74.70) Prec@5 100.00 (98.24) Acls-loss 0.790 (0.811) FLOP-Loss 0.000 (0.000) Arch-Loss 0.790 (0.811)
 **TRAIN** Prec@1 74.70 Prec@5 98.24 Error@1 25.30 Error@5 1.76 Base-Loss:0.747, Arch-Loss=0.811
***[2020-01-29 08:50:36]*** TRAIN [epoch=356/600] base-loss = 0.747057, arch-loss = 0.810590, accuracy-1 = 74.70, accuracy-5 = 98.24
[epoch=356/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 12, 14, 32, 32, 32, 25, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.861632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.446 0.194 0.360  ||  0.3032 -0.5281 0.0912  || discrepancy=0.09 || select=0/3
001/003-th : 0.339 0.135 0.526  ||  0.0810 -0.8410 0.5183  || discrepancy=0.19 || select=2/3
002/003-th : 0.006 0.028 0.965  ||  -2.3343 -0.8268 2.6998  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.033 0.057 0.078 0.079 0.128 0.158 0.202 0.264  ||  -1.119 -0.585 -0.267 -0.252 0.228 0.433 0.682 0.948   || dis=0.06 || select=7/8
001/019-th : 0.110 0.128 0.133 0.132 0.131 0.128 0.121 0.116  ||  -0.118 0.034 0.068 0.066 0.057 0.031 -0.023 -0.062    || dis=0.00 || select=2/8
002/019-th : 0.121 0.129 0.132 0.137 0.125 0.130 0.117 0.109  ||  -0.032 0.036 0.053 0.094 -0.002 0.042 -0.067 -0.135   || dis=0.01 || select=3/8
003/019-th : 0.097 0.110 0.125 0.129 0.129 0.131 0.138 0.140  ||  -0.249 -0.116 0.011 0.040 0.043 0.058 0.107 0.120     || dis=0.00 || select=7/8
004/019-th : 0.107 0.112 0.116 0.118 0.125 0.134 0.143 0.145  ||  -0.155 -0.105 -0.068 -0.059 0.006 0.069 0.139 0.148   || dis=0.00 || select=7/8
005/019-th : 0.110 0.120 0.129 0.122 0.127 0.131 0.130 0.131  ||  -0.125 -0.037 0.033 -0.023 0.015 0.047 0.040 0.046    || dis=0.00 || select=5/8
006/019-th : 0.120 0.113 0.118 0.118 0.127 0.131 0.139 0.134  ||  -0.039 -0.097 -0.059 -0.057 0.021 0.046 0.110 0.075   || dis=0.01 || select=6/8
007/019-th : 0.034 0.049 0.079 0.092 0.129 0.150 0.189 0.278  ||  -1.091 -0.731 -0.257 -0.100 0.238 0.385 0.617 1.005   || dis=0.09 || select=7/8
008/019-th : 0.026 0.038 0.060 0.097 0.115 0.163 0.239 0.262  ||  -1.299 -0.905 -0.442 0.027 0.199 0.551 0.934 1.026    || dis=0.02 || select=7/8
009/019-th : 0.075 0.084 0.098 0.119 0.124 0.136 0.166 0.198  ||  -0.456 -0.351 -0.186 0.001 0.044 0.137 0.338 0.510    || dis=0.03 || select=7/8
010/019-th : 0.088 0.092 0.111 0.130 0.133 0.154 0.142 0.150  ||  -0.329 -0.283 -0.092 0.058 0.086 0.230 0.148 0.208    || dis=0.00 || select=5/8
011/019-th : 0.096 0.106 0.110 0.118 0.122 0.133 0.150 0.164  ||  -0.248 -0.153 -0.111 -0.043 -0.006 0.078 0.199 0.287  || dis=0.01 || select=7/8
012/019-th : 0.114 0.108 0.116 0.122 0.131 0.129 0.133 0.148  ||  -0.093 -0.140 -0.075 -0.022 0.048 0.033 0.068 0.171   || dis=0.01 || select=7/8
013/019-th : 0.014 0.018 0.022 0.031 0.042 0.075 0.178 0.620  ||  -1.365 -1.078 -0.890 -0.537 -0.240 0.341 1.207 2.455  || dis=0.44 || select=7/8
014/019-th : 0.019 0.032 0.036 0.051 0.080 0.124 0.242 0.415  ||  -1.389 -0.862 -0.741 -0.392 0.046 0.489 1.158 1.696   || dis=0.17 || select=7/8
015/019-th : 0.010 0.016 0.021 0.029 0.042 0.077 0.173 0.631  ||  -1.574 -1.108 -0.864 -0.552 -0.179 0.440 1.244 2.539  || dis=0.46 || select=7/8
016/019-th : 0.056 0.071 0.090 0.123 0.139 0.163 0.170 0.188  ||  -0.723 -0.483 -0.252 0.058 0.180 0.345 0.384 0.486    || dis=0.02 || select=7/8
017/019-th : 0.103 0.109 0.108 0.120 0.129 0.137 0.147 0.148  ||  -0.187 -0.123 -0.134 -0.030 0.042 0.101 0.172 0.177   || dis=0.00 || select=7/8
018/019-th : 0.082 0.096 0.121 0.132 0.133 0.132 0.139 0.164  ||  -0.400 -0.241 -0.014 0.072 0.085 0.077 0.128 0.289    || dis=0.02 || select=7/8
[epoch=356/600] FLOP : 27.86 MB, ratio : 0.6827, Expected-ratio : 0.7000, Discrepancy : 0.117
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:50:37] [epoch=356/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.344 (2.344)  Prec@1 44.14 (44.14) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:50:43] [epoch=356/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.735 (2.545)  Prec@1 56.55 (36.84) Prec@5 91.67 (81.82) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.84 Prec@5 81.82 Error@1 63.16 Error@5 18.18 Loss:2.545
***[2020-01-29 08:50:43]*** VALID [epoch=356/600] loss = 2.544762, accuracy@1 = 36.84, accuracy@5 = 81.82 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:50:43]*** start epoch=357/600 Time Left: [02:09:06], LR=[0.035298 ~ 0.035298], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=357, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8296012031808557, FLOP=40.81
[Search] : epoch=357/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:50:43] [epoch=357/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.588 (0.588)  Prec@1 78.91 (78.91) Prec@5 98.44 (98.44) Acls-loss 0.858 (0.858) FLOP-Loss 0.000 (0.000) Arch-Loss 0.858 (0.858)
**TRAIN** [2020-01-29 08:51:08] [epoch=357/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.636 (0.729)  Prec@1 77.38 (74.90) Prec@5 99.40 (98.23) Acls-loss 0.694 (0.775) FLOP-Loss 0.000 (0.000) Arch-Loss 0.694 (0.775)
 **TRAIN** Prec@1 74.90 Prec@5 98.23 Error@1 25.10 Error@5 1.77 Base-Loss:0.729, Arch-Loss=0.775
***[2020-01-29 08:51:08]*** TRAIN [epoch=357/600] base-loss = 0.728564, arch-loss = 0.775062, accuracy-1 = 74.90, accuracy-5 = 98.23
[epoch=357/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.437 0.196 0.367  ||  0.2845 -0.5203 0.1099  || discrepancy=0.07 || select=0/3
001/003-th : 0.333 0.135 0.532  ||  0.0665 -0.8398 0.5331  || discrepancy=0.20 || select=2/3
002/003-th : 0.006 0.027 0.967  ||  -2.3430 -0.8464 2.7189  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.057 0.078 0.079 0.128 0.155 0.202 0.267  ||  -1.113 -0.589 -0.275 -0.253 0.228 0.420 0.683 0.961   || dis=0.07 || select=7/8
001/019-th : 0.110 0.128 0.133 0.131 0.131 0.128 0.122 0.118  ||  -0.124 0.029 0.071 0.052 0.056 0.029 -0.019 -0.049    || dis=0.00 || select=2/8
002/019-th : 0.119 0.127 0.130 0.139 0.124 0.131 0.119 0.111  ||  -0.045 0.020 0.037 0.107 -0.009 0.050 -0.049 -0.121   || dis=0.01 || select=3/8
003/019-th : 0.095 0.109 0.124 0.128 0.129 0.133 0.141 0.140  ||  -0.262 -0.127 0.001 0.033 0.040 0.075 0.133 0.124     || dis=0.00 || select=6/8
004/019-th : 0.106 0.112 0.117 0.116 0.126 0.134 0.143 0.145  ||  -0.163 -0.103 -0.063 -0.069 0.014 0.070 0.140 0.153   || dis=0.00 || select=7/8
005/019-th : 0.109 0.120 0.126 0.122 0.128 0.132 0.131 0.133  ||  -0.137 -0.042 0.012 -0.024 0.024 0.054 0.047 0.062    || dis=0.00 || select=7/8
006/019-th : 0.119 0.111 0.117 0.116 0.127 0.132 0.141 0.137  ||  -0.050 -0.113 -0.063 -0.077 0.021 0.057 0.124 0.091   || dis=0.00 || select=6/8
007/019-th : 0.033 0.049 0.078 0.091 0.129 0.150 0.188 0.282  ||  -1.108 -0.722 -0.265 -0.104 0.237 0.389 0.616 1.024   || dis=0.09 || select=7/8
008/019-th : 0.026 0.038 0.060 0.097 0.114 0.161 0.240 0.264  ||  -1.300 -0.912 -0.453 0.032 0.200 0.543 0.942 1.037    || dis=0.02 || select=7/8
009/019-th : 0.074 0.083 0.097 0.119 0.123 0.136 0.165 0.202  ||  -0.468 -0.352 -0.200 0.007 0.034 0.139 0.334 0.535    || dis=0.04 || select=7/8
010/019-th : 0.087 0.091 0.110 0.128 0.132 0.153 0.144 0.154  ||  -0.339 -0.291 -0.101 0.049 0.077 0.225 0.167 0.230    || dis=0.00 || select=7/8
011/019-th : 0.096 0.101 0.107 0.118 0.121 0.137 0.153 0.166  ||  -0.245 -0.194 -0.136 -0.040 -0.013 0.109 0.220 0.298  || dis=0.01 || select=7/8
012/019-th : 0.112 0.108 0.115 0.122 0.132 0.128 0.134 0.148  ||  -0.101 -0.142 -0.080 -0.017 0.057 0.030 0.073 0.173   || dis=0.01 || select=7/8
013/019-th : 0.013 0.018 0.022 0.031 0.042 0.075 0.174 0.626  ||  -1.379 -1.079 -0.887 -0.538 -0.234 0.345 1.192 2.471  || dis=0.45 || select=7/8
014/019-th : 0.019 0.031 0.036 0.050 0.081 0.122 0.240 0.420  ||  -1.394 -0.878 -0.738 -0.408 0.064 0.481 1.157 1.716   || dis=0.18 || select=7/8
015/019-th : 0.010 0.016 0.021 0.028 0.041 0.076 0.170 0.637  ||  -1.562 -1.101 -0.862 -0.558 -0.187 0.431 1.231 2.555  || dis=0.47 || select=7/8
016/019-th : 0.054 0.069 0.089 0.119 0.136 0.165 0.173 0.194  ||  -0.752 -0.507 -0.260 0.036 0.170 0.363 0.409 0.522    || dis=0.02 || select=7/8
017/019-th : 0.100 0.109 0.107 0.119 0.130 0.138 0.149 0.149  ||  -0.214 -0.127 -0.146 -0.031 0.051 0.117 0.189 0.188   || dis=0.00 || select=6/8
018/019-th : 0.082 0.095 0.119 0.130 0.134 0.133 0.141 0.166  ||  -0.406 -0.256 -0.032 0.062 0.093 0.084 0.140 0.305    || dis=0.03 || select=7/8
[epoch=357/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.119
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:51:08] [epoch=357/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.370 (2.370)  Prec@1 36.33 (36.33) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:51:14] [epoch=357/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.959 (2.511)  Prec@1 33.33 (33.80) Prec@5 77.98 (78.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 33.80 Prec@5 78.72 Error@1 66.20 Error@5 21.28 Loss:2.511
***[2020-01-29 08:51:14]*** VALID [epoch=357/600] loss = 2.511205, accuracy@1 = 33.80, accuracy@5 = 78.72 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:51:14]*** start epoch=358/600 Time Left: [02:08:34], LR=[0.035048 ~ 0.035048], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=358, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.817350058972588, FLOP=40.81
[Search] : epoch=358/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:51:15] [epoch=358/600][000/098] Time 0.75 (0.75) Data 0.36 (0.36) Base-Loss 0.689 (0.689)  Prec@1 74.22 (74.22) Prec@5 97.27 (97.27) Acls-loss 0.916 (0.916) FLOP-Loss 0.000 (0.000) Arch-Loss 0.916 (0.916)
**TRAIN** [2020-01-29 08:51:39] [epoch=358/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.597 (0.729)  Prec@1 80.36 (75.17) Prec@5 100.00 (98.15) Acls-loss 0.759 (0.756) FLOP-Loss 0.000 (0.000) Arch-Loss 0.759 (0.756)
 **TRAIN** Prec@1 75.17 Prec@5 98.15 Error@1 24.83 Error@5 1.85 Base-Loss:0.729, Arch-Loss=0.756
***[2020-01-29 08:51:39]*** TRAIN [epoch=358/600] base-loss = 0.728856, arch-loss = 0.756173, accuracy-1 = 75.17, accuracy-5 = 98.15
[epoch=358/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.433 0.197 0.370  ||  0.2751 -0.5125 0.1186  || discrepancy=0.06 || select=0/3
001/003-th : 0.330 0.132 0.538  ||  0.0570 -0.8555 0.5465  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.026 0.968  ||  -2.3532 -0.8706 2.7409  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.057 0.077 0.078 0.125 0.153 0.202 0.273  ||  -1.108 -0.585 -0.275 -0.266 0.206 0.407 0.684 0.984   || dis=0.07 || select=7/8
001/019-th : 0.108 0.130 0.132 0.129 0.130 0.129 0.122 0.120  ||  -0.136 0.042 0.062 0.036 0.049 0.034 -0.018 -0.034    || dis=0.00 || select=2/8
002/019-th : 0.118 0.126 0.128 0.137 0.125 0.132 0.122 0.112  ||  -0.060 0.008 0.024 0.093 0.003 0.058 -0.027 -0.108    || dis=0.01 || select=3/8
003/019-th : 0.094 0.107 0.123 0.128 0.127 0.135 0.142 0.143  ||  -0.277 -0.143 -0.003 0.037 0.031 0.092 0.141 0.143    || dis=0.00 || select=7/8
004/019-th : 0.105 0.111 0.115 0.116 0.127 0.134 0.144 0.148  ||  -0.170 -0.113 -0.076 -0.074 0.018 0.074 0.145 0.169   || dis=0.00 || select=7/8
005/019-th : 0.105 0.118 0.125 0.123 0.129 0.131 0.132 0.136  ||  -0.166 -0.055 0.002 -0.009 0.037 0.054 0.061 0.086    || dis=0.00 || select=7/8
006/019-th : 0.117 0.111 0.116 0.116 0.128 0.132 0.141 0.139  ||  -0.067 -0.114 -0.075 -0.068 0.024 0.057 0.124 0.107   || dis=0.00 || select=6/8
007/019-th : 0.034 0.050 0.078 0.092 0.128 0.148 0.187 0.284  ||  -1.099 -0.712 -0.270 -0.099 0.231 0.373 0.607 1.028   || dis=0.10 || select=7/8
008/019-th : 0.025 0.037 0.058 0.094 0.115 0.162 0.242 0.268  ||  -1.318 -0.929 -0.461 0.012 0.216 0.556 0.961 1.061    || dis=0.03 || select=7/8
009/019-th : 0.073 0.081 0.094 0.118 0.123 0.138 0.168 0.204  ||  -0.479 -0.376 -0.221 0.003 0.042 0.157 0.357 0.550    || dis=0.04 || select=7/8
010/019-th : 0.085 0.090 0.110 0.126 0.132 0.153 0.146 0.158  ||  -0.357 -0.302 -0.108 0.031 0.082 0.226 0.180 0.259    || dis=0.01 || select=7/8
011/019-th : 0.095 0.099 0.105 0.118 0.124 0.137 0.154 0.168  ||  -0.259 -0.212 -0.152 -0.042 0.008 0.113 0.228 0.315   || dis=0.01 || select=7/8
012/019-th : 0.111 0.106 0.114 0.121 0.134 0.129 0.135 0.150  ||  -0.114 -0.158 -0.087 -0.030 0.077 0.035 0.083 0.185   || dis=0.01 || select=7/8
013/019-th : 0.013 0.018 0.022 0.031 0.041 0.074 0.171 0.631  ||  -1.394 -1.084 -0.874 -0.537 -0.245 0.345 1.187 2.490  || dis=0.46 || select=7/8
014/019-th : 0.018 0.030 0.035 0.049 0.081 0.123 0.241 0.423  ||  -1.398 -0.909 -0.757 -0.414 0.077 0.499 1.171 1.734   || dis=0.18 || select=7/8
015/019-th : 0.010 0.017 0.021 0.028 0.040 0.075 0.170 0.639  ||  -1.551 -1.091 -0.872 -0.553 -0.205 0.417 1.240 2.565  || dis=0.47 || select=7/8
016/019-th : 0.053 0.067 0.086 0.118 0.138 0.169 0.175 0.196  ||  -0.767 -0.540 -0.283 0.030 0.189 0.389 0.425 0.538    || dis=0.02 || select=7/8
017/019-th : 0.099 0.108 0.103 0.118 0.130 0.140 0.152 0.150  ||  -0.218 -0.134 -0.177 -0.039 0.057 0.127 0.210 0.201   || dis=0.00 || select=6/8
018/019-th : 0.079 0.094 0.115 0.129 0.135 0.136 0.143 0.168  ||  -0.431 -0.264 -0.060 0.053 0.097 0.110 0.160 0.321    || dis=0.03 || select=7/8
[epoch=358/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.121
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:51:40] [epoch=358/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.874 (1.874)  Prec@1 43.36 (43.36) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:51:46] [epoch=358/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.575 (2.424)  Prec@1 52.98 (35.89) Prec@5 91.67 (79.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.89 Prec@5 79.34 Error@1 64.11 Error@5 20.66 Loss:2.424
***[2020-01-29 08:51:46]*** VALID [epoch=358/600] loss = 2.423917, accuracy@1 = 35.89, accuracy@5 = 79.34 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:51:46]*** start epoch=359/600 Time Left: [02:08:02], LR=[0.034798 ~ 0.034798], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=359, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.8051190007325488, FLOP=40.81
[Search] : epoch=359/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:51:47] [epoch=359/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.660 (0.660)  Prec@1 78.52 (78.52) Prec@5 96.88 (96.88) Acls-loss 0.853 (0.853) FLOP-Loss 0.000 (0.000) Arch-Loss 0.853 (0.853)
**TRAIN** [2020-01-29 08:52:11] [epoch=359/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.570 (0.731)  Prec@1 80.95 (74.82) Prec@5 95.83 (98.26) Acls-loss 1.171 (0.813) FLOP-Loss 0.000 (0.088) Arch-Loss 1.171 (0.989)
 **TRAIN** Prec@1 74.82 Prec@5 98.26 Error@1 25.18 Error@5 1.74 Base-Loss:0.731, Arch-Loss=0.989
***[2020-01-29 08:52:11]*** TRAIN [epoch=359/600] base-loss = 0.731109, arch-loss = 0.989032, accuracy-1 = 74.82, accuracy-5 = 98.26
[epoch=359/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.428 0.200 0.372  ||  0.2665 -0.4951 0.1243  || discrepancy=0.06 || select=0/3
001/003-th : 0.326 0.134 0.540  ||  0.0484 -0.8431 0.5536  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.026 0.968  ||  -2.3521 -0.8778 2.7465  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.033 0.056 0.077 0.076 0.124 0.154 0.203 0.276  ||  -1.111 -0.589 -0.276 -0.287 0.200 0.415 0.692 0.998   || dis=0.07 || select=7/8
001/019-th : 0.109 0.127 0.132 0.129 0.130 0.129 0.123 0.121  ||  -0.134 0.024 0.059 0.040 0.048 0.039 -0.010 -0.031    || dis=0.00 || select=2/8
002/019-th : 0.117 0.126 0.128 0.136 0.127 0.130 0.123 0.112  ||  -0.061 0.006 0.027 0.086 0.017 0.043 -0.016 -0.107    || dis=0.01 || select=3/8
003/019-th : 0.094 0.108 0.122 0.127 0.126 0.135 0.143 0.145  ||  -0.271 -0.139 -0.012 0.027 0.015 0.090 0.142 0.158    || dis=0.00 || select=7/8
004/019-th : 0.105 0.109 0.118 0.116 0.127 0.133 0.141 0.150  ||  -0.169 -0.131 -0.055 -0.074 0.023 0.068 0.127 0.184   || dis=0.01 || select=7/8
005/019-th : 0.102 0.117 0.126 0.123 0.131 0.130 0.134 0.137  ||  -0.193 -0.062 0.016 -0.010 0.050 0.044 0.078 0.095    || dis=0.00 || select=7/8
006/019-th : 0.118 0.112 0.115 0.117 0.127 0.132 0.141 0.139  ||  -0.060 -0.112 -0.085 -0.065 0.018 0.058 0.124 0.107   || dis=0.00 || select=6/8
007/019-th : 0.034 0.050 0.076 0.087 0.130 0.148 0.187 0.288  ||  -1.098 -0.708 -0.279 -0.148 0.253 0.379 0.617 1.046   || dis=0.10 || select=7/8
008/019-th : 0.025 0.036 0.059 0.095 0.114 0.165 0.239 0.267  ||  -1.308 -0.948 -0.457 0.022 0.210 0.574 0.949 1.058    || dis=0.03 || select=7/8
009/019-th : 0.072 0.080 0.095 0.117 0.125 0.138 0.167 0.204  ||  -0.487 -0.382 -0.211 -0.003 0.062 0.158 0.348 0.548   || dis=0.04 || select=7/8
010/019-th : 0.084 0.088 0.109 0.127 0.133 0.153 0.148 0.158  ||  -0.369 -0.321 -0.111 0.041 0.088 0.226 0.198 0.262    || dis=0.01 || select=7/8
011/019-th : 0.095 0.097 0.107 0.115 0.126 0.136 0.153 0.170  ||  -0.254 -0.229 -0.138 -0.061 0.028 0.101 0.224 0.327   || dis=0.02 || select=7/8
012/019-th : 0.110 0.107 0.114 0.121 0.135 0.128 0.135 0.150  ||  -0.119 -0.147 -0.090 -0.029 0.082 0.025 0.078 0.190   || dis=0.01 || select=7/8
013/019-th : 0.013 0.018 0.022 0.030 0.041 0.074 0.170 0.633  ||  -1.398 -1.087 -0.876 -0.537 -0.244 0.346 1.186 2.498  || dis=0.46 || select=7/8
014/019-th : 0.018 0.030 0.034 0.049 0.080 0.123 0.242 0.424  ||  -1.418 -0.912 -0.764 -0.415 0.078 0.510 1.185 1.744   || dis=0.18 || select=7/8
015/019-th : 0.011 0.016 0.020 0.028 0.039 0.073 0.175 0.638  ||  -1.531 -1.102 -0.892 -0.566 -0.213 0.406 1.275 2.569  || dis=0.46 || select=7/8
016/019-th : 0.053 0.066 0.086 0.117 0.141 0.166 0.177 0.195  ||  -0.770 -0.547 -0.283 0.023 0.209 0.375 0.440 0.536    || dis=0.02 || select=7/8
017/019-th : 0.098 0.107 0.101 0.120 0.130 0.139 0.153 0.151  ||  -0.227 -0.142 -0.191 -0.023 0.059 0.126 0.223 0.207   || dis=0.00 || select=6/8
018/019-th : 0.080 0.095 0.114 0.130 0.135 0.136 0.142 0.169  ||  -0.425 -0.253 -0.074 0.062 0.096 0.106 0.151 0.322    || dis=0.03 || select=7/8
[epoch=359/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.121
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:52:11] [epoch=359/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.009 (2.009)  Prec@1 36.72 (36.72) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:52:17] [epoch=359/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.887 (2.529)  Prec@1 28.57 (34.42) Prec@5 76.19 (78.59) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.42 Prec@5 78.59 Error@1 65.58 Error@5 21.41 Loss:2.529
***[2020-01-29 08:52:17]*** VALID [epoch=359/600] loss = 2.529155, accuracy@1 = 34.42, accuracy@5 = 78.59 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:52:18]*** start epoch=360/600 Time Left: [02:07:30], LR=[0.034549 ~ 0.034549], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=360, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7929083637813792, FLOP=40.81
[Search] : epoch=360/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:52:18] [epoch=360/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.619 (0.619)  Prec@1 77.34 (77.34) Prec@5 98.44 (98.44) Acls-loss 0.843 (0.843) FLOP-Loss 0.000 (0.000) Arch-Loss 0.843 (0.843)
**TRAIN** [2020-01-29 08:52:43] [epoch=360/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.893 (0.723)  Prec@1 67.26 (75.26) Prec@5 99.40 (98.41) Acls-loss 0.673 (0.774) FLOP-Loss 0.000 (0.117) Arch-Loss 0.673 (1.009)
 **TRAIN** Prec@1 75.26 Prec@5 98.41 Error@1 24.74 Error@5 1.59 Base-Loss:0.723, Arch-Loss=1.009
***[2020-01-29 08:52:43]*** TRAIN [epoch=360/600] base-loss = 0.722702, arch-loss = 1.008558, accuracy-1 = 75.26, accuracy-5 = 98.41
[epoch=360/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.428 0.203 0.369  ||  0.2681 -0.4800 0.1195  || discrepancy=0.06 || select=0/3
001/003-th : 0.328 0.135 0.538  ||  0.0533 -0.8360 0.5486  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.026 0.968  ||  -2.3504 -0.8783 2.7489  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.057 0.076 0.077 0.122 0.151 0.203 0.281  ||  -1.106 -0.580 -0.292 -0.281 0.187 0.399 0.692 1.017   || dis=0.08 || select=7/8
001/019-th : 0.109 0.129 0.131 0.129 0.131 0.128 0.123 0.120  ||  -0.134 0.041 0.055 0.038 0.053 0.026 -0.014 -0.036    || dis=0.00 || select=2/8
002/019-th : 0.118 0.125 0.129 0.135 0.127 0.130 0.122 0.112  ||  -0.056 0.003 0.031 0.081 0.019 0.039 -0.021 -0.106    || dis=0.01 || select=3/8
003/019-th : 0.094 0.108 0.122 0.128 0.128 0.133 0.142 0.145  ||  -0.278 -0.135 -0.012 0.034 0.037 0.071 0.138 0.158    || dis=0.00 || select=7/8
004/019-th : 0.106 0.111 0.116 0.116 0.126 0.132 0.143 0.150  ||  -0.162 -0.119 -0.071 -0.068 0.014 0.054 0.137 0.185   || dis=0.01 || select=7/8
005/019-th : 0.102 0.119 0.128 0.125 0.128 0.130 0.132 0.137  ||  -0.200 -0.047 0.026 0.007 0.031 0.042 0.061 0.097     || dis=0.01 || select=7/8
006/019-th : 0.119 0.112 0.114 0.118 0.125 0.133 0.142 0.137  ||  -0.046 -0.111 -0.091 -0.054 -0.000 0.065 0.131 0.093  || dis=0.00 || select=6/8
007/019-th : 0.034 0.050 0.076 0.086 0.128 0.151 0.186 0.289  ||  -1.102 -0.694 -0.285 -0.156 0.237 0.401 0.614 1.052   || dis=0.10 || select=7/8
008/019-th : 0.025 0.036 0.059 0.095 0.115 0.165 0.237 0.268  ||  -1.299 -0.949 -0.457 0.018 0.211 0.574 0.937 1.060    || dis=0.03 || select=7/8
009/019-th : 0.073 0.080 0.097 0.119 0.126 0.138 0.166 0.201  ||  -0.483 -0.388 -0.200 0.008 0.065 0.160 0.344 0.531    || dis=0.04 || select=7/8
010/019-th : 0.084 0.089 0.109 0.126 0.132 0.152 0.150 0.157  ||  -0.371 -0.314 -0.107 0.036 0.084 0.223 0.211 0.253    || dis=0.01 || select=7/8
011/019-th : 0.094 0.098 0.108 0.115 0.126 0.135 0.155 0.169  ||  -0.264 -0.225 -0.131 -0.061 0.031 0.096 0.236 0.318   || dis=0.01 || select=7/8
012/019-th : 0.112 0.107 0.115 0.122 0.134 0.125 0.136 0.149  ||  -0.107 -0.149 -0.078 -0.022 0.074 0.008 0.086 0.180   || dis=0.01 || select=7/8
013/019-th : 0.013 0.017 0.021 0.031 0.040 0.074 0.167 0.638  ||  -1.411 -1.093 -0.884 -0.521 -0.250 0.355 1.172 2.515  || dis=0.47 || select=7/8
014/019-th : 0.018 0.029 0.035 0.048 0.080 0.123 0.239 0.428  ||  -1.409 -0.926 -0.753 -0.427 0.080 0.513 1.173 1.758   || dis=0.19 || select=7/8
015/019-th : 0.011 0.016 0.020 0.027 0.040 0.074 0.177 0.636  ||  -1.524 -1.122 -0.900 -0.580 -0.195 0.413 1.286 2.566  || dis=0.46 || select=7/8
016/019-th : 0.053 0.066 0.087 0.116 0.141 0.164 0.176 0.197  ||  -0.765 -0.543 -0.278 0.014 0.213 0.360 0.435 0.544    || dis=0.02 || select=7/8
017/019-th : 0.098 0.107 0.101 0.120 0.130 0.138 0.154 0.151  ||  -0.222 -0.134 -0.193 -0.025 0.056 0.116 0.227 0.204   || dis=0.00 || select=6/8
018/019-th : 0.081 0.096 0.114 0.127 0.136 0.136 0.142 0.169  ||  -0.417 -0.247 -0.072 0.040 0.107 0.105 0.148 0.320    || dis=0.03 || select=7/8
[epoch=360/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.122
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:52:43] [epoch=360/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.141 (2.141)  Prec@1 43.75 (43.75) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:52:49] [epoch=360/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.062 (2.495)  Prec@1 42.86 (38.22) Prec@5 79.17 (81.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.22 Prec@5 81.17 Error@1 61.78 Error@5 18.83 Loss:2.495
***[2020-01-29 08:52:49]*** VALID [epoch=360/600] loss = 2.495482, accuracy@1 = 38.22, accuracy@5 = 81.17 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:52:49]*** start epoch=361/600 Time Left: [02:06:57], LR=[0.034300 ~ 0.034300], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=361, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.780718482879858, FLOP=40.81
[Search] : epoch=361/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:52:50] [epoch=361/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.773 (0.773)  Prec@1 74.22 (74.22) Prec@5 97.27 (97.27) Acls-loss 0.793 (0.793) FLOP-Loss 0.000 (0.000) Arch-Loss 0.793 (0.793)
**TRAIN** [2020-01-29 08:53:14] [epoch=361/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.768 (0.742)  Prec@1 73.21 (74.66) Prec@5 98.81 (98.24) Acls-loss 0.782 (0.778) FLOP-Loss 0.000 (0.117) Arch-Loss 0.782 (1.012)
 **TRAIN** Prec@1 74.66 Prec@5 98.24 Error@1 25.34 Error@5 1.76 Base-Loss:0.742, Arch-Loss=1.012
***[2020-01-29 08:53:14]*** TRAIN [epoch=361/600] base-loss = 0.741990, arch-loss = 1.011621, accuracy-1 = 74.66, accuracy-5 = 98.24
[epoch=361/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.198528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.433 0.198 0.369  ||  0.2765 -0.5075 0.1177  || discrepancy=0.06 || select=0/3
001/003-th : 0.330 0.135 0.535  ||  0.0602 -0.8326 0.5423  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.026 0.968  ||  -2.3459 -0.8709 2.7456  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.057 0.075 0.077 0.121 0.152 0.204 0.280  ||  -1.096 -0.582 -0.302 -0.282 0.176 0.406 0.700 1.015   || dis=0.08 || select=7/8
001/019-th : 0.110 0.130 0.131 0.132 0.132 0.125 0.121 0.119  ||  -0.124 0.044 0.054 0.061 0.057 0.007 -0.025 -0.044    || dis=0.00 || select=3/8
002/019-th : 0.118 0.125 0.131 0.135 0.127 0.130 0.122 0.112  ||  -0.055 -0.001 0.046 0.077 0.016 0.040 -0.023 -0.108   || dis=0.00 || select=3/8
003/019-th : 0.095 0.108 0.121 0.128 0.126 0.133 0.142 0.146  ||  -0.262 -0.142 -0.020 0.033 0.020 0.072 0.138 0.164    || dis=0.00 || select=7/8
004/019-th : 0.106 0.109 0.117 0.117 0.125 0.132 0.145 0.148  ||  -0.165 -0.131 -0.065 -0.059 0.007 0.061 0.153 0.175   || dis=0.00 || select=7/8
005/019-th : 0.103 0.120 0.128 0.126 0.126 0.129 0.132 0.135  ||  -0.187 -0.036 0.029 0.015 0.016 0.036 0.055 0.082     || dis=0.00 || select=7/8
006/019-th : 0.120 0.112 0.115 0.116 0.124 0.130 0.145 0.138  ||  -0.038 -0.109 -0.087 -0.076 -0.005 0.041 0.147 0.100  || dis=0.01 || select=6/8
007/019-th : 0.034 0.050 0.077 0.086 0.127 0.151 0.186 0.290  ||  -1.102 -0.708 -0.274 -0.154 0.227 0.403 0.614 1.056   || dis=0.10 || select=7/8
008/019-th : 0.025 0.036 0.059 0.094 0.115 0.163 0.237 0.270  ||  -1.301 -0.941 -0.451 0.012 0.212 0.563 0.933 1.064    || dis=0.03 || select=7/8
009/019-th : 0.073 0.081 0.097 0.117 0.124 0.140 0.164 0.205  ||  -0.475 -0.383 -0.198 -0.013 0.052 0.169 0.328 0.549   || dis=0.04 || select=7/8
010/019-th : 0.085 0.090 0.110 0.126 0.132 0.151 0.148 0.157  ||  -0.358 -0.299 -0.105 0.033 0.078 0.212 0.197 0.254    || dis=0.01 || select=7/8
011/019-th : 0.095 0.098 0.105 0.118 0.127 0.133 0.156 0.167  ||  -0.260 -0.223 -0.154 -0.035 0.036 0.084 0.241 0.312   || dis=0.01 || select=7/8
012/019-th : 0.113 0.108 0.117 0.122 0.133 0.125 0.135 0.147  ||  -0.096 -0.139 -0.065 -0.023 0.069 0.006 0.079 0.166   || dis=0.01 || select=7/8
013/019-th : 0.013 0.017 0.021 0.031 0.040 0.072 0.167 0.639  ||  -1.394 -1.094 -0.882 -0.512 -0.255 0.333 1.175 2.519  || dis=0.47 || select=7/8
014/019-th : 0.018 0.029 0.035 0.048 0.080 0.123 0.240 0.428  ||  -1.408 -0.925 -0.753 -0.437 0.080 0.509 1.182 1.759   || dis=0.19 || select=7/8
015/019-th : 0.010 0.016 0.020 0.027 0.040 0.072 0.176 0.638  ||  -1.559 -1.117 -0.882 -0.576 -0.185 0.392 1.290 2.575  || dis=0.46 || select=7/8
016/019-th : 0.053 0.066 0.086 0.118 0.140 0.163 0.177 0.196  ||  -0.760 -0.543 -0.284 0.031 0.207 0.354 0.437 0.540    || dis=0.02 || select=7/8
017/019-th : 0.097 0.107 0.101 0.121 0.133 0.137 0.154 0.151  ||  -0.233 -0.141 -0.196 -0.016 0.080 0.109 0.225 0.208   || dis=0.00 || select=6/8
018/019-th : 0.080 0.097 0.115 0.127 0.134 0.138 0.141 0.168  ||  -0.431 -0.236 -0.061 0.041 0.088 0.123 0.141 0.320    || dis=0.03 || select=7/8
[epoch=361/600] FLOP : 28.20 MB, ratio : 0.6909, Expected-ratio : 0.7000, Discrepancy : 0.122
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:53:15] [epoch=361/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.989 (2.989)  Prec@1 25.00 (25.00) Prec@5 73.44 (73.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:53:21] [epoch=361/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.125 (2.424)  Prec@1 19.64 (32.89) Prec@5 59.52 (78.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 32.89 Prec@5 78.21 Error@1 67.11 Error@5 21.79 Loss:2.424
***[2020-01-29 08:53:21]*** VALID [epoch=361/600] loss = 2.424053, accuracy@1 = 32.89, accuracy@5 = 78.21 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:53:21]*** start epoch=362/600 Time Left: [02:06:25], LR=[0.034052 ~ 0.034052], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=362, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7685496922197286, FLOP=40.81
[Search] : epoch=362/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:53:21] [epoch=362/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.691 (0.691)  Prec@1 76.17 (76.17) Prec@5 98.44 (98.44) Acls-loss 0.946 (0.946) FLOP-Loss 0.000 (0.000) Arch-Loss 0.946 (0.946)
**TRAIN** [2020-01-29 08:53:46] [epoch=362/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.578 (0.711)  Prec@1 79.76 (75.81) Prec@5 99.40 (98.14) Acls-loss 0.751 (0.780) FLOP-Loss 0.000 (0.029) Arch-Loss 0.751 (0.838)
 **TRAIN** Prec@1 75.81 Prec@5 98.14 Error@1 24.19 Error@5 1.86 Base-Loss:0.711, Arch-Loss=0.838
***[2020-01-29 08:53:46]*** TRAIN [epoch=362/600] base-loss = 0.710926, arch-loss = 0.838196, accuracy-1 = 75.81, accuracy-5 = 98.14
[epoch=362/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 27.968128)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.425 0.201 0.374  ||  0.2590 -0.4907 0.1326  || discrepancy=0.05 || select=0/3
001/003-th : 0.325 0.137 0.538  ||  0.0481 -0.8158 0.5516  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3538 -0.8860 2.7620  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.034 0.057 0.075 0.076 0.120 0.154 0.208 0.278  ||  -1.104 -0.582 -0.303 -0.292 0.168 0.420 0.720 1.011   || dis=0.07 || select=7/8
001/019-th : 0.109 0.127 0.133 0.132 0.132 0.125 0.122 0.121  ||  -0.131 0.024 0.066 0.061 0.059 0.003 -0.019 -0.031    || dis=0.00 || select=2/8
002/019-th : 0.117 0.125 0.128 0.134 0.129 0.131 0.123 0.114  ||  -0.070 -0.001 0.026 0.073 0.028 0.045 -0.015 -0.093   || dis=0.00 || select=3/8
003/019-th : 0.094 0.107 0.121 0.127 0.125 0.134 0.144 0.147  ||  -0.274 -0.143 -0.022 0.022 0.012 0.077 0.154 0.174    || dis=0.00 || select=7/8
004/019-th : 0.106 0.108 0.116 0.118 0.127 0.132 0.145 0.149  ||  -0.162 -0.142 -0.073 -0.054 0.017 0.062 0.153 0.177   || dis=0.00 || select=7/8
005/019-th : 0.104 0.121 0.127 0.126 0.126 0.130 0.131 0.136  ||  -0.182 -0.033 0.017 0.009 0.012 0.041 0.049 0.090     || dis=0.01 || select=7/8
006/019-th : 0.120 0.113 0.113 0.116 0.123 0.131 0.146 0.138  ||  -0.041 -0.103 -0.099 -0.073 -0.014 0.051 0.153 0.099  || dis=0.01 || select=6/8
007/019-th : 0.033 0.047 0.076 0.085 0.125 0.152 0.187 0.295  ||  -1.109 -0.748 -0.275 -0.160 0.227 0.420 0.626 1.084   || dis=0.11 || select=7/8
008/019-th : 0.025 0.035 0.058 0.091 0.115 0.164 0.238 0.273  ||  -1.292 -0.968 -0.458 -0.020 0.223 0.577 0.948 1.083   || dis=0.04 || select=7/8
009/019-th : 0.073 0.079 0.097 0.116 0.123 0.141 0.165 0.206  ||  -0.479 -0.397 -0.193 -0.017 0.043 0.177 0.335 0.560   || dis=0.04 || select=7/8
010/019-th : 0.084 0.090 0.108 0.123 0.132 0.151 0.151 0.160  ||  -0.372 -0.299 -0.121 0.013 0.078 0.215 0.216 0.274    || dis=0.01 || select=7/8
011/019-th : 0.095 0.097 0.103 0.117 0.127 0.136 0.157 0.168  ||  -0.251 -0.233 -0.175 -0.048 0.041 0.103 0.251 0.317   || dis=0.01 || select=7/8
012/019-th : 0.113 0.109 0.117 0.122 0.131 0.124 0.136 0.147  ||  -0.096 -0.132 -0.064 -0.023 0.054 -0.005 0.090 0.169  || dis=0.01 || select=7/8
013/019-th : 0.013 0.017 0.021 0.031 0.039 0.071 0.161 0.647  ||  -1.391 -1.100 -0.880 -0.502 -0.265 0.332 1.155 2.543  || dis=0.49 || select=7/8
014/019-th : 0.018 0.029 0.034 0.047 0.079 0.122 0.242 0.429  ||  -1.407 -0.930 -0.765 -0.442 0.078 0.510 1.195 1.768   || dis=0.19 || select=7/8
015/019-th : 0.010 0.016 0.020 0.027 0.040 0.070 0.172 0.644  ||  -1.564 -1.112 -0.876 -0.563 -0.185 0.380 1.270 2.593  || dis=0.47 || select=7/8
016/019-th : 0.053 0.065 0.086 0.118 0.139 0.160 0.182 0.197  ||  -0.771 -0.560 -0.283 0.037 0.202 0.340 0.469 0.545    || dis=0.02 || select=7/8
017/019-th : 0.097 0.106 0.101 0.117 0.131 0.138 0.157 0.152  ||  -0.237 -0.146 -0.190 -0.044 0.065 0.120 0.246 0.214   || dis=0.01 || select=6/8
018/019-th : 0.079 0.096 0.114 0.125 0.133 0.140 0.141 0.171  ||  -0.432 -0.240 -0.068 0.024 0.082 0.133 0.145 0.333    || dis=0.03 || select=7/8
[epoch=362/600] FLOP : 27.97 MB, ratio : 0.6853, Expected-ratio : 0.7000, Discrepancy : 0.123
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:53:46] [epoch=362/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.712 (1.712)  Prec@1 38.28 (38.28) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:53:52] [epoch=362/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.696 (2.549)  Prec@1 44.05 (35.01) Prec@5 89.29 (78.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.01 Prec@5 78.60 Error@1 64.99 Error@5 21.40 Loss:2.549
***[2020-01-29 08:53:52]*** VALID [epoch=362/600] loss = 2.548805, accuracy@1 = 35.01, accuracy@5 = 78.60 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:53:52]*** start epoch=363/600 Time Left: [02:05:53], LR=[0.033804 ~ 0.033804], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=363, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7564023254145347, FLOP=40.81
[Search] : epoch=363/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:53:53] [epoch=363/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.647 (0.647)  Prec@1 75.78 (75.78) Prec@5 98.83 (98.83) Acls-loss 1.070 (1.070) FLOP-Loss 0.000 (0.000) Arch-Loss 1.070 (1.070)
**TRAIN** [2020-01-29 08:54:18] [epoch=363/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.012 (0.731)  Prec@1 60.71 (75.22) Prec@5 96.43 (98.13) Acls-loss 1.082 (0.800) FLOP-Loss 0.000 (0.029) Arch-Loss 1.082 (0.858)
 **TRAIN** Prec@1 75.22 Prec@5 98.13 Error@1 24.78 Error@5 1.87 Base-Loss:0.731, Arch-Loss=0.858
***[2020-01-29 08:54:18]*** TRAIN [epoch=363/600] base-loss = 0.731205, arch-loss = 0.858270, accuracy-1 = 75.22, accuracy-5 = 98.13
[epoch=363/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.198528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.417 0.205 0.378  ||  0.2424 -0.4663 0.1444  || discrepancy=0.04 || select=0/3
001/003-th : 0.321 0.138 0.541  ||  0.0390 -0.8051 0.5591  || discrepancy=0.22 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3404 -0.8906 2.7564  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.033 0.057 0.073 0.076 0.118 0.154 0.206 0.283  ||  -1.105 -0.574 -0.318 -0.285 0.155 0.420 0.713 1.030   || dis=0.08 || select=7/8
001/019-th : 0.107 0.127 0.133 0.133 0.131 0.124 0.123 0.121  ||  -0.149 0.022 0.071 0.072 0.053 0.002 -0.010 -0.022    || dis=0.00 || select=3/8
002/019-th : 0.115 0.123 0.129 0.134 0.128 0.132 0.124 0.115  ||  -0.080 -0.012 0.029 0.071 0.025 0.052 -0.009 -0.081   || dis=0.00 || select=3/8
003/019-th : 0.093 0.107 0.121 0.125 0.126 0.133 0.146 0.149  ||  -0.289 -0.145 -0.020 0.014 0.018 0.076 0.164 0.184    || dis=0.00 || select=7/8
004/019-th : 0.106 0.107 0.116 0.117 0.126 0.132 0.147 0.148  ||  -0.156 -0.155 -0.070 -0.059 0.012 0.060 0.168 0.175   || dis=0.00 || select=7/8
005/019-th : 0.104 0.119 0.125 0.124 0.124 0.129 0.134 0.141  ||  -0.180 -0.045 0.000 -0.006 -0.004 0.034 0.069 0.121   || dis=0.01 || select=7/8
006/019-th : 0.117 0.112 0.112 0.117 0.125 0.131 0.147 0.139  ||  -0.064 -0.107 -0.106 -0.069 0.000 0.047 0.163 0.111   || dis=0.01 || select=6/8
007/019-th : 0.033 0.047 0.075 0.086 0.126 0.151 0.187 0.296  ||  -1.112 -0.756 -0.287 -0.151 0.232 0.418 0.629 1.091   || dis=0.11 || select=7/8
008/019-th : 0.025 0.034 0.059 0.091 0.113 0.162 0.241 0.275  ||  -1.298 -0.986 -0.450 -0.013 0.211 0.568 0.966 1.099   || dis=0.03 || select=7/8
009/019-th : 0.074 0.079 0.094 0.116 0.121 0.140 0.167 0.209  ||  -0.467 -0.398 -0.223 -0.013 0.025 0.175 0.351 0.575   || dis=0.04 || select=7/8
010/019-th : 0.081 0.090 0.108 0.125 0.130 0.152 0.152 0.163  ||  -0.410 -0.299 -0.114 0.029 0.066 0.222 0.222 0.291    || dis=0.01 || select=7/8
011/019-th : 0.094 0.096 0.102 0.117 0.123 0.136 0.160 0.172  ||  -0.262 -0.239 -0.178 -0.040 0.004 0.103 0.268 0.341   || dis=0.01 || select=7/8
012/019-th : 0.111 0.108 0.118 0.122 0.131 0.125 0.138 0.148  ||  -0.117 -0.145 -0.052 -0.022 0.050 0.004 0.104 0.174   || dis=0.01 || select=7/8
013/019-th : 0.012 0.017 0.021 0.031 0.038 0.071 0.159 0.652  ||  -1.400 -1.106 -0.886 -0.496 -0.271 0.338 1.149 2.560  || dis=0.49 || select=7/8
014/019-th : 0.018 0.028 0.033 0.046 0.079 0.118 0.235 0.442  ||  -1.415 -0.933 -0.779 -0.447 0.092 0.493 1.180 1.812   || dis=0.21 || select=7/8
015/019-th : 0.010 0.016 0.020 0.027 0.039 0.069 0.170 0.649  ||  -1.583 -1.114 -0.883 -0.556 -0.187 0.369 1.278 2.616  || dis=0.48 || select=7/8
016/019-th : 0.053 0.063 0.085 0.116 0.138 0.162 0.183 0.199  ||  -0.768 -0.582 -0.293 0.025 0.195 0.358 0.479 0.561    || dis=0.02 || select=7/8
017/019-th : 0.094 0.105 0.101 0.118 0.132 0.139 0.158 0.152  ||  -0.265 -0.150 -0.190 -0.036 0.079 0.130 0.257 0.214   || dis=0.01 || select=6/8
018/019-th : 0.079 0.097 0.114 0.123 0.133 0.138 0.143 0.173  ||  -0.438 -0.236 -0.071 0.007 0.084 0.123 0.156 0.345    || dis=0.03 || select=7/8
[epoch=363/600] FLOP : 28.20 MB, ratio : 0.6909, Expected-ratio : 0.7000, Discrepancy : 0.125
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:54:18] [epoch=363/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.582 (1.582)  Prec@1 48.05 (48.05) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:54:24] [epoch=363/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.003 (2.364)  Prec@1 50.00 (37.55) Prec@5 92.86 (80.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.55 Prec@5 80.04 Error@1 62.45 Error@5 19.96 Loss:2.364
***[2020-01-29 08:54:24]*** VALID [epoch=363/600] loss = 2.363570, accuracy@1 = 37.55, accuracy@5 = 80.04 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:54:24]*** start epoch=364/600 Time Left: [02:05:21], LR=[0.033557 ~ 0.033557], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=364, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7442767154904713, FLOP=40.81
[Search] : epoch=364/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:54:25] [epoch=364/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.722 (0.722)  Prec@1 77.73 (77.73) Prec@5 98.44 (98.44) Acls-loss 0.824 (0.824) FLOP-Loss 0.000 (0.000) Arch-Loss 0.824 (0.824)
**TRAIN** [2020-01-29 08:54:49] [epoch=364/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.763 (0.739)  Prec@1 72.02 (74.78) Prec@5 98.21 (98.21) Acls-loss 0.686 (0.774) FLOP-Loss 0.000 (0.000) Arch-Loss 0.686 (0.774)
 **TRAIN** Prec@1 74.78 Prec@5 98.21 Error@1 25.22 Error@5 1.79 Base-Loss:0.739, Arch-Loss=0.774
***[2020-01-29 08:54:49]*** TRAIN [epoch=364/600] base-loss = 0.739361, arch-loss = 0.774098, accuracy-1 = 74.78, accuracy-5 = 98.21
[epoch=364/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.496512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.410 0.206 0.384  ||  0.2256 -0.4615 0.1612  || discrepancy=0.03 || select=0/3
001/003-th : 0.315 0.138 0.547  ||  0.0240 -0.8016 0.5739  || discrepancy=0.23 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3393 -0.8970 2.7621  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.033 0.055 0.072 0.076 0.118 0.153 0.206 0.287  ||  -1.113 -0.603 -0.328 -0.279 0.168 0.423 0.720 1.053   || dis=0.08 || select=7/8
001/019-th : 0.104 0.124 0.131 0.134 0.133 0.126 0.124 0.123  ||  -0.174 0.006 0.054 0.080 0.072 0.021 0.005 -0.006     || dis=0.00 || select=3/8
002/019-th : 0.113 0.122 0.128 0.133 0.128 0.133 0.125 0.118  ||  -0.103 -0.027 0.027 0.063 0.024 0.065 0.002 -0.055    || dis=0.00 || select=5/8
003/019-th : 0.091 0.106 0.122 0.124 0.127 0.135 0.146 0.149  ||  -0.302 -0.157 -0.013 0.005 0.028 0.089 0.167 0.191    || dis=0.00 || select=7/8
004/019-th : 0.105 0.105 0.115 0.116 0.126 0.133 0.149 0.150  ||  -0.167 -0.167 -0.080 -0.066 0.016 0.069 0.183 0.186   || dis=0.00 || select=7/8
005/019-th : 0.103 0.118 0.125 0.123 0.126 0.130 0.135 0.141  ||  -0.188 -0.055 0.000 -0.013 0.008 0.042 0.079 0.123    || dis=0.01 || select=7/8
006/019-th : 0.115 0.111 0.112 0.118 0.126 0.128 0.148 0.143  ||  -0.084 -0.119 -0.108 -0.056 0.011 0.022 0.170 0.134   || dis=0.01 || select=6/8
007/019-th : 0.032 0.047 0.073 0.085 0.123 0.152 0.189 0.299  ||  -1.117 -0.747 -0.308 -0.159 0.219 0.427 0.645 1.104   || dis=0.11 || select=7/8
008/019-th : 0.025 0.035 0.058 0.090 0.110 0.159 0.240 0.282  ||  -1.300 -0.970 -0.450 -0.016 0.181 0.551 0.963 1.125   || dis=0.04 || select=7/8
009/019-th : 0.072 0.078 0.094 0.117 0.121 0.138 0.168 0.212  ||  -0.485 -0.404 -0.222 -0.008 0.034 0.160 0.356 0.592   || dis=0.04 || select=7/8
010/019-th : 0.079 0.090 0.107 0.124 0.131 0.150 0.155 0.165  ||  -0.429 -0.300 -0.124 0.020 0.074 0.213 0.245 0.307    || dis=0.01 || select=7/8
011/019-th : 0.094 0.095 0.101 0.115 0.124 0.135 0.161 0.174  ||  -0.262 -0.246 -0.188 -0.056 0.012 0.101 0.278 0.356   || dis=0.01 || select=7/8
012/019-th : 0.109 0.106 0.118 0.123 0.128 0.125 0.141 0.152  ||  -0.131 -0.163 -0.057 -0.014 0.027 0.003 0.122 0.198   || dis=0.01 || select=7/8
013/019-th : 0.012 0.016 0.021 0.031 0.038 0.070 0.157 0.655  ||  -1.416 -1.115 -0.877 -0.490 -0.268 0.335 1.146 2.574  || dis=0.50 || select=7/8
014/019-th : 0.017 0.028 0.033 0.046 0.079 0.118 0.232 0.445  ||  -1.417 -0.938 -0.774 -0.443 0.089 0.496 1.169 1.820   || dis=0.21 || select=7/8
015/019-th : 0.010 0.015 0.020 0.027 0.038 0.068 0.173 0.650  ||  -1.586 -1.128 -0.871 -0.568 -0.206 0.363 1.300 2.625  || dis=0.48 || select=7/8
016/019-th : 0.053 0.062 0.084 0.114 0.136 0.162 0.186 0.203  ||  -0.763 -0.598 -0.303 0.007 0.185 0.361 0.495 0.585    || dis=0.02 || select=7/8
017/019-th : 0.092 0.105 0.100 0.119 0.132 0.140 0.160 0.152  ||  -0.285 -0.148 -0.203 -0.026 0.078 0.137 0.272 0.221   || dis=0.01 || select=6/8
018/019-th : 0.079 0.096 0.115 0.121 0.135 0.138 0.144 0.173  ||  -0.437 -0.247 -0.065 -0.009 0.099 0.121 0.163 0.345   || dis=0.03 || select=7/8
[epoch=364/600] FLOP : 28.50 MB, ratio : 0.6982, Expected-ratio : 0.7000, Discrepancy : 0.126
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:54:49] [epoch=364/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.092 (2.092)  Prec@1 56.25 (56.25) Prec@5 90.62 (90.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:54:55] [epoch=364/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.006 (2.431)  Prec@1 32.74 (40.04) Prec@5 73.81 (82.12) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.04 Prec@5 82.12 Error@1 59.96 Error@5 17.88 Loss:2.431
***[2020-01-29 08:54:56]*** VALID [epoch=364/600] loss = 2.430850, accuracy@1 = 40.04, accuracy@5 = 82.12 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:54:56]*** start epoch=365/600 Time Left: [02:04:49], LR=[0.033310 ~ 0.033310], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=365, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7321731948772616, FLOP=40.81
[Search] : epoch=365/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:54:56] [epoch=365/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.809 (0.809)  Prec@1 71.88 (71.88) Prec@5 97.27 (97.27) Acls-loss 0.663 (0.663) FLOP-Loss 0.000 (0.000) Arch-Loss 0.663 (0.663)
**TRAIN** [2020-01-29 08:55:21] [epoch=365/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.666 (0.739)  Prec@1 74.40 (74.80) Prec@5 98.21 (98.16) Acls-loss 0.691 (0.774) FLOP-Loss 0.000 (0.030) Arch-Loss 0.691 (0.833)
 **TRAIN** Prec@1 74.80 Prec@5 98.16 Error@1 25.20 Error@5 1.84 Base-Loss:0.739, Arch-Loss=0.833
***[2020-01-29 08:55:21]*** TRAIN [epoch=365/600] base-loss = 0.739046, arch-loss = 0.833456, accuracy-1 = 74.80, accuracy-5 = 98.16
[epoch=365/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.496512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.403 0.206 0.391  ||  0.2099 -0.4623 0.1783  || discrepancy=0.01 || select=0/3
001/003-th : 0.312 0.135 0.553  ||  0.0151 -0.8192 0.5874  || discrepancy=0.24 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3341 -0.9026 2.7637  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.033 0.053 0.072 0.075 0.116 0.152 0.207 0.292  ||  -1.109 -0.632 -0.321 -0.287 0.153 0.419 0.733 1.076   || dis=0.08 || select=7/8
001/019-th : 0.100 0.124 0.128 0.137 0.134 0.128 0.125 0.124  ||  -0.212 0.009 0.041 0.104 0.087 0.036 0.012 0.009      || dis=0.00 || select=3/8
002/019-th : 0.113 0.121 0.128 0.131 0.127 0.132 0.128 0.120  ||  -0.101 -0.032 0.025 0.046 0.016 0.053 0.020 -0.045    || dis=0.00 || select=5/8
003/019-th : 0.089 0.105 0.122 0.124 0.128 0.135 0.147 0.150  ||  -0.320 -0.156 -0.014 0.006 0.036 0.090 0.173 0.199    || dis=0.00 || select=7/8
004/019-th : 0.105 0.106 0.116 0.116 0.125 0.132 0.148 0.152  ||  -0.170 -0.158 -0.067 -0.070 0.009 0.056 0.174 0.199   || dis=0.00 || select=7/8
005/019-th : 0.102 0.117 0.123 0.121 0.125 0.132 0.136 0.143  ||  -0.199 -0.063 -0.009 -0.024 0.006 0.060 0.085 0.142   || dis=0.01 || select=7/8
006/019-th : 0.113 0.109 0.111 0.119 0.126 0.127 0.151 0.144  ||  -0.102 -0.139 -0.112 -0.046 0.014 0.019 0.191 0.142   || dis=0.01 || select=6/8
007/019-th : 0.032 0.047 0.072 0.083 0.123 0.148 0.193 0.302  ||  -1.112 -0.748 -0.322 -0.168 0.219 0.406 0.669 1.118   || dis=0.11 || select=7/8
008/019-th : 0.024 0.034 0.057 0.089 0.108 0.160 0.241 0.287  ||  -1.331 -0.974 -0.470 -0.016 0.176 0.572 0.980 1.156   || dis=0.05 || select=7/8
009/019-th : 0.071 0.077 0.095 0.118 0.121 0.138 0.166 0.214  ||  -0.507 -0.423 -0.204 0.005 0.030 0.167 0.352 0.604    || dis=0.05 || select=7/8
010/019-th : 0.080 0.091 0.107 0.122 0.131 0.148 0.156 0.166  ||  -0.422 -0.293 -0.127 0.007 0.079 0.200 0.248 0.310    || dis=0.01 || select=7/8
011/019-th : 0.094 0.094 0.102 0.116 0.121 0.136 0.162 0.175  ||  -0.266 -0.257 -0.176 -0.054 -0.008 0.109 0.283 0.363  || dis=0.01 || select=7/8
012/019-th : 0.109 0.106 0.117 0.123 0.124 0.126 0.141 0.154  ||  -0.133 -0.161 -0.066 -0.016 -0.004 0.015 0.127 0.213  || dis=0.01 || select=7/8
013/019-th : 0.012 0.016 0.021 0.030 0.038 0.070 0.154 0.660  ||  -1.432 -1.136 -0.870 -0.493 -0.252 0.342 1.135 2.591  || dis=0.51 || select=7/8
014/019-th : 0.018 0.028 0.033 0.046 0.079 0.118 0.229 0.451  ||  -1.406 -0.951 -0.773 -0.454 0.091 0.495 1.160 1.837   || dis=0.22 || select=7/8
015/019-th : 0.010 0.015 0.019 0.026 0.037 0.065 0.169 0.659  ||  -1.574 -1.153 -0.870 -0.577 -0.219 0.349 1.303 2.663  || dis=0.49 || select=7/8
016/019-th : 0.052 0.063 0.084 0.113 0.136 0.164 0.186 0.203  ||  -0.777 -0.590 -0.301 -0.003 0.187 0.371 0.499 0.583   || dis=0.02 || select=7/8
017/019-th : 0.091 0.104 0.099 0.119 0.130 0.143 0.160 0.155  ||  -0.292 -0.164 -0.209 -0.024 0.065 0.158 0.269 0.239   || dis=0.01 || select=6/8
018/019-th : 0.079 0.096 0.115 0.121 0.134 0.139 0.145 0.171  ||  -0.431 -0.243 -0.065 -0.012 0.092 0.129 0.171 0.335   || dis=0.03 || select=7/8
[epoch=365/600] FLOP : 28.50 MB, ratio : 0.6982, Expected-ratio : 0.7000, Discrepancy : 0.128
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:55:21] [epoch=365/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.091 (3.091)  Prec@1 41.80 (41.80) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:55:27] [epoch=365/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.029 (2.298)  Prec@1 27.98 (37.98) Prec@5 80.95 (81.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.98 Prec@5 81.08 Error@1 62.02 Error@5 18.92 Loss:2.298
***[2020-01-29 08:55:27]*** VALID [epoch=365/600] loss = 2.298444, accuracy@1 = 37.98, accuracy@5 = 81.08 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:55:27]*** start epoch=366/600 Time Left: [02:04:17], LR=[0.033063 ~ 0.033063], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=366, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7200920953990364, FLOP=40.81
[Search] : epoch=366/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:55:28] [epoch=366/600][000/098] Time 0.62 (0.62) Data 0.35 (0.35) Base-Loss 0.651 (0.651)  Prec@1 78.91 (78.91) Prec@5 98.83 (98.83) Acls-loss 0.747 (0.747) FLOP-Loss 0.000 (0.000) Arch-Loss 0.747 (0.747)
**TRAIN** [2020-01-29 08:55:52] [epoch=366/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.686 (0.743)  Prec@1 76.19 (74.75) Prec@5 99.40 (98.12) Acls-loss 0.803 (0.805) FLOP-Loss 0.000 (0.089) Arch-Loss 0.803 (0.983)
 **TRAIN** Prec@1 74.75 Prec@5 98.12 Error@1 25.25 Error@5 1.88 Base-Loss:0.743, Arch-Loss=0.983
***[2020-01-29 08:55:52]*** TRAIN [epoch=366/600] base-loss = 0.742763, arch-loss = 0.982803, accuracy-1 = 74.75, accuracy-5 = 98.12
[epoch=366/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.198528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.398 0.207 0.395  ||  0.1980 -0.4558 0.1895  || discrepancy=0.00 || select=0/3
001/003-th : 0.310 0.136 0.553  ||  0.0120 -0.8115 0.5898  || discrepancy=0.24 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3360 -0.8980 2.7671  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.052 0.072 0.075 0.115 0.152 0.211 0.292  ||  -1.144 -0.642 -0.316 -0.272 0.151 0.428 0.760 1.083   || dis=0.08 || select=7/8
001/019-th : 0.099 0.125 0.128 0.135 0.135 0.128 0.128 0.123  ||  -0.222 0.015 0.039 0.092 0.090 0.037 0.036 0.002      || dis=0.00 || select=3/8
002/019-th : 0.114 0.122 0.128 0.134 0.125 0.131 0.127 0.119  ||  -0.096 -0.026 0.026 0.065 0.001 0.046 0.017 -0.051    || dis=0.00 || select=3/8
003/019-th : 0.090 0.106 0.122 0.123 0.128 0.134 0.145 0.151  ||  -0.315 -0.151 -0.008 -0.002 0.041 0.084 0.163 0.199   || dis=0.01 || select=7/8
004/019-th : 0.104 0.106 0.115 0.115 0.126 0.133 0.151 0.150  ||  -0.178 -0.163 -0.074 -0.078 0.017 0.066 0.195 0.190   || dis=0.00 || select=6/8
005/019-th : 0.103 0.117 0.121 0.121 0.126 0.132 0.135 0.144  ||  -0.189 -0.061 -0.026 -0.031 0.010 0.061 0.081 0.147   || dis=0.01 || select=7/8
006/019-th : 0.112 0.108 0.111 0.121 0.129 0.126 0.149 0.144  ||  -0.108 -0.145 -0.118 -0.029 0.036 0.015 0.178 0.147   || dis=0.01 || select=6/8
007/019-th : 0.032 0.046 0.071 0.084 0.125 0.150 0.193 0.298  ||  -1.115 -0.765 -0.323 -0.159 0.233 0.421 0.668 1.106   || dis=0.10 || select=7/8
008/019-th : 0.023 0.033 0.056 0.086 0.106 0.157 0.251 0.288  ||  -1.350 -0.982 -0.461 -0.041 0.167 0.563 1.031 1.168   || dis=0.04 || select=7/8
009/019-th : 0.070 0.077 0.097 0.117 0.121 0.138 0.167 0.213  ||  -0.514 -0.418 -0.193 -0.002 0.032 0.167 0.358 0.597   || dis=0.05 || select=7/8
010/019-th : 0.080 0.091 0.105 0.122 0.133 0.145 0.156 0.168  ||  -0.413 -0.294 -0.149 0.003 0.093 0.178 0.250 0.328    || dis=0.01 || select=7/8
011/019-th : 0.095 0.093 0.101 0.115 0.118 0.137 0.163 0.177  ||  -0.252 -0.268 -0.184 -0.055 -0.033 0.115 0.292 0.375  || dis=0.01 || select=7/8
012/019-th : 0.109 0.106 0.118 0.122 0.124 0.127 0.139 0.155  ||  -0.130 -0.159 -0.056 -0.021 -0.003 0.016 0.112 0.218  || dis=0.02 || select=7/8
013/019-th : 0.012 0.016 0.021 0.030 0.038 0.070 0.151 0.663  ||  -1.429 -1.143 -0.871 -0.496 -0.261 0.354 1.125 2.602  || dis=0.51 || select=7/8
014/019-th : 0.018 0.027 0.033 0.045 0.080 0.117 0.231 0.451  ||  -1.404 -0.969 -0.772 -0.472 0.108 0.491 1.172 1.844   || dis=0.22 || select=7/8
015/019-th : 0.010 0.014 0.019 0.026 0.036 0.065 0.171 0.658  ||  -1.572 -1.159 -0.873 -0.567 -0.233 0.348 1.316 2.663  || dis=0.49 || select=7/8
016/019-th : 0.051 0.062 0.084 0.111 0.136 0.164 0.187 0.205  ||  -0.795 -0.594 -0.296 -0.012 0.185 0.375 0.504 0.598   || dis=0.02 || select=7/8
017/019-th : 0.091 0.102 0.100 0.118 0.130 0.142 0.159 0.157  ||  -0.293 -0.175 -0.201 -0.030 0.068 0.154 0.263 0.253   || dis=0.00 || select=6/8
018/019-th : 0.079 0.096 0.113 0.123 0.134 0.140 0.144 0.170  ||  -0.431 -0.244 -0.077 0.007 0.094 0.138 0.163 0.331    || dis=0.03 || select=7/8
[epoch=366/600] FLOP : 28.20 MB, ratio : 0.6909, Expected-ratio : 0.7000, Discrepancy : 0.127
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:55:53] [epoch=366/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.165 (2.165)  Prec@1 27.34 (27.34) Prec@5 72.66 (72.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:55:59] [epoch=366/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.079 (2.302)  Prec@1 27.98 (37.09) Prec@5 71.43 (79.44) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.09 Prec@5 79.44 Error@1 62.91 Error@5 20.56 Loss:2.302
***[2020-01-29 08:55:59]*** VALID [epoch=366/600] loss = 2.302114, accuracy@1 = 37.09, accuracy@5 = 79.44 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:55:59]*** start epoch=367/600 Time Left: [02:03:45], LR=[0.032817 ~ 0.032817], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=367, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.7080337482652408, FLOP=40.81
[Search] : epoch=367/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:56:00] [epoch=367/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.706 (0.706)  Prec@1 78.12 (78.12) Prec@5 96.88 (96.88) Acls-loss 0.837 (0.837) FLOP-Loss 0.000 (0.000) Arch-Loss 0.837 (0.837)
**TRAIN** [2020-01-29 08:56:24] [epoch=367/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.805 (0.739)  Prec@1 75.60 (74.78) Prec@5 95.83 (98.19) Acls-loss 0.666 (0.781) FLOP-Loss 0.000 (0.089) Arch-Loss 0.666 (0.958)
 **TRAIN** Prec@1 74.78 Prec@5 98.19 Error@1 25.22 Error@5 1.81 Base-Loss:0.739, Arch-Loss=0.958
***[2020-01-29 08:56:24]*** TRAIN [epoch=367/600] base-loss = 0.738569, arch-loss = 0.958113, accuracy-1 = 74.78, accuracy-5 = 98.19
[epoch=367/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.496512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.399 0.208 0.393  ||  0.2007 -0.4501 0.1856  || discrepancy=0.01 || select=0/3
001/003-th : 0.309 0.134 0.557  ||  0.0082 -0.8236 0.5972  || discrepancy=0.25 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3209 -0.8870 2.7537  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.051 0.071 0.074 0.114 0.153 0.212 0.294  ||  -1.154 -0.660 -0.323 -0.276 0.148 0.444 0.772 1.100   || dis=0.08 || select=7/8
001/019-th : 0.100 0.125 0.128 0.135 0.134 0.128 0.127 0.123  ||  -0.214 0.011 0.041 0.089 0.085 0.038 0.029 -0.001     || dis=0.00 || select=3/8
002/019-th : 0.114 0.122 0.126 0.132 0.127 0.133 0.127 0.119  ||  -0.095 -0.022 0.007 0.054 0.014 0.060 0.016 -0.053    || dis=0.00 || select=5/8
003/019-th : 0.090 0.106 0.121 0.124 0.129 0.135 0.145 0.149  ||  -0.320 -0.148 -0.018 0.009 0.044 0.094 0.164 0.191    || dis=0.00 || select=7/8
004/019-th : 0.103 0.106 0.115 0.115 0.129 0.133 0.148 0.150  ||  -0.185 -0.157 -0.073 -0.073 0.039 0.067 0.177 0.189   || dis=0.00 || select=7/8
005/019-th : 0.104 0.118 0.122 0.121 0.125 0.132 0.134 0.144  ||  -0.184 -0.052 -0.019 -0.029 0.002 0.059 0.071 0.142   || dis=0.01 || select=7/8
006/019-th : 0.112 0.108 0.112 0.123 0.128 0.126 0.147 0.145  ||  -0.110 -0.147 -0.109 -0.008 0.028 0.009 0.169 0.150   || dis=0.00 || select=6/8
007/019-th : 0.032 0.046 0.072 0.084 0.126 0.149 0.190 0.301  ||  -1.120 -0.770 -0.311 -0.165 0.243 0.412 0.658 1.118   || dis=0.11 || select=7/8
008/019-th : 0.023 0.033 0.056 0.085 0.105 0.156 0.251 0.290  ||  -1.343 -0.984 -0.463 -0.048 0.165 0.554 1.031 1.177   || dis=0.04 || select=7/8
009/019-th : 0.071 0.075 0.096 0.117 0.121 0.141 0.166 0.213  ||  -0.501 -0.450 -0.194 -0.000 0.037 0.185 0.352 0.601   || dis=0.05 || select=7/8
010/019-th : 0.081 0.092 0.105 0.121 0.133 0.146 0.155 0.167  ||  -0.404 -0.281 -0.149 -0.001 0.089 0.182 0.244 0.318   || dis=0.01 || select=7/8
011/019-th : 0.095 0.094 0.101 0.115 0.119 0.137 0.161 0.177  ||  -0.250 -0.259 -0.184 -0.057 -0.024 0.120 0.276 0.372  || dis=0.02 || select=7/8
012/019-th : 0.109 0.105 0.118 0.122 0.125 0.127 0.140 0.153  ||  -0.130 -0.169 -0.051 -0.020 0.004 0.022 0.120 0.208   || dis=0.01 || select=7/8
013/019-th : 0.012 0.016 0.020 0.029 0.038 0.068 0.151 0.667  ||  -1.427 -1.137 -0.866 -0.506 -0.258 0.333 1.130 2.617  || dis=0.52 || select=7/8
014/019-th : 0.017 0.027 0.033 0.044 0.078 0.117 0.229 0.455  ||  -1.413 -0.977 -0.766 -0.480 0.098 0.503 1.176 1.861   || dis=0.23 || select=7/8
015/019-th : 0.009 0.014 0.019 0.025 0.036 0.064 0.173 0.659  ||  -1.578 -1.173 -0.873 -0.591 -0.238 0.351 1.340 2.677  || dis=0.49 || select=7/8
016/019-th : 0.051 0.062 0.084 0.112 0.136 0.163 0.185 0.207  ||  -0.793 -0.595 -0.292 -0.009 0.185 0.369 0.494 0.605   || dis=0.02 || select=7/8
017/019-th : 0.090 0.101 0.100 0.119 0.130 0.142 0.160 0.157  ||  -0.301 -0.185 -0.193 -0.023 0.067 0.150 0.273 0.253   || dis=0.00 || select=6/8
018/019-th : 0.080 0.097 0.114 0.125 0.137 0.139 0.141 0.168  ||  -0.426 -0.233 -0.071 0.019 0.111 0.125 0.146 0.318    || dis=0.03 || select=7/8
[epoch=367/600] FLOP : 28.50 MB, ratio : 0.6982, Expected-ratio : 0.7000, Discrepancy : 0.128
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:56:25] [epoch=367/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.014 (2.014)  Prec@1 46.88 (46.88) Prec@5 81.25 (81.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:56:31] [epoch=367/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.290 (2.499)  Prec@1 30.36 (36.41) Prec@5 81.55 (79.73) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.41 Prec@5 79.73 Error@1 63.59 Error@5 20.27 Loss:2.499
***[2020-01-29 08:56:31]*** VALID [epoch=367/600] loss = 2.498532, accuracy@1 = 36.41, accuracy@5 = 79.73 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:56:31]*** start epoch=368/600 Time Left: [02:03:13], LR=[0.032571 ~ 0.032571], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=368, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.6959984840615534, FLOP=40.81
[Search] : epoch=368/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:56:31] [epoch=368/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.853 (0.853)  Prec@1 69.14 (69.14) Prec@5 96.09 (96.09) Acls-loss 0.807 (0.807) FLOP-Loss 0.000 (0.000) Arch-Loss 0.807 (0.807)
**TRAIN** [2020-01-29 08:56:57] [epoch=368/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.738 (0.746)  Prec@1 77.38 (74.64) Prec@5 96.43 (97.99) Acls-loss 0.662 (0.764) FLOP-Loss 0.000 (0.089) Arch-Loss 0.662 (0.942)
 **TRAIN** Prec@1 74.64 Prec@5 97.99 Error@1 25.36 Error@5 2.01 Base-Loss:0.746, Arch-Loss=0.942
***[2020-01-29 08:56:57]*** TRAIN [epoch=368/600] base-loss = 0.746433, arch-loss = 0.941845, accuracy-1 = 74.64, accuracy-5 = 97.99
[epoch=368/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.496512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.398 0.207 0.395  ||  0.1969 -0.4539 0.1909  || discrepancy=0.00 || select=0/3
001/003-th : 0.306 0.136 0.558  ||  0.0011 -0.8134 0.6028  || discrepancy=0.25 || select=2/3
002/003-th : 0.006 0.025 0.968  ||  -2.3142 -0.8882 2.7523  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.049 0.071 0.075 0.114 0.152 0.210 0.300  ||  -1.167 -0.687 -0.322 -0.262 0.158 0.444 0.769 1.124   || dis=0.09 || select=7/8
001/019-th : 0.100 0.124 0.129 0.135 0.132 0.129 0.127 0.125  ||  -0.215 0.004 0.045 0.091 0.068 0.042 0.025 0.012      || dis=0.00 || select=3/8
002/019-th : 0.115 0.122 0.125 0.130 0.127 0.133 0.128 0.120  ||  -0.090 -0.024 -0.004 0.035 0.010 0.062 0.021 -0.042   || dis=0.00 || select=5/8
003/019-th : 0.089 0.106 0.121 0.124 0.131 0.137 0.143 0.149  ||  -0.329 -0.150 -0.018 0.010 0.062 0.105 0.151 0.193    || dis=0.01 || select=7/8
004/019-th : 0.103 0.106 0.114 0.116 0.130 0.134 0.148 0.149  ||  -0.187 -0.159 -0.084 -0.063 0.047 0.075 0.180 0.182   || dis=0.00 || select=7/8
005/019-th : 0.104 0.118 0.122 0.123 0.126 0.133 0.134 0.142  ||  -0.181 -0.058 -0.019 -0.015 0.008 0.063 0.070 0.129   || dis=0.01 || select=7/8
006/019-th : 0.112 0.108 0.112 0.122 0.127 0.126 0.147 0.146  ||  -0.105 -0.145 -0.107 -0.022 0.020 0.013 0.165 0.158   || dis=0.00 || select=6/8
007/019-th : 0.033 0.045 0.072 0.081 0.125 0.150 0.187 0.308  ||  -1.106 -0.775 -0.315 -0.189 0.240 0.420 0.644 1.142   || dis=0.12 || select=7/8
008/019-th : 0.023 0.034 0.055 0.084 0.104 0.153 0.256 0.290  ||  -1.336 -0.976 -0.480 -0.057 0.152 0.536 1.055 1.179   || dis=0.03 || select=7/8
009/019-th : 0.072 0.075 0.095 0.116 0.121 0.141 0.164 0.215  ||  -0.491 -0.440 -0.208 -0.008 0.032 0.189 0.340 0.609   || dis=0.05 || select=7/8
010/019-th : 0.081 0.091 0.105 0.123 0.132 0.144 0.155 0.169  ||  -0.401 -0.290 -0.151 0.014 0.081 0.168 0.244 0.328    || dis=0.01 || select=7/8
011/019-th : 0.094 0.093 0.102 0.114 0.120 0.140 0.160 0.176  ||  -0.262 -0.266 -0.178 -0.063 -0.014 0.142 0.269 0.368  || dis=0.02 || select=7/8
012/019-th : 0.109 0.105 0.118 0.122 0.123 0.129 0.139 0.156  ||  -0.128 -0.173 -0.057 -0.018 -0.013 0.033 0.108 0.225  || dis=0.02 || select=7/8
013/019-th : 0.012 0.016 0.020 0.029 0.038 0.068 0.148 0.670  ||  -1.421 -1.139 -0.887 -0.507 -0.246 0.343 1.114 2.626  || dis=0.52 || select=7/8
014/019-th : 0.017 0.027 0.033 0.043 0.078 0.116 0.226 0.461  ||  -1.435 -0.968 -0.768 -0.480 0.107 0.498 1.168 1.881   || dis=0.24 || select=7/8
015/019-th : 0.009 0.014 0.019 0.025 0.035 0.064 0.171 0.663  ||  -1.573 -1.181 -0.862 -0.590 -0.259 0.353 1.337 2.689  || dis=0.49 || select=7/8
016/019-th : 0.051 0.062 0.084 0.111 0.135 0.161 0.187 0.209  ||  -0.792 -0.603 -0.293 -0.014 0.178 0.360 0.507 0.616   || dis=0.02 || select=7/8
017/019-th : 0.089 0.101 0.100 0.120 0.130 0.141 0.161 0.157  ||  -0.313 -0.190 -0.196 -0.014 0.068 0.150 0.283 0.258   || dis=0.00 || select=6/8
018/019-th : 0.080 0.097 0.114 0.125 0.138 0.137 0.143 0.167  ||  -0.428 -0.232 -0.072 0.022 0.121 0.117 0.154 0.313    || dis=0.02 || select=7/8
[epoch=368/600] FLOP : 28.50 MB, ratio : 0.6982, Expected-ratio : 0.7000, Discrepancy : 0.130
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:56:57] [epoch=368/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 4.441 (4.441)  Prec@1 44.92 (44.92) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:57:03] [epoch=368/600][097/098] Time 0.15 (0.07) Data 0.00 (0.00) Loss 1.502 (2.254)  Prec@1 55.36 (37.15) Prec@5 95.24 (81.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.15 Prec@5 81.40 Error@1 62.85 Error@5 18.60 Loss:2.254
***[2020-01-29 08:57:03]*** VALID [epoch=368/600] loss = 2.253521, accuracy@1 = 37.15, accuracy@5 = 81.40 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:57:03]*** start epoch=369/600 Time Left: [02:02:42], LR=[0.032326 ~ 0.032326], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=369, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.6839866327408206, FLOP=40.81
[Search] : epoch=369/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:57:04] [epoch=369/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.631 (0.631)  Prec@1 75.39 (75.39) Prec@5 98.83 (98.83) Acls-loss 0.744 (0.744) FLOP-Loss 0.000 (0.000) Arch-Loss 0.744 (0.744)
**TRAIN** [2020-01-29 08:57:28] [epoch=369/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.721 (0.769)  Prec@1 74.40 (73.81) Prec@5 98.81 (97.96) Acls-loss 0.830 (0.837) FLOP-Loss 0.000 (0.089) Arch-Loss 0.830 (1.014)
 **TRAIN** Prec@1 73.81 Prec@5 97.96 Error@1 26.19 Error@5 2.04 Base-Loss:0.769, Arch-Loss=1.014
***[2020-01-29 08:57:28]*** TRAIN [epoch=369/600] base-loss = 0.769500, arch-loss = 1.014372, accuracy-1 = 73.81, accuracy-5 = 97.96
[epoch=369/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 12, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.496512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.397 0.209 0.394  ||  0.1978 -0.4448 0.1879  || discrepancy=0.00 || select=0/3
001/003-th : 0.301 0.138 0.560  ||  -0.0107 -0.7891 0.6096  || discrepancy=0.26 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3208 -0.8858 2.7603  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.048 0.071 0.074 0.115 0.151 0.208 0.303  ||  -1.168 -0.696 -0.319 -0.275 0.172 0.440 0.764 1.137   || dis=0.10 || select=7/8
001/019-th : 0.100 0.124 0.130 0.134 0.130 0.128 0.128 0.126  ||  -0.210 0.004 0.046 0.078 0.049 0.038 0.035 0.015      || dis=0.00 || select=3/8
002/019-th : 0.114 0.124 0.126 0.129 0.126 0.133 0.128 0.121  ||  -0.097 -0.014 0.007 0.029 0.002 0.060 0.020 -0.039    || dis=0.00 || select=5/8
003/019-th : 0.089 0.107 0.119 0.126 0.131 0.135 0.142 0.151  ||  -0.322 -0.144 -0.033 0.019 0.064 0.090 0.144 0.202    || dis=0.01 || select=7/8
004/019-th : 0.103 0.106 0.114 0.119 0.129 0.135 0.147 0.149  ||  -0.190 -0.161 -0.085 -0.042 0.037 0.083 0.167 0.183   || dis=0.00 || select=7/8
005/019-th : 0.104 0.117 0.122 0.125 0.124 0.134 0.131 0.142  ||  -0.183 -0.062 -0.020 0.004 -0.001 0.076 0.052 0.133   || dis=0.01 || select=7/8
006/019-th : 0.113 0.107 0.111 0.122 0.127 0.128 0.149 0.144  ||  -0.097 -0.153 -0.111 -0.021 0.016 0.025 0.177 0.145   || dis=0.01 || select=6/8
007/019-th : 0.033 0.044 0.072 0.082 0.125 0.148 0.187 0.309  ||  -1.099 -0.793 -0.307 -0.181 0.241 0.409 0.640 1.144   || dis=0.12 || select=7/8
008/019-th : 0.022 0.034 0.055 0.084 0.104 0.152 0.259 0.290  ||  -1.379 -0.956 -0.472 -0.059 0.161 0.538 1.073 1.185   || dis=0.03 || select=7/8
009/019-th : 0.071 0.076 0.096 0.115 0.121 0.143 0.163 0.215  ||  -0.500 -0.427 -0.202 -0.014 0.029 0.196 0.331 0.608   || dis=0.05 || select=7/8
010/019-th : 0.080 0.091 0.105 0.124 0.133 0.146 0.155 0.166  ||  -0.411 -0.290 -0.147 0.024 0.090 0.183 0.244 0.310    || dis=0.01 || select=7/8
011/019-th : 0.095 0.094 0.102 0.116 0.119 0.140 0.160 0.174  ||  -0.251 -0.260 -0.182 -0.053 -0.023 0.141 0.274 0.354  || dis=0.01 || select=7/8
012/019-th : 0.109 0.106 0.116 0.123 0.122 0.129 0.141 0.155  ||  -0.133 -0.162 -0.068 -0.009 -0.024 0.032 0.124 0.218  || dis=0.01 || select=7/8
013/019-th : 0.011 0.015 0.020 0.030 0.038 0.067 0.146 0.672  ||  -1.437 -1.137 -0.891 -0.481 -0.249 0.336 1.110 2.635  || dis=0.53 || select=7/8
014/019-th : 0.016 0.026 0.032 0.043 0.078 0.116 0.228 0.461  ||  -1.475 -0.977 -0.787 -0.474 0.123 0.519 1.191 1.895   || dis=0.23 || select=7/8
015/019-th : 0.009 0.014 0.019 0.024 0.034 0.064 0.170 0.667  ||  -1.569 -1.188 -0.869 -0.601 -0.273 0.357 1.342 2.708  || dis=0.50 || select=7/8
016/019-th : 0.050 0.063 0.085 0.111 0.133 0.165 0.187 0.207  ||  -0.809 -0.584 -0.284 -0.015 0.167 0.379 0.504 0.606   || dis=0.02 || select=7/8
017/019-th : 0.088 0.100 0.101 0.119 0.132 0.142 0.160 0.158  ||  -0.326 -0.192 -0.189 -0.023 0.084 0.159 0.274 0.264   || dis=0.00 || select=6/8
018/019-th : 0.080 0.095 0.112 0.128 0.137 0.137 0.144 0.167  ||  -0.426 -0.247 -0.090 0.045 0.115 0.116 0.165 0.315    || dis=0.02 || select=7/8
[epoch=369/600] FLOP : 28.50 MB, ratio : 0.6982, Expected-ratio : 0.7000, Discrepancy : 0.131
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:57:29] [epoch=369/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.639 (2.639)  Prec@1 24.61 (24.61) Prec@5 61.33 (61.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:57:35] [epoch=369/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.069 (2.525)  Prec@1 28.57 (34.28) Prec@5 73.81 (79.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.28 Prec@5 79.66 Error@1 65.72 Error@5 20.34 Loss:2.525
***[2020-01-29 08:57:35]*** VALID [epoch=369/600] loss = 2.524665, accuracy@1 = 34.28, accuracy@5 = 79.66 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:57:35]*** start epoch=370/600 Time Left: [02:02:10], LR=[0.032082 ~ 0.032082], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=370, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.6719985236140145, FLOP=40.81
[Search] : epoch=370/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:57:36] [epoch=370/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.685 (0.685)  Prec@1 77.73 (77.73) Prec@5 98.05 (98.05) Acls-loss 0.775 (0.775) FLOP-Loss 0.000 (0.000) Arch-Loss 0.775 (0.775)
**TRAIN** [2020-01-29 08:58:00] [epoch=370/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.595 (0.758)  Prec@1 76.19 (73.87) Prec@5 99.40 (98.07) Acls-loss 1.189 (0.816) FLOP-Loss 0.000 (0.296) Arch-Loss 1.189 (1.407)
 **TRAIN** Prec@1 73.87 Prec@5 98.07 Error@1 26.13 Error@5 1.93 Base-Loss:0.758, Arch-Loss=1.407
***[2020-01-29 08:58:00]*** TRAIN [epoch=370/600] base-loss = 0.757962, arch-loss = 1.406827, accuracy-1 = 73.87, accuracy-5 = 98.07
[epoch=370/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 9, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 57, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.198528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.408 0.208 0.384  ||  0.2243 -0.4487 0.1622  || discrepancy=0.02 || select=0/3
001/003-th : 0.313 0.141 0.546  ||  0.0206 -0.7756 0.5773  || discrepancy=0.23 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3328 -0.8751 2.7696  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.049 0.071 0.074 0.115 0.151 0.208 0.301  ||  -1.152 -0.685 -0.317 -0.276 0.164 0.437 0.753 1.125   || dis=0.09 || select=7/8
001/019-th : 0.102 0.129 0.134 0.134 0.129 0.126 0.124 0.122  ||  -0.191 0.044 0.075 0.082 0.038 0.015 -0.000 -0.014    || dis=0.00 || select=3/8
002/019-th : 0.117 0.127 0.130 0.132 0.124 0.130 0.124 0.117  ||  -0.071 0.018 0.034 0.049 -0.008 0.034 -0.008 -0.071   || dis=0.00 || select=3/8
003/019-th : 0.093 0.110 0.124 0.127 0.131 0.131 0.138 0.147  ||  -0.283 -0.118 -0.002 0.025 0.055 0.057 0.107 0.169    || dis=0.01 || select=7/8
004/019-th : 0.105 0.107 0.116 0.120 0.129 0.132 0.144 0.148  ||  -0.172 -0.150 -0.072 -0.030 0.038 0.063 0.149 0.173   || dis=0.00 || select=7/8
005/019-th : 0.108 0.120 0.125 0.125 0.125 0.133 0.127 0.138  ||  -0.147 -0.040 -0.002 0.003 0.001 0.064 0.016 0.097    || dis=0.01 || select=7/8
006/019-th : 0.117 0.109 0.113 0.123 0.126 0.126 0.145 0.141  ||  -0.062 -0.134 -0.097 -0.013 0.014 0.009 0.150 0.123   || dis=0.00 || select=6/8
007/019-th : 0.033 0.044 0.073 0.082 0.125 0.148 0.186 0.310  ||  -1.098 -0.796 -0.299 -0.185 0.242 0.408 0.635 1.147   || dis=0.12 || select=7/8
008/019-th : 0.022 0.034 0.055 0.082 0.106 0.154 0.257 0.289  ||  -1.379 -0.967 -0.475 -0.074 0.183 0.556 1.067 1.184   || dis=0.03 || select=7/8
009/019-th : 0.072 0.078 0.096 0.116 0.123 0.143 0.161 0.210  ||  -0.485 -0.412 -0.207 -0.014 0.046 0.198 0.316 0.580   || dis=0.05 || select=7/8
010/019-th : 0.082 0.093 0.105 0.124 0.133 0.145 0.154 0.164  ||  -0.391 -0.272 -0.145 0.020 0.086 0.173 0.236 0.296    || dis=0.01 || select=7/8
011/019-th : 0.096 0.096 0.103 0.118 0.120 0.140 0.158 0.171  ||  -0.246 -0.243 -0.176 -0.039 -0.018 0.136 0.256 0.334  || dis=0.01 || select=7/8
012/019-th : 0.111 0.109 0.118 0.124 0.122 0.128 0.138 0.150  ||  -0.111 -0.134 -0.055 -0.001 -0.018 0.028 0.105 0.184  || dis=0.01 || select=7/8
013/019-th : 0.012 0.016 0.020 0.030 0.039 0.069 0.148 0.667  ||  -1.424 -1.131 -0.897 -0.493 -0.231 0.342 1.109 2.612  || dis=0.52 || select=7/8
014/019-th : 0.015 0.026 0.031 0.043 0.079 0.114 0.235 0.457  ||  -1.515 -0.972 -0.796 -0.458 0.136 0.508 1.230 1.895   || dis=0.22 || select=7/8
015/019-th : 0.009 0.014 0.019 0.024 0.035 0.063 0.170 0.667  ||  -1.555 -1.185 -0.872 -0.617 -0.252 0.345 1.341 2.706  || dis=0.50 || select=7/8
016/019-th : 0.051 0.063 0.086 0.113 0.134 0.162 0.184 0.205  ||  -0.794 -0.582 -0.273 0.002 0.171 0.362 0.489 0.595    || dis=0.02 || select=7/8
017/019-th : 0.091 0.103 0.101 0.119 0.132 0.142 0.156 0.156  ||  -0.296 -0.174 -0.187 -0.023 0.081 0.150 0.248 0.246   || dis=0.00 || select=6/8
018/019-th : 0.082 0.095 0.114 0.128 0.136 0.136 0.145 0.165  ||  -0.402 -0.250 -0.074 0.044 0.109 0.104 0.167 0.301    || dis=0.02 || select=7/8
[epoch=370/600] FLOP : 28.20 MB, ratio : 0.6909, Expected-ratio : 0.7000, Discrepancy : 0.129
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:58:01] [epoch=370/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.629 (1.629)  Prec@1 53.12 (53.12) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:58:07] [epoch=370/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.184 (2.433)  Prec@1 26.79 (36.47) Prec@5 72.02 (80.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.47 Prec@5 80.80 Error@1 63.53 Error@5 19.20 Loss:2.433
***[2020-01-29 08:58:07]*** VALID [epoch=370/600] loss = 2.432700, accuracy@1 = 36.47, accuracy@5 = 80.80 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:58:07]*** start epoch=371/600 Time Left: [02:01:38], LR=[0.031837 ~ 0.031837], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=371, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.6600344853412035, FLOP=40.81
[Search] : epoch=371/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:58:08] [epoch=371/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.659 (0.659)  Prec@1 77.73 (77.73) Prec@5 98.44 (98.44) Acls-loss 0.850 (0.850) FLOP-Loss 0.000 (0.000) Arch-Loss 0.850 (0.850)
**TRAIN** [2020-01-29 08:58:32] [epoch=371/600][097/098] Time 0.31 (0.26) Data 0.00 (0.00) Base-Loss 0.580 (0.743)  Prec@1 80.36 (74.87) Prec@5 99.40 (98.06) Acls-loss 0.742 (0.785) FLOP-Loss 0.000 (0.177) Arch-Loss 0.742 (1.138)
 **TRAIN** Prec@1 74.87 Prec@5 98.06 Error@1 25.13 Error@5 1.94 Base-Loss:0.743, Arch-Loss=1.138
***[2020-01-29 08:58:32]*** TRAIN [epoch=371/600] base-loss = 0.743434, arch-loss = 1.138280, accuracy-1 = 74.87, accuracy-5 = 98.06
[epoch=371/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.557952)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.413 0.207 0.380  ||  0.2356 -0.4528 0.1518  || discrepancy=0.03 || select=0/3
001/003-th : 0.319 0.142 0.539  ||  0.0369 -0.7715 0.5615  || discrepancy=0.22 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3349 -0.8975 2.7833  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.049 0.071 0.074 0.114 0.151 0.205 0.305  ||  -1.155 -0.683 -0.318 -0.272 0.153 0.434 0.743 1.140   || dis=0.10 || select=7/8
001/019-th : 0.104 0.130 0.135 0.133 0.129 0.125 0.122 0.121  ||  -0.172 0.044 0.082 0.072 0.041 0.004 -0.014 -0.021    || dis=0.00 || select=2/8
002/019-th : 0.118 0.127 0.132 0.130 0.126 0.128 0.123 0.115  ||  -0.056 0.015 0.050 0.040 0.005 0.026 -0.018 -0.083    || dis=0.00 || select=2/8
003/019-th : 0.093 0.111 0.125 0.127 0.130 0.131 0.137 0.148  ||  -0.289 -0.113 0.008 0.026 0.046 0.053 0.101 0.175     || dis=0.01 || select=7/8
004/019-th : 0.107 0.107 0.116 0.121 0.129 0.131 0.144 0.146  ||  -0.150 -0.149 -0.068 -0.025 0.035 0.053 0.145 0.162   || dis=0.00 || select=7/8
005/019-th : 0.109 0.121 0.125 0.125 0.126 0.131 0.126 0.137  ||  -0.137 -0.036 0.002 0.003 0.006 0.051 0.010 0.090     || dis=0.01 || select=7/8
006/019-th : 0.118 0.111 0.115 0.120 0.128 0.126 0.141 0.142  ||  -0.059 -0.118 -0.080 -0.039 0.028 0.009 0.124 0.129   || dis=0.00 || select=7/8
007/019-th : 0.033 0.044 0.074 0.081 0.126 0.148 0.186 0.308  ||  -1.092 -0.804 -0.291 -0.191 0.248 0.410 0.636 1.141   || dis=0.12 || select=7/8
008/019-th : 0.022 0.033 0.055 0.082 0.106 0.155 0.257 0.290  ||  -1.374 -0.979 -0.473 -0.080 0.181 0.560 1.067 1.189   || dis=0.03 || select=7/8
009/019-th : 0.073 0.079 0.096 0.116 0.124 0.143 0.162 0.207  ||  -0.480 -0.403 -0.209 -0.015 0.048 0.197 0.321 0.566   || dis=0.04 || select=7/8
010/019-th : 0.083 0.093 0.105 0.124 0.133 0.145 0.156 0.162  ||  -0.388 -0.268 -0.150 0.014 0.085 0.176 0.246 0.287    || dis=0.01 || select=7/8
011/019-th : 0.094 0.096 0.103 0.117 0.120 0.141 0.158 0.171  ||  -0.258 -0.236 -0.172 -0.045 -0.018 0.142 0.260 0.336  || dis=0.01 || select=7/8
012/019-th : 0.113 0.110 0.119 0.126 0.122 0.127 0.136 0.147  ||  -0.096 -0.123 -0.044 0.009 -0.020 0.021 0.092 0.166   || dis=0.01 || select=7/8
013/019-th : 0.012 0.016 0.020 0.029 0.038 0.068 0.148 0.669  ||  -1.409 -1.131 -0.909 -0.502 -0.238 0.338 1.117 2.622  || dis=0.52 || select=7/8
014/019-th : 0.015 0.026 0.031 0.041 0.078 0.113 0.235 0.462  ||  -1.533 -0.966 -0.790 -0.496 0.147 0.509 1.242 1.919   || dis=0.23 || select=7/8
015/019-th : 0.009 0.014 0.018 0.024 0.034 0.062 0.169 0.670  ||  -1.544 -1.182 -0.872 -0.621 -0.266 0.338 1.340 2.718  || dis=0.50 || select=7/8
016/019-th : 0.050 0.063 0.086 0.115 0.136 0.161 0.185 0.203  ||  -0.814 -0.581 -0.268 0.018 0.182 0.357 0.494 0.588    || dis=0.02 || select=7/8
017/019-th : 0.093 0.103 0.102 0.121 0.133 0.141 0.153 0.155  ||  -0.278 -0.171 -0.185 -0.014 0.083 0.143 0.222 0.240   || dis=0.00 || select=7/8
018/019-th : 0.081 0.096 0.115 0.128 0.135 0.135 0.144 0.165  ||  -0.410 -0.237 -0.066 0.048 0.102 0.099 0.164 0.299    || dis=0.02 || select=7/8
[epoch=371/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.129
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:58:32] [epoch=371/600][000/098] Time 0.35 (0.35) Data 0.28 (0.28) Loss 2.106 (2.106)  Prec@1 41.41 (41.41) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:58:38] [epoch=371/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.790 (2.318)  Prec@1 27.38 (38.77) Prec@5 73.81 (82.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.77 Prec@5 82.52 Error@1 61.23 Error@5 17.48 Loss:2.318
***[2020-01-29 08:58:38]*** VALID [epoch=371/600] loss = 2.318024, accuracy@1 = 38.77, accuracy@5 = 82.52 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:58:39]*** start epoch=372/600 Time Left: [02:01:06], LR=[0.031594 ~ 0.031594], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=372, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.6480948459225393, FLOP=40.81
[Search] : epoch=372/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:58:39] [epoch=372/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.609 (0.609)  Prec@1 79.69 (79.69) Prec@5 99.22 (99.22) Acls-loss 0.633 (0.633) FLOP-Loss 0.000 (0.000) Arch-Loss 0.633 (0.633)
**TRAIN** [2020-01-29 08:59:04] [epoch=372/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.628 (0.746)  Prec@1 81.55 (74.61) Prec@5 98.21 (98.08) Acls-loss 0.962 (0.806) FLOP-Loss 0.000 (0.147) Arch-Loss 0.962 (1.100)
 **TRAIN** Prec@1 74.61 Prec@5 98.08 Error@1 25.39 Error@5 1.92 Base-Loss:0.746, Arch-Loss=1.100
***[2020-01-29 08:59:04]*** TRAIN [epoch=372/600] base-loss = 0.746353, arch-loss = 1.100443, accuracy-1 = 74.61, accuracy-5 = 98.08
[epoch=372/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.414 0.208 0.378  ||  0.2387 -0.4470 0.1477  || discrepancy=0.04 || select=0/3
001/003-th : 0.319 0.144 0.537  ||  0.0378 -0.7541 0.5578  || discrepancy=0.22 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3327 -0.8863 2.7802  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.049 0.072 0.074 0.116 0.153 0.205 0.301  ||  -1.157 -0.695 -0.310 -0.274 0.169 0.448 0.741 1.126   || dis=0.10 || select=7/8
001/019-th : 0.106 0.130 0.136 0.133 0.129 0.124 0.121 0.121  ||  -0.155 0.047 0.092 0.067 0.035 -0.002 -0.028 -0.029   || dis=0.00 || select=2/8
002/019-th : 0.119 0.126 0.130 0.130 0.127 0.130 0.122 0.115  ||  -0.050 0.010 0.041 0.039 0.015 0.039 -0.025 -0.085    || dis=0.00 || select=2/8
003/019-th : 0.094 0.111 0.125 0.129 0.128 0.129 0.138 0.147  ||  -0.280 -0.114 0.007 0.039 0.028 0.040 0.106 0.174     || dis=0.01 || select=7/8
004/019-th : 0.108 0.108 0.114 0.119 0.128 0.132 0.144 0.148  ||  -0.143 -0.142 -0.083 -0.045 0.028 0.056 0.146 0.173   || dis=0.00 || select=7/8
005/019-th : 0.110 0.119 0.125 0.125 0.128 0.130 0.126 0.137  ||  -0.128 -0.045 0.003 -0.003 0.026 0.038 0.007 0.089    || dis=0.01 || select=7/8
006/019-th : 0.118 0.112 0.114 0.120 0.129 0.124 0.143 0.140  ||  -0.052 -0.110 -0.090 -0.042 0.036 -0.005 0.137 0.116  || dis=0.00 || select=6/8
007/019-th : 0.033 0.043 0.072 0.083 0.127 0.148 0.188 0.306  ||  -1.094 -0.829 -0.303 -0.173 0.258 0.413 0.649 1.138   || dis=0.12 || select=7/8
008/019-th : 0.022 0.033 0.055 0.082 0.107 0.154 0.256 0.292  ||  -1.370 -0.984 -0.481 -0.081 0.190 0.558 1.062 1.195   || dis=0.04 || select=7/8
009/019-th : 0.072 0.080 0.097 0.117 0.125 0.143 0.163 0.204  ||  -0.496 -0.390 -0.200 -0.003 0.056 0.193 0.324 0.548   || dis=0.04 || select=7/8
010/019-th : 0.082 0.093 0.104 0.123 0.130 0.147 0.156 0.163  ||  -0.390 -0.270 -0.155 0.010 0.069 0.189 0.249 0.294    || dis=0.01 || select=7/8
011/019-th : 0.094 0.097 0.105 0.119 0.120 0.140 0.156 0.169  ||  -0.265 -0.234 -0.156 -0.026 -0.017 0.138 0.247 0.326  || dis=0.01 || select=7/8
012/019-th : 0.114 0.111 0.119 0.125 0.121 0.128 0.137 0.145  ||  -0.084 -0.116 -0.043 0.006 -0.029 0.031 0.093 0.151   || dis=0.01 || select=7/8
013/019-th : 0.012 0.015 0.019 0.029 0.038 0.066 0.146 0.676  ||  -1.404 -1.145 -0.909 -0.516 -0.227 0.319 1.115 2.650  || dis=0.53 || select=7/8
014/019-th : 0.014 0.026 0.030 0.042 0.080 0.112 0.237 0.461  ||  -1.567 -0.968 -0.811 -0.478 0.170 0.512 1.259 1.925   || dis=0.22 || select=7/8
015/019-th : 0.010 0.014 0.018 0.024 0.033 0.061 0.166 0.675  ||  -1.524 -1.177 -0.885 -0.614 -0.282 0.329 1.334 2.733  || dis=0.51 || select=7/8
016/019-th : 0.050 0.063 0.086 0.115 0.135 0.165 0.182 0.205  ||  -0.817 -0.586 -0.271 0.019 0.179 0.379 0.481 0.595    || dis=0.02 || select=7/8
017/019-th : 0.092 0.102 0.103 0.123 0.134 0.139 0.152 0.155  ||  -0.281 -0.181 -0.168 0.009 0.088 0.127 0.216 0.235    || dis=0.00 || select=7/8
018/019-th : 0.082 0.095 0.116 0.129 0.135 0.137 0.143 0.164  ||  -0.404 -0.250 -0.053 0.057 0.097 0.111 0.154 0.292    || dis=0.02 || select=7/8
[epoch=372/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.130
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:59:04] [epoch=372/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.608 (2.608)  Prec@1 47.66 (47.66) Prec@5 85.16 (85.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:59:10] [epoch=372/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.990 (2.274)  Prec@1 28.57 (37.58) Prec@5 82.14 (79.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.58 Prec@5 79.80 Error@1 62.42 Error@5 20.20 Loss:2.274
***[2020-01-29 08:59:10]*** VALID [epoch=372/600] loss = 2.274052, accuracy@1 = 37.58, accuracy@5 = 79.80 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:59:10]*** start epoch=373/600 Time Left: [02:00:34], LR=[0.031351 ~ 0.031351], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=373, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.636179932689268, FLOP=40.81
[Search] : epoch=373/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:59:11] [epoch=373/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.820 (0.820)  Prec@1 76.17 (76.17) Prec@5 97.66 (97.66) Acls-loss 0.678 (0.678) FLOP-Loss 0.000 (0.000) Arch-Loss 0.678 (0.678)
**TRAIN** [2020-01-29 08:59:35] [epoch=373/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.167 (0.734)  Prec@1 57.14 (74.64) Prec@5 97.02 (98.20) Acls-loss 0.818 (0.810) FLOP-Loss 0.000 (0.088) Arch-Loss 0.818 (0.986)
 **TRAIN** Prec@1 74.64 Prec@5 98.20 Error@1 25.36 Error@5 1.80 Base-Loss:0.734, Arch-Loss=0.986
***[2020-01-29 08:59:35]*** TRAIN [epoch=373/600] base-loss = 0.733990, arch-loss = 0.986350, accuracy-1 = 74.64, accuracy-5 = 98.20
[epoch=373/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.410 0.210 0.380  ||  0.2312 -0.4395 0.1541  || discrepancy=0.03 || select=0/3
001/003-th : 0.317 0.146 0.536  ||  0.0338 -0.7393 0.5592  || discrepancy=0.22 || select=2/3
002/003-th : 0.006 0.025 0.969  ||  -2.3279 -0.8706 2.7729  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.049 0.072 0.073 0.114 0.153 0.205 0.303  ||  -1.161 -0.684 -0.308 -0.284 0.155 0.451 0.745 1.133   || dis=0.10 || select=7/8
001/019-th : 0.107 0.129 0.135 0.133 0.128 0.124 0.121 0.122  ||  -0.148 0.038 0.083 0.070 0.030 -0.006 -0.027 -0.022   || dis=0.00 || select=2/8
002/019-th : 0.120 0.125 0.129 0.130 0.128 0.130 0.123 0.115  ||  -0.044 0.002 0.030 0.041 0.019 0.036 -0.017 -0.085    || dis=0.00 || select=3/8
003/019-th : 0.095 0.109 0.125 0.128 0.128 0.128 0.139 0.148  ||  -0.266 -0.131 0.003 0.031 0.028 0.032 0.114 0.178     || dis=0.01 || select=7/8
004/019-th : 0.107 0.109 0.113 0.119 0.128 0.131 0.144 0.148  ||  -0.149 -0.135 -0.092 -0.044 0.032 0.050 0.149 0.177   || dis=0.00 || select=7/8
005/019-th : 0.109 0.119 0.125 0.126 0.127 0.131 0.126 0.137  ||  -0.135 -0.046 -0.000 0.013 0.019 0.046 0.005 0.093    || dis=0.01 || select=7/8
006/019-th : 0.117 0.110 0.114 0.119 0.129 0.127 0.142 0.141  ||  -0.059 -0.122 -0.087 -0.045 0.033 0.022 0.132 0.122   || dis=0.00 || select=6/8
007/019-th : 0.031 0.042 0.072 0.081 0.128 0.151 0.188 0.308  ||  -1.138 -0.841 -0.298 -0.178 0.275 0.442 0.663 1.155   || dis=0.12 || select=7/8
008/019-th : 0.022 0.032 0.055 0.080 0.107 0.156 0.253 0.295  ||  -1.372 -0.999 -0.474 -0.094 0.193 0.576 1.056 1.212   || dis=0.04 || select=7/8
009/019-th : 0.071 0.080 0.097 0.115 0.126 0.146 0.162 0.202  ||  -0.504 -0.389 -0.192 -0.024 0.068 0.216 0.322 0.539   || dis=0.04 || select=7/8
010/019-th : 0.080 0.092 0.104 0.124 0.132 0.145 0.160 0.163  ||  -0.412 -0.276 -0.160 0.022 0.081 0.179 0.277 0.291    || dis=0.00 || select=7/8
011/019-th : 0.094 0.097 0.104 0.119 0.118 0.139 0.158 0.170  ||  -0.261 -0.227 -0.161 -0.025 -0.036 0.132 0.256 0.329  || dis=0.01 || select=7/8
012/019-th : 0.115 0.110 0.117 0.125 0.121 0.130 0.138 0.145  ||  -0.080 -0.120 -0.066 0.002 -0.030 0.042 0.106 0.149   || dis=0.01 || select=7/8
013/019-th : 0.012 0.015 0.019 0.028 0.038 0.065 0.144 0.678  ||  -1.392 -1.152 -0.909 -0.529 -0.221 0.320 1.111 2.657  || dis=0.53 || select=7/8
014/019-th : 0.014 0.025 0.029 0.041 0.079 0.112 0.234 0.465  ||  -1.579 -0.964 -0.818 -0.478 0.165 0.523 1.256 1.943   || dis=0.23 || select=7/8
015/019-th : 0.010 0.013 0.018 0.024 0.032 0.059 0.162 0.682  ||  -1.517 -1.168 -0.888 -0.612 -0.292 0.316 1.319 2.755  || dis=0.52 || select=7/8
016/019-th : 0.050 0.062 0.087 0.115 0.137 0.164 0.183 0.202  ||  -0.812 -0.600 -0.264 0.018 0.192 0.378 0.486 0.586    || dis=0.02 || select=7/8
017/019-th : 0.092 0.102 0.104 0.122 0.133 0.140 0.152 0.154  ||  -0.283 -0.184 -0.157 0.001 0.086 0.135 0.217 0.231    || dis=0.00 || select=7/8
018/019-th : 0.082 0.096 0.118 0.130 0.133 0.137 0.143 0.161  ||  -0.403 -0.239 -0.037 0.062 0.083 0.116 0.158 0.276    || dis=0.02 || select=7/8
[epoch=373/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.130
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 08:59:36] [epoch=373/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.018 (1.018)  Prec@1 68.36 (68.36) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 08:59:42] [epoch=373/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.108 (2.589)  Prec@1 29.17 (34.48) Prec@5 69.64 (77.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.48 Prec@5 77.94 Error@1 65.52 Error@5 22.06 Loss:2.589
***[2020-01-29 08:59:42]*** VALID [epoch=373/600] loss = 2.588781, accuracy@1 = 34.48, accuracy@5 = 77.94 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 08:59:42]*** start epoch=374/600 Time Left: [02:00:02], LR=[0.031108 ~ 0.031108], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=374, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.624290072294756, FLOP=40.81
[Search] : epoch=374/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 08:59:43] [epoch=374/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.693 (0.693)  Prec@1 75.39 (75.39) Prec@5 97.66 (97.66) Acls-loss 0.674 (0.674) FLOP-Loss 0.000 (0.000) Arch-Loss 0.674 (0.674)
**TRAIN** [2020-01-29 09:00:07] [epoch=374/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.722 (0.729)  Prec@1 77.38 (75.22) Prec@5 97.62 (98.24) Acls-loss 1.034 (0.772) FLOP-Loss 0.000 (0.000) Arch-Loss 1.034 (0.772)
 **TRAIN** Prec@1 75.22 Prec@5 98.24 Error@1 24.78 Error@5 1.76 Base-Loss:0.729, Arch-Loss=0.772
***[2020-01-29 09:00:07]*** TRAIN [epoch=374/600] base-loss = 0.729060, arch-loss = 0.772431, accuracy-1 = 75.22, accuracy-5 = 98.24
[epoch=374/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.402 0.212 0.386  ||  0.2120 -0.4271 0.1712  || discrepancy=0.02 || select=0/3
001/003-th : 0.310 0.146 0.544  ||  0.0143 -0.7344 0.5777  || discrepancy=0.23 || select=2/3
002/003-th : 0.006 0.025 0.970  ||  -2.3299 -0.8903 2.7857  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.049 0.072 0.073 0.113 0.152 0.205 0.305  ||  -1.164 -0.680 -0.306 -0.287 0.145 0.446 0.746 1.143   || dis=0.10 || select=7/8
001/019-th : 0.104 0.128 0.134 0.132 0.131 0.126 0.122 0.124  ||  -0.182 0.031 0.074 0.060 0.050 0.016 -0.018 0.001     || dis=0.00 || select=2/8
002/019-th : 0.118 0.125 0.128 0.131 0.128 0.130 0.125 0.117  ||  -0.058 -0.005 0.022 0.045 0.020 0.035 -0.005 -0.070   || dis=0.00 || select=3/8
003/019-th : 0.094 0.109 0.123 0.129 0.127 0.128 0.141 0.149  ||  -0.281 -0.133 -0.005 0.041 0.024 0.031 0.132 0.184    || dis=0.01 || select=7/8
004/019-th : 0.106 0.109 0.113 0.117 0.127 0.132 0.146 0.150  ||  -0.158 -0.133 -0.097 -0.060 0.020 0.063 0.159 0.188   || dis=0.00 || select=7/8
005/019-th : 0.109 0.117 0.122 0.124 0.126 0.133 0.128 0.140  ||  -0.134 -0.062 -0.020 -0.007 0.011 0.061 0.022 0.113   || dis=0.01 || select=7/8
006/019-th : 0.116 0.110 0.114 0.119 0.129 0.129 0.144 0.140  ||  -0.070 -0.122 -0.088 -0.044 0.032 0.034 0.143 0.116   || dis=0.00 || select=6/8
007/019-th : 0.029 0.041 0.071 0.081 0.128 0.148 0.190 0.312  ||  -1.187 -0.848 -0.301 -0.171 0.296 0.434 0.688 1.184   || dis=0.12 || select=7/8
008/019-th : 0.022 0.032 0.054 0.078 0.105 0.156 0.257 0.296  ||  -1.384 -1.004 -0.475 -0.111 0.184 0.583 1.082 1.222   || dis=0.04 || select=7/8
009/019-th : 0.069 0.080 0.097 0.116 0.125 0.148 0.163 0.202  ||  -0.532 -0.383 -0.194 -0.016 0.066 0.234 0.326 0.541   || dis=0.04 || select=7/8
010/019-th : 0.081 0.092 0.102 0.123 0.130 0.147 0.160 0.165  ||  -0.410 -0.279 -0.173 0.016 0.068 0.188 0.278 0.305    || dis=0.01 || select=7/8
011/019-th : 0.092 0.097 0.104 0.117 0.119 0.141 0.159 0.171  ||  -0.280 -0.231 -0.164 -0.039 -0.024 0.143 0.267 0.337  || dis=0.01 || select=7/8
012/019-th : 0.113 0.109 0.116 0.124 0.121 0.131 0.140 0.145  ||  -0.095 -0.128 -0.071 -0.003 -0.028 0.051 0.118 0.156  || dis=0.00 || select=7/8
013/019-th : 0.012 0.015 0.019 0.027 0.038 0.065 0.146 0.678  ||  -1.379 -1.148 -0.900 -0.562 -0.221 0.315 1.123 2.660  || dis=0.53 || select=7/8
014/019-th : 0.013 0.025 0.029 0.040 0.076 0.111 0.231 0.476  ||  -1.589 -0.964 -0.824 -0.498 0.151 0.528 1.262 1.985   || dis=0.24 || select=7/8
015/019-th : 0.009 0.013 0.018 0.023 0.031 0.057 0.156 0.692  ||  -1.503 -1.162 -0.887 -0.619 -0.304 0.301 1.298 2.789  || dis=0.54 || select=7/8
016/019-th : 0.050 0.061 0.085 0.113 0.133 0.162 0.187 0.209  ||  -0.804 -0.613 -0.279 0.008 0.164 0.366 0.506 0.618    || dis=0.02 || select=7/8
017/019-th : 0.091 0.101 0.105 0.120 0.132 0.142 0.153 0.156  ||  -0.292 -0.190 -0.156 -0.020 0.080 0.148 0.228 0.245   || dis=0.00 || select=7/8
018/019-th : 0.080 0.096 0.118 0.130 0.131 0.137 0.144 0.163  ||  -0.423 -0.243 -0.031 0.060 0.073 0.117 0.167 0.288    || dis=0.02 || select=7/8
[epoch=374/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.132
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:00:07] [epoch=374/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.845 (1.845)  Prec@1 42.97 (42.97) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:00:13] [epoch=374/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.752 (2.193)  Prec@1 27.98 (41.33) Prec@5 76.19 (82.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.33 Prec@5 82.66 Error@1 58.67 Error@5 17.34 Loss:2.193
***[2020-01-29 09:00:13]*** VALID [epoch=374/600] loss = 2.192664, accuracy@1 = 41.33, accuracy@5 = 82.66 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:00:13]*** start epoch=375/600 Time Left: [01:59:30], LR=[0.030866 ~ 0.030866], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=375, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.6124255907055303, FLOP=40.81
[Search] : epoch=375/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:00:14] [epoch=375/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.591 (0.591)  Prec@1 84.38 (84.38) Prec@5 99.61 (99.61) Acls-loss 0.653 (0.653) FLOP-Loss 0.000 (0.000) Arch-Loss 0.653 (0.653)
**TRAIN** [2020-01-29 09:00:38] [epoch=375/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.708 (0.701)  Prec@1 69.64 (76.23) Prec@5 98.81 (98.40) Acls-loss 0.791 (0.780) FLOP-Loss 0.000 (0.118) Arch-Loss 0.791 (1.017)
 **TRAIN** Prec@1 76.23 Prec@5 98.40 Error@1 23.77 Error@5 1.60 Base-Loss:0.701, Arch-Loss=1.017
***[2020-01-29 09:00:38]*** TRAIN [epoch=375/600] base-loss = 0.701292, arch-loss = 1.017157, accuracy-1 = 76.23, accuracy-5 = 98.40
[epoch=375/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.400 0.211 0.389  ||  0.2060 -0.4351 0.1794  || discrepancy=0.01 || select=0/3
001/003-th : 0.309 0.148 0.543  ||  0.0143 -0.7231 0.5759  || discrepancy=0.23 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3436 -0.8893 2.8005  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.049 0.073 0.073 0.110 0.149 0.206 0.309  ||  -1.160 -0.678 -0.295 -0.285 0.121 0.427 0.750 1.154   || dis=0.10 || select=7/8
001/019-th : 0.103 0.127 0.133 0.131 0.132 0.127 0.122 0.124  ||  -0.182 0.021 0.070 0.058 0.061 0.023 -0.019 0.003     || dis=0.00 || select=2/8
002/019-th : 0.118 0.125 0.128 0.132 0.130 0.127 0.124 0.117  ||  -0.056 -0.004 0.025 0.050 0.035 0.017 -0.011 -0.068   || dis=0.00 || select=3/8
003/019-th : 0.094 0.109 0.124 0.127 0.128 0.129 0.141 0.149  ||  -0.277 -0.132 -0.000 0.021 0.034 0.036 0.127 0.183    || dis=0.01 || select=7/8
004/019-th : 0.106 0.109 0.114 0.116 0.128 0.132 0.146 0.150  ||  -0.162 -0.133 -0.090 -0.068 0.029 0.059 0.164 0.186   || dis=0.00 || select=7/8
005/019-th : 0.108 0.118 0.124 0.124 0.125 0.134 0.128 0.139  ||  -0.142 -0.060 -0.009 -0.006 -0.003 0.071 0.026 0.109  || dis=0.01 || select=7/8
006/019-th : 0.116 0.111 0.112 0.121 0.128 0.129 0.142 0.140  ||  -0.067 -0.114 -0.103 -0.028 0.027 0.036 0.133 0.117   || dis=0.00 || select=6/8
007/019-th : 0.029 0.040 0.070 0.080 0.129 0.147 0.191 0.314  ||  -1.189 -0.858 -0.312 -0.174 0.306 0.437 0.694 1.192   || dis=0.12 || select=7/8
008/019-th : 0.022 0.032 0.054 0.079 0.104 0.157 0.256 0.295  ||  -1.377 -1.003 -0.476 -0.105 0.178 0.584 1.075 1.217   || dis=0.04 || select=7/8
009/019-th : 0.068 0.079 0.097 0.116 0.126 0.146 0.168 0.200  ||  -0.540 -0.397 -0.192 -0.009 0.071 0.221 0.359 0.531   || dis=0.03 || select=7/8
010/019-th : 0.080 0.092 0.103 0.124 0.130 0.147 0.160 0.165  ||  -0.412 -0.276 -0.169 0.018 0.068 0.188 0.273 0.307    || dis=0.01 || select=7/8
011/019-th : 0.092 0.098 0.105 0.117 0.119 0.141 0.158 0.171  ||  -0.285 -0.223 -0.152 -0.044 -0.021 0.144 0.257 0.337  || dis=0.01 || select=7/8
012/019-th : 0.113 0.111 0.117 0.123 0.120 0.132 0.139 0.144  ||  -0.099 -0.114 -0.059 -0.007 -0.032 0.059 0.114 0.146  || dis=0.00 || select=7/8
013/019-th : 0.012 0.015 0.019 0.027 0.037 0.064 0.142 0.683  ||  -1.392 -1.126 -0.887 -0.554 -0.236 0.309 1.106 2.677  || dis=0.54 || select=7/8
014/019-th : 0.013 0.025 0.028 0.039 0.076 0.112 0.231 0.477  ||  -1.596 -0.973 -0.835 -0.503 0.156 0.541 1.268 1.993   || dis=0.25 || select=7/8
015/019-th : 0.009 0.013 0.017 0.022 0.031 0.057 0.152 0.697  ||  -1.500 -1.161 -0.889 -0.632 -0.301 0.308 1.281 2.804  || dis=0.54 || select=7/8
016/019-th : 0.051 0.061 0.085 0.112 0.130 0.164 0.190 0.207  ||  -0.798 -0.614 -0.285 0.001 0.147 0.380 0.526 0.611    || dis=0.02 || select=7/8
017/019-th : 0.092 0.102 0.104 0.119 0.131 0.140 0.154 0.157  ||  -0.285 -0.181 -0.159 -0.024 0.070 0.138 0.230 0.247   || dis=0.00 || select=7/8
018/019-th : 0.080 0.097 0.118 0.131 0.130 0.137 0.143 0.163  ||  -0.419 -0.233 -0.034 0.072 0.062 0.117 0.159 0.286    || dis=0.02 || select=7/8
[epoch=375/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.132
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:00:39] [epoch=375/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.901 (1.901)  Prec@1 38.67 (38.67) Prec@5 79.30 (79.30) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:00:45] [epoch=375/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.035 (2.697)  Prec@1 33.93 (36.84) Prec@5 80.95 (80.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.84 Prec@5 80.31 Error@1 63.16 Error@5 19.69 Loss:2.697
***[2020-01-29 09:00:45]*** VALID [epoch=375/600] loss = 2.696546, accuracy@1 = 36.84, accuracy@5 = 80.31 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:00:45]*** start epoch=376/600 Time Left: [01:58:58], LR=[0.030624 ~ 0.030624], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=376, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.600586813192348, FLOP=40.81
[Search] : epoch=376/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:00:45] [epoch=376/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.548 (0.548)  Prec@1 82.42 (82.42) Prec@5 99.61 (99.61) Acls-loss 0.750 (0.750) FLOP-Loss 0.000 (0.000) Arch-Loss 0.750 (0.750)
**TRAIN** [2020-01-29 09:01:10] [epoch=376/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 1.104 (0.725)  Prec@1 61.31 (75.08) Prec@5 93.45 (98.23) Acls-loss 0.712 (0.762) FLOP-Loss 0.000 (0.442) Arch-Loss 0.712 (1.646)
 **TRAIN** Prec@1 75.08 Prec@5 98.23 Error@1 24.92 Error@5 1.77 Base-Loss:0.725, Arch-Loss=1.646
***[2020-01-29 09:01:10]*** TRAIN [epoch=376/600] base-loss = 0.724658, arch-loss = 1.645946, accuracy-1 = 75.08, accuracy-5 = 98.23
[epoch=376/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.415 0.214 0.371  ||  0.2462 -0.4182 0.1353  || discrepancy=0.04 || select=0/3
001/003-th : 0.330 0.153 0.517  ||  0.0693 -0.7011 0.5191  || discrepancy=0.19 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3349 -0.8845 2.7939  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.050 0.074 0.075 0.112 0.152 0.204 0.302  ||  -1.148 -0.675 -0.288 -0.269 0.128 0.438 0.732 1.123   || dis=0.10 || select=7/8
001/019-th : 0.109 0.130 0.135 0.135 0.130 0.123 0.118 0.119  ||  -0.133 0.044 0.085 0.083 0.046 -0.008 -0.049 -0.043   || dis=0.00 || select=2/8
002/019-th : 0.123 0.130 0.132 0.136 0.127 0.123 0.117 0.112  ||  -0.015 0.038 0.058 0.085 0.013 -0.016 -0.063 -0.110   || dis=0.00 || select=3/8
003/019-th : 0.098 0.113 0.127 0.129 0.127 0.129 0.135 0.143  ||  -0.239 -0.092 0.021 0.034 0.017 0.034 0.083 0.138     || dis=0.01 || select=7/8
004/019-th : 0.110 0.114 0.116 0.119 0.127 0.129 0.141 0.143  ||  -0.123 -0.090 -0.066 -0.041 0.021 0.040 0.127 0.139   || dis=0.00 || select=7/8
005/019-th : 0.111 0.122 0.129 0.127 0.122 0.131 0.124 0.135  ||  -0.116 -0.025 0.028 0.012 -0.022 0.043 -0.009 0.074   || dis=0.00 || select=7/8
006/019-th : 0.122 0.116 0.114 0.122 0.127 0.127 0.137 0.134  ||  -0.019 -0.075 -0.085 -0.016 0.019 0.021 0.098 0.073   || dis=0.00 || select=6/8
007/019-th : 0.029 0.041 0.072 0.082 0.129 0.150 0.190 0.308  ||  -1.186 -0.850 -0.293 -0.162 0.294 0.444 0.684 1.168   || dis=0.12 || select=7/8
008/019-th : 0.022 0.032 0.056 0.081 0.105 0.156 0.258 0.291  ||  -1.372 -1.011 -0.446 -0.088 0.177 0.570 1.074 1.195   || dis=0.03 || select=7/8
009/019-th : 0.071 0.080 0.099 0.117 0.127 0.146 0.165 0.194  ||  -0.508 -0.385 -0.175 -0.005 0.073 0.211 0.335 0.499   || dis=0.03 || select=7/8
010/019-th : 0.082 0.095 0.105 0.125 0.132 0.146 0.156 0.158  ||  -0.396 -0.245 -0.144 0.029 0.078 0.183 0.247 0.264    || dis=0.00 || select=7/8
011/019-th : 0.094 0.096 0.106 0.119 0.120 0.139 0.157 0.168  ||  -0.265 -0.239 -0.139 -0.024 -0.022 0.130 0.253 0.319  || dis=0.01 || select=7/8
012/019-th : 0.118 0.117 0.121 0.123 0.119 0.129 0.134 0.138  ||  -0.055 -0.064 -0.026 -0.014 -0.042 0.038 0.077 0.105  || dis=0.00 || select=7/8
013/019-th : 0.012 0.015 0.019 0.027 0.037 0.065 0.142 0.682  ||  -1.387 -1.130 -0.886 -0.555 -0.237 0.320 1.104 2.671  || dis=0.54 || select=7/8
014/019-th : 0.013 0.025 0.028 0.040 0.077 0.113 0.231 0.473  ||  -1.605 -0.967 -0.837 -0.500 0.166 0.553 1.266 1.982   || dis=0.24 || select=7/8
015/019-th : 0.010 0.013 0.017 0.022 0.031 0.057 0.153 0.696  ||  -1.483 -1.162 -0.900 -0.642 -0.297 0.306 1.287 2.804  || dis=0.54 || select=7/8
016/019-th : 0.052 0.063 0.087 0.114 0.134 0.164 0.184 0.201  ||  -0.772 -0.584 -0.261 0.007 0.165 0.373 0.488 0.573    || dis=0.02 || select=7/8
017/019-th : 0.095 0.106 0.108 0.122 0.130 0.138 0.150 0.151  ||  -0.259 -0.145 -0.133 -0.003 0.054 0.116 0.199 0.209   || dis=0.00 || select=7/8
018/019-th : 0.082 0.101 0.120 0.133 0.130 0.134 0.143 0.157  ||  -0.402 -0.191 -0.018 0.084 0.058 0.093 0.153 0.248    || dis=0.01 || select=7/8
[epoch=376/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.130
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:01:10] [epoch=376/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.268 (2.268)  Prec@1 30.86 (30.86) Prec@5 77.34 (77.34) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:01:16] [epoch=376/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.185 (2.201)  Prec@1 30.95 (37.17) Prec@5 73.81 (81.25) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.17 Prec@5 81.25 Error@1 62.83 Error@5 18.75 Loss:2.201
***[2020-01-29 09:01:16]*** VALID [epoch=376/600] loss = 2.201043, accuracy@1 = 37.17, accuracy@5 = 81.25 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:01:16]*** start epoch=377/600 Time Left: [01:58:26], LR=[0.030383 ~ 0.030383], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=377, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5887740643212753, FLOP=40.81
[Search] : epoch=377/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:01:17] [epoch=377/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.648 (0.648)  Prec@1 76.95 (76.95) Prec@5 100.00 (100.00) Acls-loss 0.681 (0.681) FLOP-Loss 0.000 (0.000) Arch-Loss 0.681 (0.681)
**TRAIN** [2020-01-29 09:01:41] [epoch=377/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.659 (0.721)  Prec@1 76.79 (75.03) Prec@5 98.81 (98.17) Acls-loss 1.060 (0.784) FLOP-Loss 0.000 (0.000) Arch-Loss 1.060 (0.784)
 **TRAIN** Prec@1 75.03 Prec@5 98.17 Error@1 24.97 Error@5 1.83 Base-Loss:0.721, Arch-Loss=0.784
***[2020-01-29 09:01:42]*** TRAIN [epoch=377/600] base-loss = 0.721400, arch-loss = 0.784148, accuracy-1 = 75.03, accuracy-5 = 98.17
[epoch=377/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.409 0.215 0.376  ||  0.2314 -0.4118 0.1492  || discrepancy=0.03 || select=0/3
001/003-th : 0.322 0.149 0.529  ||  0.0478 -0.7230 0.5444  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.024 0.971  ||  -2.3367 -0.9057 2.8068  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.031 0.050 0.073 0.075 0.110 0.154 0.202 0.305  ||  -1.140 -0.674 -0.300 -0.272 0.113 0.447 0.723 1.134   || dis=0.10 || select=7/8
001/019-th : 0.108 0.127 0.135 0.133 0.132 0.124 0.120 0.120  ||  -0.136 0.019 0.086 0.065 0.063 -0.001 -0.031 -0.034   || dis=0.00 || select=2/8
002/019-th : 0.121 0.127 0.132 0.135 0.128 0.124 0.118 0.114  ||  -0.029 0.020 0.052 0.079 0.026 -0.006 -0.056 -0.090   || dis=0.00 || select=3/8
003/019-th : 0.097 0.112 0.127 0.128 0.126 0.129 0.138 0.143  ||  -0.251 -0.102 0.019 0.029 0.016 0.041 0.102 0.144     || dis=0.00 || select=7/8
004/019-th : 0.109 0.112 0.114 0.119 0.127 0.130 0.144 0.144  ||  -0.131 -0.101 -0.087 -0.046 0.023 0.043 0.149 0.149   || dis=0.00 || select=7/8
005/019-th : 0.111 0.122 0.128 0.125 0.122 0.130 0.126 0.137  ||  -0.122 -0.026 0.020 0.002 -0.026 0.038 0.006 0.088    || dis=0.01 || select=7/8
006/019-th : 0.119 0.114 0.113 0.122 0.128 0.130 0.139 0.135  ||  -0.046 -0.085 -0.096 -0.020 0.028 0.043 0.112 0.084   || dis=0.00 || select=6/8
007/019-th : 0.029 0.041 0.071 0.081 0.129 0.148 0.192 0.310  ||  -1.197 -0.847 -0.303 -0.165 0.297 0.439 0.696 1.177   || dis=0.12 || select=7/8
008/019-th : 0.022 0.031 0.055 0.077 0.103 0.158 0.258 0.295  ||  -1.370 -1.022 -0.455 -0.121 0.168 0.594 1.082 1.217   || dis=0.04 || select=7/8
009/019-th : 0.070 0.078 0.098 0.115 0.127 0.149 0.165 0.198  ||  -0.520 -0.406 -0.181 -0.020 0.075 0.237 0.338 0.521   || dis=0.03 || select=7/8
010/019-th : 0.080 0.094 0.104 0.126 0.133 0.144 0.159 0.160  ||  -0.417 -0.259 -0.156 0.036 0.090 0.172 0.271 0.277    || dis=0.00 || select=7/8
011/019-th : 0.094 0.094 0.106 0.119 0.119 0.139 0.160 0.169  ||  -0.265 -0.257 -0.142 -0.024 -0.022 0.129 0.268 0.324  || dis=0.01 || select=7/8
012/019-th : 0.116 0.115 0.120 0.123 0.120 0.130 0.134 0.142  ||  -0.071 -0.082 -0.036 -0.012 -0.037 0.046 0.075 0.129  || dis=0.01 || select=7/8
013/019-th : 0.012 0.015 0.020 0.027 0.037 0.065 0.141 0.685  ||  -1.384 -1.158 -0.875 -0.556 -0.241 0.321 1.105 2.683  || dis=0.54 || select=7/8
014/019-th : 0.013 0.024 0.028 0.039 0.075 0.112 0.232 0.477  ||  -1.619 -0.967 -0.844 -0.504 0.153 0.551 1.284 2.003   || dis=0.24 || select=7/8
015/019-th : 0.009 0.013 0.017 0.022 0.031 0.057 0.151 0.700  ||  -1.505 -1.177 -0.912 -0.646 -0.294 0.320 1.289 2.824  || dis=0.55 || select=7/8
016/019-th : 0.050 0.062 0.085 0.112 0.131 0.166 0.188 0.205  ||  -0.808 -0.591 -0.275 -0.003 0.155 0.388 0.511 0.602   || dis=0.02 || select=7/8
017/019-th : 0.093 0.106 0.106 0.122 0.130 0.138 0.152 0.153  ||  -0.274 -0.143 -0.149 -0.008 0.060 0.117 0.213 0.221   || dis=0.00 || select=7/8
018/019-th : 0.079 0.101 0.120 0.131 0.129 0.135 0.144 0.160  ||  -0.435 -0.192 -0.020 0.069 0.053 0.100 0.167 0.272    || dis=0.02 || select=7/8
[epoch=377/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.131
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:01:42] [epoch=377/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.239 (2.239)  Prec@1 33.59 (33.59) Prec@5 73.44 (73.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:01:48] [epoch=377/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.728 (2.309)  Prec@1 25.60 (35.44) Prec@5 70.83 (79.44) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.44 Prec@5 79.44 Error@1 64.56 Error@5 20.56 Loss:2.309
***[2020-01-29 09:01:48]*** VALID [epoch=377/600] loss = 2.308693, accuracy@1 = 35.44, accuracy@5 = 79.44 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:01:48]*** start epoch=378/600 Time Left: [01:57:54], LR=[0.030143 ~ 0.030143], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=378, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5769876679447878, FLOP=40.81
[Search] : epoch=378/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:01:49] [epoch=378/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.718 (0.718)  Prec@1 73.44 (73.44) Prec@5 98.83 (98.83) Acls-loss 0.846 (0.846) FLOP-Loss 0.000 (0.000) Arch-Loss 0.846 (0.846)
**TRAIN** [2020-01-29 09:02:13] [epoch=378/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.877 (0.730)  Prec@1 69.64 (75.19) Prec@5 97.02 (98.25) Acls-loss 0.551 (0.783) FLOP-Loss 0.000 (0.265) Arch-Loss 0.551 (1.313)
 **TRAIN** Prec@1 75.19 Prec@5 98.25 Error@1 24.81 Error@5 1.75 Base-Loss:0.730, Arch-Loss=1.313
***[2020-01-29 09:02:13]*** TRAIN [epoch=378/600] base-loss = 0.729884, arch-loss = 1.313034, accuracy-1 = 75.19, accuracy-5 = 98.25
[epoch=378/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.417 0.213 0.370  ||  0.2515 -0.4224 0.1311  || discrepancy=0.05 || select=0/3
001/003-th : 0.332 0.152 0.517  ||  0.0737 -0.7091 0.5175  || discrepancy=0.18 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3370 -0.8895 2.8036  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.050 0.073 0.076 0.112 0.155 0.202 0.300  ||  -1.126 -0.679 -0.302 -0.267 0.126 0.455 0.716 1.113   || dis=0.10 || select=7/8
001/019-th : 0.108 0.127 0.138 0.134 0.134 0.124 0.118 0.117  ||  -0.136 0.027 0.112 0.076 0.075 0.002 -0.047 -0.059    || dis=0.00 || select=2/8
002/019-th : 0.124 0.131 0.134 0.137 0.126 0.120 0.115 0.111  ||  -0.005 0.051 0.074 0.096 0.013 -0.041 -0.081 -0.115   || dis=0.00 || select=3/8
003/019-th : 0.099 0.113 0.129 0.130 0.124 0.129 0.136 0.141  ||  -0.233 -0.098 0.038 0.047 -0.001 0.033 0.087 0.126    || dis=0.00 || select=7/8
004/019-th : 0.112 0.114 0.117 0.122 0.125 0.128 0.141 0.141  ||  -0.104 -0.087 -0.064 -0.022 0.007 0.028 0.128 0.124   || dis=0.00 || select=6/8
005/019-th : 0.112 0.123 0.127 0.125 0.121 0.129 0.127 0.135  ||  -0.108 -0.019 0.015 0.002 -0.032 0.032 0.015 0.075    || dis=0.01 || select=7/8
006/019-th : 0.119 0.117 0.115 0.121 0.128 0.132 0.134 0.134  ||  -0.040 -0.063 -0.081 -0.029 0.027 0.060 0.079 0.076   || dis=0.00 || select=6/8
007/019-th : 0.029 0.040 0.070 0.081 0.131 0.147 0.192 0.310  ||  -1.196 -0.865 -0.308 -0.163 0.318 0.431 0.699 1.180   || dis=0.12 || select=7/8
008/019-th : 0.022 0.031 0.055 0.077 0.103 0.157 0.256 0.298  ||  -1.364 -1.028 -0.457 -0.119 0.166 0.589 1.077 1.227   || dis=0.04 || select=7/8
009/019-th : 0.070 0.080 0.098 0.117 0.129 0.147 0.162 0.195  ||  -0.520 -0.385 -0.181 -0.006 0.093 0.221 0.317 0.505   || dis=0.03 || select=7/8
010/019-th : 0.082 0.094 0.103 0.128 0.134 0.144 0.157 0.158  ||  -0.398 -0.258 -0.164 0.055 0.100 0.166 0.255 0.264    || dis=0.00 || select=7/8
011/019-th : 0.094 0.096 0.107 0.120 0.120 0.139 0.157 0.167  ||  -0.267 -0.237 -0.138 -0.014 -0.022 0.126 0.253 0.314  || dis=0.01 || select=7/8
012/019-th : 0.120 0.116 0.124 0.122 0.122 0.128 0.131 0.137  ||  -0.039 -0.071 -0.007 -0.018 -0.019 0.030 0.053 0.097  || dis=0.01 || select=7/8
013/019-th : 0.012 0.015 0.019 0.027 0.037 0.063 0.139 0.689  ||  -1.376 -1.153 -0.868 -0.560 -0.238 0.301 1.099 2.696  || dis=0.55 || select=7/8
014/019-th : 0.012 0.025 0.027 0.039 0.075 0.111 0.230 0.480  ||  -1.646 -0.956 -0.850 -0.491 0.163 0.551 1.281 2.016   || dis=0.25 || select=7/8
015/019-th : 0.009 0.013 0.017 0.022 0.031 0.056 0.150 0.703  ||  -1.515 -1.167 -0.899 -0.648 -0.295 0.297 1.292 2.833  || dis=0.55 || select=7/8
016/019-th : 0.051 0.063 0.086 0.114 0.131 0.167 0.186 0.202  ||  -0.786 -0.582 -0.275 0.008 0.147 0.389 0.500 0.584    || dis=0.02 || select=7/8
017/019-th : 0.093 0.105 0.107 0.123 0.130 0.136 0.152 0.152  ||  -0.278 -0.151 -0.132 0.003 0.062 0.102 0.216 0.218    || dis=0.00 || select=7/8
018/019-th : 0.081 0.102 0.120 0.132 0.131 0.135 0.142 0.157  ||  -0.415 -0.182 -0.020 0.077 0.069 0.098 0.147 0.250    || dis=0.02 || select=7/8
[epoch=378/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.131
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:02:13] [epoch=378/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.776 (3.776)  Prec@1 35.16 (35.16) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:02:19] [epoch=378/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.374 (2.229)  Prec@1 57.74 (42.14) Prec@5 92.86 (82.95) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.14 Prec@5 82.95 Error@1 57.86 Error@5 17.05 Loss:2.229
***[2020-01-29 09:02:19]*** VALID [epoch=378/600] loss = 2.229171, accuracy@1 = 42.14, accuracy@5 = 82.95 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:02:20]*** start epoch=379/600 Time Left: [01:57:22], LR=[0.029903 ~ 0.029903], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=379, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.565227947192898, FLOP=40.81
[Search] : epoch=379/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:02:20] [epoch=379/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.690 (0.690)  Prec@1 78.12 (78.12) Prec@5 98.83 (98.83) Acls-loss 0.812 (0.812) FLOP-Loss 0.000 (0.000) Arch-Loss 0.812 (0.812)
**TRAIN** [2020-01-29 09:02:44] [epoch=379/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.730 (0.698)  Prec@1 72.02 (76.05) Prec@5 98.21 (98.30) Acls-loss 0.812 (0.794) FLOP-Loss 0.000 (0.088) Arch-Loss 0.812 (0.971)
 **TRAIN** Prec@1 76.05 Prec@5 98.30 Error@1 23.95 Error@5 1.70 Base-Loss:0.698, Arch-Loss=0.971
***[2020-01-29 09:02:44]*** TRAIN [epoch=379/600] base-loss = 0.697907, arch-loss = 0.970609, accuracy-1 = 76.05, accuracy-5 = 98.30
[epoch=379/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.415 0.212 0.373  ||  0.2461 -0.4288 0.1382  || discrepancy=0.04 || select=0/3
001/003-th : 0.330 0.152 0.518  ||  0.0692 -0.7038 0.5214  || discrepancy=0.19 || select=2/3
002/003-th : 0.006 0.024 0.971  ||  -2.3366 -0.9028 2.8115  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.049 0.072 0.075 0.111 0.151 0.203 0.307  ||  -1.131 -0.694 -0.305 -0.263 0.120 0.433 0.728 1.143   || dis=0.10 || select=7/8
001/019-th : 0.107 0.127 0.137 0.131 0.137 0.124 0.119 0.117  ||  -0.149 0.028 0.102 0.059 0.101 0.005 -0.041 -0.053    || dis=0.00 || select=2/8
002/019-th : 0.124 0.131 0.134 0.137 0.127 0.121 0.115 0.111  ||  -0.004 0.050 0.071 0.089 0.016 -0.034 -0.082 -0.115   || dis=0.00 || select=3/8
003/019-th : 0.099 0.111 0.129 0.128 0.126 0.130 0.135 0.142  ||  -0.225 -0.114 0.038 0.031 0.012 0.042 0.081 0.133     || dis=0.01 || select=7/8
004/019-th : 0.112 0.114 0.116 0.123 0.125 0.127 0.140 0.143  ||  -0.103 -0.084 -0.069 -0.014 0.002 0.016 0.115 0.140   || dis=0.00 || select=7/8
005/019-th : 0.111 0.121 0.126 0.124 0.124 0.130 0.127 0.136  ||  -0.117 -0.033 0.012 -0.005 -0.010 0.041 0.015 0.085   || dis=0.01 || select=7/8
006/019-th : 0.119 0.116 0.113 0.120 0.127 0.134 0.137 0.134  ||  -0.044 -0.069 -0.098 -0.035 0.023 0.073 0.100 0.074   || dis=0.00 || select=6/8
007/019-th : 0.029 0.040 0.070 0.080 0.131 0.145 0.190 0.314  ||  -1.187 -0.866 -0.312 -0.171 0.321 0.422 0.689 1.191   || dis=0.12 || select=7/8
008/019-th : 0.022 0.031 0.053 0.078 0.103 0.156 0.258 0.299  ||  -1.379 -1.014 -0.494 -0.112 0.174 0.584 1.087 1.237   || dis=0.04 || select=7/8
009/019-th : 0.071 0.081 0.098 0.116 0.128 0.147 0.163 0.196  ||  -0.512 -0.375 -0.185 -0.017 0.082 0.218 0.320 0.508   || dis=0.03 || select=7/8
010/019-th : 0.082 0.094 0.102 0.128 0.132 0.143 0.158 0.160  ||  -0.396 -0.262 -0.171 0.055 0.086 0.164 0.262 0.275    || dis=0.00 || select=7/8
011/019-th : 0.094 0.096 0.104 0.120 0.118 0.138 0.159 0.170  ||  -0.264 -0.238 -0.156 -0.014 -0.038 0.125 0.263 0.330  || dis=0.01 || select=7/8
012/019-th : 0.119 0.114 0.123 0.123 0.123 0.130 0.131 0.139  ||  -0.043 -0.092 -0.013 -0.015 -0.016 0.040 0.052 0.108  || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.019 0.026 0.035 0.060 0.134 0.701  ||  -1.372 -1.146 -0.871 -0.570 -0.250 0.281 1.085 2.742  || dis=0.57 || select=7/8
014/019-th : 0.012 0.024 0.027 0.039 0.074 0.110 0.228 0.485  ||  -1.647 -0.962 -0.845 -0.480 0.147 0.548 1.275 2.031   || dis=0.26 || select=7/8
015/019-th : 0.009 0.013 0.016 0.021 0.030 0.053 0.145 0.712  ||  -1.513 -1.166 -0.899 -0.647 -0.293 0.274 1.277 2.867  || dis=0.57 || select=7/8
016/019-th : 0.052 0.063 0.086 0.114 0.131 0.166 0.186 0.203  ||  -0.781 -0.586 -0.274 0.008 0.149 0.383 0.499 0.587    || dis=0.02 || select=7/8
017/019-th : 0.093 0.105 0.108 0.123 0.132 0.135 0.151 0.153  ||  -0.281 -0.158 -0.128 0.005 0.072 0.098 0.211 0.223    || dis=0.00 || select=7/8
018/019-th : 0.081 0.103 0.118 0.132 0.131 0.135 0.143 0.158  ||  -0.417 -0.171 -0.041 0.078 0.068 0.096 0.154 0.252    || dis=0.02 || select=7/8
[epoch=379/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.134
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:02:45] [epoch=379/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.746 (1.746)  Prec@1 44.14 (44.14) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:02:51] [epoch=379/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.191 (2.275)  Prec@1 20.83 (37.92) Prec@5 67.26 (81.12) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.92 Prec@5 81.12 Error@1 62.08 Error@5 18.88 Loss:2.275
***[2020-01-29 09:02:51]*** VALID [epoch=379/600] loss = 2.275084, accuracy@1 = 37.92, accuracy@5 = 81.12 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:02:51]*** start epoch=380/600 Time Left: [01:56:50], LR=[0.029663 ~ 0.029663], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=380, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5534952244642901, FLOP=40.81
[Search] : epoch=380/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:02:52] [epoch=380/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.694 (0.694)  Prec@1 77.73 (77.73) Prec@5 98.05 (98.05) Acls-loss 0.640 (0.640) FLOP-Loss 0.000 (0.000) Arch-Loss 0.640 (0.640)
**TRAIN** [2020-01-29 09:03:16] [epoch=380/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.537 (0.733)  Prec@1 82.14 (74.84) Prec@5 98.81 (98.18) Acls-loss 1.061 (0.779) FLOP-Loss 2.879 (0.049) Arch-Loss 6.818 (0.877)
 **TRAIN** Prec@1 74.84 Prec@5 98.18 Error@1 25.16 Error@5 1.82 Base-Loss:0.733, Arch-Loss=0.877
***[2020-01-29 09:03:16]*** TRAIN [epoch=380/600] base-loss = 0.733402, arch-loss = 0.876760, accuracy-1 = 74.84, accuracy-5 = 98.18
[epoch=380/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.408 0.211 0.381  ||  0.2266 -0.4297 0.1585  || discrepancy=0.03 || select=0/3
001/003-th : 0.326 0.152 0.522  ||  0.0597 -0.7057 0.5313  || discrepancy=0.20 || select=2/3
002/003-th : 0.006 0.023 0.971  ||  -2.3344 -0.9108 2.8158  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.049 0.070 0.074 0.110 0.149 0.203 0.312  ||  -1.117 -0.688 -0.332 -0.276 0.121 0.423 0.730 1.158   || dis=0.11 || select=7/8
001/019-th : 0.105 0.126 0.137 0.132 0.136 0.125 0.120 0.119  ||  -0.163 0.021 0.098 0.062 0.097 0.012 -0.033 -0.039    || dis=0.00 || select=2/8
002/019-th : 0.123 0.130 0.134 0.133 0.129 0.123 0.116 0.112  ||  -0.014 0.043 0.068 0.059 0.029 -0.020 -0.071 -0.106   || dis=0.00 || select=2/8
003/019-th : 0.099 0.108 0.128 0.127 0.128 0.131 0.137 0.142  ||  -0.227 -0.139 0.033 0.025 0.028 0.052 0.098 0.137     || dis=0.00 || select=7/8
004/019-th : 0.110 0.113 0.116 0.123 0.126 0.126 0.140 0.145  ||  -0.121 -0.101 -0.070 -0.010 0.013 0.013 0.120 0.155   || dis=0.00 || select=7/8
005/019-th : 0.109 0.120 0.124 0.124 0.126 0.132 0.128 0.138  ||  -0.139 -0.041 -0.007 -0.009 0.011 0.057 0.023 0.103   || dis=0.01 || select=7/8
006/019-th : 0.119 0.114 0.113 0.117 0.126 0.135 0.140 0.136  ||  -0.048 -0.084 -0.093 -0.066 0.015 0.081 0.115 0.091   || dis=0.00 || select=6/8
007/019-th : 0.029 0.040 0.068 0.079 0.132 0.143 0.193 0.316  ||  -1.185 -0.869 -0.340 -0.180 0.332 0.412 0.708 1.204   || dis=0.12 || select=7/8
008/019-th : 0.022 0.031 0.053 0.077 0.103 0.158 0.255 0.302  ||  -1.388 -1.023 -0.494 -0.111 0.175 0.602 1.080 1.251   || dis=0.05 || select=7/8
009/019-th : 0.071 0.081 0.098 0.114 0.128 0.148 0.162 0.198  ||  -0.506 -0.376 -0.182 -0.035 0.078 0.223 0.317 0.515   || dis=0.04 || select=7/8
010/019-th : 0.081 0.094 0.103 0.128 0.132 0.142 0.158 0.162  ||  -0.410 -0.258 -0.162 0.050 0.084 0.159 0.261 0.286    || dis=0.00 || select=7/8
011/019-th : 0.094 0.096 0.104 0.119 0.120 0.137 0.160 0.170  ||  -0.258 -0.245 -0.163 -0.028 -0.017 0.117 0.273 0.328  || dis=0.01 || select=7/8
012/019-th : 0.119 0.112 0.122 0.124 0.122 0.130 0.132 0.141  ||  -0.047 -0.107 -0.023 -0.008 -0.023 0.040 0.062 0.121  || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.019 0.025 0.035 0.059 0.134 0.703  ||  -1.381 -1.141 -0.880 -0.580 -0.250 0.277 1.094 2.753  || dis=0.57 || select=7/8
014/019-th : 0.012 0.024 0.027 0.039 0.072 0.110 0.227 0.489  ||  -1.664 -0.953 -0.840 -0.479 0.131 0.551 1.281 2.046   || dis=0.26 || select=7/8
015/019-th : 0.009 0.013 0.016 0.022 0.030 0.053 0.144 0.714  ||  -1.521 -1.161 -0.923 -0.623 -0.307 0.279 1.276 2.874  || dis=0.57 || select=7/8
016/019-th : 0.051 0.063 0.086 0.115 0.132 0.163 0.184 0.205  ||  -0.794 -0.583 -0.273 0.016 0.158 0.368 0.491 0.598    || dis=0.02 || select=7/8
017/019-th : 0.090 0.104 0.109 0.125 0.130 0.134 0.153 0.155  ||  -0.304 -0.160 -0.117 0.017 0.061 0.088 0.222 0.235    || dis=0.00 || select=7/8
018/019-th : 0.081 0.104 0.117 0.131 0.132 0.135 0.142 0.158  ||  -0.414 -0.163 -0.047 0.066 0.076 0.096 0.149 0.254    || dis=0.02 || select=7/8
[epoch=380/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.135
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:03:16] [epoch=380/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.342 (1.342)  Prec@1 55.08 (55.08) Prec@5 91.41 (91.41) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:03:23] [epoch=380/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.201 (2.214)  Prec@1 46.43 (40.48) Prec@5 86.90 (83.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.48 Prec@5 83.17 Error@1 59.52 Error@5 16.83 Loss:2.214
***[2020-01-29 09:03:23]*** VALID [epoch=380/600] loss = 2.214122, accuracy@1 = 40.48, accuracy@5 = 83.17 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:03:23]*** start epoch=381/600 Time Left: [01:56:18], LR=[0.029424 ~ 0.029424], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=381, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5417898214174837, FLOP=40.81
[Search] : epoch=381/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:03:23] [epoch=381/600][000/098] Time 0.65 (0.65) Data 0.38 (0.38) Base-Loss 0.959 (0.959)  Prec@1 67.19 (67.19) Prec@5 97.27 (97.27) Acls-loss 0.620 (0.620) FLOP-Loss 0.000 (0.000) Arch-Loss 0.620 (0.620)
**TRAIN** [2020-01-29 09:03:48] [epoch=381/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.801 (0.720)  Prec@1 75.00 (75.26) Prec@5 97.62 (98.32) Acls-loss 0.568 (0.768) FLOP-Loss 0.000 (0.000) Arch-Loss 0.568 (0.768)
 **TRAIN** Prec@1 75.26 Prec@5 98.32 Error@1 24.74 Error@5 1.68 Base-Loss:0.720, Arch-Loss=0.768
***[2020-01-29 09:03:48]*** TRAIN [epoch=381/600] base-loss = 0.720006, arch-loss = 0.767756, accuracy-1 = 75.26, accuracy-5 = 98.32
[epoch=381/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.404 0.212 0.384  ||  0.2177 -0.4286 0.1675  || discrepancy=0.02 || select=0/3
001/003-th : 0.321 0.151 0.528  ||  0.0476 -0.7080 0.5438  || discrepancy=0.21 || select=2/3
002/003-th : 0.006 0.023 0.971  ||  -2.3406 -0.9015 2.8207  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.049 0.069 0.074 0.110 0.150 0.205 0.312  ||  -1.123 -0.694 -0.349 -0.270 0.124 0.431 0.741 1.162   || dis=0.11 || select=7/8
001/019-th : 0.104 0.124 0.137 0.131 0.136 0.128 0.121 0.119  ||  -0.176 0.005 0.101 0.059 0.094 0.033 -0.018 -0.035    || dis=0.00 || select=2/8
002/019-th : 0.123 0.126 0.134 0.132 0.129 0.124 0.119 0.113  ||  -0.018 0.012 0.072 0.053 0.031 -0.010 -0.051 -0.097   || dis=0.00 || select=2/8
003/019-th : 0.098 0.107 0.127 0.127 0.127 0.132 0.138 0.144  ||  -0.235 -0.149 0.023 0.026 0.027 0.060 0.108 0.148     || dis=0.01 || select=7/8
004/019-th : 0.109 0.111 0.115 0.121 0.127 0.127 0.142 0.147  ||  -0.133 -0.113 -0.078 -0.025 0.019 0.023 0.135 0.166   || dis=0.01 || select=7/8
005/019-th : 0.107 0.119 0.123 0.123 0.126 0.134 0.129 0.139  ||  -0.151 -0.048 -0.011 -0.015 0.011 0.072 0.032 0.111   || dis=0.01 || select=7/8
006/019-th : 0.118 0.115 0.112 0.115 0.127 0.136 0.140 0.138  ||  -0.057 -0.082 -0.104 -0.081 0.019 0.088 0.118 0.103   || dis=0.00 || select=6/8
007/019-th : 0.029 0.039 0.067 0.079 0.131 0.140 0.192 0.324  ||  -1.173 -0.889 -0.344 -0.184 0.326 0.395 0.709 1.232   || dis=0.13 || select=7/8
008/019-th : 0.022 0.031 0.052 0.075 0.103 0.157 0.256 0.305  ||  -1.384 -1.031 -0.511 -0.130 0.179 0.600 1.093 1.269   || dis=0.05 || select=7/8
009/019-th : 0.068 0.081 0.098 0.115 0.127 0.145 0.165 0.201  ||  -0.547 -0.368 -0.186 -0.021 0.074 0.211 0.337 0.533   || dis=0.04 || select=7/8
010/019-th : 0.082 0.093 0.104 0.127 0.131 0.142 0.159 0.162  ||  -0.400 -0.268 -0.158 0.040 0.076 0.157 0.267 0.289    || dis=0.00 || select=7/8
011/019-th : 0.095 0.094 0.105 0.118 0.121 0.135 0.160 0.172  ||  -0.252 -0.267 -0.155 -0.032 -0.013 0.103 0.273 0.343  || dis=0.01 || select=7/8
012/019-th : 0.118 0.111 0.120 0.122 0.123 0.130 0.133 0.143  ||  -0.056 -0.112 -0.041 -0.018 -0.012 0.042 0.067 0.136  || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.018 0.025 0.034 0.059 0.133 0.705  ||  -1.373 -1.138 -0.885 -0.570 -0.262 0.277 1.088 2.758  || dis=0.57 || select=7/8
014/019-th : 0.012 0.024 0.027 0.038 0.070 0.108 0.224 0.498  ||  -1.662 -0.970 -0.827 -0.503 0.116 0.551 1.279 2.079   || dis=0.27 || select=7/8
015/019-th : 0.009 0.013 0.016 0.021 0.030 0.053 0.144 0.715  ||  -1.520 -1.164 -0.922 -0.635 -0.303 0.281 1.278 2.879  || dis=0.57 || select=7/8
016/019-th : 0.050 0.063 0.085 0.112 0.131 0.166 0.186 0.207  ||  -0.821 -0.575 -0.276 -0.007 0.152 0.392 0.505 0.609   || dis=0.02 || select=7/8
017/019-th : 0.090 0.103 0.109 0.122 0.129 0.136 0.154 0.158  ||  -0.308 -0.171 -0.120 -0.004 0.052 0.105 0.228 0.255   || dis=0.00 || select=7/8
018/019-th : 0.080 0.104 0.115 0.131 0.133 0.136 0.144 0.157  ||  -0.420 -0.165 -0.064 0.072 0.080 0.104 0.165 0.249    || dis=0.01 || select=7/8
[epoch=381/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.136
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:03:48] [epoch=381/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.083 (2.083)  Prec@1 34.38 (34.38) Prec@5 79.30 (79.30) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:03:54] [epoch=381/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.487 (2.530)  Prec@1 29.76 (37.34) Prec@5 87.50 (80.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.34 Prec@5 80.52 Error@1 62.66 Error@5 19.48 Loss:2.530
***[2020-01-29 09:03:54]*** VALID [epoch=381/600] loss = 2.530036, accuracy@1 = 37.34, accuracy@5 = 80.52 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:03:54]*** start epoch=382/600 Time Left: [01:55:46], LR=[0.029186 ~ 0.029186], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=382, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5301120589620176, FLOP=40.81
[Search] : epoch=382/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:03:55] [epoch=382/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.635 (0.635)  Prec@1 77.73 (77.73) Prec@5 98.83 (98.83) Acls-loss 0.714 (0.714) FLOP-Loss 0.000 (0.000) Arch-Loss 0.714 (0.714)
**TRAIN** [2020-01-29 09:04:20] [epoch=382/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.553 (0.756)  Prec@1 80.95 (74.06) Prec@5 99.40 (98.16) Acls-loss 0.891 (0.809) FLOP-Loss 0.000 (0.207) Arch-Loss 0.891 (1.222)
 **TRAIN** Prec@1 74.06 Prec@5 98.16 Error@1 25.94 Error@5 1.84 Base-Loss:0.756, Arch-Loss=1.222
***[2020-01-29 09:04:20]*** TRAIN [epoch=382/600] base-loss = 0.755748, arch-loss = 1.222394, accuracy-1 = 74.06, accuracy-5 = 98.16
[epoch=382/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.404 0.211 0.384  ||  0.2179 -0.4299 0.1679  || discrepancy=0.02 || select=0/3
001/003-th : 0.324 0.154 0.522  ||  0.0558 -0.6910 0.5332  || discrepancy=0.20 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3304 -0.8800 2.8062  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.049 0.069 0.074 0.111 0.152 0.205 0.307  ||  -1.113 -0.691 -0.346 -0.281 0.128 0.442 0.742 1.144   || dis=0.10 || select=7/8
001/019-th : 0.104 0.126 0.137 0.130 0.137 0.127 0.122 0.118  ||  -0.174 0.017 0.099 0.054 0.099 0.025 -0.010 -0.050    || dis=0.00 || select=2/8
002/019-th : 0.125 0.129 0.136 0.131 0.127 0.123 0.117 0.112  ||  0.003 0.030 0.083 0.045 0.016 -0.019 -0.065 -0.114    || dis=0.01 || select=2/8
003/019-th : 0.100 0.109 0.128 0.127 0.129 0.131 0.135 0.141  ||  -0.218 -0.129 0.028 0.024 0.035 0.055 0.082 0.130     || dis=0.01 || select=7/8
004/019-th : 0.111 0.113 0.118 0.121 0.125 0.127 0.142 0.144  ||  -0.119 -0.098 -0.057 -0.026 0.006 0.020 0.129 0.146   || dis=0.00 || select=7/8
005/019-th : 0.106 0.120 0.123 0.124 0.128 0.131 0.128 0.139  ||  -0.160 -0.038 -0.010 -0.007 0.026 0.054 0.028 0.113   || dis=0.01 || select=7/8
006/019-th : 0.120 0.115 0.112 0.117 0.128 0.133 0.138 0.137  ||  -0.036 -0.075 -0.108 -0.061 0.029 0.064 0.100 0.096   || dis=0.00 || select=6/8
007/019-th : 0.028 0.039 0.067 0.079 0.131 0.142 0.192 0.322  ||  -1.200 -0.888 -0.345 -0.172 0.332 0.414 0.710 1.229   || dis=0.13 || select=7/8
008/019-th : 0.021 0.030 0.052 0.075 0.101 0.156 0.261 0.304  ||  -1.402 -1.036 -0.498 -0.129 0.167 0.603 1.116 1.269   || dis=0.04 || select=7/8
009/019-th : 0.069 0.083 0.099 0.115 0.125 0.142 0.165 0.201  ||  -0.536 -0.350 -0.175 -0.024 0.060 0.182 0.336 0.534   || dis=0.04 || select=7/8
010/019-th : 0.084 0.094 0.103 0.127 0.128 0.142 0.160 0.163  ||  -0.372 -0.264 -0.169 0.043 0.049 0.152 0.270 0.291    || dis=0.00 || select=7/8
011/019-th : 0.096 0.095 0.106 0.118 0.119 0.135 0.159 0.172  ||  -0.241 -0.253 -0.147 -0.034 -0.027 0.101 0.262 0.338  || dis=0.01 || select=7/8
012/019-th : 0.120 0.112 0.122 0.122 0.125 0.126 0.132 0.141  ||  -0.037 -0.103 -0.019 -0.025 0.004 0.009 0.057 0.122   || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.018 0.024 0.034 0.059 0.131 0.709  ||  -1.373 -1.149 -0.885 -0.593 -0.268 0.290 1.088 2.778  || dis=0.58 || select=7/8
014/019-th : 0.012 0.023 0.027 0.038 0.068 0.106 0.223 0.503  ||  -1.675 -0.982 -0.818 -0.491 0.096 0.547 1.287 2.100   || dis=0.28 || select=7/8
015/019-th : 0.008 0.012 0.016 0.021 0.030 0.053 0.144 0.715  ||  -1.554 -1.162 -0.919 -0.639 -0.296 0.288 1.285 2.885  || dis=0.57 || select=7/8
016/019-th : 0.050 0.065 0.085 0.114 0.132 0.164 0.185 0.205  ||  -0.811 -0.559 -0.279 0.014 0.160 0.375 0.492 0.595    || dis=0.02 || select=7/8
017/019-th : 0.090 0.102 0.110 0.123 0.129 0.136 0.154 0.158  ||  -0.311 -0.183 -0.109 0.004 0.052 0.104 0.229 0.254    || dis=0.00 || select=7/8
018/019-th : 0.082 0.105 0.116 0.132 0.132 0.136 0.144 0.152  ||  -0.400 -0.149 -0.055 0.077 0.074 0.101 0.164 0.219    || dis=0.01 || select=7/8
[epoch=382/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.136
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:04:21] [epoch=382/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.856 (2.856)  Prec@1 27.73 (27.73) Prec@5 81.25 (81.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:04:27] [epoch=382/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.896 (2.222)  Prec@1 53.57 (37.56) Prec@5 88.10 (80.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.56 Prec@5 80.66 Error@1 62.44 Error@5 19.34 Loss:2.222
***[2020-01-29 09:04:27]*** VALID [epoch=382/600] loss = 2.222383, accuracy@1 = 37.56, accuracy@5 = 80.66 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:04:27]*** start epoch=383/600 Time Left: [01:55:14], LR=[0.028948 ~ 0.028948], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=383, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5184622572496473, FLOP=40.81
[Search] : epoch=383/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:04:27] [epoch=383/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.613 (0.613)  Prec@1 82.81 (82.81) Prec@5 99.22 (99.22) Acls-loss 0.765 (0.765) FLOP-Loss 0.000 (0.000) Arch-Loss 0.765 (0.765)
**TRAIN** [2020-01-29 09:04:51] [epoch=383/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.555 (0.709)  Prec@1 79.76 (75.89) Prec@5 100.00 (98.34) Acls-loss 0.614 (0.794) FLOP-Loss 0.000 (0.207) Arch-Loss 0.614 (1.207)
 **TRAIN** Prec@1 75.89 Prec@5 98.34 Error@1 24.11 Error@5 1.66 Base-Loss:0.709, Arch-Loss=1.207
***[2020-01-29 09:04:51]*** TRAIN [epoch=383/600] base-loss = 0.708997, arch-loss = 1.206506, accuracy-1 = 75.89, accuracy-5 = 98.34
[epoch=383/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 8, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 29.221504)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.408 0.211 0.381  ||  0.2274 -0.4294 0.1583  || discrepancy=0.03 || select=0/3
001/003-th : 0.331 0.155 0.514  ||  0.0739 -0.6860 0.5149  || discrepancy=0.18 || select=2/3
002/003-th : 0.006 0.024 0.971  ||  -2.3457 -0.8845 2.8243  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.049 0.070 0.074 0.111 0.154 0.204 0.306  ||  -1.120 -0.694 -0.333 -0.285 0.123 0.456 0.736 1.142   || dis=0.10 || select=7/8
001/019-th : 0.104 0.127 0.135 0.132 0.136 0.128 0.123 0.116  ||  -0.171 0.023 0.091 0.063 0.092 0.032 -0.006 -0.064    || dis=0.00 || select=4/8
002/019-th : 0.128 0.129 0.136 0.132 0.126 0.122 0.116 0.111  ||  0.019 0.034 0.087 0.052 0.010 -0.025 -0.077 -0.122    || dis=0.00 || select=2/8
003/019-th : 0.101 0.110 0.128 0.126 0.128 0.130 0.136 0.142  ||  -0.209 -0.124 0.030 0.013 0.025 0.044 0.088 0.130     || dis=0.01 || select=7/8
004/019-th : 0.113 0.113 0.118 0.121 0.126 0.127 0.139 0.143  ||  -0.100 -0.096 -0.053 -0.029 0.013 0.022 0.108 0.140   || dis=0.00 || select=7/8
005/019-th : 0.108 0.122 0.122 0.124 0.128 0.131 0.128 0.138  ||  -0.147 -0.021 -0.021 -0.002 0.025 0.047 0.024 0.100   || dis=0.01 || select=7/8
006/019-th : 0.122 0.118 0.113 0.115 0.127 0.131 0.136 0.137  ||  -0.019 -0.056 -0.102 -0.077 0.022 0.050 0.088 0.095   || dis=0.00 || select=7/8
007/019-th : 0.029 0.038 0.067 0.081 0.130 0.141 0.191 0.323  ||  -1.194 -0.898 -0.341 -0.157 0.320 0.406 0.709 1.231   || dis=0.13 || select=7/8
008/019-th : 0.020 0.030 0.052 0.074 0.099 0.158 0.261 0.306  ||  -1.422 -1.045 -0.494 -0.129 0.159 0.626 1.128 1.286   || dis=0.04 || select=7/8
009/019-th : 0.071 0.083 0.096 0.117 0.126 0.143 0.166 0.199  ||  -0.516 -0.357 -0.205 -0.011 0.063 0.188 0.342 0.522   || dis=0.03 || select=7/8
010/019-th : 0.086 0.095 0.102 0.127 0.126 0.142 0.157 0.165  ||  -0.355 -0.249 -0.176 0.043 0.032 0.151 0.252 0.300    || dis=0.01 || select=7/8
011/019-th : 0.096 0.097 0.106 0.118 0.119 0.135 0.158 0.170  ||  -0.239 -0.235 -0.140 -0.039 -0.027 0.101 0.254 0.327  || dis=0.01 || select=7/8
012/019-th : 0.121 0.115 0.124 0.121 0.126 0.123 0.130 0.139  ||  -0.031 -0.084 -0.003 -0.027 0.014 -0.011 0.044 0.111  || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.018 0.024 0.033 0.058 0.130 0.712  ||  -1.372 -1.148 -0.896 -0.595 -0.269 0.278 1.094 2.792  || dis=0.58 || select=7/8
014/019-th : 0.012 0.023 0.027 0.038 0.067 0.107 0.222 0.505  ||  -1.670 -0.989 -0.838 -0.483 0.090 0.556 1.284 2.108   || dis=0.28 || select=7/8
015/019-th : 0.008 0.012 0.016 0.021 0.029 0.053 0.145 0.716  ||  -1.540 -1.200 -0.928 -0.643 -0.299 0.301 1.296 2.895  || dis=0.57 || select=7/8
016/019-th : 0.050 0.066 0.085 0.115 0.135 0.162 0.185 0.201  ||  -0.806 -0.541 -0.283 0.015 0.180 0.361 0.495 0.574    || dis=0.02 || select=7/8
017/019-th : 0.090 0.103 0.110 0.124 0.129 0.134 0.153 0.157  ||  -0.304 -0.174 -0.110 0.015 0.056 0.091 0.220 0.245    || dis=0.00 || select=7/8
018/019-th : 0.084 0.107 0.118 0.132 0.130 0.136 0.142 0.150  ||  -0.382 -0.141 -0.037 0.077 0.062 0.106 0.147 0.205    || dis=0.01 || select=7/8
[epoch=383/600] FLOP : 29.22 MB, ratio : 0.7160, Expected-ratio : 0.7000, Discrepancy : 0.136
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:04:52] [epoch=383/600][000/098] Time 0.58 (0.58) Data 0.41 (0.41) Loss 1.537 (1.537)  Prec@1 46.88 (46.88) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:04:58] [epoch=383/600][097/098] Time 0.06 (0.07) Data 0.00 (0.01) Loss 2.136 (2.079)  Prec@1 41.07 (40.19) Prec@5 86.90 (82.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.19 Prec@5 82.53 Error@1 59.81 Error@5 17.47 Loss:2.079
***[2020-01-29 09:04:58]*** VALID [epoch=383/600] loss = 2.079094, accuracy@1 = 40.19, accuracy@5 = 82.53 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:04:58]*** start epoch=384/600 Time Left: [01:54:42], LR=[0.028711 ~ 0.028711], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=384, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.5068407356655722, FLOP=40.81
[Search] : epoch=384/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:04:59] [epoch=384/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.718 (0.718)  Prec@1 75.00 (75.00) Prec@5 98.83 (98.83) Acls-loss 0.662 (0.662) FLOP-Loss 2.876 (2.876) Arch-Loss 6.415 (6.415)
**TRAIN** [2020-01-29 09:05:23] [epoch=384/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.583 (0.743)  Prec@1 80.36 (74.44) Prec@5 98.21 (98.12) Acls-loss 0.868 (0.777) FLOP-Loss 0.000 (0.177) Arch-Loss 0.868 (1.130)
 **TRAIN** Prec@1 74.44 Prec@5 98.12 Error@1 25.56 Error@5 1.88 Base-Loss:0.743, Arch-Loss=1.130
***[2020-01-29 09:05:23]*** TRAIN [epoch=384/600] base-loss = 0.743459, arch-loss = 1.130343, accuracy-1 = 74.44, accuracy-5 = 98.12
[epoch=384/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.410 0.214 0.376  ||  0.2342 -0.4150 0.1485  || discrepancy=0.03 || select=0/3
001/003-th : 0.336 0.158 0.505  ||  0.0894 -0.6643 0.4963  || discrepancy=0.17 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3481 -0.8726 2.8246  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.049 0.070 0.072 0.111 0.157 0.203 0.306  ||  -1.111 -0.696 -0.333 -0.303 0.126 0.474 0.727 1.138   || dis=0.10 || select=7/8
001/019-th : 0.105 0.129 0.136 0.132 0.136 0.126 0.122 0.114  ||  -0.162 0.041 0.092 0.064 0.091 0.016 -0.011 -0.078    || dis=0.00 || select=2/8
002/019-th : 0.130 0.130 0.137 0.132 0.125 0.121 0.115 0.109  ||  0.035 0.039 0.094 0.057 0.002 -0.033 -0.085 -0.134    || dis=0.01 || select=2/8
003/019-th : 0.101 0.111 0.130 0.125 0.128 0.131 0.134 0.140  ||  -0.212 -0.114 0.048 0.003 0.029 0.054 0.074 0.122     || dis=0.01 || select=7/8
004/019-th : 0.113 0.114 0.118 0.120 0.127 0.126 0.139 0.143  ||  -0.094 -0.090 -0.053 -0.039 0.017 0.012 0.112 0.137   || dis=0.00 || select=7/8
005/019-th : 0.107 0.123 0.123 0.125 0.128 0.130 0.128 0.136  ||  -0.149 -0.011 -0.016 0.002 0.023 0.043 0.029 0.089    || dis=0.01 || select=7/8
006/019-th : 0.124 0.120 0.112 0.117 0.127 0.132 0.135 0.133  ||  -0.007 -0.039 -0.104 -0.065 0.016 0.060 0.083 0.069   || dis=0.00 || select=6/8
007/019-th : 0.029 0.039 0.067 0.081 0.131 0.140 0.191 0.323  ||  -1.191 -0.889 -0.349 -0.150 0.325 0.395 0.702 1.229   || dis=0.13 || select=7/8
008/019-th : 0.020 0.030 0.051 0.075 0.097 0.159 0.261 0.308  ||  -1.429 -1.039 -0.511 -0.123 0.145 0.636 1.130 1.296   || dis=0.05 || select=7/8
009/019-th : 0.071 0.084 0.097 0.118 0.125 0.143 0.165 0.198  ||  -0.506 -0.343 -0.201 -0.004 0.052 0.185 0.330 0.514   || dis=0.03 || select=7/8
010/019-th : 0.086 0.097 0.104 0.128 0.126 0.142 0.157 0.162  ||  -0.354 -0.233 -0.165 0.045 0.030 0.148 0.249 0.285    || dis=0.01 || select=7/8
011/019-th : 0.097 0.099 0.106 0.118 0.120 0.134 0.157 0.170  ||  -0.232 -0.217 -0.146 -0.042 -0.023 0.088 0.248 0.324  || dis=0.01 || select=7/8
012/019-th : 0.122 0.117 0.126 0.123 0.125 0.123 0.129 0.137  ||  -0.025 -0.066 0.009 -0.014 0.002 -0.014 0.037 0.092   || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.018 0.024 0.033 0.057 0.131 0.712  ||  -1.364 -1.149 -0.886 -0.597 -0.279 0.273 1.098 2.792  || dis=0.58 || select=7/8
014/019-th : 0.012 0.022 0.027 0.038 0.067 0.106 0.219 0.510  ||  -1.664 -1.018 -0.834 -0.473 0.095 0.547 1.278 2.121   || dis=0.29 || select=7/8
015/019-th : 0.008 0.012 0.015 0.020 0.028 0.052 0.141 0.723  ||  -1.557 -1.194 -0.947 -0.645 -0.313 0.299 1.295 2.928  || dis=0.58 || select=7/8
016/019-th : 0.051 0.067 0.085 0.116 0.136 0.161 0.184 0.200  ||  -0.792 -0.530 -0.293 0.027 0.179 0.353 0.486 0.568    || dis=0.02 || select=7/8
017/019-th : 0.092 0.103 0.110 0.125 0.129 0.133 0.152 0.156  ||  -0.289 -0.177 -0.104 0.019 0.051 0.081 0.216 0.239    || dis=0.00 || select=7/8
018/019-th : 0.085 0.106 0.119 0.133 0.130 0.136 0.141 0.150  ||  -0.365 -0.146 -0.031 0.079 0.059 0.101 0.137 0.201    || dis=0.01 || select=7/8
[epoch=384/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.136
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:05:24] [epoch=384/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.209 (2.209)  Prec@1 28.52 (28.52) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:05:30] [epoch=384/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.219 (2.492)  Prec@1 22.02 (34.18) Prec@5 70.83 (77.46) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.18 Prec@5 77.46 Error@1 65.82 Error@5 22.54 Loss:2.492
***[2020-01-29 09:05:30]*** VALID [epoch=384/600] loss = 2.491521, accuracy@1 = 34.18, accuracy@5 = 77.46 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:05:30]*** start epoch=385/600 Time Left: [01:54:10], LR=[0.028474 ~ 0.028474], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=385, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4952478128196767, FLOP=40.81
[Search] : epoch=385/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:05:31] [epoch=385/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.801 (0.801)  Prec@1 72.27 (72.27) Prec@5 97.66 (97.66) Acls-loss 0.786 (0.786) FLOP-Loss 0.000 (0.000) Arch-Loss 0.786 (0.786)
**TRAIN** [2020-01-29 09:05:55] [epoch=385/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.724 (0.720)  Prec@1 76.19 (75.38) Prec@5 99.40 (98.16) Acls-loss 0.655 (0.778) FLOP-Loss 0.000 (0.059) Arch-Loss 0.655 (0.896)
 **TRAIN** Prec@1 75.38 Prec@5 98.16 Error@1 24.62 Error@5 1.84 Base-Loss:0.720, Arch-Loss=0.896
***[2020-01-29 09:05:55]*** TRAIN [epoch=385/600] base-loss = 0.719506, arch-loss = 0.895736, accuracy-1 = 75.38, accuracy-5 = 98.16
[epoch=385/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.404 0.216 0.380  ||  0.2211 -0.4061 0.1600  || discrepancy=0.02 || select=0/3
001/003-th : 0.334 0.158 0.507  ||  0.0842 -0.6636 0.5015  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.971  ||  -2.3586 -0.8845 2.8409  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.048 0.070 0.072 0.111 0.158 0.204 0.306  ||  -1.111 -0.718 -0.339 -0.300 0.130 0.482 0.735 1.142   || dis=0.10 || select=7/8
001/019-th : 0.106 0.127 0.136 0.131 0.134 0.128 0.122 0.115  ||  -0.158 0.025 0.095 0.058 0.081 0.036 -0.011 -0.075    || dis=0.00 || select=2/8
002/019-th : 0.130 0.129 0.137 0.131 0.126 0.122 0.115 0.110  ||  0.040 0.031 0.090 0.046 0.003 -0.030 -0.085 -0.126    || dis=0.01 || select=2/8
003/019-th : 0.101 0.110 0.128 0.125 0.129 0.131 0.133 0.142  ||  -0.204 -0.122 0.030 0.004 0.034 0.055 0.066 0.134     || dis=0.01 || select=7/8
004/019-th : 0.113 0.114 0.117 0.119 0.126 0.126 0.143 0.142  ||  -0.094 -0.092 -0.066 -0.044 0.010 0.015 0.136 0.133   || dis=0.00 || select=6/8
005/019-th : 0.105 0.123 0.122 0.123 0.127 0.130 0.130 0.139  ||  -0.168 -0.014 -0.019 -0.014 0.020 0.042 0.045 0.111   || dis=0.01 || select=7/8
006/019-th : 0.123 0.120 0.112 0.117 0.126 0.130 0.136 0.135  ||  -0.014 -0.041 -0.104 -0.066 0.014 0.045 0.088 0.082   || dis=0.00 || select=6/8
007/019-th : 0.029 0.038 0.065 0.080 0.129 0.139 0.193 0.325  ||  -1.185 -0.895 -0.364 -0.156 0.318 0.393 0.721 1.238   || dis=0.13 || select=7/8
008/019-th : 0.020 0.030 0.050 0.075 0.096 0.159 0.261 0.308  ||  -1.434 -1.035 -0.518 -0.115 0.136 0.640 1.131 1.299   || dis=0.05 || select=7/8
009/019-th : 0.071 0.084 0.097 0.118 0.124 0.143 0.165 0.197  ||  -0.506 -0.343 -0.199 -0.004 0.043 0.191 0.333 0.511   || dis=0.03 || select=7/8
010/019-th : 0.085 0.095 0.104 0.126 0.128 0.141 0.158 0.163  ||  -0.367 -0.245 -0.163 0.033 0.049 0.147 0.262 0.287    || dis=0.01 || select=7/8
011/019-th : 0.098 0.099 0.107 0.117 0.120 0.133 0.155 0.171  ||  -0.229 -0.213 -0.141 -0.045 -0.021 0.077 0.235 0.333  || dis=0.02 || select=7/8
012/019-th : 0.121 0.115 0.125 0.121 0.127 0.124 0.129 0.137  ||  -0.029 -0.078 0.007 -0.027 0.017 -0.002 0.034 0.098   || dis=0.01 || select=7/8
013/019-th : 0.011 0.014 0.018 0.024 0.033 0.057 0.129 0.715  ||  -1.359 -1.161 -0.887 -0.596 -0.269 0.267 1.090 2.805  || dis=0.59 || select=7/8
014/019-th : 0.011 0.022 0.026 0.038 0.065 0.104 0.218 0.514  ||  -1.666 -1.018 -0.837 -0.458 0.074 0.537 1.282 2.138   || dis=0.30 || select=7/8
015/019-th : 0.008 0.011 0.015 0.020 0.029 0.052 0.141 0.724  ||  -1.577 -1.208 -0.954 -0.629 -0.286 0.294 1.298 2.935  || dis=0.58 || select=7/8
016/019-th : 0.051 0.066 0.085 0.114 0.136 0.162 0.183 0.203  ||  -0.799 -0.541 -0.287 0.009 0.183 0.361 0.482 0.584    || dis=0.02 || select=7/8
017/019-th : 0.090 0.103 0.110 0.124 0.128 0.131 0.154 0.159  ||  -0.304 -0.171 -0.109 0.009 0.043 0.070 0.231 0.258    || dis=0.01 || select=7/8
018/019-th : 0.086 0.107 0.117 0.133 0.130 0.133 0.143 0.151  ||  -0.362 -0.142 -0.050 0.081 0.057 0.082 0.152 0.209    || dis=0.01 || select=7/8
[epoch=385/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.137
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:05:55] [epoch=385/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 1.411 (1.411)  Prec@1 62.11 (62.11) Prec@5 94.92 (94.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:06:02] [epoch=385/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.387 (2.279)  Prec@1 50.60 (39.43) Prec@5 89.88 (82.05) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.43 Prec@5 82.05 Error@1 60.57 Error@5 17.95 Loss:2.279
***[2020-01-29 09:06:02]*** VALID [epoch=385/600] loss = 2.279172, accuracy@1 = 39.43, accuracy@5 = 82.05 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:06:02]*** start epoch=386/600 Time Left: [01:53:38], LR=[0.028238 ~ 0.028238], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=386, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.483683806537798, FLOP=40.81
[Search] : epoch=386/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:06:02] [epoch=386/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.795 (0.795)  Prec@1 74.22 (74.22) Prec@5 98.44 (98.44) Acls-loss 0.918 (0.918) FLOP-Loss 0.000 (0.000) Arch-Loss 0.918 (0.918)
**TRAIN** [2020-01-29 09:06:26] [epoch=386/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.716 (0.718)  Prec@1 72.62 (75.32) Prec@5 97.62 (98.19) Acls-loss 0.676 (0.777) FLOP-Loss 0.000 (0.089) Arch-Loss 0.676 (0.954)
 **TRAIN** Prec@1 75.32 Prec@5 98.19 Error@1 24.68 Error@5 1.81 Base-Loss:0.718, Arch-Loss=0.954
***[2020-01-29 09:06:26]*** TRAIN [epoch=386/600] base-loss = 0.718384, arch-loss = 0.954239, accuracy-1 = 75.32, accuracy-5 = 98.19
[epoch=386/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.404 0.215 0.381  ||  0.2207 -0.4121 0.1619  || discrepancy=0.02 || select=0/3
001/003-th : 0.333 0.157 0.510  ||  0.0794 -0.6700 0.5077  || discrepancy=0.18 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3551 -0.9039 2.8474  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.047 0.068 0.072 0.112 0.156 0.202 0.311  ||  -1.109 -0.722 -0.357 -0.295 0.142 0.469 0.728 1.161   || dis=0.11 || select=7/8
001/019-th : 0.105 0.126 0.135 0.132 0.134 0.129 0.124 0.115  ||  -0.163 0.017 0.083 0.061 0.082 0.038 0.002 -0.070     || dis=0.00 || select=2/8
002/019-th : 0.130 0.129 0.135 0.132 0.127 0.122 0.116 0.110  ||  0.036 0.027 0.075 0.050 0.017 -0.026 -0.080 -0.126    || dis=0.00 || select=2/8
003/019-th : 0.100 0.109 0.127 0.125 0.128 0.132 0.135 0.143  ||  -0.215 -0.127 0.019 0.009 0.033 0.060 0.082 0.140     || dis=0.01 || select=7/8
004/019-th : 0.114 0.114 0.117 0.120 0.126 0.127 0.141 0.142  ||  -0.090 -0.087 -0.064 -0.036 0.010 0.020 0.121 0.129   || dis=0.00 || select=7/8
005/019-th : 0.105 0.124 0.124 0.122 0.127 0.128 0.130 0.139  ||  -0.172 -0.007 -0.002 -0.018 0.022 0.029 0.040 0.112   || dis=0.01 || select=7/8
006/019-th : 0.122 0.121 0.112 0.118 0.125 0.130 0.137 0.135  ||  -0.019 -0.026 -0.109 -0.059 0.003 0.043 0.092 0.080   || dis=0.00 || select=6/8
007/019-th : 0.029 0.038 0.065 0.081 0.127 0.139 0.194 0.325  ||  -1.179 -0.901 -0.365 -0.147 0.302 0.392 0.725 1.240   || dis=0.13 || select=7/8
008/019-th : 0.020 0.030 0.049 0.075 0.096 0.160 0.259 0.310  ||  -1.432 -1.035 -0.545 -0.109 0.135 0.648 1.129 1.309   || dis=0.05 || select=7/8
009/019-th : 0.072 0.085 0.097 0.116 0.124 0.143 0.166 0.198  ||  -0.503 -0.337 -0.203 -0.017 0.047 0.186 0.335 0.515   || dis=0.03 || select=7/8
010/019-th : 0.085 0.095 0.103 0.126 0.131 0.141 0.157 0.162  ||  -0.366 -0.249 -0.170 0.035 0.068 0.147 0.251 0.286    || dis=0.01 || select=7/8
011/019-th : 0.097 0.098 0.106 0.118 0.120 0.135 0.156 0.171  ||  -0.237 -0.219 -0.149 -0.040 -0.019 0.094 0.238 0.333  || dis=0.02 || select=7/8
012/019-th : 0.121 0.115 0.124 0.123 0.125 0.124 0.130 0.138  ||  -0.031 -0.084 -0.007 -0.011 0.007 -0.001 0.040 0.105  || dis=0.01 || select=7/8
013/019-th : 0.011 0.013 0.018 0.023 0.032 0.055 0.126 0.722  ||  -1.341 -1.160 -0.871 -0.618 -0.288 0.252 1.088 2.832  || dis=0.60 || select=7/8
014/019-th : 0.011 0.021 0.026 0.037 0.063 0.103 0.220 0.518  ||  -1.670 -1.030 -0.842 -0.474 0.057 0.544 1.304 2.161   || dis=0.30 || select=7/8
015/019-th : 0.008 0.011 0.015 0.020 0.029 0.051 0.140 0.726  ||  -1.593 -1.204 -0.953 -0.639 -0.285 0.291 1.304 2.948  || dis=0.59 || select=7/8
016/019-th : 0.050 0.066 0.084 0.113 0.134 0.162 0.184 0.205  ||  -0.812 -0.538 -0.295 0.003 0.175 0.364 0.489 0.598    || dis=0.02 || select=7/8
017/019-th : 0.089 0.102 0.109 0.124 0.128 0.133 0.154 0.162  ||  -0.317 -0.179 -0.120 0.012 0.042 0.079 0.231 0.280    || dis=0.01 || select=7/8
018/019-th : 0.085 0.105 0.118 0.133 0.129 0.135 0.144 0.152  ||  -0.371 -0.159 -0.040 0.077 0.053 0.094 0.160 0.211    || dis=0.01 || select=7/8
[epoch=386/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.138
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:06:27] [epoch=386/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.712 (2.712)  Prec@1 24.61 (24.61) Prec@5 81.25 (81.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:06:33] [epoch=386/600][097/098] Time 0.08 (0.06) Data 0.00 (0.00) Loss 1.590 (2.623)  Prec@1 63.10 (34.95) Prec@5 92.86 (78.39) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.95 Prec@5 78.39 Error@1 65.05 Error@5 21.61 Loss:2.623
***[2020-01-29 09:06:33]*** VALID [epoch=386/600] loss = 2.622875, accuracy@1 = 34.95, accuracy@5 = 78.39 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:06:33]*** start epoch=387/600 Time Left: [01:53:06], LR=[0.028003 ~ 0.028003], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=387, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4721490338530079, FLOP=40.81
[Search] : epoch=387/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:06:34] [epoch=387/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.617 (0.617)  Prec@1 78.12 (78.12) Prec@5 98.83 (98.83) Acls-loss 0.588 (0.588) FLOP-Loss 0.000 (0.000) Arch-Loss 0.588 (0.588)
**TRAIN** [2020-01-29 09:06:58] [epoch=387/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.889 (0.767)  Prec@1 72.02 (74.07) Prec@5 95.83 (97.98) Acls-loss 0.782 (0.775) FLOP-Loss 0.000 (0.177) Arch-Loss 0.782 (1.129)
 **TRAIN** Prec@1 74.07 Prec@5 97.98 Error@1 25.93 Error@5 2.02 Base-Loss:0.767, Arch-Loss=1.129
***[2020-01-29 09:06:58]*** TRAIN [epoch=387/600] base-loss = 0.766569, arch-loss = 1.128579, accuracy-1 = 74.07, accuracy-5 = 97.98
[epoch=387/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 11, 8, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 29.057664)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.406 0.217 0.377  ||  0.2277 -0.3994 0.1520  || discrepancy=0.03 || select=0/3
001/003-th : 0.334 0.161 0.505  ||  0.0857 -0.6464 0.4974  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3638 -0.8973 2.8554  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.047 0.068 0.072 0.113 0.154 0.200 0.313  ||  -1.115 -0.726 -0.353 -0.298 0.154 0.462 0.720 1.171   || dis=0.11 || select=7/8
001/019-th : 0.105 0.126 0.135 0.131 0.135 0.128 0.123 0.116  ||  -0.165 0.020 0.087 0.053 0.087 0.035 -0.007 -0.064    || dis=0.00 || select=4/8
002/019-th : 0.130 0.130 0.135 0.134 0.127 0.121 0.113 0.110  ||  0.039 0.040 0.081 0.069 0.018 -0.035 -0.098 -0.131    || dis=0.00 || select=2/8
003/019-th : 0.102 0.110 0.128 0.126 0.130 0.130 0.134 0.141  ||  -0.200 -0.125 0.029 0.011 0.043 0.045 0.072 0.127     || dis=0.01 || select=7/8
004/019-th : 0.115 0.114 0.118 0.121 0.124 0.129 0.139 0.141  ||  -0.079 -0.092 -0.054 -0.027 -0.004 0.032 0.108 0.123  || dis=0.00 || select=7/8
005/019-th : 0.106 0.123 0.126 0.122 0.126 0.130 0.128 0.138  ||  -0.164 -0.012 0.014 -0.023 0.013 0.046 0.029 0.103    || dis=0.01 || select=7/8
006/019-th : 0.123 0.123 0.112 0.117 0.127 0.132 0.134 0.133  ||  -0.010 -0.015 -0.102 -0.062 0.017 0.056 0.071 0.064   || dis=0.00 || select=6/8
007/019-th : 0.029 0.039 0.066 0.080 0.127 0.137 0.196 0.326  ||  -1.173 -0.891 -0.359 -0.160 0.300 0.375 0.731 1.239   || dis=0.13 || select=7/8
008/019-th : 0.020 0.030 0.048 0.076 0.096 0.162 0.259 0.309  ||  -1.441 -1.031 -0.551 -0.100 0.132 0.662 1.131 1.306   || dis=0.05 || select=7/8
009/019-th : 0.072 0.084 0.096 0.118 0.124 0.142 0.168 0.196  ||  -0.498 -0.342 -0.209 -0.006 0.048 0.180 0.347 0.506   || dis=0.03 || select=7/8
010/019-th : 0.084 0.095 0.104 0.127 0.131 0.140 0.158 0.161  ||  -0.368 -0.250 -0.161 0.041 0.074 0.138 0.260 0.275    || dis=0.00 || select=7/8
011/019-th : 0.097 0.100 0.105 0.117 0.121 0.134 0.156 0.169  ||  -0.233 -0.205 -0.153 -0.046 -0.010 0.089 0.242 0.320  || dis=0.01 || select=7/8
012/019-th : 0.122 0.116 0.124 0.123 0.124 0.124 0.129 0.137  ||  -0.021 -0.071 -0.002 -0.015 -0.003 -0.004 0.034 0.097  || dis=0.01 || select=7/8
013/019-th : 0.011 0.013 0.018 0.023 0.032 0.053 0.129 0.722  ||  -1.337 -1.160 -0.863 -0.630 -0.288 0.224 1.112 2.837  || dis=0.59 || select=7/8
014/019-th : 0.011 0.021 0.025 0.037 0.062 0.102 0.214 0.528  ||  -1.698 -1.037 -0.858 -0.470 0.062 0.553 1.296 2.197   || dis=0.31 || select=7/8
015/019-th : 0.008 0.011 0.015 0.020 0.028 0.050 0.140 0.729  ||  -1.599 -1.204 -0.954 -0.645 -0.299 0.291 1.309 2.963  || dis=0.59 || select=7/8
016/019-th : 0.050 0.066 0.084 0.115 0.137 0.160 0.185 0.204  ||  -0.812 -0.542 -0.300 0.016 0.191 0.349 0.494 0.591    || dis=0.02 || select=7/8
017/019-th : 0.089 0.102 0.110 0.125 0.127 0.133 0.153 0.161  ||  -0.320 -0.181 -0.104 0.020 0.034 0.081 0.224 0.275    || dis=0.01 || select=7/8
018/019-th : 0.086 0.106 0.119 0.129 0.130 0.136 0.143 0.152  ||  -0.360 -0.149 -0.035 0.046 0.059 0.097 0.152 0.210    || dis=0.01 || select=7/8
[epoch=387/600] FLOP : 29.06 MB, ratio : 0.7120, Expected-ratio : 0.7000, Discrepancy : 0.138
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:06:58] [epoch=387/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.532 (2.532)  Prec@1 57.81 (57.81) Prec@5 94.14 (94.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:07:04] [epoch=387/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.497 (2.510)  Prec@1 36.90 (36.76) Prec@5 81.55 (80.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.76 Prec@5 80.84 Error@1 63.24 Error@5 19.16 Loss:2.510
***[2020-01-29 09:07:04]*** VALID [epoch=387/600] loss = 2.509524, accuracy@1 = 36.76, accuracy@5 = 80.84 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:07:04]*** start epoch=388/600 Time Left: [01:52:34], LR=[0.027768 ~ 0.027768], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=388, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4606438109969284, FLOP=40.81
[Search] : epoch=388/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:07:05] [epoch=388/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.599 (0.599)  Prec@1 80.86 (80.86) Prec@5 98.44 (98.44) Acls-loss 0.687 (0.687) FLOP-Loss 2.877 (2.877) Arch-Loss 6.441 (6.441)
**TRAIN** [2020-01-29 09:07:30] [epoch=388/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.785 (0.729)  Prec@1 75.00 (75.04) Prec@5 97.62 (98.41) Acls-loss 0.667 (0.773) FLOP-Loss 0.000 (0.147) Arch-Loss 0.667 (1.068)
 **TRAIN** Prec@1 75.04 Prec@5 98.41 Error@1 24.96 Error@5 1.59 Base-Loss:0.729, Arch-Loss=1.068
***[2020-01-29 09:07:30]*** TRAIN [epoch=388/600] base-loss = 0.728945, arch-loss = 1.068050, accuracy-1 = 75.04, accuracy-5 = 98.41
[epoch=388/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.394112)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.401 0.222 0.377  ||  0.2185 -0.3747 0.1561  || discrepancy=0.02 || select=0/3
001/003-th : 0.337 0.161 0.502  ||  0.0915 -0.6464 0.4921  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3533 -0.9037 2.8507  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.032 0.048 0.068 0.073 0.115 0.154 0.198 0.312  ||  -1.107 -0.706 -0.362 -0.293 0.165 0.455 0.705 1.160   || dis=0.11 || select=7/8
001/019-th : 0.106 0.128 0.136 0.130 0.135 0.129 0.122 0.115  ||  -0.160 0.029 0.090 0.048 0.087 0.037 -0.016 -0.072    || dis=0.00 || select=2/8
002/019-th : 0.130 0.130 0.134 0.134 0.128 0.121 0.115 0.109  ||  0.037 0.042 0.074 0.069 0.025 -0.035 -0.087 -0.139    || dis=0.00 || select=2/8
003/019-th : 0.102 0.111 0.129 0.124 0.131 0.130 0.133 0.139  ||  -0.195 -0.112 0.036 0.001 0.050 0.047 0.064 0.113     || dis=0.01 || select=7/8
004/019-th : 0.114 0.113 0.118 0.120 0.123 0.130 0.141 0.141  ||  -0.092 -0.093 -0.052 -0.034 -0.016 0.042 0.127 0.123  || dis=0.00 || select=6/8
005/019-th : 0.107 0.125 0.125 0.122 0.127 0.130 0.127 0.138  ||  -0.157 -0.001 0.004 -0.025 0.019 0.045 0.015 0.103    || dis=0.01 || select=7/8
006/019-th : 0.124 0.123 0.113 0.115 0.127 0.132 0.134 0.132  ||  -0.006 -0.013 -0.094 -0.078 0.024 0.059 0.073 0.056   || dis=0.00 || select=6/8
007/019-th : 0.029 0.038 0.066 0.078 0.126 0.137 0.192 0.334  ||  -1.184 -0.896 -0.353 -0.184 0.301 0.381 0.721 1.272   || dis=0.14 || select=7/8
008/019-th : 0.020 0.030 0.048 0.075 0.097 0.162 0.258 0.311  ||  -1.436 -1.035 -0.556 -0.109 0.150 0.657 1.125 1.311   || dis=0.05 || select=7/8
009/019-th : 0.072 0.084 0.096 0.117 0.125 0.143 0.166 0.197  ||  -0.493 -0.349 -0.214 -0.011 0.054 0.190 0.340 0.508   || dis=0.03 || select=7/8
010/019-th : 0.085 0.094 0.104 0.129 0.131 0.139 0.157 0.160  ||  -0.363 -0.255 -0.158 0.053 0.075 0.131 0.255 0.273    || dis=0.00 || select=7/8
011/019-th : 0.097 0.099 0.106 0.118 0.122 0.133 0.157 0.168  ||  -0.232 -0.213 -0.146 -0.042 -0.005 0.082 0.247 0.315  || dis=0.01 || select=7/8
012/019-th : 0.121 0.116 0.125 0.123 0.126 0.124 0.129 0.137  ||  -0.025 -0.075 0.001 -0.014 0.009 -0.008 0.038 0.094   || dis=0.01 || select=7/8
013/019-th : 0.011 0.013 0.018 0.022 0.031 0.052 0.128 0.725  ||  -1.326 -1.159 -0.858 -0.638 -0.298 0.209 1.119 2.849  || dis=0.60 || select=7/8
014/019-th : 0.011 0.021 0.025 0.037 0.063 0.101 0.214 0.530  ||  -1.697 -1.037 -0.868 -0.470 0.071 0.543 1.298 2.204   || dis=0.32 || select=7/8
015/019-th : 0.007 0.011 0.014 0.019 0.027 0.050 0.139 0.732  ||  -1.607 -1.211 -0.952 -0.654 -0.303 0.289 1.317 2.979  || dis=0.59 || select=7/8
016/019-th : 0.051 0.066 0.082 0.116 0.137 0.159 0.185 0.203  ||  -0.803 -0.531 -0.317 0.025 0.195 0.342 0.495 0.584    || dis=0.02 || select=7/8
017/019-th : 0.089 0.100 0.111 0.127 0.125 0.133 0.153 0.162  ||  -0.314 -0.202 -0.102 0.034 0.023 0.086 0.225 0.278    || dis=0.01 || select=7/8
018/019-th : 0.086 0.105 0.118 0.131 0.131 0.136 0.143 0.150  ||  -0.362 -0.156 -0.040 0.061 0.066 0.101 0.155 0.202    || dis=0.01 || select=7/8
[epoch=388/600] FLOP : 28.39 MB, ratio : 0.6957, Expected-ratio : 0.7000, Discrepancy : 0.139
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:07:30] [epoch=388/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.835 (1.835)  Prec@1 37.50 (37.50) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:07:36] [epoch=388/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.832 (2.452)  Prec@1 54.76 (39.54) Prec@5 94.05 (82.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.54 Prec@5 82.40 Error@1 60.46 Error@5 17.60 Loss:2.452
***[2020-01-29 09:07:36]*** VALID [epoch=388/600] loss = 2.452090, accuracy@1 = 39.54, accuracy@5 = 82.40 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:07:36]*** start epoch=389/600 Time Left: [01:52:02], LR=[0.027534 ~ 0.027534], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=389, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.449168453391054, FLOP=40.81
[Search] : epoch=389/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:07:37] [epoch=389/600][000/098] Time 0.73 (0.73) Data 0.34 (0.34) Base-Loss 0.793 (0.793)  Prec@1 72.27 (72.27) Prec@5 98.44 (98.44) Acls-loss 0.854 (0.854) FLOP-Loss 0.000 (0.000) Arch-Loss 0.854 (0.854)
**TRAIN** [2020-01-29 09:08:02] [epoch=389/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.703 (0.722)  Prec@1 74.40 (75.61) Prec@5 97.62 (98.29) Acls-loss 0.710 (0.778) FLOP-Loss 0.000 (0.000) Arch-Loss 0.710 (0.778)
 **TRAIN** Prec@1 75.61 Prec@5 98.29 Error@1 24.39 Error@5 1.71 Base-Loss:0.722, Arch-Loss=0.778
***[2020-01-29 09:08:02]*** TRAIN [epoch=389/600] base-loss = 0.722150, arch-loss = 0.778440, accuracy-1 = 75.61, accuracy-5 = 98.29
[epoch=389/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.391 0.221 0.387  ||  0.1926 -0.3770 0.1831  || discrepancy=0.00 || select=0/3
001/003-th : 0.327 0.163 0.511  ||  0.0665 -0.6316 0.5136  || discrepancy=0.18 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3544 -0.9014 2.8533  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.048 0.067 0.072 0.113 0.153 0.202 0.314  ||  -1.153 -0.692 -0.369 -0.295 0.156 0.463 0.739 1.178   || dis=0.11 || select=7/8
001/019-th : 0.103 0.126 0.136 0.130 0.134 0.131 0.124 0.117  ||  -0.181 0.018 0.094 0.047 0.076 0.053 0.002 -0.060     || dis=0.00 || select=2/8
002/019-th : 0.129 0.130 0.132 0.133 0.128 0.121 0.117 0.111  ||  0.029 0.036 0.051 0.060 0.025 -0.034 -0.068 -0.122    || dis=0.00 || select=3/8
003/019-th : 0.101 0.113 0.126 0.125 0.130 0.131 0.133 0.141  ||  -0.212 -0.100 0.014 0.002 0.044 0.054 0.070 0.128     || dis=0.01 || select=7/8
004/019-th : 0.110 0.111 0.117 0.120 0.123 0.132 0.145 0.142  ||  -0.120 -0.114 -0.057 -0.040 -0.014 0.060 0.152 0.136  || dis=0.00 || select=6/8
005/019-th : 0.105 0.123 0.122 0.120 0.129 0.129 0.129 0.142  ||  -0.176 -0.010 -0.018 -0.039 0.035 0.033 0.037 0.133   || dis=0.01 || select=7/8
006/019-th : 0.121 0.120 0.112 0.114 0.128 0.133 0.137 0.136  ||  -0.031 -0.040 -0.110 -0.085 0.025 0.063 0.098 0.085   || dis=0.00 || select=6/8
007/019-th : 0.029 0.038 0.065 0.077 0.124 0.138 0.192 0.339  ||  -1.180 -0.899 -0.366 -0.190 0.283 0.391 0.723 1.291   || dis=0.15 || select=7/8
008/019-th : 0.020 0.030 0.048 0.073 0.097 0.159 0.261 0.313  ||  -1.435 -1.032 -0.556 -0.132 0.146 0.642 1.140 1.321   || dis=0.05 || select=7/8
009/019-th : 0.073 0.082 0.095 0.116 0.122 0.144 0.169 0.199  ||  -0.485 -0.364 -0.222 -0.018 0.035 0.198 0.355 0.520   || dis=0.03 || select=7/8
010/019-th : 0.085 0.094 0.104 0.126 0.132 0.139 0.159 0.163  ||  -0.362 -0.264 -0.159 0.032 0.077 0.129 0.264 0.288    || dis=0.00 || select=7/8
011/019-th : 0.097 0.098 0.106 0.118 0.121 0.133 0.157 0.170  ||  -0.230 -0.222 -0.148 -0.043 -0.013 0.084 0.248 0.325  || dis=0.01 || select=7/8
012/019-th : 0.118 0.114 0.123 0.124 0.127 0.124 0.132 0.138  ||  -0.050 -0.086 -0.009 -0.006 0.017 -0.001 0.058 0.101  || dis=0.01 || select=7/8
013/019-th : 0.011 0.013 0.018 0.022 0.031 0.051 0.125 0.730  ||  -1.312 -1.151 -0.852 -0.653 -0.303 0.206 1.102 2.869  || dis=0.60 || select=7/8
014/019-th : 0.011 0.020 0.024 0.036 0.062 0.099 0.211 0.538  ||  -1.698 -1.053 -0.864 -0.476 0.064 0.536 1.294 2.230   || dis=0.33 || select=7/8
015/019-th : 0.007 0.011 0.014 0.019 0.028 0.048 0.137 0.736  ||  -1.605 -1.220 -0.955 -0.660 -0.288 0.270 1.316 2.997  || dis=0.60 || select=7/8
016/019-th : 0.050 0.065 0.079 0.114 0.136 0.159 0.189 0.209  ||  -0.817 -0.545 -0.357 0.011 0.192 0.349 0.518 0.618    || dis=0.02 || select=7/8
017/019-th : 0.087 0.099 0.107 0.126 0.124 0.137 0.154 0.165  ||  -0.338 -0.208 -0.129 0.036 0.017 0.115 0.235 0.300    || dis=0.01 || select=7/8
018/019-th : 0.085 0.103 0.118 0.131 0.132 0.137 0.142 0.152  ||  -0.370 -0.176 -0.037 0.067 0.069 0.106 0.147 0.217    || dis=0.01 || select=7/8
[epoch=389/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.141
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:08:02] [epoch=389/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.570 (1.570)  Prec@1 54.30 (54.30) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:08:08] [epoch=389/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.718 (2.811)  Prec@1 18.45 (37.17) Prec@5 69.64 (79.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.17 Prec@5 79.43 Error@1 62.83 Error@5 20.57 Loss:2.811
***[2020-01-29 09:08:08]*** VALID [epoch=389/600] loss = 2.810906, accuracy@1 = 37.17, accuracy@5 = 79.43 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:08:09]*** start epoch=390/600 Time Left: [01:51:30], LR=[0.027300 ~ 0.027300], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=390, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4377232756381106, FLOP=40.81
[Search] : epoch=390/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:08:09] [epoch=390/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.458 (0.458)  Prec@1 85.16 (85.16) Prec@5 99.22 (99.22) Acls-loss 0.807 (0.807) FLOP-Loss 0.000 (0.000) Arch-Loss 0.807 (0.807)
**TRAIN** [2020-01-29 09:08:33] [epoch=390/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.950 (0.778)  Prec@1 67.86 (73.44) Prec@5 94.64 (97.79) Acls-loss 0.728 (0.816) FLOP-Loss 0.000 (0.178) Arch-Loss 0.728 (1.171)
 **TRAIN** Prec@1 73.44 Prec@5 97.79 Error@1 26.56 Error@5 2.21 Base-Loss:0.778, Arch-Loss=1.171
***[2020-01-29 09:08:33]*** TRAIN [epoch=390/600] base-loss = 0.777652, arch-loss = 1.171121, accuracy-1 = 73.44, accuracy-5 = 97.79
[epoch=390/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 14, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.391 0.219 0.390  ||  0.1917 -0.3889 0.1869  || discrepancy=0.00 || select=0/3
001/003-th : 0.326 0.163 0.511  ||  0.0647 -0.6289 0.5151  || discrepancy=0.18 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3642 -0.8823 2.8575  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.048 0.067 0.071 0.113 0.151 0.199 0.321  ||  -1.166 -0.688 -0.368 -0.302 0.161 0.453 0.728 1.206   || dis=0.12 || select=7/8
001/019-th : 0.105 0.126 0.137 0.130 0.133 0.129 0.123 0.116  ||  -0.165 0.019 0.099 0.046 0.074 0.037 -0.008 -0.064    || dis=0.00 || select=2/8
002/019-th : 0.128 0.130 0.131 0.135 0.128 0.121 0.116 0.111  ||  0.023 0.041 0.045 0.075 0.027 -0.034 -0.074 -0.120    || dis=0.00 || select=3/8
003/019-th : 0.099 0.112 0.127 0.125 0.130 0.133 0.133 0.141  ||  -0.230 -0.101 0.022 0.011 0.048 0.066 0.066 0.128     || dis=0.01 || select=7/8
004/019-th : 0.111 0.112 0.117 0.119 0.123 0.131 0.144 0.143  ||  -0.113 -0.102 -0.062 -0.049 -0.009 0.052 0.145 0.137  || dis=0.00 || select=6/8
005/019-th : 0.106 0.124 0.121 0.120 0.130 0.128 0.129 0.141  ||  -0.160 -0.006 -0.028 -0.041 0.045 0.028 0.030 0.124   || dis=0.01 || select=7/8
006/019-th : 0.122 0.119 0.111 0.113 0.130 0.130 0.138 0.137  ||  -0.026 -0.045 -0.112 -0.100 0.040 0.040 0.103 0.097   || dis=0.00 || select=6/8
007/019-th : 0.028 0.038 0.063 0.077 0.124 0.137 0.192 0.343  ||  -1.192 -0.901 -0.389 -0.186 0.290 0.391 0.730 1.311   || dis=0.15 || select=7/8
008/019-th : 0.019 0.029 0.048 0.073 0.097 0.161 0.261 0.311  ||  -1.456 -1.048 -0.554 -0.123 0.160 0.666 1.146 1.324   || dis=0.05 || select=7/8
009/019-th : 0.072 0.082 0.096 0.112 0.125 0.144 0.168 0.201  ||  -0.501 -0.366 -0.208 -0.055 0.060 0.197 0.353 0.534   || dis=0.03 || select=7/8
010/019-th : 0.085 0.094 0.106 0.127 0.132 0.139 0.158 0.160  ||  -0.359 -0.259 -0.145 0.038 0.080 0.127 0.261 0.269    || dis=0.00 || select=7/8
011/019-th : 0.099 0.100 0.106 0.118 0.122 0.132 0.155 0.168  ||  -0.218 -0.209 -0.144 -0.039 -0.004 0.070 0.233 0.315  || dis=0.01 || select=7/8
012/019-th : 0.119 0.116 0.123 0.124 0.127 0.123 0.131 0.136  ||  -0.042 -0.072 -0.009 -0.002 0.021 -0.009 0.054 0.089  || dis=0.01 || select=7/8
013/019-th : 0.011 0.013 0.017 0.021 0.030 0.050 0.122 0.735  ||  -1.291 -1.144 -0.854 -0.681 -0.308 0.205 1.096 2.891  || dis=0.61 || select=7/8
014/019-th : 0.010 0.020 0.024 0.035 0.062 0.097 0.211 0.540  ||  -1.700 -1.060 -0.867 -0.493 0.079 0.523 1.303 2.243   || dis=0.33 || select=7/8
015/019-th : 0.007 0.011 0.014 0.019 0.027 0.048 0.132 0.743  ||  -1.599 -1.209 -0.955 -0.659 -0.304 0.272 1.290 3.019  || dis=0.61 || select=7/8
016/019-th : 0.050 0.065 0.079 0.113 0.136 0.161 0.188 0.208  ||  -0.804 -0.551 -0.354 0.007 0.191 0.359 0.512 0.613    || dis=0.02 || select=7/8
017/019-th : 0.087 0.100 0.109 0.124 0.124 0.138 0.155 0.163  ||  -0.338 -0.196 -0.118 0.016 0.016 0.122 0.239 0.287    || dis=0.01 || select=7/8
018/019-th : 0.085 0.104 0.118 0.133 0.130 0.135 0.142 0.152  ||  -0.366 -0.165 -0.041 0.079 0.060 0.094 0.145 0.215    || dis=0.01 || select=7/8
[epoch=390/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.142
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:08:34] [epoch=390/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.728 (1.728)  Prec@1 47.27 (47.27) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:08:40] [epoch=390/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.202 (2.472)  Prec@1 17.26 (38.24) Prec@5 60.12 (81.98) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.24 Prec@5 81.98 Error@1 61.76 Error@5 18.02 Loss:2.472
***[2020-01-29 09:08:40]*** VALID [epoch=390/600] loss = 2.471667, accuracy@1 = 38.24, accuracy@5 = 81.98 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:08:40]*** start epoch=391/600 Time Left: [01:50:58], LR=[0.027068 ~ 0.027068], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=391, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4263085915134295, FLOP=40.81
[Search] : epoch=391/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:08:40] [epoch=391/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.687 (0.687)  Prec@1 78.52 (78.52) Prec@5 98.44 (98.44) Acls-loss 0.684 (0.684) FLOP-Loss 0.000 (0.000) Arch-Loss 0.684 (0.684)
**TRAIN** [2020-01-29 09:09:05] [epoch=391/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.715 (0.752)  Prec@1 76.19 (74.37) Prec@5 97.62 (98.11) Acls-loss 0.671 (0.764) FLOP-Loss 0.000 (0.266) Arch-Loss 0.671 (1.296)
 **TRAIN** Prec@1 74.37 Prec@5 98.11 Error@1 25.63 Error@5 1.89 Base-Loss:0.752, Arch-Loss=1.296
***[2020-01-29 09:09:05]*** TRAIN [epoch=391/600] base-loss = 0.752070, arch-loss = 1.296041, accuracy-1 = 74.37, accuracy-5 = 98.11
[epoch=391/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.394 0.223 0.382  ||  0.2023 -0.3674 0.1712  || discrepancy=0.01 || select=0/3
001/003-th : 0.335 0.165 0.501  ||  0.0885 -0.6219 0.4907  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3551 -0.8684 2.8462  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.048 0.068 0.071 0.113 0.150 0.199 0.320  ||  -1.152 -0.695 -0.354 -0.305 0.159 0.441 0.724 1.200   || dis=0.12 || select=7/8
001/019-th : 0.108 0.128 0.140 0.130 0.132 0.127 0.121 0.113  ||  -0.143 0.033 0.123 0.048 0.064 0.022 -0.024 -0.090    || dis=0.01 || select=2/8
002/019-th : 0.130 0.133 0.134 0.134 0.127 0.118 0.114 0.109  ||  0.042 0.059 0.066 0.072 0.013 -0.054 -0.090 -0.135    || dis=0.00 || select=3/8
003/019-th : 0.100 0.113 0.127 0.127 0.131 0.133 0.131 0.139  ||  -0.216 -0.095 0.019 0.023 0.051 0.066 0.051 0.112     || dis=0.01 || select=7/8
004/019-th : 0.114 0.113 0.118 0.121 0.123 0.129 0.140 0.143  ||  -0.089 -0.101 -0.052 -0.032 -0.015 0.031 0.120 0.137  || dis=0.00 || select=7/8
005/019-th : 0.109 0.125 0.123 0.121 0.129 0.128 0.127 0.138  ||  -0.139 0.004 -0.015 -0.031 0.033 0.022 0.020 0.099    || dis=0.01 || select=7/8
006/019-th : 0.125 0.122 0.113 0.113 0.129 0.126 0.136 0.136  ||  0.000 -0.021 -0.098 -0.098 0.032 0.013 0.084 0.084    || dis=0.00 || select=6/8
007/019-th : 0.028 0.038 0.062 0.078 0.125 0.136 0.192 0.342  ||  -1.193 -0.893 -0.400 -0.175 0.297 0.384 0.730 1.306   || dis=0.15 || select=7/8
008/019-th : 0.019 0.029 0.047 0.073 0.097 0.160 0.259 0.316  ||  -1.461 -1.050 -0.558 -0.120 0.159 0.663 1.143 1.342   || dis=0.06 || select=7/8
009/019-th : 0.072 0.083 0.097 0.111 0.125 0.143 0.168 0.200  ||  -0.495 -0.357 -0.199 -0.061 0.059 0.190 0.353 0.525   || dis=0.03 || select=7/8
010/019-th : 0.087 0.096 0.108 0.128 0.131 0.139 0.156 0.156  ||  -0.342 -0.246 -0.124 0.046 0.067 0.128 0.244 0.248    || dis=0.00 || select=7/8
011/019-th : 0.100 0.100 0.109 0.120 0.123 0.132 0.152 0.164  ||  -0.210 -0.204 -0.124 -0.024 0.003 0.074 0.215 0.288   || dis=0.01 || select=7/8
012/019-th : 0.121 0.118 0.124 0.124 0.127 0.121 0.131 0.133  ||  -0.027 -0.051 -0.002 -0.001 0.025 -0.026 0.049 0.067  || dis=0.00 || select=7/8
013/019-th : 0.011 0.013 0.017 0.021 0.029 0.049 0.120 0.739  ||  -1.294 -1.147 -0.840 -0.670 -0.322 0.190 1.091 2.906  || dis=0.62 || select=7/8
014/019-th : 0.011 0.020 0.024 0.035 0.063 0.096 0.208 0.543  ||  -1.697 -1.062 -0.862 -0.495 0.087 0.515 1.289 2.248   || dis=0.34 || select=7/8
015/019-th : 0.007 0.011 0.014 0.019 0.027 0.047 0.130 0.746  ||  -1.603 -1.221 -0.944 -0.656 -0.301 0.267 1.283 3.031  || dis=0.62 || select=7/8
016/019-th : 0.052 0.066 0.080 0.113 0.136 0.159 0.187 0.206  ||  -0.784 -0.538 -0.342 0.003 0.186 0.345 0.505 0.601    || dis=0.02 || select=7/8
017/019-th : 0.088 0.102 0.109 0.125 0.125 0.137 0.153 0.160  ||  -0.327 -0.182 -0.115 0.023 0.024 0.114 0.224 0.271    || dis=0.01 || select=7/8
018/019-th : 0.085 0.107 0.117 0.134 0.132 0.135 0.142 0.149  ||  -0.366 -0.142 -0.052 0.086 0.070 0.094 0.149 0.193    || dis=0.01 || select=7/8
[epoch=391/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.142
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:09:05] [epoch=391/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.767 (2.767)  Prec@1 17.97 (17.97) Prec@5 67.97 (67.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:09:11] [epoch=391/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.787 (2.236)  Prec@1 39.88 (38.04) Prec@5 85.12 (81.77) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.04 Prec@5 81.77 Error@1 61.96 Error@5 18.23 Loss:2.236
***[2020-01-29 09:09:11]*** VALID [epoch=391/600] loss = 2.235615, accuracy@1 = 38.04, accuracy@5 = 81.77 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:09:11]*** start epoch=392/600 Time Left: [01:50:26], LR=[0.026835 ~ 0.026835], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=392, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4149247139563395, FLOP=40.81
[Search] : epoch=392/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:09:12] [epoch=392/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.664 (0.664)  Prec@1 78.52 (78.52) Prec@5 98.05 (98.05) Acls-loss 0.816 (0.816) FLOP-Loss 0.000 (0.000) Arch-Loss 0.816 (0.816)
**TRAIN** [2020-01-29 09:09:36] [epoch=392/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.669 (0.717)  Prec@1 76.19 (75.25) Prec@5 98.21 (98.42) Acls-loss 0.771 (0.757) FLOP-Loss 0.000 (0.030) Arch-Loss 0.771 (0.816)
 **TRAIN** Prec@1 75.25 Prec@5 98.42 Error@1 24.75 Error@5 1.58 Base-Loss:0.717, Arch-Loss=0.816
***[2020-01-29 09:09:36]*** TRAIN [epoch=392/600] base-loss = 0.716724, arch-loss = 0.816403, accuracy-1 = 75.25, accuracy-5 = 98.42
[epoch=392/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.389 0.222 0.389  ||  0.1874 -0.3711 0.1872  || discrepancy=0.00 || select=0/3
001/003-th : 0.327 0.164 0.508  ||  0.0691 -0.6208 0.5096  || discrepancy=0.18 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3669 -0.8761 2.8624  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.048 0.067 0.070 0.111 0.149 0.200 0.325  ||  -1.159 -0.698 -0.364 -0.317 0.150 0.441 0.738 1.222   || dis=0.12 || select=7/8
001/019-th : 0.104 0.126 0.141 0.131 0.133 0.128 0.123 0.114  ||  -0.173 0.022 0.130 0.056 0.070 0.034 -0.006 -0.081    || dis=0.01 || select=2/8
002/019-th : 0.128 0.130 0.133 0.133 0.129 0.121 0.116 0.111  ||  0.027 0.042 0.059 0.059 0.031 -0.034 -0.078 -0.123    || dis=0.00 || select=3/8
003/019-th : 0.099 0.109 0.126 0.126 0.132 0.134 0.133 0.142  ||  -0.224 -0.131 0.013 0.018 0.064 0.075 0.067 0.135     || dis=0.01 || select=7/8
004/019-th : 0.113 0.112 0.117 0.119 0.124 0.129 0.140 0.145  ||  -0.094 -0.106 -0.061 -0.046 -0.003 0.034 0.120 0.151  || dis=0.00 || select=7/8
005/019-th : 0.109 0.124 0.121 0.122 0.129 0.128 0.129 0.139  ||  -0.140 -0.009 -0.035 -0.021 0.036 0.021 0.033 0.107   || dis=0.01 || select=7/8
006/019-th : 0.123 0.122 0.113 0.113 0.128 0.127 0.138 0.136  ||  -0.012 -0.023 -0.101 -0.095 0.025 0.016 0.099 0.086   || dis=0.00 || select=6/8
007/019-th : 0.028 0.038 0.061 0.076 0.124 0.135 0.192 0.344  ||  -1.188 -0.879 -0.411 -0.190 0.294 0.381 0.731 1.315   || dis=0.15 || select=7/8
008/019-th : 0.019 0.029 0.047 0.072 0.096 0.157 0.260 0.319  ||  -1.472 -1.052 -0.559 -0.124 0.161 0.653 1.156 1.359   || dis=0.06 || select=7/8
009/019-th : 0.070 0.083 0.097 0.110 0.127 0.144 0.169 0.200  ||  -0.517 -0.351 -0.201 -0.072 0.072 0.197 0.360 0.528   || dis=0.03 || select=7/8
010/019-th : 0.086 0.095 0.106 0.127 0.131 0.139 0.156 0.159  ||  -0.348 -0.255 -0.138 0.038 0.069 0.133 0.248 0.266    || dis=0.00 || select=7/8
011/019-th : 0.099 0.100 0.108 0.118 0.125 0.134 0.153 0.164  ||  -0.217 -0.209 -0.129 -0.040 0.014 0.084 0.223 0.290   || dis=0.01 || select=7/8
012/019-th : 0.120 0.116 0.122 0.125 0.127 0.123 0.132 0.135  ||  -0.037 -0.068 -0.018 0.001 0.017 -0.010 0.061 0.081   || dis=0.00 || select=7/8
013/019-th : 0.011 0.013 0.017 0.020 0.029 0.048 0.117 0.744  ||  -1.279 -1.137 -0.833 -0.671 -0.329 0.179 1.074 2.922  || dis=0.63 || select=7/8
014/019-th : 0.011 0.020 0.024 0.034 0.061 0.094 0.210 0.546  ||  -1.690 -1.063 -0.865 -0.508 0.076 0.501 1.304 2.261   || dis=0.34 || select=7/8
015/019-th : 0.007 0.010 0.014 0.018 0.026 0.045 0.128 0.752  ||  -1.610 -1.221 -0.945 -0.655 -0.299 0.238 1.284 3.058  || dis=0.62 || select=7/8
016/019-th : 0.051 0.065 0.078 0.112 0.135 0.161 0.188 0.210  ||  -0.793 -0.549 -0.369 -0.008 0.185 0.359 0.515 0.626   || dis=0.02 || select=7/8
017/019-th : 0.087 0.101 0.109 0.125 0.125 0.138 0.153 0.163  ||  -0.334 -0.194 -0.119 0.020 0.021 0.118 0.225 0.291    || dis=0.01 || select=7/8
018/019-th : 0.083 0.105 0.116 0.133 0.132 0.136 0.142 0.153  ||  -0.393 -0.153 -0.057 0.078 0.074 0.105 0.147 0.220    || dis=0.01 || select=7/8
[epoch=392/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.144
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:09:37] [epoch=392/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.716 (2.716)  Prec@1 16.02 (16.02) Prec@5 73.44 (73.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:09:43] [epoch=392/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.311 (2.794)  Prec@1 55.36 (36.02) Prec@5 90.48 (79.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.02 Prec@5 79.34 Error@1 63.98 Error@5 20.66 Loss:2.794
***[2020-01-29 09:09:43]*** VALID [epoch=392/600] loss = 2.794490, accuracy@1 = 36.02, accuracy@5 = 79.34 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:09:43]*** start epoch=393/600 Time Left: [01:49:54], LR=[0.026604 ~ 0.026604], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=393, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.4035719550615957, FLOP=40.81
[Search] : epoch=393/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:09:44] [epoch=393/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.718 (0.718)  Prec@1 73.83 (73.83) Prec@5 98.44 (98.44) Acls-loss 0.793 (0.793) FLOP-Loss 0.000 (0.000) Arch-Loss 0.793 (0.793)
**TRAIN** [2020-01-29 09:10:08] [epoch=393/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.624 (0.724)  Prec@1 80.36 (75.54) Prec@5 99.40 (98.23) Acls-loss 1.096 (0.778) FLOP-Loss 0.000 (0.472) Arch-Loss 1.096 (1.723)
 **TRAIN** Prec@1 75.54 Prec@5 98.23 Error@1 24.46 Error@5 1.77 Base-Loss:0.724, Arch-Loss=1.723
***[2020-01-29 09:10:08]*** TRAIN [epoch=393/600] base-loss = 0.723840, arch-loss = 1.722653, accuracy-1 = 75.54, accuracy-5 = 98.23
[epoch=393/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.405 0.222 0.374  ||  0.2269 -0.3748 0.1481  || discrepancy=0.03 || select=0/3
001/003-th : 0.343 0.166 0.491  ||  0.1093 -0.6125 0.4690  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.023 0.971  ||  -2.3608 -0.8685 2.8565  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.030 0.047 0.065 0.070 0.110 0.148 0.200 0.329  ||  -1.168 -0.702 -0.382 -0.314 0.148 0.445 0.744 1.242   || dis=0.13 || select=7/8
001/019-th : 0.107 0.130 0.144 0.135 0.131 0.124 0.120 0.109  ||  -0.148 0.052 0.150 0.086 0.061 0.005 -0.027 -0.123    || dis=0.01 || select=2/8
002/019-th : 0.135 0.136 0.135 0.136 0.126 0.116 0.111 0.105  ||  0.075 0.084 0.077 0.086 0.009 -0.074 -0.115 -0.169    || dis=0.00 || select=3/8
003/019-th : 0.102 0.113 0.128 0.128 0.130 0.133 0.129 0.137  ||  -0.194 -0.100 0.026 0.033 0.048 0.069 0.035 0.094     || dis=0.00 || select=7/8
004/019-th : 0.119 0.116 0.120 0.121 0.122 0.126 0.136 0.140  ||  -0.047 -0.074 -0.038 -0.028 -0.019 0.007 0.086 0.117  || dis=0.00 || select=7/8
005/019-th : 0.111 0.128 0.123 0.125 0.130 0.125 0.126 0.133  ||  -0.115 0.026 -0.016 -0.002 0.039 -0.000 0.007 0.063   || dis=0.00 || select=7/8
006/019-th : 0.129 0.126 0.115 0.116 0.126 0.123 0.132 0.133  ||  0.034 0.006 -0.080 -0.077 0.005 -0.012 0.059 0.063    || dis=0.00 || select=7/8
007/019-th : 0.028 0.039 0.063 0.077 0.121 0.136 0.196 0.340  ||  -1.185 -0.877 -0.388 -0.190 0.268 0.379 0.748 1.299   || dis=0.14 || select=7/8
008/019-th : 0.019 0.028 0.047 0.072 0.097 0.159 0.258 0.321  ||  -1.463 -1.059 -0.555 -0.138 0.164 0.659 1.145 1.363   || dis=0.06 || select=7/8
009/019-th : 0.073 0.086 0.099 0.111 0.128 0.143 0.166 0.195  ||  -0.490 -0.324 -0.180 -0.069 0.072 0.184 0.333 0.492   || dis=0.03 || select=7/8
010/019-th : 0.088 0.097 0.108 0.129 0.132 0.138 0.153 0.155  ||  -0.327 -0.230 -0.127 0.056 0.074 0.119 0.222 0.238    || dis=0.00 || select=7/8
011/019-th : 0.102 0.104 0.111 0.119 0.123 0.133 0.150 0.158  ||  -0.184 -0.170 -0.103 -0.031 -0.004 0.073 0.197 0.247  || dis=0.01 || select=7/8
012/019-th : 0.126 0.120 0.126 0.126 0.124 0.121 0.126 0.130  ||  0.014 -0.034 0.014 0.008 -0.000 -0.025 0.009 0.045    || dis=0.00 || select=7/8
013/019-th : 0.011 0.013 0.017 0.020 0.029 0.047 0.120 0.743  ||  -1.278 -1.130 -0.840 -0.684 -0.319 0.165 1.093 2.920  || dis=0.62 || select=7/8
014/019-th : 0.010 0.020 0.024 0.034 0.061 0.096 0.210 0.546  ||  -1.698 -1.057 -0.865 -0.519 0.070 0.520 1.305 2.262   || dis=0.34 || select=7/8
015/019-th : 0.007 0.010 0.014 0.018 0.026 0.044 0.130 0.751  ||  -1.604 -1.228 -0.952 -0.658 -0.312 0.230 1.306 3.063  || dis=0.62 || select=7/8
016/019-th : 0.051 0.066 0.080 0.115 0.138 0.160 0.183 0.206  ||  -0.788 -0.532 -0.347 0.017 0.197 0.349 0.485 0.602    || dis=0.02 || select=7/8
017/019-th : 0.091 0.100 0.111 0.128 0.128 0.136 0.150 0.156  ||  -0.300 -0.201 -0.095 0.042 0.048 0.101 0.200 0.244    || dis=0.01 || select=7/8
018/019-th : 0.085 0.108 0.119 0.135 0.130 0.134 0.139 0.150  ||  -0.365 -0.129 -0.032 0.092 0.056 0.087 0.124 0.196    || dis=0.01 || select=7/8
[epoch=393/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.143
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:10:09] [epoch=393/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.307 (1.307)  Prec@1 56.25 (56.25) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:10:15] [epoch=393/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.836 (2.550)  Prec@1 34.52 (36.10) Prec@5 85.71 (80.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.10 Prec@5 80.34 Error@1 63.90 Error@5 19.66 Loss:2.550
***[2020-01-29 09:10:15]*** VALID [epoch=393/600] loss = 2.550062, accuracy@1 = 36.10, accuracy@5 = 80.34 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:10:15]*** start epoch=394/600 Time Left: [01:49:22], LR=[0.026372 ~ 0.026372], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=394, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.392250626070818, FLOP=40.81
[Search] : epoch=394/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:10:15] [epoch=394/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.852 (0.852)  Prec@1 70.70 (70.70) Prec@5 97.27 (97.27) Acls-loss 0.851 (0.851) FLOP-Loss 2.873 (2.873) Arch-Loss 6.598 (6.598)
**TRAIN** [2020-01-29 09:10:40] [epoch=394/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.691 (0.731)  Prec@1 77.98 (74.86) Prec@5 97.02 (98.12) Acls-loss 0.682 (0.773) FLOP-Loss 0.000 (0.176) Arch-Loss 0.682 (1.125)
 **TRAIN** Prec@1 74.86 Prec@5 98.12 Error@1 25.14 Error@5 1.88 Base-Loss:0.731, Arch-Loss=1.125
***[2020-01-29 09:10:40]*** TRAIN [epoch=394/600] base-loss = 0.730690, arch-loss = 1.125363, accuracy-1 = 74.86, accuracy-5 = 98.12
[epoch=394/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.404 0.223 0.373  ||  0.2258 -0.3665 0.1475  || discrepancy=0.03 || select=0/3
001/003-th : 0.342 0.166 0.492  ||  0.1068 -0.6148 0.4721  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3513 -0.8672 2.8498  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.029 0.046 0.064 0.069 0.109 0.149 0.203 0.330  ||  -1.187 -0.711 -0.387 -0.312 0.146 0.453 0.767 1.253   || dis=0.13 || select=7/8
001/019-th : 0.107 0.130 0.145 0.135 0.131 0.123 0.120 0.109  ||  -0.143 0.048 0.157 0.091 0.058 -0.005 -0.026 -0.126   || dis=0.01 || select=2/8
002/019-th : 0.135 0.137 0.135 0.137 0.124 0.115 0.112 0.105  ||  0.081 0.091 0.074 0.093 -0.008 -0.080 -0.107 -0.177   || dis=0.00 || select=3/8
003/019-th : 0.104 0.113 0.126 0.127 0.130 0.135 0.129 0.135  ||  -0.182 -0.096 0.015 0.022 0.044 0.084 0.036 0.083     || dis=0.00 || select=5/8
004/019-th : 0.119 0.115 0.119 0.122 0.124 0.126 0.136 0.139  ||  -0.045 -0.080 -0.043 -0.020 -0.009 0.009 0.089 0.109  || dis=0.00 || select=7/8
005/019-th : 0.111 0.129 0.123 0.125 0.129 0.125 0.126 0.131  ||  -0.116 0.035 -0.012 0.001 0.036 0.003 0.010 0.051     || dis=0.00 || select=7/8
006/019-th : 0.130 0.126 0.116 0.116 0.126 0.124 0.132 0.131  ||  0.042 0.006 -0.075 -0.076 0.007 -0.004 0.056 0.048    || dis=0.00 || select=6/8
007/019-th : 0.028 0.038 0.063 0.076 0.121 0.136 0.199 0.340  ||  -1.198 -0.891 -0.378 -0.197 0.267 0.385 0.767 1.303   || dis=0.14 || select=7/8
008/019-th : 0.019 0.028 0.047 0.073 0.097 0.158 0.255 0.324  ||  -1.470 -1.071 -0.562 -0.120 0.167 0.656 1.139 1.378   || dis=0.07 || select=7/8
009/019-th : 0.074 0.087 0.099 0.110 0.126 0.141 0.165 0.196  ||  -0.471 -0.313 -0.183 -0.076 0.059 0.170 0.325 0.499   || dis=0.03 || select=7/8
010/019-th : 0.089 0.096 0.109 0.129 0.132 0.138 0.153 0.154  ||  -0.316 -0.243 -0.118 0.056 0.074 0.119 0.224 0.229    || dis=0.00 || select=7/8
011/019-th : 0.104 0.105 0.110 0.119 0.123 0.131 0.149 0.158  ||  -0.171 -0.157 -0.113 -0.034 -0.006 0.062 0.191 0.248  || dis=0.01 || select=7/8
012/019-th : 0.126 0.120 0.126 0.124 0.126 0.123 0.126 0.130  ||  0.014 -0.034 0.009 -0.008 0.011 -0.014 0.013 0.040    || dis=0.00 || select=7/8
013/019-th : 0.011 0.013 0.017 0.020 0.029 0.046 0.117 0.747  ||  -1.298 -1.121 -0.837 -0.680 -0.313 0.152 1.086 2.937  || dis=0.63 || select=7/8
014/019-th : 0.010 0.019 0.024 0.033 0.059 0.095 0.208 0.552  ||  -1.686 -1.086 -0.867 -0.531 0.058 0.523 1.309 2.286   || dis=0.34 || select=7/8
015/019-th : 0.007 0.010 0.014 0.018 0.026 0.043 0.129 0.753  ||  -1.608 -1.231 -0.939 -0.659 -0.307 0.215 1.306 3.070  || dis=0.62 || select=7/8
016/019-th : 0.052 0.067 0.079 0.113 0.137 0.160 0.184 0.208  ||  -0.778 -0.524 -0.361 0.001 0.196 0.345 0.487 0.610    || dis=0.02 || select=7/8
017/019-th : 0.091 0.102 0.109 0.128 0.131 0.136 0.148 0.155  ||  -0.299 -0.185 -0.113 0.046 0.064 0.106 0.188 0.238    || dis=0.01 || select=7/8
018/019-th : 0.085 0.108 0.119 0.134 0.130 0.133 0.139 0.151  ||  -0.364 -0.129 -0.033 0.083 0.058 0.080 0.125 0.204    || dis=0.01 || select=7/8
[epoch=394/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.144
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:10:40] [epoch=394/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.686 (3.686)  Prec@1 19.14 (19.14) Prec@5 57.03 (57.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:10:46] [epoch=394/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.096 (2.670)  Prec@1 61.90 (34.28) Prec@5 94.05 (79.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.28 Prec@5 79.02 Error@1 65.72 Error@5 20.98 Loss:2.670
***[2020-01-29 09:10:47]*** VALID [epoch=394/600] loss = 2.670242, accuracy@1 = 34.28, accuracy@5 = 79.02 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:10:47]*** start epoch=395/600 Time Left: [01:48:50], LR=[0.026142 ~ 0.026142], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=395, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3809610373639594, FLOP=40.81
[Search] : epoch=395/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:10:47] [epoch=395/600][000/098] Time 0.74 (0.74) Data 0.35 (0.35) Base-Loss 0.640 (0.640)  Prec@1 78.52 (78.52) Prec@5 98.83 (98.83) Acls-loss 0.686 (0.686) FLOP-Loss 0.000 (0.000) Arch-Loss 0.686 (0.686)
**TRAIN** [2020-01-29 09:11:12] [epoch=395/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.615 (0.753)  Prec@1 79.17 (74.08) Prec@5 98.81 (98.03) Acls-loss 0.687 (0.757) FLOP-Loss 0.000 (0.000) Arch-Loss 0.687 (0.757)
 **TRAIN** Prec@1 74.08 Prec@5 98.03 Error@1 25.92 Error@5 1.97 Base-Loss:0.753, Arch-Loss=0.757
***[2020-01-29 09:11:12]*** TRAIN [epoch=395/600] base-loss = 0.753350, arch-loss = 0.757138, accuracy-1 = 74.08, accuracy-5 = 98.03
[epoch=395/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.395 0.223 0.382  ||  0.2046 -0.3670 0.1693  || discrepancy=0.01 || select=0/3
001/003-th : 0.332 0.168 0.500  ||  0.0837 -0.5982 0.4915  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3407 -0.8666 2.8423  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.064 0.068 0.108 0.147 0.205 0.334  ||  -1.192 -0.730 -0.388 -0.314 0.138 0.453 0.782 1.271   || dis=0.13 || select=7/8
001/019-th : 0.106 0.128 0.143 0.133 0.133 0.125 0.121 0.110  ||  -0.151 0.032 0.147 0.073 0.071 0.015 -0.018 -0.114    || dis=0.01 || select=2/8
002/019-th : 0.133 0.135 0.132 0.137 0.124 0.117 0.115 0.107  ||  0.062 0.073 0.054 0.094 -0.013 -0.064 -0.088 -0.152   || dis=0.00 || select=3/8
003/019-th : 0.102 0.112 0.125 0.125 0.131 0.136 0.132 0.137  ||  -0.200 -0.107 0.007 0.009 0.054 0.088 0.057 0.101     || dis=0.00 || select=7/8
004/019-th : 0.117 0.113 0.118 0.122 0.125 0.126 0.140 0.140  ||  -0.065 -0.097 -0.055 -0.024 -0.000 0.010 0.116 0.120  || dis=0.00 || select=7/8
005/019-th : 0.106 0.128 0.126 0.124 0.129 0.129 0.127 0.132  ||  -0.164 0.026 0.012 -0.001 0.038 0.036 0.020 0.059     || dis=0.00 || select=7/8
006/019-th : 0.129 0.123 0.115 0.115 0.127 0.126 0.135 0.131  ||  0.030 -0.018 -0.084 -0.082 0.019 0.007 0.079 0.052    || dis=0.00 || select=6/8
007/019-th : 0.028 0.037 0.062 0.073 0.119 0.134 0.195 0.353  ||  -1.199 -0.905 -0.393 -0.218 0.267 0.385 0.759 1.352   || dis=0.16 || select=7/8
008/019-th : 0.019 0.028 0.046 0.071 0.096 0.157 0.258 0.325  ||  -1.469 -1.082 -0.565 -0.133 0.162 0.656 1.156 1.387   || dis=0.07 || select=7/8
009/019-th : 0.074 0.087 0.099 0.110 0.126 0.139 0.167 0.198  ||  -0.480 -0.313 -0.188 -0.079 0.059 0.156 0.338 0.511   || dis=0.03 || select=7/8
010/019-th : 0.088 0.095 0.107 0.127 0.133 0.140 0.154 0.155  ||  -0.325 -0.248 -0.133 0.036 0.084 0.139 0.229 0.240    || dis=0.00 || select=7/8
011/019-th : 0.103 0.103 0.110 0.120 0.122 0.133 0.151 0.159  ||  -0.180 -0.176 -0.118 -0.026 -0.010 0.074 0.200 0.253  || dis=0.01 || select=7/8
012/019-th : 0.125 0.119 0.123 0.123 0.128 0.124 0.127 0.132  ||  0.005 -0.048 -0.015 -0.010 0.024 -0.004 0.016 0.058   || dis=0.00 || select=7/8
013/019-th : 0.010 0.013 0.017 0.020 0.028 0.043 0.112 0.757  ||  -1.311 -1.124 -0.843 -0.665 -0.308 0.117 1.072 2.979  || dis=0.65 || select=7/8
014/019-th : 0.010 0.019 0.023 0.033 0.059 0.093 0.202 0.560  ||  -1.676 -1.094 -0.871 -0.531 0.055 0.515 1.290 2.308   || dis=0.36 || select=7/8
015/019-th : 0.007 0.010 0.013 0.018 0.025 0.043 0.128 0.756  ||  -1.616 -1.220 -0.943 -0.660 -0.328 0.216 1.308 3.085  || dis=0.63 || select=7/8
016/019-th : 0.051 0.067 0.078 0.112 0.137 0.157 0.187 0.210  ||  -0.789 -0.523 -0.369 -0.005 0.194 0.332 0.506 0.623   || dis=0.02 || select=7/8
017/019-th : 0.089 0.101 0.109 0.126 0.132 0.136 0.152 0.156  ||  -0.315 -0.194 -0.118 0.031 0.077 0.107 0.216 0.243    || dis=0.00 || select=7/8
018/019-th : 0.084 0.108 0.119 0.135 0.129 0.132 0.140 0.152  ||  -0.377 -0.127 -0.033 0.089 0.051 0.073 0.127 0.215    || dis=0.01 || select=7/8
[epoch=395/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.146
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:11:12] [epoch=395/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 2.568 (2.568)  Prec@1 42.58 (42.58) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:11:18] [epoch=395/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.503 (2.589)  Prec@1 49.40 (36.82) Prec@5 88.10 (81.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.82 Prec@5 81.14 Error@1 63.18 Error@5 18.86 Loss:2.589
***[2020-01-29 09:11:18]*** VALID [epoch=395/600] loss = 2.588524, accuracy@1 = 36.82, accuracy@5 = 81.14 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:11:18]*** start epoch=396/600 Time Left: [01:48:19], LR=[0.025912 ~ 0.025912], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=396, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3697034984507974, FLOP=40.81
[Search] : epoch=396/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:11:19] [epoch=396/600][000/098] Time 0.82 (0.82) Data 0.48 (0.48) Base-Loss 0.836 (0.836)  Prec@1 73.05 (73.05) Prec@5 96.48 (96.48) Acls-loss 0.883 (0.883) FLOP-Loss 0.000 (0.000) Arch-Loss 0.883 (0.883)
**TRAIN** [2020-01-29 09:11:45] [epoch=396/600][097/098] Time 0.24 (0.27) Data 0.00 (0.01) Base-Loss 0.719 (0.712)  Prec@1 70.83 (75.61) Prec@5 98.81 (98.30) Acls-loss 0.584 (0.762) FLOP-Loss 0.000 (0.059) Arch-Loss 0.584 (0.880)
 **TRAIN** Prec@1 75.61 Prec@5 98.30 Error@1 24.39 Error@5 1.70 Base-Loss:0.712, Arch-Loss=0.880
***[2020-01-29 09:11:45]*** TRAIN [epoch=396/600] base-loss = 0.712213, arch-loss = 0.879890, accuracy-1 = 75.61, accuracy-5 = 98.30
[epoch=396/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.387 0.227 0.385  ||  0.1874 -0.3461 0.1819  || discrepancy=0.00 || select=0/3
001/003-th : 0.329 0.170 0.501  ||  0.0762 -0.5832 0.4959  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.971  ||  -2.3424 -0.8806 2.8515  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.062 0.067 0.107 0.148 0.208 0.333  ||  -1.196 -0.723 -0.405 -0.328 0.140 0.458 0.803 1.273   || dis=0.13 || select=7/8
001/019-th : 0.106 0.125 0.142 0.134 0.134 0.125 0.122 0.111  ||  -0.151 0.014 0.141 0.081 0.084 0.013 -0.016 -0.105    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.132 0.137 0.124 0.118 0.115 0.108  ||  0.059 0.069 0.053 0.088 -0.008 -0.059 -0.087 -0.146   || dis=0.00 || select=3/8
003/019-th : 0.099 0.110 0.126 0.126 0.130 0.138 0.134 0.138  ||  -0.223 -0.123 0.016 0.013 0.048 0.107 0.078 0.104     || dis=0.00 || select=5/8
004/019-th : 0.116 0.112 0.116 0.123 0.124 0.128 0.139 0.142  ||  -0.071 -0.109 -0.071 -0.008 -0.005 0.029 0.108 0.131  || dis=0.00 || select=7/8
005/019-th : 0.105 0.126 0.125 0.126 0.128 0.130 0.128 0.133  ||  -0.172 0.018 0.004 0.015 0.029 0.042 0.027 0.070      || dis=0.00 || select=7/8
006/019-th : 0.129 0.121 0.114 0.115 0.128 0.127 0.134 0.131  ||  0.032 -0.028 -0.089 -0.079 0.027 0.017 0.072 0.053    || dis=0.00 || select=6/8
007/019-th : 0.027 0.036 0.060 0.073 0.119 0.132 0.196 0.356  ||  -1.212 -0.910 -0.406 -0.211 0.275 0.377 0.770 1.367   || dis=0.16 || select=7/8
008/019-th : 0.018 0.026 0.046 0.070 0.096 0.155 0.260 0.329  ||  -1.472 -1.112 -0.563 -0.137 0.172 0.653 1.171 1.406   || dis=0.07 || select=7/8
009/019-th : 0.074 0.087 0.098 0.110 0.127 0.140 0.165 0.199  ||  -0.476 -0.318 -0.190 -0.080 0.064 0.164 0.328 0.512   || dis=0.03 || select=7/8
010/019-th : 0.089 0.096 0.108 0.125 0.132 0.141 0.154 0.157  ||  -0.321 -0.245 -0.124 0.018 0.073 0.142 0.228 0.248    || dis=0.00 || select=7/8
011/019-th : 0.103 0.098 0.111 0.122 0.120 0.134 0.152 0.160  ||  -0.178 -0.223 -0.107 -0.013 -0.022 0.083 0.213 0.262  || dis=0.01 || select=7/8
012/019-th : 0.125 0.119 0.122 0.125 0.127 0.125 0.126 0.132  ||  0.002 -0.044 -0.024 0.003 0.017 0.001 0.015 0.058     || dis=0.01 || select=7/8
013/019-th : 0.010 0.013 0.016 0.019 0.028 0.043 0.111 0.759  ||  -1.314 -1.110 -0.856 -0.675 -0.314 0.129 1.063 2.990  || dis=0.65 || select=7/8
014/019-th : 0.010 0.019 0.023 0.033 0.058 0.091 0.198 0.568  ||  -1.669 -1.090 -0.879 -0.531 0.054 0.499 1.274 2.329   || dis=0.37 || select=7/8
015/019-th : 0.007 0.010 0.013 0.017 0.024 0.042 0.125 0.762  ||  -1.625 -1.219 -0.949 -0.681 -0.335 0.212 1.308 3.117  || dis=0.64 || select=7/8
016/019-th : 0.051 0.067 0.079 0.112 0.134 0.155 0.189 0.214  ||  -0.791 -0.525 -0.358 -0.011 0.171 0.315 0.519 0.640   || dis=0.02 || select=7/8
017/019-th : 0.088 0.099 0.110 0.124 0.132 0.137 0.153 0.156  ||  -0.323 -0.205 -0.107 0.014 0.082 0.116 0.225 0.247    || dis=0.00 || select=7/8
018/019-th : 0.083 0.106 0.120 0.135 0.130 0.133 0.142 0.152  ||  -0.390 -0.145 -0.024 0.096 0.054 0.078 0.144 0.211    || dis=0.01 || select=7/8
[epoch=396/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.147
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:11:45] [epoch=396/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 6.727 (6.727)  Prec@1 14.06 (14.06) Prec@5 61.72 (61.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:11:51] [epoch=396/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.517 (2.558)  Prec@1 59.52 (37.94) Prec@5 95.83 (81.15) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.94 Prec@5 81.15 Error@1 62.06 Error@5 18.85 Loss:2.558
***[2020-01-29 09:11:51]*** VALID [epoch=396/600] loss = 2.558085, accuracy@1 = 37.94, accuracy@5 = 81.15 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:11:51]*** start epoch=397/600 Time Left: [01:47:47], LR=[0.025683 ~ 0.025683], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=397, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3584783179624487, FLOP=40.81
[Search] : epoch=397/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:11:52] [epoch=397/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.850 (0.850)  Prec@1 70.31 (70.31) Prec@5 96.48 (96.48) Acls-loss 0.776 (0.776) FLOP-Loss 0.000 (0.000) Arch-Loss 0.776 (0.776)
**TRAIN** [2020-01-29 09:12:17] [epoch=397/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.079 (0.710)  Prec@1 66.67 (75.75) Prec@5 95.83 (98.33) Acls-loss 0.896 (0.768) FLOP-Loss 0.000 (0.118) Arch-Loss 0.896 (1.005)
 **TRAIN** Prec@1 75.75 Prec@5 98.33 Error@1 24.25 Error@5 1.67 Base-Loss:0.710, Arch-Loss=1.005
***[2020-01-29 09:12:17]*** TRAIN [epoch=397/600] base-loss = 0.710420, arch-loss = 1.004713, accuracy-1 = 75.75, accuracy-5 = 98.33
[epoch=397/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.387 0.228 0.385  ||  0.1861 -0.3437 0.1826  || discrepancy=0.00 || select=0/3
001/003-th : 0.327 0.169 0.504  ||  0.0716 -0.5908 0.5021  || discrepancy=0.18 || select=2/3
002/003-th : 0.006 0.024 0.971  ||  -2.3324 -0.8689 2.8404  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.062 0.066 0.107 0.148 0.208 0.337  ||  -1.200 -0.731 -0.410 -0.348 0.138 0.469 0.807 1.290   || dis=0.13 || select=7/8
001/019-th : 0.105 0.127 0.144 0.134 0.133 0.125 0.121 0.110  ||  -0.159 0.026 0.158 0.086 0.078 0.010 -0.018 -0.116    || dis=0.01 || select=2/8
002/019-th : 0.132 0.133 0.132 0.138 0.123 0.120 0.114 0.108  ||  0.057 0.065 0.054 0.097 -0.014 -0.040 -0.093 -0.149   || dis=0.01 || select=3/8
003/019-th : 0.100 0.109 0.125 0.124 0.132 0.137 0.135 0.138  ||  -0.220 -0.126 0.010 -0.004 0.060 0.099 0.087 0.109    || dis=0.00 || select=7/8
004/019-th : 0.115 0.111 0.114 0.124 0.123 0.129 0.140 0.143  ||  -0.077 -0.112 -0.088 -0.006 -0.012 0.037 0.114 0.140  || dis=0.00 || select=7/8
005/019-th : 0.105 0.126 0.124 0.127 0.128 0.129 0.128 0.134  ||  -0.168 0.016 -0.005 0.025 0.028 0.036 0.027 0.075     || dis=0.01 || select=7/8
006/019-th : 0.129 0.121 0.115 0.116 0.126 0.127 0.135 0.132  ||  0.032 -0.032 -0.085 -0.075 0.012 0.019 0.080 0.054    || dis=0.00 || select=6/8
007/019-th : 0.025 0.036 0.060 0.072 0.119 0.127 0.193 0.367  ||  -1.261 -0.900 -0.395 -0.214 0.292 0.353 0.772 1.413   || dis=0.17 || select=7/8
008/019-th : 0.018 0.026 0.044 0.069 0.095 0.153 0.261 0.333  ||  -1.477 -1.111 -0.587 -0.145 0.169 0.649 1.182 1.427   || dis=0.07 || select=7/8
009/019-th : 0.071 0.087 0.098 0.111 0.130 0.141 0.164 0.198  ||  -0.515 -0.315 -0.188 -0.071 0.093 0.175 0.322 0.511   || dis=0.03 || select=7/8
010/019-th : 0.089 0.096 0.109 0.125 0.129 0.140 0.155 0.158  ||  -0.318 -0.246 -0.117 0.018 0.055 0.135 0.234 0.253    || dis=0.00 || select=7/8
011/019-th : 0.102 0.097 0.113 0.120 0.122 0.135 0.153 0.158  ||  -0.184 -0.240 -0.083 -0.023 -0.006 0.090 0.217 0.251  || dis=0.01 || select=7/8
012/019-th : 0.125 0.119 0.122 0.125 0.125 0.125 0.128 0.131  ||  0.004 -0.047 -0.018 0.003 0.001 0.000 0.027 0.053     || dis=0.00 || select=7/8
013/019-th : 0.010 0.013 0.016 0.019 0.028 0.042 0.108 0.763  ||  -1.298 -1.097 -0.857 -0.677 -0.306 0.105 1.053 3.005  || dis=0.66 || select=7/8
014/019-th : 0.010 0.018 0.023 0.032 0.057 0.090 0.196 0.572  ||  -1.661 -1.092 -0.875 -0.536 0.038 0.495 1.272 2.342   || dis=0.38 || select=7/8
015/019-th : 0.006 0.010 0.013 0.016 0.023 0.041 0.121 0.769  ||  -1.630 -1.207 -0.958 -0.705 -0.353 0.214 1.305 3.152  || dis=0.65 || select=7/8
016/019-th : 0.052 0.067 0.079 0.109 0.134 0.153 0.191 0.214  ||  -0.785 -0.517 -0.351 -0.031 0.169 0.305 0.527 0.641   || dis=0.02 || select=7/8
017/019-th : 0.088 0.099 0.110 0.122 0.134 0.135 0.154 0.157  ||  -0.323 -0.210 -0.107 -0.000 0.096 0.104 0.235 0.251   || dis=0.00 || select=7/8
018/019-th : 0.084 0.106 0.120 0.136 0.131 0.132 0.142 0.150  ||  -0.381 -0.148 -0.021 0.099 0.062 0.073 0.143 0.200    || dis=0.01 || select=7/8
[epoch=397/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.149
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:12:17] [epoch=397/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.181 (2.181)  Prec@1 27.34 (27.34) Prec@5 69.92 (69.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:12:23] [epoch=397/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.415 (2.481)  Prec@1 52.38 (38.11) Prec@5 91.67 (81.19) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.11 Prec@5 81.19 Error@1 61.89 Error@5 18.81 Loss:2.481
***[2020-01-29 09:12:23]*** VALID [epoch=397/600] loss = 2.480825, accuracy@1 = 38.11, accuracy@5 = 81.19 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:12:23]*** start epoch=398/600 Time Left: [01:47:15], LR=[0.025455 ~ 0.025455], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=398, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3472858036429052, FLOP=40.81
[Search] : epoch=398/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:12:24] [epoch=398/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.720 (0.720)  Prec@1 75.78 (75.78) Prec@5 97.27 (97.27) Acls-loss 0.809 (0.809) FLOP-Loss 0.000 (0.000) Arch-Loss 0.809 (0.809)
**TRAIN** [2020-01-29 09:12:48] [epoch=398/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.617 (0.697)  Prec@1 76.79 (76.62) Prec@5 98.81 (98.33) Acls-loss 1.055 (0.762) FLOP-Loss 0.000 (0.178) Arch-Loss 1.055 (1.117)
 **TRAIN** Prec@1 76.62 Prec@5 98.33 Error@1 23.38 Error@5 1.67 Base-Loss:0.697, Arch-Loss=1.117
***[2020-01-29 09:12:49]*** TRAIN [epoch=398/600] base-loss = 0.697047, arch-loss = 1.117445, accuracy-1 = 76.62, accuracy-5 = 98.33
[epoch=398/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.387 0.228 0.385  ||  0.1873 -0.3419 0.1808  || discrepancy=0.00 || select=0/3
001/003-th : 0.329 0.173 0.498  ||  0.0765 -0.5672 0.4924  || discrepancy=0.17 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3313 -0.8497 2.8345  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.062 0.065 0.104 0.145 0.206 0.344  ||  -1.191 -0.728 -0.409 -0.350 0.119 0.447 0.799 1.311   || dis=0.14 || select=7/8
001/019-th : 0.106 0.126 0.146 0.135 0.132 0.124 0.121 0.110  ||  -0.150 0.019 0.170 0.086 0.071 0.006 -0.023 -0.118    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.133 0.137 0.122 0.119 0.114 0.107  ||  0.065 0.067 0.062 0.093 -0.023 -0.045 -0.095 -0.152   || dis=0.00 || select=3/8
003/019-th : 0.099 0.111 0.128 0.124 0.130 0.136 0.135 0.138  ||  -0.224 -0.114 0.027 0.001 0.043 0.090 0.081 0.108     || dis=0.00 || select=7/8
004/019-th : 0.115 0.113 0.115 0.125 0.123 0.128 0.139 0.142  ||  -0.076 -0.102 -0.080 0.004 -0.014 0.027 0.109 0.133   || dis=0.00 || select=7/8
005/019-th : 0.106 0.127 0.125 0.127 0.126 0.129 0.127 0.134  ||  -0.163 0.017 0.002 0.019 0.014 0.034 0.021 0.076      || dis=0.01 || select=7/8
006/019-th : 0.131 0.121 0.114 0.116 0.126 0.127 0.134 0.132  ||  0.045 -0.028 -0.094 -0.074 0.008 0.013 0.070 0.057    || dis=0.00 || select=6/8
007/019-th : 0.025 0.036 0.060 0.071 0.118 0.127 0.195 0.368  ||  -1.258 -0.892 -0.403 -0.225 0.279 0.352 0.786 1.417   || dis=0.17 || select=7/8
008/019-th : 0.017 0.026 0.043 0.068 0.095 0.151 0.264 0.336  ||  -1.511 -1.113 -0.597 -0.149 0.186 0.648 1.208 1.448   || dis=0.07 || select=7/8
009/019-th : 0.071 0.085 0.100 0.111 0.131 0.139 0.162 0.200  ||  -0.509 -0.332 -0.171 -0.066 0.099 0.157 0.310 0.518   || dis=0.04 || select=7/8
010/019-th : 0.089 0.096 0.110 0.123 0.132 0.141 0.153 0.156  ||  -0.314 -0.244 -0.108 0.003 0.073 0.141 0.226 0.241    || dis=0.00 || select=7/8
011/019-th : 0.103 0.098 0.114 0.119 0.122 0.133 0.154 0.157  ||  -0.180 -0.224 -0.078 -0.032 -0.010 0.078 0.222 0.243  || dis=0.00 || select=7/8
012/019-th : 0.126 0.120 0.122 0.125 0.123 0.125 0.128 0.130  ||  0.015 -0.042 -0.019 0.004 -0.016 0.005 0.028 0.046    || dis=0.00 || select=7/8
013/019-th : 0.010 0.012 0.016 0.019 0.027 0.042 0.106 0.767  ||  -1.284 -1.111 -0.881 -0.679 -0.310 0.112 1.046 3.021  || dis=0.66 || select=7/8
014/019-th : 0.010 0.019 0.023 0.032 0.055 0.089 0.195 0.578  ||  -1.670 -1.075 -0.870 -0.532 0.007 0.487 1.271 2.359   || dis=0.38 || select=7/8
015/019-th : 0.006 0.010 0.012 0.016 0.023 0.040 0.119 0.774  ||  -1.626 -1.194 -0.956 -0.719 -0.367 0.207 1.300 3.171  || dis=0.66 || select=7/8
016/019-th : 0.051 0.067 0.078 0.109 0.137 0.154 0.191 0.213  ||  -0.791 -0.526 -0.362 -0.029 0.193 0.312 0.529 0.636   || dis=0.02 || select=7/8
017/019-th : 0.087 0.100 0.108 0.123 0.138 0.134 0.154 0.157  ||  -0.335 -0.200 -0.125 0.008 0.121 0.092 0.235 0.256    || dis=0.00 || select=7/8
018/019-th : 0.086 0.106 0.120 0.137 0.132 0.132 0.141 0.148  ||  -0.362 -0.147 -0.025 0.106 0.070 0.068 0.135 0.185    || dis=0.01 || select=7/8
[epoch=398/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.150
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:12:49] [epoch=398/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.773 (2.773)  Prec@1 33.59 (33.59) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:12:55] [epoch=398/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.636 (2.205)  Prec@1 44.64 (39.89) Prec@5 86.31 (82.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.89 Prec@5 82.07 Error@1 60.11 Error@5 17.93 Loss:2.205
***[2020-01-29 09:12:55]*** VALID [epoch=398/600] loss = 2.205393, accuracy@1 = 39.89, accuracy@5 = 82.07 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:12:55]*** start epoch=399/600 Time Left: [01:46:44], LR=[0.025227 ~ 0.025227], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=399, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3361262623406016, FLOP=40.81
[Search] : epoch=399/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:12:56] [epoch=399/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.631 (0.631)  Prec@1 77.34 (77.34) Prec@5 98.83 (98.83) Acls-loss 0.989 (0.989) FLOP-Loss 0.000 (0.000) Arch-Loss 0.989 (0.989)
**TRAIN** [2020-01-29 09:13:20] [epoch=399/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.642 (0.694)  Prec@1 79.17 (76.35) Prec@5 99.40 (98.39) Acls-loss 0.825 (0.766) FLOP-Loss 0.000 (0.237) Arch-Loss 0.825 (1.240)
 **TRAIN** Prec@1 76.35 Prec@5 98.39 Error@1 23.65 Error@5 1.61 Base-Loss:0.694, Arch-Loss=1.240
***[2020-01-29 09:13:21]*** TRAIN [epoch=399/600] base-loss = 0.693865, arch-loss = 1.239645, accuracy-1 = 76.35, accuracy-5 = 98.39
[epoch=399/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 14, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.484224)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.389 0.229 0.382  ||  0.1916 -0.3363 0.1750  || discrepancy=0.01 || select=0/3
001/003-th : 0.334 0.174 0.492  ||  0.0901 -0.5622 0.4780  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.024 0.970  ||  -2.3273 -0.8560 2.8356  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.061 0.064 0.104 0.149 0.208 0.341  ||  -1.185 -0.726 -0.422 -0.375 0.120 0.476 0.810 1.302   || dis=0.13 || select=7/8
001/019-th : 0.108 0.127 0.148 0.136 0.130 0.123 0.120 0.108  ||  -0.134 0.030 0.184 0.093 0.050 -0.008 -0.032 -0.134   || dis=0.01 || select=2/8
002/019-th : 0.134 0.136 0.134 0.138 0.123 0.117 0.113 0.107  ||  0.068 0.082 0.066 0.097 -0.020 -0.068 -0.105 -0.151   || dis=0.00 || select=3/8
003/019-th : 0.101 0.113 0.129 0.124 0.130 0.134 0.132 0.137  ||  -0.208 -0.094 0.036 -0.005 0.046 0.073 0.063 0.094    || dis=0.00 || select=7/8
004/019-th : 0.117 0.111 0.117 0.126 0.124 0.128 0.138 0.140  ||  -0.064 -0.112 -0.061 0.011 -0.006 0.025 0.104 0.117   || dis=0.00 || select=7/8
005/019-th : 0.107 0.127 0.127 0.126 0.128 0.129 0.125 0.132  ||  -0.151 0.015 0.015 0.011 0.024 0.033 0.003 0.059      || dis=0.00 || select=7/8
006/019-th : 0.132 0.123 0.116 0.114 0.126 0.126 0.133 0.132  ||  0.055 -0.019 -0.075 -0.092 0.005 0.005 0.060 0.056    || dis=0.00 || select=6/8
007/019-th : 0.025 0.035 0.058 0.071 0.117 0.127 0.199 0.367  ||  -1.268 -0.915 -0.418 -0.221 0.285 0.364 0.811 1.425   || dis=0.17 || select=7/8
008/019-th : 0.017 0.026 0.043 0.067 0.095 0.151 0.263 0.338  ||  -1.521 -1.101 -0.607 -0.161 0.192 0.652 1.208 1.458   || dis=0.08 || select=7/8
009/019-th : 0.072 0.086 0.100 0.113 0.130 0.137 0.164 0.197  ||  -0.499 -0.329 -0.170 -0.053 0.088 0.143 0.320 0.505   || dis=0.03 || select=7/8
010/019-th : 0.091 0.098 0.110 0.124 0.131 0.140 0.152 0.155  ||  -0.301 -0.220 -0.107 0.009 0.066 0.129 0.214 0.232    || dis=0.00 || select=7/8
011/019-th : 0.104 0.098 0.113 0.120 0.121 0.134 0.153 0.157  ||  -0.172 -0.225 -0.082 -0.026 -0.015 0.081 0.214 0.243  || dis=0.00 || select=7/8
012/019-th : 0.128 0.121 0.123 0.124 0.122 0.125 0.129 0.129  ||  0.027 -0.034 -0.016 -0.006 -0.022 -0.001 0.031 0.036  || dis=0.00 || select=7/8
013/019-th : 0.010 0.012 0.015 0.019 0.028 0.042 0.105 0.769  ||  -1.290 -1.095 -0.901 -0.684 -0.300 0.118 1.038 3.028  || dis=0.66 || select=7/8
014/019-th : 0.010 0.019 0.023 0.031 0.055 0.090 0.194 0.578  ||  -1.670 -1.077 -0.867 -0.549 0.002 0.502 1.271 2.364   || dis=0.38 || select=7/8
015/019-th : 0.006 0.010 0.012 0.016 0.022 0.039 0.117 0.778  ||  -1.641 -1.190 -0.962 -0.718 -0.363 0.200 1.293 3.190  || dis=0.66 || select=7/8
016/019-th : 0.051 0.067 0.079 0.110 0.140 0.153 0.191 0.208  ||  -0.790 -0.517 -0.356 -0.022 0.216 0.304 0.529 0.614   || dis=0.02 || select=7/8
017/019-th : 0.088 0.102 0.109 0.122 0.137 0.134 0.154 0.155  ||  -0.324 -0.185 -0.118 -0.002 0.112 0.096 0.229 0.238   || dis=0.00 || select=7/8
018/019-th : 0.087 0.106 0.120 0.139 0.132 0.131 0.138 0.146  ||  -0.340 -0.149 -0.023 0.119 0.074 0.064 0.118 0.173    || dis=0.01 || select=7/8
[epoch=399/600] FLOP : 28.48 MB, ratio : 0.6979, Expected-ratio : 0.7000, Discrepancy : 0.149
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:13:21] [epoch=399/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.280 (2.280)  Prec@1 55.08 (55.08) Prec@5 84.38 (84.38) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:13:27] [epoch=399/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.182 (2.511)  Prec@1 35.12 (39.36) Prec@5 76.19 (82.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.36 Prec@5 82.72 Error@1 60.64 Error@5 17.28 Loss:2.511
***[2020-01-29 09:13:27]*** VALID [epoch=399/600] loss = 2.511299, accuracy@1 = 39.36, accuracy@5 = 82.72 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:13:27]*** start epoch=400/600 Time Left: [01:46:12], LR=[0.025000 ~ 0.025000], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=400, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3250000000000006, FLOP=40.81
[Search] : epoch=400/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:13:28] [epoch=400/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.937 (0.937)  Prec@1 68.75 (68.75) Prec@5 96.48 (96.48) Acls-loss 0.612 (0.612) FLOP-Loss 0.000 (0.000) Arch-Loss 0.612 (0.612)
**TRAIN** [2020-01-29 09:13:52] [epoch=400/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.550 (0.709)  Prec@1 79.76 (75.92) Prec@5 98.81 (98.34) Acls-loss 0.834 (0.756) FLOP-Loss -2.886 (0.158) Arch-Loss -4.938 (1.073)
 **TRAIN** Prec@1 75.92 Prec@5 98.34 Error@1 24.08 Error@5 1.66 Base-Loss:0.709, Arch-Loss=1.073
***[2020-01-29 09:13:52]*** TRAIN [epoch=400/600] base-loss = 0.708519, arch-loss = 1.072615, accuracy-1 = 75.92, accuracy-5 = 98.34
[epoch=400/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.390 0.231 0.379  ||  0.1965 -0.3287 0.1683  || discrepancy=0.01 || select=0/3
001/003-th : 0.334 0.174 0.493  ||  0.0890 -0.5630 0.4793  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.024 0.971  ||  -2.3163 -0.8747 2.8357  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.060 0.064 0.106 0.149 0.208 0.339  ||  -1.190 -0.720 -0.432 -0.366 0.136 0.474 0.806 1.298   || dis=0.13 || select=7/8
001/019-th : 0.108 0.130 0.147 0.134 0.129 0.124 0.119 0.108  ||  -0.140 0.053 0.174 0.081 0.045 -0.001 -0.036 -0.136   || dis=0.01 || select=2/8
002/019-th : 0.133 0.136 0.134 0.137 0.123 0.118 0.112 0.108  ||  0.063 0.083 0.069 0.092 -0.012 -0.056 -0.113 -0.149   || dis=0.00 || select=3/8
003/019-th : 0.101 0.114 0.126 0.123 0.130 0.136 0.132 0.137  ||  -0.207 -0.085 0.012 -0.008 0.043 0.087 0.063 0.097    || dis=0.00 || select=7/8
004/019-th : 0.116 0.111 0.118 0.125 0.124 0.127 0.138 0.141  ||  -0.068 -0.116 -0.057 0.008 -0.001 0.023 0.100 0.123   || dis=0.00 || select=7/8
005/019-th : 0.108 0.127 0.127 0.126 0.128 0.129 0.125 0.130  ||  -0.143 0.021 0.017 0.008 0.022 0.032 0.003 0.044      || dis=0.00 || select=7/8
006/019-th : 0.132 0.123 0.118 0.115 0.125 0.126 0.131 0.132  ||  0.052 -0.019 -0.058 -0.086 -0.003 0.008 0.051 0.055   || dis=0.00 || select=7/8
007/019-th : 0.025 0.035 0.057 0.072 0.116 0.126 0.196 0.373  ||  -1.261 -0.924 -0.436 -0.203 0.276 0.359 0.798 1.444   || dis=0.18 || select=7/8
008/019-th : 0.017 0.026 0.043 0.067 0.096 0.150 0.263 0.337  ||  -1.516 -1.100 -0.614 -0.163 0.198 0.647 1.207 1.454   || dis=0.07 || select=7/8
009/019-th : 0.073 0.085 0.101 0.114 0.129 0.138 0.164 0.196  ||  -0.489 -0.338 -0.169 -0.047 0.081 0.150 0.322 0.496   || dis=0.03 || select=7/8
010/019-th : 0.092 0.098 0.109 0.124 0.131 0.142 0.151 0.154  ||  -0.288 -0.229 -0.120 0.008 0.069 0.144 0.209 0.228    || dis=0.00 || select=7/8
011/019-th : 0.103 0.099 0.112 0.119 0.123 0.133 0.153 0.159  ||  -0.180 -0.222 -0.091 -0.038 -0.002 0.080 0.214 0.253  || dis=0.01 || select=7/8
012/019-th : 0.129 0.121 0.122 0.123 0.122 0.125 0.128 0.129  ||  0.033 -0.028 -0.024 -0.013 -0.019 0.003 0.025 0.035   || dis=0.00 || select=7/8
013/019-th : 0.010 0.012 0.015 0.018 0.026 0.041 0.103 0.773  ||  -1.290 -1.102 -0.889 -0.685 -0.327 0.115 1.034 3.049  || dis=0.67 || select=7/8
014/019-th : 0.010 0.019 0.023 0.031 0.054 0.089 0.189 0.586  ||  -1.669 -1.068 -0.871 -0.554 -0.002 0.499 1.253 2.385  || dis=0.40 || select=7/8
015/019-th : 0.006 0.010 0.012 0.015 0.022 0.039 0.115 0.780  ||  -1.657 -1.188 -0.959 -0.729 -0.359 0.214 1.287 3.199  || dis=0.67 || select=7/8
016/019-th : 0.050 0.068 0.078 0.110 0.140 0.152 0.192 0.210  ||  -0.814 -0.507 -0.371 -0.018 0.222 0.301 0.533 0.627   || dis=0.02 || select=7/8
017/019-th : 0.088 0.102 0.108 0.123 0.138 0.135 0.152 0.155  ||  -0.330 -0.182 -0.124 0.009 0.120 0.099 0.219 0.239    || dis=0.00 || select=7/8
018/019-th : 0.088 0.105 0.119 0.138 0.133 0.132 0.139 0.146  ||  -0.332 -0.157 -0.034 0.119 0.077 0.068 0.125 0.169    || dis=0.01 || select=7/8
[epoch=400/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.151
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:13:53] [epoch=400/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.944 (2.944)  Prec@1 52.73 (52.73) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:13:59] [epoch=400/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.037 (2.566)  Prec@1 47.02 (35.14) Prec@5 83.93 (78.67) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.14 Prec@5 78.67 Error@1 64.86 Error@5 21.33 Loss:2.566
***[2020-01-29 09:13:59]*** VALID [epoch=400/600] loss = 2.565936, accuracy@1 = 35.14, accuracy@5 = 78.67 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:13:59]*** start epoch=401/600 Time Left: [01:45:40], LR=[0.024774 ~ 0.024774], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=401, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3139073216532033, FLOP=40.81
[Search] : epoch=401/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:14:00] [epoch=401/600][000/098] Time 0.75 (0.75) Data 0.37 (0.37) Base-Loss 0.772 (0.772)  Prec@1 71.09 (71.09) Prec@5 97.66 (97.66) Acls-loss 0.797 (0.797) FLOP-Loss 2.887 (2.887) Arch-Loss 6.570 (6.570)
**TRAIN** [2020-01-29 09:14:25] [epoch=401/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.764 (0.684)  Prec@1 74.40 (76.54) Prec@5 100.00 (98.37) Acls-loss 0.755 (0.754) FLOP-Loss 0.000 (0.089) Arch-Loss 0.755 (0.932)
 **TRAIN** Prec@1 76.54 Prec@5 98.37 Error@1 23.46 Error@5 1.63 Base-Loss:0.684, Arch-Loss=0.932
***[2020-01-29 09:14:25]*** TRAIN [epoch=401/600] base-loss = 0.683954, arch-loss = 0.932292, accuracy-1 = 76.54, accuracy-5 = 98.37
[epoch=401/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 28, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.418688)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.386 0.233 0.381  ||  0.1871 -0.3166 0.1758  || discrepancy=0.01 || select=0/3
001/003-th : 0.331 0.176 0.493  ||  0.0843 -0.5492 0.4818  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.024 0.971  ||  -2.3061 -0.8785 2.8308  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.045 0.060 0.064 0.106 0.149 0.206 0.342  ||  -1.183 -0.721 -0.441 -0.375 0.138 0.473 0.802 1.306   || dis=0.14 || select=7/8
001/019-th : 0.105 0.130 0.146 0.134 0.132 0.125 0.120 0.108  ||  -0.161 0.048 0.164 0.082 0.063 0.013 -0.027 -0.130    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.133 0.137 0.124 0.118 0.113 0.108  ||  0.059 0.074 0.062 0.093 -0.011 -0.057 -0.101 -0.143   || dis=0.00 || select=3/8
003/019-th : 0.100 0.114 0.126 0.124 0.129 0.136 0.133 0.137  ||  -0.216 -0.083 0.013 -0.003 0.038 0.087 0.068 0.100    || dis=0.00 || select=7/8
004/019-th : 0.116 0.109 0.116 0.126 0.125 0.129 0.138 0.141  ||  -0.072 -0.130 -0.071 0.014 0.002 0.041 0.104 0.127    || dis=0.00 || select=7/8
005/019-th : 0.107 0.127 0.127 0.123 0.129 0.128 0.127 0.131  ||  -0.152 0.022 0.014 -0.012 0.035 0.030 0.015 0.051     || dis=0.00 || select=7/8
006/019-th : 0.130 0.120 0.118 0.116 0.124 0.127 0.131 0.132  ||  0.044 -0.035 -0.051 -0.071 -0.007 0.021 0.050 0.060   || dis=0.00 || select=7/8
007/019-th : 0.025 0.035 0.057 0.071 0.115 0.126 0.194 0.378  ||  -1.267 -0.919 -0.439 -0.218 0.274 0.360 0.792 1.462   || dis=0.18 || select=7/8
008/019-th : 0.017 0.026 0.041 0.066 0.096 0.150 0.263 0.340  ||  -1.507 -1.098 -0.641 -0.177 0.199 0.646 1.209 1.467   || dis=0.08 || select=7/8
009/019-th : 0.073 0.084 0.100 0.114 0.131 0.137 0.164 0.197  ||  -0.494 -0.347 -0.170 -0.047 0.093 0.141 0.322 0.504   || dis=0.03 || select=7/8
010/019-th : 0.091 0.096 0.107 0.122 0.132 0.145 0.152 0.156  ||  -0.297 -0.247 -0.135 -0.001 0.071 0.167 0.215 0.243   || dis=0.00 || select=7/8
011/019-th : 0.102 0.098 0.112 0.117 0.122 0.133 0.154 0.162  ||  -0.191 -0.224 -0.095 -0.051 -0.012 0.074 0.224 0.274  || dis=0.01 || select=7/8
012/019-th : 0.128 0.121 0.122 0.122 0.122 0.126 0.130 0.129  ||  0.028 -0.032 -0.023 -0.021 -0.021 0.007 0.037 0.035   || dis=0.00 || select=6/8
013/019-th : 0.010 0.012 0.015 0.018 0.026 0.041 0.101 0.776  ||  -1.299 -1.111 -0.880 -0.681 -0.333 0.120 1.025 3.060  || dis=0.68 || select=7/8
014/019-th : 0.010 0.018 0.022 0.030 0.053 0.087 0.188 0.591  ||  -1.667 -1.084 -0.866 -0.562 -0.004 0.487 1.256 2.403  || dis=0.40 || select=7/8
015/019-th : 0.006 0.010 0.012 0.015 0.022 0.038 0.113 0.783  ||  -1.649 -1.196 -0.946 -0.723 -0.369 0.198 1.279 3.213  || dis=0.67 || select=7/8
016/019-th : 0.049 0.067 0.076 0.108 0.142 0.153 0.194 0.212  ||  -0.829 -0.516 -0.393 -0.033 0.237 0.311 0.551 0.638   || dis=0.02 || select=7/8
017/019-th : 0.086 0.101 0.106 0.123 0.137 0.136 0.153 0.157  ||  -0.353 -0.185 -0.135 0.006 0.120 0.112 0.231 0.255    || dis=0.00 || select=7/8
018/019-th : 0.089 0.105 0.118 0.139 0.132 0.130 0.139 0.147  ||  -0.325 -0.161 -0.038 0.123 0.072 0.056 0.124 0.178    || dis=0.01 || select=7/8
[epoch=401/600] FLOP : 28.42 MB, ratio : 0.6963, Expected-ratio : 0.7000, Discrepancy : 0.153
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:14:25] [epoch=401/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.514 (2.514)  Prec@1 35.55 (35.55) Prec@5 71.88 (71.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:14:31] [epoch=401/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.360 (2.643)  Prec@1 38.10 (36.32) Prec@5 80.36 (79.90) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.32 Prec@5 79.90 Error@1 63.68 Error@5 20.10 Loss:2.643
***[2020-01-29 09:14:31]*** VALID [epoch=401/600] loss = 2.642579, accuracy@1 = 36.32, accuracy@5 = 79.90 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:14:31]*** start epoch=402/600 Time Left: [01:45:08], LR=[0.024548 ~ 0.024548], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=402, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.3028485314115905, FLOP=40.81
[Search] : epoch=402/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:14:32] [epoch=402/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.688 (0.688)  Prec@1 75.78 (75.78) Prec@5 98.83 (98.83) Acls-loss 0.791 (0.791) FLOP-Loss 0.000 (0.000) Arch-Loss 0.791 (0.791)
**TRAIN** [2020-01-29 09:14:57] [epoch=402/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.571 (0.705)  Prec@1 80.36 (75.65) Prec@5 100.00 (98.35) Acls-loss 0.891 (0.767) FLOP-Loss -2.891 (0.158) Arch-Loss -4.891 (1.083)
 **TRAIN** Prec@1 75.65 Prec@5 98.35 Error@1 24.35 Error@5 1.65 Base-Loss:0.705, Arch-Loss=1.083
***[2020-01-29 09:14:57]*** TRAIN [epoch=402/600] base-loss = 0.704899, arch-loss = 1.083432, accuracy-1 = 75.65, accuracy-5 = 98.35
[epoch=402/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.385 0.235 0.380  ||  0.1873 -0.3088 0.1744  || discrepancy=0.01 || select=0/3
001/003-th : 0.331 0.178 0.491  ||  0.0848 -0.5356 0.4795  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.023 0.971  ||  -2.3188 -0.8813 2.8454  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.029 0.044 0.059 0.065 0.106 0.148 0.208 0.343  ||  -1.173 -0.743 -0.457 -0.354 0.133 0.470 0.809 1.310   || dis=0.14 || select=7/8
001/019-th : 0.106 0.130 0.147 0.132 0.131 0.124 0.121 0.108  ||  -0.152 0.046 0.173 0.067 0.054 0.005 -0.022 -0.134    || dis=0.01 || select=2/8
002/019-th : 0.133 0.135 0.132 0.136 0.124 0.119 0.113 0.108  ||  0.059 0.075 0.057 0.085 -0.009 -0.048 -0.102 -0.143   || dis=0.00 || select=3/8
003/019-th : 0.101 0.116 0.125 0.124 0.130 0.133 0.133 0.138  ||  -0.206 -0.074 0.006 -0.005 0.043 0.069 0.063 0.099    || dis=0.01 || select=7/8
004/019-th : 0.116 0.108 0.116 0.126 0.126 0.131 0.138 0.140  ||  -0.067 -0.140 -0.070 0.015 0.012 0.050 0.102 0.121    || dis=0.00 || select=7/8
005/019-th : 0.108 0.127 0.127 0.123 0.129 0.129 0.128 0.130  ||  -0.145 0.018 0.015 -0.011 0.032 0.031 0.022 0.042     || dis=0.00 || select=7/8
006/019-th : 0.130 0.121 0.118 0.117 0.123 0.128 0.130 0.133  ||  0.038 -0.028 -0.052 -0.064 -0.014 0.028 0.045 0.062   || dis=0.00 || select=7/8
007/019-th : 0.024 0.035 0.056 0.070 0.114 0.126 0.198 0.377  ||  -1.290 -0.925 -0.449 -0.213 0.270 0.371 0.824 1.467   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.041 0.065 0.095 0.152 0.263 0.340  ||  -1.498 -1.100 -0.641 -0.186 0.187 0.658 1.209 1.464   || dis=0.08 || select=7/8
009/019-th : 0.073 0.084 0.101 0.113 0.131 0.140 0.163 0.195  ||  -0.488 -0.353 -0.160 -0.050 0.098 0.160 0.314 0.493   || dis=0.03 || select=7/8
010/019-th : 0.091 0.095 0.108 0.122 0.133 0.145 0.150 0.157  ||  -0.299 -0.252 -0.130 -0.006 0.080 0.167 0.205 0.250   || dis=0.01 || select=7/8
011/019-th : 0.103 0.098 0.113 0.118 0.120 0.133 0.153 0.161  ||  -0.183 -0.229 -0.085 -0.040 -0.027 0.075 0.219 0.269  || dis=0.01 || select=7/8
012/019-th : 0.130 0.122 0.122 0.122 0.122 0.124 0.129 0.130  ||  0.037 -0.027 -0.026 -0.028 -0.023 -0.004 0.031 0.037  || dis=0.00 || select=7/8
013/019-th : 0.010 0.012 0.015 0.018 0.026 0.040 0.100 0.780  ||  -1.305 -1.122 -0.886 -0.684 -0.336 0.116 1.023 3.080  || dis=0.68 || select=7/8
014/019-th : 0.010 0.018 0.023 0.030 0.053 0.088 0.187 0.592  ||  -1.666 -1.095 -0.861 -0.561 -0.010 0.497 1.253 2.407  || dis=0.40 || select=7/8
015/019-th : 0.006 0.009 0.012 0.015 0.021 0.037 0.109 0.791  ||  -1.646 -1.202 -0.936 -0.732 -0.362 0.169 1.266 3.245  || dis=0.68 || select=7/8
016/019-th : 0.048 0.066 0.076 0.108 0.143 0.151 0.193 0.215  ||  -0.845 -0.531 -0.383 -0.032 0.244 0.303 0.547 0.655   || dis=0.02 || select=7/8
017/019-th : 0.085 0.101 0.105 0.124 0.137 0.137 0.154 0.158  ||  -0.360 -0.187 -0.150 0.015 0.117 0.118 0.235 0.260    || dis=0.00 || select=7/8
018/019-th : 0.089 0.105 0.119 0.139 0.132 0.131 0.137 0.149  ||  -0.326 -0.163 -0.033 0.122 0.068 0.060 0.104 0.189    || dis=0.01 || select=7/8
[epoch=402/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.154
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:14:57] [epoch=402/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.886 (1.886)  Prec@1 55.47 (55.47) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:15:03] [epoch=402/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.633 (2.676)  Prec@1 26.19 (39.30) Prec@5 73.81 (82.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.30 Prec@5 82.40 Error@1 60.70 Error@5 17.60 Loss:2.676
***[2020-01-29 09:15:03]*** VALID [epoch=402/600] loss = 2.676295, accuracy@1 = 39.30, accuracy@5 = 82.40 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:15:03]*** start epoch=403/600 Time Left: [01:44:36], LR=[0.024323 ~ 0.024323], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=403, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.291823932457484, FLOP=40.81
[Search] : epoch=403/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:15:04] [epoch=403/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.705 (0.705)  Prec@1 74.61 (74.61) Prec@5 98.44 (98.44) Acls-loss 0.997 (0.997) FLOP-Loss 2.892 (2.892) Arch-Loss 6.780 (6.780)
**TRAIN** [2020-01-29 09:15:29] [epoch=403/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.574 (0.688)  Prec@1 80.36 (76.79) Prec@5 100.00 (98.49) Acls-loss 0.712 (0.755) FLOP-Loss -2.892 (0.188) Arch-Loss -5.072 (1.131)
 **TRAIN** Prec@1 76.79 Prec@5 98.49 Error@1 23.21 Error@5 1.51 Base-Loss:0.688, Arch-Loss=1.131
***[2020-01-29 09:15:29]*** TRAIN [epoch=403/600] base-loss = 0.687983, arch-loss = 1.131462, accuracy-1 = 76.79, accuracy-5 = 98.49
[epoch=403/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.083968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.386 0.235 0.379  ||  0.1891 -0.3041 0.1719  || discrepancy=0.01 || select=0/3
001/003-th : 0.330 0.180 0.491  ||  0.0833 -0.5254 0.4799  || discrepancy=0.16 || select=2/3
002/003-th : 0.006 0.023 0.971  ||  -2.3189 -0.8792 2.8469  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.029 0.044 0.058 0.064 0.104 0.147 0.206 0.347  ||  -1.163 -0.748 -0.465 -0.360 0.122 0.468 0.803 1.324   || dis=0.14 || select=7/8
001/019-th : 0.106 0.129 0.147 0.133 0.131 0.124 0.121 0.109  ||  -0.153 0.039 0.173 0.076 0.055 0.006 -0.025 -0.128    || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.133 0.136 0.123 0.120 0.113 0.108  ||  0.056 0.078 0.064 0.087 -0.012 -0.043 -0.102 -0.147   || dis=0.00 || select=3/8
003/019-th : 0.102 0.116 0.125 0.125 0.129 0.133 0.133 0.137  ||  -0.202 -0.071 0.004 0.003 0.030 0.067 0.061 0.097     || dis=0.00 || select=7/8
004/019-th : 0.117 0.108 0.116 0.126 0.124 0.131 0.137 0.141  ||  -0.064 -0.137 -0.067 0.015 -0.001 0.050 0.095 0.124   || dis=0.00 || select=7/8
005/019-th : 0.109 0.126 0.126 0.124 0.130 0.129 0.126 0.130  ||  -0.138 0.011 0.008 -0.005 0.039 0.030 0.013 0.044     || dis=0.00 || select=7/8
006/019-th : 0.130 0.121 0.119 0.118 0.123 0.127 0.130 0.132  ||  0.043 -0.031 -0.050 -0.052 -0.014 0.018 0.041 0.061   || dis=0.00 || select=7/8
007/019-th : 0.024 0.034 0.055 0.070 0.114 0.126 0.197 0.379  ||  -1.288 -0.938 -0.454 -0.215 0.276 0.376 0.821 1.474   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.041 0.065 0.095 0.152 0.261 0.341  ||  -1.493 -1.100 -0.644 -0.191 0.192 0.658 1.200 1.466   || dis=0.08 || select=7/8
009/019-th : 0.073 0.083 0.102 0.114 0.132 0.138 0.164 0.193  ||  -0.483 -0.359 -0.153 -0.045 0.104 0.150 0.320 0.485   || dis=0.03 || select=7/8
010/019-th : 0.091 0.094 0.108 0.122 0.134 0.145 0.150 0.156  ||  -0.293 -0.259 -0.127 -0.003 0.088 0.167 0.203 0.246   || dis=0.01 || select=7/8
011/019-th : 0.103 0.098 0.113 0.118 0.120 0.132 0.154 0.160  ||  -0.176 -0.226 -0.083 -0.043 -0.024 0.070 0.222 0.261  || dis=0.01 || select=7/8
012/019-th : 0.130 0.122 0.122 0.121 0.122 0.124 0.129 0.130  ||  0.040 -0.027 -0.029 -0.029 -0.024 -0.010 0.029 0.040  || dis=0.00 || select=0/8
013/019-th : 0.009 0.011 0.015 0.018 0.025 0.039 0.098 0.785  ||  -1.316 -1.138 -0.881 -0.679 -0.347 0.111 1.019 3.104  || dis=0.69 || select=7/8
014/019-th : 0.010 0.017 0.022 0.030 0.052 0.085 0.186 0.597  ||  -1.655 -1.113 -0.873 -0.557 -0.007 0.477 1.258 2.424  || dis=0.41 || select=7/8
015/019-th : 0.006 0.009 0.012 0.015 0.022 0.036 0.109 0.791  ||  -1.654 -1.197 -0.926 -0.731 -0.354 0.164 1.264 3.243  || dis=0.68 || select=7/8
016/019-th : 0.048 0.065 0.076 0.107 0.143 0.153 0.192 0.215  ||  -0.846 -0.533 -0.387 -0.039 0.250 0.318 0.541 0.656   || dis=0.02 || select=7/8
017/019-th : 0.086 0.100 0.104 0.124 0.136 0.138 0.154 0.157  ||  -0.351 -0.199 -0.155 0.020 0.114 0.126 0.237 0.257    || dis=0.00 || select=7/8
018/019-th : 0.089 0.104 0.118 0.140 0.131 0.131 0.138 0.149  ||  -0.320 -0.168 -0.047 0.127 0.058 0.061 0.116 0.191    || dis=0.01 || select=7/8
[epoch=403/600] FLOP : 26.08 MB, ratio : 0.6391, Expected-ratio : 0.7000, Discrepancy : 0.155
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:15:29] [epoch=403/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.859 (2.859)  Prec@1 40.23 (40.23) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:15:35] [epoch=403/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.573 (2.202)  Prec@1 63.69 (39.52) Prec@5 91.07 (81.75) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.52 Prec@5 81.75 Error@1 60.48 Error@5 18.25 Loss:2.202
***[2020-01-29 09:15:35]*** VALID [epoch=403/600] loss = 2.201622, accuracy@1 = 39.52, accuracy@5 = 81.75 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:15:35]*** start epoch=404/600 Time Left: [01:44:05], LR=[0.024099 ~ 0.024099], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=404, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.2808338270358315, FLOP=40.81
[Search] : epoch=404/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:15:36] [epoch=404/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.936 (0.936)  Prec@1 64.84 (64.84) Prec@5 98.05 (98.05) Acls-loss 0.637 (0.637) FLOP-Loss -2.892 (-2.892) Arch-Loss -5.147 (-5.147)
**TRAIN** [2020-01-29 09:16:01] [epoch=404/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.786 (0.716)  Prec@1 72.62 (75.53) Prec@5 96.43 (98.24) Acls-loss 0.604 (0.751) FLOP-Loss 2.894 (0.168) Arch-Loss 6.391 (1.086)
 **TRAIN** Prec@1 75.53 Prec@5 98.24 Error@1 24.47 Error@5 1.76 Base-Loss:0.716, Arch-Loss=1.086
***[2020-01-29 09:16:01]*** TRAIN [epoch=404/600] base-loss = 0.715773, arch-loss = 1.086326, accuracy-1 = 75.53, accuracy-5 = 98.24
[epoch=404/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 11, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.083968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.386 0.235 0.379  ||  0.1890 -0.3083 0.1724  || discrepancy=0.01 || select=0/3
001/003-th : 0.330 0.179 0.490  ||  0.0836 -0.5258 0.4794  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3259 -0.8844 2.8573  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.029 0.044 0.057 0.065 0.104 0.146 0.206 0.350  ||  -1.157 -0.741 -0.478 -0.358 0.114 0.456 0.802 1.332   || dis=0.14 || select=7/8
001/019-th : 0.107 0.129 0.147 0.133 0.130 0.124 0.121 0.109  ||  -0.150 0.039 0.173 0.072 0.051 0.000 -0.026 -0.127    || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.133 0.138 0.123 0.119 0.113 0.108  ||  0.053 0.078 0.065 0.099 -0.016 -0.048 -0.098 -0.145   || dis=0.00 || select=3/8
003/019-th : 0.103 0.116 0.125 0.125 0.128 0.133 0.134 0.137  ||  -0.197 -0.072 -0.002 0.004 0.023 0.062 0.070 0.094    || dis=0.00 || select=7/8
004/019-th : 0.117 0.109 0.117 0.126 0.124 0.130 0.136 0.140  ||  -0.064 -0.132 -0.061 0.010 0.001 0.048 0.093 0.122    || dis=0.00 || select=7/8
005/019-th : 0.108 0.125 0.125 0.125 0.132 0.129 0.126 0.130  ||  -0.139 0.005 0.005 0.004 0.056 0.034 0.009 0.043      || dis=0.00 || select=4/8
006/019-th : 0.130 0.121 0.118 0.119 0.122 0.127 0.130 0.132  ||  0.044 -0.030 -0.052 -0.044 -0.022 0.019 0.045 0.058   || dis=0.00 || select=7/8
007/019-th : 0.024 0.034 0.054 0.069 0.113 0.128 0.201 0.377  ||  -1.281 -0.944 -0.464 -0.230 0.269 0.390 0.842 1.473   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.041 0.065 0.095 0.152 0.258 0.344  ||  -1.501 -1.097 -0.640 -0.189 0.191 0.656 1.188 1.476   || dis=0.09 || select=7/8
009/019-th : 0.074 0.082 0.102 0.113 0.133 0.137 0.163 0.194  ||  -0.475 -0.368 -0.154 -0.048 0.109 0.144 0.316 0.490   || dis=0.03 || select=7/8
010/019-th : 0.091 0.094 0.108 0.121 0.134 0.144 0.150 0.158  ||  -0.295 -0.262 -0.125 -0.008 0.090 0.159 0.205 0.253   || dis=0.01 || select=7/8
011/019-th : 0.104 0.098 0.112 0.121 0.120 0.131 0.153 0.161  ||  -0.169 -0.230 -0.092 -0.020 -0.031 0.058 0.215 0.266  || dis=0.01 || select=7/8
012/019-th : 0.131 0.122 0.122 0.122 0.122 0.123 0.128 0.130  ||  0.043 -0.025 -0.023 -0.027 -0.029 -0.016 0.025 0.041  || dis=0.00 || select=0/8
013/019-th : 0.009 0.011 0.014 0.018 0.025 0.038 0.096 0.788  ||  -1.315 -1.135 -0.879 -0.680 -0.342 0.092 1.014 3.118  || dis=0.69 || select=7/8
014/019-th : 0.010 0.017 0.022 0.029 0.051 0.084 0.182 0.605  ||  -1.650 -1.122 -0.881 -0.573 -0.017 0.474 1.252 2.451  || dis=0.42 || select=7/8
015/019-th : 0.006 0.009 0.012 0.015 0.021 0.036 0.105 0.798  ||  -1.653 -1.215 -0.943 -0.723 -0.382 0.175 1.248 3.280  || dis=0.69 || select=7/8
016/019-th : 0.047 0.065 0.076 0.107 0.142 0.155 0.192 0.216  ||  -0.854 -0.540 -0.388 -0.036 0.243 0.329 0.542 0.662   || dis=0.02 || select=7/8
017/019-th : 0.086 0.100 0.104 0.126 0.137 0.137 0.153 0.158  ||  -0.352 -0.199 -0.156 0.033 0.120 0.118 0.228 0.260    || dis=0.01 || select=7/8
018/019-th : 0.089 0.106 0.117 0.138 0.130 0.132 0.138 0.150  ||  -0.328 -0.155 -0.053 0.115 0.052 0.065 0.116 0.197    || dis=0.01 || select=7/8
[epoch=404/600] FLOP : 26.08 MB, ratio : 0.6391, Expected-ratio : 0.7000, Discrepancy : 0.157
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:16:02] [epoch=404/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.824 (2.824)  Prec@1 43.36 (43.36) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:16:08] [epoch=404/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.325 (2.487)  Prec@1 60.12 (40.87) Prec@5 97.62 (82.90) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.87 Prec@5 82.90 Error@1 59.13 Error@5 17.10 Loss:2.487
***[2020-01-29 09:16:08]*** VALID [epoch=404/600] loss = 2.486714, accuracy@1 = 40.87, accuracy@5 = 82.90 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:16:08]*** start epoch=405/600 Time Left: [01:43:33], LR=[0.023875 ~ 0.023875], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=405, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.2698785164459256, FLOP=40.81
[Search] : epoch=405/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:16:09] [epoch=405/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.624 (0.624)  Prec@1 77.34 (77.34) Prec@5 99.61 (99.61) Acls-loss 0.749 (0.749) FLOP-Loss -2.893 (-2.893) Arch-Loss -5.038 (-5.038)
**TRAIN** [2020-01-29 09:16:34] [epoch=405/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.868 (0.722)  Prec@1 69.05 (75.20) Prec@5 97.62 (98.34) Acls-loss 0.774 (0.754) FLOP-Loss 2.896 (0.109) Arch-Loss 6.565 (0.971)
 **TRAIN** Prec@1 75.20 Prec@5 98.34 Error@1 24.80 Error@5 1.66 Base-Loss:0.722, Arch-Loss=0.971
***[2020-01-29 09:16:34]*** TRAIN [epoch=405/600] base-loss = 0.721988, arch-loss = 0.970916, accuracy-1 = 75.20, accuracy-5 = 98.34
[epoch=405/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 11, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.386 0.234 0.380  ||  0.1878 -0.3124 0.1739  || discrepancy=0.01 || select=0/3
001/003-th : 0.328 0.183 0.490  ||  0.0798 -0.5039 0.4812  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3299 -0.8794 2.8609  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.029 0.044 0.056 0.064 0.102 0.145 0.208 0.351  ||  -1.144 -0.746 -0.491 -0.361 0.105 0.449 0.813 1.337   || dis=0.14 || select=7/8
001/019-th : 0.106 0.128 0.146 0.132 0.131 0.125 0.123 0.109  ||  -0.156 0.034 0.165 0.061 0.057 0.005 -0.010 -0.126    || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.135 0.136 0.122 0.119 0.114 0.108  ||  0.056 0.077 0.075 0.083 -0.022 -0.048 -0.094 -0.148   || dis=0.00 || select=3/8
003/019-th : 0.101 0.116 0.124 0.127 0.127 0.135 0.133 0.137  ||  -0.206 -0.071 -0.008 0.018 0.022 0.080 0.067 0.094    || dis=0.00 || select=7/8
004/019-th : 0.116 0.109 0.117 0.125 0.124 0.131 0.137 0.141  ||  -0.071 -0.129 -0.061 0.001 0.001 0.054 0.094 0.125    || dis=0.00 || select=7/8
005/019-th : 0.109 0.124 0.126 0.125 0.131 0.128 0.127 0.130  ||  -0.137 -0.003 0.010 0.006 0.050 0.029 0.021 0.040     || dis=0.00 || select=4/8
006/019-th : 0.129 0.120 0.119 0.119 0.120 0.128 0.132 0.132  ||  0.037 -0.034 -0.045 -0.050 -0.039 0.028 0.056 0.060   || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.053 0.068 0.111 0.127 0.205 0.378  ||  -1.294 -0.949 -0.475 -0.231 0.258 0.392 0.871 1.480   || dis=0.17 || select=7/8
008/019-th : 0.018 0.026 0.041 0.064 0.095 0.153 0.257 0.346  ||  -1.498 -1.100 -0.654 -0.205 0.195 0.668 1.186 1.483   || dis=0.09 || select=7/8
009/019-th : 0.074 0.082 0.103 0.112 0.133 0.137 0.165 0.194  ||  -0.470 -0.368 -0.150 -0.062 0.112 0.142 0.324 0.485   || dis=0.03 || select=7/8
010/019-th : 0.091 0.095 0.108 0.120 0.135 0.143 0.149 0.158  ||  -0.295 -0.257 -0.123 -0.017 0.097 0.155 0.198 0.255   || dis=0.01 || select=7/8
011/019-th : 0.104 0.098 0.112 0.119 0.120 0.132 0.153 0.161  ||  -0.168 -0.226 -0.093 -0.039 -0.025 0.068 0.215 0.264  || dis=0.01 || select=7/8
012/019-th : 0.130 0.122 0.123 0.123 0.122 0.122 0.128 0.130  ||  0.040 -0.027 -0.019 -0.018 -0.021 -0.021 0.025 0.041  || dis=0.00 || select=7/8
013/019-th : 0.009 0.011 0.014 0.018 0.024 0.038 0.094 0.792  ||  -1.320 -1.142 -0.868 -0.675 -0.344 0.089 0.998 3.134  || dis=0.70 || select=7/8
014/019-th : 0.010 0.016 0.021 0.029 0.050 0.082 0.180 0.612  ||  -1.661 -1.142 -0.877 -0.580 -0.026 0.466 1.256 2.481  || dis=0.43 || select=7/8
015/019-th : 0.006 0.009 0.012 0.014 0.021 0.035 0.103 0.801  ||  -1.650 -1.211 -0.950 -0.726 -0.376 0.173 1.235 3.289  || dis=0.70 || select=7/8
016/019-th : 0.047 0.064 0.076 0.107 0.142 0.155 0.193 0.217  ||  -0.858 -0.553 -0.388 -0.037 0.240 0.329 0.549 0.667   || dis=0.02 || select=7/8
017/019-th : 0.086 0.099 0.104 0.128 0.136 0.136 0.153 0.159  ||  -0.351 -0.205 -0.159 0.047 0.107 0.112 0.228 0.264    || dis=0.01 || select=7/8
018/019-th : 0.088 0.105 0.118 0.140 0.131 0.131 0.138 0.149  ||  -0.335 -0.162 -0.043 0.132 0.061 0.066 0.113 0.192    || dis=0.01 || select=7/8
[epoch=405/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.157
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:16:34] [epoch=405/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.279 (1.279)  Prec@1 62.50 (62.50) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:16:40] [epoch=405/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.247 (2.312)  Prec@1 44.05 (35.72) Prec@5 84.52 (79.52) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.72 Prec@5 79.52 Error@1 64.28 Error@5 20.48 Loss:2.312
***[2020-01-29 09:16:40]*** VALID [epoch=405/600] loss = 2.311742, accuracy@1 = 35.72, accuracy@5 = 79.52 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:16:40]*** start epoch=406/600 Time Left: [01:43:02], LR=[0.023652 ~ 0.023652], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=406, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.25895830103314, FLOP=40.81
[Search] : epoch=406/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:16:41] [epoch=406/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.782 (0.782)  Prec@1 73.83 (73.83) Prec@5 98.05 (98.05) Acls-loss 1.029 (1.029) FLOP-Loss 2.896 (2.896) Arch-Loss 6.820 (6.820)
**TRAIN** [2020-01-29 09:17:05] [epoch=406/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.638 (0.690)  Prec@1 80.36 (76.30) Prec@5 98.81 (98.40) Acls-loss 0.665 (0.755) FLOP-Loss 0.000 (0.030) Arch-Loss 0.665 (0.815)
 **TRAIN** Prec@1 76.30 Prec@5 98.40 Error@1 23.70 Error@5 1.60 Base-Loss:0.690, Arch-Loss=0.815
***[2020-01-29 09:17:06]*** TRAIN [epoch=406/600] base-loss = 0.690217, arch-loss = 0.814784, accuracy-1 = 76.30, accuracy-5 = 98.40
[epoch=406/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.377728)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.383 0.234 0.383  ||  0.1816 -0.3115 0.1800  || discrepancy=0.00 || select=0/3
001/003-th : 0.325 0.183 0.492  ||  0.0737 -0.5009 0.4868  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3288 -0.8833 2.8635  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.043 0.056 0.064 0.102 0.140 0.212 0.355  ||  -1.170 -0.755 -0.491 -0.363 0.103 0.428 0.838 1.355   || dis=0.14 || select=7/8
001/019-th : 0.106 0.128 0.144 0.131 0.133 0.126 0.123 0.110  ||  -0.160 0.029 0.146 0.058 0.068 0.013 -0.007 -0.118    || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.133 0.134 0.122 0.120 0.115 0.109  ||  0.051 0.076 0.064 0.067 -0.028 -0.040 -0.086 -0.142   || dis=0.00 || select=1/8
003/019-th : 0.101 0.116 0.123 0.125 0.127 0.136 0.134 0.138  ||  -0.215 -0.073 -0.011 0.006 0.019 0.085 0.075 0.102    || dis=0.00 || select=7/8
004/019-th : 0.115 0.109 0.116 0.124 0.126 0.131 0.137 0.142  ||  -0.077 -0.135 -0.068 0.001 0.015 0.052 0.098 0.131    || dis=0.00 || select=7/8
005/019-th : 0.109 0.124 0.124 0.124 0.130 0.128 0.130 0.130  ||  -0.135 -0.005 -0.004 -0.005 0.037 0.025 0.039 0.043   || dis=0.00 || select=7/8
006/019-th : 0.129 0.120 0.118 0.119 0.122 0.128 0.132 0.133  ||  0.035 -0.039 -0.054 -0.050 -0.024 0.025 0.057 0.065   || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.053 0.068 0.110 0.127 0.206 0.378  ||  -1.282 -0.947 -0.480 -0.237 0.246 0.393 0.872 1.481   || dis=0.17 || select=7/8
008/019-th : 0.017 0.026 0.040 0.063 0.094 0.153 0.257 0.348  ||  -1.502 -1.095 -0.660 -0.211 0.185 0.673 1.188 1.491   || dis=0.09 || select=7/8
009/019-th : 0.074 0.082 0.101 0.113 0.131 0.139 0.167 0.194  ||  -0.474 -0.375 -0.161 -0.056 0.098 0.153 0.338 0.488   || dis=0.03 || select=7/8
010/019-th : 0.090 0.095 0.109 0.120 0.133 0.144 0.149 0.159  ||  -0.303 -0.257 -0.121 -0.020 0.084 0.164 0.199 0.261   || dis=0.01 || select=7/8
011/019-th : 0.104 0.098 0.112 0.116 0.123 0.132 0.155 0.161  ||  -0.170 -0.234 -0.100 -0.059 -0.005 0.067 0.228 0.268  || dis=0.01 || select=7/8
012/019-th : 0.129 0.122 0.122 0.123 0.122 0.124 0.129 0.130  ||  0.035 -0.027 -0.027 -0.018 -0.020 -0.010 0.029 0.041  || dis=0.00 || select=7/8
013/019-th : 0.009 0.011 0.014 0.017 0.024 0.038 0.092 0.794  ||  -1.326 -1.143 -0.868 -0.679 -0.347 0.101 0.987 3.142  || dis=0.70 || select=7/8
014/019-th : 0.010 0.016 0.021 0.028 0.050 0.081 0.179 0.615  ||  -1.666 -1.138 -0.883 -0.588 -0.026 0.459 1.255 2.490  || dis=0.44 || select=7/8
015/019-th : 0.006 0.009 0.011 0.014 0.020 0.035 0.101 0.804  ||  -1.640 -1.208 -0.947 -0.733 -0.387 0.163 1.229 3.304  || dis=0.70 || select=7/8
016/019-th : 0.047 0.063 0.075 0.107 0.140 0.156 0.194 0.219  ||  -0.859 -0.561 -0.399 -0.043 0.231 0.338 0.554 0.677   || dis=0.02 || select=7/8
017/019-th : 0.084 0.098 0.103 0.127 0.136 0.138 0.154 0.159  ||  -0.371 -0.212 -0.164 0.045 0.117 0.132 0.238 0.270    || dis=0.01 || select=7/8
018/019-th : 0.088 0.104 0.118 0.141 0.129 0.133 0.138 0.150  ||  -0.336 -0.164 -0.044 0.133 0.048 0.074 0.113 0.194    || dis=0.01 || select=7/8
[epoch=406/600] FLOP : 28.38 MB, ratio : 0.6953, Expected-ratio : 0.7000, Discrepancy : 0.158
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:17:06] [epoch=406/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.057 (2.057)  Prec@1 32.03 (32.03) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:17:12] [epoch=406/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.710 (2.354)  Prec@1 20.24 (36.47) Prec@5 69.05 (80.59) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.47 Prec@5 80.59 Error@1 63.53 Error@5 19.41 Loss:2.354
***[2020-01-29 09:17:12]*** VALID [epoch=406/600] loss = 2.354191, accuracy@1 = 36.47, accuracy@5 = 80.59 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:17:12]*** start epoch=407/600 Time Left: [01:42:30], LR=[0.023430 ~ 0.023430], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=407, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.2480734801806967, FLOP=40.81
[Search] : epoch=407/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:17:13] [epoch=407/600][000/098] Time 0.73 (0.73) Data 0.35 (0.35) Base-Loss 0.679 (0.679)  Prec@1 76.17 (76.17) Prec@5 98.44 (98.44) Acls-loss 0.467 (0.467) FLOP-Loss 0.000 (0.000) Arch-Loss 0.467 (0.467)
**TRAIN** [2020-01-29 09:17:37] [epoch=407/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.518 (0.695)  Prec@1 83.93 (76.20) Prec@5 98.21 (98.32) Acls-loss 0.537 (0.763) FLOP-Loss 0.000 (0.148) Arch-Loss 0.537 (1.060)
 **TRAIN** Prec@1 76.20 Prec@5 98.32 Error@1 23.80 Error@5 1.68 Base-Loss:0.695, Arch-Loss=1.060
***[2020-01-29 09:17:37]*** TRAIN [epoch=407/600] base-loss = 0.694911, arch-loss = 1.060369, accuracy-1 = 76.20, accuracy-5 = 98.32
[epoch=407/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.377728)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.381 0.238 0.381  ||  0.1802 -0.2888 0.1792  || discrepancy=0.00 || select=0/3
001/003-th : 0.324 0.185 0.491  ||  0.0715 -0.4880 0.4877  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3493 -0.8745 2.8811  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.043 0.056 0.064 0.101 0.139 0.210 0.358  ||  -1.175 -0.749 -0.494 -0.352 0.095 0.416 0.831 1.365   || dis=0.15 || select=7/8
001/019-th : 0.105 0.129 0.144 0.130 0.133 0.126 0.123 0.110  ||  -0.167 0.038 0.147 0.049 0.072 0.012 -0.007 -0.118    || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.134 0.133 0.121 0.121 0.115 0.109  ||  0.052 0.073 0.068 0.059 -0.031 -0.036 -0.084 -0.142   || dis=0.00 || select=1/8
003/019-th : 0.101 0.116 0.123 0.125 0.125 0.136 0.134 0.139  ||  -0.208 -0.070 -0.014 0.004 -0.002 0.084 0.072 0.106   || dis=0.00 || select=7/8
004/019-th : 0.114 0.109 0.117 0.124 0.127 0.131 0.136 0.141  ||  -0.082 -0.128 -0.061 0.001 0.021 0.054 0.093 0.129    || dis=0.00 || select=7/8
005/019-th : 0.108 0.123 0.125 0.125 0.130 0.128 0.129 0.131  ||  -0.140 -0.011 0.001 0.002 0.043 0.027 0.037 0.047     || dis=0.00 || select=7/8
006/019-th : 0.129 0.120 0.117 0.119 0.123 0.128 0.131 0.132  ||  0.034 -0.037 -0.060 -0.048 -0.010 0.031 0.053 0.062   || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.053 0.067 0.109 0.127 0.208 0.378  ||  -1.283 -0.941 -0.488 -0.249 0.241 0.395 0.885 1.484   || dis=0.17 || select=7/8
008/019-th : 0.018 0.026 0.040 0.064 0.095 0.153 0.257 0.347  ||  -1.495 -1.099 -0.665 -0.202 0.194 0.665 1.185 1.488   || dis=0.09 || select=7/8
009/019-th : 0.074 0.082 0.102 0.113 0.132 0.138 0.167 0.193  ||  -0.472 -0.378 -0.156 -0.052 0.104 0.149 0.337 0.483   || dis=0.03 || select=7/8
010/019-th : 0.090 0.094 0.108 0.120 0.134 0.144 0.149 0.160  ||  -0.309 -0.260 -0.123 -0.018 0.092 0.165 0.193 0.268   || dis=0.01 || select=7/8
011/019-th : 0.104 0.097 0.112 0.116 0.124 0.131 0.156 0.161  ||  -0.170 -0.241 -0.100 -0.062 0.005 0.058 0.239 0.268   || dis=0.01 || select=7/8
012/019-th : 0.129 0.121 0.122 0.123 0.124 0.123 0.128 0.130  ||  0.036 -0.029 -0.019 -0.018 -0.009 -0.018 0.028 0.040  || dis=0.00 || select=7/8
013/019-th : 0.009 0.011 0.014 0.017 0.024 0.037 0.089 0.799  ||  -1.329 -1.152 -0.865 -0.678 -0.341 0.090 0.971 3.166  || dis=0.71 || select=7/8
014/019-th : 0.010 0.016 0.021 0.027 0.049 0.080 0.178 0.619  ||  -1.663 -1.142 -0.875 -0.624 -0.022 0.455 1.261 2.506  || dis=0.44 || select=7/8
015/019-th : 0.006 0.009 0.011 0.014 0.020 0.034 0.098 0.809  ||  -1.643 -1.205 -0.942 -0.736 -0.385 0.148 1.211 3.326  || dis=0.71 || select=7/8
016/019-th : 0.047 0.063 0.075 0.106 0.140 0.155 0.195 0.218  ||  -0.853 -0.561 -0.396 -0.046 0.234 0.331 0.560 0.673   || dis=0.02 || select=7/8
017/019-th : 0.084 0.098 0.104 0.127 0.135 0.139 0.155 0.159  ||  -0.373 -0.216 -0.159 0.046 0.106 0.137 0.244 0.268    || dis=0.00 || select=7/8
018/019-th : 0.088 0.105 0.118 0.142 0.129 0.131 0.138 0.149  ||  -0.332 -0.162 -0.040 0.139 0.049 0.059 0.113 0.192    || dis=0.01 || select=7/8
[epoch=407/600] FLOP : 28.38 MB, ratio : 0.6953, Expected-ratio : 0.7000, Discrepancy : 0.158
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:17:38] [epoch=407/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.893 (1.893)  Prec@1 36.33 (36.33) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:17:44] [epoch=407/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.954 (2.382)  Prec@1 42.86 (38.32) Prec@5 85.12 (81.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.32 Prec@5 81.07 Error@1 61.68 Error@5 18.93 Loss:2.382
***[2020-01-29 09:17:44]*** VALID [epoch=407/600] loss = 2.382157, accuracy@1 = 38.32, accuracy@5 = 81.07 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:17:44]*** start epoch=408/600 Time Left: [01:41:58], LR=[0.023209 ~ 0.023209], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=408, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.2372243523014579, FLOP=40.81
[Search] : epoch=408/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:17:45] [epoch=408/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.503 (0.503)  Prec@1 85.16 (85.16) Prec@5 98.44 (98.44) Acls-loss 0.747 (0.747) FLOP-Loss 0.000 (0.000) Arch-Loss 0.747 (0.747)
**TRAIN** [2020-01-29 09:18:09] [epoch=408/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.624 (0.711)  Prec@1 77.38 (75.79) Prec@5 98.81 (98.38) Acls-loss 0.824 (0.753) FLOP-Loss 0.000 (0.149) Arch-Loss 0.824 (1.050)
 **TRAIN** Prec@1 75.79 Prec@5 98.38 Error@1 24.21 Error@5 1.62 Base-Loss:0.711, Arch-Loss=1.050
***[2020-01-29 09:18:09]*** TRAIN [epoch=408/600] base-loss = 0.710837, arch-loss = 1.049612, accuracy-1 = 75.79, accuracy-5 = 98.38
[epoch=408/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 16, 16, 11, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.557952)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.380 0.239 0.380  ||  0.1796 -0.2839 0.1792  || discrepancy=0.00 || select=0/3
001/003-th : 0.325 0.185 0.491  ||  0.0731 -0.4896 0.4861  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3377 -0.8721 2.8712  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.044 0.055 0.064 0.102 0.137 0.210 0.359  ||  -1.177 -0.743 -0.502 -0.359 0.113 0.407 0.832 1.368   || dis=0.15 || select=7/8
001/019-th : 0.105 0.129 0.143 0.130 0.134 0.125 0.123 0.110  ||  -0.167 0.036 0.143 0.049 0.079 0.012 -0.006 -0.117    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.134 0.132 0.122 0.121 0.115 0.109  ||  0.056 0.069 0.070 0.055 -0.031 -0.038 -0.082 -0.144   || dis=0.00 || select=2/8
003/019-th : 0.102 0.116 0.123 0.125 0.125 0.134 0.135 0.139  ||  -0.206 -0.071 -0.015 0.004 0.003 0.072 0.077 0.105    || dis=0.00 || select=7/8
004/019-th : 0.114 0.110 0.116 0.124 0.127 0.130 0.137 0.142  ||  -0.085 -0.121 -0.067 -0.006 0.021 0.048 0.094 0.133   || dis=0.00 || select=7/8
005/019-th : 0.107 0.123 0.125 0.124 0.131 0.129 0.128 0.131  ||  -0.147 -0.009 0.004 -0.002 0.051 0.038 0.030 0.047    || dis=0.00 || select=4/8
006/019-th : 0.129 0.120 0.118 0.118 0.124 0.128 0.131 0.132  ||  0.036 -0.033 -0.052 -0.053 -0.004 0.030 0.048 0.058   || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.053 0.068 0.110 0.127 0.205 0.380  ||  -1.279 -0.946 -0.488 -0.241 0.250 0.388 0.870 1.486   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.040 0.063 0.096 0.153 0.255 0.350  ||  -1.499 -1.098 -0.661 -0.222 0.203 0.668 1.179 1.495   || dis=0.09 || select=7/8
009/019-th : 0.075 0.082 0.102 0.111 0.131 0.140 0.168 0.192  ||  -0.462 -0.377 -0.155 -0.071 0.099 0.160 0.347 0.477   || dis=0.02 || select=7/8
010/019-th : 0.089 0.093 0.109 0.119 0.134 0.145 0.150 0.161  ||  -0.313 -0.272 -0.116 -0.028 0.092 0.168 0.202 0.273   || dis=0.01 || select=7/8
011/019-th : 0.104 0.098 0.112 0.115 0.124 0.129 0.156 0.161  ||  -0.166 -0.234 -0.097 -0.066 0.006 0.048 0.233 0.268   || dis=0.01 || select=7/8
012/019-th : 0.129 0.122 0.123 0.124 0.123 0.122 0.129 0.129  ||  0.035 -0.025 -0.015 -0.009 -0.016 -0.024 0.030 0.037  || dis=0.00 || select=7/8
013/019-th : 0.009 0.010 0.014 0.017 0.024 0.037 0.088 0.801  ||  -1.315 -1.168 -0.870 -0.670 -0.341 0.087 0.961 3.175  || dis=0.71 || select=7/8
014/019-th : 0.010 0.016 0.021 0.027 0.048 0.080 0.178 0.621  ||  -1.653 -1.149 -0.879 -0.626 -0.050 0.464 1.264 2.516  || dis=0.44 || select=7/8
015/019-th : 0.006 0.009 0.011 0.014 0.020 0.034 0.096 0.812  ||  -1.638 -1.204 -0.970 -0.738 -0.385 0.156 1.203 3.341  || dis=0.72 || select=7/8
016/019-th : 0.048 0.064 0.075 0.105 0.139 0.159 0.193 0.218  ||  -0.848 -0.560 -0.393 -0.061 0.223 0.361 0.553 0.672   || dis=0.02 || select=7/8
017/019-th : 0.083 0.098 0.103 0.130 0.134 0.140 0.155 0.158  ||  -0.380 -0.218 -0.158 0.067 0.099 0.143 0.246 0.264    || dis=0.00 || select=7/8
018/019-th : 0.088 0.105 0.120 0.140 0.130 0.131 0.137 0.149  ||  -0.334 -0.163 -0.023 0.127 0.054 0.059 0.108 0.192    || dis=0.01 || select=7/8
[epoch=408/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.159
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:18:10] [epoch=408/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 4.120 (4.120)  Prec@1 14.84 (14.84) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:18:16] [epoch=408/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.206 (2.223)  Prec@1 35.71 (39.44) Prec@5 84.52 (81.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.44 Prec@5 81.40 Error@1 60.56 Error@5 18.60 Loss:2.223
***[2020-01-29 09:18:16]*** VALID [epoch=408/600] loss = 2.222965, accuracy@1 = 39.44, accuracy@5 = 81.40 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:18:16]*** start epoch=409/600 Time Left: [01:41:26], LR=[0.022988 ~ 0.022988], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=409, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.2264112148297455, FLOP=40.81
[Search] : epoch=409/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:18:17] [epoch=409/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.562 (0.562)  Prec@1 83.20 (83.20) Prec@5 99.22 (99.22) Acls-loss 0.582 (0.582) FLOP-Loss 0.000 (0.000) Arch-Loss 0.582 (0.582)
**TRAIN** [2020-01-29 09:18:41] [epoch=409/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.595 (0.707)  Prec@1 80.36 (75.79) Prec@5 98.81 (98.19) Acls-loss 0.537 (0.790) FLOP-Loss 2.902 (0.168) Arch-Loss 6.342 (1.127)
 **TRAIN** Prec@1 75.79 Prec@5 98.19 Error@1 24.21 Error@5 1.81 Base-Loss:0.707, Arch-Loss=1.127
***[2020-01-29 09:18:41]*** TRAIN [epoch=409/600] base-loss = 0.707172, arch-loss = 1.126628, accuracy-1 = 75.79, accuracy-5 = 98.19
[epoch=409/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 28.648064)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.379 0.244 0.377  ||  0.1810 -0.2591 0.1752  || discrepancy=0.00 || select=0/3
001/003-th : 0.323 0.187 0.490  ||  0.0708 -0.4780 0.4871  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3334 -0.8789 2.8716  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.043 0.055 0.064 0.100 0.138 0.210 0.361  ||  -1.170 -0.743 -0.510 -0.353 0.093 0.408 0.829 1.374   || dis=0.15 || select=7/8
001/019-th : 0.104 0.129 0.143 0.131 0.133 0.126 0.123 0.110  ||  -0.171 0.043 0.140 0.058 0.069 0.017 -0.007 -0.118    || dis=0.01 || select=2/8
002/019-th : 0.132 0.134 0.134 0.134 0.122 0.121 0.115 0.108  ||  0.053 0.068 0.067 0.068 -0.022 -0.035 -0.081 -0.145   || dis=0.00 || select=3/8
003/019-th : 0.101 0.114 0.123 0.127 0.127 0.134 0.134 0.139  ||  -0.212 -0.086 -0.011 0.017 0.020 0.074 0.073 0.111    || dis=0.01 || select=7/8
004/019-th : 0.114 0.110 0.117 0.121 0.128 0.132 0.136 0.141  ||  -0.084 -0.118 -0.063 -0.029 0.027 0.063 0.094 0.128   || dis=0.00 || select=7/8
005/019-th : 0.107 0.123 0.125 0.125 0.129 0.129 0.129 0.131  ||  -0.148 -0.013 0.005 0.006 0.037 0.033 0.034 0.053     || dis=0.00 || select=7/8
006/019-th : 0.129 0.121 0.118 0.118 0.124 0.128 0.130 0.132  ||  0.039 -0.033 -0.053 -0.049 -0.008 0.028 0.044 0.058   || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.051 0.066 0.109 0.125 0.208 0.384  ||  -1.287 -0.954 -0.508 -0.257 0.250 0.384 0.892 1.505   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.040 0.062 0.096 0.152 0.254 0.351  ||  -1.489 -1.098 -0.665 -0.230 0.202 0.664 1.173 1.499   || dis=0.10 || select=7/8
009/019-th : 0.075 0.081 0.102 0.110 0.130 0.140 0.169 0.192  ||  -0.455 -0.384 -0.156 -0.077 0.089 0.164 0.352 0.479   || dis=0.02 || select=7/8
010/019-th : 0.089 0.093 0.110 0.119 0.134 0.144 0.149 0.161  ||  -0.315 -0.278 -0.104 -0.028 0.095 0.166 0.199 0.274   || dis=0.01 || select=7/8
011/019-th : 0.103 0.098 0.112 0.116 0.123 0.130 0.156 0.161  ||  -0.179 -0.229 -0.091 -0.063 0.001 0.057 0.238 0.265   || dis=0.01 || select=7/8
012/019-th : 0.129 0.121 0.124 0.123 0.123 0.122 0.129 0.129  ||  0.034 -0.032 -0.009 -0.012 -0.014 -0.019 0.032 0.036  || dis=0.00 || select=7/8
013/019-th : 0.009 0.010 0.013 0.016 0.023 0.034 0.084 0.811  ||  -1.310 -1.184 -0.883 -0.687 -0.345 0.064 0.952 3.226  || dis=0.73 || select=7/8
014/019-th : 0.010 0.016 0.021 0.027 0.047 0.080 0.175 0.624  ||  -1.649 -1.156 -0.886 -0.626 -0.052 0.473 1.254 2.523  || dis=0.45 || select=7/8
015/019-th : 0.005 0.008 0.011 0.014 0.019 0.033 0.096 0.813  ||  -1.654 -1.217 -0.981 -0.723 -0.387 0.158 1.209 3.349  || dis=0.72 || select=7/8
016/019-th : 0.047 0.064 0.075 0.104 0.139 0.159 0.194 0.219  ||  -0.864 -0.557 -0.395 -0.064 0.222 0.362 0.560 0.678   || dis=0.02 || select=7/8
017/019-th : 0.083 0.097 0.103 0.129 0.134 0.141 0.155 0.158  ||  -0.383 -0.221 -0.159 0.063 0.103 0.152 0.247 0.264    || dis=0.00 || select=7/8
018/019-th : 0.088 0.103 0.120 0.139 0.129 0.133 0.137 0.149  ||  -0.333 -0.175 -0.023 0.125 0.047 0.075 0.109 0.194    || dis=0.01 || select=7/8
[epoch=409/600] FLOP : 28.65 MB, ratio : 0.7019, Expected-ratio : 0.7000, Discrepancy : 0.161
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:18:42] [epoch=409/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.011 (1.011)  Prec@1 63.67 (63.67) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:18:48] [epoch=409/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.665 (2.215)  Prec@1 56.55 (41.28) Prec@5 92.86 (82.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.28 Prec@5 82.32 Error@1 58.72 Error@5 17.68 Loss:2.215
***[2020-01-29 09:18:48]*** VALID [epoch=409/600] loss = 2.214686, accuracy@1 = 41.28, accuracy@5 = 82.32 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:18:48]*** start epoch=410/600 Time Left: [01:40:54], LR=[0.022768 ~ 0.022768], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=410, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.2156343642131837, FLOP=40.81
[Search] : epoch=410/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:18:49] [epoch=410/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.692 (0.692)  Prec@1 75.78 (75.78) Prec@5 99.22 (99.22) Acls-loss 0.634 (0.634) FLOP-Loss 2.902 (2.902) Arch-Loss 6.438 (6.438)
**TRAIN** [2020-01-29 09:19:14] [epoch=410/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.767 (0.680)  Prec@1 76.19 (77.10) Prec@5 98.81 (98.39) Acls-loss 0.628 (0.719) FLOP-Loss 2.903 (0.109) Arch-Loss 6.434 (0.937)
 **TRAIN** Prec@1 77.10 Prec@5 98.39 Error@1 22.90 Error@5 1.61 Base-Loss:0.680, Arch-Loss=0.937
***[2020-01-29 09:19:14]*** TRAIN [epoch=410/600] base-loss = 0.679935, arch-loss = 0.936994, accuracy-1 = 77.10, accuracy-5 = 98.39
[epoch=410/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 37.200512)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.376 0.248 0.376  ||  0.1769 -0.2411 0.1774  || discrepancy=0.00 || select=2/3
001/003-th : 0.323 0.188 0.489  ||  0.0704 -0.4714 0.4868  || discrepancy=0.17 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3299 -0.8878 2.8736  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.043 0.055 0.065 0.099 0.139 0.211 0.360  ||  -1.190 -0.750 -0.508 -0.339 0.085 0.422 0.840 1.375   || dis=0.15 || select=7/8
001/019-th : 0.104 0.130 0.143 0.132 0.132 0.125 0.124 0.110  ||  -0.172 0.045 0.142 0.066 0.062 0.008 -0.003 -0.120    || dis=0.01 || select=2/8
002/019-th : 0.131 0.133 0.133 0.134 0.123 0.121 0.115 0.108  ||  0.051 0.066 0.066 0.073 -0.012 -0.034 -0.079 -0.148   || dis=0.00 || select=3/8
003/019-th : 0.101 0.114 0.123 0.128 0.126 0.134 0.134 0.140  ||  -0.211 -0.089 -0.016 0.030 0.012 0.075 0.071 0.113    || dis=0.01 || select=7/8
004/019-th : 0.114 0.110 0.114 0.120 0.131 0.133 0.137 0.142  ||  -0.084 -0.119 -0.086 -0.037 0.056 0.065 0.095 0.131   || dis=0.00 || select=7/8
005/019-th : 0.108 0.122 0.125 0.125 0.130 0.129 0.129 0.132  ||  -0.145 -0.019 0.005 -0.000 0.039 0.031 0.030 0.059    || dis=0.00 || select=7/8
006/019-th : 0.130 0.120 0.119 0.119 0.123 0.128 0.129 0.132  ||  0.043 -0.034 -0.049 -0.044 -0.010 0.026 0.036 0.058   || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.051 0.066 0.107 0.127 0.206 0.387  ||  -1.283 -0.959 -0.514 -0.252 0.231 0.397 0.886 1.513   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.040 0.061 0.094 0.155 0.254 0.352  ||  -1.478 -1.110 -0.670 -0.246 0.187 0.683 1.176 1.503   || dis=0.10 || select=7/8
009/019-th : 0.076 0.082 0.103 0.110 0.127 0.141 0.169 0.193  ||  -0.451 -0.374 -0.150 -0.082 0.067 0.165 0.347 0.480   || dis=0.02 || select=7/8
010/019-th : 0.089 0.092 0.108 0.119 0.140 0.144 0.149 0.160  ||  -0.318 -0.283 -0.123 -0.027 0.138 0.166 0.204 0.270   || dis=0.01 || select=7/8
011/019-th : 0.103 0.098 0.112 0.116 0.124 0.130 0.157 0.161  ||  -0.178 -0.229 -0.096 -0.058 0.003 0.051 0.240 0.267   || dis=0.00 || select=7/8
012/019-th : 0.129 0.121 0.124 0.124 0.122 0.121 0.129 0.129  ||  0.036 -0.028 -0.005 -0.009 -0.019 -0.028 0.030 0.036  || dis=0.00 || select=7/8
013/019-th : 0.009 0.010 0.013 0.016 0.023 0.034 0.083 0.812  ||  -1.303 -1.191 -0.887 -0.680 -0.353 0.068 0.945 3.231  || dis=0.73 || select=7/8
014/019-th : 0.010 0.015 0.021 0.027 0.047 0.080 0.176 0.624  ||  -1.640 -1.171 -0.877 -0.628 -0.053 0.470 1.261 2.524  || dis=0.45 || select=7/8
015/019-th : 0.006 0.008 0.011 0.014 0.019 0.033 0.094 0.814  ||  -1.643 -1.219 -0.974 -0.714 -0.386 0.155 1.196 3.351  || dis=0.72 || select=7/8
016/019-th : 0.046 0.063 0.074 0.104 0.137 0.162 0.194 0.220  ||  -0.869 -0.559 -0.405 -0.064 0.211 0.379 0.561 0.684   || dis=0.03 || select=7/8
017/019-th : 0.082 0.098 0.102 0.130 0.133 0.142 0.155 0.158  ||  -0.385 -0.217 -0.171 0.068 0.094 0.156 0.247 0.267    || dis=0.00 || select=7/8
018/019-th : 0.088 0.103 0.121 0.142 0.129 0.132 0.136 0.149  ||  -0.335 -0.177 -0.013 0.140 0.049 0.070 0.098 0.193    || dis=0.01 || select=7/8
[epoch=410/600] FLOP : 37.20 MB, ratio : 0.9115, Expected-ratio : 0.7000, Discrepancy : 0.161
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:19:14] [epoch=410/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.370 (2.370)  Prec@1 33.98 (33.98) Prec@5 73.05 (73.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:19:20] [epoch=410/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 5.423 (2.378)  Prec@1 16.07 (39.34) Prec@5 57.14 (81.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.34 Prec@5 81.84 Error@1 60.66 Error@5 18.16 Loss:2.378
***[2020-01-29 09:19:20]*** VALID [epoch=410/600] loss = 2.377632, accuracy@1 = 39.34, accuracy@5 = 81.84 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:19:20]*** start epoch=411/600 Time Left: [01:40:23], LR=[0.022549 ~ 0.022549], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=411, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.204894095904577, FLOP=40.81
[Search] : epoch=411/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:19:21] [epoch=411/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.683 (0.683)  Prec@1 78.91 (78.91) Prec@5 98.44 (98.44) Acls-loss 0.660 (0.660) FLOP-Loss 2.903 (2.903) Arch-Loss 6.465 (6.465)
**TRAIN** [2020-01-29 09:19:46] [epoch=411/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.532 (0.688)  Prec@1 83.93 (76.48) Prec@5 98.81 (98.38) Acls-loss 0.591 (0.736) FLOP-Loss -2.902 (0.189) Arch-Loss -5.213 (1.114)
 **TRAIN** Prec@1 76.48 Prec@5 98.38 Error@1 23.52 Error@5 1.62 Base-Loss:0.688, Arch-Loss=1.114
***[2020-01-29 09:19:46]*** TRAIN [epoch=411/600] base-loss = 0.688318, arch-loss = 1.113510, accuracy-1 = 76.48, accuracy-5 = 98.38
[epoch=411/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.813632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.377 0.247 0.376  ||  0.1777 -0.2461 0.1767  || discrepancy=0.00 || select=0/3
001/003-th : 0.324 0.189 0.487  ||  0.0736 -0.4619 0.4828  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3351 -0.8813 2.8779  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.042 0.055 0.064 0.098 0.137 0.215 0.362  ||  -1.192 -0.761 -0.501 -0.355 0.072 0.411 0.861 1.385   || dis=0.15 || select=7/8
001/019-th : 0.105 0.131 0.143 0.132 0.132 0.125 0.123 0.109  ||  -0.167 0.054 0.140 0.064 0.066 0.004 -0.006 -0.127    || dis=0.01 || select=2/8
002/019-th : 0.131 0.134 0.134 0.134 0.123 0.121 0.116 0.107  ||  0.051 0.073 0.068 0.068 -0.015 -0.032 -0.077 -0.153   || dis=0.00 || select=1/8
003/019-th : 0.102 0.113 0.122 0.128 0.126 0.135 0.134 0.140  ||  -0.205 -0.097 -0.021 0.028 0.009 0.081 0.073 0.114    || dis=0.01 || select=7/8
004/019-th : 0.114 0.109 0.113 0.120 0.130 0.134 0.137 0.142  ||  -0.084 -0.127 -0.092 -0.038 0.047 0.075 0.100 0.134   || dis=0.00 || select=7/8
005/019-th : 0.108 0.123 0.126 0.125 0.128 0.129 0.128 0.132  ||  -0.146 -0.011 0.009 0.004 0.023 0.033 0.025 0.058     || dis=0.00 || select=7/8
006/019-th : 0.130 0.120 0.119 0.119 0.125 0.127 0.129 0.132  ||  0.041 -0.036 -0.046 -0.045 0.003 0.018 0.038 0.058    || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.051 0.067 0.107 0.126 0.204 0.388  ||  -1.288 -0.949 -0.514 -0.242 0.230 0.392 0.873 1.515   || dis=0.18 || select=7/8
008/019-th : 0.018 0.026 0.039 0.061 0.095 0.155 0.254 0.352  ||  -1.476 -1.099 -0.694 -0.243 0.192 0.682 1.178 1.502   || dis=0.10 || select=7/8
009/019-th : 0.076 0.083 0.102 0.110 0.128 0.143 0.167 0.192  ||  -0.456 -0.365 -0.157 -0.082 0.070 0.186 0.335 0.480   || dis=0.02 || select=7/8
010/019-th : 0.090 0.092 0.108 0.118 0.139 0.143 0.149 0.160  ||  -0.304 -0.279 -0.124 -0.033 0.131 0.159 0.196 0.269   || dis=0.01 || select=7/8
011/019-th : 0.103 0.098 0.111 0.117 0.123 0.131 0.155 0.161  ||  -0.176 -0.225 -0.105 -0.051 -0.001 0.058 0.230 0.269  || dis=0.01 || select=7/8
012/019-th : 0.130 0.122 0.125 0.125 0.120 0.122 0.128 0.129  ||  0.037 -0.022 0.001 -0.000 -0.041 -0.027 0.026 0.033   || dis=0.00 || select=0/8
013/019-th : 0.009 0.010 0.013 0.016 0.022 0.034 0.082 0.814  ||  -1.286 -1.182 -0.882 -0.680 -0.375 0.064 0.938 3.237  || dis=0.73 || select=7/8
014/019-th : 0.010 0.015 0.021 0.027 0.047 0.079 0.175 0.627  ||  -1.630 -1.174 -0.874 -0.629 -0.066 0.458 1.261 2.534  || dis=0.45 || select=7/8
015/019-th : 0.006 0.009 0.011 0.014 0.019 0.034 0.093 0.815  ||  -1.635 -1.211 -0.976 -0.714 -0.397 0.169 1.184 3.350  || dis=0.72 || select=7/8
016/019-th : 0.046 0.063 0.074 0.104 0.135 0.161 0.195 0.220  ||  -0.873 -0.558 -0.399 -0.060 0.198 0.376 0.564 0.685   || dis=0.02 || select=7/8
017/019-th : 0.083 0.098 0.103 0.130 0.132 0.142 0.155 0.159  ||  -0.382 -0.216 -0.167 0.069 0.084 0.155 0.242 0.268    || dis=0.00 || select=7/8
018/019-th : 0.089 0.103 0.122 0.140 0.129 0.133 0.135 0.149  ||  -0.323 -0.176 -0.014 0.127 0.049 0.074 0.089 0.193    || dis=0.01 || select=7/8
[epoch=411/600] FLOP : 25.81 MB, ratio : 0.6325, Expected-ratio : 0.7000, Discrepancy : 0.162
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:19:47] [epoch=411/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.097 (3.097)  Prec@1 23.05 (23.05) Prec@5 68.75 (68.75) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:19:53] [epoch=411/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.873 (2.253)  Prec@1 32.74 (38.77) Prec@5 80.95 (81.50) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.77 Prec@5 81.50 Error@1 61.23 Error@5 18.50 Loss:2.253
***[2020-01-29 09:19:53]*** VALID [epoch=411/600] loss = 2.252743, accuracy@1 = 38.77, accuracy@5 = 81.50 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:19:53]*** start epoch=412/600 Time Left: [01:39:51], LR=[0.022330 ~ 0.022330], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=412, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1941907043538074, FLOP=40.81
[Search] : epoch=412/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:19:54] [epoch=412/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.562 (0.562)  Prec@1 80.86 (80.86) Prec@5 98.44 (98.44) Acls-loss 0.863 (0.863) FLOP-Loss -2.902 (-2.902) Arch-Loss -4.941 (-4.941)
**TRAIN** [2020-01-29 09:20:19] [epoch=412/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.543 (0.671)  Prec@1 84.52 (77.27) Prec@5 98.81 (98.49) Acls-loss 0.733 (0.749) FLOP-Loss 2.902 (0.228) Arch-Loss 6.538 (1.204)
 **TRAIN** Prec@1 77.27 Prec@5 98.49 Error@1 22.73 Error@5 1.51 Base-Loss:0.671, Arch-Loss=1.204
***[2020-01-29 09:20:19]*** TRAIN [epoch=412/600] base-loss = 0.671344, arch-loss = 1.204422, accuracy-1 = 77.27, accuracy-5 = 98.49
[epoch=412/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.813632)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.375 0.251 0.374  ||  0.1768 -0.2249 0.1755  || discrepancy=0.00 || select=0/3
001/003-th : 0.323 0.192 0.485  ||  0.0747 -0.4487 0.4804  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.972  ||  -2.3404 -0.8819 2.8848  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.042 0.055 0.063 0.098 0.136 0.215 0.363  ||  -1.177 -0.765 -0.505 -0.363 0.073 0.402 0.862 1.386   || dis=0.15 || select=7/8
001/019-th : 0.105 0.132 0.142 0.133 0.132 0.124 0.123 0.109  ||  -0.166 0.063 0.133 0.071 0.065 0.001 -0.011 -0.130    || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.134 0.134 0.124 0.121 0.115 0.107  ||  0.056 0.075 0.068 0.071 -0.011 -0.035 -0.083 -0.157   || dis=0.00 || select=1/8
003/019-th : 0.102 0.115 0.123 0.127 0.126 0.135 0.134 0.139  ||  -0.200 -0.086 -0.019 0.021 0.008 0.075 0.068 0.109    || dis=0.00 || select=7/8
004/019-th : 0.114 0.110 0.114 0.122 0.128 0.134 0.136 0.142  ||  -0.082 -0.125 -0.089 -0.017 0.031 0.076 0.091 0.134   || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.127 0.125 0.127 0.128 0.127 0.133  ||  -0.145 -0.004 0.015 -0.000 0.018 0.021 0.018 0.063    || dis=0.01 || select=7/8
006/019-th : 0.130 0.120 0.119 0.117 0.127 0.126 0.129 0.132  ||  0.045 -0.034 -0.047 -0.066 0.018 0.013 0.034 0.059    || dis=0.00 || select=7/8
007/019-th : 0.023 0.033 0.051 0.067 0.107 0.125 0.202 0.392  ||  -1.294 -0.941 -0.519 -0.245 0.226 0.388 0.863 1.527   || dis=0.19 || select=7/8
008/019-th : 0.018 0.026 0.040 0.061 0.094 0.154 0.253 0.353  ||  -1.472 -1.090 -0.676 -0.247 0.177 0.672 1.170 1.503   || dis=0.10 || select=7/8
009/019-th : 0.075 0.084 0.102 0.109 0.128 0.144 0.166 0.192  ||  -0.461 -0.354 -0.152 -0.092 0.074 0.190 0.330 0.478   || dis=0.03 || select=7/8
010/019-th : 0.091 0.092 0.109 0.118 0.138 0.144 0.148 0.159  ||  -0.297 -0.281 -0.114 -0.032 0.120 0.162 0.193 0.264   || dis=0.01 || select=7/8
011/019-th : 0.104 0.099 0.111 0.119 0.121 0.131 0.154 0.161  ||  -0.173 -0.223 -0.106 -0.033 -0.017 0.060 0.225 0.266  || dis=0.01 || select=7/8
012/019-th : 0.130 0.123 0.125 0.125 0.120 0.120 0.128 0.129  ||  0.043 -0.017 0.003 0.003 -0.043 -0.042 0.025 0.029    || dis=0.00 || select=0/8
013/019-th : 0.009 0.010 0.013 0.016 0.021 0.034 0.080 0.817  ||  -1.278 -1.191 -0.890 -0.674 -0.388 0.061 0.935 3.252  || dis=0.74 || select=7/8
014/019-th : 0.010 0.015 0.021 0.026 0.046 0.077 0.172 0.633  ||  -1.620 -1.171 -0.876 -0.631 -0.072 0.447 1.243 2.548  || dis=0.46 || select=7/8
015/019-th : 0.006 0.008 0.011 0.014 0.019 0.034 0.092 0.817  ||  -1.638 -1.209 -0.982 -0.712 -0.396 0.169 1.173 3.363  || dis=0.72 || select=7/8
016/019-th : 0.046 0.064 0.075 0.104 0.134 0.162 0.194 0.221  ||  -0.879 -0.552 -0.394 -0.067 0.190 0.380 0.560 0.690   || dis=0.03 || select=7/8
017/019-th : 0.083 0.097 0.102 0.130 0.133 0.143 0.154 0.158  ||  -0.381 -0.218 -0.175 0.071 0.093 0.164 0.240 0.266    || dis=0.00 || select=7/8
018/019-th : 0.089 0.104 0.123 0.138 0.129 0.132 0.135 0.149  ||  -0.323 -0.172 -0.004 0.114 0.049 0.072 0.087 0.192    || dis=0.01 || select=7/8
[epoch=412/600] FLOP : 25.81 MB, ratio : 0.6325, Expected-ratio : 0.7000, Discrepancy : 0.163
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:20:20] [epoch=412/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 3.610 (3.610)  Prec@1 21.09 (21.09) Prec@5 68.36 (68.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:20:26] [epoch=412/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.521 (2.477)  Prec@1 49.40 (34.95) Prec@5 87.50 (78.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 34.95 Prec@5 78.07 Error@1 65.05 Error@5 21.93 Loss:2.477
***[2020-01-29 09:20:26]*** VALID [epoch=412/600] loss = 2.477142, accuracy@1 = 34.95, accuracy@5 = 78.07 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:20:26]*** start epoch=413/600 Time Left: [01:39:20], LR=[0.022113 ~ 0.022113], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=413, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1835244829997595, FLOP=40.81
[Search] : epoch=413/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:20:27] [epoch=413/600][000/098] Time 0.79 (0.79) Data 0.38 (0.38) Base-Loss 0.576 (0.576)  Prec@1 80.47 (80.47) Prec@5 98.44 (98.44) Acls-loss 0.720 (0.720) FLOP-Loss -2.902 (-2.902) Arch-Loss -5.084 (-5.084)
**TRAIN** [2020-01-29 09:20:54] [epoch=413/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 0.757 (0.670)  Prec@1 74.40 (77.45) Prec@5 98.81 (98.44) Acls-loss 0.780 (0.728) FLOP-Loss -2.902 (0.189) Arch-Loss -5.023 (1.106)
 **TRAIN** Prec@1 77.45 Prec@5 98.44 Error@1 22.55 Error@5 1.56 Base-Loss:0.670, Arch-Loss=1.106
***[2020-01-29 09:20:54]*** TRAIN [epoch=413/600] base-loss = 0.669992, arch-loss = 1.105568, accuracy-1 = 77.45, accuracy-5 = 98.44
[epoch=413/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.083968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.375 0.251 0.375  ||  0.1766 -0.2263 0.1756  || discrepancy=0.00 || select=0/3
001/003-th : 0.325 0.189 0.487  ||  0.0759 -0.4667 0.4807  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3533 -0.8941 2.9029  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.042 0.054 0.062 0.099 0.136 0.215 0.363  ||  -1.164 -0.769 -0.515 -0.375 0.086 0.402 0.862 1.387   || dis=0.15 || select=7/8
001/019-th : 0.106 0.133 0.142 0.135 0.131 0.123 0.122 0.109  ||  -0.161 0.071 0.134 0.085 0.053 -0.007 -0.017 -0.133   || dis=0.01 || select=2/8
002/019-th : 0.132 0.135 0.133 0.135 0.123 0.121 0.115 0.106  ||  0.060 0.075 0.064 0.078 -0.015 -0.034 -0.083 -0.160   || dis=0.00 || select=3/8
003/019-th : 0.102 0.115 0.123 0.127 0.126 0.134 0.133 0.139  ||  -0.197 -0.083 -0.015 0.019 0.013 0.074 0.067 0.105    || dis=0.01 || select=7/8
004/019-th : 0.114 0.109 0.114 0.123 0.128 0.134 0.136 0.142  ||  -0.085 -0.127 -0.084 -0.010 0.027 0.080 0.089 0.133   || dis=0.01 || select=7/8
005/019-th : 0.108 0.125 0.126 0.125 0.127 0.129 0.127 0.133  ||  -0.143 -0.002 0.009 0.001 0.017 0.030 0.016 0.061     || dis=0.00 || select=7/8
006/019-th : 0.131 0.121 0.119 0.115 0.126 0.127 0.129 0.132  ||  0.050 -0.033 -0.047 -0.083 0.014 0.020 0.038 0.054    || dis=0.00 || select=7/8
007/019-th : 0.023 0.033 0.051 0.066 0.105 0.127 0.201 0.393  ||  -1.294 -0.947 -0.510 -0.247 0.211 0.401 0.861 1.529   || dis=0.19 || select=7/8
008/019-th : 0.017 0.027 0.039 0.062 0.094 0.152 0.257 0.352  ||  -1.501 -1.077 -0.683 -0.234 0.186 0.664 1.190 1.506   || dis=0.09 || select=7/8
009/019-th : 0.075 0.084 0.104 0.108 0.127 0.144 0.165 0.193  ||  -0.459 -0.356 -0.133 -0.100 0.066 0.186 0.324 0.480   || dis=0.03 || select=7/8
010/019-th : 0.091 0.094 0.109 0.119 0.137 0.143 0.149 0.158  ||  -0.296 -0.269 -0.115 -0.025 0.111 0.159 0.199 0.253   || dis=0.01 || select=7/8
011/019-th : 0.105 0.099 0.111 0.120 0.121 0.130 0.154 0.160  ||  -0.166 -0.217 -0.102 -0.030 -0.022 0.052 0.222 0.261  || dis=0.01 || select=7/8
012/019-th : 0.131 0.123 0.126 0.124 0.119 0.121 0.128 0.129  ||  0.045 -0.016 0.006 -0.007 -0.049 -0.035 0.020 0.029   || dis=0.00 || select=0/8
013/019-th : 0.009 0.009 0.013 0.016 0.021 0.033 0.080 0.818  ||  -1.285 -1.199 -0.885 -0.680 -0.385 0.058 0.936 3.261  || dis=0.74 || select=7/8
014/019-th : 0.010 0.015 0.020 0.026 0.045 0.078 0.173 0.633  ||  -1.627 -1.173 -0.892 -0.636 -0.091 0.462 1.261 2.556  || dis=0.46 || select=7/8
015/019-th : 0.006 0.008 0.011 0.014 0.019 0.033 0.090 0.819  ||  -1.625 -1.204 -0.974 -0.712 -0.384 0.154 1.157 3.367  || dis=0.73 || select=7/8
016/019-th : 0.046 0.064 0.075 0.104 0.134 0.162 0.193 0.222  ||  -0.887 -0.550 -0.396 -0.065 0.189 0.381 0.557 0.695   || dis=0.03 || select=7/8
017/019-th : 0.083 0.098 0.102 0.130 0.130 0.143 0.154 0.159  ||  -0.383 -0.212 -0.169 0.072 0.071 0.163 0.241 0.267    || dis=0.01 || select=7/8
018/019-th : 0.089 0.104 0.122 0.138 0.129 0.133 0.135 0.149  ||  -0.326 -0.165 -0.010 0.116 0.049 0.074 0.093 0.187    || dis=0.01 || select=7/8
[epoch=413/600] FLOP : 26.08 MB, ratio : 0.6391, Expected-ratio : 0.7000, Discrepancy : 0.163
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:20:54] [epoch=413/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.847 (1.847)  Prec@1 33.59 (33.59) Prec@5 84.77 (84.77) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:21:00] [epoch=413/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.441 (2.334)  Prec@1 30.36 (42.02) Prec@5 80.95 (83.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.02 Prec@5 83.31 Error@1 57.98 Error@5 16.69 Loss:2.334
***[2020-01-29 09:21:00]*** VALID [epoch=413/600] loss = 2.333764, accuracy@1 = 42.02, accuracy@5 = 83.31 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:21:00]*** start epoch=414/600 Time Left: [01:38:49], LR=[0.021896 ~ 0.021896], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=414, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1728957242622808, FLOP=40.81
[Search] : epoch=414/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:21:01] [epoch=414/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 0.636 (0.636)  Prec@1 75.78 (75.78) Prec@5 98.44 (98.44) Acls-loss 0.617 (0.617) FLOP-Loss -2.902 (-2.902) Arch-Loss -5.187 (-5.187)
**TRAIN** [2020-01-29 09:21:28] [epoch=414/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.760 (0.669)  Prec@1 73.81 (77.09) Prec@5 100.00 (98.56) Acls-loss 0.691 (0.735) FLOP-Loss -2.902 (0.129) Arch-Loss -5.113 (0.994)
 **TRAIN** Prec@1 77.09 Prec@5 98.56 Error@1 22.91 Error@5 1.44 Base-Loss:0.669, Arch-Loss=0.994
***[2020-01-29 09:21:28]*** TRAIN [epoch=414/600] base-loss = 0.668805, arch-loss = 0.993687, accuracy-1 = 77.09, accuracy-5 = 98.56
[epoch=414/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 34.636416)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.373 0.254 0.373  ||  0.1750 -0.2070 0.1755  || discrepancy=0.00 || select=2/3
001/003-th : 0.324 0.189 0.486  ||  0.0753 -0.4627 0.4809  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3414 -0.8937 2.8936  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.042 0.054 0.062 0.098 0.135 0.214 0.368  ||  -1.173 -0.761 -0.518 -0.383 0.074 0.399 0.858 1.401   || dis=0.15 || select=7/8
001/019-th : 0.105 0.133 0.142 0.136 0.131 0.123 0.122 0.108  ||  -0.162 0.071 0.132 0.090 0.052 -0.006 -0.016 -0.135   || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.134 0.135 0.123 0.121 0.114 0.106  ||  0.063 0.074 0.067 0.076 -0.015 -0.031 -0.087 -0.161   || dis=0.00 || select=3/8
003/019-th : 0.103 0.115 0.123 0.126 0.128 0.134 0.133 0.138  ||  -0.195 -0.081 -0.013 0.013 0.024 0.069 0.066 0.102    || dis=0.00 || select=7/8
004/019-th : 0.114 0.109 0.114 0.122 0.127 0.135 0.136 0.143  ||  -0.087 -0.127 -0.087 -0.021 0.017 0.085 0.092 0.139   || dis=0.01 || select=7/8
005/019-th : 0.109 0.124 0.125 0.126 0.127 0.128 0.127 0.133  ||  -0.141 -0.005 0.003 0.005 0.015 0.026 0.019 0.063     || dis=0.01 || select=7/8
006/019-th : 0.131 0.121 0.119 0.115 0.127 0.127 0.129 0.132  ||  0.047 -0.033 -0.044 -0.076 0.020 0.017 0.035 0.055    || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.051 0.067 0.104 0.127 0.200 0.394  ||  -1.287 -0.944 -0.512 -0.239 0.199 0.401 0.851 1.531   || dis=0.19 || select=7/8
008/019-th : 0.017 0.027 0.038 0.062 0.094 0.152 0.258 0.351  ||  -1.495 -1.078 -0.707 -0.235 0.189 0.670 1.197 1.504   || dis=0.09 || select=7/8
009/019-th : 0.075 0.084 0.105 0.108 0.126 0.143 0.165 0.194  ||  -0.459 -0.356 -0.133 -0.104 0.054 0.182 0.324 0.487   || dis=0.03 || select=7/8
010/019-th : 0.092 0.093 0.108 0.118 0.137 0.144 0.151 0.158  ||  -0.289 -0.276 -0.124 -0.038 0.111 0.164 0.209 0.254   || dis=0.01 || select=7/8
011/019-th : 0.105 0.099 0.111 0.120 0.121 0.130 0.154 0.160  ||  -0.162 -0.222 -0.101 -0.026 -0.020 0.056 0.220 0.259  || dis=0.01 || select=7/8
012/019-th : 0.131 0.122 0.126 0.125 0.120 0.120 0.127 0.129  ||  0.048 -0.020 0.005 0.002 -0.040 -0.038 0.018 0.029    || dis=0.00 || select=0/8
013/019-th : 0.009 0.009 0.013 0.016 0.021 0.033 0.080 0.820  ||  -1.283 -1.188 -0.894 -0.674 -0.403 0.049 0.939 3.269  || dis=0.74 || select=7/8
014/019-th : 0.009 0.015 0.020 0.026 0.044 0.077 0.173 0.636  ||  -1.647 -1.166 -0.885 -0.639 -0.108 0.460 1.270 2.569  || dis=0.46 || select=7/8
015/019-th : 0.006 0.009 0.010 0.014 0.019 0.033 0.090 0.820  ||  -1.617 -1.199 -1.002 -0.702 -0.384 0.161 1.155 3.369  || dis=0.73 || select=7/8
016/019-th : 0.045 0.064 0.075 0.104 0.133 0.164 0.192 0.223  ||  -0.901 -0.549 -0.392 -0.067 0.184 0.394 0.553 0.700   || dis=0.03 || select=7/8
017/019-th : 0.083 0.099 0.102 0.129 0.130 0.143 0.155 0.159  ||  -0.380 -0.208 -0.171 0.059 0.067 0.165 0.242 0.267    || dis=0.00 || select=7/8
018/019-th : 0.089 0.105 0.122 0.138 0.128 0.135 0.136 0.149  ||  -0.328 -0.165 -0.014 0.111 0.038 0.090 0.094 0.187    || dis=0.01 || select=7/8
[epoch=414/600] FLOP : 34.64 MB, ratio : 0.8487, Expected-ratio : 0.7000, Discrepancy : 0.164
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:21:28] [epoch=414/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 2.697 (2.697)  Prec@1 23.44 (23.44) Prec@5 67.19 (67.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:21:34] [epoch=414/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.868 (2.264)  Prec@1 27.98 (42.01) Prec@5 72.02 (83.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.01 Prec@5 83.14 Error@1 57.99 Error@5 16.86 Loss:2.264
***[2020-01-29 09:21:34]*** VALID [epoch=414/600] loss = 2.264103, accuracy@1 = 42.01, accuracy@5 = 83.14 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:21:34]*** start epoch=415/600 Time Left: [01:38:18], LR=[0.021680 ~ 0.021680], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=415, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1623047195341603, FLOP=40.81
[Search] : epoch=415/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:21:35] [epoch=415/600][000/098] Time 0.69 (0.69) Data 0.40 (0.40) Base-Loss 0.489 (0.489)  Prec@1 81.64 (81.64) Prec@5 99.22 (99.22) Acls-loss 0.728 (0.728) FLOP-Loss 2.903 (2.903) Arch-Loss 6.533 (6.533)
**TRAIN** [2020-01-29 09:22:01] [epoch=415/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.962 (0.678)  Prec@1 69.05 (76.84) Prec@5 97.62 (98.43) Acls-loss 0.604 (0.732) FLOP-Loss -2.904 (0.129) Arch-Loss -5.204 (0.991)
 **TRAIN** Prec@1 76.84 Prec@5 98.43 Error@1 23.16 Error@5 1.57 Base-Loss:0.678, Arch-Loss=0.991
***[2020-01-29 09:22:01]*** TRAIN [epoch=415/600] base-loss = 0.678013, arch-loss = 0.990912, accuracy-1 = 76.84, accuracy-5 = 98.43
[epoch=415/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 34.636416)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.371 0.258 0.371  ||  0.1738 -0.1914 0.1751  || discrepancy=0.00 || select=2/3
001/003-th : 0.324 0.190 0.486  ||  0.0753 -0.4616 0.4807  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3363 -0.8950 2.8911  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.042 0.053 0.060 0.096 0.135 0.216 0.371  ||  -1.180 -0.770 -0.525 -0.408 0.064 0.405 0.876 1.415   || dis=0.15 || select=7/8
001/019-th : 0.105 0.133 0.142 0.134 0.129 0.125 0.123 0.108  ||  -0.167 0.071 0.132 0.080 0.042 0.004 -0.008 -0.135    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.132 0.134 0.124 0.121 0.115 0.107  ||  0.063 0.069 0.059 0.074 -0.011 -0.028 -0.084 -0.159   || dis=0.00 || select=3/8
003/019-th : 0.101 0.115 0.124 0.126 0.130 0.133 0.133 0.138  ||  -0.205 -0.079 -0.005 0.014 0.044 0.070 0.065 0.103    || dis=0.01 || select=7/8
004/019-th : 0.114 0.109 0.113 0.122 0.128 0.135 0.136 0.143  ||  -0.087 -0.130 -0.096 -0.022 0.029 0.085 0.093 0.141   || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.126 0.126 0.128 0.127 0.127 0.133  ||  -0.145 -0.004 0.007 0.009 0.027 0.020 0.018 0.063     || dis=0.01 || select=7/8
006/019-th : 0.131 0.120 0.119 0.115 0.128 0.126 0.129 0.132  ||  0.048 -0.036 -0.048 -0.079 0.028 0.014 0.037 0.055    || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.051 0.066 0.104 0.127 0.200 0.395  ||  -1.281 -0.946 -0.511 -0.249 0.194 0.398 0.854 1.534   || dis=0.20 || select=7/8
008/019-th : 0.017 0.027 0.038 0.061 0.092 0.153 0.259 0.352  ||  -1.495 -1.073 -0.715 -0.237 0.170 0.679 1.203 1.508   || dis=0.09 || select=7/8
009/019-th : 0.076 0.084 0.102 0.106 0.128 0.145 0.165 0.195  ||  -0.458 -0.352 -0.154 -0.114 0.067 0.192 0.325 0.489   || dis=0.03 || select=7/8
010/019-th : 0.092 0.093 0.108 0.119 0.137 0.143 0.151 0.158  ||  -0.287 -0.272 -0.126 -0.032 0.111 0.151 0.207 0.254   || dis=0.01 || select=7/8
011/019-th : 0.105 0.098 0.112 0.121 0.121 0.130 0.153 0.159  ||  -0.157 -0.226 -0.099 -0.020 -0.021 0.053 0.218 0.257  || dis=0.01 || select=7/8
012/019-th : 0.131 0.122 0.125 0.124 0.120 0.121 0.128 0.129  ||  0.050 -0.022 -0.004 -0.006 -0.042 -0.031 0.020 0.031  || dis=0.00 || select=0/8
013/019-th : 0.009 0.009 0.013 0.016 0.021 0.032 0.077 0.824  ||  -1.271 -1.185 -0.898 -0.683 -0.396 0.052 0.914 3.287  || dis=0.75 || select=7/8
014/019-th : 0.009 0.015 0.020 0.026 0.044 0.075 0.169 0.641  ||  -1.653 -1.164 -0.878 -0.628 -0.100 0.436 1.251 2.583  || dis=0.47 || select=7/8
015/019-th : 0.006 0.008 0.010 0.014 0.019 0.033 0.087 0.824  ||  -1.607 -1.226 -1.005 -0.695 -0.384 0.163 1.144 3.392  || dis=0.74 || select=7/8
016/019-th : 0.044 0.063 0.074 0.104 0.135 0.163 0.194 0.223  ||  -0.913 -0.557 -0.404 -0.058 0.203 0.393 0.562 0.702   || dis=0.03 || select=7/8
017/019-th : 0.083 0.099 0.103 0.127 0.130 0.144 0.155 0.159  ||  -0.385 -0.204 -0.163 0.042 0.067 0.172 0.244 0.266    || dis=0.00 || select=7/8
018/019-th : 0.088 0.105 0.121 0.137 0.127 0.136 0.136 0.150  ||  -0.335 -0.165 -0.018 0.102 0.033 0.098 0.094 0.196    || dis=0.01 || select=7/8
[epoch=415/600] FLOP : 34.64 MB, ratio : 0.8487, Expected-ratio : 0.7000, Discrepancy : 0.165
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:22:02] [epoch=415/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.584 (2.584)  Prec@1 20.31 (20.31) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:22:08] [epoch=415/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.499 (2.461)  Prec@1 47.02 (36.26) Prec@5 89.29 (78.61) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.26 Prec@5 78.61 Error@1 63.74 Error@5 21.39 Loss:2.461
***[2020-01-29 09:22:08]*** VALID [epoch=415/600] loss = 2.461029, accuracy@1 = 36.26, accuracy@5 = 78.61 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:22:08]*** start epoch=416/600 Time Left: [01:37:47], LR=[0.021464 ~ 0.021464], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=416, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1517517591731428, FLOP=40.81
[Search] : epoch=416/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:22:09] [epoch=416/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 0.524 (0.524)  Prec@1 82.81 (82.81) Prec@5 97.66 (97.66) Acls-loss 0.927 (0.927) FLOP-Loss 2.904 (2.904) Arch-Loss 6.735 (6.735)
**TRAIN** [2020-01-29 09:22:35] [epoch=416/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.788 (0.668)  Prec@1 72.62 (77.28) Prec@5 97.02 (98.51) Acls-loss 0.793 (0.720) FLOP-Loss -2.904 (0.189) Arch-Loss -5.016 (1.098)
 **TRAIN** Prec@1 77.28 Prec@5 98.51 Error@1 22.72 Error@5 1.49 Base-Loss:0.668, Arch-Loss=1.098
***[2020-01-29 09:22:35]*** TRAIN [epoch=416/600] base-loss = 0.667651, arch-loss = 1.098004, accuracy-1 = 77.28, accuracy-5 = 98.51
[epoch=416/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 16, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 26.083968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.372 0.256 0.372  ||  0.1750 -0.1980 0.1743  || discrepancy=0.00 || select=0/3
001/003-th : 0.323 0.190 0.486  ||  0.0738 -0.4557 0.4815  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3288 -0.8836 2.8816  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.028 0.042 0.053 0.059 0.095 0.134 0.216 0.373  ||  -1.180 -0.762 -0.533 -0.415 0.057 0.400 0.879 1.423   || dis=0.16 || select=7/8
001/019-th : 0.105 0.134 0.142 0.135 0.128 0.125 0.124 0.108  ||  -0.169 0.076 0.137 0.080 0.032 0.003 -0.005 -0.138    || dis=0.01 || select=2/8
002/019-th : 0.134 0.134 0.132 0.135 0.123 0.122 0.114 0.106  ||  0.067 0.069 0.058 0.078 -0.016 -0.027 -0.088 -0.160   || dis=0.00 || select=3/8
003/019-th : 0.101 0.114 0.123 0.127 0.132 0.133 0.132 0.137  ||  -0.206 -0.082 -0.010 0.023 0.062 0.069 0.065 0.100    || dis=0.00 || select=7/8
004/019-th : 0.114 0.109 0.113 0.122 0.126 0.136 0.137 0.143  ||  -0.090 -0.128 -0.098 -0.020 0.012 0.090 0.096 0.142   || dis=0.01 || select=7/8
005/019-th : 0.108 0.125 0.126 0.127 0.127 0.128 0.127 0.134  ||  -0.149 -0.002 0.012 0.013 0.013 0.024 0.015 0.066     || dis=0.01 || select=7/8
006/019-th : 0.131 0.121 0.120 0.115 0.126 0.126 0.130 0.131  ||  0.049 -0.029 -0.041 -0.083 0.010 0.006 0.043 0.051    || dis=0.00 || select=7/8
007/019-th : 0.024 0.033 0.051 0.066 0.103 0.127 0.199 0.398  ||  -1.286 -0.956 -0.504 -0.259 0.195 0.399 0.851 1.543   || dis=0.20 || select=7/8
008/019-th : 0.018 0.027 0.038 0.061 0.093 0.156 0.255 0.353  ||  -1.493 -1.070 -0.722 -0.245 0.179 0.696 1.186 1.510   || dis=0.10 || select=7/8
009/019-th : 0.075 0.084 0.102 0.107 0.129 0.144 0.164 0.195  ||  -0.468 -0.345 -0.154 -0.104 0.077 0.187 0.319 0.490   || dis=0.03 || select=7/8
010/019-th : 0.092 0.092 0.108 0.118 0.138 0.143 0.151 0.158  ||  -0.285 -0.283 -0.125 -0.034 0.123 0.154 0.207 0.256   || dis=0.01 || select=7/8
011/019-th : 0.106 0.099 0.111 0.121 0.120 0.131 0.153 0.159  ||  -0.153 -0.225 -0.106 -0.019 -0.029 0.060 0.218 0.255  || dis=0.01 || select=7/8
012/019-th : 0.131 0.123 0.124 0.126 0.119 0.121 0.127 0.129  ||  0.050 -0.018 -0.009 0.010 -0.050 -0.035 0.018 0.030   || dis=0.00 || select=0/8
013/019-th : 0.009 0.009 0.012 0.015 0.021 0.032 0.077 0.824  ||  -1.274 -1.195 -0.902 -0.690 -0.389 0.055 0.917 3.291  || dis=0.75 || select=7/8
014/019-th : 0.009 0.015 0.020 0.026 0.043 0.074 0.169 0.643  ||  -1.647 -1.157 -0.872 -0.624 -0.123 0.429 1.251 2.587  || dis=0.47 || select=7/8
015/019-th : 0.006 0.008 0.010 0.014 0.018 0.032 0.084 0.829  ||  -1.588 -1.222 -0.989 -0.701 -0.421 0.152 1.125 3.415  || dis=0.74 || select=7/8
016/019-th : 0.044 0.063 0.073 0.104 0.134 0.166 0.194 0.222  ||  -0.919 -0.564 -0.405 -0.060 0.198 0.412 0.569 0.702   || dis=0.03 || select=7/8
017/019-th : 0.083 0.099 0.104 0.127 0.130 0.143 0.155 0.159  ||  -0.384 -0.205 -0.155 0.045 0.067 0.164 0.240 0.266    || dis=0.00 || select=7/8
018/019-th : 0.089 0.105 0.120 0.137 0.127 0.136 0.136 0.150  ||  -0.333 -0.162 -0.028 0.104 0.029 0.097 0.098 0.195    || dis=0.01 || select=7/8
[epoch=416/600] FLOP : 26.08 MB, ratio : 0.6391, Expected-ratio : 0.7000, Discrepancy : 0.166
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:22:36] [epoch=416/600][000/098] Time 0.39 (0.39) Data 0.31 (0.31) Loss 1.002 (1.002)  Prec@1 67.19 (67.19) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:22:42] [epoch=416/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.031 (2.270)  Prec@1 54.76 (40.10) Prec@5 90.48 (81.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.10 Prec@5 81.28 Error@1 59.90 Error@5 18.72 Loss:2.270
***[2020-01-29 09:22:42]*** VALID [epoch=416/600] loss = 2.269755, accuracy@1 = 40.10, accuracy@5 = 81.28 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:22:42]*** start epoch=417/600 Time Left: [01:37:16], LR=[0.021250 ~ 0.021250], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=417, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1412371324939685, FLOP=40.81
[Search] : epoch=417/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:22:43] [epoch=417/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.967 (0.967)  Prec@1 66.41 (66.41) Prec@5 96.48 (96.48) Acls-loss 0.834 (0.834) FLOP-Loss -2.905 (-2.905) Arch-Loss -4.975 (-4.975)
**TRAIN** [2020-01-29 09:23:09] [epoch=417/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.037 (0.661)  Prec@1 64.29 (77.49) Prec@5 95.83 (98.43) Acls-loss 0.608 (0.732) FLOP-Loss 2.905 (0.168) Arch-Loss 6.418 (1.069)
 **TRAIN** Prec@1 77.49 Prec@5 98.43 Error@1 22.51 Error@5 1.57 Base-Loss:0.661, Arch-Loss=1.069
***[2020-01-29 09:23:09]*** TRAIN [epoch=417/600] base-loss = 0.660663, arch-loss = 1.069213, accuracy-1 = 77.49, accuracy-5 = 98.43
[epoch=417/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.371 0.258 0.371  ||  0.1744 -0.1905 0.1740  || discrepancy=0.00 || select=0/3
001/003-th : 0.322 0.192 0.485  ||  0.0727 -0.4446 0.4816  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3200 -0.8852 2.8762  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.027 0.042 0.052 0.060 0.094 0.134 0.218 0.373  ||  -1.193 -0.757 -0.543 -0.409 0.053 0.402 0.888 1.427   || dis=0.15 || select=7/8
001/019-th : 0.105 0.134 0.141 0.134 0.129 0.125 0.124 0.108  ||  -0.168 0.078 0.128 0.077 0.036 0.009 -0.005 -0.140    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.133 0.135 0.123 0.122 0.114 0.106  ||  0.064 0.069 0.067 0.079 -0.015 -0.023 -0.087 -0.163   || dis=0.00 || select=3/8
003/019-th : 0.101 0.115 0.124 0.126 0.133 0.133 0.132 0.137  ||  -0.208 -0.077 -0.004 0.019 0.067 0.067 0.064 0.098    || dis=0.00 || select=7/8
004/019-th : 0.113 0.110 0.114 0.122 0.127 0.135 0.136 0.144  ||  -0.092 -0.127 -0.091 -0.022 0.021 0.079 0.092 0.145   || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.125 0.127 0.125 0.130 0.127 0.134  ||  -0.149 -0.007 0.002 0.016 0.004 0.039 0.016 0.069     || dis=0.00 || select=7/8
006/019-th : 0.132 0.121 0.119 0.115 0.126 0.126 0.130 0.131  ||  0.053 -0.027 -0.045 -0.080 0.014 0.008 0.040 0.048    || dis=0.00 || select=0/8
007/019-th : 0.023 0.032 0.051 0.065 0.103 0.126 0.198 0.402  ||  -1.312 -0.973 -0.502 -0.263 0.202 0.404 0.852 1.562   || dis=0.20 || select=7/8
008/019-th : 0.017 0.027 0.037 0.061 0.093 0.155 0.257 0.352  ||  -1.500 -1.067 -0.734 -0.247 0.184 0.694 1.199 1.512   || dis=0.09 || select=7/8
009/019-th : 0.075 0.085 0.103 0.107 0.128 0.143 0.165 0.195  ||  -0.465 -0.343 -0.151 -0.112 0.072 0.182 0.324 0.489   || dis=0.03 || select=7/8
010/019-th : 0.092 0.092 0.108 0.118 0.137 0.143 0.151 0.158  ||  -0.282 -0.283 -0.122 -0.036 0.111 0.152 0.212 0.254   || dis=0.01 || select=7/8
011/019-th : 0.106 0.099 0.109 0.122 0.119 0.132 0.154 0.158  ||  -0.151 -0.222 -0.121 -0.014 -0.032 0.071 0.222 0.251  || dis=0.00 || select=7/8
012/019-th : 0.132 0.123 0.125 0.126 0.117 0.120 0.128 0.129  ||  0.053 -0.014 -0.005 0.007 -0.064 -0.041 0.019 0.029   || dis=0.00 || select=0/8
013/019-th : 0.009 0.009 0.012 0.015 0.020 0.032 0.076 0.826  ||  -1.270 -1.183 -0.912 -0.691 -0.398 0.052 0.914 3.299  || dis=0.75 || select=7/8
014/019-th : 0.009 0.015 0.020 0.026 0.043 0.075 0.171 0.642  ||  -1.650 -1.166 -0.878 -0.631 -0.125 0.437 1.264 2.589  || dis=0.47 || select=7/8
015/019-th : 0.005 0.008 0.010 0.013 0.017 0.031 0.081 0.834  ||  -1.585 -1.215 -0.989 -0.716 -0.435 0.141 1.112 3.438  || dis=0.75 || select=7/8
016/019-th : 0.044 0.063 0.074 0.104 0.134 0.164 0.195 0.223  ||  -0.919 -0.565 -0.404 -0.055 0.195 0.395 0.569 0.707   || dis=0.03 || select=7/8
017/019-th : 0.083 0.099 0.105 0.128 0.129 0.142 0.154 0.159  ||  -0.381 -0.203 -0.148 0.046 0.058 0.156 0.237 0.266    || dis=0.01 || select=7/8
018/019-th : 0.089 0.105 0.120 0.137 0.126 0.137 0.136 0.150  ||  -0.332 -0.161 -0.026 0.103 0.022 0.106 0.093 0.195    || dis=0.01 || select=7/8
[epoch=417/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.166
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:23:10] [epoch=417/600][000/098] Time 0.41 (0.41) Data 0.31 (0.31) Loss 2.580 (2.580)  Prec@1 40.23 (40.23) Prec@5 78.12 (78.12) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:23:16] [epoch=417/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.834 (2.838)  Prec@1 38.10 (39.52) Prec@5 89.88 (81.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.52 Prec@5 81.99 Error@1 60.48 Error@5 18.01 Loss:2.838
***[2020-01-29 09:23:16]*** VALID [epoch=417/600] loss = 2.838078, accuracy@1 = 39.52, accuracy@5 = 81.99 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:23:16]*** start epoch=418/600 Time Left: [01:36:45], LR=[0.021036 ~ 0.021036], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=418, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1307611277604375, FLOP=40.81
[Search] : epoch=418/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:23:17] [epoch=418/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.577 (0.577)  Prec@1 78.91 (78.91) Prec@5 99.61 (99.61) Acls-loss 0.758 (0.758) FLOP-Loss -2.905 (-2.905) Arch-Loss -5.053 (-5.053)
**TRAIN** [2020-01-29 09:23:43] [epoch=418/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.684 (0.671)  Prec@1 78.57 (77.22) Prec@5 98.21 (98.39) Acls-loss 0.828 (0.735) FLOP-Loss -2.906 (0.129) Arch-Loss -4.983 (0.994)
 **TRAIN** Prec@1 77.22 Prec@5 98.39 Error@1 22.78 Error@5 1.61 Base-Loss:0.671, Arch-Loss=0.994
***[2020-01-29 09:23:43]*** TRAIN [epoch=418/600] base-loss = 0.671475, arch-loss = 0.994251, accuracy-1 = 77.22, accuracy-5 = 98.39
[epoch=418/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.94944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.369 0.261 0.370  ||  0.1728 -0.1740 0.1741  || discrepancy=0.00 || select=2/3
001/003-th : 0.322 0.195 0.483  ||  0.0731 -0.4290 0.4798  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3327 -0.8872 2.8901  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.027 0.042 0.052 0.059 0.095 0.135 0.214 0.374  ||  -1.190 -0.759 -0.540 -0.413 0.062 0.412 0.871 1.428   || dis=0.16 || select=7/8
001/019-th : 0.105 0.132 0.141 0.135 0.131 0.125 0.124 0.108  ||  -0.168 0.062 0.131 0.082 0.056 0.007 -0.001 -0.138    || dis=0.01 || select=2/8
002/019-th : 0.133 0.134 0.133 0.135 0.122 0.122 0.114 0.106  ||  0.065 0.074 0.062 0.083 -0.023 -0.022 -0.087 -0.165   || dis=0.00 || select=3/8
003/019-th : 0.101 0.115 0.124 0.125 0.132 0.133 0.132 0.138  ||  -0.203 -0.079 -0.001 0.009 0.062 0.065 0.059 0.101    || dis=0.01 || select=7/8
004/019-th : 0.114 0.110 0.113 0.122 0.128 0.133 0.137 0.143  ||  -0.091 -0.125 -0.093 -0.021 0.030 0.067 0.100 0.141   || dis=0.01 || select=7/8
005/019-th : 0.108 0.123 0.125 0.127 0.125 0.129 0.128 0.135  ||  -0.148 -0.017 0.004 0.015 0.003 0.032 0.022 0.073     || dis=0.01 || select=7/8
006/019-th : 0.132 0.122 0.118 0.115 0.127 0.124 0.130 0.132  ||  0.056 -0.027 -0.058 -0.082 0.018 -0.006 0.042 0.052   || dis=0.00 || select=0/8
007/019-th : 0.023 0.032 0.051 0.065 0.103 0.126 0.198 0.402  ||  -1.315 -0.968 -0.498 -0.266 0.195 0.404 0.856 1.562   || dis=0.20 || select=7/8
008/019-th : 0.017 0.027 0.037 0.060 0.093 0.154 0.258 0.354  ||  -1.515 -1.064 -0.727 -0.256 0.190 0.688 1.205 1.522   || dis=0.10 || select=7/8
009/019-th : 0.075 0.085 0.103 0.107 0.128 0.143 0.164 0.194  ||  -0.464 -0.339 -0.152 -0.106 0.071 0.184 0.317 0.488   || dis=0.03 || select=7/8
010/019-th : 0.093 0.091 0.109 0.120 0.136 0.142 0.151 0.158  ||  -0.281 -0.293 -0.118 -0.017 0.101 0.148 0.210 0.256   || dis=0.01 || select=7/8
011/019-th : 0.107 0.099 0.109 0.121 0.120 0.132 0.154 0.158  ||  -0.144 -0.216 -0.123 -0.022 -0.032 0.063 0.221 0.249  || dis=0.00 || select=7/8
012/019-th : 0.132 0.123 0.123 0.128 0.118 0.120 0.127 0.128  ||  0.054 -0.016 -0.013 0.022 -0.056 -0.040 0.018 0.027   || dis=0.00 || select=0/8
013/019-th : 0.009 0.009 0.012 0.015 0.020 0.032 0.075 0.828  ||  -1.267 -1.170 -0.912 -0.692 -0.405 0.044 0.908 3.309  || dis=0.75 || select=7/8
014/019-th : 0.009 0.015 0.020 0.025 0.041 0.073 0.169 0.647  ||  -1.639 -1.158 -0.887 -0.634 -0.146 0.422 1.262 2.604  || dis=0.48 || select=7/8
015/019-th : 0.005 0.008 0.010 0.013 0.017 0.030 0.078 0.839  ||  -1.568 -1.220 -0.988 -0.728 -0.442 0.133 1.093 3.462  || dis=0.76 || select=7/8
016/019-th : 0.043 0.062 0.073 0.104 0.133 0.166 0.194 0.224  ||  -0.936 -0.569 -0.405 -0.053 0.194 0.415 0.567 0.712   || dis=0.03 || select=7/8
017/019-th : 0.083 0.099 0.105 0.127 0.130 0.141 0.154 0.160  ||  -0.382 -0.204 -0.145 0.038 0.066 0.147 0.237 0.270    || dis=0.01 || select=7/8
018/019-th : 0.089 0.105 0.120 0.135 0.127 0.139 0.135 0.149  ||  -0.330 -0.160 -0.027 0.090 0.032 0.122 0.091 0.190    || dis=0.01 || select=7/8
[epoch=418/600] FLOP : 31.95 MB, ratio : 0.7828, Expected-ratio : 0.7000, Discrepancy : 0.167
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:23:43] [epoch=418/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.653 (1.653)  Prec@1 43.36 (43.36) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:23:50] [epoch=418/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.612 (2.233)  Prec@1 41.67 (39.63) Prec@5 85.12 (81.49) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.63 Prec@5 81.49 Error@1 60.37 Error@5 18.51 Loss:2.233
***[2020-01-29 09:23:50]*** VALID [epoch=418/600] loss = 2.233330, accuracy@1 = 39.63, accuracy@5 = 81.49 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:23:50]*** start epoch=419/600 Time Left: [01:36:14], LR=[0.020823 ~ 0.020823], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=419, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1203240321775125, FLOP=40.81
[Search] : epoch=419/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:23:51] [epoch=419/600][000/098] Time 0.67 (0.67) Data 0.38 (0.38) Base-Loss 0.546 (0.546)  Prec@1 81.25 (81.25) Prec@5 98.83 (98.83) Acls-loss 0.805 (0.805) FLOP-Loss 2.906 (2.906) Arch-Loss 6.616 (6.616)
**TRAIN** [2020-01-29 09:24:17] [epoch=419/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.686 (0.676)  Prec@1 76.19 (77.06) Prec@5 97.02 (98.41) Acls-loss 0.983 (0.754) FLOP-Loss 2.906 (0.228) Arch-Loss 6.795 (1.210)
 **TRAIN** Prec@1 77.06 Prec@5 98.41 Error@1 22.94 Error@5 1.59 Base-Loss:0.676, Arch-Loss=1.210
***[2020-01-29 09:24:17]*** TRAIN [epoch=419/600] base-loss = 0.675978, arch-loss = 1.209774, accuracy-1 = 77.06, accuracy-5 = 98.41
[epoch=419/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.369 0.262 0.369  ||  0.1732 -0.1707 0.1732  || discrepancy=0.00 || select=0/3
001/003-th : 0.321 0.197 0.482  ||  0.0733 -0.4142 0.4783  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3220 -0.8973 2.8863  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.027 0.041 0.052 0.058 0.095 0.138 0.213 0.374  ||  -1.202 -0.770 -0.536 -0.431 0.067 0.438 0.871 1.434   || dis=0.16 || select=7/8
001/019-th : 0.104 0.132 0.141 0.135 0.131 0.125 0.123 0.108  ||  -0.171 0.065 0.132 0.084 0.060 0.007 -0.006 -0.137    || dis=0.01 || select=2/8
002/019-th : 0.133 0.135 0.134 0.136 0.123 0.121 0.114 0.105  ||  0.068 0.076 0.070 0.084 -0.017 -0.028 -0.090 -0.170   || dis=0.00 || select=3/8
003/019-th : 0.101 0.116 0.124 0.125 0.132 0.133 0.132 0.138  ||  -0.207 -0.070 -0.007 0.003 0.056 0.065 0.059 0.103    || dis=0.01 || select=7/8
004/019-th : 0.114 0.110 0.113 0.122 0.129 0.133 0.136 0.142  ||  -0.085 -0.123 -0.092 -0.016 0.041 0.068 0.091 0.136   || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.125 0.127 0.126 0.129 0.127 0.135  ||  -0.147 -0.012 -0.002 0.015 0.006 0.035 0.017 0.074    || dis=0.01 || select=7/8
006/019-th : 0.133 0.122 0.119 0.116 0.126 0.124 0.130 0.132  ||  0.059 -0.027 -0.053 -0.076 0.004 -0.009 0.039 0.052   || dis=0.00 || select=0/8
007/019-th : 0.022 0.032 0.051 0.065 0.105 0.128 0.198 0.399  ||  -1.334 -0.963 -0.506 -0.254 0.216 0.419 0.854 1.556   || dis=0.20 || select=7/8
008/019-th : 0.017 0.026 0.037 0.060 0.092 0.155 0.258 0.356  ||  -1.511 -1.082 -0.731 -0.257 0.173 0.699 1.209 1.531   || dis=0.10 || select=7/8
009/019-th : 0.076 0.085 0.103 0.106 0.129 0.144 0.163 0.193  ||  -0.452 -0.336 -0.152 -0.115 0.079 0.187 0.312 0.482   || dis=0.03 || select=7/8
010/019-th : 0.092 0.091 0.108 0.120 0.137 0.142 0.152 0.158  ||  -0.289 -0.295 -0.123 -0.014 0.114 0.148 0.221 0.255   || dis=0.01 || select=7/8
011/019-th : 0.107 0.100 0.109 0.121 0.120 0.132 0.153 0.158  ||  -0.147 -0.210 -0.124 -0.021 -0.029 0.067 0.217 0.248  || dis=0.01 || select=7/8
012/019-th : 0.132 0.123 0.124 0.126 0.119 0.120 0.127 0.129  ||  0.056 -0.013 -0.010 0.008 -0.052 -0.045 0.015 0.029   || dis=0.00 || select=0/8
013/019-th : 0.008 0.010 0.012 0.015 0.020 0.032 0.074 0.829  ||  -1.266 -1.153 -0.918 -0.705 -0.408 0.050 0.902 3.316  || dis=0.76 || select=7/8
014/019-th : 0.009 0.015 0.020 0.025 0.040 0.074 0.170 0.647  ||  -1.630 -1.177 -0.892 -0.639 -0.165 0.441 1.270 2.610  || dis=0.48 || select=7/8
015/019-th : 0.005 0.008 0.010 0.012 0.016 0.029 0.077 0.842  ||  -1.565 -1.220 -0.978 -0.755 -0.461 0.130 1.092 3.483  || dis=0.77 || select=7/8
016/019-th : 0.043 0.062 0.073 0.104 0.135 0.166 0.194 0.224  ||  -0.940 -0.573 -0.412 -0.051 0.207 0.413 0.570 0.713   || dis=0.03 || select=7/8
017/019-th : 0.083 0.100 0.106 0.127 0.130 0.141 0.153 0.160  ||  -0.382 -0.197 -0.144 0.037 0.065 0.147 0.230 0.269    || dis=0.01 || select=7/8
018/019-th : 0.089 0.107 0.119 0.135 0.128 0.138 0.135 0.149  ||  -0.328 -0.147 -0.038 0.093 0.040 0.115 0.090 0.186    || dis=0.01 || select=7/8
[epoch=419/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.168
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:24:17] [epoch=419/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.808 (1.808)  Prec@1 33.98 (33.98) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:24:24] [epoch=419/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.064 (2.590)  Prec@1 28.57 (37.90) Prec@5 76.19 (79.56) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.90 Prec@5 79.56 Error@1 62.10 Error@5 20.44 Loss:2.590
***[2020-01-29 09:24:24]*** VALID [epoch=419/600] loss = 2.589709, accuracy@1 = 37.90, accuracy@5 = 79.56 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:24:24]*** start epoch=420/600 Time Left: [01:35:43], LR=[0.020611 ~ 0.020611], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=420, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.1099261318834412, FLOP=40.81
[Search] : epoch=420/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:24:24] [epoch=420/600][000/098] Time 0.67 (0.67) Data 0.38 (0.38) Base-Loss 0.604 (0.604)  Prec@1 78.91 (78.91) Prec@5 99.61 (99.61) Acls-loss 0.621 (0.621) FLOP-Loss -2.906 (-2.906) Arch-Loss -5.190 (-5.190)
**TRAIN** [2020-01-29 09:24:49] [epoch=420/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.607 (0.717)  Prec@1 79.17 (75.55) Prec@5 99.40 (98.30) Acls-loss 0.824 (0.729) FLOP-Loss 2.905 (0.228) Arch-Loss 6.633 (1.185)
 **TRAIN** Prec@1 75.55 Prec@5 98.30 Error@1 24.45 Error@5 1.70 Base-Loss:0.717, Arch-Loss=1.185
***[2020-01-29 09:24:49]*** TRAIN [epoch=420/600] base-loss = 0.716881, arch-loss = 1.184611, accuracy-1 = 75.55, accuracy-5 = 98.30
[epoch=420/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.370 0.260 0.370  ||  0.1734 -0.1793 0.1734  || discrepancy=0.00 || select=0/3
001/003-th : 0.323 0.197 0.480  ||  0.0783 -0.4175 0.4736  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.972  ||  -2.3128 -0.8928 2.8782  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.027 0.041 0.053 0.058 0.096 0.136 0.214 0.375  ||  -1.209 -0.773 -0.524 -0.424 0.070 0.425 0.874 1.436   || dis=0.16 || select=7/8
001/019-th : 0.105 0.133 0.142 0.134 0.130 0.124 0.123 0.108  ||  -0.169 0.073 0.138 0.078 0.050 0.002 -0.009 -0.139    || dis=0.01 || select=2/8
002/019-th : 0.134 0.135 0.134 0.136 0.123 0.120 0.114 0.105  ||  0.072 0.082 0.069 0.085 -0.016 -0.035 -0.094 -0.173   || dis=0.00 || select=3/8
003/019-th : 0.101 0.116 0.124 0.127 0.130 0.132 0.133 0.137  ||  -0.203 -0.073 -0.005 0.021 0.048 0.061 0.064 0.096    || dis=0.00 || select=7/8
004/019-th : 0.114 0.110 0.115 0.121 0.128 0.133 0.136 0.143  ||  -0.085 -0.119 -0.082 -0.026 0.029 0.065 0.089 0.137   || dis=0.01 || select=7/8
005/019-th : 0.108 0.123 0.126 0.128 0.124 0.129 0.127 0.133  ||  -0.145 -0.012 0.012 0.026 -0.004 0.033 0.017 0.066    || dis=0.00 || select=7/8
006/019-th : 0.134 0.122 0.118 0.116 0.123 0.125 0.130 0.132  ||  0.066 -0.026 -0.057 -0.081 -0.017 -0.002 0.036 0.052  || dis=0.00 || select=0/8
007/019-th : 0.022 0.032 0.051 0.066 0.104 0.128 0.200 0.397  ||  -1.348 -0.975 -0.500 -0.236 0.216 0.420 0.870 1.553   || dis=0.20 || select=7/8
008/019-th : 0.017 0.026 0.037 0.060 0.091 0.154 0.260 0.356  ||  -1.511 -1.082 -0.743 -0.255 0.172 0.695 1.218 1.532   || dis=0.10 || select=7/8
009/019-th : 0.077 0.085 0.103 0.107 0.129 0.144 0.162 0.193  ||  -0.445 -0.336 -0.145 -0.113 0.073 0.188 0.304 0.480   || dis=0.03 || select=7/8
010/019-th : 0.092 0.092 0.108 0.122 0.136 0.142 0.152 0.157  ||  -0.280 -0.288 -0.128 -0.006 0.108 0.148 0.214 0.249   || dis=0.01 || select=7/8
011/019-th : 0.107 0.101 0.110 0.121 0.118 0.132 0.153 0.158  ||  -0.147 -0.206 -0.113 -0.017 -0.048 0.065 0.215 0.248  || dis=0.01 || select=7/8
012/019-th : 0.133 0.124 0.125 0.126 0.119 0.119 0.126 0.128  ||  0.060 -0.009 -0.003 0.004 -0.049 -0.049 0.011 0.024   || dis=0.01 || select=0/8
013/019-th : 0.008 0.010 0.012 0.015 0.019 0.031 0.073 0.832  ||  -1.270 -1.142 -0.910 -0.694 -0.428 0.034 0.898 3.330  || dis=0.76 || select=7/8
014/019-th : 0.009 0.015 0.020 0.025 0.041 0.073 0.167 0.650  ||  -1.622 -1.167 -0.882 -0.635 -0.164 0.426 1.253 2.612  || dis=0.48 || select=7/8
015/019-th : 0.005 0.008 0.010 0.012 0.016 0.029 0.076 0.843  ||  -1.567 -1.223 -0.979 -0.756 -0.456 0.134 1.083 3.488  || dis=0.77 || select=7/8
016/019-th : 0.043 0.062 0.072 0.104 0.136 0.167 0.193 0.224  ||  -0.927 -0.573 -0.416 -0.057 0.212 0.418 0.564 0.712   || dis=0.03 || select=7/8
017/019-th : 0.084 0.100 0.106 0.128 0.130 0.141 0.152 0.159  ||  -0.374 -0.202 -0.142 0.047 0.068 0.148 0.222 0.267    || dis=0.01 || select=7/8
018/019-th : 0.090 0.108 0.118 0.135 0.129 0.138 0.135 0.148  ||  -0.318 -0.136 -0.046 0.086 0.040 0.110 0.089 0.180    || dis=0.01 || select=7/8
[epoch=420/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.168
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:24:50] [epoch=420/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.749 (3.749)  Prec@1 41.41 (41.41) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:24:56] [epoch=420/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.262 (2.488)  Prec@1 70.83 (38.82) Prec@5 96.43 (81.71) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.82 Prec@5 81.71 Error@1 61.18 Error@5 18.29 Loss:2.488
***[2020-01-29 09:24:56]*** VALID [epoch=420/600] loss = 2.487510, accuracy@1 = 38.82, accuracy@5 = 81.71 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:24:56]*** start epoch=421/600 Time Left: [01:35:11], LR=[0.020399 ~ 0.020399], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=421, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0995677119419123, FLOP=40.81
[Search] : epoch=421/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:24:57] [epoch=421/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.671 (0.671)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.799 (0.799) FLOP-Loss -2.905 (-2.905) Arch-Loss -5.010 (-5.010)
**TRAIN** [2020-01-29 09:25:21] [epoch=421/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.758 (0.670)  Prec@1 71.43 (77.18) Prec@5 97.62 (98.38) Acls-loss 0.762 (0.732) FLOP-Loss 2.904 (0.228) Arch-Loss 6.570 (1.188)
 **TRAIN** Prec@1 77.18 Prec@5 98.38 Error@1 22.82 Error@5 1.62 Base-Loss:0.670, Arch-Loss=1.188
***[2020-01-29 09:25:21]*** TRAIN [epoch=421/600] base-loss = 0.669820, arch-loss = 1.187596, accuracy-1 = 77.18, accuracy-5 = 98.38
[epoch=421/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.369 0.263 0.368  ||  0.1729 -0.1648 0.1725  || discrepancy=0.00 || select=0/3
001/003-th : 0.324 0.197 0.479  ||  0.0810 -0.4180 0.4709  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3378 -0.8920 2.9018  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.026 0.041 0.053 0.058 0.094 0.136 0.215 0.378  ||  -1.220 -0.776 -0.523 -0.428 0.058 0.423 0.881 1.446   || dis=0.16 || select=7/8
001/019-th : 0.105 0.134 0.144 0.134 0.130 0.123 0.122 0.107  ||  -0.165 0.078 0.148 0.079 0.045 -0.005 -0.013 -0.145   || dis=0.01 || select=2/8
002/019-th : 0.134 0.135 0.134 0.135 0.122 0.121 0.113 0.105  ||  0.076 0.081 0.073 0.083 -0.019 -0.032 -0.099 -0.174   || dis=0.00 || select=3/8
003/019-th : 0.102 0.116 0.124 0.128 0.130 0.132 0.132 0.136  ||  -0.197 -0.072 -0.001 0.029 0.046 0.060 0.059 0.090    || dis=0.00 || select=7/8
004/019-th : 0.115 0.112 0.115 0.122 0.127 0.132 0.136 0.142  ||  -0.083 -0.110 -0.081 -0.022 0.019 0.056 0.090 0.133   || dis=0.01 || select=7/8
005/019-th : 0.109 0.123 0.128 0.128 0.124 0.128 0.126 0.133  ||  -0.139 -0.013 0.025 0.027 -0.006 0.028 0.011 0.063    || dis=0.01 || select=7/8
006/019-th : 0.134 0.123 0.118 0.117 0.123 0.125 0.129 0.132  ||  0.071 -0.022 -0.058 -0.072 -0.019 -0.003 0.030 0.049  || dis=0.00 || select=0/8
007/019-th : 0.022 0.032 0.050 0.066 0.104 0.127 0.200 0.399  ||  -1.347 -0.975 -0.512 -0.242 0.215 0.418 0.870 1.561   || dis=0.20 || select=7/8
008/019-th : 0.017 0.026 0.036 0.060 0.090 0.154 0.261 0.356  ||  -1.518 -1.079 -0.754 -0.250 0.164 0.702 1.225 1.537   || dis=0.09 || select=7/8
009/019-th : 0.077 0.085 0.104 0.106 0.129 0.144 0.162 0.192  ||  -0.443 -0.335 -0.138 -0.116 0.078 0.185 0.303 0.476   || dis=0.03 || select=7/8
010/019-th : 0.093 0.092 0.108 0.123 0.136 0.142 0.151 0.155  ||  -0.274 -0.285 -0.126 0.004 0.108 0.147 0.213 0.240    || dis=0.00 || select=7/8
011/019-th : 0.107 0.100 0.110 0.122 0.117 0.132 0.154 0.157  ||  -0.143 -0.208 -0.112 -0.016 -0.058 0.068 0.222 0.242  || dis=0.00 || select=7/8
012/019-th : 0.133 0.125 0.125 0.125 0.120 0.118 0.126 0.127  ||  0.064 -0.001 0.002 -0.005 -0.044 -0.056 0.008 0.019   || dis=0.01 || select=0/8
013/019-th : 0.008 0.010 0.012 0.015 0.020 0.031 0.074 0.831  ||  -1.265 -1.130 -0.937 -0.691 -0.417 0.042 0.900 3.323  || dis=0.76 || select=7/8
014/019-th : 0.010 0.015 0.020 0.026 0.040 0.073 0.164 0.653  ||  -1.611 -1.177 -0.873 -0.627 -0.169 0.426 1.232 2.616  || dis=0.49 || select=7/8
015/019-th : 0.005 0.008 0.009 0.012 0.016 0.029 0.074 0.845  ||  -1.570 -1.214 -0.996 -0.750 -0.449 0.136 1.066 3.496  || dis=0.77 || select=7/8
016/019-th : 0.044 0.062 0.073 0.103 0.134 0.167 0.195 0.224  ||  -0.925 -0.574 -0.414 -0.061 0.199 0.417 0.573 0.712   || dis=0.03 || select=7/8
017/019-th : 0.083 0.100 0.106 0.128 0.132 0.142 0.152 0.158  ||  -0.381 -0.197 -0.138 0.050 0.080 0.155 0.221 0.262    || dis=0.01 || select=7/8
018/019-th : 0.090 0.108 0.119 0.136 0.129 0.135 0.135 0.148  ||  -0.322 -0.136 -0.037 0.096 0.041 0.091 0.089 0.183    || dis=0.01 || select=7/8
[epoch=421/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.168
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:25:22] [epoch=421/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.387 (1.387)  Prec@1 63.28 (63.28) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:25:27] [epoch=421/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 4.328 (2.442)  Prec@1 16.67 (40.10) Prec@5 61.31 (81.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.10 Prec@5 81.14 Error@1 59.90 Error@5 18.86 Loss:2.442
***[2020-01-29 09:25:27]*** VALID [epoch=421/600] loss = 2.441630, accuracy@1 = 40.10, accuracy@5 = 81.14 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:25:28]*** start epoch=422/600 Time Left: [01:34:39], LR=[0.020189 ~ 0.020189], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=422, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.089249056334241, FLOP=40.81
[Search] : epoch=422/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:25:28] [epoch=422/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.485 (0.485)  Prec@1 83.59 (83.59) Prec@5 99.61 (99.61) Acls-loss 0.706 (0.706) FLOP-Loss -2.904 (-2.904) Arch-Loss -5.103 (-5.103)
**TRAIN** [2020-01-29 09:25:53] [epoch=422/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.614 (0.637)  Prec@1 77.98 (78.19) Prec@5 99.40 (98.60) Acls-loss 0.739 (0.735) FLOP-Loss -2.905 (0.070) Arch-Loss -5.072 (0.875)
 **TRAIN** Prec@1 78.19 Prec@5 98.60 Error@1 21.81 Error@5 1.40 Base-Loss:0.637, Arch-Loss=0.875
***[2020-01-29 09:25:53]*** TRAIN [epoch=422/600] base-loss = 0.636910, arch-loss = 0.874756, accuracy-1 = 78.19, accuracy-5 = 98.60
[epoch=422/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.94944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.368 0.263 0.369  ||  0.1724 -0.1646 0.1728  || discrepancy=0.00 || select=2/3
001/003-th : 0.323 0.197 0.480  ||  0.0778 -0.4194 0.4739  || discrepancy=0.16 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3284 -0.8890 2.8940  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.026 0.040 0.052 0.058 0.094 0.135 0.215 0.379  ||  -1.225 -0.790 -0.524 -0.432 0.060 0.424 0.887 1.455   || dis=0.16 || select=7/8
001/019-th : 0.105 0.134 0.143 0.135 0.129 0.124 0.123 0.107  ||  -0.163 0.074 0.144 0.083 0.038 -0.002 -0.009 -0.145   || dis=0.01 || select=2/8
002/019-th : 0.134 0.135 0.133 0.136 0.123 0.122 0.113 0.105  ||  0.072 0.079 0.069 0.085 -0.013 -0.023 -0.095 -0.175   || dis=0.00 || select=3/8
003/019-th : 0.102 0.115 0.124 0.129 0.131 0.131 0.132 0.136  ||  -0.195 -0.075 -0.004 0.036 0.049 0.051 0.057 0.093    || dis=0.00 || select=7/8
004/019-th : 0.115 0.112 0.115 0.120 0.126 0.132 0.137 0.142  ||  -0.084 -0.111 -0.076 -0.035 0.010 0.060 0.096 0.134   || dis=0.00 || select=7/8
005/019-th : 0.109 0.123 0.128 0.126 0.125 0.130 0.126 0.133  ||  -0.137 -0.018 0.027 0.008 0.003 0.037 0.012 0.063     || dis=0.00 || select=7/8
006/019-th : 0.134 0.122 0.119 0.115 0.124 0.125 0.129 0.132  ||  0.070 -0.024 -0.054 -0.087 -0.013 0.002 0.030 0.049   || dis=0.00 || select=0/8
007/019-th : 0.022 0.032 0.049 0.065 0.102 0.129 0.198 0.403  ||  -1.347 -0.974 -0.531 -0.248 0.199 0.436 0.865 1.573   || dis=0.21 || select=7/8
008/019-th : 0.017 0.026 0.036 0.060 0.090 0.154 0.258 0.359  ||  -1.511 -1.070 -0.766 -0.243 0.153 0.694 1.212 1.543   || dis=0.10 || select=7/8
009/019-th : 0.076 0.086 0.104 0.106 0.129 0.144 0.162 0.192  ||  -0.447 -0.332 -0.138 -0.117 0.078 0.184 0.307 0.476   || dis=0.03 || select=7/8
010/019-th : 0.092 0.091 0.108 0.123 0.136 0.143 0.152 0.155  ||  -0.280 -0.288 -0.127 0.009 0.108 0.157 0.217 0.239    || dis=0.00 || select=7/8
011/019-th : 0.107 0.100 0.110 0.121 0.117 0.132 0.155 0.158  ||  -0.140 -0.210 -0.114 -0.019 -0.057 0.062 0.224 0.243  || dis=0.00 || select=7/8
012/019-th : 0.133 0.125 0.126 0.124 0.120 0.118 0.126 0.127  ||  0.063 -0.002 0.005 -0.005 -0.041 -0.055 0.006 0.019   || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.012 0.015 0.019 0.031 0.073 0.834  ||  -1.265 -1.154 -0.941 -0.691 -0.429 0.035 0.905 3.342  || dis=0.76 || select=7/8
014/019-th : 0.009 0.015 0.020 0.025 0.039 0.072 0.161 0.659  ||  -1.623 -1.173 -0.881 -0.644 -0.177 0.427 1.230 2.638  || dis=0.50 || select=7/8
015/019-th : 0.005 0.008 0.010 0.012 0.016 0.030 0.072 0.847  ||  -1.554 -1.210 -0.987 -0.747 -0.464 0.148 1.042 3.502  || dis=0.78 || select=7/8
016/019-th : 0.043 0.061 0.071 0.102 0.134 0.170 0.193 0.224  ||  -0.934 -0.576 -0.432 -0.064 0.207 0.444 0.569 0.718   || dis=0.03 || select=7/8
017/019-th : 0.084 0.100 0.106 0.126 0.131 0.143 0.152 0.159  ||  -0.376 -0.201 -0.139 0.033 0.069 0.160 0.222 0.267    || dis=0.01 || select=7/8
018/019-th : 0.089 0.107 0.121 0.135 0.131 0.134 0.134 0.148  ||  -0.325 -0.141 -0.020 0.086 0.060 0.086 0.085 0.184    || dis=0.01 || select=7/8
[epoch=422/600] FLOP : 31.95 MB, ratio : 0.7828, Expected-ratio : 0.7000, Discrepancy : 0.169
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:25:53] [epoch=422/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 4.434 (4.434)  Prec@1 26.17 (26.17) Prec@5 67.97 (67.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:25:59] [epoch=422/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 1.345 (2.815)  Prec@1 55.95 (37.16) Prec@5 95.83 (79.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 37.16 Prec@5 79.02 Error@1 62.84 Error@5 20.98 Loss:2.815
***[2020-01-29 09:25:59]*** VALID [epoch=422/600] loss = 2.815117, accuracy@1 = 37.16, accuracy@5 = 79.02 | Best-Valid-Acc@1=42.27, Error@1=57.73
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:25:59]*** start epoch=423/600 Time Left: [01:34:07], LR=[0.019979 ~ 0.019979], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=423, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0789704479515845, FLOP=40.81
[Search] : epoch=423/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:26:00] [epoch=423/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.560 (0.560)  Prec@1 80.08 (80.08) Prec@5 100.00 (100.00) Acls-loss 0.818 (0.818) FLOP-Loss 2.906 (2.906) Arch-Loss 6.630 (6.630)
**TRAIN** [2020-01-29 09:26:25] [epoch=423/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.461 (0.684)  Prec@1 83.93 (76.98) Prec@5 99.40 (98.35) Acls-loss 0.796 (0.762) FLOP-Loss 2.906 (0.288) Arch-Loss 6.607 (1.337)
 **TRAIN** Prec@1 76.98 Prec@5 98.35 Error@1 23.02 Error@5 1.65 Base-Loss:0.684, Arch-Loss=1.337
***[2020-01-29 09:26:25]*** TRAIN [epoch=423/600] base-loss = 0.683799, arch-loss = 1.337402, accuracy-1 = 76.98, accuracy-5 = 98.35
[epoch=423/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.366 0.267 0.366  ||  0.1719 -0.1438 0.1714  || discrepancy=0.00 || select=0/3
001/003-th : 0.324 0.198 0.478  ||  0.0820 -0.4134 0.4693  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3293 -0.8749 2.8910  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.026 0.041 0.052 0.058 0.095 0.132 0.214 0.382  ||  -1.242 -0.780 -0.537 -0.416 0.075 0.403 0.885 1.463   || dis=0.17 || select=7/8
001/019-th : 0.106 0.133 0.143 0.135 0.130 0.124 0.122 0.107  ||  -0.161 0.072 0.143 0.089 0.044 -0.003 -0.013 -0.144   || dis=0.01 || select=2/8
002/019-th : 0.134 0.135 0.133 0.136 0.122 0.122 0.113 0.104  ||  0.074 0.080 0.070 0.091 -0.021 -0.021 -0.097 -0.177   || dis=0.00 || select=3/8
003/019-th : 0.102 0.115 0.124 0.130 0.133 0.131 0.131 0.135  ||  -0.195 -0.075 -0.001 0.046 0.071 0.056 0.053 0.085    || dis=0.00 || select=7/8
004/019-th : 0.115 0.112 0.114 0.120 0.127 0.132 0.137 0.143  ||  -0.080 -0.109 -0.086 -0.039 0.017 0.054 0.093 0.136   || dis=0.01 || select=7/8
005/019-th : 0.109 0.123 0.128 0.127 0.125 0.129 0.127 0.132  ||  -0.134 -0.015 0.021 0.021 -0.000 0.033 0.014 0.057    || dis=0.00 || select=7/8
006/019-th : 0.134 0.123 0.117 0.116 0.124 0.127 0.129 0.131  ||  0.071 -0.020 -0.064 -0.080 -0.013 0.011 0.030 0.045   || dis=0.00 || select=0/8
007/019-th : 0.021 0.032 0.049 0.064 0.101 0.131 0.198 0.404  ||  -1.369 -0.964 -0.530 -0.258 0.197 0.455 0.865 1.579   || dis=0.21 || select=7/8
008/019-th : 0.017 0.026 0.035 0.060 0.089 0.152 0.259 0.361  ||  -1.503 -1.065 -0.792 -0.245 0.147 0.686 1.219 1.550   || dis=0.10 || select=7/8
009/019-th : 0.077 0.086 0.104 0.107 0.128 0.145 0.162 0.191  ||  -0.438 -0.324 -0.140 -0.115 0.069 0.191 0.301 0.469   || dis=0.03 || select=7/8
010/019-th : 0.093 0.091 0.108 0.126 0.136 0.142 0.151 0.154  ||  -0.274 -0.293 -0.126 0.032 0.109 0.151 0.210 0.236    || dis=0.00 || select=7/8
011/019-th : 0.108 0.100 0.110 0.123 0.117 0.132 0.153 0.156  ||  -0.136 -0.207 -0.116 -0.005 -0.051 0.068 0.217 0.235  || dis=0.00 || select=7/8
012/019-th : 0.134 0.125 0.126 0.128 0.119 0.117 0.126 0.127  ||  0.068 -0.001 0.007 0.022 -0.049 -0.065 0.005 0.014    || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.011 0.015 0.019 0.029 0.072 0.836  ||  -1.260 -1.144 -0.947 -0.692 -0.419 0.011 0.901 3.357  || dis=0.76 || select=7/8
014/019-th : 0.009 0.015 0.019 0.025 0.040 0.072 0.160 0.661  ||  -1.623 -1.173 -0.896 -0.648 -0.169 0.426 1.227 2.644  || dis=0.50 || select=7/8
015/019-th : 0.006 0.008 0.010 0.012 0.016 0.030 0.072 0.848  ||  -1.537 -1.210 -0.977 -0.748 -0.460 0.145 1.032 3.500  || dis=0.78 || select=7/8
016/019-th : 0.042 0.061 0.071 0.102 0.135 0.172 0.192 0.224  ||  -0.946 -0.579 -0.425 -0.068 0.209 0.457 0.565 0.721   || dis=0.03 || select=7/8
017/019-th : 0.083 0.100 0.106 0.127 0.133 0.142 0.152 0.158  ||  -0.384 -0.197 -0.135 0.041 0.087 0.154 0.223 0.261    || dis=0.01 || select=7/8
018/019-th : 0.090 0.107 0.122 0.135 0.130 0.134 0.134 0.148  ||  -0.316 -0.148 -0.012 0.093 0.052 0.082 0.083 0.180    || dis=0.01 || select=7/8
[epoch=423/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.170
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:26:25] [epoch=423/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.725 (1.725)  Prec@1 42.97 (42.97) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:26:31] [epoch=423/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 2.208 (2.292)  Prec@1 48.81 (43.36) Prec@5 86.90 (84.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.36 Prec@5 84.18 Error@1 56.64 Error@5 15.82 Loss:2.292
***[2020-01-29 09:26:31]*** VALID [epoch=423/600] loss = 2.291555, accuracy@1 = 43.36, accuracy@5 = 84.18 | Best-Valid-Acc@1=42.27, Error@1=57.73
Currently, the best validation accuracy found at 423-epoch :: acc@1=43.36, acc@5=84.18, error@1=56.64, error@5=15.82, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:26:31]*** start epoch=424/600 Time Left: [01:33:35], LR=[0.019770 ~ 0.019770], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=424, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0687321685871818, FLOP=40.81
[Search] : epoch=424/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:26:32] [epoch=424/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.623 (0.623)  Prec@1 77.34 (77.34) Prec@5 99.61 (99.61) Acls-loss 0.931 (0.931) FLOP-Loss -2.905 (-2.905) Arch-Loss -4.880 (-4.880)
**TRAIN** [2020-01-29 09:26:56] [epoch=424/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.662 (0.657)  Prec@1 76.79 (77.60) Prec@5 98.81 (98.42) Acls-loss 0.735 (0.748) FLOP-Loss -2.906 (0.129) Arch-Loss -5.078 (1.007)
 **TRAIN** Prec@1 77.60 Prec@5 98.42 Error@1 22.40 Error@5 1.58 Base-Loss:0.657, Arch-Loss=1.007
***[2020-01-29 09:26:57]*** TRAIN [epoch=424/600] base-loss = 0.656762, arch-loss = 1.006682, accuracy-1 = 77.60, accuracy-5 = 98.42
[epoch=424/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.94944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.365 0.269 0.366  ||  0.1709 -0.1347 0.1714  || discrepancy=0.00 || select=2/3
001/003-th : 0.325 0.197 0.478  ||  0.0822 -0.4188 0.4694  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3299 -0.8918 2.9000  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.025 0.040 0.050 0.058 0.095 0.131 0.217 0.384  ||  -1.249 -0.784 -0.556 -0.424 0.077 0.397 0.906 1.474   || dis=0.17 || select=7/8
001/019-th : 0.105 0.133 0.143 0.135 0.130 0.123 0.123 0.107  ||  -0.163 0.071 0.142 0.088 0.051 -0.005 -0.009 -0.144   || dis=0.01 || select=2/8
002/019-th : 0.134 0.135 0.132 0.136 0.122 0.122 0.113 0.105  ||  0.073 0.082 0.059 0.085 -0.024 -0.019 -0.096 -0.173   || dis=0.00 || select=3/8
003/019-th : 0.102 0.115 0.125 0.129 0.133 0.132 0.131 0.135  ||  -0.198 -0.077 0.005 0.037 0.072 0.062 0.056 0.083     || dis=0.00 || select=7/8
004/019-th : 0.115 0.112 0.115 0.119 0.127 0.132 0.137 0.143  ||  -0.083 -0.109 -0.082 -0.048 0.017 0.054 0.097 0.138   || dis=0.01 || select=7/8
005/019-th : 0.108 0.123 0.126 0.126 0.126 0.130 0.127 0.133  ||  -0.141 -0.013 0.011 0.009 0.012 0.038 0.013 0.066     || dis=0.00 || select=7/8
006/019-th : 0.134 0.122 0.117 0.116 0.122 0.127 0.130 0.131  ||  0.068 -0.024 -0.067 -0.079 -0.025 0.016 0.040 0.046   || dis=0.00 || select=0/8
007/019-th : 0.021 0.031 0.049 0.064 0.101 0.131 0.197 0.407  ||  -1.371 -0.979 -0.533 -0.261 0.198 0.457 0.863 1.589   || dis=0.21 || select=7/8
008/019-th : 0.016 0.026 0.034 0.059 0.088 0.153 0.262 0.362  ||  -1.529 -1.077 -0.793 -0.255 0.144 0.703 1.241 1.562   || dis=0.10 || select=7/8
009/019-th : 0.078 0.087 0.104 0.106 0.128 0.146 0.161 0.191  ||  -0.432 -0.323 -0.141 -0.122 0.067 0.202 0.298 0.466   || dis=0.03 || select=7/8
010/019-th : 0.093 0.090 0.108 0.127 0.134 0.142 0.152 0.155  ||  -0.277 -0.303 -0.124 0.036 0.091 0.153 0.216 0.241    || dis=0.00 || select=7/8
011/019-th : 0.108 0.101 0.110 0.122 0.119 0.131 0.153 0.156  ||  -0.130 -0.204 -0.118 -0.013 -0.040 0.063 0.216 0.232  || dis=0.00 || select=7/8
012/019-th : 0.134 0.125 0.125 0.128 0.119 0.117 0.126 0.127  ||  0.070 -0.001 0.002 0.025 -0.049 -0.069 0.008 0.013    || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.011 0.014 0.019 0.029 0.071 0.838  ||  -1.281 -1.132 -0.962 -0.699 -0.422 0.014 0.905 3.370  || dis=0.77 || select=7/8
014/019-th : 0.009 0.015 0.019 0.024 0.040 0.071 0.156 0.666  ||  -1.616 -1.171 -0.900 -0.651 -0.159 0.417 1.204 2.655  || dis=0.51 || select=7/8
015/019-th : 0.006 0.008 0.010 0.012 0.016 0.030 0.071 0.849  ||  -1.524 -1.221 -0.976 -0.741 -0.461 0.146 1.023 3.505  || dis=0.78 || select=7/8
016/019-th : 0.042 0.060 0.072 0.102 0.134 0.172 0.192 0.227  ||  -0.952 -0.594 -0.420 -0.070 0.210 0.455 0.564 0.731   || dis=0.04 || select=7/8
017/019-th : 0.082 0.098 0.105 0.129 0.132 0.143 0.152 0.158  ||  -0.391 -0.209 -0.140 0.061 0.083 0.164 0.225 0.266    || dis=0.01 || select=7/8
018/019-th : 0.089 0.106 0.122 0.136 0.130 0.135 0.134 0.148  ||  -0.324 -0.149 -0.009 0.097 0.056 0.089 0.080 0.182    || dis=0.01 || select=7/8
[epoch=424/600] FLOP : 31.95 MB, ratio : 0.7828, Expected-ratio : 0.7000, Discrepancy : 0.171
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:26:57] [epoch=424/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.039 (2.039)  Prec@1 37.50 (37.50) Prec@5 81.25 (81.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:27:03] [epoch=424/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.816 (2.428)  Prec@1 42.86 (40.20) Prec@5 86.90 (82.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.20 Prec@5 82.70 Error@1 59.80 Error@5 17.30 Loss:2.428
***[2020-01-29 09:27:03]*** VALID [epoch=424/600] loss = 2.428172, accuracy@1 = 40.20, accuracy@5 = 82.70 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:27:03]*** start epoch=425/600 Time Left: [01:33:03], LR=[0.019562 ~ 0.019562], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=425, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0585344989286345, FLOP=40.81
[Search] : epoch=425/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:27:04] [epoch=425/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.794 (0.794)  Prec@1 69.14 (69.14) Prec@5 98.83 (98.83) Acls-loss 0.666 (0.666) FLOP-Loss 2.907 (2.907) Arch-Loss 6.480 (6.480)
**TRAIN** [2020-01-29 09:27:28] [epoch=425/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.544 (0.643)  Prec@1 82.74 (78.10) Prec@5 98.21 (98.55) Acls-loss 0.822 (0.709) FLOP-Loss 2.908 (0.169) Arch-Loss 6.638 (1.046)
 **TRAIN** Prec@1 78.10 Prec@5 98.55 Error@1 21.90 Error@5 1.45 Base-Loss:0.643, Arch-Loss=1.046
***[2020-01-29 09:27:28]*** TRAIN [epoch=425/600] base-loss = 0.643409, arch-loss = 1.045924, accuracy-1 = 78.10, accuracy-5 = 98.55
[epoch=425/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.367 0.266 0.367  ||  0.1717 -0.1493 0.1715  || discrepancy=0.00 || select=0/3
001/003-th : 0.325 0.197 0.478  ||  0.0830 -0.4189 0.4685  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.972  ||  -2.3189 -0.8868 2.8901  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.025 0.040 0.050 0.056 0.095 0.131 0.215 0.388  ||  -1.252 -0.794 -0.559 -0.444 0.078 0.406 0.898 1.489   || dis=0.17 || select=7/8
001/019-th : 0.104 0.133 0.142 0.136 0.133 0.123 0.122 0.107  ||  -0.171 0.074 0.136 0.095 0.071 -0.004 -0.010 -0.144   || dis=0.01 || select=2/8
002/019-th : 0.134 0.135 0.133 0.135 0.123 0.122 0.113 0.105  ||  0.074 0.080 0.060 0.075 -0.018 -0.023 -0.096 -0.170   || dis=0.00 || select=1/8
003/019-th : 0.102 0.114 0.124 0.128 0.134 0.133 0.131 0.134  ||  -0.197 -0.083 0.003 0.030 0.080 0.072 0.058 0.082     || dis=0.00 || select=7/8
004/019-th : 0.115 0.112 0.115 0.118 0.127 0.131 0.138 0.143  ||  -0.081 -0.107 -0.079 -0.057 0.019 0.048 0.099 0.138   || dis=0.00 || select=7/8
005/019-th : 0.108 0.123 0.125 0.127 0.127 0.129 0.127 0.133  ||  -0.143 -0.011 0.002 0.020 0.018 0.037 0.015 0.065     || dis=0.00 || select=7/8
006/019-th : 0.134 0.122 0.117 0.116 0.123 0.128 0.130 0.131  ||  0.065 -0.027 -0.067 -0.079 -0.015 0.019 0.038 0.049   || dis=0.00 || select=0/8
007/019-th : 0.021 0.031 0.049 0.064 0.101 0.128 0.202 0.405  ||  -1.379 -0.979 -0.528 -0.260 0.198 0.438 0.890 1.587   || dis=0.20 || select=7/8
008/019-th : 0.016 0.026 0.034 0.059 0.088 0.152 0.261 0.365  ||  -1.532 -1.075 -0.792 -0.255 0.148 0.692 1.235 1.570   || dis=0.10 || select=7/8
009/019-th : 0.078 0.086 0.105 0.106 0.128 0.146 0.161 0.191  ||  -0.432 -0.331 -0.131 -0.118 0.066 0.200 0.297 0.466   || dis=0.03 || select=7/8
010/019-th : 0.093 0.091 0.108 0.126 0.133 0.143 0.150 0.156  ||  -0.276 -0.296 -0.121 0.032 0.082 0.157 0.207 0.243    || dis=0.01 || select=7/8
011/019-th : 0.108 0.101 0.109 0.122 0.120 0.132 0.153 0.155  ||  -0.132 -0.202 -0.122 -0.013 -0.031 0.064 0.216 0.231  || dis=0.00 || select=7/8
012/019-th : 0.134 0.125 0.125 0.128 0.119 0.117 0.125 0.126  ||  0.072 -0.001 0.001 0.026 -0.047 -0.062 0.003 0.012    || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.011 0.014 0.019 0.029 0.069 0.841  ||  -1.278 -1.134 -0.955 -0.689 -0.430 0.015 0.883 3.384  || dis=0.77 || select=7/8
014/019-th : 0.009 0.015 0.019 0.025 0.040 0.069 0.156 0.668  ||  -1.630 -1.164 -0.913 -0.636 -0.159 0.394 1.213 2.666  || dis=0.51 || select=7/8
015/019-th : 0.006 0.008 0.010 0.012 0.016 0.029 0.069 0.850  ||  -1.509 -1.216 -0.970 -0.734 -0.463 0.138 1.005 3.510  || dis=0.78 || select=7/8
016/019-th : 0.042 0.060 0.071 0.102 0.134 0.171 0.192 0.228  ||  -0.963 -0.591 -0.423 -0.071 0.208 0.448 0.568 0.737   || dis=0.04 || select=7/8
017/019-th : 0.082 0.098 0.105 0.129 0.132 0.144 0.152 0.158  ||  -0.396 -0.207 -0.144 0.065 0.088 0.174 0.225 0.263    || dis=0.01 || select=7/8
018/019-th : 0.090 0.106 0.122 0.136 0.132 0.134 0.134 0.147  ||  -0.319 -0.150 -0.012 0.100 0.070 0.082 0.081 0.177    || dis=0.01 || select=7/8
[epoch=425/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.171
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:27:29] [epoch=425/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.531 (1.531)  Prec@1 60.16 (60.16) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:27:34] [epoch=425/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.555 (2.466)  Prec@1 63.10 (39.41) Prec@5 91.67 (80.25) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.41 Prec@5 80.25 Error@1 60.59 Error@5 19.75 Loss:2.466
***[2020-01-29 09:27:34]*** VALID [epoch=425/600] loss = 2.466251, accuracy@1 = 39.41, accuracy@5 = 80.25 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:27:35]*** start epoch=426/600 Time Left: [01:32:31], LR=[0.019355 ~ 0.019355], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=426, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0483777185502083, FLOP=40.81
[Search] : epoch=426/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:27:35] [epoch=426/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.720 (0.720)  Prec@1 76.17 (76.17) Prec@5 98.44 (98.44) Acls-loss 0.545 (0.545) FLOP-Loss -2.907 (-2.907) Arch-Loss -5.270 (-5.270)
**TRAIN** [2020-01-29 09:28:00] [epoch=426/600][097/098] Time 0.32 (0.26) Data 0.00 (0.00) Base-Loss 0.657 (0.671)  Prec@1 79.17 (77.11) Prec@5 98.21 (98.51) Acls-loss 0.534 (0.706) FLOP-Loss 2.908 (0.109) Arch-Loss 6.351 (0.924)
 **TRAIN** Prec@1 77.11 Prec@5 98.51 Error@1 22.89 Error@5 1.49 Base-Loss:0.671, Arch-Loss=0.924
***[2020-01-29 09:28:00]*** TRAIN [epoch=426/600] base-loss = 0.670945, arch-loss = 0.923992, accuracy-1 = 77.11, accuracy-5 = 98.51
[epoch=426/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.367 0.266 0.367  ||  0.1721 -0.1507 0.1709  || discrepancy=0.00 || select=0/3
001/003-th : 0.324 0.198 0.477  ||  0.0817 -0.4089 0.4689  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.972  ||  -2.3126 -0.8844 2.8853  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.025 0.040 0.050 0.056 0.095 0.130 0.215 0.389  ||  -1.255 -0.788 -0.568 -0.444 0.086 0.397 0.899 1.492   || dis=0.17 || select=7/8
001/019-th : 0.104 0.133 0.141 0.136 0.133 0.123 0.123 0.107  ||  -0.173 0.073 0.133 0.093 0.072 -0.004 -0.008 -0.141   || dis=0.00 || select=2/8
002/019-th : 0.134 0.135 0.133 0.134 0.122 0.123 0.114 0.106  ||  0.072 0.078 0.059 0.071 -0.025 -0.020 -0.093 -0.168   || dis=0.00 || select=1/8
003/019-th : 0.102 0.114 0.124 0.128 0.133 0.133 0.132 0.134  ||  -0.193 -0.084 -0.000 0.030 0.071 0.071 0.061 0.081    || dis=0.00 || select=7/8
004/019-th : 0.115 0.113 0.115 0.117 0.126 0.132 0.138 0.144  ||  -0.086 -0.105 -0.082 -0.062 0.010 0.052 0.098 0.144   || dis=0.01 || select=7/8
005/019-th : 0.108 0.123 0.125 0.126 0.126 0.132 0.128 0.133  ||  -0.147 -0.014 0.001 0.013 0.009 0.053 0.022 0.065     || dis=0.00 || select=7/8
006/019-th : 0.134 0.122 0.117 0.117 0.123 0.126 0.130 0.131  ||  0.068 -0.023 -0.067 -0.072 -0.021 0.007 0.038 0.048   || dis=0.00 || select=0/8
007/019-th : 0.021 0.031 0.049 0.064 0.101 0.127 0.200 0.407  ||  -1.372 -0.972 -0.527 -0.261 0.196 0.430 0.878 1.590   || dis=0.21 || select=7/8
008/019-th : 0.016 0.026 0.035 0.058 0.088 0.150 0.260 0.367  ||  -1.538 -1.074 -0.783 -0.264 0.151 0.682 1.232 1.578   || dis=0.11 || select=7/8
009/019-th : 0.078 0.086 0.105 0.107 0.127 0.146 0.162 0.190  ||  -0.433 -0.330 -0.133 -0.114 0.063 0.199 0.303 0.464   || dis=0.03 || select=7/8
010/019-th : 0.091 0.091 0.109 0.126 0.133 0.144 0.150 0.156  ||  -0.289 -0.294 -0.116 0.028 0.086 0.163 0.208 0.246    || dis=0.01 || select=7/8
011/019-th : 0.108 0.101 0.109 0.122 0.119 0.132 0.152 0.156  ||  -0.130 -0.198 -0.124 -0.013 -0.034 0.067 0.209 0.232  || dis=0.00 || select=7/8
012/019-th : 0.134 0.124 0.124 0.128 0.120 0.118 0.126 0.127  ||  0.071 -0.004 -0.008 0.023 -0.040 -0.059 0.006 0.014   || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.011 0.014 0.018 0.029 0.067 0.843  ||  -1.267 -1.121 -0.960 -0.691 -0.433 0.021 0.862 3.393  || dis=0.78 || select=7/8
014/019-th : 0.009 0.015 0.019 0.024 0.039 0.068 0.154 0.672  ||  -1.627 -1.158 -0.914 -0.641 -0.158 0.386 1.201 2.676  || dis=0.52 || select=7/8
015/019-th : 0.006 0.007 0.010 0.012 0.016 0.029 0.068 0.852  ||  -1.518 -1.218 -0.967 -0.746 -0.455 0.149 0.994 3.517  || dis=0.78 || select=7/8
016/019-th : 0.041 0.060 0.072 0.101 0.134 0.170 0.194 0.228  ||  -0.966 -0.595 -0.415 -0.075 0.206 0.447 0.575 0.737   || dis=0.03 || select=7/8
017/019-th : 0.082 0.099 0.105 0.129 0.132 0.145 0.151 0.158  ||  -0.395 -0.204 -0.144 0.059 0.085 0.177 0.221 0.264    || dis=0.01 || select=7/8
018/019-th : 0.090 0.107 0.121 0.136 0.131 0.133 0.134 0.147  ||  -0.318 -0.145 -0.015 0.100 0.058 0.078 0.086 0.177    || dis=0.01 || select=7/8
[epoch=426/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.172
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:28:01] [epoch=426/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.585 (2.585)  Prec@1 44.53 (44.53) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:28:06] [epoch=426/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.903 (2.332)  Prec@1 57.14 (35.18) Prec@5 93.45 (78.85) Size=[168, 3, 32, 32]
 **VALID** Prec@1 35.18 Prec@5 78.85 Error@1 64.82 Error@5 21.15 Loss:2.332
***[2020-01-29 09:28:06]*** VALID [epoch=426/600] loss = 2.332033, accuracy@1 = 35.18, accuracy@5 = 78.85 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:28:07]*** start epoch=427/600 Time Left: [01:31:59], LR=[0.019148 ~ 0.019148], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=427, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0382621059051662, FLOP=40.81
[Search] : epoch=427/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:28:07] [epoch=427/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.577 (0.577)  Prec@1 80.08 (80.08) Prec@5 98.83 (98.83) Acls-loss 0.876 (0.876) FLOP-Loss -2.908 (-2.908) Arch-Loss -4.940 (-4.940)
**TRAIN** [2020-01-29 09:28:32] [epoch=427/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.592 (0.675)  Prec@1 81.55 (76.81) Prec@5 98.21 (98.43) Acls-loss 1.046 (0.707) FLOP-Loss -2.910 (0.070) Arch-Loss -4.773 (0.847)
 **TRAIN** Prec@1 76.81 Prec@5 98.43 Error@1 23.19 Error@5 1.57 Base-Loss:0.675, Arch-Loss=0.847
***[2020-01-29 09:28:32]*** TRAIN [epoch=427/600] base-loss = 0.675210, arch-loss = 0.846962, accuracy-1 = 76.81, accuracy-5 = 98.43
[epoch=427/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.187584)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.366 0.267 0.366  ||  0.1707 -0.1438 0.1715  || discrepancy=0.00 || select=2/3
001/003-th : 0.324 0.197 0.479  ||  0.0801 -0.4194 0.4711  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3204 -0.8966 2.8989  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.024 0.039 0.049 0.056 0.093 0.127 0.215 0.397  ||  -1.271 -0.797 -0.570 -0.439 0.064 0.377 0.904 1.517   || dis=0.18 || select=7/8
001/019-th : 0.104 0.133 0.140 0.136 0.133 0.123 0.123 0.108  ||  -0.173 0.072 0.127 0.093 0.074 -0.003 -0.007 -0.140   || dis=0.00 || select=2/8
002/019-th : 0.134 0.135 0.132 0.135 0.122 0.123 0.114 0.106  ||  0.068 0.077 0.058 0.075 -0.023 -0.015 -0.090 -0.167   || dis=0.00 || select=1/8
003/019-th : 0.102 0.113 0.124 0.128 0.132 0.134 0.133 0.134  ||  -0.195 -0.092 -0.004 0.034 0.064 0.075 0.071 0.081    || dis=0.00 || select=7/8
004/019-th : 0.114 0.112 0.114 0.118 0.128 0.132 0.137 0.145  ||  -0.091 -0.106 -0.090 -0.058 0.022 0.058 0.097 0.148   || dis=0.01 || select=7/8
005/019-th : 0.107 0.122 0.125 0.127 0.126 0.132 0.128 0.133  ||  -0.151 -0.023 0.001 0.021 0.011 0.061 0.027 0.065     || dis=0.00 || select=7/8
006/019-th : 0.133 0.122 0.117 0.118 0.123 0.126 0.131 0.130  ||  0.065 -0.023 -0.066 -0.058 -0.016 0.006 0.044 0.042   || dis=0.00 || select=0/8
007/019-th : 0.021 0.031 0.049 0.063 0.101 0.127 0.202 0.406  ||  -1.373 -0.983 -0.516 -0.270 0.194 0.426 0.893 1.590   || dis=0.20 || select=7/8
008/019-th : 0.016 0.026 0.034 0.058 0.087 0.149 0.260 0.369  ||  -1.533 -1.073 -0.788 -0.271 0.143 0.679 1.234 1.583   || dis=0.11 || select=7/8
009/019-th : 0.077 0.086 0.104 0.107 0.127 0.146 0.162 0.191  ||  -0.436 -0.332 -0.137 -0.113 0.060 0.196 0.306 0.468   || dis=0.03 || select=7/8
010/019-th : 0.092 0.091 0.109 0.124 0.133 0.145 0.150 0.157  ||  -0.284 -0.292 -0.119 0.016 0.081 0.168 0.204 0.248    || dis=0.01 || select=7/8
011/019-th : 0.109 0.102 0.108 0.122 0.120 0.131 0.152 0.156  ||  -0.128 -0.196 -0.130 -0.016 -0.031 0.062 0.210 0.233  || dis=0.00 || select=7/8
012/019-th : 0.134 0.125 0.123 0.126 0.121 0.118 0.126 0.127  ||  0.072 -0.002 -0.016 0.011 -0.034 -0.058 0.007 0.014   || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.011 0.014 0.018 0.028 0.066 0.845  ||  -1.264 -1.112 -0.957 -0.693 -0.429 0.010 0.855 3.400  || dis=0.78 || select=7/8
014/019-th : 0.009 0.015 0.019 0.024 0.039 0.067 0.152 0.675  ||  -1.621 -1.155 -0.910 -0.644 -0.167 0.378 1.195 2.683  || dis=0.52 || select=7/8
015/019-th : 0.006 0.007 0.009 0.012 0.016 0.029 0.067 0.854  ||  -1.499 -1.213 -0.980 -0.754 -0.453 0.149 0.982 3.528  || dis=0.79 || select=7/8
016/019-th : 0.041 0.060 0.072 0.101 0.133 0.170 0.195 0.228  ||  -0.970 -0.597 -0.418 -0.076 0.198 0.448 0.582 0.740   || dis=0.03 || select=7/8
017/019-th : 0.081 0.099 0.104 0.128 0.132 0.146 0.151 0.158  ||  -0.398 -0.207 -0.150 0.052 0.089 0.189 0.220 0.268    || dis=0.01 || select=7/8
018/019-th : 0.090 0.106 0.121 0.136 0.130 0.135 0.135 0.148  ||  -0.321 -0.153 -0.017 0.095 0.054 0.089 0.087 0.182    || dis=0.01 || select=7/8
[epoch=427/600] FLOP : 31.19 MB, ratio : 0.7642, Expected-ratio : 0.7000, Discrepancy : 0.173
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:28:32] [epoch=427/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.735 (2.735)  Prec@1 54.69 (54.69) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:28:38] [epoch=427/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.672 (2.334)  Prec@1 48.81 (40.28) Prec@5 86.90 (81.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.28 Prec@5 81.31 Error@1 59.72 Error@5 18.69 Loss:2.334
***[2020-01-29 09:28:38]*** VALID [epoch=427/600] loss = 2.333520, accuracy@1 = 40.28, accuracy@5 = 81.31 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:28:38]*** start epoch=428/600 Time Left: [01:31:27], LR=[0.018943 ~ 0.018943], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=428, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0281879383181398, FLOP=40.81
[Search] : epoch=428/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:28:39] [epoch=428/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.870 (0.870)  Prec@1 71.09 (71.09) Prec@5 98.05 (98.05) Acls-loss 0.712 (0.712) FLOP-Loss 2.910 (2.910) Arch-Loss 6.531 (6.531)
**TRAIN** [2020-01-29 09:29:03] [epoch=428/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.860 (0.658)  Prec@1 71.43 (77.50) Prec@5 98.81 (98.48) Acls-loss 0.747 (0.692) FLOP-Loss 2.909 (0.228) Arch-Loss 6.565 (1.149)
 **TRAIN** Prec@1 77.50 Prec@5 98.48 Error@1 22.50 Error@5 1.52 Base-Loss:0.658, Arch-Loss=1.149
***[2020-01-29 09:29:04]*** TRAIN [epoch=428/600] base-loss = 0.657668, arch-loss = 1.148886, accuracy-1 = 77.50, accuracy-5 = 98.48
[epoch=428/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.187584)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.367 0.266 0.367  ||  0.1709 -0.1501 0.1715  || discrepancy=0.00 || select=2/3
001/003-th : 0.325 0.197 0.478  ||  0.0837 -0.4175 0.4673  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3293 -0.8859 2.9038  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.025 0.039 0.049 0.055 0.093 0.127 0.216 0.396  ||  -1.262 -0.806 -0.563 -0.461 0.064 0.381 0.912 1.518   || dis=0.18 || select=7/8
001/019-th : 0.104 0.133 0.141 0.137 0.134 0.123 0.122 0.107  ||  -0.174 0.076 0.130 0.103 0.082 -0.006 -0.012 -0.143   || dis=0.00 || select=2/8
002/019-th : 0.134 0.135 0.133 0.134 0.122 0.123 0.114 0.106  ||  0.069 0.079 0.062 0.072 -0.027 -0.015 -0.092 -0.168   || dis=0.00 || select=1/8
003/019-th : 0.102 0.113 0.125 0.128 0.132 0.134 0.133 0.134  ||  -0.198 -0.091 0.006 0.030 0.062 0.076 0.072 0.079     || dis=0.00 || select=7/8
004/019-th : 0.114 0.113 0.114 0.118 0.127 0.133 0.137 0.145  ||  -0.091 -0.104 -0.088 -0.054 0.014 0.060 0.093 0.148   || dis=0.01 || select=7/8
005/019-th : 0.107 0.123 0.125 0.128 0.125 0.131 0.127 0.133  ||  -0.154 -0.014 0.003 0.029 0.003 0.053 0.022 0.066     || dis=0.00 || select=7/8
006/019-th : 0.134 0.122 0.117 0.118 0.123 0.125 0.131 0.130  ||  0.068 -0.021 -0.068 -0.055 -0.014 -0.002 0.045 0.039  || dis=0.00 || select=0/8
007/019-th : 0.021 0.031 0.050 0.064 0.100 0.127 0.202 0.407  ||  -1.369 -0.987 -0.510 -0.266 0.184 0.426 0.889 1.591   || dis=0.20 || select=7/8
008/019-th : 0.016 0.026 0.034 0.057 0.088 0.148 0.262 0.369  ||  -1.526 -1.071 -0.796 -0.288 0.152 0.670 1.240 1.584   || dis=0.11 || select=7/8
009/019-th : 0.078 0.086 0.105 0.107 0.126 0.147 0.162 0.190  ||  -0.432 -0.331 -0.133 -0.114 0.051 0.209 0.301 0.464   || dis=0.03 || select=7/8
010/019-th : 0.093 0.093 0.109 0.124 0.131 0.145 0.150 0.156  ||  -0.280 -0.276 -0.120 0.012 0.067 0.168 0.200 0.242    || dis=0.01 || select=7/8
011/019-th : 0.109 0.101 0.110 0.121 0.120 0.130 0.153 0.156  ||  -0.125 -0.198 -0.120 -0.020 -0.033 0.054 0.213 0.230  || dis=0.00 || select=7/8
012/019-th : 0.135 0.126 0.124 0.126 0.121 0.118 0.125 0.127  ||  0.074 0.006 -0.013 0.004 -0.036 -0.061 0.002 0.011    || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.010 0.014 0.018 0.028 0.065 0.848  ||  -1.249 -1.146 -0.973 -0.704 -0.420 0.013 0.853 3.419  || dis=0.78 || select=7/8
014/019-th : 0.009 0.015 0.018 0.024 0.039 0.067 0.150 0.678  ||  -1.611 -1.148 -0.918 -0.641 -0.178 0.372 1.184 2.690  || dis=0.53 || select=7/8
015/019-th : 0.006 0.008 0.009 0.012 0.016 0.029 0.066 0.855  ||  -1.482 -1.202 -0.978 -0.749 -0.457 0.152 0.962 3.530  || dis=0.79 || select=7/8
016/019-th : 0.041 0.060 0.072 0.101 0.133 0.172 0.194 0.228  ||  -0.971 -0.599 -0.419 -0.074 0.200 0.456 0.578 0.741   || dis=0.03 || select=7/8
017/019-th : 0.082 0.099 0.105 0.128 0.132 0.145 0.150 0.159  ||  -0.393 -0.201 -0.143 0.055 0.082 0.178 0.212 0.267    || dis=0.01 || select=7/8
018/019-th : 0.090 0.105 0.122 0.136 0.132 0.134 0.134 0.147  ||  -0.315 -0.156 -0.008 0.095 0.071 0.084 0.086 0.174    || dis=0.01 || select=7/8
[epoch=428/600] FLOP : 31.19 MB, ratio : 0.7642, Expected-ratio : 0.7000, Discrepancy : 0.173
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:29:04] [epoch=428/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 6.460 (6.460)  Prec@1 20.31 (20.31) Prec@5 62.50 (62.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:29:10] [epoch=428/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.288 (2.522)  Prec@1 50.00 (36.96) Prec@5 91.67 (79.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 36.96 Prec@5 79.80 Error@1 63.04 Error@5 20.20 Loss:2.522
***[2020-01-29 09:29:10]*** VALID [epoch=428/600] loss = 2.522336, accuracy@1 = 36.96, accuracy@5 = 79.80 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:29:10]*** start epoch=429/600 Time Left: [01:30:55], LR=[0.018738 ~ 0.018738], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=429, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.018155491977523, FLOP=40.81
[Search] : epoch=429/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:29:11] [epoch=429/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.733 (0.733)  Prec@1 78.52 (78.52) Prec@5 98.83 (98.83) Acls-loss 0.748 (0.748) FLOP-Loss 2.909 (2.909) Arch-Loss 6.567 (6.567)
**TRAIN** [2020-01-29 09:29:35] [epoch=429/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.645 (0.670)  Prec@1 80.95 (76.93) Prec@5 96.43 (98.43) Acls-loss 0.635 (0.740) FLOP-Loss 2.910 (0.109) Arch-Loss 6.456 (0.958)
 **TRAIN** Prec@1 76.93 Prec@5 98.43 Error@1 23.07 Error@5 1.57 Base-Loss:0.670, Arch-Loss=0.958
***[2020-01-29 09:29:35]*** TRAIN [epoch=429/600] base-loss = 0.670221, arch-loss = 0.957876, accuracy-1 = 76.93, accuracy-5 = 98.43
[epoch=429/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.187584)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.367 0.267 0.367  ||  0.1708 -0.1479 0.1712  || discrepancy=0.00 || select=2/3
001/003-th : 0.325 0.197 0.478  ||  0.0838 -0.4186 0.4672  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3422 -0.8854 2.9170  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.024 0.038 0.048 0.054 0.091 0.129 0.218 0.398  ||  -1.283 -0.808 -0.580 -0.465 0.052 0.401 0.927 1.530   || dis=0.18 || select=7/8
001/019-th : 0.104 0.134 0.140 0.137 0.134 0.123 0.122 0.107  ||  -0.174 0.078 0.127 0.105 0.079 -0.008 -0.014 -0.141   || dis=0.00 || select=2/8
002/019-th : 0.134 0.135 0.133 0.133 0.122 0.123 0.114 0.106  ||  0.070 0.079 0.061 0.062 -0.023 -0.014 -0.095 -0.165   || dis=0.00 || select=1/8
003/019-th : 0.101 0.113 0.125 0.128 0.132 0.134 0.134 0.134  ||  -0.201 -0.090 0.005 0.030 0.062 0.075 0.076 0.079     || dis=0.00 || select=7/8
004/019-th : 0.113 0.112 0.115 0.119 0.125 0.135 0.136 0.144  ||  -0.095 -0.105 -0.085 -0.043 -0.001 0.081 0.090 0.147  || dis=0.01 || select=7/8
005/019-th : 0.107 0.123 0.124 0.128 0.127 0.131 0.127 0.133  ||  -0.156 -0.013 -0.002 0.027 0.018 0.053 0.022 0.065    || dis=0.00 || select=7/8
006/019-th : 0.134 0.123 0.117 0.117 0.124 0.124 0.131 0.130  ||  0.069 -0.018 -0.064 -0.067 -0.011 -0.007 0.043 0.041  || dis=0.00 || select=0/8
007/019-th : 0.021 0.030 0.049 0.063 0.101 0.125 0.201 0.409  ||  -1.370 -1.003 -0.515 -0.271 0.198 0.417 0.891 1.599   || dis=0.21 || select=7/8
008/019-th : 0.017 0.026 0.034 0.056 0.087 0.148 0.261 0.371  ||  -1.516 -1.082 -0.799 -0.298 0.138 0.675 1.238 1.591   || dis=0.11 || select=7/8
009/019-th : 0.078 0.085 0.104 0.106 0.127 0.146 0.163 0.191  ||  -0.429 -0.344 -0.136 -0.119 0.062 0.203 0.309 0.468   || dis=0.03 || select=7/8
010/019-th : 0.093 0.093 0.108 0.123 0.132 0.145 0.150 0.157  ||  -0.277 -0.278 -0.124 0.005 0.072 0.167 0.199 0.244    || dis=0.01 || select=7/8
011/019-th : 0.109 0.102 0.110 0.120 0.118 0.132 0.153 0.156  ||  -0.128 -0.195 -0.121 -0.026 -0.044 0.064 0.214 0.231  || dis=0.00 || select=7/8
012/019-th : 0.135 0.125 0.123 0.126 0.122 0.118 0.125 0.126  ||  0.075 0.004 -0.016 0.005 -0.027 -0.054 0.002 0.009    || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.010 0.014 0.018 0.028 0.064 0.850  ||  -1.246 -1.145 -0.974 -0.709 -0.423 0.014 0.841 3.431  || dis=0.79 || select=7/8
014/019-th : 0.009 0.014 0.018 0.024 0.038 0.066 0.150 0.680  ||  -1.616 -1.161 -0.915 -0.652 -0.180 0.369 1.190 2.702  || dis=0.53 || select=7/8
015/019-th : 0.006 0.007 0.009 0.012 0.015 0.029 0.063 0.858  ||  -1.463 -1.208 -0.976 -0.743 -0.475 0.154 0.943 3.549  || dis=0.79 || select=7/8
016/019-th : 0.041 0.060 0.071 0.101 0.132 0.172 0.195 0.228  ||  -0.975 -0.601 -0.419 -0.071 0.196 0.460 0.583 0.740   || dis=0.03 || select=7/8
017/019-th : 0.082 0.099 0.105 0.128 0.131 0.145 0.151 0.159  ||  -0.389 -0.204 -0.144 0.052 0.077 0.174 0.218 0.266    || dis=0.01 || select=7/8
018/019-th : 0.091 0.105 0.123 0.136 0.131 0.134 0.135 0.146  ||  -0.309 -0.161 -0.006 0.096 0.061 0.080 0.091 0.172    || dis=0.01 || select=7/8
[epoch=429/600] FLOP : 31.19 MB, ratio : 0.7642, Expected-ratio : 0.7000, Discrepancy : 0.174
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:29:36] [epoch=429/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.326 (2.326)  Prec@1 40.23 (40.23) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:29:42] [epoch=429/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.075 (2.157)  Prec@1 17.86 (40.96) Prec@5 65.48 (83.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.96 Prec@5 83.04 Error@1 59.04 Error@5 16.96 Loss:2.157
***[2020-01-29 09:29:42]*** VALID [epoch=429/600] loss = 2.156816, accuracy@1 = 40.96, accuracy@5 = 83.04 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:29:42]*** start epoch=430/600 Time Left: [01:30:24], LR=[0.018534 ~ 0.018534], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=430, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=1.0081650419278987, FLOP=40.81
[Search] : epoch=430/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:29:43] [epoch=430/600][000/098] Time 0.86 (0.86) Data 0.52 (0.52) Base-Loss 0.751 (0.751)  Prec@1 69.92 (69.92) Prec@5 98.83 (98.83) Acls-loss 0.589 (0.589) FLOP-Loss 2.910 (2.910) Arch-Loss 6.410 (6.410)
**TRAIN** [2020-01-29 09:30:09] [epoch=430/600][097/098] Time 0.25 (0.27) Data 0.00 (0.01) Base-Loss 0.548 (0.663)  Prec@1 81.55 (76.94) Prec@5 98.21 (98.49) Acls-loss 0.565 (0.726) FLOP-Loss 2.910 (0.288) Arch-Loss 6.386 (1.302)
 **TRAIN** Prec@1 76.94 Prec@5 98.49 Error@1 23.06 Error@5 1.51 Base-Loss:0.663, Arch-Loss=1.302
***[2020-01-29 09:30:09]*** TRAIN [epoch=430/600] base-loss = 0.662721, arch-loss = 1.302188, accuracy-1 = 76.94, accuracy-5 = 98.49
[epoch=430/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.364 0.273 0.363  ||  0.1704 -0.1187 0.1691  || discrepancy=0.00 || select=0/3
001/003-th : 0.326 0.199 0.475  ||  0.0864 -0.4071 0.4637  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.974  ||  -2.3535 -0.8837 2.9284  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.024 0.038 0.049 0.054 0.088 0.126 0.218 0.402  ||  -1.287 -0.807 -0.573 -0.459 0.026 0.382 0.931 1.542   || dis=0.18 || select=7/8
001/019-th : 0.103 0.133 0.141 0.138 0.133 0.122 0.122 0.107  ||  -0.178 0.077 0.132 0.114 0.077 -0.012 -0.013 -0.140   || dis=0.00 || select=2/8
002/019-th : 0.134 0.136 0.132 0.133 0.122 0.123 0.113 0.106  ||  0.073 0.088 0.056 0.064 -0.026 -0.017 -0.099 -0.169   || dis=0.00 || select=1/8
003/019-th : 0.102 0.114 0.125 0.129 0.131 0.133 0.133 0.134  ||  -0.197 -0.087 0.012 0.043 0.053 0.068 0.068 0.077     || dis=0.00 || select=7/8
004/019-th : 0.113 0.112 0.114 0.119 0.125 0.136 0.137 0.144  ||  -0.094 -0.107 -0.085 -0.044 0.001 0.085 0.094 0.143   || dis=0.01 || select=7/8
005/019-th : 0.107 0.123 0.125 0.128 0.126 0.132 0.127 0.133  ||  -0.150 -0.011 -0.000 0.023 0.009 0.055 0.020 0.062    || dis=0.00 || select=7/8
006/019-th : 0.135 0.124 0.118 0.117 0.123 0.124 0.129 0.130  ||  0.075 -0.010 -0.062 -0.064 -0.014 -0.012 0.033 0.038  || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.049 0.063 0.100 0.128 0.200 0.410  ||  -1.379 -1.004 -0.515 -0.273 0.189 0.437 0.885 1.605   || dis=0.21 || select=7/8
008/019-th : 0.016 0.025 0.034 0.055 0.086 0.147 0.262 0.373  ||  -1.519 -1.098 -0.795 -0.306 0.137 0.671 1.249 1.600   || dis=0.11 || select=7/8
009/019-th : 0.079 0.086 0.105 0.104 0.127 0.146 0.163 0.191  ||  -0.420 -0.336 -0.136 -0.139 0.062 0.196 0.308 0.467   || dis=0.03 || select=7/8
010/019-th : 0.093 0.093 0.108 0.124 0.131 0.145 0.148 0.156  ||  -0.272 -0.275 -0.128 0.014 0.069 0.169 0.190 0.242    || dis=0.01 || select=7/8
011/019-th : 0.109 0.103 0.110 0.122 0.116 0.131 0.153 0.155  ||  -0.126 -0.180 -0.118 -0.013 -0.062 0.059 0.213 0.223  || dis=0.00 || select=7/8
012/019-th : 0.135 0.126 0.123 0.125 0.122 0.119 0.125 0.126  ||  0.078 0.005 -0.017 -0.003 -0.025 -0.051 -0.001 0.007  || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.010 0.013 0.018 0.027 0.063 0.851  ||  -1.229 -1.140 -0.966 -0.709 -0.433 -0.002 0.837 3.439  || dis=0.79 || select=7/8
014/019-th : 0.009 0.014 0.018 0.024 0.038 0.066 0.146 0.686  ||  -1.606 -1.173 -0.911 -0.656 -0.188 0.374 1.168 2.715  || dis=0.54 || select=7/8
015/019-th : 0.006 0.007 0.009 0.012 0.015 0.029 0.062 0.859  ||  -1.455 -1.205 -0.977 -0.727 -0.472 0.156 0.925 3.551  || dis=0.80 || select=7/8
016/019-th : 0.041 0.059 0.071 0.101 0.133 0.172 0.195 0.228  ||  -0.971 -0.607 -0.425 -0.076 0.201 0.462 0.584 0.743   || dis=0.03 || select=7/8
017/019-th : 0.082 0.100 0.106 0.127 0.133 0.144 0.150 0.159  ||  -0.396 -0.197 -0.138 0.048 0.091 0.170 0.212 0.268    || dis=0.01 || select=7/8
018/019-th : 0.090 0.105 0.123 0.137 0.131 0.133 0.135 0.146  ||  -0.310 -0.158 0.001 0.102 0.061 0.077 0.088 0.169     || dis=0.01 || select=7/8
[epoch=430/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.175
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:30:09] [epoch=430/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.569 (1.569)  Prec@1 51.95 (51.95) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:30:15] [epoch=430/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.318 (2.144)  Prec@1 71.43 (39.90) Prec@5 97.02 (81.37) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.90 Prec@5 81.37 Error@1 60.10 Error@5 18.63 Loss:2.144
***[2020-01-29 09:30:15]*** VALID [epoch=430/600] loss = 2.143510, accuracy@1 = 39.90, accuracy@5 = 81.37 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:30:16]*** start epoch=431/600 Time Left: [01:29:52], LR=[0.018331 ~ 0.018331], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=431, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9982168620625024, FLOP=40.81
[Search] : epoch=431/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:30:16] [epoch=431/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.696 (0.696)  Prec@1 78.12 (78.12) Prec@5 98.05 (98.05) Acls-loss 0.646 (0.646) FLOP-Loss -2.910 (-2.910) Arch-Loss -5.174 (-5.174)
**TRAIN** [2020-01-29 09:30:42] [epoch=431/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.609 (0.642)  Prec@1 77.98 (78.41) Prec@5 100.00 (98.58) Acls-loss 0.598 (0.708) FLOP-Loss 2.911 (0.169) Arch-Loss 6.420 (1.046)
 **TRAIN** Prec@1 78.41 Prec@5 98.58 Error@1 21.59 Error@5 1.42 Base-Loss:0.642, Arch-Loss=1.046
***[2020-01-29 09:30:42]*** TRAIN [epoch=431/600] base-loss = 0.641645, arch-loss = 1.045515, accuracy-1 = 78.41, accuracy-5 = 98.58
[epoch=431/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.363 0.274 0.363  ||  0.1698 -0.1126 0.1689  || discrepancy=0.00 || select=0/3
001/003-th : 0.325 0.201 0.474  ||  0.0863 -0.3935 0.4627  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3450 -0.8825 2.9215  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.037 0.048 0.054 0.086 0.125 0.222 0.404  ||  -1.298 -0.826 -0.580 -0.463 0.011 0.383 0.955 1.555   || dis=0.18 || select=7/8
001/019-th : 0.103 0.133 0.141 0.138 0.133 0.123 0.122 0.107  ||  -0.184 0.075 0.133 0.113 0.078 -0.002 -0.009 -0.141   || dis=0.00 || select=2/8
002/019-th : 0.135 0.137 0.133 0.133 0.122 0.123 0.113 0.105  ||  0.073 0.092 0.060 0.062 -0.025 -0.018 -0.102 -0.171   || dis=0.00 || select=1/8
003/019-th : 0.101 0.114 0.125 0.129 0.131 0.133 0.133 0.134  ||  -0.202 -0.086 0.007 0.041 0.054 0.070 0.069 0.081     || dis=0.00 || select=7/8
004/019-th : 0.113 0.112 0.115 0.118 0.125 0.135 0.138 0.144  ||  -0.096 -0.104 -0.081 -0.052 -0.002 0.080 0.099 0.143  || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.125 0.128 0.125 0.132 0.126 0.132  ||  -0.147 -0.008 0.003 0.025 0.006 0.056 0.014 0.059     || dis=0.00 || select=7/8
006/019-th : 0.135 0.124 0.118 0.118 0.123 0.123 0.129 0.130  ||  0.078 -0.011 -0.056 -0.056 -0.017 -0.018 0.031 0.035  || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.049 0.063 0.098 0.127 0.198 0.414  ||  -1.382 -1.008 -0.511 -0.266 0.171 0.434 0.878 1.615   || dis=0.22 || select=7/8
008/019-th : 0.016 0.025 0.034 0.054 0.085 0.147 0.263 0.376  ||  -1.528 -1.102 -0.790 -0.331 0.131 0.676 1.258 1.615   || dis=0.11 || select=7/8
009/019-th : 0.079 0.086 0.104 0.104 0.128 0.143 0.164 0.192  ||  -0.417 -0.330 -0.147 -0.139 0.061 0.177 0.310 0.471   || dis=0.03 || select=7/8
010/019-th : 0.094 0.094 0.109 0.124 0.131 0.146 0.147 0.156  ||  -0.266 -0.272 -0.122 0.008 0.062 0.173 0.182 0.241    || dis=0.01 || select=7/8
011/019-th : 0.109 0.104 0.111 0.122 0.118 0.130 0.153 0.154  ||  -0.126 -0.173 -0.112 -0.014 -0.045 0.048 0.212 0.217  || dis=0.00 || select=7/8
012/019-th : 0.135 0.127 0.123 0.123 0.122 0.119 0.125 0.126  ||  0.078 0.012 -0.016 -0.021 -0.024 -0.053 -0.003 0.008  || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.010 0.013 0.017 0.027 0.060 0.855  ||  -1.234 -1.127 -0.968 -0.704 -0.436 -0.003 0.805 3.459  || dis=0.79 || select=7/8
014/019-th : 0.009 0.014 0.018 0.024 0.037 0.065 0.146 0.687  ||  -1.595 -1.166 -0.922 -0.653 -0.193 0.365 1.168 2.718  || dis=0.54 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.015 0.028 0.060 0.864  ||  -1.441 -1.194 -0.979 -0.742 -0.474 0.135 0.904 3.578  || dis=0.80 || select=7/8
016/019-th : 0.041 0.059 0.071 0.100 0.134 0.170 0.196 0.228  ||  -0.965 -0.614 -0.423 -0.082 0.212 0.449 0.589 0.743   || dis=0.03 || select=7/8
017/019-th : 0.082 0.100 0.106 0.127 0.132 0.145 0.151 0.159  ||  -0.397 -0.197 -0.140 0.042 0.083 0.174 0.217 0.267    || dis=0.01 || select=7/8
018/019-th : 0.091 0.105 0.124 0.138 0.131 0.132 0.134 0.145  ||  -0.304 -0.157 0.003 0.113 0.062 0.071 0.085 0.163     || dis=0.01 || select=7/8
[epoch=431/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.175
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:30:43] [epoch=431/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.077 (1.077)  Prec@1 65.23 (65.23) Prec@5 98.05 (98.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:30:49] [epoch=431/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.594 (2.171)  Prec@1 46.43 (40.20) Prec@5 84.52 (82.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.20 Prec@5 82.89 Error@1 59.80 Error@5 17.11 Loss:2.171
***[2020-01-29 09:30:49]*** VALID [epoch=431/600] loss = 2.171261, accuracy@1 = 40.20, accuracy@5 = 82.89 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:30:49]*** start epoch=432/600 Time Left: [01:29:21], LR=[0.018129 ~ 0.018129], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=432, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9883112251157101, FLOP=40.81
[Search] : epoch=432/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:30:50] [epoch=432/600][000/098] Time 0.67 (0.67) Data 0.36 (0.36) Base-Loss 0.563 (0.563)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.923 (0.923) FLOP-Loss -2.911 (-2.911) Arch-Loss -4.899 (-4.899)
**TRAIN** [2020-01-29 09:31:16] [epoch=432/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.592 (0.665)  Prec@1 82.14 (77.26) Prec@5 98.21 (98.48) Acls-loss 0.964 (0.727) FLOP-Loss 2.911 (0.169) Arch-Loss 6.787 (1.065)
 **TRAIN** Prec@1 77.26 Prec@5 98.48 Error@1 22.74 Error@5 1.52 Base-Loss:0.665, Arch-Loss=1.065
***[2020-01-29 09:31:16]*** TRAIN [epoch=432/600] base-loss = 0.664940, arch-loss = 1.064505, accuracy-1 = 77.26, accuracy-5 = 98.48
[epoch=432/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.452736)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.363 0.273 0.363  ||  0.1693 -0.1160 0.1693  || discrepancy=0.00 || select=0/3
001/003-th : 0.326 0.202 0.472  ||  0.0890 -0.3884 0.4595  || discrepancy=0.15 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3388 -0.8808 2.9165  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.037 0.047 0.054 0.086 0.124 0.224 0.405  ||  -1.302 -0.826 -0.592 -0.455 0.009 0.377 0.966 1.559   || dis=0.18 || select=7/8
001/019-th : 0.103 0.133 0.141 0.138 0.133 0.123 0.122 0.107  ||  -0.185 0.074 0.131 0.113 0.073 0.001 -0.007 -0.140    || dis=0.00 || select=2/8
002/019-th : 0.134 0.137 0.132 0.134 0.122 0.123 0.113 0.106  ||  0.073 0.089 0.057 0.070 -0.027 -0.016 -0.103 -0.168   || dis=0.00 || select=1/8
003/019-th : 0.102 0.113 0.126 0.129 0.129 0.133 0.133 0.135  ||  -0.198 -0.091 0.012 0.039 0.040 0.071 0.070 0.082     || dis=0.00 || select=7/8
004/019-th : 0.113 0.113 0.114 0.119 0.125 0.136 0.137 0.143  ||  -0.094 -0.101 -0.085 -0.042 -0.000 0.084 0.094 0.139  || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.125 0.127 0.126 0.131 0.126 0.132  ||  -0.147 -0.004 0.003 0.019 0.015 0.053 0.012 0.059     || dis=0.00 || select=7/8
006/019-th : 0.135 0.124 0.118 0.117 0.125 0.122 0.129 0.129  ||  0.077 -0.008 -0.054 -0.069 -0.000 -0.021 0.031 0.034  || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.049 0.063 0.096 0.126 0.200 0.414  ||  -1.378 -1.003 -0.510 -0.267 0.158 0.423 0.888 1.616   || dis=0.21 || select=7/8
008/019-th : 0.016 0.025 0.033 0.053 0.085 0.145 0.267 0.376  ||  -1.527 -1.111 -0.799 -0.337 0.129 0.668 1.279 1.618   || dis=0.11 || select=7/8
009/019-th : 0.079 0.087 0.104 0.105 0.127 0.143 0.164 0.192  ||  -0.416 -0.328 -0.142 -0.135 0.055 0.172 0.310 0.469   || dis=0.03 || select=7/8
010/019-th : 0.093 0.092 0.109 0.125 0.129 0.147 0.149 0.157  ||  -0.274 -0.284 -0.121 0.016 0.049 0.178 0.191 0.247    || dis=0.01 || select=7/8
011/019-th : 0.110 0.104 0.111 0.122 0.117 0.130 0.154 0.153  ||  -0.122 -0.174 -0.108 -0.015 -0.059 0.045 0.216 0.214  || dis=0.00 || select=6/8
012/019-th : 0.136 0.127 0.124 0.123 0.122 0.118 0.125 0.126  ||  0.085 0.013 -0.011 -0.021 -0.023 -0.063 -0.005 0.004  || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.010 0.013 0.017 0.026 0.059 0.859  ||  -1.220 -1.117 -0.967 -0.703 -0.442 -0.035 0.800 3.478  || dis=0.80 || select=7/8
014/019-th : 0.009 0.014 0.018 0.024 0.037 0.064 0.144 0.690  ||  -1.597 -1.171 -0.912 -0.640 -0.208 0.356 1.157 2.727  || dis=0.55 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.015 0.027 0.057 0.868  ||  -1.438 -1.209 -0.980 -0.741 -0.471 0.126 0.884 3.604  || dis=0.81 || select=7/8
016/019-th : 0.041 0.058 0.071 0.099 0.133 0.173 0.196 0.228  ||  -0.964 -0.618 -0.424 -0.086 0.202 0.470 0.594 0.742   || dis=0.03 || select=7/8
017/019-th : 0.081 0.100 0.105 0.127 0.133 0.145 0.151 0.158  ||  -0.400 -0.193 -0.141 0.041 0.088 0.176 0.220 0.264    || dis=0.01 || select=7/8
018/019-th : 0.091 0.105 0.123 0.137 0.131 0.133 0.134 0.145  ||  -0.299 -0.156 -0.002 0.107 0.063 0.073 0.087 0.160    || dis=0.01 || select=7/8
[epoch=432/600] FLOP : 24.45 MB, ratio : 0.5991, Expected-ratio : 0.7000, Discrepancy : 0.176
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:31:16] [epoch=432/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.554 (1.554)  Prec@1 58.20 (58.20) Prec@5 94.92 (94.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:31:22] [epoch=432/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.046 (2.535)  Prec@1 33.93 (39.23) Prec@5 78.57 (81.68) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.23 Prec@5 81.68 Error@1 60.77 Error@5 18.32 Loss:2.535
***[2020-01-29 09:31:22]*** VALID [epoch=432/600] loss = 2.534815, accuracy@1 = 39.23, accuracy@5 = 81.68 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:31:22]*** start epoch=433/600 Time Left: [01:28:50], LR=[0.017928 ~ 0.017928], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=433, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9784484026555632, FLOP=40.81
[Search] : epoch=433/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:31:23] [epoch=433/600][000/098] Time 0.67 (0.67) Data 0.36 (0.36) Base-Loss 0.602 (0.602)  Prec@1 80.86 (80.86) Prec@5 98.83 (98.83) Acls-loss 0.707 (0.707) FLOP-Loss -2.911 (-2.911) Arch-Loss -5.115 (-5.115)
**TRAIN** [2020-01-29 09:31:49] [epoch=433/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.536 (0.662)  Prec@1 83.33 (77.46) Prec@5 100.00 (98.42) Acls-loss 0.739 (0.728) FLOP-Loss -2.911 (0.189) Arch-Loss -5.083 (1.106)
 **TRAIN** Prec@1 77.46 Prec@5 98.42 Error@1 22.54 Error@5 1.58 Base-Loss:0.662, Arch-Loss=1.106
***[2020-01-29 09:31:49]*** TRAIN [epoch=433/600] base-loss = 0.662364, arch-loss = 1.106493, accuracy-1 = 77.46, accuracy-5 = 98.42
[epoch=433/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 16, 16, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 31.187584)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.364 0.272 0.364  ||  0.1693 -0.1232 0.1697  || discrepancy=0.00 || select=2/3
001/003-th : 0.326 0.202 0.471  ||  0.0901 -0.3872 0.4582  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.022 0.973  ||  -2.3362 -0.8791 2.9150  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.037 0.046 0.054 0.086 0.125 0.223 0.406  ||  -1.299 -0.828 -0.613 -0.461 0.011 0.386 0.968 1.565   || dis=0.18 || select=7/8
001/019-th : 0.103 0.133 0.141 0.138 0.131 0.123 0.123 0.108  ||  -0.181 0.073 0.130 0.113 0.059 -0.003 -0.008 -0.137   || dis=0.00 || select=2/8
002/019-th : 0.134 0.136 0.133 0.136 0.121 0.122 0.113 0.106  ||  0.071 0.090 0.060 0.084 -0.029 -0.021 -0.103 -0.168   || dis=0.00 || select=1/8
003/019-th : 0.102 0.114 0.126 0.129 0.129 0.133 0.133 0.134  ||  -0.200 -0.086 0.017 0.038 0.036 0.071 0.071 0.078     || dis=0.00 || select=7/8
004/019-th : 0.114 0.112 0.115 0.119 0.124 0.136 0.137 0.144  ||  -0.092 -0.110 -0.078 -0.042 -0.003 0.086 0.092 0.142  || dis=0.01 || select=7/8
005/019-th : 0.108 0.124 0.125 0.127 0.127 0.131 0.126 0.132  ||  -0.146 -0.001 0.002 0.018 0.016 0.053 0.012 0.056     || dis=0.00 || select=7/8
006/019-th : 0.135 0.125 0.118 0.117 0.125 0.123 0.129 0.129  ||  0.076 -0.004 -0.060 -0.070 -0.001 -0.015 0.029 0.034  || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.048 0.064 0.096 0.123 0.200 0.418  ||  -1.373 -1.013 -0.528 -0.253 0.155 0.401 0.890 1.627   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.033 0.053 0.084 0.144 0.268 0.377  ||  -1.518 -1.131 -0.802 -0.336 0.127 0.660 1.284 1.625   || dis=0.11 || select=7/8
009/019-th : 0.078 0.087 0.103 0.106 0.126 0.144 0.163 0.192  ||  -0.425 -0.322 -0.148 -0.122 0.051 0.181 0.309 0.469   || dis=0.03 || select=7/8
010/019-th : 0.094 0.093 0.109 0.125 0.129 0.145 0.149 0.156  ||  -0.269 -0.279 -0.118 0.019 0.048 0.169 0.194 0.239    || dis=0.01 || select=7/8
011/019-th : 0.110 0.105 0.111 0.123 0.116 0.130 0.153 0.153  ||  -0.122 -0.169 -0.112 -0.005 -0.068 0.051 0.210 0.215  || dis=0.00 || select=7/8
012/019-th : 0.137 0.127 0.124 0.123 0.121 0.117 0.124 0.126  ||  0.087 0.016 -0.009 -0.019 -0.034 -0.067 -0.009 0.005  || dis=0.01 || select=0/8
013/019-th : 0.008 0.009 0.010 0.013 0.017 0.025 0.058 0.860  ||  -1.212 -1.120 -0.970 -0.703 -0.457 -0.031 0.794 3.489  || dis=0.80 || select=7/8
014/019-th : 0.009 0.014 0.018 0.023 0.036 0.064 0.142 0.693  ||  -1.593 -1.174 -0.908 -0.651 -0.211 0.360 1.148 2.735  || dis=0.55 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.015 0.026 0.056 0.871  ||  -1.422 -1.203 -0.977 -0.744 -0.466 0.092 0.876 3.618  || dis=0.81 || select=7/8
016/019-th : 0.042 0.058 0.070 0.099 0.133 0.174 0.196 0.229  ||  -0.958 -0.622 -0.431 -0.091 0.202 0.471 0.593 0.746   || dis=0.03 || select=7/8
017/019-th : 0.081 0.101 0.106 0.126 0.133 0.145 0.152 0.157  ||  -0.408 -0.187 -0.135 0.037 0.093 0.176 0.226 0.259    || dis=0.01 || select=7/8
018/019-th : 0.092 0.105 0.123 0.138 0.130 0.133 0.134 0.145  ||  -0.292 -0.162 -0.003 0.114 0.053 0.072 0.086 0.160    || dis=0.01 || select=7/8
[epoch=433/600] FLOP : 31.19 MB, ratio : 0.7642, Expected-ratio : 0.7000, Discrepancy : 0.176
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:31:49] [epoch=433/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 2.472 (2.472)  Prec@1 33.98 (33.98) Prec@5 77.73 (77.73) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:31:56] [epoch=433/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.260 (2.370)  Prec@1 33.33 (39.01) Prec@5 79.76 (81.23) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.01 Prec@5 81.23 Error@1 60.99 Error@5 18.77 Loss:2.370
***[2020-01-29 09:31:56]*** VALID [epoch=433/600] loss = 2.369982, accuracy@1 = 39.01, accuracy@5 = 81.23 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:31:56]*** start epoch=434/600 Time Left: [01:28:18], LR=[0.017727 ~ 0.017727], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=434, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9686286650763207, FLOP=40.81
[Search] : epoch=434/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:31:57] [epoch=434/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.582 (0.582)  Prec@1 78.91 (78.91) Prec@5 99.61 (99.61) Acls-loss 0.617 (0.617) FLOP-Loss 2.912 (2.912) Arch-Loss 6.440 (6.440)
**TRAIN** [2020-01-29 09:32:23] [epoch=434/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.599 (0.698)  Prec@1 79.17 (76.21) Prec@5 98.81 (98.09) Acls-loss 0.741 (0.745) FLOP-Loss 2.910 (0.348) Arch-Loss 6.560 (1.440)
 **TRAIN** Prec@1 76.21 Prec@5 98.09 Error@1 23.79 Error@5 1.91 Base-Loss:0.698, Arch-Loss=1.440
***[2020-01-29 09:32:23]*** TRAIN [epoch=434/600] base-loss = 0.698212, arch-loss = 1.440125, accuracy-1 = 76.21, accuracy-5 = 98.09
[epoch=434/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.361 0.278 0.361  ||  0.1681 -0.0914 0.1679  || discrepancy=0.00 || select=0/3
001/003-th : 0.328 0.204 0.468  ||  0.0964 -0.3760 0.4512  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3326 -0.8594 2.9052  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.037 0.046 0.053 0.085 0.124 0.222 0.410  ||  -1.311 -0.818 -0.604 -0.464 0.001 0.383 0.961 1.576   || dis=0.19 || select=7/8
001/019-th : 0.104 0.133 0.142 0.140 0.129 0.121 0.122 0.107  ||  -0.171 0.076 0.140 0.128 0.044 -0.018 -0.015 -0.141   || dis=0.00 || select=2/8
002/019-th : 0.135 0.137 0.133 0.138 0.120 0.121 0.111 0.105  ||  0.078 0.095 0.063 0.102 -0.036 -0.027 -0.112 -0.172   || dis=0.00 || select=3/8
003/019-th : 0.102 0.114 0.128 0.128 0.128 0.135 0.132 0.133  ||  -0.197 -0.083 0.033 0.032 0.034 0.082 0.061 0.072     || dis=0.00 || select=5/8
004/019-th : 0.114 0.111 0.116 0.119 0.126 0.134 0.136 0.143  ||  -0.089 -0.111 -0.069 -0.041 0.009 0.076 0.089 0.138   || dis=0.01 || select=7/8
005/019-th : 0.109 0.124 0.125 0.128 0.125 0.133 0.125 0.130  ||  -0.134 -0.004 0.006 0.025 0.006 0.064 0.006 0.044     || dis=0.00 || select=5/8
006/019-th : 0.136 0.126 0.119 0.117 0.122 0.123 0.128 0.129  ||  0.083 0.003 -0.049 -0.066 -0.022 -0.022 0.021 0.031   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.048 0.064 0.094 0.124 0.200 0.419  ||  -1.371 -0.996 -0.538 -0.254 0.135 0.410 0.889 1.629   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.033 0.053 0.084 0.145 0.268 0.376  ||  -1.519 -1.135 -0.800 -0.332 0.123 0.673 1.284 1.622   || dis=0.11 || select=7/8
009/019-th : 0.078 0.087 0.104 0.108 0.128 0.142 0.162 0.191  ||  -0.426 -0.322 -0.143 -0.106 0.066 0.172 0.299 0.467   || dis=0.03 || select=7/8
010/019-th : 0.094 0.094 0.110 0.124 0.127 0.145 0.149 0.156  ||  -0.266 -0.267 -0.110 0.009 0.035 0.167 0.189 0.236    || dis=0.01 || select=7/8
011/019-th : 0.110 0.105 0.112 0.123 0.117 0.129 0.151 0.153  ||  -0.119 -0.166 -0.102 -0.003 -0.054 0.043 0.201 0.210  || dis=0.00 || select=7/8
012/019-th : 0.138 0.128 0.124 0.124 0.121 0.117 0.123 0.125  ||  0.095 0.024 -0.007 -0.010 -0.034 -0.071 -0.016 -0.004  || dis=0.01 || select=0/8
013/019-th : 0.008 0.008 0.010 0.012 0.017 0.025 0.056 0.863  ||  -1.198 -1.116 -0.975 -0.732 -0.448 -0.038 0.778 3.506  || dis=0.81 || select=7/8
014/019-th : 0.009 0.014 0.018 0.023 0.036 0.062 0.141 0.697  ||  -1.583 -1.191 -0.907 -0.666 -0.204 0.333 1.156 2.751  || dis=0.56 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.015 0.025 0.055 0.872  ||  -1.403 -1.196 -0.973 -0.749 -0.467 0.081 0.866 3.625  || dis=0.82 || select=7/8
016/019-th : 0.042 0.059 0.071 0.099 0.134 0.174 0.195 0.228  ||  -0.958 -0.614 -0.422 -0.089 0.209 0.470 0.584 0.741   || dis=0.03 || select=7/8
017/019-th : 0.081 0.100 0.107 0.126 0.132 0.144 0.152 0.156  ||  -0.402 -0.189 -0.127 0.041 0.084 0.174 0.227 0.253    || dis=0.00 || select=7/8
018/019-th : 0.093 0.106 0.124 0.139 0.130 0.132 0.133 0.143  ||  -0.280 -0.153 0.002 0.120 0.054 0.071 0.072 0.151     || dis=0.00 || select=7/8
[epoch=434/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.177
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:32:23] [epoch=434/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 3.151 (3.151)  Prec@1 41.41 (41.41) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:32:29] [epoch=434/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.588 (2.263)  Prec@1 18.45 (42.52) Prec@5 66.07 (83.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.52 Prec@5 83.10 Error@1 57.48 Error@5 16.90 Loss:2.263
***[2020-01-29 09:32:29]*** VALID [epoch=434/600] loss = 2.262976, accuracy@1 = 42.52, accuracy@5 = 83.10 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:32:29]*** start epoch=435/600 Time Left: [01:27:47], LR=[0.017528 ~ 0.017528], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=435, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9588522815910504, FLOP=40.81
[Search] : epoch=435/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:32:30] [epoch=435/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.614 (0.614)  Prec@1 79.69 (79.69) Prec@5 100.00 (100.00) Acls-loss 0.735 (0.735) FLOP-Loss -2.910 (-2.910) Arch-Loss -5.084 (-5.084)
**TRAIN** [2020-01-29 09:32:56] [epoch=435/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.671 (0.658)  Prec@1 77.98 (77.64) Prec@5 97.62 (98.52) Acls-loss 0.840 (0.715) FLOP-Loss -2.909 (0.249) Arch-Loss -4.977 (1.212)
 **TRAIN** Prec@1 77.64 Prec@5 98.52 Error@1 22.36 Error@5 1.48 Base-Loss:0.658, Arch-Loss=1.212
***[2020-01-29 09:32:56]*** TRAIN [epoch=435/600] base-loss = 0.658109, arch-loss = 1.212300, accuracy-1 = 77.64, accuracy-5 = 98.52
[epoch=435/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.276 0.362  ||  0.1684 -0.1037 0.1683  || discrepancy=0.00 || select=0/3
001/003-th : 0.328 0.206 0.465  ||  0.0985 -0.3645 0.4482  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.022 0.972  ||  -2.3342 -0.8607 2.9086  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.038 0.046 0.053 0.084 0.123 0.222 0.410  ||  -1.304 -0.802 -0.605 -0.470 -0.005 0.374 0.959 1.575  || dis=0.19 || select=7/8
001/019-th : 0.105 0.134 0.143 0.140 0.129 0.122 0.121 0.107  ||  -0.167 0.078 0.144 0.127 0.046 -0.016 -0.019 -0.147   || dis=0.00 || select=2/8
002/019-th : 0.135 0.138 0.134 0.138 0.119 0.121 0.111 0.104  ||  0.079 0.099 0.070 0.106 -0.042 -0.027 -0.114 -0.178   || dis=0.00 || select=3/8
003/019-th : 0.102 0.114 0.129 0.129 0.128 0.135 0.131 0.133  ||  -0.195 -0.084 0.040 0.041 0.033 0.087 0.053 0.068     || dis=0.00 || select=5/8
004/019-th : 0.114 0.111 0.116 0.118 0.127 0.135 0.136 0.143  ||  -0.089 -0.113 -0.068 -0.053 0.024 0.079 0.089 0.138   || dis=0.01 || select=7/8
005/019-th : 0.109 0.124 0.126 0.129 0.125 0.131 0.125 0.130  ||  -0.134 -0.001 0.014 0.036 0.001 0.052 0.005 0.044     || dis=0.00 || select=5/8
006/019-th : 0.136 0.126 0.119 0.118 0.123 0.122 0.128 0.129  ||  0.084 0.006 -0.051 -0.060 -0.019 -0.027 0.022 0.028   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.046 0.064 0.094 0.125 0.200 0.420  ||  -1.371 -0.994 -0.569 -0.250 0.133 0.422 0.895 1.634   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.033 0.054 0.084 0.144 0.267 0.377  ||  -1.510 -1.129 -0.804 -0.324 0.121 0.661 1.275 1.621   || dis=0.11 || select=7/8
009/019-th : 0.079 0.088 0.104 0.108 0.127 0.142 0.161 0.191  ||  -0.421 -0.314 -0.139 -0.102 0.058 0.166 0.294 0.462   || dis=0.03 || select=7/8
010/019-th : 0.095 0.096 0.110 0.123 0.127 0.145 0.149 0.155  ||  -0.256 -0.254 -0.118 -0.000 0.028 0.160 0.188 0.231   || dis=0.01 || select=7/8
011/019-th : 0.110 0.105 0.113 0.124 0.118 0.129 0.150 0.152  ||  -0.114 -0.163 -0.093 -0.001 -0.050 0.040 0.192 0.205  || dis=0.00 || select=7/8
012/019-th : 0.139 0.129 0.125 0.123 0.122 0.116 0.123 0.124  ||  0.101 0.027 -0.004 -0.017 -0.026 -0.079 -0.020 -0.008  || dis=0.01 || select=0/8
013/019-th : 0.008 0.008 0.010 0.012 0.016 0.024 0.055 0.867  ||  -1.204 -1.102 -0.967 -0.753 -0.451 -0.043 0.764 3.525  || dis=0.81 || select=7/8
014/019-th : 0.009 0.014 0.018 0.023 0.036 0.061 0.139 0.701  ||  -1.575 -1.185 -0.918 -0.666 -0.209 0.326 1.146 2.762  || dis=0.56 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.014 0.024 0.053 0.876  ||  -1.411 -1.199 -0.963 -0.748 -0.484 0.069 0.853 3.649  || dis=0.82 || select=7/8
016/019-th : 0.042 0.059 0.072 0.100 0.135 0.169 0.193 0.229  ||  -0.946 -0.613 -0.416 -0.082 0.218 0.441 0.571 0.743   || dis=0.04 || select=7/8
017/019-th : 0.082 0.100 0.108 0.127 0.131 0.143 0.152 0.157  ||  -0.395 -0.191 -0.117 0.046 0.073 0.163 0.221 0.254    || dis=0.01 || select=7/8
018/019-th : 0.094 0.106 0.123 0.139 0.131 0.131 0.132 0.143  ||  -0.273 -0.148 -0.000 0.122 0.060 0.059 0.064 0.150    || dis=0.00 || select=7/8
[epoch=435/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.178
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:32:56] [epoch=435/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.284 (2.284)  Prec@1 18.75 (18.75) Prec@5 64.45 (64.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:33:03] [epoch=435/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.216 (2.207)  Prec@1 61.31 (42.37) Prec@5 93.45 (84.15) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.37 Prec@5 84.15 Error@1 57.63 Error@5 15.85 Loss:2.207
***[2020-01-29 09:33:03]*** VALID [epoch=435/600] loss = 2.206810, accuracy@1 = 42.37, accuracy@5 = 84.15 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:33:03]*** start epoch=436/600 Time Left: [01:27:16], LR=[0.017329 ~ 0.017329], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=436, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9491195202242416, FLOP=40.81
[Search] : epoch=436/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:33:04] [epoch=436/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.610 (0.610)  Prec@1 78.91 (78.91) Prec@5 99.22 (99.22) Acls-loss 0.661 (0.661) FLOP-Loss -2.909 (-2.909) Arch-Loss -5.157 (-5.157)
**TRAIN** [2020-01-29 09:33:30] [epoch=436/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 0.562 (0.671)  Prec@1 82.74 (77.08) Prec@5 98.81 (98.40) Acls-loss 0.610 (0.733) FLOP-Loss 2.908 (0.288) Arch-Loss 6.427 (1.308)
 **TRAIN** Prec@1 77.08 Prec@5 98.40 Error@1 22.92 Error@5 1.60 Base-Loss:0.671, Arch-Loss=1.308
***[2020-01-29 09:33:30]*** TRAIN [epoch=436/600] base-loss = 0.671168, arch-loss = 1.308258, accuracy-1 = 77.08, accuracy-5 = 98.40
[epoch=436/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 25.100928)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.363 0.274 0.363  ||  0.1693 -0.1120 0.1678  || discrepancy=0.00 || select=0/3
001/003-th : 0.330 0.204 0.465  ||  0.1026 -0.3774 0.4450  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.023 0.972  ||  -2.3250 -0.8466 2.8960  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.038 0.047 0.054 0.083 0.122 0.222 0.411  ||  -1.310 -0.802 -0.590 -0.459 -0.025 0.364 0.963 1.579  || dis=0.19 || select=7/8
001/019-th : 0.104 0.135 0.143 0.141 0.129 0.122 0.120 0.106  ||  -0.172 0.088 0.148 0.131 0.048 -0.010 -0.027 -0.151   || dis=0.00 || select=2/8
002/019-th : 0.135 0.138 0.134 0.139 0.119 0.120 0.111 0.104  ||  0.083 0.102 0.071 0.107 -0.042 -0.036 -0.115 -0.180   || dis=0.00 || select=3/8
003/019-th : 0.102 0.114 0.129 0.132 0.128 0.134 0.130 0.132  ||  -0.196 -0.084 0.043 0.065 0.034 0.082 0.048 0.065     || dis=0.00 || select=5/8
004/019-th : 0.115 0.112 0.116 0.117 0.128 0.134 0.136 0.142  ||  -0.083 -0.107 -0.070 -0.060 0.026 0.076 0.090 0.132   || dis=0.01 || select=7/8
005/019-th : 0.110 0.124 0.126 0.130 0.126 0.131 0.125 0.129  ||  -0.125 -0.006 0.016 0.039 0.009 0.047 0.001 0.039     || dis=0.00 || select=5/8
006/019-th : 0.137 0.126 0.119 0.116 0.123 0.122 0.129 0.128  ||  0.091 0.003 -0.051 -0.075 -0.019 -0.025 0.029 0.022   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.047 0.063 0.093 0.126 0.198 0.422  ||  -1.367 -1.011 -0.557 -0.255 0.129 0.428 0.883 1.640   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.033 0.054 0.084 0.144 0.267 0.377  ||  -1.519 -1.121 -0.817 -0.320 0.124 0.663 1.279 1.624   || dis=0.11 || select=7/8
009/019-th : 0.078 0.088 0.105 0.110 0.129 0.139 0.162 0.190  ||  -0.426 -0.314 -0.134 -0.090 0.075 0.151 0.298 0.458   || dis=0.03 || select=7/8
010/019-th : 0.096 0.097 0.110 0.126 0.126 0.144 0.149 0.155  ||  -0.254 -0.245 -0.117 0.017 0.018 0.152 0.185 0.226    || dis=0.01 || select=7/8
011/019-th : 0.111 0.106 0.113 0.124 0.119 0.128 0.149 0.151  ||  -0.110 -0.153 -0.093 -0.001 -0.039 0.037 0.185 0.198  || dis=0.00 || select=7/8
012/019-th : 0.139 0.129 0.124 0.124 0.122 0.117 0.122 0.124  ||  0.102 0.030 -0.010 -0.012 -0.023 -0.068 -0.024 -0.012  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.012 0.016 0.024 0.053 0.870  ||  -1.228 -1.098 -0.971 -0.742 -0.448 -0.060 0.753 3.550  || dis=0.82 || select=7/8
014/019-th : 0.009 0.013 0.018 0.022 0.035 0.061 0.140 0.702  ||  -1.563 -1.194 -0.920 -0.682 -0.228 0.326 1.159 2.770  || dis=0.56 || select=7/8
015/019-th : 0.006 0.007 0.008 0.011 0.014 0.024 0.052 0.880  ||  -1.398 -1.188 -0.973 -0.743 -0.505 0.064 0.833 3.670  || dis=0.83 || select=7/8
016/019-th : 0.043 0.058 0.072 0.101 0.136 0.168 0.192 0.229  ||  -0.935 -0.626 -0.410 -0.072 0.219 0.433 0.566 0.742   || dis=0.04 || select=7/8
017/019-th : 0.082 0.100 0.109 0.126 0.131 0.144 0.151 0.157  ||  -0.394 -0.195 -0.109 0.038 0.078 0.166 0.215 0.255    || dis=0.01 || select=7/8
018/019-th : 0.095 0.108 0.124 0.139 0.129 0.131 0.132 0.143  ||  -0.265 -0.138 -0.000 0.118 0.039 0.055 0.064 0.146    || dis=0.00 || select=7/8
[epoch=436/600] FLOP : 25.10 MB, ratio : 0.6150, Expected-ratio : 0.7000, Discrepancy : 0.178
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:33:30] [epoch=436/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.955 (1.955)  Prec@1 28.12 (28.12) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:33:36] [epoch=436/600][097/098] Time 0.13 (0.07) Data 0.00 (0.00) Loss 3.157 (2.138)  Prec@1 28.57 (42.52) Prec@5 77.98 (83.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.52 Prec@5 83.78 Error@1 57.48 Error@5 16.22 Loss:2.138
***[2020-01-29 09:33:37]*** VALID [epoch=436/600] loss = 2.138280, accuracy@1 = 42.52, accuracy@5 = 83.78 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:33:37]*** start epoch=437/600 Time Left: [01:26:44], LR=[0.017131 ~ 0.017131], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=437, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9394306478044651, FLOP=40.81
[Search] : epoch=437/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:33:37] [epoch=437/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.987 (0.987)  Prec@1 66.41 (66.41) Prec@5 94.92 (94.92) Acls-loss 0.671 (0.671) FLOP-Loss -2.908 (-2.908) Arch-Loss -5.145 (-5.145)
**TRAIN** [2020-01-29 09:34:03] [epoch=437/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.746 (0.644)  Prec@1 74.40 (77.97) Prec@5 98.81 (98.55) Acls-loss 0.622 (0.718) FLOP-Loss 2.909 (0.169) Arch-Loss 6.439 (1.055)
 **TRAIN** Prec@1 77.97 Prec@5 98.55 Error@1 22.03 Error@5 1.45 Base-Loss:0.644, Arch-Loss=1.055
***[2020-01-29 09:34:03]*** TRAIN [epoch=437/600] base-loss = 0.643590, arch-loss = 1.054876, accuracy-1 = 77.97, accuracy-5 = 98.55
[epoch=437/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 29.7376)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.362 0.275 0.362  ||  0.1682 -0.1073 0.1682  || discrepancy=0.00 || select=2/3
001/003-th : 0.330 0.206 0.464  ||  0.1023 -0.3684 0.4444  || discrepancy=0.13 || select=2/3
002/003-th : 0.005 0.023 0.971  ||  -2.3269 -0.8337 2.8937  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.038 0.047 0.054 0.083 0.121 0.221 0.412  ||  -1.304 -0.798 -0.589 -0.448 -0.028 0.356 0.955 1.579  || dis=0.19 || select=7/8
001/019-th : 0.104 0.134 0.144 0.141 0.129 0.122 0.121 0.106  ||  -0.171 0.080 0.151 0.130 0.041 -0.009 -0.023 -0.148   || dis=0.00 || select=2/8
002/019-th : 0.135 0.138 0.134 0.139 0.120 0.120 0.110 0.104  ||  0.083 0.104 0.077 0.108 -0.036 -0.039 -0.119 -0.181   || dis=0.00 || select=3/8
003/019-th : 0.102 0.114 0.129 0.133 0.128 0.134 0.130 0.131  ||  -0.193 -0.083 0.039 0.069 0.034 0.078 0.052 0.061     || dis=0.00 || select=5/8
004/019-th : 0.115 0.112 0.117 0.116 0.127 0.134 0.137 0.143  ||  -0.083 -0.109 -0.067 -0.076 0.022 0.072 0.094 0.136   || dis=0.01 || select=7/8
005/019-th : 0.110 0.124 0.126 0.131 0.128 0.130 0.124 0.128  ||  -0.125 -0.002 0.015 0.051 0.032 0.042 -0.005 0.033    || dis=0.00 || select=3/8
006/019-th : 0.138 0.126 0.117 0.117 0.123 0.122 0.129 0.128  ||  0.095 0.005 -0.066 -0.073 -0.018 -0.028 0.026 0.024   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.046 0.064 0.094 0.126 0.198 0.421  ||  -1.366 -1.014 -0.570 -0.247 0.137 0.433 0.883 1.639   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.033 0.053 0.084 0.144 0.265 0.381  ||  -1.519 -1.137 -0.812 -0.328 0.124 0.665 1.273 1.636   || dis=0.12 || select=7/8
009/019-th : 0.078 0.088 0.104 0.110 0.130 0.140 0.161 0.189  ||  -0.425 -0.312 -0.139 -0.087 0.081 0.157 0.295 0.455   || dis=0.03 || select=7/8
010/019-th : 0.096 0.097 0.109 0.125 0.127 0.143 0.149 0.155  ||  -0.250 -0.245 -0.122 0.011 0.024 0.144 0.188 0.227    || dis=0.01 || select=7/8
011/019-th : 0.111 0.106 0.113 0.123 0.119 0.130 0.148 0.150  ||  -0.109 -0.153 -0.086 -0.007 -0.037 0.048 0.182 0.194  || dis=0.00 || select=7/8
012/019-th : 0.139 0.129 0.124 0.122 0.124 0.117 0.122 0.123  ||  0.104 0.033 -0.013 -0.021 -0.012 -0.066 -0.027 -0.015  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.010 0.012 0.016 0.023 0.053 0.871  ||  -1.236 -1.090 -0.958 -0.743 -0.447 -0.068 0.750 3.553  || dis=0.82 || select=7/8
014/019-th : 0.009 0.013 0.018 0.022 0.035 0.060 0.140 0.703  ||  -1.557 -1.191 -0.912 -0.693 -0.236 0.318 1.163 2.774  || dis=0.56 || select=7/8
015/019-th : 0.005 0.007 0.008 0.011 0.013 0.024 0.051 0.881  ||  -1.399 -1.183 -0.966 -0.743 -0.503 0.061 0.820 3.677  || dis=0.83 || select=7/8
016/019-th : 0.043 0.058 0.071 0.102 0.134 0.169 0.193 0.230  ||  -0.940 -0.628 -0.422 -0.064 0.208 0.438 0.572 0.747   || dis=0.04 || select=7/8
017/019-th : 0.082 0.100 0.109 0.128 0.131 0.142 0.151 0.157  ||  -0.392 -0.191 -0.112 0.047 0.073 0.156 0.217 0.253    || dis=0.01 || select=7/8
018/019-th : 0.094 0.107 0.124 0.138 0.129 0.131 0.132 0.145  ||  -0.271 -0.149 0.003 0.112 0.039 0.060 0.064 0.156     || dis=0.01 || select=7/8
[epoch=437/600] FLOP : 29.74 MB, ratio : 0.7286, Expected-ratio : 0.7000, Discrepancy : 0.179
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:34:03] [epoch=437/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.022 (1.022)  Prec@1 67.97 (67.97) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:34:10] [epoch=437/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.941 (2.379)  Prec@1 23.21 (39.11) Prec@5 74.40 (81.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.11 Prec@5 81.62 Error@1 60.89 Error@5 18.38 Loss:2.379
***[2020-01-29 09:34:10]*** VALID [epoch=437/600] loss = 2.378754, accuracy@1 = 39.11, accuracy@5 = 81.62 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:34:10]*** start epoch=438/600 Time Left: [01:26:13], LR=[0.016934 ~ 0.016934], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=438, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9297859299570533, FLOP=40.81
[Search] : epoch=438/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:34:10] [epoch=438/600][000/098] Time 0.67 (0.67) Data 0.38 (0.38) Base-Loss 0.532 (0.532)  Prec@1 81.64 (81.64) Prec@5 99.61 (99.61) Acls-loss 0.597 (0.597) FLOP-Loss 2.908 (2.908) Arch-Loss 6.414 (6.414)
**TRAIN** [2020-01-29 09:34:36] [epoch=438/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.577 (0.651)  Prec@1 80.95 (77.79) Prec@5 98.81 (98.59) Acls-loss 1.356 (0.707) FLOP-Loss 2.907 (0.347) Arch-Loss 7.170 (1.401)
 **TRAIN** Prec@1 77.79 Prec@5 98.59 Error@1 22.21 Error@5 1.41 Base-Loss:0.651, Arch-Loss=1.401
***[2020-01-29 09:34:36]*** TRAIN [epoch=438/600] base-loss = 0.650957, arch-loss = 1.401469, accuracy-1 = 77.79, accuracy-5 = 98.59
[epoch=438/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 9, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.360 0.279 0.360  ||  0.1673 -0.0866 0.1671  || discrepancy=0.00 || select=0/3
001/003-th : 0.333 0.205 0.462  ||  0.1104 -0.3752 0.4369  || discrepancy=0.13 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3354 -0.8200 2.8975  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.039 0.048 0.054 0.082 0.121 0.218 0.415  ||  -1.298 -0.786 -0.576 -0.452 -0.038 0.353 0.938 1.582  || dis=0.20 || select=7/8
001/019-th : 0.104 0.135 0.145 0.142 0.128 0.121 0.119 0.106  ||  -0.168 0.089 0.161 0.139 0.039 -0.017 -0.033 -0.154   || dis=0.00 || select=2/8
002/019-th : 0.136 0.139 0.136 0.138 0.120 0.119 0.110 0.103  ||  0.088 0.112 0.088 0.107 -0.038 -0.046 -0.123 -0.190   || dis=0.00 || select=1/8
003/019-th : 0.103 0.114 0.128 0.134 0.128 0.134 0.129 0.131  ||  -0.187 -0.077 0.037 0.078 0.035 0.078 0.043 0.055     || dis=0.00 || select=3/8
004/019-th : 0.115 0.112 0.117 0.115 0.128 0.135 0.136 0.142  ||  -0.078 -0.107 -0.064 -0.079 0.024 0.078 0.089 0.131   || dis=0.01 || select=7/8
005/019-th : 0.110 0.125 0.126 0.131 0.127 0.130 0.123 0.127  ||  -0.118 0.010 0.014 0.049 0.024 0.047 -0.010 0.022     || dis=0.00 || select=3/8
006/019-th : 0.139 0.127 0.118 0.117 0.123 0.121 0.128 0.128  ||  0.103 0.010 -0.063 -0.070 -0.020 -0.038 0.020 0.020   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.046 0.064 0.094 0.128 0.197 0.422  ||  -1.364 -1.010 -0.578 -0.253 0.137 0.445 0.877 1.640   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.032 0.054 0.085 0.144 0.264 0.381  ||  -1.519 -1.143 -0.827 -0.322 0.136 0.663 1.274 1.640   || dis=0.12 || select=7/8
009/019-th : 0.078 0.088 0.105 0.109 0.132 0.140 0.160 0.188  ||  -0.424 -0.307 -0.132 -0.092 0.096 0.155 0.290 0.450   || dis=0.03 || select=7/8
010/019-th : 0.097 0.097 0.110 0.123 0.127 0.142 0.149 0.154  ||  -0.245 -0.239 -0.118 -0.002 0.030 0.142 0.190 0.221   || dis=0.01 || select=7/8
011/019-th : 0.112 0.107 0.114 0.123 0.118 0.129 0.148 0.149  ||  -0.102 -0.146 -0.085 -0.003 -0.045 0.039 0.181 0.187  || dis=0.00 || select=7/8
012/019-th : 0.140 0.130 0.124 0.124 0.122 0.116 0.122 0.122  ||  0.110 0.039 -0.011 -0.011 -0.021 -0.071 -0.028 -0.022  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.012 0.016 0.023 0.052 0.873  ||  -1.223 -1.088 -0.978 -0.748 -0.447 -0.070 0.742 3.568  || dis=0.82 || select=7/8
014/019-th : 0.009 0.013 0.017 0.022 0.035 0.059 0.138 0.707  ||  -1.547 -1.208 -0.926 -0.681 -0.231 0.304 1.154 2.787  || dis=0.57 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.013 0.024 0.052 0.879  ||  -1.384 -1.186 -0.954 -0.737 -0.511 0.052 0.834 3.666  || dis=0.83 || select=7/8
016/019-th : 0.043 0.058 0.071 0.102 0.136 0.166 0.194 0.230  ||  -0.928 -0.631 -0.423 -0.065 0.217 0.421 0.576 0.744   || dis=0.04 || select=7/8
017/019-th : 0.083 0.101 0.109 0.128 0.132 0.141 0.150 0.156  ||  -0.388 -0.183 -0.108 0.051 0.079 0.148 0.212 0.246    || dis=0.01 || select=7/8
018/019-th : 0.094 0.107 0.123 0.139 0.130 0.131 0.132 0.144  ||  -0.274 -0.142 -0.004 0.118 0.050 0.060 0.064 0.151    || dis=0.00 || select=7/8
[epoch=438/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.179
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:34:37] [epoch=438/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.594 (1.594)  Prec@1 44.53 (44.53) Prec@5 82.81 (82.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:34:43] [epoch=438/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.577 (2.309)  Prec@1 44.05 (43.32) Prec@5 88.69 (83.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.32 Prec@5 83.18 Error@1 56.68 Error@5 16.82 Loss:2.309
***[2020-01-29 09:34:43]*** VALID [epoch=438/600] loss = 2.309455, accuracy@1 = 43.32, accuracy@5 = 83.18 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:34:43]*** start epoch=439/600 Time Left: [01:25:41], LR=[0.016738 ~ 0.016738], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=439, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9201856310968162, FLOP=40.81
[Search] : epoch=439/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:34:44] [epoch=439/600][000/098] Time 0.69 (0.69) Data 0.35 (0.35) Base-Loss 0.897 (0.897)  Prec@1 78.91 (78.91) Prec@5 98.05 (98.05) Acls-loss 0.626 (0.626) FLOP-Loss -2.907 (-2.907) Arch-Loss -5.187 (-5.187)
**TRAIN** [2020-01-29 09:35:10] [epoch=439/600][097/098] Time 0.33 (0.27) Data 0.00 (0.00) Base-Loss 0.749 (0.619)  Prec@1 73.21 (78.91) Prec@5 97.02 (98.77) Acls-loss 0.809 (0.704) FLOP-Loss -2.906 (0.219) Arch-Loss -5.002 (1.141)
 **TRAIN** Prec@1 78.91 Prec@5 98.77 Error@1 21.09 Error@5 1.23 Base-Loss:0.619, Arch-Loss=1.141
***[2020-01-29 09:35:10]*** TRAIN [epoch=439/600] base-loss = 0.619397, arch-loss = 1.141379, accuracy-1 = 78.91, accuracy-5 = 98.77
[epoch=439/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 29.639296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.360 0.279 0.360  ||  0.1669 -0.0870 0.1673  || discrepancy=0.00 || select=2/3
001/003-th : 0.334 0.205 0.461  ||  0.1115 -0.3738 0.4356  || discrepancy=0.13 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3276 -0.8079 2.8870  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.039 0.048 0.054 0.083 0.123 0.214 0.416  ||  -1.298 -0.786 -0.571 -0.457 -0.033 0.363 0.920 1.584  || dis=0.20 || select=7/8
001/019-th : 0.105 0.135 0.145 0.142 0.127 0.121 0.119 0.105  ||  -0.166 0.092 0.163 0.139 0.030 -0.017 -0.034 -0.157   || dis=0.00 || select=2/8
002/019-th : 0.136 0.140 0.135 0.139 0.119 0.119 0.111 0.103  ||  0.090 0.115 0.082 0.108 -0.046 -0.048 -0.117 -0.193   || dis=0.00 || select=1/8
003/019-th : 0.103 0.115 0.128 0.133 0.129 0.133 0.129 0.130  ||  -0.182 -0.076 0.037 0.071 0.039 0.076 0.041 0.053     || dis=0.00 || select=5/8
004/019-th : 0.115 0.112 0.115 0.115 0.129 0.135 0.137 0.142  ||  -0.077 -0.105 -0.078 -0.079 0.031 0.078 0.093 0.129   || dis=0.00 || select=7/8
005/019-th : 0.111 0.125 0.125 0.129 0.129 0.130 0.122 0.127  ||  -0.112 0.010 0.010 0.041 0.036 0.048 -0.017 0.021     || dis=0.00 || select=5/8
006/019-th : 0.140 0.127 0.118 0.118 0.122 0.120 0.128 0.128  ||  0.107 0.013 -0.060 -0.060 -0.032 -0.047 0.017 0.019   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.046 0.064 0.094 0.126 0.199 0.420  ||  -1.363 -1.017 -0.580 -0.242 0.142 0.437 0.890 1.636   || dis=0.22 || select=7/8
008/019-th : 0.016 0.024 0.032 0.054 0.085 0.144 0.262 0.382  ||  -1.510 -1.143 -0.830 -0.323 0.140 0.663 1.263 1.640   || dis=0.12 || select=7/8
009/019-th : 0.079 0.089 0.105 0.111 0.131 0.140 0.158 0.187  ||  -0.417 -0.301 -0.129 -0.079 0.087 0.155 0.278 0.445   || dis=0.03 || select=7/8
010/019-th : 0.097 0.098 0.110 0.124 0.126 0.143 0.150 0.153  ||  -0.244 -0.233 -0.115 0.002 0.016 0.146 0.193 0.214    || dis=0.00 || select=7/8
011/019-th : 0.112 0.107 0.114 0.123 0.119 0.128 0.148 0.149  ||  -0.097 -0.148 -0.082 -0.003 -0.040 0.038 0.177 0.184  || dis=0.00 || select=7/8
012/019-th : 0.140 0.131 0.124 0.124 0.122 0.116 0.121 0.122  ||  0.114 0.043 -0.009 -0.010 -0.023 -0.078 -0.029 -0.026  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.012 0.015 0.023 0.050 0.876  ||  -1.220 -1.099 -0.973 -0.743 -0.464 -0.069 0.723 3.589  || dis=0.83 || select=7/8
014/019-th : 0.009 0.013 0.017 0.022 0.034 0.058 0.138 0.710  ||  -1.555 -1.219 -0.930 -0.688 -0.240 0.297 1.168 2.803  || dis=0.57 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.014 0.024 0.052 0.878  ||  -1.373 -1.182 -0.951 -0.734 -0.501 0.053 0.827 3.659  || dis=0.83 || select=7/8
016/019-th : 0.043 0.057 0.070 0.102 0.138 0.168 0.194 0.228  ||  -0.930 -0.638 -0.436 -0.060 0.240 0.437 0.578 0.740   || dis=0.03 || select=7/8
017/019-th : 0.083 0.102 0.109 0.128 0.132 0.141 0.150 0.155  ||  -0.384 -0.177 -0.108 0.054 0.082 0.145 0.206 0.242    || dis=0.01 || select=7/8
018/019-th : 0.095 0.108 0.124 0.139 0.128 0.131 0.132 0.144  ||  -0.268 -0.137 -0.002 0.119 0.033 0.054 0.063 0.150    || dis=0.00 || select=7/8
[epoch=439/600] FLOP : 29.64 MB, ratio : 0.7262, Expected-ratio : 0.7000, Discrepancy : 0.179
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:35:10] [epoch=439/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.543 (1.543)  Prec@1 39.84 (39.84) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:35:16] [epoch=439/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.362 (2.566)  Prec@1 51.19 (41.30) Prec@5 91.07 (82.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.30 Prec@5 82.31 Error@1 58.70 Error@5 17.69 Loss:2.566
***[2020-01-29 09:35:17]*** VALID [epoch=439/600] loss = 2.565558, accuracy@1 = 41.30, accuracy@5 = 82.31 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:35:17]*** start epoch=440/600 Time Left: [01:25:10], LR=[0.016543 ~ 0.016543], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=440, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9106300144207982, FLOP=40.81
[Search] : epoch=440/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:35:17] [epoch=440/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.407 (0.407)  Prec@1 87.11 (87.11) Prec@5 99.22 (99.22) Acls-loss 0.806 (0.806) FLOP-Loss 2.906 (2.906) Arch-Loss 6.617 (6.617)
**TRAIN** [2020-01-29 09:35:43] [epoch=440/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.604 (0.636)  Prec@1 79.76 (78.26) Prec@5 97.62 (98.62) Acls-loss 1.043 (0.701) FLOP-Loss 2.906 (0.228) Arch-Loss 6.855 (1.157)
 **TRAIN** Prec@1 78.26 Prec@5 98.62 Error@1 21.74 Error@5 1.38 Base-Loss:0.636, Arch-Loss=1.157
***[2020-01-29 09:35:43]*** TRAIN [epoch=440/600] base-loss = 0.636420, arch-loss = 1.157312, accuracy-1 = 78.26, accuracy-5 = 98.62
[epoch=440/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 9, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 29.03104)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.361 0.279 0.361  ||  0.1670 -0.0895 0.1670  || discrepancy=0.00 || select=2/3
001/003-th : 0.333 0.207 0.460  ||  0.1115 -0.3634 0.4346  || discrepancy=0.13 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3305 -0.8127 2.8928  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.024 0.039 0.048 0.053 0.082 0.120 0.213 0.421  ||  -1.284 -0.782 -0.575 -0.468 -0.036 0.343 0.912 1.595  || dis=0.21 || select=7/8
001/019-th : 0.105 0.136 0.145 0.141 0.127 0.121 0.119 0.105  ||  -0.165 0.097 0.162 0.136 0.031 -0.019 -0.036 -0.159   || dis=0.00 || select=2/8
002/019-th : 0.137 0.140 0.136 0.138 0.119 0.117 0.111 0.102  ||  0.093 0.116 0.089 0.105 -0.041 -0.058 -0.118 -0.196   || dis=0.00 || select=1/8
003/019-th : 0.104 0.114 0.128 0.134 0.128 0.133 0.129 0.131  ||  -0.178 -0.079 0.034 0.076 0.033 0.069 0.038 0.056     || dis=0.00 || select=3/8
004/019-th : 0.115 0.113 0.116 0.115 0.128 0.135 0.137 0.141  ||  -0.078 -0.100 -0.074 -0.083 0.027 0.081 0.098 0.124   || dis=0.00 || select=7/8
005/019-th : 0.112 0.126 0.126 0.129 0.128 0.130 0.122 0.127  ||  -0.109 0.011 0.009 0.038 0.026 0.042 -0.016 0.023     || dis=0.00 || select=5/8
006/019-th : 0.140 0.127 0.118 0.119 0.121 0.120 0.128 0.128  ||  0.110 0.009 -0.061 -0.057 -0.035 -0.042 0.017 0.017   || dis=0.01 || select=0/8
007/019-th : 0.021 0.030 0.045 0.063 0.094 0.124 0.201 0.421  ||  -1.358 -1.012 -0.586 -0.262 0.145 0.422 0.902 1.641   || dis=0.22 || select=7/8
008/019-th : 0.017 0.024 0.033 0.054 0.084 0.143 0.262 0.384  ||  -1.498 -1.145 -0.820 -0.325 0.123 0.651 1.259 1.643   || dis=0.12 || select=7/8
009/019-th : 0.080 0.089 0.106 0.110 0.129 0.140 0.158 0.188  ||  -0.411 -0.296 -0.129 -0.084 0.072 0.154 0.271 0.448   || dis=0.03 || select=7/8
010/019-th : 0.097 0.098 0.111 0.124 0.125 0.142 0.149 0.153  ||  -0.241 -0.229 -0.110 -0.000 0.011 0.137 0.189 0.215   || dis=0.00 || select=7/8
011/019-th : 0.113 0.107 0.114 0.124 0.119 0.128 0.148 0.149  ||  -0.093 -0.149 -0.082 0.001 -0.040 0.030 0.176 0.184   || dis=0.00 || select=7/8
012/019-th : 0.141 0.131 0.124 0.124 0.122 0.115 0.121 0.122  ||  0.117 0.047 -0.013 -0.009 -0.024 -0.081 -0.032 -0.028  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.015 0.022 0.049 0.878  ||  -1.221 -1.096 -0.969 -0.759 -0.455 -0.072 0.713 3.599  || dis=0.83 || select=7/8
014/019-th : 0.009 0.013 0.017 0.021 0.033 0.057 0.138 0.712  ||  -1.545 -1.224 -0.934 -0.694 -0.246 0.285 1.170 2.814  || dis=0.57 || select=7/8
015/019-th : 0.006 0.007 0.009 0.011 0.014 0.024 0.051 0.879  ||  -1.357 -1.171 -0.940 -0.744 -0.498 0.053 0.810 3.662  || dis=0.83 || select=7/8
016/019-th : 0.043 0.058 0.069 0.101 0.138 0.169 0.195 0.227  ||  -0.926 -0.633 -0.450 -0.073 0.245 0.445 0.589 0.738   || dis=0.03 || select=7/8
017/019-th : 0.083 0.101 0.109 0.129 0.132 0.141 0.149 0.155  ||  -0.380 -0.183 -0.108 0.059 0.082 0.149 0.205 0.240    || dis=0.01 || select=7/8
018/019-th : 0.094 0.108 0.124 0.139 0.130 0.130 0.131 0.144  ||  -0.271 -0.137 0.000 0.118 0.050 0.050 0.059 0.152     || dis=0.00 || select=7/8
[epoch=440/600] FLOP : 29.03 MB, ratio : 0.7113, Expected-ratio : 0.7000, Discrepancy : 0.180
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:35:43] [epoch=440/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 6.449 (6.449)  Prec@1 15.23 (15.23) Prec@5 63.28 (63.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:35:50] [epoch=440/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.091 (2.519)  Prec@1 29.76 (38.80) Prec@5 76.19 (82.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.80 Prec@5 82.42 Error@1 61.20 Error@5 17.58 Loss:2.519
***[2020-01-29 09:35:50]*** VALID [epoch=440/600] loss = 2.519030, accuracy@1 = 38.80, accuracy@5 = 82.42 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:35:50]*** start epoch=441/600 Time Left: [01:24:39], LR=[0.016349 ~ 0.016349], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=441, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.9011193419010559, FLOP=40.81
[Search] : epoch=441/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:35:51] [epoch=441/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.699 (0.699)  Prec@1 72.66 (72.66) Prec@5 99.61 (99.61) Acls-loss 0.552 (0.552) FLOP-Loss 2.906 (2.906) Arch-Loss 6.364 (6.364)
**TRAIN** [2020-01-29 09:36:16] [epoch=441/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.596 (0.621)  Prec@1 80.36 (78.70) Prec@5 98.81 (98.74) Acls-loss 0.658 (0.688) FLOP-Loss 0.000 (0.149) Arch-Loss 0.658 (0.986)
 **TRAIN** Prec@1 78.70 Prec@5 98.74 Error@1 21.30 Error@5 1.26 Base-Loss:0.621, Arch-Loss=0.986
***[2020-01-29 09:36:16]*** TRAIN [epoch=441/600] base-loss = 0.620555, arch-loss = 0.986123, accuracy-1 = 78.70, accuracy-5 = 98.74
[epoch=441/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 9, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.47808)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.361 0.278 0.361  ||  0.1659 -0.0938 0.1682  || discrepancy=0.00 || select=2/3
001/003-th : 0.334 0.206 0.460  ||  0.1136 -0.3719 0.4330  || discrepancy=0.13 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3285 -0.8152 2.8933  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.024 0.039 0.048 0.052 0.082 0.119 0.212 0.424  ||  -1.281 -0.772 -0.577 -0.489 -0.039 0.332 0.912 1.605  || dis=0.21 || select=7/8
001/019-th : 0.104 0.136 0.145 0.143 0.127 0.121 0.119 0.105  ||  -0.169 0.097 0.162 0.148 0.028 -0.019 -0.036 -0.157   || dis=0.00 || select=2/8
002/019-th : 0.136 0.139 0.137 0.138 0.120 0.117 0.111 0.102  ||  0.090 0.114 0.094 0.106 -0.035 -0.059 -0.118 -0.194   || dis=0.00 || select=1/8
003/019-th : 0.103 0.114 0.127 0.134 0.128 0.133 0.129 0.131  ||  -0.183 -0.078 0.025 0.083 0.036 0.073 0.038 0.059     || dis=0.00 || select=3/8
004/019-th : 0.116 0.113 0.115 0.116 0.127 0.134 0.139 0.141  ||  -0.077 -0.099 -0.080 -0.076 0.014 0.071 0.105 0.125   || dis=0.00 || select=7/8
005/019-th : 0.112 0.126 0.126 0.129 0.127 0.129 0.123 0.127  ||  -0.108 0.010 0.012 0.037 0.019 0.035 -0.012 0.023     || dis=0.00 || select=3/8
006/019-th : 0.140 0.126 0.119 0.119 0.119 0.121 0.128 0.128  ||  0.111 0.007 -0.057 -0.051 -0.051 -0.039 0.020 0.016   || dis=0.01 || select=0/8
007/019-th : 0.021 0.029 0.044 0.062 0.094 0.122 0.200 0.427  ||  -1.359 -1.015 -0.602 -0.269 0.142 0.410 0.903 1.660   || dis=0.23 || select=7/8
008/019-th : 0.017 0.023 0.032 0.053 0.084 0.143 0.264 0.384  ||  -1.488 -1.158 -0.836 -0.330 0.121 0.659 1.270 1.646   || dis=0.12 || select=7/8
009/019-th : 0.079 0.090 0.106 0.110 0.128 0.139 0.160 0.188  ||  -0.417 -0.293 -0.128 -0.086 0.065 0.142 0.283 0.449   || dis=0.03 || select=7/8
010/019-th : 0.097 0.099 0.110 0.125 0.125 0.142 0.150 0.153  ||  -0.239 -0.226 -0.120 0.008 0.008 0.136 0.191 0.213    || dis=0.00 || select=7/8
011/019-th : 0.112 0.107 0.115 0.125 0.118 0.128 0.147 0.148  ||  -0.098 -0.145 -0.076 0.007 -0.043 0.031 0.176 0.182   || dis=0.00 || select=7/8
012/019-th : 0.141 0.132 0.124 0.124 0.122 0.115 0.120 0.122  ||  0.117 0.051 -0.009 -0.007 -0.024 -0.081 -0.038 -0.028  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.015 0.022 0.048 0.878  ||  -1.214 -1.090 -0.966 -0.752 -0.453 -0.076 0.700 3.599  || dis=0.83 || select=7/8
014/019-th : 0.009 0.012 0.017 0.021 0.033 0.057 0.133 0.719  ||  -1.530 -1.222 -0.931 -0.709 -0.253 0.290 1.141 2.831  || dis=0.59 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.013 0.023 0.049 0.883  ||  -1.339 -1.160 -0.962 -0.750 -0.521 0.052 0.797 3.686  || dis=0.83 || select=7/8
016/019-th : 0.042 0.057 0.069 0.101 0.140 0.170 0.196 0.226  ||  -0.935 -0.642 -0.455 -0.070 0.256 0.452 0.596 0.738   || dis=0.03 || select=7/8
017/019-th : 0.082 0.101 0.108 0.130 0.133 0.142 0.150 0.154  ||  -0.389 -0.183 -0.116 0.068 0.094 0.157 0.209 0.240    || dis=0.00 || select=7/8
018/019-th : 0.094 0.107 0.122 0.140 0.132 0.129 0.131 0.144  ||  -0.268 -0.143 -0.010 0.125 0.067 0.046 0.062 0.151    || dis=0.00 || select=7/8
[epoch=441/600] FLOP : 28.48 MB, ratio : 0.6978, Expected-ratio : 0.7000, Discrepancy : 0.181
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:36:17] [epoch=441/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 3.159 (3.159)  Prec@1 22.66 (22.66) Prec@5 64.84 (64.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:36:23] [epoch=441/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.126 (2.262)  Prec@1 14.29 (39.00) Prec@5 59.52 (82.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.00 Prec@5 82.10 Error@1 61.00 Error@5 17.90 Loss:2.262
***[2020-01-29 09:36:23]*** VALID [epoch=441/600] loss = 2.261867, accuracy@1 = 39.00, accuracy@5 = 82.10 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:36:23]*** start epoch=442/600 Time Left: [01:24:07], LR=[0.016156 ~ 0.016156], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=442, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8916538742774816, FLOP=40.81
[Search] : epoch=442/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:36:24] [epoch=442/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.589 (0.589)  Prec@1 78.12 (78.12) Prec@5 98.83 (98.83) Acls-loss 0.992 (0.992) FLOP-Loss 0.000 (0.000) Arch-Loss 0.992 (0.992)
**TRAIN** [2020-01-29 09:36:50] [epoch=442/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.584 (0.661)  Prec@1 79.76 (77.36) Prec@5 99.40 (98.58) Acls-loss 0.712 (0.714) FLOP-Loss 2.906 (0.317) Arch-Loss 6.525 (1.349)
 **TRAIN** Prec@1 77.36 Prec@5 98.58 Error@1 22.64 Error@5 1.42 Base-Loss:0.661, Arch-Loss=1.349
***[2020-01-29 09:36:50]*** TRAIN [epoch=442/600] base-loss = 0.660625, arch-loss = 1.348745, accuracy-1 = 77.36, accuracy-5 = 98.58
[epoch=442/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 9, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.360 0.280 0.360  ||  0.1668 -0.0836 0.1660  || discrepancy=0.00 || select=0/3
001/003-th : 0.333 0.210 0.456  ||  0.1150 -0.3452 0.4295  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3215 -0.8162 2.8889  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.039 0.048 0.052 0.081 0.114 0.212 0.431  ||  -1.293 -0.782 -0.573 -0.493 -0.040 0.299 0.920 1.626  || dis=0.22 || select=7/8
001/019-th : 0.104 0.136 0.145 0.142 0.128 0.121 0.119 0.105  ||  -0.166 0.096 0.163 0.144 0.034 -0.021 -0.038 -0.159   || dis=0.00 || select=2/8
002/019-th : 0.136 0.139 0.138 0.138 0.120 0.116 0.110 0.102  ||  0.094 0.114 0.105 0.108 -0.036 -0.065 -0.119 -0.200   || dis=0.00 || select=1/8
003/019-th : 0.103 0.115 0.127 0.136 0.128 0.133 0.128 0.130  ||  -0.180 -0.072 0.023 0.095 0.031 0.076 0.035 0.052     || dis=0.00 || select=3/8
004/019-th : 0.116 0.113 0.117 0.115 0.127 0.134 0.137 0.141  ||  -0.076 -0.098 -0.068 -0.076 0.018 0.076 0.095 0.123   || dis=0.00 || select=7/8
005/019-th : 0.113 0.126 0.127 0.129 0.127 0.129 0.122 0.127  ||  -0.101 0.012 0.018 0.037 0.017 0.038 -0.018 0.015     || dis=0.00 || select=5/8
006/019-th : 0.141 0.127 0.119 0.120 0.118 0.121 0.127 0.127  ||  0.115 0.008 -0.052 -0.046 -0.064 -0.034 0.012 0.015   || dis=0.01 || select=0/8
007/019-th : 0.020 0.030 0.045 0.062 0.093 0.121 0.204 0.426  ||  -1.402 -1.002 -0.580 -0.271 0.139 0.403 0.930 1.663   || dis=0.22 || select=7/8
008/019-th : 0.017 0.023 0.032 0.054 0.082 0.143 0.264 0.385  ||  -1.484 -1.153 -0.843 -0.319 0.106 0.657 1.271 1.647   || dis=0.12 || select=7/8
009/019-th : 0.080 0.090 0.107 0.111 0.129 0.137 0.158 0.188  ||  -0.405 -0.291 -0.121 -0.081 0.068 0.133 0.272 0.443   || dis=0.03 || select=7/8
010/019-th : 0.097 0.099 0.110 0.125 0.125 0.142 0.149 0.153  ||  -0.239 -0.224 -0.118 0.012 0.008 0.136 0.187 0.212    || dis=0.00 || select=7/8
011/019-th : 0.113 0.108 0.115 0.126 0.118 0.127 0.147 0.147  ||  -0.092 -0.137 -0.071 0.016 -0.045 0.023 0.170 0.174   || dis=0.00 || select=7/8
012/019-th : 0.141 0.132 0.124 0.124 0.122 0.115 0.120 0.121  ||  0.121 0.055 -0.008 -0.006 -0.026 -0.081 -0.043 -0.032  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.015 0.022 0.049 0.878  ||  -1.208 -1.084 -0.975 -0.765 -0.454 -0.071 0.705 3.601  || dis=0.83 || select=7/8
014/019-th : 0.009 0.012 0.016 0.021 0.032 0.056 0.133 0.720  ||  -1.524 -1.217 -0.952 -0.716 -0.277 0.294 1.155 2.840  || dis=0.59 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.013 0.023 0.049 0.884  ||  -1.325 -1.152 -0.957 -0.748 -0.527 0.026 0.797 3.693  || dis=0.83 || select=7/8
016/019-th : 0.043 0.056 0.068 0.101 0.140 0.171 0.196 0.224  ||  -0.927 -0.648 -0.455 -0.063 0.259 0.458 0.597 0.732   || dis=0.03 || select=7/8
017/019-th : 0.082 0.101 0.109 0.131 0.133 0.141 0.148 0.153  ||  -0.388 -0.184 -0.103 0.079 0.095 0.154 0.199 0.236    || dis=0.01 || select=7/8
018/019-th : 0.094 0.108 0.123 0.140 0.135 0.127 0.130 0.142  ||  -0.270 -0.136 -0.002 0.130 0.095 0.034 0.053 0.144    || dis=0.00 || select=7/8
[epoch=442/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.181
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:36:50] [epoch=442/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.588 (1.588)  Prec@1 42.58 (42.58) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:36:57] [epoch=442/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.035 (2.386)  Prec@1 52.38 (40.66) Prec@5 91.67 (82.67) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.66 Prec@5 82.67 Error@1 59.34 Error@5 17.33 Loss:2.386
***[2020-01-29 09:36:57]*** VALID [epoch=442/600] loss = 2.386051, accuracy@1 = 40.66, accuracy@5 = 82.67 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:36:57]*** start epoch=443/600 Time Left: [01:23:36], LR=[0.015964 ~ 0.015964], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=443, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8822338710506514, FLOP=40.81
[Search] : epoch=443/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:36:58] [epoch=443/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.522 (0.522)  Prec@1 81.64 (81.64) Prec@5 100.00 (100.00) Acls-loss 0.703 (0.703) FLOP-Loss -2.906 (-2.906) Arch-Loss -5.109 (-5.109)
**TRAIN** [2020-01-29 09:37:23] [epoch=443/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.592 (0.606)  Prec@1 79.76 (79.20) Prec@5 100.00 (98.84) Acls-loss 0.794 (0.703) FLOP-Loss 0.000 (0.179) Arch-Loss 0.794 (1.060)
 **TRAIN** Prec@1 79.20 Prec@5 98.84 Error@1 20.80 Error@5 1.16 Base-Loss:0.606, Arch-Loss=1.060
***[2020-01-29 09:37:23]*** TRAIN [epoch=443/600] base-loss = 0.606450, arch-loss = 1.060158, accuracy-1 = 79.20, accuracy-5 = 98.84
[epoch=443/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 9, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 29.59936)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.359 0.281 0.360  ||  0.1652 -0.0807 0.1670  || discrepancy=0.00 || select=2/3
001/003-th : 0.334 0.210 0.456  ||  0.1173 -0.3457 0.4271  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3215 -0.8068 2.8861  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.038 0.047 0.051 0.082 0.117 0.209 0.434  ||  -1.306 -0.793 -0.583 -0.509 -0.027 0.326 0.911 1.639  || dis=0.23 || select=7/8
001/019-th : 0.105 0.135 0.146 0.144 0.127 0.121 0.118 0.105  ||  -0.163 0.092 0.168 0.155 0.030 -0.021 -0.042 -0.160   || dis=0.00 || select=2/8
002/019-th : 0.136 0.139 0.138 0.139 0.120 0.116 0.110 0.102  ||  0.092 0.116 0.104 0.116 -0.032 -0.070 -0.118 -0.199   || dis=0.00 || select=3/8
003/019-th : 0.104 0.115 0.127 0.136 0.126 0.135 0.128 0.130  ||  -0.175 -0.072 0.022 0.092 0.019 0.084 0.035 0.047     || dis=0.00 || select=3/8
004/019-th : 0.115 0.113 0.116 0.114 0.128 0.137 0.137 0.140  ||  -0.078 -0.095 -0.070 -0.089 0.028 0.093 0.093 0.120   || dis=0.00 || select=7/8
005/019-th : 0.113 0.126 0.127 0.129 0.126 0.129 0.122 0.126  ||  -0.095 0.014 0.021 0.036 0.010 0.036 -0.019 0.011     || dis=0.00 || select=5/8
006/019-th : 0.141 0.127 0.118 0.120 0.119 0.121 0.126 0.127  ||  0.119 0.009 -0.060 -0.044 -0.055 -0.033 0.008 0.014   || dis=0.01 || select=0/8
007/019-th : 0.019 0.029 0.045 0.061 0.093 0.119 0.203 0.430  ||  -1.423 -1.016 -0.572 -0.277 0.147 0.399 0.930 1.681   || dis=0.23 || select=7/8
008/019-th : 0.017 0.023 0.032 0.054 0.082 0.142 0.266 0.384  ||  -1.488 -1.158 -0.836 -0.308 0.098 0.652 1.279 1.646   || dis=0.12 || select=7/8
009/019-th : 0.080 0.089 0.107 0.111 0.128 0.139 0.158 0.189  ||  -0.403 -0.306 -0.119 -0.079 0.058 0.141 0.272 0.449   || dis=0.03 || select=7/8
010/019-th : 0.097 0.099 0.110 0.123 0.125 0.142 0.150 0.153  ||  -0.240 -0.225 -0.118 -0.004 0.011 0.138 0.191 0.215   || dis=0.00 || select=7/8
011/019-th : 0.113 0.107 0.114 0.126 0.118 0.127 0.147 0.148  ||  -0.090 -0.144 -0.078 0.015 -0.047 0.027 0.172 0.178   || dis=0.00 || select=7/8
012/019-th : 0.141 0.132 0.125 0.124 0.123 0.115 0.119 0.121  ||  0.121 0.056 -0.002 -0.008 -0.019 -0.081 -0.045 -0.034  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.015 0.022 0.047 0.882  ||  -1.194 -1.104 -0.967 -0.777 -0.460 -0.072 0.690 3.622  || dis=0.83 || select=7/8
014/019-th : 0.009 0.012 0.016 0.020 0.031 0.056 0.133 0.722  ||  -1.513 -1.212 -0.955 -0.721 -0.303 0.289 1.158 2.851  || dis=0.59 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.013 0.022 0.047 0.887  ||  -1.307 -1.142 -0.967 -0.746 -0.525 0.006 0.781 3.710  || dis=0.84 || select=7/8
016/019-th : 0.043 0.056 0.069 0.101 0.139 0.170 0.198 0.225  ||  -0.927 -0.652 -0.454 -0.062 0.252 0.452 0.607 0.732   || dis=0.03 || select=7/8
017/019-th : 0.083 0.101 0.110 0.131 0.132 0.142 0.148 0.153  ||  -0.383 -0.183 -0.102 0.077 0.084 0.156 0.201 0.232    || dis=0.01 || select=7/8
018/019-th : 0.094 0.107 0.123 0.141 0.137 0.128 0.129 0.142  ||  -0.270 -0.139 -0.004 0.135 0.106 0.039 0.048 0.144    || dis=0.00 || select=7/8
[epoch=443/600] FLOP : 29.60 MB, ratio : 0.7252, Expected-ratio : 0.7000, Discrepancy : 0.182
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:37:24] [epoch=443/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.707 (2.707)  Prec@1 13.67 (13.67) Prec@5 62.89 (62.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:37:30] [epoch=443/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.163 (2.547)  Prec@1 60.71 (39.81) Prec@5 94.64 (81.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.81 Prec@5 81.89 Error@1 60.19 Error@5 18.11 Loss:2.547
***[2020-01-29 09:37:30]*** VALID [epoch=443/600] loss = 2.546766, accuracy@1 = 39.81, accuracy@5 = 81.89 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:37:30]*** start epoch=444/600 Time Left: [01:23:04], LR=[0.015773 ~ 0.015773], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=444, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8728595904747126, FLOP=40.81
[Search] : epoch=444/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:37:31] [epoch=444/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 0.676 (0.676)  Prec@1 77.73 (77.73) Prec@5 98.83 (98.83) Acls-loss 0.555 (0.555) FLOP-Loss 2.907 (2.907) Arch-Loss 6.369 (6.369)
**TRAIN** [2020-01-29 09:37:57] [epoch=444/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.761 (0.615)  Prec@1 72.62 (78.95) Prec@5 98.81 (98.69) Acls-loss 0.665 (0.681) FLOP-Loss -2.906 (0.278) Arch-Loss -5.147 (1.237)
 **TRAIN** Prec@1 78.95 Prec@5 98.69 Error@1 21.05 Error@5 1.31 Base-Loss:0.615, Arch-Loss=1.237
***[2020-01-29 09:37:57]*** TRAIN [epoch=444/600] base-loss = 0.615411, arch-loss = 1.237426, accuracy-1 = 78.95, accuracy-5 = 98.69
[epoch=444/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 9, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.243324)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.357 0.285 0.357  ||  0.1650 -0.0603 0.1651  || discrepancy=0.00 || select=2/3
001/003-th : 0.334 0.213 0.453  ||  0.1198 -0.3297 0.4233  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.024 0.970  ||  -2.3146 -0.8015 2.8789  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.038 0.047 0.050 0.081 0.117 0.211 0.432  ||  -1.302 -0.799 -0.583 -0.513 -0.031 0.333 0.921 1.637  || dis=0.22 || select=7/8
001/019-th : 0.104 0.136 0.146 0.143 0.128 0.120 0.118 0.105  ||  -0.168 0.098 0.172 0.153 0.036 -0.027 -0.040 -0.162   || dis=0.00 || select=2/8
002/019-th : 0.135 0.140 0.139 0.140 0.120 0.115 0.110 0.101  ||  0.087 0.123 0.113 0.124 -0.027 -0.076 -0.123 -0.199   || dis=0.00 || select=3/8
003/019-th : 0.104 0.115 0.126 0.137 0.127 0.135 0.127 0.129  ||  -0.174 -0.071 0.021 0.102 0.025 0.086 0.031 0.044     || dis=0.00 || select=3/8
004/019-th : 0.115 0.113 0.116 0.115 0.130 0.136 0.137 0.140  ||  -0.080 -0.098 -0.073 -0.080 0.046 0.092 0.094 0.117   || dis=0.00 || select=7/8
005/019-th : 0.114 0.127 0.128 0.130 0.128 0.128 0.121 0.125  ||  -0.090 0.023 0.026 0.040 0.029 0.027 -0.030 0.002     || dis=0.00 || select=3/8
006/019-th : 0.142 0.127 0.119 0.120 0.119 0.121 0.125 0.126  ||  0.125 0.013 -0.050 -0.044 -0.053 -0.032 0.001 0.005   || dis=0.01 || select=0/8
007/019-th : 0.019 0.029 0.044 0.060 0.092 0.119 0.204 0.432  ||  -1.417 -1.020 -0.585 -0.286 0.137 0.398 0.939 1.688   || dis=0.23 || select=7/8
008/019-th : 0.016 0.023 0.032 0.053 0.082 0.143 0.264 0.386  ||  -1.508 -1.146 -0.835 -0.324 0.106 0.658 1.274 1.655   || dis=0.12 || select=7/8
009/019-th : 0.081 0.089 0.106 0.110 0.129 0.138 0.158 0.189  ||  -0.397 -0.298 -0.132 -0.094 0.066 0.136 0.272 0.451   || dis=0.03 || select=7/8
010/019-th : 0.097 0.099 0.110 0.125 0.126 0.139 0.149 0.153  ||  -0.243 -0.219 -0.113 0.013 0.021 0.118 0.189 0.212    || dis=0.00 || select=7/8
011/019-th : 0.114 0.107 0.114 0.126 0.118 0.127 0.147 0.147  ||  -0.082 -0.144 -0.083 0.019 -0.049 0.029 0.171 0.171   || dis=0.00 || select=7/8
012/019-th : 0.142 0.132 0.126 0.124 0.121 0.115 0.120 0.121  ||  0.125 0.057 0.005 -0.007 -0.031 -0.087 -0.045 -0.036  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.015 0.021 0.045 0.885  ||  -1.204 -1.106 -0.957 -0.774 -0.460 -0.078 0.666 3.642  || dis=0.84 || select=7/8
014/019-th : 0.009 0.012 0.016 0.020 0.031 0.055 0.132 0.724  ||  -1.510 -1.223 -0.946 -0.723 -0.303 0.286 1.154 2.857  || dis=0.59 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.013 0.021 0.046 0.888  ||  -1.291 -1.143 -0.966 -0.741 -0.524 -0.007 0.767 3.720  || dis=0.84 || select=7/8
016/019-th : 0.042 0.056 0.069 0.101 0.137 0.172 0.197 0.225  ||  -0.939 -0.659 -0.449 -0.062 0.244 0.468 0.605 0.738   || dis=0.03 || select=7/8
017/019-th : 0.083 0.102 0.110 0.131 0.131 0.142 0.149 0.153  ||  -0.381 -0.179 -0.095 0.073 0.074 0.153 0.203 0.229    || dis=0.00 || select=7/8
018/019-th : 0.094 0.107 0.123 0.142 0.136 0.127 0.128 0.142  ||  -0.268 -0.139 -0.001 0.147 0.100 0.029 0.042 0.145    || dis=0.00 || select=3/8
[epoch=444/600] FLOP : 28.24 MB, ratio : 0.6920, Expected-ratio : 0.7000, Discrepancy : 0.182
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:37:57] [epoch=444/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.060 (2.060)  Prec@1 51.56 (51.56) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:38:03] [epoch=444/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.688 (2.501)  Prec@1 25.00 (39.49) Prec@5 70.24 (82.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.49 Prec@5 82.04 Error@1 60.51 Error@5 17.96 Loss:2.501
***[2020-01-29 09:38:03]*** VALID [epoch=444/600] loss = 2.500656, accuracy@1 = 39.49, accuracy@5 = 82.04 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:38:03]*** start epoch=445/600 Time Left: [01:22:33], LR=[0.015582 ~ 0.015582], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=445, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8635312895503024, FLOP=40.81
[Search] : epoch=445/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:38:04] [epoch=445/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.687 (0.687)  Prec@1 77.34 (77.34) Prec@5 98.83 (98.83) Acls-loss 0.968 (0.968) FLOP-Loss 0.000 (0.000) Arch-Loss 0.968 (0.968)
**TRAIN** [2020-01-29 09:38:29] [epoch=445/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.573 (0.627)  Prec@1 81.55 (78.60) Prec@5 98.21 (98.66) Acls-loss 0.809 (0.688) FLOP-Loss 0.000 (0.119) Arch-Loss 0.809 (0.927)
 **TRAIN** Prec@1 78.60 Prec@5 98.66 Error@1 21.40 Error@5 1.34 Base-Loss:0.627, Arch-Loss=0.927
***[2020-01-29 09:38:29]*** TRAIN [epoch=445/600] base-loss = 0.627385, arch-loss = 0.926804, accuracy-1 = 78.60, accuracy-5 = 98.66
[epoch=445/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 9, 16, 12, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.227964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.354 0.290 0.356  ||  0.1619 -0.0386 0.1658  || discrepancy=0.00 || select=2/3
001/003-th : 0.333 0.213 0.453  ||  0.1179 -0.3291 0.4249  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.024 0.970  ||  -2.3061 -0.8085 2.8759  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.037 0.047 0.049 0.081 0.117 0.209 0.437  ||  -1.293 -0.812 -0.579 -0.545 -0.034 0.334 0.915 1.653  || dis=0.23 || select=7/8
001/019-th : 0.104 0.135 0.146 0.143 0.128 0.121 0.119 0.105  ||  -0.171 0.093 0.173 0.148 0.038 -0.018 -0.034 -0.163   || dis=0.00 || select=2/8
002/019-th : 0.135 0.140 0.139 0.138 0.121 0.115 0.110 0.102  ||  0.086 0.120 0.112 0.103 -0.026 -0.077 -0.119 -0.194   || dis=0.00 || select=1/8
003/019-th : 0.103 0.115 0.125 0.136 0.128 0.135 0.128 0.130  ||  -0.185 -0.072 0.013 0.097 0.037 0.089 0.034 0.052     || dis=0.00 || select=3/8
004/019-th : 0.114 0.113 0.116 0.113 0.131 0.136 0.137 0.140  ||  -0.083 -0.097 -0.069 -0.092 0.052 0.091 0.098 0.116   || dis=0.00 || select=7/8
005/019-th : 0.114 0.128 0.127 0.128 0.128 0.129 0.121 0.125  ||  -0.087 0.023 0.021 0.027 0.028 0.031 -0.029 0.003     || dis=0.00 || select=5/8
006/019-th : 0.142 0.127 0.118 0.120 0.119 0.122 0.126 0.126  ||  0.124 0.016 -0.058 -0.044 -0.052 -0.027 0.004 0.003   || dis=0.01 || select=0/8
007/019-th : 0.019 0.029 0.044 0.059 0.092 0.117 0.205 0.435  ||  -1.417 -1.027 -0.589 -0.298 0.145 0.387 0.944 1.697   || dis=0.23 || select=7/8
008/019-th : 0.016 0.023 0.032 0.053 0.081 0.139 0.270 0.387  ||  -1.503 -1.164 -0.834 -0.327 0.093 0.636 1.303 1.663   || dis=0.12 || select=7/8
009/019-th : 0.079 0.090 0.105 0.110 0.128 0.138 0.159 0.190  ||  -0.417 -0.291 -0.134 -0.088 0.060 0.138 0.276 0.459   || dis=0.03 || select=7/8
010/019-th : 0.097 0.100 0.109 0.124 0.127 0.139 0.152 0.153  ||  -0.242 -0.215 -0.128 0.002 0.023 0.115 0.206 0.212    || dis=0.00 || select=7/8
011/019-th : 0.114 0.107 0.113 0.124 0.119 0.128 0.147 0.147  ||  -0.084 -0.143 -0.089 0.002 -0.040 0.033 0.172 0.175   || dis=0.00 || select=7/8
012/019-th : 0.141 0.131 0.126 0.124 0.121 0.115 0.120 0.121  ||  0.120 0.050 0.011 -0.012 -0.031 -0.081 -0.040 -0.034  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.014 0.021 0.045 0.885  ||  -1.194 -1.096 -0.946 -0.779 -0.470 -0.100 0.672 3.645  || dis=0.84 || select=7/8
014/019-th : 0.009 0.012 0.016 0.020 0.030 0.054 0.131 0.728  ||  -1.497 -1.217 -0.956 -0.726 -0.318 0.268 1.157 2.871  || dis=0.60 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.013 0.021 0.046 0.890  ||  -1.322 -1.132 -0.977 -0.743 -0.520 -0.008 0.766 3.733  || dis=0.84 || select=7/8
016/019-th : 0.042 0.056 0.069 0.100 0.138 0.173 0.198 0.225  ||  -0.949 -0.660 -0.448 -0.070 0.247 0.475 0.613 0.739   || dis=0.03 || select=7/8
017/019-th : 0.083 0.102 0.110 0.130 0.130 0.143 0.150 0.153  ||  -0.379 -0.181 -0.104 0.066 0.068 0.158 0.206 0.231    || dis=0.00 || select=7/8
018/019-th : 0.094 0.107 0.124 0.142 0.136 0.127 0.128 0.142  ||  -0.270 -0.140 0.006 0.146 0.097 0.030 0.042 0.145     || dis=0.00 || select=3/8
[epoch=445/600] FLOP : 28.23 MB, ratio : 0.6916, Expected-ratio : 0.7000, Discrepancy : 0.183
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:38:30] [epoch=445/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.519 (2.519)  Prec@1 32.42 (32.42) Prec@5 76.56 (76.56) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:38:36] [epoch=445/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.120 (2.404)  Prec@1 63.10 (38.42) Prec@5 90.48 (80.82) Size=[168, 3, 32, 32]
 **VALID** Prec@1 38.42 Prec@5 80.82 Error@1 61.58 Error@5 19.18 Loss:2.404
***[2020-01-29 09:38:36]*** VALID [epoch=445/600] loss = 2.403527, accuracy@1 = 38.42, accuracy@5 = 80.82 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:38:36]*** start epoch=446/600 Time Left: [01:22:01], LR=[0.015393 ~ 0.015393], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=446, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8542492240175036, FLOP=40.81
[Search] : epoch=446/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:38:37] [epoch=446/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.566 (0.566)  Prec@1 78.52 (78.52) Prec@5 99.22 (99.22) Acls-loss 0.803 (0.803) FLOP-Loss 0.000 (0.000) Arch-Loss 0.803 (0.803)
**TRAIN** [2020-01-29 09:39:02] [epoch=446/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.837 (0.645)  Prec@1 73.81 (77.94) Prec@5 96.43 (98.44) Acls-loss 0.661 (0.686) FLOP-Loss 2.908 (0.258) Arch-Loss 6.477 (1.202)
 **TRAIN** Prec@1 77.94 Prec@5 98.44 Error@1 22.06 Error@5 1.56 Base-Loss:0.645, Arch-Loss=1.202
***[2020-01-29 09:39:02]*** TRAIN [epoch=446/600] base-loss = 0.644587, arch-loss = 1.202045, accuracy-1 = 77.94, accuracy-5 = 98.44
[epoch=446/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 9, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [1, 3, 3]), ('estimated_FLOP', 24.830592)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.355 0.291 0.354  ||  0.1638 -0.0327 0.1629  || discrepancy=0.00 || select=0/3
001/003-th : 0.334 0.216 0.451  ||  0.1210 -0.3169 0.4206  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.025 0.970  ||  -2.3133 -0.7984 2.8793  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.037 0.046 0.048 0.081 0.117 0.209 0.439  ||  -1.302 -0.824 -0.585 -0.547 -0.024 0.336 0.922 1.662  || dis=0.23 || select=7/8
001/019-th : 0.104 0.135 0.147 0.143 0.127 0.120 0.119 0.104  ||  -0.166 0.091 0.180 0.146 0.034 -0.024 -0.034 -0.165   || dis=0.00 || select=2/8
002/019-th : 0.136 0.140 0.138 0.138 0.121 0.114 0.110 0.102  ||  0.091 0.123 0.109 0.109 -0.024 -0.082 -0.121 -0.199   || dis=0.00 || select=1/8
003/019-th : 0.103 0.114 0.125 0.137 0.128 0.135 0.127 0.130  ||  -0.185 -0.077 0.015 0.101 0.039 0.092 0.029 0.055     || dis=0.00 || select=3/8
004/019-th : 0.115 0.113 0.116 0.114 0.130 0.135 0.137 0.141  ||  -0.079 -0.100 -0.072 -0.089 0.045 0.082 0.094 0.123   || dis=0.00 || select=7/8
005/019-th : 0.114 0.128 0.127 0.128 0.129 0.128 0.121 0.124  ||  -0.086 0.025 0.024 0.031 0.034 0.029 -0.027 -0.004    || dis=0.00 || select=4/8
006/019-th : 0.142 0.128 0.119 0.120 0.119 0.120 0.127 0.125  ||  0.125 0.019 -0.055 -0.040 -0.052 -0.041 0.011 -0.000  || dis=0.01 || select=0/8
007/019-th : 0.019 0.028 0.045 0.059 0.091 0.117 0.204 0.436  ||  -1.413 -1.035 -0.578 -0.294 0.132 0.380 0.942 1.701   || dis=0.23 || select=7/8
008/019-th : 0.016 0.023 0.031 0.053 0.081 0.138 0.270 0.388  ||  -1.502 -1.155 -0.858 -0.326 0.099 0.635 1.305 1.667   || dis=0.12 || select=7/8
009/019-th : 0.080 0.091 0.106 0.111 0.127 0.139 0.158 0.189  ||  -0.412 -0.286 -0.129 -0.078 0.053 0.140 0.270 0.451   || dis=0.03 || select=7/8
010/019-th : 0.098 0.101 0.109 0.125 0.126 0.139 0.151 0.152  ||  -0.239 -0.208 -0.125 0.008 0.016 0.116 0.198 0.207    || dis=0.00 || select=7/8
011/019-th : 0.114 0.107 0.114 0.124 0.121 0.128 0.146 0.147  ||  -0.082 -0.141 -0.080 0.002 -0.026 0.032 0.163 0.170   || dis=0.00 || select=7/8
012/019-th : 0.142 0.132 0.127 0.123 0.121 0.115 0.120 0.120  ||  0.125 0.055 0.019 -0.018 -0.030 -0.085 -0.044 -0.039  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.011 0.014 0.020 0.044 0.887  ||  -1.204 -1.084 -0.940 -0.772 -0.469 -0.119 0.664 3.656  || dis=0.84 || select=7/8
014/019-th : 0.009 0.012 0.016 0.020 0.030 0.053 0.129 0.732  ||  -1.482 -1.223 -0.964 -0.739 -0.319 0.268 1.148 2.885  || dis=0.60 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.013 0.021 0.046 0.890  ||  -1.319 -1.118 -0.969 -0.770 -0.527 -0.016 0.777 3.737  || dis=0.84 || select=7/8
016/019-th : 0.042 0.055 0.069 0.101 0.136 0.172 0.199 0.226  ||  -0.941 -0.666 -0.443 -0.065 0.236 0.471 0.612 0.740   || dis=0.03 || select=7/8
017/019-th : 0.084 0.102 0.110 0.130 0.129 0.142 0.149 0.154  ||  -0.377 -0.173 -0.104 0.061 0.061 0.155 0.201 0.232    || dis=0.01 || select=7/8
018/019-th : 0.094 0.107 0.126 0.141 0.133 0.127 0.129 0.144  ||  -0.276 -0.145 0.019 0.137 0.077 0.026 0.046 0.153     || dis=0.00 || select=7/8
[epoch=446/600] FLOP : 24.83 MB, ratio : 0.6084, Expected-ratio : 0.7000, Discrepancy : 0.184
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:39:03] [epoch=446/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.928 (1.928)  Prec@1 44.92 (44.92) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:39:09] [epoch=446/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.333 (2.256)  Prec@1 48.21 (39.75) Prec@5 89.88 (82.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.75 Prec@5 82.08 Error@1 60.25 Error@5 17.92 Loss:2.256
***[2020-01-29 09:39:09]*** VALID [epoch=446/600] loss = 2.256135, accuracy@1 = 39.75, accuracy@5 = 82.08 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:39:09]*** start epoch=447/600 Time Left: [01:21:30], LR=[0.015204 ~ 0.015204], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=447, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.84501364834883, FLOP=40.81
[Search] : epoch=447/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:39:10] [epoch=447/600][000/098] Time 0.67 (0.67) Data 0.36 (0.36) Base-Loss 1.015 (1.015)  Prec@1 66.02 (66.02) Prec@5 96.48 (96.48) Acls-loss 0.692 (0.692) FLOP-Loss -2.908 (-2.908) Arch-Loss -5.124 (-5.124)
**TRAIN** [2020-01-29 09:39:35] [epoch=447/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.642 (0.649)  Prec@1 80.95 (77.85) Prec@5 97.62 (98.64) Acls-loss 1.257 (0.720) FLOP-Loss 0.000 (0.149) Arch-Loss 1.257 (1.018)
 **TRAIN** Prec@1 77.85 Prec@5 98.64 Error@1 22.15 Error@5 1.36 Base-Loss:0.649, Arch-Loss=1.018
***[2020-01-29 09:39:35]*** TRAIN [epoch=447/600] base-loss = 0.648689, arch-loss = 1.017857, accuracy-1 = 77.85, accuracy-5 = 98.64
[epoch=447/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.15552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.354 0.290 0.356  ||  0.1607 -0.0381 0.1661  || discrepancy=0.00 || select=2/3
001/003-th : 0.333 0.217 0.450  ||  0.1203 -0.3089 0.4203  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.025 0.969  ||  -2.3074 -0.7831 2.8688  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.036 0.046 0.048 0.081 0.116 0.212 0.438  ||  -1.316 -0.841 -0.579 -0.549 -0.021 0.342 0.941 1.668  || dis=0.23 || select=7/8
001/019-th : 0.105 0.134 0.148 0.143 0.127 0.120 0.119 0.105  ||  -0.164 0.083 0.182 0.149 0.034 -0.026 -0.033 -0.164   || dis=0.01 || select=2/8
002/019-th : 0.136 0.140 0.138 0.138 0.122 0.115 0.110 0.102  ||  0.089 0.124 0.107 0.108 -0.020 -0.079 -0.119 -0.200   || dis=0.00 || select=1/8
003/019-th : 0.102 0.114 0.126 0.135 0.129 0.137 0.127 0.131  ||  -0.187 -0.083 0.018 0.087 0.041 0.100 0.030 0.058     || dis=0.00 || select=5/8
004/019-th : 0.115 0.113 0.116 0.114 0.129 0.135 0.137 0.142  ||  -0.084 -0.097 -0.073 -0.088 0.034 0.077 0.095 0.130   || dis=0.00 || select=7/8
005/019-th : 0.115 0.128 0.127 0.128 0.128 0.128 0.122 0.124  ||  -0.082 0.029 0.015 0.025 0.026 0.026 -0.024 -0.004    || dis=0.00 || select=1/8
006/019-th : 0.142 0.128 0.118 0.120 0.120 0.120 0.127 0.126  ||  0.126 0.017 -0.060 -0.046 -0.044 -0.045 0.014 0.001   || dis=0.01 || select=0/8
007/019-th : 0.019 0.028 0.044 0.059 0.089 0.114 0.209 0.438  ||  -1.420 -1.043 -0.579 -0.300 0.116 0.363 0.969 1.711   || dis=0.23 || select=7/8
008/019-th : 0.016 0.023 0.031 0.053 0.081 0.136 0.268 0.394  ||  -1.510 -1.165 -0.867 -0.326 0.101 0.623 1.304 1.689   || dis=0.13 || select=7/8
009/019-th : 0.080 0.091 0.105 0.111 0.126 0.139 0.159 0.189  ||  -0.408 -0.286 -0.135 -0.081 0.044 0.144 0.274 0.450   || dis=0.03 || select=7/8
010/019-th : 0.097 0.098 0.109 0.124 0.126 0.143 0.151 0.152  ||  -0.242 -0.227 -0.126 0.006 0.017 0.143 0.199 0.210    || dis=0.00 || select=7/8
011/019-th : 0.114 0.108 0.113 0.122 0.121 0.128 0.147 0.147  ||  -0.082 -0.136 -0.088 -0.013 -0.025 0.034 0.171 0.169  || dis=0.00 || select=6/8
012/019-th : 0.143 0.133 0.128 0.121 0.122 0.114 0.120 0.121  ||  0.129 0.057 0.023 -0.038 -0.031 -0.096 -0.047 -0.036  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.010 0.014 0.020 0.043 0.888  ||  -1.197 -1.078 -0.949 -0.778 -0.467 -0.109 0.640 3.665  || dis=0.84 || select=7/8
014/019-th : 0.009 0.012 0.015 0.019 0.029 0.052 0.125 0.739  ||  -1.465 -1.214 -0.973 -0.748 -0.329 0.247 1.135 2.909  || dis=0.61 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.012 0.020 0.045 0.892  ||  -1.310 -1.104 -0.968 -0.764 -0.524 -0.037 0.758 3.751  || dis=0.85 || select=7/8
016/019-th : 0.042 0.055 0.068 0.101 0.138 0.172 0.199 0.225  ||  -0.940 -0.673 -0.459 -0.057 0.251 0.470 0.617 0.739   || dis=0.03 || select=7/8
017/019-th : 0.083 0.102 0.109 0.131 0.129 0.142 0.149 0.155  ||  -0.378 -0.180 -0.108 0.070 0.057 0.155 0.200 0.238    || dis=0.01 || select=7/8
018/019-th : 0.094 0.106 0.126 0.142 0.134 0.126 0.128 0.143  ||  -0.269 -0.152 0.025 0.141 0.080 0.025 0.040 0.151     || dis=0.00 || select=7/8
[epoch=447/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.184
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:39:36] [epoch=447/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.636 (1.636)  Prec@1 46.48 (46.48) Prec@5 93.75 (93.75) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:39:42] [epoch=447/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.361 (2.039)  Prec@1 35.12 (41.96) Prec@5 84.52 (83.05) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.96 Prec@5 83.05 Error@1 58.04 Error@5 16.95 Loss:2.039
***[2020-01-29 09:39:42]*** VALID [epoch=447/600] loss = 2.039043, accuracy@1 = 41.96, accuracy@5 = 83.05 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:39:42]*** start epoch=448/600 Time Left: [01:20:58], LR=[0.015017 ~ 0.015017], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=448, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8358248157422544, FLOP=40.81
[Search] : epoch=448/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:39:43] [epoch=448/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.524 (0.524)  Prec@1 82.03 (82.03) Prec@5 99.61 (99.61) Acls-loss 0.777 (0.777) FLOP-Loss 0.000 (0.000) Arch-Loss 0.777 (0.777)
**TRAIN** [2020-01-29 09:40:07] [epoch=448/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.547 (0.613)  Prec@1 80.36 (79.12) Prec@5 99.40 (98.65) Acls-loss 0.585 (0.706) FLOP-Loss 0.000 (0.000) Arch-Loss 0.585 (0.706)
 **TRAIN** Prec@1 79.12 Prec@5 98.65 Error@1 20.88 Error@5 1.35 Base-Loss:0.613, Arch-Loss=0.706
***[2020-01-29 09:40:08]*** TRAIN [epoch=448/600] base-loss = 0.612957, arch-loss = 0.705795, accuracy-1 = 79.12, accuracy-5 = 98.65
[epoch=448/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.15552)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.351 0.291 0.358  ||  0.1535 -0.0338 0.1725  || discrepancy=0.01 || select=2/3
001/003-th : 0.330 0.218 0.452  ||  0.1131 -0.3019 0.4265  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.025 0.970  ||  -2.3151 -0.7925 2.8806  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.035 0.046 0.047 0.080 0.115 0.210 0.444  ||  -1.305 -0.848 -0.580 -0.563 -0.036 0.334 0.936 1.683  || dis=0.23 || select=7/8
001/019-th : 0.104 0.133 0.147 0.142 0.127 0.120 0.120 0.105  ||  -0.171 0.079 0.175 0.142 0.033 -0.023 -0.024 -0.157   || dis=0.01 || select=2/8
002/019-th : 0.135 0.139 0.137 0.137 0.123 0.115 0.111 0.103  ||  0.081 0.114 0.101 0.097 -0.012 -0.073 -0.108 -0.192   || dis=0.00 || select=1/8
003/019-th : 0.102 0.113 0.126 0.132 0.130 0.137 0.128 0.132  ||  -0.190 -0.089 0.016 0.065 0.049 0.104 0.032 0.067     || dis=0.01 || select=5/8
004/019-th : 0.114 0.112 0.116 0.114 0.128 0.134 0.138 0.144  ||  -0.091 -0.107 -0.073 -0.088 0.029 0.074 0.101 0.142   || dis=0.01 || select=7/8
005/019-th : 0.115 0.128 0.127 0.127 0.128 0.127 0.123 0.125  ||  -0.085 0.028 0.019 0.018 0.025 0.014 -0.019 0.002     || dis=0.00 || select=1/8
006/019-th : 0.141 0.127 0.117 0.118 0.121 0.122 0.128 0.126  ||  0.120 0.011 -0.065 -0.060 -0.036 -0.025 0.018 0.004   || dis=0.01 || select=0/8
007/019-th : 0.019 0.028 0.044 0.058 0.088 0.115 0.206 0.442  ||  -1.424 -1.047 -0.586 -0.309 0.111 0.380 0.960 1.725   || dis=0.24 || select=7/8
008/019-th : 0.016 0.023 0.030 0.051 0.079 0.134 0.267 0.400  ||  -1.504 -1.169 -0.869 -0.345 0.085 0.612 1.304 1.708   || dis=0.13 || select=7/8
009/019-th : 0.080 0.091 0.105 0.111 0.125 0.138 0.160 0.190  ||  -0.409 -0.287 -0.140 -0.085 0.039 0.138 0.281 0.454   || dis=0.03 || select=7/8
010/019-th : 0.095 0.098 0.108 0.124 0.126 0.145 0.152 0.153  ||  -0.257 -0.234 -0.132 0.008 0.020 0.162 0.208 0.213    || dis=0.00 || select=7/8
011/019-th : 0.113 0.108 0.113 0.123 0.121 0.128 0.147 0.147  ||  -0.089 -0.135 -0.095 -0.008 -0.022 0.037 0.173 0.173  || dis=0.00 || select=6/8
012/019-th : 0.141 0.132 0.127 0.121 0.124 0.114 0.120 0.121  ||  0.121 0.052 0.015 -0.032 -0.012 -0.090 -0.042 -0.032  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.010 0.014 0.020 0.043 0.890  ||  -1.205 -1.067 -0.940 -0.796 -0.463 -0.126 0.639 3.679  || dis=0.85 || select=7/8
014/019-th : 0.009 0.012 0.015 0.019 0.028 0.051 0.125 0.741  ||  -1.459 -1.226 -0.974 -0.754 -0.355 0.249 1.144 2.925  || dis=0.62 || select=7/8
015/019-th : 0.006 0.007 0.008 0.010 0.012 0.020 0.045 0.893  ||  -1.307 -1.149 -0.979 -0.764 -0.511 -0.038 0.764 3.763  || dis=0.85 || select=7/8
016/019-th : 0.041 0.053 0.067 0.101 0.137 0.175 0.198 0.227  ||  -0.948 -0.694 -0.462 -0.061 0.246 0.489 0.615 0.752   || dis=0.03 || select=7/8
017/019-th : 0.082 0.101 0.109 0.132 0.129 0.142 0.149 0.155  ||  -0.390 -0.187 -0.112 0.079 0.062 0.157 0.204 0.244    || dis=0.01 || select=7/8
018/019-th : 0.093 0.105 0.126 0.140 0.134 0.126 0.131 0.145  ||  -0.279 -0.157 0.023 0.129 0.080 0.021 0.057 0.158     || dis=0.00 || select=7/8
[epoch=448/600] FLOP : 28.16 MB, ratio : 0.6899, Expected-ratio : 0.7000, Discrepancy : 0.186
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:40:08] [epoch=448/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.054 (2.054)  Prec@1 44.14 (44.14) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:40:14] [epoch=448/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.368 (2.306)  Prec@1 52.98 (40.10) Prec@5 91.07 (81.86) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.10 Prec@5 81.86 Error@1 59.90 Error@5 18.14 Loss:2.306
***[2020-01-29 09:40:14]*** VALID [epoch=448/600] loss = 2.306283, accuracy@1 = 40.10, accuracy@5 = 81.86 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:40:14]*** start epoch=449/600 Time Left: [01:20:26], LR=[0.014830 ~ 0.014830], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=449, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8266829781142658, FLOP=40.81
[Search] : epoch=449/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:40:15] [epoch=449/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.677 (0.677)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.774 (0.774) FLOP-Loss 0.000 (0.000) Arch-Loss 0.774 (0.774)
**TRAIN** [2020-01-29 09:40:39] [epoch=449/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.566 (0.631)  Prec@1 82.14 (78.67) Prec@5 98.21 (98.56) Acls-loss 0.612 (0.699) FLOP-Loss 0.000 (0.149) Arch-Loss 0.612 (0.997)
 **TRAIN** Prec@1 78.67 Prec@5 98.56 Error@1 21.33 Error@5 1.44 Base-Loss:0.631, Arch-Loss=0.997
***[2020-01-29 09:40:39]*** TRAIN [epoch=449/600] base-loss = 0.631432, arch-loss = 0.997295, accuracy-1 = 78.67, accuracy-5 = 98.56
[epoch=449/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 6, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.163712)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.350 0.292 0.358  ||  0.1517 -0.0313 0.1734  || discrepancy=0.01 || select=2/3
001/003-th : 0.329 0.220 0.451  ||  0.1120 -0.2897 0.4261  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.024 0.971  ||  -2.3348 -0.7892 2.8987  || discrepancy=0.95 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.036 0.045 0.047 0.078 0.114 0.211 0.447  ||  -1.298 -0.840 -0.595 -0.561 -0.054 0.323 0.940 1.692  || dis=0.24 || select=7/8
001/019-th : 0.105 0.133 0.147 0.142 0.127 0.120 0.121 0.105  ||  -0.166 0.077 0.175 0.139 0.027 -0.024 -0.024 -0.157   || dis=0.01 || select=2/8
002/019-th : 0.135 0.139 0.137 0.137 0.123 0.116 0.111 0.103  ||  0.080 0.114 0.095 0.100 -0.012 -0.068 -0.110 -0.190   || dis=0.00 || select=1/8
003/019-th : 0.103 0.113 0.126 0.131 0.130 0.137 0.128 0.132  ||  -0.187 -0.087 0.016 0.057 0.052 0.102 0.032 0.066     || dis=0.01 || select=5/8
004/019-th : 0.113 0.112 0.115 0.115 0.127 0.136 0.138 0.143  ||  -0.098 -0.106 -0.077 -0.079 0.024 0.089 0.105 0.139   || dis=0.00 || select=7/8
005/019-th : 0.115 0.129 0.128 0.126 0.128 0.126 0.123 0.125  ||  -0.084 0.032 0.025 0.010 0.021 0.011 -0.017 -0.001    || dis=0.00 || select=1/8
006/019-th : 0.141 0.127 0.117 0.117 0.122 0.123 0.127 0.126  ||  0.121 0.012 -0.065 -0.068 -0.026 -0.021 0.015 0.002   || dis=0.01 || select=0/8
007/019-th : 0.018 0.028 0.042 0.056 0.086 0.117 0.203 0.449  ||  -1.448 -1.040 -0.606 -0.327 0.099 0.410 0.960 1.751   || dis=0.25 || select=7/8
008/019-th : 0.016 0.023 0.030 0.051 0.078 0.133 0.267 0.402  ||  -1.495 -1.159 -0.870 -0.361 0.078 0.607 1.302 1.711   || dis=0.14 || select=7/8
009/019-th : 0.080 0.090 0.105 0.111 0.124 0.139 0.160 0.191  ||  -0.408 -0.289 -0.136 -0.088 0.029 0.138 0.282 0.456   || dis=0.03 || select=7/8
010/019-th : 0.096 0.097 0.107 0.123 0.124 0.145 0.154 0.153  ||  -0.250 -0.239 -0.145 -0.001 0.001 0.162 0.223 0.216   || dis=0.00 || select=6/8
011/019-th : 0.114 0.109 0.113 0.123 0.121 0.129 0.146 0.146  ||  -0.085 -0.131 -0.093 -0.005 -0.024 0.038 0.167 0.168  || dis=0.00 || select=7/8
012/019-th : 0.141 0.131 0.127 0.122 0.123 0.115 0.119 0.121  ||  0.121 0.050 0.015 -0.021 -0.015 -0.087 -0.045 -0.031  || dis=0.01 || select=0/8
013/019-th : 0.007 0.007 0.009 0.010 0.014 0.019 0.041 0.893  ||  -1.201 -1.078 -0.946 -0.813 -0.478 -0.125 0.631 3.705  || dis=0.85 || select=7/8
014/019-th : 0.009 0.012 0.015 0.019 0.028 0.050 0.123 0.745  ||  -1.442 -1.220 -0.967 -0.759 -0.362 0.235 1.134 2.935  || dis=0.62 || select=7/8
015/019-th : 0.006 0.007 0.008 0.009 0.012 0.019 0.043 0.896  ||  -1.293 -1.142 -0.973 -0.773 -0.514 -0.051 0.745 3.779  || dis=0.85 || select=7/8
016/019-th : 0.041 0.052 0.067 0.099 0.136 0.177 0.199 0.228  ||  -0.956 -0.716 -0.463 -0.072 0.246 0.507 0.625 0.762   || dis=0.03 || select=7/8
017/019-th : 0.082 0.101 0.109 0.131 0.131 0.141 0.150 0.156  ||  -0.395 -0.191 -0.112 0.071 0.072 0.147 0.209 0.251    || dis=0.01 || select=7/8
018/019-th : 0.094 0.106 0.126 0.141 0.133 0.127 0.130 0.143  ||  -0.274 -0.154 0.022 0.134 0.075 0.030 0.052 0.151     || dis=0.00 || select=7/8
[epoch=449/600] FLOP : 28.16 MB, ratio : 0.6901, Expected-ratio : 0.7000, Discrepancy : 0.188
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:40:39] [epoch=449/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.226 (2.226)  Prec@1 25.78 (25.78) Prec@5 71.48 (71.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:40:45] [epoch=449/600][097/098] Time 0.13 (0.06) Data 0.00 (0.00) Loss 1.881 (2.208)  Prec@1 52.38 (40.87) Prec@5 88.69 (82.03) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.87 Prec@5 82.03 Error@1 59.13 Error@5 17.97 Loss:2.208
***[2020-01-29 09:40:45]*** VALID [epoch=449/600] loss = 2.208444, accuracy@1 = 40.87, accuracy@5 = 82.03 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:40:45]*** start epoch=450/600 Time Left: [01:19:54], LR=[0.014645 ~ 0.014645], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=450, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8175883860929587, FLOP=40.81
[Search] : epoch=450/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:40:46] [epoch=450/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.690 (0.690)  Prec@1 78.12 (78.12) Prec@5 98.83 (98.83) Acls-loss 0.601 (0.601) FLOP-Loss 0.000 (0.000) Arch-Loss 0.601 (0.601)
**TRAIN** [2020-01-29 09:41:10] [epoch=450/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.580 (0.609)  Prec@1 80.36 (79.30) Prec@5 99.40 (98.80) Acls-loss 0.847 (0.700) FLOP-Loss 0.000 (0.388) Arch-Loss 0.847 (1.475)
 **TRAIN** Prec@1 79.30 Prec@5 98.80 Error@1 20.70 Error@5 1.20 Base-Loss:0.609, Arch-Loss=1.475
***[2020-01-29 09:41:10]*** TRAIN [epoch=450/600] base-loss = 0.609404, arch-loss = 1.475380, accuracy-1 = 79.30, accuracy-5 = 98.80
[epoch=450/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 6, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.163712)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.350 0.294 0.356  ||  0.1530 -0.0212 0.1705  || discrepancy=0.01 || select=2/3
001/003-th : 0.332 0.223 0.445  ||  0.1220 -0.2777 0.4150  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.025 0.970  ||  -2.3235 -0.7724 2.8834  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.036 0.045 0.047 0.078 0.114 0.210 0.448  ||  -1.307 -0.829 -0.592 -0.561 -0.059 0.326 0.937 1.696  || dis=0.24 || select=7/8
001/019-th : 0.104 0.136 0.148 0.141 0.128 0.119 0.119 0.105  ||  -0.170 0.095 0.186 0.136 0.038 -0.038 -0.034 -0.163   || dis=0.01 || select=2/8
002/019-th : 0.136 0.140 0.136 0.140 0.123 0.115 0.110 0.102  ||  0.089 0.121 0.091 0.118 -0.011 -0.080 -0.117 -0.200   || dis=0.00 || select=1/8
003/019-th : 0.103 0.114 0.127 0.130 0.129 0.137 0.127 0.132  ||  -0.181 -0.083 0.021 0.047 0.044 0.099 0.028 0.064     || dis=0.01 || select=5/8
004/019-th : 0.113 0.113 0.116 0.116 0.127 0.134 0.138 0.142  ||  -0.094 -0.093 -0.069 -0.072 0.023 0.073 0.102 0.131   || dis=0.00 || select=7/8
005/019-th : 0.116 0.129 0.129 0.128 0.129 0.125 0.121 0.124  ||  -0.075 0.033 0.029 0.021 0.031 0.004 -0.028 -0.009    || dis=0.00 || select=1/8
006/019-th : 0.143 0.128 0.118 0.118 0.121 0.122 0.126 0.125  ||  0.134 0.019 -0.056 -0.062 -0.039 -0.025 0.003 -0.006  || dis=0.01 || select=0/8
007/019-th : 0.018 0.027 0.042 0.056 0.087 0.115 0.207 0.448  ||  -1.450 -1.053 -0.618 -0.329 0.115 0.399 0.980 1.754   || dis=0.24 || select=7/8
008/019-th : 0.016 0.023 0.031 0.051 0.079 0.132 0.268 0.401  ||  -1.500 -1.158 -0.856 -0.361 0.085 0.595 1.308 1.708   || dis=0.13 || select=7/8
009/019-th : 0.080 0.092 0.104 0.111 0.124 0.139 0.160 0.189  ||  -0.407 -0.275 -0.145 -0.083 0.028 0.139 0.284 0.449   || dis=0.03 || select=7/8
010/019-th : 0.097 0.099 0.106 0.125 0.123 0.145 0.153 0.152  ||  -0.240 -0.225 -0.150 0.010 -0.006 0.159 0.213 0.208   || dis=0.00 || select=6/8
011/019-th : 0.115 0.109 0.114 0.125 0.122 0.127 0.144 0.144  ||  -0.073 -0.128 -0.078 0.012 -0.012 0.028 0.150 0.155   || dis=0.00 || select=7/8
012/019-th : 0.142 0.133 0.128 0.124 0.122 0.114 0.118 0.120  ||  0.131 0.060 0.024 -0.011 -0.021 -0.095 -0.055 -0.044  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.010 0.014 0.020 0.041 0.893  ||  -1.191 -1.068 -0.943 -0.805 -0.484 -0.122 0.622 3.699  || dis=0.85 || select=7/8
014/019-th : 0.009 0.011 0.015 0.018 0.026 0.049 0.121 0.751  ||  -1.465 -1.224 -0.978 -0.761 -0.388 0.231 1.141 2.966  || dis=0.63 || select=7/8
015/019-th : 0.006 0.007 0.008 0.009 0.012 0.019 0.043 0.897  ||  -1.288 -1.139 -0.963 -0.777 -0.508 -0.054 0.734 3.782  || dis=0.85 || select=7/8
016/019-th : 0.042 0.053 0.068 0.101 0.136 0.174 0.198 0.229  ||  -0.947 -0.703 -0.458 -0.056 0.239 0.485 0.614 0.758   || dis=0.03 || select=7/8
017/019-th : 0.083 0.101 0.110 0.132 0.131 0.139 0.149 0.155  ||  -0.386 -0.183 -0.104 0.078 0.075 0.133 0.198 0.244    || dis=0.01 || select=7/8
018/019-th : 0.094 0.108 0.128 0.141 0.133 0.126 0.128 0.142  ||  -0.274 -0.133 0.037 0.137 0.073 0.022 0.041 0.139     || dis=0.00 || select=7/8
[epoch=450/600] FLOP : 28.16 MB, ratio : 0.6901, Expected-ratio : 0.7000, Discrepancy : 0.187
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:41:10] [epoch=450/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 1.520 (1.520)  Prec@1 67.19 (67.19) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:41:16] [epoch=450/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.480 (2.348)  Prec@1 30.36 (39.87) Prec@5 75.60 (82.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.87 Prec@5 82.42 Error@1 60.13 Error@5 17.58 Loss:2.348
***[2020-01-29 09:41:16]*** VALID [epoch=450/600] loss = 2.348390, accuracy@1 = 39.87, accuracy@5 = 82.42 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:41:16]*** start epoch=451/600 Time Left: [01:19:21], LR=[0.014460 ~ 0.014460], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=451, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.8085412890111685, FLOP=40.81
[Search] : epoch=451/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:41:17] [epoch=451/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.455 (0.455)  Prec@1 83.59 (83.59) Prec@5 100.00 (100.00) Acls-loss 0.525 (0.525) FLOP-Loss 0.000 (0.000) Arch-Loss 0.525 (0.525)
**TRAIN** [2020-01-29 09:41:41] [epoch=451/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.750 (0.623)  Prec@1 69.64 (78.98) Prec@5 99.40 (98.72) Acls-loss 0.541 (0.695) FLOP-Loss 0.000 (0.298) Arch-Loss 0.541 (1.291)
 **TRAIN** Prec@1 78.98 Prec@5 98.72 Error@1 21.02 Error@5 1.28 Base-Loss:0.623, Arch-Loss=1.291
***[2020-01-29 09:41:41]*** TRAIN [epoch=451/600] base-loss = 0.622954, arch-loss = 1.290938, accuracy-1 = 78.98, accuracy-5 = 98.72
[epoch=451/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 9, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.913596)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.348 0.298 0.354  ||  0.1508 -0.0024 0.1700  || discrepancy=0.01 || select=2/3
001/003-th : 0.333 0.223 0.444  ||  0.1252 -0.2757 0.4113  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.026 0.969  ||  -2.3226 -0.7486 2.8755  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.036 0.045 0.046 0.076 0.115 0.210 0.449  ||  -1.297 -0.824 -0.594 -0.577 -0.073 0.338 0.937 1.698  || dis=0.24 || select=7/8
001/019-th : 0.104 0.135 0.149 0.143 0.127 0.118 0.118 0.105  ||  -0.165 0.091 0.190 0.150 0.031 -0.042 -0.040 -0.162   || dis=0.01 || select=2/8
002/019-th : 0.137 0.141 0.137 0.139 0.120 0.115 0.110 0.101  ||  0.098 0.124 0.101 0.112 -0.033 -0.079 -0.124 -0.203   || dis=0.00 || select=1/8
003/019-th : 0.104 0.115 0.128 0.129 0.128 0.137 0.127 0.132  ||  -0.174 -0.079 0.028 0.041 0.034 0.096 0.025 0.060     || dis=0.01 || select=5/8
004/019-th : 0.114 0.113 0.118 0.115 0.127 0.133 0.138 0.142  ||  -0.089 -0.097 -0.058 -0.077 0.018 0.069 0.102 0.130   || dis=0.00 || select=7/8
005/019-th : 0.116 0.129 0.129 0.130 0.128 0.124 0.121 0.122  ||  -0.068 0.035 0.036 0.038 0.028 -0.003 -0.030 -0.019   || dis=0.00 || select=3/8
006/019-th : 0.144 0.128 0.119 0.119 0.121 0.121 0.125 0.124  ||  0.143 0.021 -0.053 -0.049 -0.038 -0.037 -0.004 -0.012  || dis=0.02 || select=0/8
007/019-th : 0.018 0.026 0.041 0.056 0.085 0.118 0.203 0.453  ||  -1.460 -1.083 -0.617 -0.324 0.099 0.425 0.973 1.775   || dis=0.25 || select=7/8
008/019-th : 0.016 0.023 0.031 0.050 0.078 0.130 0.270 0.403  ||  -1.506 -1.163 -0.855 -0.363 0.072 0.585 1.320 1.720   || dis=0.13 || select=7/8
009/019-th : 0.081 0.092 0.105 0.114 0.124 0.138 0.159 0.188  ||  -0.404 -0.271 -0.137 -0.058 0.027 0.131 0.274 0.440   || dis=0.03 || select=7/8
010/019-th : 0.098 0.100 0.107 0.125 0.123 0.144 0.152 0.152  ||  -0.234 -0.216 -0.142 0.012 -0.005 0.149 0.204 0.203   || dis=0.00 || select=6/8
011/019-th : 0.116 0.110 0.115 0.125 0.123 0.126 0.143 0.143  ||  -0.067 -0.114 -0.073 0.008 -0.004 0.019 0.143 0.144   || dis=0.00 || select=7/8
012/019-th : 0.143 0.133 0.128 0.124 0.122 0.113 0.118 0.118  ||  0.136 0.065 0.029 -0.005 -0.019 -0.099 -0.058 -0.052  || dis=0.01 || select=0/8
013/019-th : 0.007 0.008 0.009 0.010 0.014 0.019 0.040 0.894  ||  -1.197 -1.058 -0.933 -0.798 -0.479 -0.127 0.603 3.706  || dis=0.85 || select=7/8
014/019-th : 0.009 0.011 0.014 0.017 0.026 0.047 0.119 0.757  ||  -1.454 -1.216 -0.968 -0.781 -0.396 0.209 1.135 2.988  || dis=0.64 || select=7/8
015/019-th : 0.006 0.006 0.008 0.009 0.012 0.019 0.041 0.899  ||  -1.274 -1.144 -0.958 -0.775 -0.506 -0.063 0.715 3.796  || dis=0.86 || select=7/8
016/019-th : 0.042 0.054 0.068 0.102 0.135 0.172 0.199 0.229  ||  -0.942 -0.693 -0.459 -0.053 0.229 0.475 0.617 0.756   || dis=0.03 || select=7/8
017/019-th : 0.083 0.102 0.111 0.132 0.131 0.139 0.147 0.155  ||  -0.385 -0.179 -0.096 0.081 0.071 0.135 0.191 0.240    || dis=0.01 || select=7/8
018/019-th : 0.095 0.109 0.127 0.142 0.131 0.127 0.127 0.141  ||  -0.258 -0.128 0.031 0.138 0.061 0.026 0.029 0.135     || dis=0.00 || select=3/8
[epoch=451/600] FLOP : 27.91 MB, ratio : 0.6839, Expected-ratio : 0.7000, Discrepancy : 0.188
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:41:41] [epoch=451/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.607 (3.607)  Prec@1 36.72 (36.72) Prec@5 71.88 (71.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:41:47] [epoch=451/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.923 (2.474)  Prec@1 69.64 (40.66) Prec@5 96.43 (82.47) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.66 Prec@5 82.47 Error@1 59.34 Error@5 17.53 Loss:2.474
***[2020-01-29 09:41:47]*** VALID [epoch=451/600] loss = 2.474418, accuracy@1 = 40.66, accuracy@5 = 82.47 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:41:47]*** start epoch=452/600 Time Left: [01:18:49], LR=[0.014276 ~ 0.014276], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=452, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7995419348996323, FLOP=40.81
[Search] : epoch=452/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:41:48] [epoch=452/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.513 (0.513)  Prec@1 80.86 (80.86) Prec@5 100.00 (100.00) Acls-loss 0.693 (0.693) FLOP-Loss 0.000 (0.000) Arch-Loss 0.693 (0.693)
**TRAIN** [2020-01-29 09:42:12] [epoch=452/600][097/098] Time 0.31 (0.25) Data 0.00 (0.00) Base-Loss 0.509 (0.637)  Prec@1 83.33 (78.39) Prec@5 98.81 (98.55) Acls-loss 0.535 (0.683) FLOP-Loss 0.000 (0.149) Arch-Loss 0.535 (0.981)
 **TRAIN** Prec@1 78.39 Prec@5 98.55 Error@1 21.61 Error@5 1.45 Base-Loss:0.637, Arch-Loss=0.981
***[2020-01-29 09:42:12]*** TRAIN [epoch=452/600] base-loss = 0.637187, arch-loss = 0.980807, accuracy-1 = 78.39, accuracy-5 = 98.55
[epoch=452/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 6, 12, 16, 6, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.163712)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.347 0.299 0.355  ||  0.1490 -0.0006 0.1709  || discrepancy=0.01 || select=2/3
001/003-th : 0.333 0.224 0.443  ||  0.1253 -0.2692 0.4101  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.025 0.970  ||  -2.3588 -0.7551 2.9130  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.023 0.036 0.046 0.046 0.075 0.113 0.209 0.452  ||  -1.292 -0.826 -0.581 -0.577 -0.087 0.322 0.936 1.706  || dis=0.24 || select=7/8
001/019-th : 0.105 0.135 0.149 0.142 0.127 0.118 0.118 0.105  ||  -0.159 0.090 0.186 0.144 0.031 -0.045 -0.040 -0.162   || dis=0.01 || select=2/8
002/019-th : 0.138 0.141 0.138 0.138 0.120 0.115 0.110 0.101  ||  0.101 0.123 0.102 0.101 -0.039 -0.075 -0.121 -0.204   || dis=0.00 || select=1/8
003/019-th : 0.104 0.115 0.128 0.130 0.128 0.136 0.127 0.132  ||  -0.175 -0.074 0.031 0.044 0.030 0.095 0.020 0.059     || dis=0.00 || select=5/8
004/019-th : 0.113 0.112 0.118 0.115 0.128 0.135 0.138 0.141  ||  -0.093 -0.106 -0.055 -0.082 0.025 0.081 0.107 0.129   || dis=0.00 || select=7/8
005/019-th : 0.118 0.130 0.128 0.129 0.128 0.124 0.120 0.123  ||  -0.059 0.042 0.025 0.029 0.027 -0.006 -0.038 -0.019   || dis=0.00 || select=1/8
006/019-th : 0.144 0.128 0.118 0.118 0.122 0.122 0.125 0.124  ||  0.141 0.020 -0.060 -0.058 -0.029 -0.026 -0.003 -0.011  || dis=0.02 || select=0/8
007/019-th : 0.018 0.026 0.041 0.054 0.083 0.118 0.204 0.456  ||  -1.460 -1.082 -0.621 -0.341 0.083 0.431 0.980 1.785   || dis=0.25 || select=7/8
008/019-th : 0.016 0.023 0.031 0.050 0.078 0.129 0.268 0.406  ||  -1.510 -1.156 -0.844 -0.376 0.074 0.582 1.312 1.726   || dis=0.14 || select=7/8
009/019-th : 0.081 0.092 0.105 0.114 0.123 0.139 0.158 0.188  ||  -0.400 -0.277 -0.138 -0.062 0.022 0.140 0.269 0.444   || dis=0.03 || select=7/8
010/019-th : 0.098 0.099 0.108 0.125 0.122 0.144 0.153 0.152  ||  -0.234 -0.223 -0.137 0.010 -0.018 0.150 0.210 0.207   || dis=0.00 || select=6/8
011/019-th : 0.115 0.110 0.115 0.125 0.124 0.126 0.141 0.142  ||  -0.069 -0.112 -0.072 0.014 0.008 0.022 0.136 0.141    || dis=0.00 || select=7/8
012/019-th : 0.142 0.134 0.128 0.124 0.124 0.112 0.117 0.118  ||  0.132 0.072 0.028 -0.004 -0.002 -0.106 -0.061 -0.052  || dis=0.01 || select=0/8
013/019-th : 0.006 0.008 0.009 0.010 0.013 0.019 0.039 0.896  ||  -1.212 -1.054 -0.923 -0.793 -0.483 -0.135 0.587 3.724  || dis=0.86 || select=7/8
014/019-th : 0.009 0.011 0.014 0.017 0.025 0.046 0.114 0.763  ||  -1.450 -1.206 -0.962 -0.792 -0.394 0.199 1.109 3.009  || dis=0.65 || select=7/8
015/019-th : 0.006 0.006 0.008 0.009 0.012 0.019 0.041 0.898  ||  -1.274 -1.139 -0.952 -0.767 -0.503 -0.072 0.713 3.794  || dis=0.86 || select=7/8
016/019-th : 0.041 0.054 0.068 0.103 0.133 0.171 0.199 0.231  ||  -0.957 -0.686 -0.463 -0.044 0.216 0.464 0.617 0.768   || dis=0.03 || select=7/8
017/019-th : 0.081 0.101 0.112 0.133 0.131 0.140 0.147 0.154  ||  -0.400 -0.182 -0.080 0.094 0.078 0.139 0.194 0.235    || dis=0.01 || select=7/8
018/019-th : 0.095 0.108 0.128 0.141 0.133 0.126 0.127 0.142  ||  -0.261 -0.132 0.036 0.132 0.073 0.017 0.026 0.141     || dis=0.00 || select=7/8
[epoch=452/600] FLOP : 28.16 MB, ratio : 0.6901, Expected-ratio : 0.7000, Discrepancy : 0.190
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:42:13] [epoch=452/600][000/098] Time 0.39 (0.39) Data 0.31 (0.31) Loss 1.925 (1.925)  Prec@1 42.58 (42.58) Prec@5 88.67 (88.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:42:18] [epoch=452/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 0.783 (2.193)  Prec@1 79.17 (40.22) Prec@5 98.21 (80.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.22 Prec@5 80.02 Error@1 59.78 Error@5 19.98 Loss:2.193
***[2020-01-29 09:42:18]*** VALID [epoch=452/600] loss = 2.192940, accuracy@1 = 40.22, accuracy@5 = 80.02 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:42:19]*** start epoch=453/600 Time Left: [01:18:17], LR=[0.014094 ~ 0.014094], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=453, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7905905704801877, FLOP=40.81
[Search] : epoch=453/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:42:19] [epoch=453/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.634 (0.634)  Prec@1 80.47 (80.47) Prec@5 98.83 (98.83) Acls-loss 0.640 (0.640) FLOP-Loss 0.000 (0.000) Arch-Loss 0.640 (0.640)
**TRAIN** [2020-01-29 09:42:43] [epoch=453/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.674 (0.598)  Prec@1 76.79 (79.73) Prec@5 98.21 (98.82) Acls-loss 0.770 (0.705) FLOP-Loss 0.000 (0.090) Arch-Loss 0.770 (0.884)
 **TRAIN** Prec@1 79.73 Prec@5 98.82 Error@1 20.27 Error@5 1.18 Base-Loss:0.598, Arch-Loss=0.884
***[2020-01-29 09:42:43]*** TRAIN [epoch=453/600] base-loss = 0.597796, arch-loss = 0.884415, accuracy-1 = 79.73, accuracy-5 = 98.82
[epoch=453/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 6, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.473984)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.341 0.304 0.355  ||  0.1392 0.0229 0.1771  || discrepancy=0.01 || select=2/3
001/003-th : 0.332 0.226 0.442  ||  0.1229 -0.2600 0.4111  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.025 0.970  ||  -2.3542 -0.7487 2.9075  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.035 0.045 0.045 0.074 0.111 0.209 0.459  ||  -1.287 -0.850 -0.595 -0.597 -0.096 0.318 0.949 1.733  || dis=0.25 || select=7/8
001/019-th : 0.104 0.134 0.150 0.142 0.128 0.118 0.119 0.105  ||  -0.166 0.084 0.193 0.141 0.036 -0.040 -0.039 -0.158   || dis=0.01 || select=2/8
002/019-th : 0.137 0.139 0.136 0.139 0.119 0.118 0.111 0.102  ||  0.099 0.109 0.087 0.111 -0.042 -0.052 -0.116 -0.202   || dis=0.00 || select=3/8
003/019-th : 0.104 0.113 0.128 0.130 0.129 0.136 0.128 0.132  ||  -0.178 -0.093 0.030 0.049 0.039 0.091 0.032 0.065     || dis=0.00 || select=5/8
004/019-th : 0.112 0.111 0.117 0.112 0.131 0.135 0.140 0.143  ||  -0.108 -0.112 -0.060 -0.104 0.056 0.081 0.116 0.139   || dis=0.00 || select=7/8
005/019-th : 0.119 0.130 0.127 0.128 0.127 0.124 0.121 0.123  ||  -0.053 0.041 0.017 0.021 0.015 -0.006 -0.031 -0.018   || dis=0.00 || select=1/8
006/019-th : 0.144 0.128 0.118 0.118 0.121 0.122 0.125 0.124  ||  0.140 0.019 -0.055 -0.062 -0.031 -0.026 -0.004 -0.009  || dis=0.02 || select=0/8
007/019-th : 0.018 0.026 0.040 0.055 0.082 0.117 0.200 0.462  ||  -1.463 -1.092 -0.636 -0.331 0.079 0.429 0.968 1.805   || dis=0.26 || select=7/8
008/019-th : 0.016 0.022 0.031 0.049 0.077 0.126 0.275 0.404  ||  -1.515 -1.196 -0.829 -0.378 0.075 0.568 1.348 1.733   || dis=0.13 || select=7/8
009/019-th : 0.081 0.091 0.104 0.113 0.123 0.138 0.161 0.189  ||  -0.404 -0.284 -0.150 -0.063 0.019 0.136 0.285 0.451   || dis=0.03 || select=7/8
010/019-th : 0.095 0.099 0.109 0.124 0.122 0.145 0.154 0.153  ||  -0.262 -0.225 -0.124 0.004 -0.011 0.160 0.218 0.213   || dis=0.00 || select=6/8
011/019-th : 0.115 0.110 0.113 0.124 0.124 0.128 0.143 0.142  ||  -0.071 -0.112 -0.092 0.004 0.002 0.038 0.147 0.143    || dis=0.00 || select=6/8
012/019-th : 0.141 0.134 0.128 0.123 0.125 0.112 0.118 0.118  ||  0.126 0.070 0.029 -0.017 0.005 -0.103 -0.054 -0.051   || dis=0.01 || select=0/8
013/019-th : 0.006 0.007 0.008 0.009 0.013 0.018 0.037 0.900  ||  -1.222 -1.064 -0.928 -0.800 -0.476 -0.140 0.564 3.757  || dis=0.86 || select=7/8
014/019-th : 0.009 0.011 0.014 0.017 0.025 0.045 0.112 0.769  ||  -1.463 -1.219 -0.980 -0.794 -0.407 0.196 1.111 3.040  || dis=0.66 || select=7/8
015/019-th : 0.006 0.006 0.008 0.009 0.012 0.018 0.040 0.900  ||  -1.263 -1.130 -0.947 -0.778 -0.513 -0.081 0.703 3.807  || dis=0.86 || select=7/8
016/019-th : 0.041 0.053 0.067 0.102 0.131 0.174 0.201 0.231  ||  -0.954 -0.706 -0.465 -0.052 0.206 0.485 0.631 0.770   || dis=0.03 || select=7/8
017/019-th : 0.081 0.101 0.112 0.133 0.131 0.138 0.149 0.155  ||  -0.407 -0.187 -0.080 0.091 0.072 0.128 0.202 0.245    || dis=0.01 || select=7/8
018/019-th : 0.095 0.108 0.128 0.141 0.132 0.126 0.128 0.142  ||  -0.262 -0.131 0.032 0.132 0.066 0.021 0.032 0.140     || dis=0.00 || select=7/8
[epoch=453/600] FLOP : 28.47 MB, ratio : 0.6977, Expected-ratio : 0.7000, Discrepancy : 0.191
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:42:44] [epoch=453/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.396 (2.396)  Prec@1 21.88 (21.88) Prec@5 56.25 (56.25) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:42:50] [epoch=453/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.364 (2.405)  Prec@1 16.67 (39.49) Prec@5 65.48 (80.68) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.49 Prec@5 80.68 Error@1 60.51 Error@5 19.32 Loss:2.405
***[2020-01-29 09:42:50]*** VALID [epoch=453/600] loss = 2.404782, accuracy@1 = 39.49, accuracy@5 = 80.68 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:42:50]*** start epoch=454/600 Time Left: [01:17:45], LR=[0.013912 ~ 0.013912], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=454, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7816874411590128, FLOP=40.81
[Search] : epoch=454/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:42:50] [epoch=454/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.595 (0.595)  Prec@1 82.81 (82.81) Prec@5 98.44 (98.44) Acls-loss 0.679 (0.679) FLOP-Loss 0.000 (0.000) Arch-Loss 0.679 (0.679)
**TRAIN** [2020-01-29 09:43:14] [epoch=454/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.711 (0.610)  Prec@1 75.60 (79.37) Prec@5 98.81 (98.64) Acls-loss 0.616 (0.680) FLOP-Loss 0.000 (0.090) Arch-Loss 0.616 (0.860)
 **TRAIN** Prec@1 79.37 Prec@5 98.64 Error@1 20.63 Error@5 1.36 Base-Loss:0.610, Arch-Loss=0.860
***[2020-01-29 09:43:14]*** TRAIN [epoch=454/600] base-loss = 0.610253, arch-loss = 0.859876, accuracy-1 = 79.37, accuracy-5 = 98.64
[epoch=454/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 6, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.473984)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.337 0.307 0.356  ||  0.1287 0.0368 0.1849  || discrepancy=0.02 || select=2/3
001/003-th : 0.328 0.231 0.441  ||  0.1179 -0.2356 0.4130  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.025 0.970  ||  -2.3488 -0.7425 2.9012  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.034 0.044 0.044 0.073 0.112 0.208 0.463  ||  -1.280 -0.855 -0.608 -0.611 -0.103 0.327 0.946 1.746  || dis=0.26 || select=7/8
001/019-th : 0.104 0.134 0.149 0.141 0.127 0.119 0.119 0.106  ||  -0.168 0.082 0.190 0.136 0.029 -0.032 -0.038 -0.153   || dis=0.01 || select=2/8
002/019-th : 0.136 0.138 0.137 0.138 0.121 0.117 0.111 0.102  ||  0.092 0.103 0.094 0.105 -0.030 -0.062 -0.109 -0.195   || dis=0.00 || select=3/8
003/019-th : 0.103 0.113 0.127 0.131 0.129 0.136 0.129 0.132  ||  -0.182 -0.095 0.026 0.055 0.039 0.089 0.042 0.063     || dis=0.00 || select=5/8
004/019-th : 0.111 0.111 0.116 0.112 0.132 0.134 0.141 0.143  ||  -0.114 -0.110 -0.065 -0.104 0.058 0.076 0.123 0.141   || dis=0.00 || select=7/8
005/019-th : 0.118 0.130 0.127 0.127 0.127 0.124 0.123 0.123  ||  -0.055 0.040 0.016 0.016 0.018 -0.010 -0.020 -0.020   || dis=0.00 || select=1/8
006/019-th : 0.143 0.126 0.117 0.119 0.123 0.121 0.126 0.125  ||  0.134 0.010 -0.065 -0.049 -0.019 -0.031 0.004 -0.004  || dis=0.02 || select=0/8
007/019-th : 0.017 0.025 0.040 0.054 0.080 0.116 0.198 0.471  ||  -1.478 -1.087 -0.643 -0.341 0.061 0.430 0.966 1.833   || dis=0.27 || select=7/8
008/019-th : 0.016 0.022 0.031 0.049 0.077 0.123 0.273 0.410  ||  -1.523 -1.194 -0.834 -0.371 0.077 0.545 1.344 1.751   || dis=0.14 || select=7/8
009/019-th : 0.081 0.090 0.104 0.112 0.122 0.140 0.162 0.190  ||  -0.404 -0.290 -0.153 -0.073 0.008 0.145 0.297 0.453   || dis=0.03 || select=7/8
010/019-th : 0.095 0.099 0.109 0.124 0.121 0.144 0.154 0.154  ||  -0.267 -0.222 -0.123 0.001 -0.017 0.156 0.223 0.218   || dis=0.00 || select=6/8
011/019-th : 0.115 0.111 0.113 0.125 0.122 0.130 0.143 0.142  ||  -0.072 -0.110 -0.092 0.010 -0.016 0.051 0.146 0.140   || dis=0.00 || select=6/8
012/019-th : 0.141 0.134 0.128 0.124 0.125 0.112 0.119 0.118  ||  0.124 0.070 0.024 -0.008 0.000 -0.102 -0.048 -0.051   || dis=0.01 || select=0/8
013/019-th : 0.006 0.007 0.008 0.009 0.013 0.018 0.036 0.902  ||  -1.213 -1.064 -0.931 -0.799 -0.490 -0.137 0.549 3.769  || dis=0.87 || select=7/8
014/019-th : 0.008 0.011 0.014 0.017 0.024 0.045 0.109 0.773  ||  -1.472 -1.220 -0.975 -0.789 -0.426 0.212 1.093 3.054  || dis=0.66 || select=7/8
015/019-th : 0.006 0.006 0.008 0.009 0.012 0.018 0.040 0.903  ||  -1.249 -1.135 -0.956 -0.814 -0.511 -0.106 0.717 3.832  || dis=0.86 || select=7/8
016/019-th : 0.041 0.052 0.066 0.101 0.129 0.173 0.203 0.233  ||  -0.957 -0.713 -0.481 -0.051 0.189 0.484 0.644 0.782   || dis=0.03 || select=7/8
017/019-th : 0.081 0.101 0.110 0.129 0.134 0.139 0.149 0.157  ||  -0.408 -0.188 -0.099 0.063 0.099 0.136 0.204 0.254    || dis=0.01 || select=7/8
018/019-th : 0.094 0.108 0.127 0.140 0.133 0.127 0.128 0.142  ||  -0.271 -0.132 0.027 0.129 0.075 0.028 0.035 0.143     || dis=0.00 || select=7/8
[epoch=454/600] FLOP : 28.47 MB, ratio : 0.6977, Expected-ratio : 0.7000, Discrepancy : 0.193
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:43:15] [epoch=454/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.920 (2.920)  Prec@1 23.83 (23.83) Prec@5 71.48 (71.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:43:21] [epoch=454/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 4.774 (2.476)  Prec@1 19.64 (41.41) Prec@5 76.19 (82.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.41 Prec@5 82.17 Error@1 58.59 Error@5 17.83 Loss:2.476
***[2020-01-29 09:43:21]*** VALID [epoch=454/600] loss = 2.476401, accuracy@1 = 41.41, accuracy@5 = 82.17 | Best-Valid-Acc@1=43.36, Error@1=56.64
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:43:21]*** start epoch=455/600 Time Left: [01:17:13], LR=[0.013731 ~ 0.013731], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=455, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7728327910198959, FLOP=40.81
[Search] : epoch=455/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:43:22] [epoch=455/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 1.002 (1.002)  Prec@1 62.89 (62.89) Prec@5 97.27 (97.27) Acls-loss 0.600 (0.600) FLOP-Loss 0.000 (0.000) Arch-Loss 0.600 (0.600)
**TRAIN** [2020-01-29 09:43:46] [epoch=455/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.713 (0.597)  Prec@1 75.60 (80.20) Prec@5 97.62 (98.71) Acls-loss 0.435 (0.714) FLOP-Loss 2.918 (0.349) Arch-Loss 6.271 (1.411)
 **TRAIN** Prec@1 80.20 Prec@5 98.71 Error@1 19.80 Error@5 1.29 Base-Loss:0.597, Arch-Loss=1.411
***[2020-01-29 09:43:46]*** TRAIN [epoch=455/600] base-loss = 0.596885, arch-loss = 1.410966, accuracy-1 = 80.20, accuracy-5 = 98.71
[epoch=455/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 6, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.814976)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.338 0.308 0.354  ||  0.1327 0.0386 0.1800  || discrepancy=0.02 || select=2/3
001/003-th : 0.331 0.230 0.439  ||  0.1253 -0.2410 0.4059  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.026 0.969  ||  -2.3371 -0.7302 2.8868  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.034 0.044 0.043 0.073 0.111 0.208 0.465  ||  -1.283 -0.849 -0.614 -0.615 -0.103 0.320 0.949 1.754  || dis=0.26 || select=7/8
001/019-th : 0.105 0.136 0.150 0.141 0.126 0.119 0.119 0.105  ||  -0.162 0.095 0.194 0.130 0.017 -0.035 -0.040 -0.163   || dis=0.01 || select=2/8
002/019-th : 0.136 0.138 0.139 0.139 0.120 0.117 0.110 0.101  ||  0.091 0.108 0.112 0.117 -0.035 -0.056 -0.118 -0.204   || dis=0.00 || select=3/8
003/019-th : 0.104 0.114 0.129 0.133 0.126 0.135 0.128 0.131  ||  -0.174 -0.084 0.037 0.070 0.019 0.082 0.031 0.053     || dis=0.00 || select=5/8
004/019-th : 0.112 0.112 0.119 0.111 0.131 0.133 0.140 0.143  ||  -0.105 -0.107 -0.047 -0.111 0.051 0.064 0.120 0.137   || dis=0.00 || select=7/8
005/019-th : 0.120 0.132 0.127 0.127 0.126 0.123 0.123 0.121  ||  -0.045 0.055 0.017 0.014 0.010 -0.014 -0.020 -0.035   || dis=0.01 || select=1/8
006/019-th : 0.145 0.128 0.118 0.119 0.120 0.119 0.125 0.125  ||  0.144 0.018 -0.058 -0.053 -0.042 -0.050 -0.001 -0.000  || dis=0.02 || select=0/8
007/019-th : 0.017 0.025 0.040 0.054 0.081 0.114 0.197 0.473  ||  -1.477 -1.099 -0.636 -0.338 0.069 0.416 0.966 1.839   || dis=0.28 || select=7/8
008/019-th : 0.015 0.021 0.030 0.049 0.077 0.124 0.271 0.414  ||  -1.532 -1.218 -0.855 -0.364 0.084 0.562 1.349 1.771   || dis=0.14 || select=7/8
009/019-th : 0.082 0.090 0.101 0.111 0.122 0.140 0.164 0.190  ||  -0.390 -0.290 -0.180 -0.082 0.009 0.146 0.307 0.456   || dis=0.03 || select=7/8
010/019-th : 0.094 0.099 0.108 0.124 0.123 0.145 0.154 0.152  ||  -0.268 -0.217 -0.136 0.007 -0.003 0.161 0.222 0.211   || dis=0.00 || select=6/8
011/019-th : 0.116 0.112 0.112 0.125 0.123 0.130 0.141 0.142  ||  -0.065 -0.102 -0.099 0.011 -0.003 0.050 0.132 0.136   || dis=0.00 || select=7/8
012/019-th : 0.143 0.135 0.129 0.123 0.124 0.112 0.117 0.117  ||  0.136 0.081 0.037 -0.013 -0.006 -0.106 -0.062 -0.063  || dis=0.01 || select=0/8
013/019-th : 0.006 0.007 0.008 0.009 0.013 0.018 0.035 0.905  ||  -1.223 -1.053 -0.927 -0.793 -0.488 -0.149 0.525 3.789  || dis=0.87 || select=7/8
014/019-th : 0.008 0.011 0.013 0.016 0.023 0.045 0.107 0.776  ||  -1.485 -1.216 -0.995 -0.784 -0.437 0.231 1.083 3.069  || dis=0.67 || select=7/8
015/019-th : 0.006 0.006 0.007 0.009 0.011 0.017 0.039 0.904  ||  -1.245 -1.139 -0.953 -0.805 -0.529 -0.117 0.710 3.846  || dis=0.86 || select=7/8
016/019-th : 0.041 0.052 0.067 0.101 0.130 0.174 0.201 0.235  ||  -0.953 -0.719 -0.474 -0.057 0.192 0.486 0.632 0.788   || dis=0.03 || select=7/8
017/019-th : 0.081 0.101 0.111 0.130 0.134 0.140 0.148 0.156  ||  -0.410 -0.182 -0.094 0.065 0.099 0.140 0.194 0.251    || dis=0.01 || select=7/8
018/019-th : 0.096 0.108 0.127 0.141 0.132 0.127 0.127 0.142  ||  -0.257 -0.131 0.027 0.129 0.065 0.030 0.028 0.137     || dis=0.00 || select=7/8
[epoch=455/600] FLOP : 28.81 MB, ratio : 0.7060, Expected-ratio : 0.7000, Discrepancy : 0.194
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:43:46] [epoch=455/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.950 (1.950)  Prec@1 31.64 (31.64) Prec@5 79.30 (79.30) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:43:52] [epoch=455/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.807 (1.996)  Prec@1 45.24 (44.86) Prec@5 79.76 (85.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 44.86 Prec@5 85.17 Error@1 55.14 Error@5 14.83 Loss:1.996
***[2020-01-29 09:43:53]*** VALID [epoch=455/600] loss = 1.995891, accuracy@1 = 44.86, accuracy@5 = 85.17 | Best-Valid-Acc@1=43.36, Error@1=56.64
Currently, the best validation accuracy found at 455-epoch :: acc@1=44.86, acc@5=85.17, error@1=55.14, error@5=14.83, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:43:53]*** start epoch=456/600 Time Left: [01:16:41], LR=[0.013552 ~ 0.013552], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=456, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7640268628175423, FLOP=40.81
[Search] : epoch=456/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:43:53] [epoch=456/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.544 (0.544)  Prec@1 81.25 (81.25) Prec@5 98.83 (98.83) Acls-loss 0.781 (0.781) FLOP-Loss 2.918 (2.918) Arch-Loss 6.617 (6.617)
**TRAIN** [2020-01-29 09:44:18] [epoch=456/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.443 (0.601)  Prec@1 86.90 (79.38) Prec@5 99.40 (98.75) Acls-loss 0.630 (0.692) FLOP-Loss 0.000 (0.478) Arch-Loss 0.630 (1.647)
 **TRAIN** Prec@1 79.38 Prec@5 98.75 Error@1 20.62 Error@5 1.25 Base-Loss:0.601, Arch-Loss=1.647
***[2020-01-29 09:44:18]*** TRAIN [epoch=456/600] base-loss = 0.600679, arch-loss = 1.646774, accuracy-1 = 79.38, accuracy-5 = 98.75
[epoch=456/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 9, 16, 6, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.123776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.342 0.306 0.352  ||  0.1424 0.0289 0.1709  || discrepancy=0.01 || select=2/3
001/003-th : 0.338 0.230 0.431  ||  0.1441 -0.2398 0.3867  || discrepancy=0.09 || select=2/3
002/003-th : 0.005 0.026 0.968  ||  -2.3299 -0.7261 2.8796  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.035 0.044 0.044 0.072 0.110 0.211 0.463  ||  -1.308 -0.834 -0.612 -0.604 -0.112 0.320 0.967 1.753  || dis=0.25 || select=7/8
001/019-th : 0.106 0.138 0.151 0.141 0.125 0.118 0.118 0.103  ||  -0.149 0.111 0.204 0.134 0.014 -0.048 -0.049 -0.184   || dis=0.01 || select=2/8
002/019-th : 0.138 0.140 0.139 0.140 0.121 0.116 0.108 0.099  ||  0.109 0.124 0.113 0.126 -0.025 -0.066 -0.138 -0.224   || dis=0.00 || select=3/8
003/019-th : 0.106 0.115 0.132 0.134 0.126 0.134 0.125 0.128  ||  -0.159 -0.075 0.066 0.078 0.016 0.075 0.011 0.032     || dis=0.00 || select=3/8
004/019-th : 0.113 0.113 0.122 0.111 0.130 0.132 0.138 0.140  ||  -0.091 -0.093 -0.018 -0.114 0.042 0.063 0.104 0.120   || dis=0.00 || select=7/8
005/019-th : 0.122 0.135 0.128 0.129 0.125 0.121 0.121 0.118  ||  -0.027 0.073 0.026 0.034 -0.002 -0.035 -0.030 -0.055  || dis=0.01 || select=1/8
006/019-th : 0.148 0.129 0.120 0.120 0.118 0.118 0.122 0.125  ||  0.166 0.031 -0.048 -0.044 -0.062 -0.062 -0.031 -0.004  || dis=0.02 || select=0/8
007/019-th : 0.017 0.025 0.040 0.052 0.081 0.113 0.198 0.474  ||  -1.470 -1.105 -0.638 -0.357 0.076 0.410 0.973 1.846   || dis=0.28 || select=7/8
008/019-th : 0.015 0.021 0.030 0.049 0.078 0.122 0.271 0.414  ||  -1.546 -1.228 -0.841 -0.362 0.104 0.556 1.353 1.776   || dis=0.14 || select=7/8
009/019-th : 0.083 0.089 0.101 0.112 0.122 0.141 0.164 0.187  ||  -0.376 -0.302 -0.172 -0.078 0.015 0.158 0.309 0.440   || dis=0.02 || select=7/8
010/019-th : 0.096 0.099 0.108 0.125 0.123 0.146 0.153 0.150  ||  -0.250 -0.223 -0.130 0.012 -0.004 0.168 0.215 0.196   || dis=0.00 || select=6/8
011/019-th : 0.118 0.114 0.113 0.124 0.123 0.131 0.138 0.139  ||  -0.047 -0.081 -0.086 0.001 -0.008 0.054 0.111 0.118   || dis=0.00 || select=7/8
012/019-th : 0.146 0.138 0.131 0.124 0.122 0.110 0.115 0.115  ||  0.157 0.100 0.050 -0.003 -0.021 -0.120 -0.081 -0.083  || dis=0.01 || select=0/8
013/019-th : 0.006 0.007 0.008 0.009 0.012 0.017 0.033 0.907  ||  -1.215 -1.076 -0.914 -0.797 -0.482 -0.150 0.500 3.809  || dis=0.87 || select=7/8
014/019-th : 0.008 0.011 0.013 0.016 0.023 0.044 0.104 0.780  ||  -1.493 -1.206 -0.989 -0.784 -0.433 0.217 1.066 3.084  || dis=0.68 || select=7/8
015/019-th : 0.006 0.006 0.007 0.009 0.011 0.017 0.040 0.904  ||  -1.244 -1.139 -0.984 -0.802 -0.531 -0.110 0.724 3.848  || dis=0.86 || select=7/8
016/019-th : 0.041 0.052 0.067 0.103 0.132 0.173 0.198 0.234  ||  -0.949 -0.716 -0.465 -0.043 0.208 0.480 0.614 0.781   || dis=0.04 || select=7/8
017/019-th : 0.082 0.103 0.113 0.131 0.134 0.137 0.146 0.154  ||  -0.392 -0.164 -0.079 0.073 0.094 0.117 0.180 0.234    || dis=0.01 || select=7/8
018/019-th : 0.097 0.109 0.129 0.141 0.131 0.127 0.126 0.141  ||  -0.242 -0.127 0.042 0.128 0.055 0.025 0.015 0.131     || dis=0.00 || select=7/8
[epoch=456/600] FLOP : 28.12 MB, ratio : 0.6891, Expected-ratio : 0.7000, Discrepancy : 0.193
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:44:18] [epoch=456/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.802 (2.802)  Prec@1 48.83 (48.83) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:44:24] [epoch=456/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.002 (2.236)  Prec@1 65.48 (42.14) Prec@5 98.21 (82.51) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.14 Prec@5 82.51 Error@1 57.86 Error@5 17.49 Loss:2.236
***[2020-01-29 09:44:24]*** VALID [epoch=456/600] loss = 2.235937, accuracy@1 = 42.14, accuracy@5 = 82.51 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 536870912 bytes, 536870.91 KB, 536.87 MB, 0.54 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:44:24]*** start epoch=457/600 Time Left: [01:16:08], LR=[0.013373 ~ 0.013373], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=457, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7552698979709223, FLOP=40.81
[Search] : epoch=457/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:44:25] [epoch=457/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.738 (0.738)  Prec@1 75.00 (75.00) Prec@5 98.83 (98.83) Acls-loss 0.904 (0.904) FLOP-Loss 0.000 (0.000) Arch-Loss 0.904 (0.904)
**TRAIN** [2020-01-29 09:44:49] [epoch=457/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.422 (0.608)  Prec@1 85.12 (79.51) Prec@5 98.81 (98.76) Acls-loss 0.764 (0.706) FLOP-Loss 0.000 (0.149) Arch-Loss 0.764 (1.005)
 **TRAIN** Prec@1 79.51 Prec@5 98.76 Error@1 20.49 Error@5 1.24 Base-Loss:0.608, Arch-Loss=1.005
***[2020-01-29 09:44:49]*** TRAIN [epoch=457/600] base-loss = 0.607924, arch-loss = 1.004655, accuracy-1 = 79.51, accuracy-5 = 98.76
[epoch=457/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 9, 16, 6, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.123776)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.340 0.310 0.350  ||  0.1402 0.0466 0.1695  || discrepancy=0.01 || select=2/3
001/003-th : 0.336 0.233 0.431  ||  0.1395 -0.2244 0.3887  || discrepancy=0.09 || select=2/3
002/003-th : 0.005 0.027 0.968  ||  -2.3241 -0.7158 2.8712  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.022 0.035 0.043 0.043 0.071 0.109 0.210 0.468  ||  -1.310 -0.829 -0.625 -0.610 -0.112 0.309 0.967 1.770  || dis=0.26 || select=7/8
001/019-th : 0.106 0.139 0.152 0.141 0.123 0.118 0.118 0.103  ||  -0.150 0.116 0.207 0.128 -0.008 -0.045 -0.046 -0.182  || dis=0.01 || select=2/8
002/019-th : 0.138 0.140 0.138 0.141 0.120 0.117 0.107 0.099  ||  0.109 0.121 0.112 0.133 -0.029 -0.058 -0.148 -0.219   || dis=0.00 || select=3/8
003/019-th : 0.106 0.115 0.132 0.134 0.125 0.133 0.126 0.129  ||  -0.155 -0.078 0.064 0.075 0.007 0.069 0.016 0.035     || dis=0.00 || select=3/8
004/019-th : 0.113 0.113 0.122 0.112 0.129 0.132 0.138 0.139  ||  -0.093 -0.091 -0.020 -0.100 0.037 0.062 0.107 0.115   || dis=0.00 || select=7/8
005/019-th : 0.120 0.131 0.129 0.129 0.128 0.122 0.122 0.119  ||  -0.037 0.046 0.032 0.033 0.027 -0.021 -0.025 -0.051   || dis=0.00 || select=1/8
006/019-th : 0.147 0.130 0.120 0.120 0.119 0.119 0.121 0.124  ||  0.161 0.034 -0.042 -0.044 -0.052 -0.050 -0.033 -0.010  || dis=0.02 || select=0/8
007/019-th : 0.017 0.025 0.039 0.051 0.079 0.112 0.197 0.480  ||  -1.471 -1.102 -0.642 -0.373 0.062 0.407 0.975 1.864   || dis=0.28 || select=7/8
008/019-th : 0.014 0.020 0.030 0.049 0.076 0.121 0.271 0.418  ||  -1.578 -1.226 -0.839 -0.344 0.097 0.555 1.361 1.797   || dis=0.15 || select=7/8
009/019-th : 0.083 0.088 0.101 0.111 0.121 0.142 0.165 0.188  ||  -0.371 -0.310 -0.173 -0.080 0.006 0.161 0.312 0.443   || dis=0.02 || select=7/8
010/019-th : 0.096 0.097 0.107 0.122 0.123 0.147 0.156 0.151  ||  -0.254 -0.238 -0.138 -0.009 -0.001 0.175 0.235 0.205  || dis=0.01 || select=6/8
011/019-th : 0.118 0.114 0.114 0.124 0.124 0.131 0.138 0.138  ||  -0.050 -0.083 -0.085 0.005 0.003 0.057 0.107 0.113    || dis=0.00 || select=7/8
012/019-th : 0.145 0.137 0.130 0.125 0.123 0.111 0.116 0.114  ||  0.152 0.097 0.042 0.005 -0.014 -0.115 -0.074 -0.085   || dis=0.01 || select=0/8
013/019-th : 0.006 0.007 0.008 0.009 0.012 0.017 0.032 0.910  ||  -1.211 -1.085 -0.921 -0.809 -0.480 -0.150 0.487 3.831  || dis=0.88 || select=7/8
014/019-th : 0.008 0.010 0.013 0.016 0.023 0.044 0.101 0.785  ||  -1.505 -1.218 -0.985 -0.780 -0.440 0.219 1.057 3.106  || dis=0.68 || select=7/8
015/019-th : 0.005 0.006 0.007 0.009 0.011 0.017 0.038 0.908  ||  -1.233 -1.154 -0.983 -0.795 -0.533 -0.122 0.695 3.876  || dis=0.87 || select=7/8
016/019-th : 0.042 0.052 0.067 0.102 0.131 0.171 0.198 0.237  ||  -0.945 -0.721 -0.469 -0.047 0.199 0.466 0.615 0.796   || dis=0.04 || select=7/8
017/019-th : 0.083 0.104 0.113 0.130 0.134 0.138 0.145 0.153  ||  -0.389 -0.157 -0.075 0.062 0.097 0.122 0.174 0.230    || dis=0.01 || select=7/8
018/019-th : 0.096 0.109 0.130 0.138 0.132 0.129 0.126 0.140  ||  -0.248 -0.123 0.050 0.106 0.067 0.041 0.018 0.122     || dis=0.00 || select=7/8
[epoch=457/600] FLOP : 28.12 MB, ratio : 0.6891, Expected-ratio : 0.7000, Discrepancy : 0.195
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:44:49] [epoch=457/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 0.952 (0.952)  Prec@1 66.41 (66.41) Prec@5 98.05 (98.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:44:55] [epoch=457/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.402 (2.180)  Prec@1 66.07 (43.74) Prec@5 89.29 (84.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.74 Prec@5 84.32 Error@1 56.26 Error@5 15.68 Loss:2.180
***[2020-01-29 09:44:55]*** VALID [epoch=457/600] loss = 2.179671, accuracy@1 = 43.74, accuracy@5 = 84.32 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:44:55]*** start epoch=458/600 Time Left: [01:15:36], LR=[0.013195 ~ 0.013195], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=458, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7465621365566509, FLOP=40.81
[Search] : epoch=458/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:44:56] [epoch=458/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.535 (0.535)  Prec@1 81.25 (81.25) Prec@5 99.22 (99.22) Acls-loss 0.663 (0.663) FLOP-Loss 0.000 (0.000) Arch-Loss 0.663 (0.663)
**TRAIN** [2020-01-29 09:45:20] [epoch=458/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.524 (0.565)  Prec@1 80.95 (80.86) Prec@5 98.21 (98.91) Acls-loss 0.452 (0.673) FLOP-Loss 0.000 (0.060) Arch-Loss 0.452 (0.792)
 **TRAIN** Prec@1 80.86 Prec@5 98.91 Error@1 19.14 Error@5 1.09 Base-Loss:0.565, Arch-Loss=0.792
***[2020-01-29 09:45:20]*** TRAIN [epoch=458/600] base-loss = 0.565192, arch-loss = 0.791949, accuracy-1 = 80.86, accuracy-5 = 98.91
[epoch=458/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 9, 16, 6, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.782784)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.338 0.310 0.352  ||  0.1336 0.0489 0.1750  || discrepancy=0.01 || select=2/3
001/003-th : 0.334 0.234 0.432  ||  0.1350 -0.2197 0.3920  || discrepancy=0.10 || select=2/3
002/003-th : 0.005 0.027 0.968  ||  -2.3198 -0.7199 2.8694  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.021 0.034 0.042 0.043 0.069 0.108 0.206 0.477  ||  -1.313 -0.844 -0.627 -0.610 -0.133 0.308 0.960 1.797  || dis=0.27 || select=7/8
001/019-th : 0.107 0.138 0.150 0.140 0.123 0.118 0.119 0.104  ||  -0.150 0.108 0.193 0.124 -0.006 -0.050 -0.040 -0.171  || dis=0.01 || select=2/8
002/019-th : 0.137 0.139 0.138 0.141 0.121 0.118 0.107 0.100  ||  0.101 0.114 0.107 0.131 -0.019 -0.046 -0.143 -0.216   || dis=0.00 || select=3/8
003/019-th : 0.105 0.114 0.132 0.134 0.126 0.134 0.127 0.128  ||  -0.162 -0.083 0.061 0.077 0.016 0.076 0.022 0.035     || dis=0.00 || select=3/8
004/019-th : 0.114 0.113 0.120 0.112 0.128 0.133 0.139 0.141  ||  -0.089 -0.101 -0.039 -0.106 0.026 0.067 0.113 0.126   || dis=0.00 || select=7/8
005/019-th : 0.118 0.131 0.129 0.128 0.128 0.123 0.123 0.121  ||  -0.058 0.047 0.035 0.024 0.024 -0.017 -0.018 -0.033   || dis=0.00 || select=1/8
006/019-th : 0.146 0.129 0.121 0.121 0.120 0.120 0.121 0.123  ||  0.152 0.029 -0.031 -0.035 -0.041 -0.044 -0.030 -0.014  || dis=0.02 || select=0/8
007/019-th : 0.017 0.024 0.039 0.050 0.078 0.109 0.196 0.487  ||  -1.466 -1.104 -0.649 -0.387 0.055 0.386 0.975 1.887   || dis=0.29 || select=7/8
008/019-th : 0.014 0.020 0.029 0.048 0.075 0.122 0.269 0.422  ||  -1.584 -1.220 -0.854 -0.358 0.088 0.568 1.360 1.812   || dis=0.15 || select=7/8
009/019-th : 0.083 0.088 0.101 0.111 0.122 0.141 0.165 0.188  ||  -0.372 -0.315 -0.174 -0.078 0.014 0.154 0.315 0.447   || dis=0.02 || select=7/8
010/019-th : 0.095 0.097 0.108 0.122 0.124 0.147 0.156 0.151  ||  -0.262 -0.240 -0.131 -0.006 0.009 0.173 0.233 0.205   || dis=0.01 || select=6/8
011/019-th : 0.117 0.113 0.114 0.123 0.125 0.131 0.139 0.138  ||  -0.054 -0.088 -0.082 -0.003 0.008 0.055 0.117 0.112   || dis=0.00 || select=6/8
012/019-th : 0.144 0.137 0.130 0.123 0.123 0.112 0.116 0.115  ||  0.147 0.095 0.041 -0.011 -0.012 -0.109 -0.069 -0.080  || dis=0.01 || select=0/8
013/019-th : 0.006 0.007 0.008 0.009 0.012 0.017 0.031 0.911  ||  -1.207 -1.091 -0.913 -0.824 -0.487 -0.153 0.475 3.848  || dis=0.88 || select=7/8
014/019-th : 0.008 0.010 0.013 0.016 0.022 0.043 0.098 0.791  ||  -1.499 -1.212 -0.984 -0.775 -0.455 0.203 1.038 3.126  || dis=0.69 || select=7/8
015/019-th : 0.005 0.006 0.007 0.008 0.011 0.016 0.036 0.911  ||  -1.245 -1.153 -0.990 -0.790 -0.534 -0.123 0.670 3.900  || dis=0.88 || select=7/8
016/019-th : 0.041 0.052 0.066 0.102 0.130 0.168 0.200 0.240  ||  -0.957 -0.726 -0.475 -0.046 0.197 0.453 0.626 0.809   || dis=0.04 || select=7/8
017/019-th : 0.083 0.104 0.111 0.131 0.133 0.139 0.147 0.153  ||  -0.387 -0.162 -0.089 0.071 0.089 0.132 0.187 0.225    || dis=0.01 || select=7/8
018/019-th : 0.095 0.109 0.130 0.140 0.134 0.129 0.124 0.140  ||  -0.260 -0.127 0.049 0.123 0.080 0.045 0.007 0.126     || dis=0.00 || select=7/8
[epoch=458/600] FLOP : 27.78 MB, ratio : 0.6807, Expected-ratio : 0.7000, Discrepancy : 0.197
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:45:21] [epoch=458/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.218 (2.218)  Prec@1 26.17 (26.17) Prec@5 76.17 (76.17) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:45:27] [epoch=458/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.764 (2.733)  Prec@1 42.86 (39.88) Prec@5 83.33 (80.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.88 Prec@5 80.42 Error@1 60.12 Error@5 19.58 Loss:2.733
***[2020-01-29 09:45:27]*** VALID [epoch=458/600] loss = 2.733021, accuracy@1 = 39.88, accuracy@5 = 80.42 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:45:27]*** start epoch=459/600 Time Left: [01:15:04], LR=[0.013018 ~ 0.013018], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=459, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7379038173024061, FLOP=40.81
[Search] : epoch=459/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:45:27] [epoch=459/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 1.577 (1.577)  Prec@1 46.48 (46.48) Prec@5 92.97 (92.97) Acls-loss 0.702 (0.702) FLOP-Loss 0.000 (0.000) Arch-Loss 0.702 (0.702)
**TRAIN** [2020-01-29 09:45:51] [epoch=459/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.644 (0.641)  Prec@1 77.98 (78.37) Prec@5 98.21 (98.64) Acls-loss 0.809 (0.685) FLOP-Loss 0.000 (0.000) Arch-Loss 0.809 (0.685)
 **TRAIN** Prec@1 78.37 Prec@5 98.64 Error@1 21.63 Error@5 1.36 Base-Loss:0.641, Arch-Loss=0.685
***[2020-01-29 09:45:51]*** TRAIN [epoch=459/600] base-loss = 0.640897, arch-loss = 0.685143, accuracy-1 = 78.37, accuracy-5 = 98.64
[epoch=459/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 6, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.473984)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.332 0.311 0.357  ||  0.1177 0.0507 0.1900  || discrepancy=0.02 || select=2/3
001/003-th : 0.329 0.237 0.434  ||  0.1227 -0.2042 0.4013  || discrepancy=0.10 || select=2/3
002/003-th : 0.005 0.027 0.968  ||  -2.3172 -0.7138 2.8655  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.033 0.042 0.042 0.068 0.105 0.203 0.486  ||  -1.338 -0.861 -0.628 -0.608 -0.134 0.302 0.956 1.831  || dis=0.28 || select=7/8
001/019-th : 0.105 0.137 0.149 0.139 0.124 0.120 0.120 0.105  ||  -0.163 0.100 0.186 0.117 -0.003 -0.031 -0.028 -0.163  || dis=0.01 || select=2/8
002/019-th : 0.136 0.137 0.136 0.141 0.122 0.120 0.108 0.100  ||  0.093 0.106 0.092 0.131 -0.014 -0.030 -0.137 -0.208   || dis=0.00 || select=3/8
003/019-th : 0.105 0.112 0.130 0.133 0.128 0.135 0.129 0.129  ||  -0.166 -0.099 0.044 0.070 0.033 0.083 0.037 0.041     || dis=0.00 || select=5/8
004/019-th : 0.113 0.113 0.118 0.112 0.127 0.134 0.141 0.142  ||  -0.098 -0.099 -0.052 -0.111 0.017 0.074 0.127 0.130   || dis=0.00 || select=7/8
005/019-th : 0.117 0.129 0.128 0.128 0.128 0.124 0.125 0.122  ||  -0.065 0.034 0.022 0.024 0.024 -0.009 -0.001 -0.025   || dis=0.00 || select=1/8
006/019-th : 0.144 0.126 0.120 0.122 0.120 0.121 0.122 0.124  ||  0.145 0.013 -0.036 -0.025 -0.042 -0.029 -0.020 -0.010  || dis=0.02 || select=0/8
007/019-th : 0.017 0.024 0.037 0.050 0.075 0.108 0.197 0.492  ||  -1.460 -1.113 -0.672 -0.383 0.024 0.385 0.990 1.904   || dis=0.29 || select=7/8
008/019-th : 0.014 0.020 0.029 0.047 0.074 0.121 0.266 0.429  ||  -1.596 -1.216 -0.864 -0.372 0.083 0.574 1.359 1.837   || dis=0.16 || select=7/8
009/019-th : 0.082 0.087 0.101 0.111 0.122 0.140 0.166 0.191  ||  -0.379 -0.328 -0.180 -0.077 0.013 0.154 0.323 0.460   || dis=0.02 || select=7/8
010/019-th : 0.094 0.096 0.108 0.122 0.124 0.146 0.157 0.152  ||  -0.266 -0.248 -0.132 -0.006 0.010 0.170 0.242 0.210   || dis=0.01 || select=6/8
011/019-th : 0.116 0.112 0.114 0.123 0.126 0.131 0.140 0.138  ||  -0.063 -0.095 -0.081 -0.004 0.018 0.060 0.123 0.113   || dis=0.00 || select=6/8
012/019-th : 0.144 0.136 0.127 0.125 0.123 0.112 0.117 0.116  ||  0.142 0.085 0.021 -0.000 -0.014 -0.103 -0.059 -0.070  || dis=0.01 || select=0/8
013/019-th : 0.006 0.006 0.008 0.008 0.012 0.016 0.031 0.914  ||  -1.208 -1.091 -0.903 -0.829 -0.505 -0.182 0.472 3.867  || dis=0.88 || select=7/8
014/019-th : 0.008 0.010 0.013 0.015 0.022 0.040 0.095 0.797  ||  -1.491 -1.205 -0.991 -0.791 -0.448 0.166 1.028 3.156  || dis=0.70 || select=7/8
015/019-th : 0.005 0.006 0.007 0.008 0.011 0.016 0.035 0.912  ||  -1.233 -1.148 -0.984 -0.785 -0.529 -0.127 0.645 3.907  || dis=0.88 || select=7/8
016/019-th : 0.041 0.052 0.065 0.102 0.129 0.169 0.200 0.242  ||  -0.959 -0.728 -0.491 -0.043 0.192 0.457 0.626 0.819   || dis=0.04 || select=7/8
017/019-th : 0.082 0.103 0.111 0.129 0.133 0.139 0.149 0.154  ||  -0.392 -0.171 -0.095 0.058 0.090 0.130 0.200 0.235    || dis=0.01 || select=7/8
018/019-th : 0.094 0.108 0.129 0.140 0.134 0.131 0.124 0.140  ||  -0.273 -0.133 0.045 0.125 0.084 0.062 0.010 0.129     || dis=0.00 || select=7/8
[epoch=459/600] FLOP : 28.47 MB, ratio : 0.6977, Expected-ratio : 0.7000, Discrepancy : 0.200
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:45:52] [epoch=459/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.439 (3.439)  Prec@1 45.70 (45.70) Prec@5 80.08 (80.08) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:45:58] [epoch=459/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.950 (2.196)  Prec@1 60.71 (43.83) Prec@5 91.07 (83.63) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.83 Prec@5 83.63 Error@1 56.17 Error@5 16.37 Loss:2.196
***[2020-01-29 09:45:58]*** VALID [epoch=459/600] loss = 2.196419, accuracy@1 = 43.83, accuracy@5 = 83.63 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:45:58]*** start epoch=460/600 Time Left: [01:14:32], LR=[0.012843 ~ 0.012843], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=460, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7292951775803839, FLOP=40.81
[Search] : epoch=460/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:45:58] [epoch=460/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.514 (0.514)  Prec@1 82.03 (82.03) Prec@5 99.61 (99.61) Acls-loss 0.535 (0.535) FLOP-Loss 0.000 (0.000) Arch-Loss 0.535 (0.535)
**TRAIN** [2020-01-29 09:46:22] [epoch=460/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.473 (0.579)  Prec@1 85.12 (79.96) Prec@5 99.40 (98.74) Acls-loss 0.579 (0.680) FLOP-Loss 0.000 (0.000) Arch-Loss 0.579 (0.680)
 **TRAIN** Prec@1 79.96 Prec@5 98.74 Error@1 20.04 Error@5 1.26 Base-Loss:0.579, Arch-Loss=0.680
***[2020-01-29 09:46:22]*** TRAIN [epoch=460/600] base-loss = 0.579237, arch-loss = 0.679961, accuracy-1 = 79.96, accuracy-5 = 98.74
[epoch=460/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 8, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.644284)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.327 0.315 0.358  ||  0.1063 0.0700 0.1970  || discrepancy=0.03 || select=2/3
001/003-th : 0.328 0.233 0.439  ||  0.1177 -0.2241 0.4087  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.027 0.968  ||  -2.3321 -0.7114 2.8800  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.032 0.040 0.042 0.067 0.103 0.201 0.494  ||  -1.328 -0.873 -0.661 -0.605 -0.141 0.292 0.957 1.856  || dis=0.29 || select=7/8
001/019-th : 0.104 0.136 0.148 0.139 0.124 0.121 0.121 0.106  ||  -0.176 0.095 0.181 0.118 0.004 -0.020 -0.023 -0.156   || dis=0.01 || select=2/8
002/019-th : 0.133 0.136 0.135 0.141 0.124 0.122 0.109 0.101  ||  0.078 0.096 0.088 0.132 0.002 -0.012 -0.129 -0.204    || dis=0.00 || select=3/8
003/019-th : 0.104 0.111 0.127 0.133 0.129 0.137 0.129 0.130  ||  -0.173 -0.106 0.026 0.070 0.044 0.099 0.041 0.047     || dis=0.00 || select=5/8
004/019-th : 0.112 0.112 0.116 0.112 0.128 0.137 0.142 0.142  ||  -0.106 -0.106 -0.074 -0.108 0.027 0.095 0.134 0.130   || dis=0.00 || select=6/8
005/019-th : 0.114 0.127 0.131 0.128 0.127 0.127 0.124 0.122  ||  -0.090 0.019 0.052 0.031 0.019 0.017 -0.001 -0.018    || dis=0.00 || select=2/8
006/019-th : 0.143 0.127 0.120 0.122 0.118 0.122 0.124 0.123  ||  0.139 0.017 -0.040 -0.022 -0.057 -0.020 -0.003 -0.017  || dis=0.02 || select=0/8
007/019-th : 0.017 0.024 0.037 0.049 0.075 0.108 0.194 0.498  ||  -1.461 -1.127 -0.674 -0.397 0.029 0.392 0.981 1.925   || dis=0.30 || select=7/8
008/019-th : 0.014 0.020 0.028 0.046 0.071 0.118 0.263 0.440  ||  -1.604 -1.230 -0.882 -0.371 0.059 0.563 1.366 1.879   || dis=0.18 || select=7/8
009/019-th : 0.082 0.086 0.100 0.110 0.121 0.139 0.169 0.194  ||  -0.385 -0.338 -0.183 -0.092 0.009 0.145 0.338 0.476   || dis=0.02 || select=7/8
010/019-th : 0.094 0.094 0.107 0.122 0.125 0.148 0.158 0.152  ||  -0.272 -0.267 -0.139 -0.005 0.017 0.183 0.253 0.213   || dis=0.01 || select=6/8
011/019-th : 0.115 0.112 0.114 0.123 0.124 0.132 0.140 0.140  ||  -0.070 -0.100 -0.082 -0.003 -0.000 0.067 0.126 0.123  || dis=0.00 || select=6/8
012/019-th : 0.142 0.135 0.125 0.124 0.125 0.114 0.117 0.117  ||  0.129 0.081 0.005 -0.003 0.004 -0.088 -0.059 -0.060   || dis=0.01 || select=0/8
013/019-th : 0.006 0.006 0.008 0.008 0.011 0.016 0.029 0.916  ||  -1.199 -1.097 -0.895 -0.832 -0.518 -0.176 0.443 3.888  || dis=0.89 || select=7/8
014/019-th : 0.008 0.010 0.013 0.015 0.022 0.039 0.093 0.802  ||  -1.483 -1.209 -0.983 -0.811 -0.444 0.155 1.017 3.174  || dis=0.71 || select=7/8
015/019-th : 0.005 0.006 0.007 0.008 0.010 0.016 0.034 0.914  ||  -1.220 -1.179 -0.974 -0.779 -0.545 -0.127 0.628 3.930  || dis=0.88 || select=7/8
016/019-th : 0.041 0.051 0.065 0.099 0.129 0.168 0.203 0.244  ||  -0.957 -0.734 -0.498 -0.073 0.193 0.456 0.648 0.828   || dis=0.04 || select=7/8
017/019-th : 0.083 0.101 0.110 0.128 0.134 0.140 0.149 0.155  ||  -0.388 -0.189 -0.105 0.053 0.095 0.140 0.203 0.243    || dis=0.01 || select=7/8
018/019-th : 0.094 0.106 0.130 0.141 0.134 0.131 0.124 0.141  ||  -0.273 -0.145 0.051 0.136 0.082 0.061 0.004 0.134     || dis=0.00 || select=3/8
[epoch=460/600] FLOP : 27.64 MB, ratio : 0.6773, Expected-ratio : 0.7000, Discrepancy : 0.203
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:46:23] [epoch=460/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.104 (1.104)  Prec@1 66.80 (66.80) Prec@5 96.88 (96.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:46:29] [epoch=460/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.709 (2.375)  Prec@1 79.76 (40.84) Prec@5 98.81 (82.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.84 Prec@5 82.10 Error@1 59.16 Error@5 17.90 Loss:2.375
***[2020-01-29 09:46:29]*** VALID [epoch=460/600] loss = 2.375258, accuracy@1 = 40.84, accuracy@5 = 82.10 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:46:29]*** start epoch=461/600 Time Left: [01:14:00], LR=[0.012668 ~ 0.012668], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=461, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7207364534007915, FLOP=40.81
[Search] : epoch=461/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:46:30] [epoch=461/600][000/098] Time 0.70 (0.70) Data 0.39 (0.39) Base-Loss 1.460 (1.460)  Prec@1 46.09 (46.09) Prec@5 94.92 (94.92) Acls-loss 0.483 (0.483) FLOP-Loss 0.000 (0.000) Arch-Loss 0.483 (0.483)
**TRAIN** [2020-01-29 09:46:55] [epoch=461/600][097/098] Time 0.23 (0.27) Data 0.00 (0.00) Base-Loss 0.508 (0.579)  Prec@1 80.36 (80.38) Prec@5 100.00 (98.89) Acls-loss 0.540 (0.678) FLOP-Loss 0.000 (0.210) Arch-Loss 0.540 (1.098)
 **TRAIN** Prec@1 80.38 Prec@5 98.89 Error@1 19.62 Error@5 1.11 Base-Loss:0.579, Arch-Loss=1.098
***[2020-01-29 09:46:55]*** TRAIN [epoch=461/600] base-loss = 0.578702, arch-loss = 1.098355, accuracy-1 = 80.38, accuracy-5 = 98.89
[epoch=461/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 8, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.788352)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.326 0.317 0.357  ||  0.1059 0.0756 0.1954  || discrepancy=0.03 || select=2/3
001/003-th : 0.327 0.235 0.439  ||  0.1151 -0.2157 0.4093  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.027 0.968  ||  -2.3268 -0.7134 2.8763  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.032 0.040 0.042 0.065 0.103 0.195 0.502  ||  -1.325 -0.862 -0.655 -0.608 -0.164 0.292 0.932 1.876  || dis=0.31 || select=7/8
001/019-th : 0.103 0.135 0.149 0.139 0.125 0.123 0.121 0.106  ||  -0.182 0.090 0.187 0.120 0.008 -0.008 -0.023 -0.156   || dis=0.01 || select=2/8
002/019-th : 0.132 0.136 0.135 0.142 0.124 0.122 0.109 0.100  ||  0.069 0.101 0.088 0.144 0.004 -0.012 -0.121 -0.211    || dis=0.01 || select=3/8
003/019-th : 0.105 0.111 0.127 0.133 0.128 0.138 0.128 0.131  ||  -0.167 -0.110 0.024 0.070 0.030 0.106 0.030 0.055     || dis=0.01 || select=5/8
004/019-th : 0.113 0.113 0.114 0.112 0.125 0.135 0.144 0.144  ||  -0.101 -0.097 -0.093 -0.109 0.006 0.078 0.146 0.140   || dis=0.00 || select=6/8
005/019-th : 0.115 0.127 0.131 0.129 0.126 0.126 0.124 0.121  ||  -0.081 0.019 0.052 0.040 0.015 0.015 -0.005 -0.026    || dis=0.00 || select=2/8
006/019-th : 0.143 0.127 0.121 0.123 0.118 0.123 0.124 0.122  ||  0.138 0.018 -0.028 -0.012 -0.054 -0.015 -0.009 -0.025  || dis=0.02 || select=0/8
007/019-th : 0.017 0.023 0.036 0.048 0.075 0.104 0.192 0.506  ||  -1.467 -1.132 -0.679 -0.408 0.039 0.370 0.981 1.951   || dis=0.31 || select=7/8
008/019-th : 0.013 0.020 0.028 0.046 0.070 0.117 0.270 0.437  ||  -1.617 -1.229 -0.882 -0.375 0.053 0.558 1.396 1.877   || dis=0.17 || select=7/8
009/019-th : 0.082 0.086 0.101 0.111 0.122 0.138 0.169 0.192  ||  -0.386 -0.335 -0.174 -0.083 0.011 0.136 0.339 0.469   || dis=0.02 || select=7/8
010/019-th : 0.093 0.094 0.108 0.123 0.125 0.147 0.157 0.152  ||  -0.280 -0.266 -0.133 0.004 0.020 0.178 0.248 0.215    || dis=0.01 || select=6/8
011/019-th : 0.116 0.112 0.114 0.123 0.124 0.131 0.139 0.140  ||  -0.062 -0.096 -0.079 -0.004 0.004 0.056 0.116 0.122   || dis=0.00 || select=7/8
012/019-th : 0.141 0.135 0.125 0.125 0.125 0.114 0.119 0.117  ||  0.124 0.082 0.003 0.001 0.008 -0.091 -0.046 -0.065    || dis=0.01 || select=0/8
013/019-th : 0.006 0.006 0.008 0.008 0.011 0.015 0.029 0.917  ||  -1.190 -1.094 -0.900 -0.836 -0.517 -0.188 0.434 3.898  || dis=0.89 || select=7/8
014/019-th : 0.008 0.010 0.013 0.015 0.021 0.038 0.090 0.806  ||  -1.473 -1.210 -0.971 -0.804 -0.440 0.128 0.998 3.189  || dis=0.72 || select=7/8
015/019-th : 0.005 0.005 0.007 0.008 0.010 0.015 0.033 0.916  ||  -1.211 -1.171 -0.966 -0.808 -0.549 -0.134 0.615 3.947  || dis=0.88 || select=7/8
016/019-th : 0.041 0.051 0.064 0.098 0.129 0.167 0.204 0.246  ||  -0.950 -0.734 -0.504 -0.084 0.192 0.451 0.649 0.836   || dis=0.04 || select=7/8
017/019-th : 0.083 0.101 0.109 0.128 0.134 0.140 0.150 0.155  ||  -0.382 -0.186 -0.111 0.053 0.096 0.138 0.205 0.239    || dis=0.01 || select=7/8
018/019-th : 0.095 0.106 0.130 0.141 0.134 0.130 0.123 0.141  ||  -0.263 -0.152 0.054 0.135 0.082 0.053 0.001 0.135     || dis=0.00 || select=7/8
[epoch=461/600] FLOP : 28.79 MB, ratio : 0.7054, Expected-ratio : 0.7000, Discrepancy : 0.204
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:46:55] [epoch=461/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.210 (1.210)  Prec@1 62.50 (62.50) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:47:01] [epoch=461/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 0.944 (2.406)  Prec@1 66.07 (39.69) Prec@5 97.02 (80.74) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.69 Prec@5 80.74 Error@1 60.31 Error@5 19.26 Loss:2.406
***[2020-01-29 09:47:01]*** VALID [epoch=461/600] loss = 2.406092, accuracy@1 = 39.69, accuracy@5 = 80.74 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:47:01]*** start epoch=462/600 Time Left: [01:13:28], LR=[0.012494 ~ 0.012494], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=462, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.712227879405374, FLOP=40.81
[Search] : epoch=462/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:47:02] [epoch=462/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.419 (0.419)  Prec@1 86.72 (86.72) Prec@5 98.83 (98.83) Acls-loss 0.596 (0.596) FLOP-Loss 2.929 (2.929) Arch-Loss 6.454 (6.454)
**TRAIN** [2020-01-29 09:47:26] [epoch=462/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.652 (0.591)  Prec@1 77.38 (80.12) Prec@5 98.81 (98.74) Acls-loss 0.925 (0.658) FLOP-Loss 0.000 (0.270) Arch-Loss 0.925 (1.197)
 **TRAIN** Prec@1 80.12 Prec@5 98.74 Error@1 19.88 Error@5 1.26 Base-Loss:0.591, Arch-Loss=1.197
***[2020-01-29 09:47:26]*** TRAIN [epoch=462/600] base-loss = 0.590892, arch-loss = 1.197206, accuracy-1 = 80.12, accuracy-5 = 98.74
[epoch=462/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.039548)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.325 0.320 0.355  ||  0.1052 0.0907 0.1921  || discrepancy=0.03 || select=2/3
001/003-th : 0.328 0.237 0.434  ||  0.1205 -0.2027 0.4011  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.027 0.967  ||  -2.3154 -0.7113 2.8652  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.032 0.040 0.042 0.064 0.102 0.194 0.506  ||  -1.327 -0.862 -0.653 -0.606 -0.173 0.289 0.927 1.888  || dis=0.31 || select=7/8
001/019-th : 0.103 0.136 0.150 0.140 0.125 0.121 0.120 0.105  ||  -0.184 0.098 0.197 0.130 0.014 -0.020 -0.032 -0.160   || dis=0.01 || select=2/8
002/019-th : 0.132 0.137 0.135 0.141 0.125 0.122 0.109 0.099  ||  0.069 0.106 0.093 0.136 0.012 -0.012 -0.121 -0.217    || dis=0.00 || select=3/8
003/019-th : 0.106 0.112 0.126 0.133 0.128 0.136 0.128 0.131  ||  -0.155 -0.105 0.014 0.067 0.027 0.089 0.033 0.054     || dis=0.00 || select=5/8
004/019-th : 0.114 0.113 0.115 0.112 0.127 0.132 0.142 0.146  ||  -0.095 -0.097 -0.087 -0.109 0.013 0.058 0.128 0.153   || dis=0.00 || select=7/8
005/019-th : 0.115 0.127 0.132 0.129 0.124 0.127 0.124 0.121  ||  -0.077 0.017 0.059 0.038 -0.001 0.022 -0.005 -0.030   || dis=0.00 || select=2/8
006/019-th : 0.144 0.129 0.122 0.120 0.118 0.121 0.124 0.121  ||  0.145 0.030 -0.019 -0.036 -0.053 -0.027 -0.010 -0.029  || dis=0.01 || select=0/8
007/019-th : 0.016 0.023 0.037 0.047 0.074 0.104 0.191 0.508  ||  -1.476 -1.147 -0.665 -0.417 0.034 0.373 0.987 1.963   || dis=0.32 || select=7/8
008/019-th : 0.013 0.019 0.028 0.045 0.070 0.116 0.266 0.442  ||  -1.622 -1.236 -0.879 -0.378 0.047 0.561 1.389 1.897   || dis=0.18 || select=7/8
009/019-th : 0.083 0.086 0.100 0.112 0.120 0.138 0.168 0.192  ||  -0.376 -0.336 -0.181 -0.068 -0.001 0.133 0.335 0.466  || dis=0.02 || select=7/8
010/019-th : 0.094 0.095 0.108 0.122 0.125 0.148 0.157 0.152  ||  -0.272 -0.263 -0.130 -0.011 0.020 0.184 0.243 0.213   || dis=0.01 || select=6/8
011/019-th : 0.118 0.112 0.114 0.123 0.124 0.129 0.140 0.139  ||  -0.050 -0.098 -0.082 -0.005 0.002 0.045 0.123 0.116   || dis=0.00 || select=6/8
012/019-th : 0.141 0.135 0.126 0.127 0.125 0.113 0.119 0.116  ||  0.126 0.082 0.011 0.019 0.002 -0.098 -0.048 -0.070    || dis=0.01 || select=0/8
013/019-th : 0.006 0.006 0.008 0.008 0.011 0.015 0.028 0.918  ||  -1.200 -1.085 -0.896 -0.829 -0.523 -0.193 0.427 3.905  || dis=0.89 || select=7/8
014/019-th : 0.008 0.010 0.013 0.015 0.021 0.037 0.088 0.809  ||  -1.471 -1.204 -0.963 -0.800 -0.446 0.121 0.978 3.201  || dis=0.72 || select=7/8
015/019-th : 0.005 0.005 0.007 0.008 0.010 0.015 0.032 0.918  ||  -1.199 -1.164 -0.971 -0.813 -0.556 -0.155 0.601 3.967  || dis=0.89 || select=7/8
016/019-th : 0.041 0.051 0.065 0.098 0.130 0.167 0.202 0.247  ||  -0.956 -0.742 -0.498 -0.079 0.198 0.451 0.640 0.842   || dis=0.04 || select=7/8
017/019-th : 0.084 0.102 0.110 0.130 0.134 0.138 0.148 0.154  ||  -0.371 -0.182 -0.102 0.062 0.097 0.120 0.196 0.232    || dis=0.01 || select=7/8
018/019-th : 0.095 0.105 0.132 0.141 0.134 0.130 0.124 0.141  ||  -0.264 -0.156 0.065 0.132 0.080 0.054 0.002 0.132     || dis=0.00 || select=3/8
[epoch=462/600] FLOP : 28.04 MB, ratio : 0.6870, Expected-ratio : 0.7000, Discrepancy : 0.205
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:47:27] [epoch=462/600][000/098] Time 0.38 (0.38) Data 0.27 (0.27) Loss 2.464 (2.464)  Prec@1 40.23 (40.23) Prec@5 80.47 (80.47) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:47:33] [epoch=462/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.276 (2.226)  Prec@1 12.50 (41.29) Prec@5 68.45 (83.15) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.29 Prec@5 83.15 Error@1 58.71 Error@5 16.85 Loss:2.226
***[2020-01-29 09:47:33]*** VALID [epoch=462/600] loss = 2.225747, accuracy@1 = 41.29, accuracy@5 = 83.15 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:47:33]*** start epoch=463/600 Time Left: [01:12:56], LR=[0.012322 ~ 0.012322], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=463, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.7037696888609877, FLOP=40.81
[Search] : epoch=463/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:47:34] [epoch=463/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 0.528 (0.528)  Prec@1 83.59 (83.59) Prec@5 98.83 (98.83) Acls-loss 0.601 (0.601) FLOP-Loss 0.000 (0.000) Arch-Loss 0.601 (0.601)
**TRAIN** [2020-01-29 09:47:58] [epoch=463/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.558 (0.548)  Prec@1 81.55 (81.32) Prec@5 98.81 (98.94) Acls-loss 0.561 (0.662) FLOP-Loss 0.000 (0.330) Arch-Loss 0.561 (1.321)
 **TRAIN** Prec@1 81.32 Prec@5 98.94 Error@1 18.68 Error@5 1.06 Base-Loss:0.548, Arch-Loss=1.321
***[2020-01-29 09:47:58]*** TRAIN [epoch=463/600] base-loss = 0.548042, arch-loss = 1.321074, accuracy-1 = 81.32, accuracy-5 = 98.94
[epoch=463/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.039548)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.328 0.320 0.352  ||  0.1137 0.0883 0.1829  || discrepancy=0.02 || select=2/3
001/003-th : 0.333 0.239 0.428  ||  0.1350 -0.1956 0.3850  || discrepancy=0.09 || select=2/3
002/003-th : 0.005 0.027 0.968  ||  -2.3326 -0.6976 2.8789  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.032 0.039 0.041 0.063 0.101 0.197 0.506  ||  -1.341 -0.852 -0.661 -0.613 -0.183 0.283 0.952 1.897  || dis=0.31 || select=7/8
001/019-th : 0.104 0.135 0.149 0.142 0.126 0.120 0.119 0.106  ||  -0.172 0.089 0.186 0.140 0.017 -0.032 -0.034 -0.154   || dis=0.01 || select=2/8
002/019-th : 0.134 0.139 0.136 0.141 0.121 0.121 0.109 0.098  ||  0.085 0.120 0.099 0.135 -0.017 -0.019 -0.127 -0.229   || dis=0.00 || select=3/8
003/019-th : 0.108 0.114 0.125 0.131 0.128 0.136 0.128 0.131  ||  -0.144 -0.088 0.003 0.054 0.024 0.088 0.027 0.048     || dis=0.01 || select=5/8
004/019-th : 0.115 0.114 0.115 0.114 0.128 0.131 0.140 0.144  ||  -0.085 -0.089 -0.084 -0.089 0.024 0.051 0.113 0.141   || dis=0.00 || select=7/8
005/019-th : 0.117 0.126 0.134 0.129 0.123 0.127 0.126 0.119  ||  -0.066 0.011 0.074 0.033 -0.009 0.017 0.008 -0.046    || dis=0.01 || select=2/8
006/019-th : 0.146 0.129 0.120 0.122 0.120 0.120 0.123 0.120  ||  0.160 0.037 -0.041 -0.025 -0.034 -0.035 -0.016 -0.042  || dis=0.02 || select=0/8
007/019-th : 0.016 0.023 0.036 0.047 0.072 0.103 0.190 0.512  ||  -1.467 -1.140 -0.677 -0.413 0.011 0.371 0.984 1.972   || dis=0.32 || select=7/8
008/019-th : 0.013 0.019 0.027 0.045 0.069 0.119 0.263 0.445  ||  -1.634 -1.233 -0.880 -0.388 0.041 0.588 1.384 1.909   || dis=0.18 || select=7/8
009/019-th : 0.084 0.087 0.100 0.115 0.119 0.137 0.168 0.191  ||  -0.364 -0.329 -0.187 -0.046 -0.017 0.125 0.333 0.459  || dis=0.02 || select=7/8
010/019-th : 0.095 0.096 0.109 0.121 0.126 0.146 0.155 0.151  ||  -0.258 -0.248 -0.118 -0.015 0.026 0.167 0.231 0.201   || dis=0.00 || select=6/8
011/019-th : 0.119 0.114 0.114 0.123 0.124 0.128 0.139 0.138  ||  -0.039 -0.081 -0.079 -0.004 -0.000 0.034 0.114 0.106  || dis=0.00 || select=6/8
012/019-th : 0.142 0.137 0.126 0.126 0.123 0.112 0.118 0.115  ||  0.134 0.098 0.015 0.013 -0.009 -0.101 -0.056 -0.079   || dis=0.00 || select=0/8
013/019-th : 0.006 0.006 0.008 0.008 0.011 0.015 0.028 0.919  ||  -1.192 -1.076 -0.886 -0.822 -0.539 -0.191 0.411 3.910  || dis=0.89 || select=7/8
014/019-th : 0.007 0.010 0.012 0.015 0.020 0.036 0.084 0.815  ||  -1.467 -1.202 -0.967 -0.796 -0.458 0.104 0.957 3.228  || dis=0.73 || select=7/8
015/019-th : 0.005 0.005 0.007 0.008 0.010 0.015 0.032 0.919  ||  -1.183 -1.170 -0.972 -0.825 -0.553 -0.154 0.600 3.973  || dis=0.89 || select=7/8
016/019-th : 0.041 0.051 0.065 0.099 0.129 0.166 0.204 0.244  ||  -0.945 -0.735 -0.493 -0.075 0.189 0.446 0.648 0.830   || dis=0.04 || select=7/8
017/019-th : 0.085 0.103 0.111 0.132 0.132 0.136 0.148 0.153  ||  -0.367 -0.174 -0.098 0.080 0.081 0.106 0.195 0.225    || dis=0.01 || select=7/8
018/019-th : 0.095 0.107 0.131 0.140 0.135 0.130 0.123 0.139  ||  -0.260 -0.142 0.064 0.124 0.091 0.052 -0.002 0.121    || dis=0.00 || select=3/8
[epoch=463/600] FLOP : 28.04 MB, ratio : 0.6870, Expected-ratio : 0.7000, Discrepancy : 0.205
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:47:58] [epoch=463/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.515 (1.515)  Prec@1 54.69 (54.69) Prec@5 94.14 (94.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:48:04] [epoch=463/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.219 (2.294)  Prec@1 63.69 (43.38) Prec@5 94.05 (82.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.38 Prec@5 82.99 Error@1 56.62 Error@5 17.01 Loss:2.294
***[2020-01-29 09:48:04]*** VALID [epoch=463/600] loss = 2.294208, accuracy@1 = 43.38, accuracy@5 = 82.99 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:48:04]*** start epoch=464/600 Time Left: [01:12:24], LR=[0.012150 ~ 0.012150], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=464, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6953621136531971, FLOP=40.81
[Search] : epoch=464/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:48:05] [epoch=464/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.389 (0.389)  Prec@1 87.50 (87.50) Prec@5 100.00 (100.00) Acls-loss 0.884 (0.884) FLOP-Loss 0.000 (0.000) Arch-Loss 0.884 (0.884)
**TRAIN** [2020-01-29 09:48:31] [epoch=464/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.503 (0.566)  Prec@1 82.74 (80.84) Prec@5 98.81 (98.86) Acls-loss 0.510 (0.655) FLOP-Loss 0.000 (0.210) Arch-Loss 0.510 (1.074)
 **TRAIN** Prec@1 80.84 Prec@5 98.86 Error@1 19.16 Error@5 1.14 Base-Loss:0.566, Arch-Loss=1.074
***[2020-01-29 09:48:32]*** TRAIN [epoch=464/600] base-loss = 0.566035, arch-loss = 1.074131, accuracy-1 = 80.84, accuracy-5 = 98.86
[epoch=464/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.039548)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.329 0.322 0.350  ||  0.1157 0.0942 0.1786  || discrepancy=0.02 || select=2/3
001/003-th : 0.335 0.239 0.427  ||  0.1381 -0.2002 0.3819  || discrepancy=0.09 || select=2/3
002/003-th : 0.005 0.027 0.967  ||  -2.3307 -0.6906 2.8758  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.033 0.039 0.042 0.063 0.103 0.195 0.505  ||  -1.338 -0.849 -0.662 -0.607 -0.187 0.302 0.943 1.892  || dis=0.31 || select=7/8
001/019-th : 0.102 0.136 0.150 0.143 0.126 0.119 0.119 0.106  ||  -0.189 0.098 0.199 0.148 0.019 -0.034 -0.037 -0.155   || dis=0.01 || select=2/8
002/019-th : 0.134 0.140 0.136 0.143 0.121 0.120 0.109 0.098  ||  0.084 0.125 0.096 0.147 -0.023 -0.026 -0.127 -0.230   || dis=0.00 || select=3/8
003/019-th : 0.107 0.116 0.124 0.132 0.127 0.137 0.127 0.130  ||  -0.148 -0.075 -0.004 0.059 0.021 0.093 0.019 0.046    || dis=0.01 || select=5/8
004/019-th : 0.116 0.115 0.114 0.114 0.128 0.130 0.140 0.143  ||  -0.077 -0.080 -0.089 -0.088 0.021 0.043 0.115 0.135   || dis=0.00 || select=7/8
005/019-th : 0.117 0.127 0.132 0.128 0.125 0.127 0.126 0.118  ||  -0.061 0.016 0.055 0.030 0.000 0.019 0.012 -0.053     || dis=0.00 || select=2/8
006/019-th : 0.147 0.131 0.120 0.122 0.120 0.121 0.121 0.119  ||  0.165 0.047 -0.038 -0.023 -0.037 -0.026 -0.028 -0.049  || dis=0.02 || select=0/8
007/019-th : 0.016 0.023 0.036 0.046 0.070 0.104 0.188 0.516  ||  -1.473 -1.131 -0.674 -0.434 -0.005 0.385 0.979 1.987  || dis=0.33 || select=7/8
008/019-th : 0.013 0.019 0.027 0.045 0.069 0.117 0.260 0.450  ||  -1.629 -1.238 -0.875 -0.390 0.043 0.578 1.373 1.921   || dis=0.19 || select=7/8
009/019-th : 0.083 0.087 0.101 0.115 0.118 0.137 0.170 0.190  ||  -0.372 -0.330 -0.175 -0.051 -0.020 0.127 0.341 0.454  || dis=0.02 || select=7/8
010/019-th : 0.095 0.097 0.107 0.123 0.127 0.146 0.154 0.151  ||  -0.258 -0.243 -0.138 -0.005 0.030 0.171 0.221 0.206   || dis=0.00 || select=6/8
011/019-th : 0.120 0.115 0.115 0.124 0.123 0.129 0.138 0.137  ||  -0.028 -0.073 -0.078 -0.001 -0.010 0.036 0.106 0.097  || dis=0.00 || select=6/8
012/019-th : 0.143 0.138 0.127 0.126 0.124 0.112 0.117 0.114  ||  0.139 0.101 0.019 0.009 -0.005 -0.108 -0.059 -0.084   || dis=0.00 || select=0/8
013/019-th : 0.005 0.006 0.008 0.008 0.011 0.015 0.027 0.920  ||  -1.209 -1.066 -0.879 -0.815 -0.534 -0.197 0.395 3.922  || dis=0.89 || select=7/8
014/019-th : 0.007 0.010 0.012 0.014 0.020 0.035 0.084 0.817  ||  -1.467 -1.213 -0.977 -0.800 -0.454 0.096 0.967 3.240  || dis=0.73 || select=7/8
015/019-th : 0.005 0.005 0.007 0.007 0.010 0.015 0.032 0.918  ||  -1.169 -1.173 -0.969 -0.841 -0.551 -0.148 0.608 3.970  || dis=0.89 || select=7/8
016/019-th : 0.041 0.051 0.064 0.099 0.127 0.168 0.204 0.246  ||  -0.949 -0.741 -0.510 -0.071 0.180 0.459 0.652 0.839   || dis=0.04 || select=7/8
017/019-th : 0.084 0.103 0.111 0.132 0.133 0.135 0.148 0.154  ||  -0.377 -0.168 -0.094 0.078 0.083 0.102 0.190 0.232    || dis=0.01 || select=7/8
018/019-th : 0.095 0.107 0.131 0.140 0.135 0.130 0.123 0.139  ||  -0.262 -0.139 0.060 0.124 0.088 0.052 0.001 0.122     || dis=0.00 || select=3/8
[epoch=464/600] FLOP : 28.04 MB, ratio : 0.6870, Expected-ratio : 0.7000, Discrepancy : 0.205
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:48:32] [epoch=464/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.498 (1.498)  Prec@1 64.84 (64.84) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:48:38] [epoch=464/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.227 (2.452)  Prec@1 25.60 (40.89) Prec@5 64.29 (81.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.89 Prec@5 81.08 Error@1 59.11 Error@5 18.92 Loss:2.452
***[2020-01-29 09:48:38]*** VALID [epoch=464/600] loss = 2.451786, accuracy@1 = 40.89, accuracy@5 = 81.08 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:48:38]*** start epoch=465/600 Time Left: [01:11:52], LR=[0.011980 ~ 0.011980], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=465, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6870053842799242, FLOP=40.81
[Search] : epoch=465/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:48:39] [epoch=465/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.493 (0.493)  Prec@1 82.03 (82.03) Prec@5 99.61 (99.61) Acls-loss 0.885 (0.885) FLOP-Loss 0.000 (0.000) Arch-Loss 0.885 (0.885)
**TRAIN** [2020-01-29 09:49:03] [epoch=465/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.507 (0.568)  Prec@1 85.12 (80.29) Prec@5 99.40 (99.00) Acls-loss 0.586 (0.677) FLOP-Loss 0.000 (0.060) Arch-Loss 0.586 (0.797)
 **TRAIN** Prec@1 80.29 Prec@5 99.00 Error@1 19.71 Error@5 1.00 Base-Loss:0.568, Arch-Loss=0.797
***[2020-01-29 09:49:03]*** TRAIN [epoch=465/600] base-loss = 0.567897, arch-loss = 0.796815, accuracy-1 = 80.29, accuracy-5 = 99.00
[epoch=465/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.039548)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.325 0.323 0.352  ||  0.1065 0.1009 0.1854  || discrepancy=0.03 || select=2/3
001/003-th : 0.332 0.240 0.428  ||  0.1314 -0.1915 0.3863  || discrepancy=0.10 || select=2/3
002/003-th : 0.005 0.027 0.967  ||  -2.3270 -0.6967 2.8743  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.020 0.032 0.039 0.041 0.062 0.101 0.194 0.512  ||  -1.349 -0.867 -0.656 -0.611 -0.194 0.294 0.948 1.918  || dis=0.32 || select=7/8
001/019-th : 0.102 0.134 0.150 0.143 0.126 0.118 0.119 0.108  ||  -0.192 0.082 0.199 0.152 0.023 -0.042 -0.038 -0.137   || dis=0.01 || select=2/8
002/019-th : 0.134 0.138 0.136 0.141 0.122 0.122 0.109 0.099  ||  0.081 0.114 0.097 0.129 -0.012 -0.013 -0.129 -0.224   || dis=0.00 || select=3/8
003/019-th : 0.107 0.115 0.121 0.132 0.128 0.137 0.128 0.132  ||  -0.150 -0.081 -0.025 0.054 0.024 0.092 0.027 0.061    || dis=0.01 || select=5/8
004/019-th : 0.115 0.114 0.113 0.115 0.127 0.131 0.141 0.143  ||  -0.080 -0.090 -0.100 -0.080 0.019 0.048 0.123 0.138   || dis=0.00 || select=7/8
005/019-th : 0.117 0.126 0.129 0.128 0.125 0.129 0.127 0.119  ||  -0.060 0.013 0.037 0.024 0.001 0.035 0.016 -0.050     || dis=0.00 || select=2/8
006/019-th : 0.145 0.131 0.118 0.120 0.121 0.123 0.123 0.119  ||  0.151 0.048 -0.051 -0.038 -0.028 -0.009 -0.015 -0.045  || dis=0.01 || select=0/8
007/019-th : 0.016 0.023 0.036 0.045 0.070 0.103 0.188 0.520  ||  -1.474 -1.133 -0.673 -0.438 -0.012 0.381 0.980 1.998  || dis=0.33 || select=7/8
008/019-th : 0.013 0.019 0.027 0.045 0.069 0.116 0.258 0.454  ||  -1.629 -1.239 -0.887 -0.386 0.047 0.568 1.371 1.933   || dis=0.20 || select=7/8
009/019-th : 0.082 0.086 0.099 0.113 0.120 0.140 0.168 0.193  ||  -0.387 -0.336 -0.197 -0.060 -0.002 0.151 0.336 0.471  || dis=0.02 || select=7/8
010/019-th : 0.095 0.097 0.107 0.122 0.127 0.146 0.154 0.151  ||  -0.260 -0.234 -0.140 -0.006 0.032 0.167 0.224 0.202   || dis=0.00 || select=6/8
011/019-th : 0.121 0.113 0.115 0.126 0.123 0.128 0.138 0.137  ||  -0.026 -0.089 -0.075 0.013 -0.005 0.029 0.107 0.097   || dis=0.00 || select=6/8
012/019-th : 0.142 0.135 0.127 0.123 0.126 0.114 0.118 0.115  ||  0.134 0.084 0.017 -0.013 0.011 -0.092 -0.052 -0.076   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.008 0.011 0.015 0.027 0.921  ||  -1.217 -1.082 -0.886 -0.810 -0.529 -0.200 0.398 3.931  || dis=0.89 || select=7/8
014/019-th : 0.007 0.009 0.012 0.014 0.020 0.035 0.083 0.820  ||  -1.468 -1.208 -0.984 -0.806 -0.471 0.097 0.963 3.258  || dis=0.74 || select=7/8
015/019-th : 0.005 0.005 0.007 0.007 0.010 0.015 0.031 0.919  ||  -1.157 -1.165 -0.964 -0.837 -0.557 -0.151 0.591 3.975  || dis=0.89 || select=7/8
016/019-th : 0.041 0.051 0.063 0.098 0.126 0.167 0.207 0.247  ||  -0.945 -0.740 -0.516 -0.079 0.168 0.454 0.665 0.845   || dis=0.04 || select=7/8
017/019-th : 0.083 0.103 0.111 0.131 0.131 0.136 0.150 0.155  ||  -0.386 -0.171 -0.095 0.071 0.070 0.106 0.204 0.240    || dis=0.01 || select=7/8
018/019-th : 0.096 0.108 0.130 0.140 0.135 0.129 0.124 0.139  ||  -0.255 -0.136 0.052 0.125 0.089 0.045 0.007 0.116     || dis=0.00 || select=3/8
[epoch=465/600] FLOP : 28.04 MB, ratio : 0.6870, Expected-ratio : 0.7000, Discrepancy : 0.206
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:49:04] [epoch=465/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.048 (1.048)  Prec@1 65.62 (65.62) Prec@5 96.09 (96.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:49:10] [epoch=465/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.237 (2.461)  Prec@1 50.60 (40.02) Prec@5 90.48 (81.56) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.02 Prec@5 81.56 Error@1 59.98 Error@5 18.44 Loss:2.461
***[2020-01-29 09:49:10]*** VALID [epoch=465/600] loss = 2.461244, accuracy@1 = 40.02, accuracy@5 = 81.56 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:49:10]*** start epoch=466/600 Time Left: [01:11:20], LR=[0.011810 ~ 0.011810], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=466, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6786997298451274, FLOP=40.81
[Search] : epoch=466/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:49:10] [epoch=466/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.614 (0.614)  Prec@1 78.91 (78.91) Prec@5 99.61 (99.61) Acls-loss 0.540 (0.540) FLOP-Loss 0.000 (0.000) Arch-Loss 0.540 (0.540)
**TRAIN** [2020-01-29 09:49:34] [epoch=466/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.618 (0.556)  Prec@1 79.76 (81.09) Prec@5 98.21 (99.05) Acls-loss 0.658 (0.676) FLOP-Loss 0.000 (0.030) Arch-Loss 0.658 (0.735)
 **TRAIN** Prec@1 81.09 Prec@5 99.05 Error@1 18.91 Error@5 0.95 Base-Loss:0.556, Arch-Loss=0.735
***[2020-01-29 09:49:35]*** TRAIN [epoch=466/600] base-loss = 0.555545, arch-loss = 0.735492, accuracy-1 = 81.09, accuracy-5 = 99.05
[epoch=466/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.38054)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.321 0.325 0.354  ||  0.0946 0.1098 0.1943  || discrepancy=0.03 || select=2/3
001/003-th : 0.328 0.240 0.432  ||  0.1216 -0.1910 0.3952  || discrepancy=0.10 || select=2/3
002/003-th : 0.005 0.027 0.967  ||  -2.3198 -0.6946 2.8673  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.019 0.032 0.038 0.040 0.061 0.099 0.191 0.520  ||  -1.353 -0.858 -0.663 -0.618 -0.195 0.282 0.939 1.942  || dis=0.33 || select=7/8
001/019-th : 0.099 0.132 0.149 0.143 0.127 0.121 0.120 0.108  ||  -0.218 0.073 0.196 0.153 0.033 -0.014 -0.022 -0.131   || dis=0.01 || select=2/8
002/019-th : 0.132 0.138 0.135 0.142 0.121 0.122 0.111 0.100  ||  0.070 0.109 0.087 0.140 -0.017 -0.016 -0.111 -0.215   || dis=0.00 || select=3/8
003/019-th : 0.107 0.113 0.121 0.131 0.129 0.137 0.129 0.133  ||  -0.152 -0.098 -0.028 0.054 0.031 0.093 0.037 0.068    || dis=0.00 || select=5/8
004/019-th : 0.114 0.113 0.112 0.115 0.128 0.131 0.141 0.145  ||  -0.088 -0.100 -0.111 -0.081 0.027 0.052 0.126 0.151   || dis=0.00 || select=7/8
005/019-th : 0.117 0.126 0.130 0.128 0.127 0.127 0.126 0.119  ||  -0.067 0.011 0.039 0.028 0.023 0.023 0.010 -0.044     || dis=0.00 || select=2/8
006/019-th : 0.144 0.130 0.119 0.121 0.121 0.124 0.123 0.118  ||  0.146 0.046 -0.048 -0.029 -0.029 -0.004 -0.009 -0.052  || dis=0.01 || select=0/8
007/019-th : 0.016 0.022 0.035 0.045 0.069 0.101 0.185 0.527  ||  -1.467 -1.159 -0.682 -0.431 -0.016 0.370 0.978 2.023  || dis=0.34 || select=7/8
008/019-th : 0.013 0.019 0.026 0.045 0.068 0.114 0.258 0.459  ||  -1.626 -1.249 -0.903 -0.379 0.039 0.557 1.376 1.954   || dis=0.20 || select=7/8
009/019-th : 0.080 0.084 0.098 0.113 0.121 0.139 0.169 0.197  ||  -0.401 -0.351 -0.206 -0.062 0.010 0.146 0.341 0.496   || dis=0.03 || select=7/8
010/019-th : 0.092 0.097 0.106 0.120 0.127 0.149 0.155 0.154  ||  -0.290 -0.236 -0.151 -0.020 0.036 0.194 0.230 0.223   || dis=0.00 || select=6/8
011/019-th : 0.121 0.113 0.113 0.125 0.121 0.125 0.141 0.141  ||  -0.026 -0.090 -0.096 0.011 -0.025 0.006 0.126 0.127   || dis=0.00 || select=7/8
012/019-th : 0.140 0.134 0.127 0.121 0.126 0.116 0.118 0.117  ||  0.119 0.073 0.022 -0.027 0.011 -0.072 -0.052 -0.058   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.008 0.010 0.015 0.026 0.922  ||  -1.209 -1.074 -0.879 -0.821 -0.532 -0.201 0.373 3.946  || dis=0.90 || select=7/8
014/019-th : 0.007 0.009 0.012 0.014 0.019 0.034 0.081 0.824  ||  -1.463 -1.222 -0.983 -0.800 -0.479 0.082 0.958 3.280  || dis=0.74 || select=7/8
015/019-th : 0.005 0.005 0.007 0.007 0.010 0.015 0.031 0.920  ||  -1.141 -1.158 -0.956 -0.832 -0.558 -0.165 0.577 3.979  || dis=0.89 || select=7/8
016/019-th : 0.040 0.051 0.061 0.098 0.126 0.171 0.202 0.251  ||  -0.963 -0.735 -0.545 -0.080 0.174 0.479 0.647 0.866   || dis=0.05 || select=7/8
017/019-th : 0.082 0.102 0.110 0.131 0.130 0.135 0.151 0.158  ||  -0.394 -0.178 -0.101 0.071 0.062 0.099 0.210 0.258    || dis=0.01 || select=7/8
018/019-th : 0.096 0.106 0.129 0.140 0.133 0.131 0.126 0.138  ||  -0.255 -0.148 0.047 0.126 0.078 0.063 0.017 0.115     || dis=0.00 || select=3/8
[epoch=466/600] FLOP : 28.38 MB, ratio : 0.6954, Expected-ratio : 0.7000, Discrepancy : 0.209
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:49:35] [epoch=466/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.127 (3.127)  Prec@1 16.02 (16.02) Prec@5 61.33 (61.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:49:41] [epoch=466/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.618 (2.226)  Prec@1 38.69 (43.14) Prec@5 76.79 (82.06) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.14 Prec@5 82.06 Error@1 56.86 Error@5 17.94 Loss:2.226
***[2020-01-29 09:49:41]*** VALID [epoch=466/600] loss = 2.225664, accuracy@1 = 43.14, accuracy@5 = 82.06 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:49:41]*** start epoch=467/600 Time Left: [01:10:48], LR=[0.011642 ~ 0.011642], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=467, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6704453780525165, FLOP=40.81
[Search] : epoch=467/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:49:42] [epoch=467/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.518 (0.518)  Prec@1 81.25 (81.25) Prec@5 100.00 (100.00) Acls-loss 0.570 (0.570) FLOP-Loss 0.000 (0.000) Arch-Loss 0.570 (0.570)
**TRAIN** [2020-01-29 09:50:06] [epoch=467/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.384 (0.550)  Prec@1 86.90 (81.23) Prec@5 100.00 (98.95) Acls-loss 0.532 (0.664) FLOP-Loss 0.000 (0.180) Arch-Loss 0.532 (1.025)
 **TRAIN** Prec@1 81.23 Prec@5 98.95 Error@1 18.77 Error@5 1.05 Base-Loss:0.550, Arch-Loss=1.025
***[2020-01-29 09:50:06]*** TRAIN [epoch=467/600] base-loss = 0.550237, arch-loss = 1.025044, accuracy-1 = 81.23, accuracy-5 = 98.95
[epoch=467/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 9, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.223868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.317 0.330 0.353  ||  0.0884 0.1291 0.1949  || discrepancy=0.02 || select=2/3
001/003-th : 0.328 0.239 0.433  ||  0.1201 -0.1950 0.3966  || discrepancy=0.10 || select=2/3
002/003-th : 0.006 0.028 0.966  ||  -2.3088 -0.6809 2.8532  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.019 0.031 0.037 0.039 0.060 0.097 0.189 0.528  ||  -1.368 -0.876 -0.675 -0.625 -0.195 0.279 0.947 1.975  || dis=0.34 || select=7/8
001/019-th : 0.099 0.130 0.150 0.144 0.128 0.122 0.119 0.108  ||  -0.214 0.060 0.202 0.157 0.041 -0.006 -0.028 -0.131   || dis=0.01 || select=2/8
002/019-th : 0.129 0.139 0.133 0.142 0.123 0.123 0.112 0.099  ||  0.049 0.117 0.073 0.144 -0.002 -0.002 -0.098 -0.218   || dis=0.00 || select=3/8
003/019-th : 0.108 0.114 0.121 0.130 0.129 0.137 0.129 0.133  ||  -0.147 -0.092 -0.029 0.043 0.034 0.093 0.033 0.064    || dis=0.00 || select=5/8
004/019-th : 0.113 0.113 0.113 0.115 0.128 0.132 0.141 0.145  ||  -0.100 -0.101 -0.102 -0.079 0.025 0.059 0.127 0.152   || dis=0.00 || select=7/8
005/019-th : 0.118 0.127 0.128 0.129 0.128 0.127 0.126 0.119  ||  -0.057 0.015 0.026 0.030 0.023 0.021 0.008 -0.049     || dis=0.00 || select=3/8
006/019-th : 0.144 0.131 0.119 0.120 0.121 0.123 0.124 0.118  ||  0.146 0.051 -0.046 -0.033 -0.030 -0.013 -0.004 -0.053  || dis=0.01 || select=0/8
007/019-th : 0.016 0.022 0.035 0.045 0.068 0.099 0.180 0.534  ||  -1.459 -1.150 -0.677 -0.432 -0.019 0.356 0.954 2.040  || dis=0.35 || select=7/8
008/019-th : 0.013 0.018 0.026 0.044 0.067 0.111 0.253 0.469  ||  -1.628 -1.276 -0.910 -0.376 0.046 0.549 1.371 1.989   || dis=0.22 || select=7/8
009/019-th : 0.081 0.085 0.098 0.113 0.118 0.138 0.169 0.199  ||  -0.398 -0.347 -0.203 -0.057 -0.014 0.139 0.340 0.505  || dis=0.03 || select=7/8
010/019-th : 0.092 0.097 0.106 0.120 0.129 0.147 0.155 0.154  ||  -0.288 -0.235 -0.145 -0.028 0.046 0.178 0.229 0.228   || dis=0.00 || select=6/8
011/019-th : 0.122 0.113 0.111 0.125 0.122 0.125 0.142 0.140  ||  -0.014 -0.096 -0.115 0.007 -0.013 0.010 0.135 0.120   || dis=0.00 || select=6/8
012/019-th : 0.140 0.133 0.126 0.121 0.125 0.119 0.117 0.118  ||  0.119 0.068 0.011 -0.027 0.003 -0.046 -0.062 -0.053   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.008 0.010 0.014 0.025 0.926  ||  -1.200 -1.066 -0.874 -0.815 -0.555 -0.234 0.350 3.976  || dis=0.90 || select=7/8
014/019-th : 0.007 0.009 0.011 0.014 0.018 0.032 0.077 0.832  ||  -1.455 -1.218 -0.989 -0.799 -0.509 0.066 0.941 3.319  || dis=0.76 || select=7/8
015/019-th : 0.006 0.005 0.007 0.007 0.010 0.014 0.030 0.921  ||  -1.125 -1.156 -0.959 -0.834 -0.554 -0.187 0.577 3.988  || dis=0.89 || select=7/8
016/019-th : 0.040 0.051 0.061 0.096 0.128 0.170 0.203 0.252  ||  -0.960 -0.733 -0.548 -0.100 0.189 0.477 0.651 0.869   || dis=0.05 || select=7/8
017/019-th : 0.083 0.104 0.110 0.130 0.131 0.133 0.151 0.158  ||  -0.390 -0.167 -0.102 0.064 0.068 0.084 0.212 0.254    || dis=0.01 || select=7/8
018/019-th : 0.096 0.105 0.130 0.140 0.134 0.131 0.126 0.138  ||  -0.252 -0.159 0.054 0.127 0.085 0.059 0.021 0.110     || dis=0.00 || select=3/8
[epoch=467/600] FLOP : 28.22 MB, ratio : 0.6915, Expected-ratio : 0.7000, Discrepancy : 0.211
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:50:07] [epoch=467/600][000/098] Time 0.42 (0.42) Data 0.31 (0.31) Loss 3.060 (3.060)  Prec@1 25.78 (25.78) Prec@5 71.88 (71.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:50:13] [epoch=467/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.491 (2.280)  Prec@1 9.52 (39.30) Prec@5 61.31 (81.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.30 Prec@5 81.40 Error@1 60.70 Error@5 18.60 Loss:2.280
***[2020-01-29 09:50:13]*** VALID [epoch=467/600] loss = 2.279521, accuracy@1 = 39.30, accuracy@5 = 81.40 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:50:13]*** start epoch=468/600 Time Left: [01:10:16], LR=[0.011474 ~ 0.011474], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=468, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6622425551993166, FLOP=40.81
[Search] : epoch=468/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:50:14] [epoch=468/600][000/098] Time 0.76 (0.76) Data 0.39 (0.39) Base-Loss 0.518 (0.518)  Prec@1 80.47 (80.47) Prec@5 99.22 (99.22) Acls-loss 0.578 (0.578) FLOP-Loss 0.000 (0.000) Arch-Loss 0.578 (0.578)
**TRAIN** [2020-01-29 09:50:40] [epoch=468/600][097/098] Time 0.27 (0.27) Data 0.00 (0.00) Base-Loss 0.626 (0.562)  Prec@1 77.38 (80.69) Prec@5 99.40 (98.96) Acls-loss 0.616 (0.663) FLOP-Loss 0.000 (0.000) Arch-Loss 0.616 (0.663)
 **TRAIN** Prec@1 80.69 Prec@5 98.96 Error@1 19.31 Error@5 1.04 Base-Loss:0.562, Arch-Loss=0.663
***[2020-01-29 09:50:40]*** TRAIN [epoch=468/600] base-loss = 0.562251, arch-loss = 0.662965, accuracy-1 = 80.69, accuracy-5 = 98.96
[epoch=468/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.372348)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.308 0.334 0.358  ||  0.0644 0.1452 0.2143  || discrepancy=0.02 || select=2/3
001/003-th : 0.324 0.239 0.437  ||  0.1093 -0.1981 0.4071  || discrepancy=0.11 || select=2/3
002/003-th : 0.006 0.028 0.967  ||  -2.3090 -0.6911 2.8570  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.018 0.030 0.037 0.039 0.059 0.096 0.185 0.536  ||  -1.370 -0.871 -0.682 -0.626 -0.211 0.276 0.938 1.999  || dis=0.35 || select=7/8
001/019-th : 0.098 0.128 0.149 0.140 0.130 0.123 0.122 0.110  ||  -0.223 0.039 0.190 0.132 0.053 0.004 -0.004 -0.114    || dis=0.01 || select=2/8
002/019-th : 0.127 0.136 0.131 0.140 0.125 0.125 0.114 0.102  ||  0.032 0.097 0.062 0.123 0.010 0.016 -0.082 -0.196     || dis=0.00 || select=3/8
003/019-th : 0.106 0.113 0.122 0.132 0.129 0.136 0.130 0.133  ||  -0.163 -0.100 -0.023 0.058 0.036 0.090 0.043 0.068    || dis=0.00 || select=5/8
004/019-th : 0.112 0.111 0.112 0.114 0.127 0.133 0.144 0.146  ||  -0.104 -0.117 -0.107 -0.091 0.015 0.066 0.146 0.161   || dis=0.00 || select=7/8
005/019-th : 0.116 0.125 0.129 0.129 0.127 0.127 0.128 0.120  ||  -0.070 0.004 0.032 0.032 0.022 0.016 0.025 -0.042     || dis=0.00 || select=2/8
006/019-th : 0.143 0.130 0.118 0.120 0.121 0.121 0.126 0.121  ||  0.135 0.044 -0.059 -0.039 -0.029 -0.030 0.012 -0.032  || dis=0.01 || select=0/8
007/019-th : 0.016 0.022 0.034 0.044 0.067 0.097 0.179 0.541  ||  -1.467 -1.157 -0.691 -0.434 -0.017 0.343 0.961 2.065  || dis=0.36 || select=7/8
008/019-th : 0.013 0.017 0.025 0.044 0.064 0.111 0.250 0.476  ||  -1.624 -1.289 -0.918 -0.377 0.014 0.554 1.371 2.015   || dis=0.23 || select=7/8
009/019-th : 0.080 0.084 0.097 0.112 0.119 0.137 0.168 0.202  ||  -0.400 -0.351 -0.207 -0.064 -0.011 0.134 0.339 0.520  || dis=0.03 || select=7/8
010/019-th : 0.090 0.097 0.104 0.119 0.129 0.148 0.156 0.156  ||  -0.312 -0.230 -0.162 -0.028 0.052 0.185 0.239 0.242   || dis=0.00 || select=7/8
011/019-th : 0.121 0.112 0.111 0.125 0.124 0.124 0.143 0.140  ||  -0.026 -0.104 -0.107 0.009 -0.002 0.002 0.144 0.122   || dis=0.00 || select=6/8
012/019-th : 0.139 0.132 0.125 0.122 0.126 0.119 0.119 0.119  ||  0.110 0.056 0.001 -0.020 0.008 -0.041 -0.049 -0.046   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.008 0.010 0.013 0.024 0.927  ||  -1.192 -1.057 -0.876 -0.809 -0.556 -0.249 0.337 3.986  || dis=0.90 || select=7/8
014/019-th : 0.007 0.009 0.011 0.013 0.018 0.031 0.076 0.835  ||  -1.448 -1.214 -0.986 -0.799 -0.516 0.053 0.931 3.333  || dis=0.76 || select=7/8
015/019-th : 0.006 0.005 0.007 0.007 0.010 0.014 0.030 0.921  ||  -1.112 -1.157 -0.953 -0.825 -0.556 -0.199 0.567 3.994  || dis=0.89 || select=7/8
016/019-th : 0.039 0.050 0.061 0.094 0.127 0.168 0.203 0.257  ||  -0.982 -0.739 -0.549 -0.111 0.192 0.469 0.660 0.893   || dis=0.05 || select=7/8
017/019-th : 0.082 0.103 0.110 0.130 0.131 0.132 0.153 0.158  ||  -0.395 -0.174 -0.102 0.063 0.067 0.078 0.225 0.259    || dis=0.01 || select=7/8
018/019-th : 0.094 0.106 0.129 0.139 0.133 0.132 0.128 0.139  ||  -0.273 -0.156 0.047 0.122 0.073 0.069 0.039 0.118     || dis=0.00 || select=3/8
[epoch=468/600] FLOP : 28.37 MB, ratio : 0.6952, Expected-ratio : 0.7000, Discrepancy : 0.214
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:50:41] [epoch=468/600][000/098] Time 0.39 (0.39) Data 0.29 (0.29) Loss 3.822 (3.822)  Prec@1 39.84 (39.84) Prec@5 86.33 (86.33) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:50:47] [epoch=468/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.914 (2.294)  Prec@1 25.60 (41.56) Prec@5 86.31 (82.61) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.56 Prec@5 82.61 Error@1 58.44 Error@5 17.39 Loss:2.294
***[2020-01-29 09:50:47]*** VALID [epoch=468/600] loss = 2.294310, accuracy@1 = 41.56, accuracy@5 = 82.61 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:50:47]*** start epoch=469/600 Time Left: [01:09:45], LR=[0.011308 ~ 0.011308], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=469, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.65409148617006, FLOP=40.81
[Search] : epoch=469/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:50:48] [epoch=469/600][000/098] Time 0.72 (0.72) Data 0.38 (0.38) Base-Loss 0.414 (0.414)  Prec@1 85.55 (85.55) Prec@5 99.61 (99.61) Acls-loss 0.693 (0.693) FLOP-Loss 0.000 (0.000) Arch-Loss 0.693 (0.693)
**TRAIN** [2020-01-29 09:51:14] [epoch=469/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 0.535 (0.583)  Prec@1 81.55 (80.22) Prec@5 98.81 (98.81) Acls-loss 1.306 (0.679) FLOP-Loss 0.000 (0.241) Arch-Loss 1.306 (1.161)
 **TRAIN** Prec@1 80.22 Prec@5 98.81 Error@1 19.78 Error@5 1.19 Base-Loss:0.583, Arch-Loss=1.161
***[2020-01-29 09:51:14]*** TRAIN [epoch=469/600] base-loss = 0.582871, arch-loss = 1.161196, accuracy-1 = 80.22, accuracy-5 = 98.81
[epoch=469/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.372348)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.304 0.337 0.359  ||  0.0545 0.1588 0.2196  || discrepancy=0.02 || select=2/3
001/003-th : 0.328 0.240 0.432  ||  0.1190 -0.1942 0.3959  || discrepancy=0.10 || select=2/3
002/003-th : 0.006 0.028 0.966  ||  -2.2964 -0.6837 2.8431  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.018 0.030 0.036 0.038 0.057 0.094 0.182 0.545  ||  -1.384 -0.866 -0.680 -0.642 -0.220 0.270 0.931 2.031  || dis=0.36 || select=7/8
001/019-th : 0.098 0.129 0.148 0.138 0.130 0.123 0.122 0.111  ||  -0.225 0.048 0.186 0.113 0.058 0.000 -0.011 -0.106    || dis=0.01 || select=2/8
002/019-th : 0.127 0.135 0.131 0.139 0.125 0.126 0.114 0.102  ||  0.031 0.092 0.060 0.118 0.008 0.023 -0.083 -0.192     || dis=0.00 || select=3/8
003/019-th : 0.106 0.114 0.121 0.129 0.130 0.136 0.130 0.132  ||  -0.159 -0.087 -0.025 0.039 0.044 0.089 0.045 0.061    || dis=0.00 || select=5/8
004/019-th : 0.113 0.113 0.111 0.110 0.124 0.133 0.148 0.148  ||  -0.103 -0.100 -0.118 -0.123 -0.007 0.062 0.168 0.170  || dis=0.00 || select=7/8
005/019-th : 0.118 0.126 0.129 0.128 0.127 0.126 0.127 0.119  ||  -0.060 0.008 0.031 0.029 0.016 0.011 0.021 -0.045     || dis=0.00 || select=2/8
006/019-th : 0.144 0.130 0.119 0.122 0.120 0.121 0.125 0.119  ||  0.142 0.041 -0.048 -0.018 -0.037 -0.025 0.004 -0.044  || dis=0.01 || select=0/8
007/019-th : 0.015 0.021 0.033 0.043 0.068 0.095 0.179 0.546  ||  -1.511 -1.152 -0.722 -0.445 0.011 0.347 0.982 2.096   || dis=0.37 || select=7/8
008/019-th : 0.013 0.017 0.025 0.044 0.064 0.109 0.247 0.480  ||  -1.615 -1.292 -0.922 -0.371 0.014 0.546 1.360 2.024   || dis=0.23 || select=7/8
009/019-th : 0.081 0.085 0.098 0.112 0.118 0.138 0.166 0.202  ||  -0.388 -0.347 -0.204 -0.070 -0.016 0.138 0.327 0.518  || dis=0.04 || select=7/8
010/019-th : 0.091 0.097 0.104 0.120 0.128 0.148 0.155 0.157  ||  -0.302 -0.233 -0.166 -0.026 0.041 0.187 0.234 0.244   || dis=0.00 || select=7/8
011/019-th : 0.122 0.111 0.113 0.125 0.122 0.125 0.143 0.139  ||  -0.017 -0.109 -0.096 0.010 -0.014 0.005 0.145 0.112   || dis=0.00 || select=6/8
012/019-th : 0.139 0.133 0.125 0.122 0.125 0.118 0.119 0.118  ||  0.108 0.064 0.007 -0.018 0.006 -0.052 -0.041 -0.054   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.013 0.024 0.929  ||  -1.182 -1.047 -0.876 -0.815 -0.578 -0.287 0.339 4.012  || dis=0.91 || select=7/8
014/019-th : 0.007 0.009 0.011 0.013 0.018 0.031 0.076 0.835  ||  -1.435 -1.238 -0.977 -0.793 -0.511 0.046 0.941 3.335  || dis=0.76 || select=7/8
015/019-th : 0.006 0.005 0.006 0.007 0.010 0.014 0.029 0.923  ||  -1.100 -1.151 -0.971 -0.823 -0.546 -0.209 0.553 4.006  || dis=0.89 || select=7/8
016/019-th : 0.039 0.051 0.061 0.095 0.127 0.168 0.204 0.255  ||  -0.992 -0.732 -0.540 -0.104 0.187 0.469 0.666 0.888   || dis=0.05 || select=7/8
017/019-th : 0.084 0.104 0.111 0.131 0.133 0.129 0.151 0.157  ||  -0.379 -0.159 -0.102 0.071 0.081 0.054 0.207 0.248    || dis=0.01 || select=7/8
018/019-th : 0.095 0.107 0.131 0.140 0.130 0.131 0.127 0.139  ||  -0.258 -0.146 0.058 0.127 0.054 0.057 0.025 0.118     || dis=0.00 || select=3/8
[epoch=469/600] FLOP : 28.37 MB, ratio : 0.6952, Expected-ratio : 0.7000, Discrepancy : 0.215
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:51:15] [epoch=469/600][000/098] Time 0.39 (0.39) Data 0.31 (0.31) Loss 4.857 (4.857)  Prec@1 22.66 (22.66) Prec@5 63.67 (63.67) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:51:21] [epoch=469/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.438 (2.307)  Prec@1 20.83 (39.94) Prec@5 47.62 (81.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 39.94 Prec@5 81.60 Error@1 60.06 Error@5 18.40 Loss:2.307
***[2020-01-29 09:51:21]*** VALID [epoch=469/600] loss = 2.306775, accuracy@1 = 39.94, accuracy@5 = 81.60 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:51:21]*** start epoch=470/600 Time Left: [01:09:14], LR=[0.011143 ~ 0.011143], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=470, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6459923944304213, FLOP=40.81
[Search] : epoch=470/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:51:22] [epoch=470/600][000/098] Time 0.71 (0.71) Data 0.40 (0.40) Base-Loss 0.485 (0.485)  Prec@1 84.38 (84.38) Prec@5 98.44 (98.44) Acls-loss 1.038 (1.038) FLOP-Loss 0.000 (0.000) Arch-Loss 1.038 (1.038)
**TRAIN** [2020-01-29 09:51:49] [epoch=470/600][097/098] Time 0.28 (0.28) Data 0.00 (0.00) Base-Loss 0.459 (0.565)  Prec@1 85.71 (80.92) Prec@5 98.81 (98.81) Acls-loss 0.563 (0.694) FLOP-Loss 2.935 (0.471) Arch-Loss 6.433 (1.637)
 **TRAIN** Prec@1 80.92 Prec@5 98.81 Error@1 19.08 Error@5 1.19 Base-Loss:0.565, Arch-Loss=1.637
***[2020-01-29 09:51:49]*** TRAIN [epoch=470/600] base-loss = 0.564869, arch-loss = 1.636554, accuracy-1 = 80.92, accuracy-5 = 98.81
[epoch=470/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 12, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.640636)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.307 0.340 0.352  ||  0.0667 0.1689 0.2030  || discrepancy=0.01 || select=2/3
001/003-th : 0.334 0.242 0.425  ||  0.1357 -0.1859 0.3767  || discrepancy=0.09 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.3007 -0.6524 2.8369  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.018 0.030 0.036 0.038 0.058 0.093 0.180 0.547  ||  -1.372 -0.859 -0.681 -0.640 -0.220 0.262 0.918 2.033  || dis=0.37 || select=7/8
001/019-th : 0.101 0.131 0.150 0.139 0.130 0.122 0.120 0.108  ||  -0.199 0.062 0.194 0.117 0.050 -0.011 -0.024 -0.132   || dis=0.01 || select=2/8
002/019-th : 0.130 0.139 0.132 0.141 0.124 0.124 0.111 0.099  ||  0.053 0.115 0.065 0.130 0.007 0.005 -0.107 -0.216     || dis=0.00 || select=3/8
003/019-th : 0.107 0.115 0.124 0.131 0.129 0.135 0.131 0.128  ||  -0.153 -0.078 -0.004 0.049 0.035 0.085 0.050 0.031    || dis=0.00 || select=5/8
004/019-th : 0.114 0.114 0.112 0.111 0.125 0.132 0.146 0.146  ||  -0.090 -0.092 -0.110 -0.120 0.001 0.053 0.159 0.157   || dis=0.00 || select=6/8
005/019-th : 0.118 0.125 0.128 0.128 0.128 0.129 0.126 0.118  ||  -0.059 0.006 0.029 0.027 0.026 0.030 0.012 -0.055     || dis=0.00 || select=5/8
006/019-th : 0.146 0.132 0.118 0.123 0.119 0.119 0.124 0.118  ||  0.161 0.058 -0.050 -0.012 -0.049 -0.041 -0.006 -0.050  || dis=0.01 || select=0/8
007/019-th : 0.014 0.021 0.032 0.043 0.067 0.093 0.177 0.552  ||  -1.532 -1.152 -0.716 -0.441 0.009 0.340 0.983 2.118   || dis=0.38 || select=7/8
008/019-th : 0.012 0.017 0.025 0.044 0.064 0.109 0.243 0.485  ||  -1.621 -1.295 -0.920 -0.365 0.018 0.544 1.348 2.038   || dis=0.24 || select=7/8
009/019-th : 0.082 0.086 0.099 0.113 0.118 0.139 0.165 0.198  ||  -0.380 -0.330 -0.195 -0.061 -0.021 0.143 0.313 0.498  || dis=0.03 || select=7/8
010/019-th : 0.092 0.098 0.104 0.120 0.129 0.150 0.152 0.156  ||  -0.294 -0.230 -0.167 -0.027 0.050 0.196 0.212 0.241   || dis=0.00 || select=7/8
011/019-th : 0.124 0.113 0.112 0.128 0.122 0.124 0.141 0.136  ||  -0.001 -0.088 -0.096 0.029 -0.015 0.002 0.129 0.092   || dis=0.00 || select=6/8
012/019-th : 0.142 0.136 0.127 0.124 0.124 0.116 0.117 0.115  ||  0.130 0.086 0.023 -0.004 -0.003 -0.072 -0.064 -0.076  || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.013 0.023 0.929  ||  -1.171 -1.049 -0.880 -0.812 -0.575 -0.291 0.333 4.015  || dis=0.91 || select=7/8
014/019-th : 0.007 0.009 0.011 0.013 0.018 0.031 0.074 0.838  ||  -1.438 -1.231 -0.992 -0.783 -0.514 0.040 0.925 3.352  || dis=0.76 || select=7/8
015/019-th : 0.006 0.005 0.006 0.007 0.010 0.014 0.029 0.923  ||  -1.109 -1.140 -0.968 -0.816 -0.543 -0.205 0.539 4.005  || dis=0.89 || select=7/8
016/019-th : 0.039 0.051 0.061 0.096 0.127 0.169 0.204 0.253  ||  -0.996 -0.720 -0.538 -0.096 0.188 0.474 0.661 0.878   || dis=0.05 || select=7/8
017/019-th : 0.086 0.107 0.113 0.133 0.134 0.127 0.148 0.153  ||  -0.360 -0.138 -0.079 0.083 0.087 0.034 0.187 0.218    || dis=0.01 || select=7/8
018/019-th : 0.097 0.108 0.132 0.142 0.132 0.128 0.124 0.136  ||  -0.240 -0.131 0.065 0.143 0.066 0.033 0.004 0.099     || dis=0.01 || select=3/8
[epoch=470/600] FLOP : 28.64 MB, ratio : 0.7017, Expected-ratio : 0.7000, Discrepancy : 0.215
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:51:49] [epoch=470/600][000/098] Time 0.39 (0.39) Data 0.29 (0.29) Loss 1.924 (1.924)  Prec@1 29.30 (29.30) Prec@5 83.59 (83.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:51:56] [epoch=470/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.002 (2.264)  Prec@1 27.98 (40.62) Prec@5 80.36 (81.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 40.62 Prec@5 81.70 Error@1 59.38 Error@5 18.30 Loss:2.264
***[2020-01-29 09:51:56]*** VALID [epoch=470/600] loss = 2.263525, accuracy@1 = 40.62, accuracy@5 = 81.70 | Best-Valid-Acc@1=44.86, Error@1=55.14
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:51:56]*** start epoch=471/600 Time Left: [01:08:42], LR=[0.010978 ~ 0.010978], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=471, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.637945502021092, FLOP=40.81
[Search] : epoch=471/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:51:57] [epoch=471/600][000/098] Time 0.71 (0.71) Data 0.41 (0.41) Base-Loss 0.512 (0.512)  Prec@1 81.25 (81.25) Prec@5 99.22 (99.22) Acls-loss 0.650 (0.650) FLOP-Loss 2.934 (2.934) Arch-Loss 6.518 (6.518)
**TRAIN** [2020-01-29 09:52:23] [epoch=471/600][097/098] Time 0.27 (0.27) Data 0.00 (0.00) Base-Loss 0.513 (0.548)  Prec@1 82.14 (81.56) Prec@5 98.21 (98.81) Acls-loss 0.535 (0.661) FLOP-Loss 0.000 (0.030) Arch-Loss 0.535 (0.721)
 **TRAIN** Prec@1 81.56 Prec@5 98.81 Error@1 18.44 Error@5 1.19 Base-Loss:0.548, Arch-Loss=0.721
***[2020-01-29 09:52:23]*** TRAIN [epoch=471/600] base-loss = 0.547684, arch-loss = 0.721224, accuracy-1 = 81.56, accuracy-5 = 98.81
[epoch=471/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 9, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.556668)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.295 0.351 0.354  ||  0.0380 0.2108 0.2195  || discrepancy=0.00 || select=2/3
001/003-th : 0.332 0.242 0.426  ||  0.1307 -0.1867 0.3810  || discrepancy=0.09 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.3027 -0.6595 2.8420  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.018 0.030 0.035 0.037 0.056 0.092 0.176 0.558  ||  -1.360 -0.872 -0.714 -0.637 -0.240 0.262 0.910 2.066  || dis=0.38 || select=7/8
001/019-th : 0.100 0.130 0.151 0.134 0.130 0.124 0.121 0.109  ||  -0.209 0.053 0.205 0.083 0.056 0.004 -0.015 -0.123    || dis=0.02 || select=2/8
002/019-th : 0.128 0.138 0.130 0.140 0.125 0.126 0.112 0.101  ||  0.032 0.112 0.052 0.123 0.010 0.022 -0.097 -0.198     || dis=0.00 || select=3/8
003/019-th : 0.106 0.116 0.125 0.129 0.129 0.135 0.131 0.129  ||  -0.158 -0.074 0.003 0.032 0.037 0.084 0.054 0.034     || dis=0.00 || select=5/8
004/019-th : 0.114 0.111 0.112 0.109 0.126 0.131 0.148 0.149  ||  -0.092 -0.118 -0.105 -0.133 0.009 0.044 0.167 0.177   || dis=0.00 || select=7/8
005/019-th : 0.117 0.125 0.129 0.130 0.126 0.128 0.126 0.120  ||  -0.061 -0.000 0.034 0.038 0.011 0.026 0.008 -0.040    || dis=0.00 || select=3/8
006/019-th : 0.145 0.132 0.118 0.123 0.120 0.120 0.124 0.118  ||  0.150 0.058 -0.051 -0.012 -0.033 -0.040 -0.003 -0.051  || dis=0.01 || select=0/8
007/019-th : 0.014 0.020 0.032 0.041 0.064 0.092 0.173 0.563  ||  -1.540 -1.157 -0.723 -0.453 -0.012 0.341 0.977 2.157  || dis=0.39 || select=7/8
008/019-th : 0.012 0.017 0.025 0.043 0.062 0.105 0.243 0.494  ||  -1.617 -1.311 -0.923 -0.376 -0.004 0.519 1.362 2.072  || dis=0.25 || select=7/8
009/019-th : 0.082 0.086 0.099 0.111 0.118 0.141 0.165 0.199  ||  -0.384 -0.337 -0.194 -0.079 -0.022 0.159 0.317 0.502  || dis=0.03 || select=7/8
010/019-th : 0.090 0.097 0.104 0.119 0.129 0.148 0.152 0.162  ||  -0.314 -0.233 -0.170 -0.036 0.050 0.189 0.210 0.275   || dis=0.01 || select=7/8
011/019-th : 0.123 0.114 0.111 0.127 0.122 0.125 0.142 0.135  ||  -0.004 -0.087 -0.108 0.028 -0.016 0.010 0.136 0.089   || dis=0.01 || select=6/8
012/019-th : 0.140 0.135 0.127 0.123 0.125 0.117 0.118 0.116  ||  0.121 0.079 0.018 -0.014 0.003 -0.065 -0.053 -0.070   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.023 0.931  ||  -1.185 -1.062 -0.870 -0.824 -0.572 -0.289 0.321 4.036  || dis=0.91 || select=7/8
014/019-th : 0.007 0.009 0.011 0.013 0.017 0.030 0.072 0.841  ||  -1.441 -1.224 -1.004 -0.780 -0.512 0.038 0.913 3.366  || dis=0.77 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.010 0.013 0.028 0.926  ||  -1.131 -1.157 -0.964 -0.812 -0.538 -0.217 0.520 4.033  || dis=0.90 || select=7/8
016/019-th : 0.038 0.051 0.060 0.094 0.125 0.170 0.207 0.256  ||  -1.023 -0.715 -0.559 -0.108 0.179 0.488 0.684 0.899   || dis=0.05 || select=7/8
017/019-th : 0.083 0.104 0.115 0.131 0.131 0.128 0.152 0.156  ||  -0.388 -0.160 -0.066 0.071 0.065 0.044 0.214 0.245    || dis=0.00 || select=7/8
018/019-th : 0.097 0.107 0.131 0.141 0.132 0.128 0.126 0.138  ||  -0.243 -0.145 0.056 0.135 0.066 0.038 0.019 0.109     || dis=0.00 || select=3/8
[epoch=471/600] FLOP : 28.56 MB, ratio : 0.6997, Expected-ratio : 0.7000, Discrepancy : 0.217
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:52:23] [epoch=471/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 3.499 (3.499)  Prec@1 25.00 (25.00) Prec@5 67.58 (67.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:52:30] [epoch=471/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 5.092 (2.184)  Prec@1 25.60 (44.97) Prec@5 72.62 (83.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 44.97 Prec@5 83.78 Error@1 55.03 Error@5 16.22 Loss:2.184
***[2020-01-29 09:52:30]*** VALID [epoch=471/600] loss = 2.184017, accuracy@1 = 44.97, accuracy@5 = 83.78 | Best-Valid-Acc@1=44.86, Error@1=55.14
Currently, the best validation accuracy found at 471-epoch :: acc@1=44.97, acc@5=83.78, error@1=55.03, error@5=16.22, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:52:30]*** start epoch=472/600 Time Left: [01:08:11], LR=[0.010815 ~ 0.010815], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=472, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6299510295516927, FLOP=40.81
[Search] : epoch=472/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:52:31] [epoch=472/600][000/098] Time 0.70 (0.70) Data 0.39 (0.39) Base-Loss 0.553 (0.553)  Prec@1 83.20 (83.20) Prec@5 99.22 (99.22) Acls-loss 0.469 (0.469) FLOP-Loss 0.000 (0.000) Arch-Loss 0.469 (0.469)
**TRAIN** [2020-01-29 09:52:57] [epoch=472/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.438 (0.563)  Prec@1 85.12 (80.97) Prec@5 100.00 (98.91) Acls-loss 0.704 (0.670) FLOP-Loss 0.000 (0.000) Arch-Loss 0.704 (0.670)
 **TRAIN** Prec@1 80.97 Prec@5 98.91 Error@1 19.03 Error@5 1.09 Base-Loss:0.563, Arch-Loss=0.670
***[2020-01-29 09:52:57]*** TRAIN [epoch=472/600] base-loss = 0.562983, arch-loss = 0.669844, accuracy-1 = 80.97, accuracy-5 = 98.91
[epoch=472/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 8, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 27.977084)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.289 0.350 0.361  ||  0.0171 0.2107 0.2395  || discrepancy=0.01 || select=2/3
001/003-th : 0.323 0.245 0.432  ||  0.1092 -0.1701 0.3982  || discrepancy=0.11 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.2949 -0.6623 2.8357  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.017 0.028 0.033 0.037 0.054 0.091 0.174 0.565  ||  -1.382 -0.895 -0.729 -0.635 -0.248 0.269 0.923 2.100  || dis=0.39 || select=7/8
001/019-th : 0.098 0.126 0.150 0.133 0.134 0.126 0.123 0.110  ||  -0.229 0.023 0.200 0.077 0.087 0.022 0.004 -0.111     || dis=0.02 || select=2/8
002/019-th : 0.125 0.136 0.130 0.139 0.127 0.128 0.113 0.102  ||  0.009 0.097 0.049 0.118 0.027 0.040 -0.084 -0.187     || dis=0.00 || select=3/8
003/019-th : 0.106 0.115 0.124 0.129 0.130 0.136 0.132 0.130  ||  -0.165 -0.079 -0.007 0.033 0.043 0.088 0.058 0.042    || dis=0.00 || select=5/8
004/019-th : 0.111 0.108 0.110 0.110 0.130 0.131 0.150 0.150  ||  -0.112 -0.144 -0.124 -0.128 0.040 0.048 0.188 0.187   || dis=0.00 || select=6/8
005/019-th : 0.118 0.125 0.129 0.127 0.128 0.127 0.126 0.121  ||  -0.060 -0.002 0.032 0.013 0.024 0.017 0.011 -0.031    || dis=0.00 || select=2/8
006/019-th : 0.141 0.132 0.118 0.123 0.120 0.121 0.126 0.120  ||  0.123 0.055 -0.056 -0.015 -0.038 -0.029 0.012 -0.036  || dis=0.01 || select=0/8
007/019-th : 0.014 0.020 0.031 0.041 0.064 0.090 0.173 0.567  ||  -1.541 -1.154 -0.738 -0.459 -0.013 0.332 0.982 2.172  || dis=0.39 || select=7/8
008/019-th : 0.012 0.017 0.024 0.041 0.061 0.103 0.240 0.501  ||  -1.608 -1.319 -0.927 -0.400 -0.005 0.511 1.360 2.094  || dis=0.26 || select=7/8
009/019-th : 0.080 0.086 0.099 0.110 0.118 0.140 0.167 0.200  ||  -0.403 -0.338 -0.188 -0.086 -0.019 0.154 0.333 0.510  || dis=0.03 || select=7/8
010/019-th : 0.089 0.097 0.103 0.118 0.127 0.149 0.154 0.163  ||  -0.322 -0.235 -0.175 -0.038 0.031 0.197 0.226 0.284   || dis=0.01 || select=7/8
011/019-th : 0.123 0.113 0.111 0.126 0.123 0.126 0.141 0.136  ||  -0.008 -0.092 -0.112 0.019 -0.010 0.020 0.131 0.094   || dis=0.00 || select=6/8
012/019-th : 0.139 0.134 0.127 0.121 0.125 0.117 0.119 0.117  ||  0.112 0.070 0.023 -0.030 0.002 -0.058 -0.043 -0.061   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.022 0.932  ||  -1.178 -1.073 -0.884 -0.839 -0.572 -0.288 0.315 4.051  || dis=0.91 || select=7/8
014/019-th : 0.007 0.008 0.010 0.013 0.017 0.030 0.071 0.844  ||  -1.434 -1.224 -1.008 -0.793 -0.528 0.035 0.906 3.387  || dis=0.77 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.010 0.013 0.027 0.926  ||  -1.120 -1.149 -0.969 -0.805 -0.532 -0.234 0.513 4.039  || dis=0.90 || select=7/8
016/019-th : 0.037 0.051 0.059 0.092 0.125 0.171 0.207 0.259  ||  -1.025 -0.721 -0.574 -0.126 0.181 0.498 0.690 0.913   || dis=0.05 || select=7/8
017/019-th : 0.081 0.103 0.113 0.133 0.131 0.127 0.154 0.158  ||  -0.407 -0.175 -0.075 0.082 0.071 0.038 0.232 0.259    || dis=0.00 || select=7/8
018/019-th : 0.096 0.106 0.129 0.140 0.133 0.129 0.129 0.139  ||  -0.250 -0.155 0.041 0.128 0.071 0.040 0.042 0.114     || dis=0.00 || select=3/8
[epoch=472/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.219
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:52:57] [epoch=472/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 3.954 (3.954)  Prec@1 20.70 (20.70) Prec@5 60.16 (60.16) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:53:04] [epoch=472/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.453 (2.154)  Prec@1 51.19 (45.97) Prec@5 92.26 (83.94) Size=[168, 3, 32, 32]
 **VALID** Prec@1 45.97 Prec@5 83.94 Error@1 54.03 Error@5 16.06 Loss:2.154
***[2020-01-29 09:53:04]*** VALID [epoch=472/600] loss = 2.154032, accuracy@1 = 45.97, accuracy@5 = 83.94 | Best-Valid-Acc@1=44.97, Error@1=55.03
Currently, the best validation accuracy found at 472-epoch :: acc@1=45.97, acc@5=83.94, error@1=54.03, error@5=16.06, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:53:04]*** start epoch=473/600 Time Left: [01:07:40], LR=[0.010653 ~ 0.010653], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=473, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6220091961947237, FLOP=40.81
[Search] : epoch=473/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:53:05] [epoch=473/600][000/098] Time 0.72 (0.72) Data 0.39 (0.39) Base-Loss 0.689 (0.689)  Prec@1 77.34 (77.34) Prec@5 98.05 (98.05) Acls-loss 0.619 (0.619) FLOP-Loss 0.000 (0.000) Arch-Loss 0.619 (0.619)
**TRAIN** [2020-01-29 09:53:31] [epoch=473/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.480 (0.562)  Prec@1 81.55 (80.89) Prec@5 100.00 (98.92) Acls-loss 0.557 (0.632) FLOP-Loss 0.000 (0.151) Arch-Loss 0.557 (0.934)
 **TRAIN** Prec@1 80.89 Prec@5 98.92 Error@1 19.11 Error@5 1.08 Base-Loss:0.562, Arch-Loss=0.934
***[2020-01-29 09:53:31]*** TRAIN [epoch=473/600] base-loss = 0.561561, arch-loss = 0.933688, accuracy-1 = 80.89, accuracy-5 = 98.92
[epoch=473/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 28.372348)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.290 0.351 0.359  ||  0.0202 0.2126 0.2340  || discrepancy=0.01 || select=2/3
001/003-th : 0.324 0.243 0.433  ||  0.1082 -0.1761 0.3997  || discrepancy=0.11 || select=2/3
002/003-th : 0.006 0.028 0.966  ||  -2.2816 -0.6917 2.8345  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.017 0.028 0.033 0.037 0.053 0.091 0.173 0.568  ||  -1.384 -0.892 -0.724 -0.636 -0.260 0.273 0.920 2.108  || dis=0.39 || select=7/8
001/019-th : 0.097 0.125 0.148 0.132 0.135 0.127 0.125 0.110  ||  -0.238 0.019 0.188 0.074 0.093 0.032 0.017 -0.110     || dis=0.01 || select=2/8
002/019-th : 0.125 0.137 0.128 0.140 0.125 0.129 0.114 0.104  ||  0.008 0.102 0.034 0.122 0.011 0.041 -0.085 -0.177     || dis=0.00 || select=3/8
003/019-th : 0.106 0.114 0.125 0.127 0.132 0.135 0.132 0.130  ||  -0.164 -0.091 0.008 0.023 0.057 0.080 0.058 0.043     || dis=0.00 || select=5/8
004/019-th : 0.111 0.109 0.111 0.110 0.129 0.132 0.148 0.150  ||  -0.113 -0.134 -0.120 -0.127 0.036 0.058 0.174 0.186   || dis=0.00 || select=7/8
005/019-th : 0.119 0.125 0.129 0.125 0.129 0.127 0.126 0.121  ||  -0.049 -0.004 0.035 -0.001 0.028 0.015 0.007 -0.033   || dis=0.00 || select=2/8
006/019-th : 0.141 0.131 0.117 0.125 0.121 0.121 0.125 0.120  ||  0.123 0.052 -0.066 0.003 -0.028 -0.028 0.008 -0.040   || dis=0.01 || select=0/8
007/019-th : 0.014 0.020 0.030 0.040 0.062 0.090 0.170 0.575  ||  -1.538 -1.148 -0.755 -0.472 -0.034 0.342 0.975 2.195  || dis=0.40 || select=7/8
008/019-th : 0.012 0.016 0.025 0.041 0.062 0.103 0.237 0.504  ||  -1.604 -1.328 -0.918 -0.405 0.001 0.512 1.350 2.103   || dis=0.27 || select=7/8
009/019-th : 0.079 0.086 0.101 0.111 0.117 0.138 0.168 0.199  ||  -0.415 -0.335 -0.174 -0.072 -0.024 0.144 0.341 0.507  || dis=0.03 || select=7/8
010/019-th : 0.089 0.097 0.102 0.118 0.132 0.147 0.153 0.161  ||  -0.316 -0.238 -0.184 -0.040 0.070 0.181 0.223 0.274   || dis=0.01 || select=7/8
011/019-th : 0.122 0.114 0.111 0.128 0.123 0.126 0.140 0.136  ||  -0.015 -0.087 -0.110 0.032 -0.007 0.016 0.124 0.093   || dis=0.00 || select=6/8
012/019-th : 0.140 0.134 0.128 0.122 0.124 0.116 0.120 0.116  ||  0.118 0.073 0.024 -0.024 -0.002 -0.067 -0.039 -0.068  || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.022 0.933  ||  -1.171 -1.068 -0.876 -0.850 -0.573 -0.288 0.307 4.055  || dis=0.91 || select=7/8
014/019-th : 0.007 0.008 0.010 0.012 0.016 0.028 0.067 0.852  ||  -1.425 -1.251 -1.019 -0.799 -0.526 0.030 0.879 3.429  || dis=0.78 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.009 0.013 0.027 0.927  ||  -1.125 -1.142 -0.961 -0.812 -0.535 -0.236 0.501 4.047  || dis=0.90 || select=7/8
016/019-th : 0.036 0.050 0.058 0.089 0.123 0.170 0.208 0.266  ||  -1.051 -0.724 -0.578 -0.148 0.175 0.499 0.702 0.949   || dis=0.06 || select=7/8
017/019-th : 0.082 0.103 0.114 0.129 0.132 0.127 0.155 0.159  ||  -0.401 -0.174 -0.068 0.056 0.074 0.035 0.239 0.260    || dis=0.00 || select=7/8
018/019-th : 0.095 0.105 0.129 0.139 0.134 0.127 0.131 0.139  ||  -0.258 -0.166 0.046 0.121 0.083 0.030 0.061 0.116     || dis=0.00 || select=3/8
[epoch=473/600] FLOP : 28.37 MB, ratio : 0.6952, Expected-ratio : 0.7000, Discrepancy : 0.221
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:53:31] [epoch=473/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 1.465 (1.465)  Prec@1 43.36 (43.36) Prec@5 91.80 (91.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:53:38] [epoch=473/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.571 (2.188)  Prec@1 58.93 (44.42) Prec@5 92.86 (83.93) Size=[168, 3, 32, 32]
 **VALID** Prec@1 44.42 Prec@5 83.93 Error@1 55.58 Error@5 16.07 Loss:2.188
***[2020-01-29 09:53:38]*** VALID [epoch=473/600] loss = 2.187697, accuracy@1 = 44.42, accuracy@5 = 83.93 | Best-Valid-Acc@1=45.97, Error@1=54.03
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:53:38]*** start epoch=474/600 Time Left: [01:07:08], LR=[0.010492 ~ 0.010492], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=474, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6141202196795585, FLOP=40.81
[Search] : epoch=474/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:53:39] [epoch=474/600][000/098] Time 0.70 (0.70) Data 0.40 (0.40) Base-Loss 0.418 (0.418)  Prec@1 85.55 (85.55) Prec@5 99.61 (99.61) Acls-loss 0.604 (0.604) FLOP-Loss 0.000 (0.000) Arch-Loss 0.604 (0.604)
**TRAIN** [2020-01-29 09:54:05] [epoch=474/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.428 (0.589)  Prec@1 80.95 (80.05) Prec@5 100.00 (98.76) Acls-loss 0.838 (0.633) FLOP-Loss 0.000 (0.332) Arch-Loss 0.838 (1.297)
 **TRAIN** Prec@1 80.05 Prec@5 98.76 Error@1 19.95 Error@5 1.24 Base-Loss:0.589, Arch-Loss=1.297
***[2020-01-29 09:54:05]*** TRAIN [epoch=474/600] base-loss = 0.589077, arch-loss = 1.297245, accuracy-1 = 80.05, accuracy-5 = 98.76
[epoch=474/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 8, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.832252)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.292 0.354 0.354  ||  0.0285 0.2225 0.2206  || discrepancy=0.00 || select=1/3
001/003-th : 0.331 0.244 0.425  ||  0.1285 -0.1775 0.3787  || discrepancy=0.09 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.2689 -0.6748 2.8157  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.017 0.028 0.033 0.036 0.052 0.089 0.169 0.574  ||  -1.378 -0.884 -0.725 -0.641 -0.268 0.263 0.902 2.125  || dis=0.40 || select=7/8
001/019-th : 0.099 0.127 0.150 0.132 0.136 0.125 0.123 0.108  ||  -0.222 0.030 0.200 0.073 0.098 0.018 -0.003 -0.127    || dis=0.01 || select=2/8
002/019-th : 0.126 0.136 0.128 0.140 0.126 0.129 0.112 0.104  ||  0.017 0.093 0.035 0.127 0.015 0.041 -0.100 -0.176     || dis=0.00 || select=3/8
003/019-th : 0.107 0.113 0.127 0.128 0.131 0.134 0.134 0.128  ||  -0.153 -0.100 0.017 0.027 0.049 0.077 0.071 0.025     || dis=0.00 || select=5/8
004/019-th : 0.114 0.111 0.111 0.110 0.128 0.133 0.146 0.147  ||  -0.090 -0.115 -0.118 -0.129 0.026 0.068 0.159 0.165   || dis=0.00 || select=7/8
005/019-th : 0.120 0.125 0.130 0.126 0.129 0.126 0.125 0.119  ||  -0.041 -0.000 0.041 0.007 0.032 0.009 0.000 -0.048    || dis=0.00 || select=2/8
006/019-th : 0.144 0.133 0.118 0.124 0.120 0.120 0.123 0.118  ||  0.148 0.069 -0.051 -0.000 -0.036 -0.039 -0.010 -0.055  || dis=0.01 || select=0/8
007/019-th : 0.014 0.020 0.030 0.039 0.061 0.089 0.168 0.580  ||  -1.540 -1.160 -0.759 -0.480 -0.037 0.342 0.975 2.214  || dis=0.41 || select=7/8
008/019-th : 0.012 0.016 0.024 0.041 0.061 0.102 0.238 0.505  ||  -1.603 -1.336 -0.920 -0.396 -0.013 0.505 1.358 2.110  || dis=0.27 || select=7/8
009/019-th : 0.080 0.087 0.102 0.112 0.118 0.139 0.168 0.194  ||  -0.405 -0.320 -0.165 -0.069 -0.017 0.143 0.333 0.482  || dis=0.03 || select=7/8
010/019-th : 0.090 0.097 0.103 0.117 0.131 0.148 0.154 0.159  ||  -0.307 -0.234 -0.172 -0.051 0.067 0.183 0.228 0.259   || dis=0.01 || select=7/8
011/019-th : 0.124 0.116 0.111 0.127 0.124 0.125 0.138 0.134  ||  0.002 -0.067 -0.110 0.025 -0.002 0.012 0.111 0.079    || dis=0.00 || select=6/8
012/019-th : 0.142 0.136 0.128 0.121 0.124 0.117 0.118 0.114  ||  0.133 0.091 0.024 -0.028 -0.001 -0.065 -0.056 -0.087  || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.022 0.932  ||  -1.162 -1.075 -0.866 -0.842 -0.565 -0.290 0.301 4.052  || dis=0.91 || select=7/8
014/019-th : 0.007 0.008 0.010 0.012 0.016 0.028 0.065 0.854  ||  -1.416 -1.246 -1.029 -0.811 -0.523 0.032 0.866 3.437  || dis=0.79 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.009 0.012 0.026 0.928  ||  -1.114 -1.133 -0.953 -0.806 -0.529 -0.260 0.491 4.053  || dis=0.90 || select=7/8
016/019-th : 0.036 0.050 0.059 0.089 0.123 0.171 0.208 0.264  ||  -1.061 -0.715 -0.560 -0.147 0.179 0.503 0.700 0.940   || dis=0.06 || select=7/8
017/019-th : 0.082 0.104 0.116 0.129 0.132 0.127 0.152 0.157  ||  -0.399 -0.161 -0.054 0.055 0.075 0.037 0.221 0.252    || dis=0.01 || select=7/8
018/019-th : 0.097 0.107 0.130 0.141 0.133 0.126 0.129 0.136  ||  -0.241 -0.148 0.054 0.135 0.074 0.019 0.041 0.099     || dis=0.00 || select=3/8
[epoch=474/600] FLOP : 26.83 MB, ratio : 0.6574, Expected-ratio : 0.7000, Discrepancy : 0.221
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:54:05] [epoch=474/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 1.882 (1.882)  Prec@1 54.69 (54.69) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:54:12] [epoch=474/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.741 (2.376)  Prec@1 22.62 (44.82) Prec@5 68.45 (83.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 44.82 Prec@5 83.20 Error@1 55.18 Error@5 16.80 Loss:2.376
***[2020-01-29 09:54:12]*** VALID [epoch=474/600] loss = 2.376176, accuracy@1 = 44.82, accuracy@5 = 83.20 | Best-Valid-Acc@1=45.97, Error@1=54.03
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:54:12]*** start epoch=475/600 Time Left: [01:06:37], LR=[0.010332 ~ 0.010332], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=475, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.6062843162864742, FLOP=40.81
[Search] : epoch=475/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:54:12] [epoch=475/600][000/098] Time 0.68 (0.68) Data 0.40 (0.40) Base-Loss 0.397 (0.397)  Prec@1 86.33 (86.33) Prec@5 99.61 (99.61) Acls-loss 0.548 (0.548) FLOP-Loss 0.000 (0.000) Arch-Loss 0.548 (0.548)
**TRAIN** [2020-01-29 09:54:38] [epoch=475/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.631 (0.580)  Prec@1 79.17 (80.30) Prec@5 100.00 (98.84) Acls-loss 0.644 (0.646) FLOP-Loss 0.000 (0.121) Arch-Loss 0.644 (0.887)
 **TRAIN** Prec@1 80.30 Prec@5 98.84 Error@1 19.70 Error@5 1.16 Base-Loss:0.580, Arch-Loss=0.887
***[2020-01-29 09:54:39]*** TRAIN [epoch=475/600] base-loss = 0.579606, arch-loss = 0.887170, accuracy-1 = 80.30, accuracy-5 = 98.84
[epoch=475/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 11, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.832252)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.289 0.356 0.355  ||  0.0197 0.2272 0.2265  || discrepancy=0.00 || select=1/3
001/003-th : 0.330 0.244 0.426  ||  0.1243 -0.1743 0.3811  || discrepancy=0.10 || select=2/3
002/003-th : 0.006 0.028 0.966  ||  -2.3073 -0.6792 2.8556  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.017 0.028 0.033 0.036 0.051 0.088 0.170 0.578  ||  -1.388 -0.898 -0.718 -0.642 -0.278 0.258 0.916 2.141  || dis=0.41 || select=7/8
001/019-th : 0.098 0.126 0.150 0.132 0.136 0.127 0.122 0.109  ||  -0.225 0.026 0.197 0.069 0.097 0.028 -0.006 -0.119    || dis=0.01 || select=2/8
002/019-th : 0.126 0.134 0.129 0.141 0.126 0.129 0.113 0.103  ||  0.018 0.081 0.041 0.129 0.016 0.042 -0.092 -0.180     || dis=0.01 || select=3/8
003/019-th : 0.107 0.113 0.126 0.127 0.131 0.136 0.134 0.127  ||  -0.153 -0.096 0.009 0.019 0.050 0.088 0.073 0.021     || dis=0.00 || select=5/8
004/019-th : 0.113 0.111 0.111 0.113 0.126 0.132 0.143 0.151  ||  -0.096 -0.115 -0.119 -0.101 0.013 0.055 0.139 0.188   || dis=0.01 || select=7/8
005/019-th : 0.118 0.125 0.130 0.127 0.131 0.124 0.125 0.119  ||  -0.055 0.000 0.041 0.020 0.047 -0.003 0.003 -0.046    || dis=0.00 || select=4/8
006/019-th : 0.144 0.133 0.119 0.124 0.122 0.118 0.123 0.118  ||  0.147 0.070 -0.046 -0.002 -0.021 -0.053 -0.013 -0.055  || dis=0.01 || select=0/8
007/019-th : 0.013 0.020 0.029 0.039 0.059 0.086 0.167 0.586  ||  -1.544 -1.159 -0.758 -0.474 -0.059 0.320 0.983 2.235  || dis=0.42 || select=7/8
008/019-th : 0.012 0.016 0.024 0.041 0.059 0.099 0.235 0.514  ||  -1.626 -1.330 -0.933 -0.396 -0.017 0.494 1.359 2.142  || dis=0.28 || select=7/8
009/019-th : 0.081 0.087 0.102 0.112 0.116 0.139 0.167 0.196  ||  -0.400 -0.321 -0.169 -0.067 -0.033 0.146 0.331 0.488  || dis=0.03 || select=7/8
010/019-th : 0.090 0.097 0.104 0.118 0.132 0.147 0.153 0.160  ||  -0.311 -0.236 -0.166 -0.043 0.073 0.179 0.219 0.263   || dis=0.01 || select=7/8
011/019-th : 0.124 0.116 0.112 0.126 0.125 0.126 0.138 0.134  ||  -0.002 -0.066 -0.104 0.020 0.006 0.012 0.104 0.080    || dis=0.00 || select=6/8
012/019-th : 0.142 0.136 0.127 0.121 0.125 0.117 0.118 0.114  ||  0.129 0.092 0.018 -0.024 0.003 -0.059 -0.056 -0.088   || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.022 0.933  ||  -1.176 -1.071 -0.858 -0.836 -0.569 -0.289 0.297 4.058  || dis=0.91 || select=7/8
014/019-th : 0.007 0.008 0.010 0.012 0.016 0.028 0.064 0.855  ||  -1.411 -1.242 -1.040 -0.806 -0.516 0.038 0.847 3.443  || dis=0.79 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.009 0.012 0.026 0.929  ||  -1.111 -1.124 -0.959 -0.799 -0.556 -0.259 0.476 4.067  || dis=0.90 || select=7/8
016/019-th : 0.035 0.051 0.058 0.088 0.122 0.169 0.210 0.267  ||  -1.068 -0.711 -0.570 -0.153 0.171 0.499 0.713 0.952   || dis=0.06 || select=7/8
017/019-th : 0.082 0.103 0.117 0.130 0.130 0.126 0.154 0.158  ||  -0.400 -0.170 -0.043 0.064 0.062 0.030 0.228 0.254    || dis=0.00 || select=7/8
018/019-th : 0.098 0.107 0.131 0.141 0.131 0.126 0.129 0.136  ||  -0.229 -0.146 0.059 0.134 0.060 0.020 0.041 0.092     || dis=0.00 || select=3/8
[epoch=475/600] FLOP : 26.83 MB, ratio : 0.6574, Expected-ratio : 0.7000, Discrepancy : 0.223
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:54:39] [epoch=475/600][000/098] Time 0.40 (0.40) Data 0.29 (0.29) Loss 3.336 (3.336)  Prec@1 19.92 (19.92) Prec@5 66.80 (66.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:54:46] [epoch=475/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.848 (2.290)  Prec@1 69.64 (42.58) Prec@5 97.02 (83.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.58 Prec@5 83.26 Error@1 57.42 Error@5 16.74 Loss:2.290
***[2020-01-29 09:54:46]*** VALID [epoch=475/600] loss = 2.289828, accuracy@1 = 42.58, accuracy@5 = 83.26 | Best-Valid-Acc@1=45.97, Error@1=54.03
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:54:46]*** start epoch=476/600 Time Left: [01:06:05], LR=[0.010174 ~ 0.010174], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=476, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5985017008407192, FLOP=40.81
[Search] : epoch=476/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:54:47] [epoch=476/600][000/098] Time 0.69 (0.69) Data 0.39 (0.39) Base-Loss 0.731 (0.731)  Prec@1 75.00 (75.00) Prec@5 98.83 (98.83) Acls-loss 0.707 (0.707) FLOP-Loss 0.000 (0.000) Arch-Loss 0.707 (0.707)
**TRAIN** [2020-01-29 09:55:13] [epoch=476/600][097/098] Time 0.28 (0.28) Data 0.00 (0.00) Base-Loss 0.479 (0.545)  Prec@1 83.33 (81.50) Prec@5 98.81 (98.98) Acls-loss 0.714 (0.651) FLOP-Loss 0.000 (0.060) Arch-Loss 0.714 (0.772)
 **TRAIN** Prec@1 81.50 Prec@5 98.98 Error@1 18.50 Error@5 1.02 Base-Loss:0.545, Arch-Loss=0.772
***[2020-01-29 09:55:13]*** TRAIN [epoch=476/600] base-loss = 0.545007, arch-loss = 0.771619, accuracy-1 = 81.50, accuracy-5 = 98.98
[epoch=476/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 11, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.832252)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.282 0.361 0.356  ||  0.0025 0.2486 0.2352  || discrepancy=0.01 || select=1/3
001/003-th : 0.326 0.244 0.430  ||  0.1146 -0.1773 0.3907  || discrepancy=0.10 || select=2/3
002/003-th : 0.005 0.028 0.966  ||  -2.3181 -0.6725 2.8647  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.017 0.027 0.032 0.035 0.050 0.085 0.166 0.587  ||  -1.386 -0.905 -0.728 -0.646 -0.288 0.238 0.910 2.172  || dis=0.42 || select=7/8
001/019-th : 0.098 0.124 0.149 0.133 0.136 0.128 0.122 0.110  ||  -0.226 0.008 0.189 0.076 0.103 0.037 -0.007 -0.110    || dis=0.01 || select=2/8
002/019-th : 0.125 0.135 0.127 0.141 0.125 0.128 0.115 0.105  ||  0.009 0.084 0.027 0.129 0.008 0.032 -0.073 -0.167     || dis=0.01 || select=3/8
003/019-th : 0.105 0.113 0.126 0.126 0.133 0.136 0.134 0.127  ||  -0.167 -0.093 0.010 0.015 0.066 0.090 0.074 0.023     || dis=0.00 || select=5/8
004/019-th : 0.115 0.111 0.111 0.112 0.125 0.133 0.142 0.152  ||  -0.086 -0.118 -0.117 -0.112 -0.003 0.064 0.128 0.200  || dis=0.01 || select=7/8
005/019-th : 0.115 0.125 0.128 0.128 0.130 0.126 0.126 0.121  ||  -0.081 0.000 0.030 0.028 0.044 0.014 0.010 -0.028     || dis=0.00 || select=4/8
006/019-th : 0.143 0.133 0.119 0.125 0.122 0.116 0.123 0.119  ||  0.142 0.065 -0.046 0.004 -0.019 -0.067 -0.013 -0.042  || dis=0.01 || select=0/8
007/019-th : 0.013 0.019 0.029 0.038 0.057 0.086 0.164 0.594  ||  -1.563 -1.155 -0.762 -0.479 -0.071 0.330 0.979 2.266  || dis=0.43 || select=7/8
008/019-th : 0.012 0.016 0.024 0.041 0.059 0.097 0.234 0.517  ||  -1.620 -1.332 -0.923 -0.396 -0.025 0.475 1.356 2.148  || dis=0.28 || select=7/8
009/019-th : 0.080 0.087 0.100 0.111 0.116 0.140 0.168 0.197  ||  -0.403 -0.324 -0.180 -0.075 -0.031 0.157 0.335 0.493  || dis=0.03 || select=7/8
010/019-th : 0.089 0.096 0.103 0.120 0.132 0.146 0.151 0.162  ||  -0.320 -0.243 -0.173 -0.022 0.072 0.177 0.209 0.278   || dis=0.01 || select=7/8
011/019-th : 0.122 0.116 0.111 0.127 0.125 0.128 0.137 0.134  ||  -0.014 -0.066 -0.107 0.021 0.005 0.032 0.099 0.078    || dis=0.00 || select=6/8
012/019-th : 0.142 0.137 0.126 0.120 0.125 0.118 0.118 0.115  ||  0.128 0.092 0.011 -0.042 0.002 -0.053 -0.056 -0.078   || dis=0.00 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.021 0.934  ||  -1.171 -1.063 -0.877 -0.830 -0.576 -0.294 0.285 4.071  || dis=0.91 || select=7/8
014/019-th : 0.007 0.008 0.010 0.012 0.016 0.027 0.063 0.858  ||  -1.414 -1.238 -1.036 -0.812 -0.533 0.021 0.846 3.462  || dis=0.79 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.009 0.012 0.026 0.929  ||  -1.100 -1.117 -0.951 -0.803 -0.556 -0.257 0.472 4.063  || dis=0.90 || select=7/8
016/019-th : 0.036 0.050 0.057 0.088 0.122 0.169 0.213 0.267  ||  -1.059 -0.726 -0.594 -0.155 0.170 0.501 0.730 0.956   || dis=0.05 || select=7/8
017/019-th : 0.082 0.101 0.118 0.129 0.131 0.126 0.156 0.157  ||  -0.404 -0.186 -0.032 0.056 0.069 0.032 0.243 0.251    || dis=0.00 || select=7/8
018/019-th : 0.097 0.106 0.130 0.142 0.130 0.128 0.131 0.136  ||  -0.238 -0.153 0.053 0.137 0.051 0.033 0.055 0.093     || dis=0.01 || select=3/8
[epoch=476/600] FLOP : 26.83 MB, ratio : 0.6574, Expected-ratio : 0.7000, Discrepancy : 0.225
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:55:14] [epoch=476/600][000/098] Time 0.41 (0.41) Data 0.31 (0.31) Loss 2.670 (2.670)  Prec@1 27.73 (27.73) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:55:20] [epoch=476/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.003 (2.498)  Prec@1 39.88 (41.74) Prec@5 89.88 (81.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 41.74 Prec@5 81.58 Error@1 58.26 Error@5 18.42 Loss:2.498
***[2020-01-29 09:55:21]*** VALID [epoch=476/600] loss = 2.498310, accuracy@1 = 41.74, accuracy@5 = 81.58 | Best-Valid-Acc@1=45.97, Error@1=54.03
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:55:21]*** start epoch=477/600 Time Left: [01:05:34], LR=[0.010016 ~ 0.010016], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=477, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5907725867066281, FLOP=40.81
[Search] : epoch=477/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:55:21] [epoch=477/600][000/098] Time 0.68 (0.68) Data 0.40 (0.40) Base-Loss 0.338 (0.338)  Prec@1 87.89 (87.89) Prec@5 98.83 (98.83) Acls-loss 0.535 (0.535) FLOP-Loss 0.000 (0.000) Arch-Loss 0.535 (0.535)
**TRAIN** [2020-01-29 09:55:48] [epoch=477/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.594 (0.540)  Prec@1 74.40 (81.63) Prec@5 100.00 (99.09) Acls-loss 0.761 (0.649) FLOP-Loss 0.000 (0.000) Arch-Loss 0.761 (0.649)
 **TRAIN** Prec@1 81.63 Prec@5 99.09 Error@1 18.37 Error@5 0.91 Base-Loss:0.540, Arch-Loss=0.649
***[2020-01-29 09:55:48]*** TRAIN [epoch=477/600] base-loss = 0.539706, arch-loss = 0.648828, accuracy-1 = 81.63, accuracy-5 = 99.09
[epoch=477/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 11, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.832252)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.277 0.364 0.359  ||  -0.0144 0.2598 0.2467  || discrepancy=0.01 || select=1/3
001/003-th : 0.320 0.244 0.435  ||  0.0977 -0.1723 0.4054  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.028 0.966  ||  -2.3104 -0.6765 2.8587  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.016 0.026 0.031 0.034 0.048 0.082 0.163 0.600  ||  -1.411 -0.911 -0.736 -0.657 -0.301 0.229 0.915 2.219  || dis=0.44 || select=7/8
001/019-th : 0.097 0.121 0.149 0.132 0.135 0.127 0.125 0.112  ||  -0.233 -0.013 0.190 0.070 0.097 0.035 0.018 -0.091    || dis=0.01 || select=2/8
002/019-th : 0.123 0.131 0.127 0.141 0.125 0.129 0.116 0.107  ||  -0.005 0.060 0.023 0.130 0.009 0.041 -0.065 -0.142    || dis=0.01 || select=3/8
003/019-th : 0.103 0.113 0.123 0.126 0.133 0.138 0.134 0.130  ||  -0.189 -0.096 -0.008 0.019 0.067 0.109 0.077 0.043    || dis=0.00 || select=5/8
004/019-th : 0.112 0.110 0.111 0.112 0.125 0.132 0.145 0.152  ||  -0.104 -0.126 -0.115 -0.107 0.001 0.056 0.153 0.199   || dis=0.01 || select=7/8
005/019-th : 0.115 0.123 0.128 0.128 0.129 0.128 0.127 0.122  ||  -0.082 -0.010 0.029 0.025 0.032 0.025 0.015 -0.020    || dis=0.00 || select=4/8
006/019-th : 0.143 0.132 0.118 0.123 0.124 0.117 0.123 0.120  ||  0.140 0.058 -0.050 -0.014 -0.007 -0.061 -0.011 -0.039  || dis=0.01 || select=0/8
007/019-th : 0.013 0.019 0.028 0.037 0.056 0.083 0.161 0.603  ||  -1.567 -1.168 -0.758 -0.482 -0.075 0.313 0.975 2.298  || dis=0.44 || select=7/8
008/019-th : 0.012 0.016 0.024 0.039 0.059 0.096 0.237 0.518  ||  -1.633 -1.334 -0.919 -0.423 -0.020 0.472 1.377 2.160  || dis=0.28 || select=7/8
009/019-th : 0.080 0.084 0.098 0.112 0.118 0.140 0.169 0.199  ||  -0.407 -0.353 -0.195 -0.064 -0.017 0.158 0.347 0.507  || dis=0.03 || select=7/8
010/019-th : 0.089 0.095 0.103 0.120 0.132 0.147 0.152 0.164  ||  -0.326 -0.255 -0.177 -0.024 0.071 0.179 0.214 0.292   || dis=0.01 || select=7/8
011/019-th : 0.119 0.117 0.111 0.125 0.124 0.131 0.138 0.135  ||  -0.041 -0.061 -0.109 0.008 -0.001 0.052 0.107 0.086   || dis=0.00 || select=6/8
012/019-th : 0.140 0.135 0.125 0.120 0.124 0.119 0.119 0.117  ||  0.119 0.081 0.005 -0.036 -0.002 -0.050 -0.046 -0.067  || dis=0.01 || select=0/8
013/019-th : 0.005 0.006 0.006 0.007 0.009 0.012 0.021 0.935  ||  -1.165 -1.056 -0.890 -0.824 -0.585 -0.291 0.277 4.078  || dis=0.91 || select=7/8
014/019-th : 0.006 0.008 0.009 0.012 0.015 0.027 0.063 0.860  ||  -1.436 -1.232 -1.031 -0.813 -0.545 0.015 0.854 3.475  || dis=0.80 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.009 0.012 0.025 0.929  ||  -1.088 -1.108 -0.961 -0.797 -0.574 -0.255 0.469 4.066  || dis=0.90 || select=7/8
016/019-th : 0.035 0.049 0.056 0.086 0.120 0.171 0.215 0.268  ||  -1.058 -0.733 -0.600 -0.171 0.160 0.512 0.742 0.964   || dis=0.05 || select=7/8
017/019-th : 0.082 0.100 0.117 0.129 0.131 0.128 0.156 0.158  ||  -0.402 -0.204 -0.046 0.054 0.069 0.051 0.244 0.261    || dis=0.00 || select=7/8
018/019-th : 0.097 0.105 0.129 0.141 0.130 0.130 0.132 0.136  ||  -0.242 -0.160 0.043 0.134 0.049 0.051 0.062 0.093     || dis=0.00 || select=3/8
[epoch=477/600] FLOP : 26.83 MB, ratio : 0.6574, Expected-ratio : 0.7000, Discrepancy : 0.227
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:55:48] [epoch=477/600][000/098] Time 0.43 (0.43) Data 0.33 (0.33) Loss 2.018 (2.018)  Prec@1 46.88 (46.88) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:55:55] [epoch=477/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 4.350 (2.494)  Prec@1 30.36 (42.18) Prec@5 76.79 (81.29) Size=[168, 3, 32, 32]
 **VALID** Prec@1 42.18 Prec@5 81.29 Error@1 57.82 Error@5 18.71 Loss:2.494
***[2020-01-29 09:55:55]*** VALID [epoch=477/600] loss = 2.494061, accuracy@1 = 42.18, accuracy@5 = 81.29 | Best-Valid-Acc@1=45.97, Error@1=54.03
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:55:55]*** start epoch=478/600 Time Left: [01:05:03], LR=[0.009859 ~ 0.009859], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=478, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5830971857817698, FLOP=40.81
[Search] : epoch=478/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:55:56] [epoch=478/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 0.482 (0.482)  Prec@1 81.64 (81.64) Prec@5 99.22 (99.22) Acls-loss 0.907 (0.907) FLOP-Loss 0.000 (0.000) Arch-Loss 0.907 (0.907)
**TRAIN** [2020-01-29 09:56:22] [epoch=478/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.428 (0.575)  Prec@1 85.71 (80.46) Prec@5 100.00 (98.83) Acls-loss 0.770 (0.639) FLOP-Loss 0.000 (0.061) Arch-Loss 0.770 (0.760)
 **TRAIN** Prec@1 80.46 Prec@5 98.83 Error@1 19.54 Error@5 1.17 Base-Loss:0.575, Arch-Loss=0.760
***[2020-01-29 09:56:22]*** TRAIN [epoch=478/600] base-loss = 0.574789, arch-loss = 0.760092, accuracy-1 = 80.46, accuracy-5 = 98.83
[epoch=478/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 11, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.832252)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.271 0.365 0.364  ||  -0.0341 0.2653 0.2635  || discrepancy=0.00 || select=1/3
001/003-th : 0.319 0.244 0.437  ||  0.0932 -0.1725 0.4089  || discrepancy=0.12 || select=2/3
002/003-th : 0.006 0.028 0.966  ||  -2.3087 -0.6699 2.8556  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.016 0.026 0.031 0.033 0.047 0.079 0.159 0.610  ||  -1.406 -0.918 -0.744 -0.665 -0.317 0.211 0.903 2.250  || dis=0.45 || select=7/8
001/019-th : 0.097 0.121 0.147 0.132 0.135 0.127 0.127 0.114  ||  -0.237 -0.015 0.176 0.068 0.090 0.033 0.028 -0.077    || dis=0.01 || select=2/8
002/019-th : 0.120 0.130 0.129 0.140 0.126 0.131 0.117 0.108  ||  -0.028 0.050 0.040 0.123 0.019 0.055 -0.052 -0.138    || dis=0.01 || select=3/8
003/019-th : 0.103 0.113 0.121 0.127 0.133 0.137 0.136 0.131  ||  -0.190 -0.094 -0.025 0.019 0.069 0.097 0.087 0.051    || dis=0.00 || select=5/8
004/019-th : 0.110 0.108 0.111 0.113 0.126 0.130 0.148 0.154  ||  -0.122 -0.143 -0.118 -0.100 0.009 0.042 0.170 0.214   || dis=0.01 || select=7/8
005/019-th : 0.116 0.122 0.126 0.127 0.129 0.129 0.129 0.122  ||  -0.071 -0.023 0.008 0.018 0.035 0.030 0.030 -0.020    || dis=0.00 || select=4/8
006/019-th : 0.142 0.130 0.117 0.126 0.125 0.116 0.123 0.120  ||  0.134 0.045 -0.064 0.015 0.006 -0.066 -0.008 -0.037   || dis=0.01 || select=0/8
007/019-th : 0.012 0.018 0.028 0.036 0.055 0.081 0.157 0.613  ||  -1.564 -1.172 -0.765 -0.506 -0.086 0.312 0.966 2.331  || dis=0.46 || select=7/8
008/019-th : 0.011 0.015 0.023 0.038 0.058 0.093 0.235 0.526  ||  -1.644 -1.349 -0.926 -0.433 -0.014 0.460 1.385 2.190  || dis=0.29 || select=7/8
009/019-th : 0.079 0.083 0.098 0.112 0.118 0.141 0.169 0.201  ||  -0.418 -0.368 -0.194 -0.063 -0.011 0.166 0.346 0.520  || dis=0.03 || select=7/8
010/019-th : 0.087 0.093 0.102 0.120 0.133 0.145 0.155 0.164  ||  -0.341 -0.268 -0.182 -0.020 0.087 0.172 0.237 0.296   || dis=0.01 || select=7/8
011/019-th : 0.119 0.116 0.112 0.123 0.123 0.132 0.138 0.137  ||  -0.039 -0.066 -0.107 -0.006 -0.010 0.057 0.105 0.096  || dis=0.00 || select=6/8
012/019-th : 0.140 0.135 0.126 0.121 0.124 0.116 0.120 0.117  ||  0.117 0.080 0.011 -0.032 -0.003 -0.069 -0.035 -0.065  || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.007 0.007 0.009 0.012 0.021 0.935  ||  -1.158 -1.065 -0.885 -0.818 -0.582 -0.292 0.274 4.077  || dis=0.91 || select=7/8
014/019-th : 0.006 0.008 0.009 0.012 0.015 0.026 0.061 0.863  ||  -1.429 -1.226 -1.045 -0.808 -0.551 -0.002 0.846 3.494  || dis=0.80 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.008 0.012 0.024 0.932  ||  -1.121 -1.118 -0.953 -0.790 -0.604 -0.276 0.465 4.105  || dis=0.91 || select=7/8
016/019-th : 0.035 0.048 0.055 0.085 0.119 0.171 0.216 0.270  ||  -1.055 -0.745 -0.608 -0.179 0.156 0.515 0.750 0.975   || dis=0.05 || select=7/8
017/019-th : 0.082 0.098 0.117 0.126 0.130 0.128 0.158 0.160  ||  -0.400 -0.215 -0.038 0.034 0.066 0.050 0.256 0.268    || dis=0.00 || select=7/8
018/019-th : 0.097 0.105 0.127 0.141 0.129 0.131 0.133 0.136  ||  -0.244 -0.160 0.028 0.134 0.043 0.056 0.074 0.096     || dis=0.00 || select=3/8
[epoch=478/600] FLOP : 26.83 MB, ratio : 0.6574, Expected-ratio : 0.7000, Discrepancy : 0.229
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:56:23] [epoch=478/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 2.006 (2.006)  Prec@1 51.17 (51.17) Prec@5 86.72 (86.72) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:56:29] [epoch=478/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 4.345 (2.048)  Prec@1 14.29 (48.59) Prec@5 59.52 (85.88) Size=[168, 3, 32, 32]
 **VALID** Prec@1 48.59 Prec@5 85.88 Error@1 51.41 Error@5 14.12 Loss:2.048
***[2020-01-29 09:56:29]*** VALID [epoch=478/600] loss = 2.047863, accuracy@1 = 48.59, accuracy@5 = 85.88 | Best-Valid-Acc@1=45.97, Error@1=54.03
Currently, the best validation accuracy found at 478-epoch :: acc@1=48.59, acc@5=85.88, error@1=51.41, error@5=14.12, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:56:30]*** start epoch=479/600 Time Left: [01:04:31], LR=[0.009704 ~ 0.009704], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=479, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5754757084911367, FLOP=40.81
[Search] : epoch=479/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:56:30] [epoch=479/600][000/098] Time 0.75 (0.75) Data 0.43 (0.43) Base-Loss 1.097 (1.097)  Prec@1 64.45 (64.45) Prec@5 95.70 (95.70) Acls-loss 0.593 (0.593) FLOP-Loss 0.000 (0.000) Arch-Loss 0.593 (0.593)
**TRAIN** [2020-01-29 09:56:57] [epoch=479/600][097/098] Time 0.27 (0.28) Data 0.00 (0.00) Base-Loss 0.329 (0.551)  Prec@1 89.88 (81.24) Prec@5 100.00 (98.85) Acls-loss 0.587 (0.669) FLOP-Loss 2.965 (0.141) Arch-Loss 6.516 (0.952)
 **TRAIN** Prec@1 81.24 Prec@5 98.85 Error@1 18.76 Error@5 1.15 Base-Loss:0.551, Arch-Loss=0.952
***[2020-01-29 09:56:57]*** TRAIN [epoch=479/600] base-loss = 0.551361, arch-loss = 0.951862, accuracy-1 = 81.24, accuracy-5 = 98.85
[epoch=479/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 14, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [3, 3, 3]), ('estimated_FLOP', 29.067004)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.267 0.366 0.367  ||  -0.0456 0.2708 0.2714  || discrepancy=0.00 || select=2/3
001/003-th : 0.320 0.243 0.437  ||  0.0950 -0.1803 0.4080  || discrepancy=0.12 || select=2/3
002/003-th : 0.006 0.029 0.966  ||  -2.2999 -0.6717 2.8479  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.016 0.026 0.030 0.033 0.046 0.078 0.159 0.613  ||  -1.398 -0.910 -0.762 -0.662 -0.335 0.201 0.909 2.259  || dis=0.45 || select=7/8
001/019-th : 0.097 0.121 0.146 0.130 0.136 0.127 0.128 0.115  ||  -0.240 -0.018 0.170 0.056 0.099 0.033 0.035 -0.073    || dis=0.01 || select=2/8
002/019-th : 0.121 0.129 0.128 0.140 0.126 0.130 0.117 0.109  ||  -0.020 0.041 0.035 0.124 0.018 0.049 -0.059 -0.129    || dis=0.01 || select=3/8
003/019-th : 0.100 0.113 0.118 0.128 0.132 0.139 0.137 0.133  ||  -0.217 -0.091 -0.053 0.033 0.062 0.113 0.102 0.069    || dis=0.00 || select=5/8
004/019-th : 0.110 0.108 0.111 0.111 0.127 0.129 0.150 0.153  ||  -0.124 -0.139 -0.118 -0.113 0.023 0.034 0.183 0.208   || dis=0.00 || select=7/8
005/019-th : 0.118 0.122 0.125 0.126 0.129 0.127 0.130 0.123  ||  -0.061 -0.024 0.003 0.010 0.033 0.016 0.037 -0.016    || dis=0.00 || select=6/8
006/019-th : 0.142 0.130 0.117 0.126 0.125 0.114 0.124 0.122  ||  0.134 0.043 -0.063 0.015 0.006 -0.091 -0.005 -0.021   || dis=0.01 || select=0/8
007/019-th : 0.012 0.018 0.027 0.035 0.053 0.079 0.154 0.621  ||  -1.559 -1.183 -0.770 -0.524 -0.092 0.300 0.965 2.360  || dis=0.47 || select=7/8
008/019-th : 0.011 0.015 0.023 0.038 0.057 0.093 0.233 0.530  ||  -1.652 -1.360 -0.936 -0.433 -0.019 0.469 1.385 2.209  || dis=0.30 || select=7/8
009/019-th : 0.077 0.082 0.098 0.111 0.119 0.139 0.169 0.205  ||  -0.434 -0.368 -0.200 -0.073 -0.001 0.154 0.351 0.542  || dis=0.04 || select=7/8
010/019-th : 0.087 0.094 0.102 0.120 0.132 0.147 0.154 0.164  ||  -0.342 -0.267 -0.179 -0.020 0.074 0.186 0.233 0.297   || dis=0.01 || select=7/8
011/019-th : 0.117 0.114 0.113 0.124 0.124 0.130 0.139 0.139  ||  -0.055 -0.083 -0.091 -0.002 -0.004 0.044 0.112 0.111  || dis=0.00 || select=6/8
012/019-th : 0.141 0.136 0.126 0.122 0.125 0.115 0.119 0.116  ||  0.122 0.091 0.011 -0.021 0.003 -0.075 -0.047 -0.071   || dis=0.00 || select=0/8
013/019-th : 0.005 0.005 0.007 0.007 0.009 0.011 0.021 0.935  ||  -1.151 -1.060 -0.880 -0.814 -0.580 -0.318 0.266 4.084  || dis=0.91 || select=7/8
014/019-th : 0.006 0.008 0.009 0.012 0.015 0.025 0.059 0.867  ||  -1.424 -1.224 -1.039 -0.799 -0.559 -0.038 0.837 3.517  || dis=0.81 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.024 0.934  ||  -1.152 -1.108 -0.955 -0.785 -0.602 -0.289 0.463 4.132  || dis=0.91 || select=7/8
016/019-th : 0.035 0.048 0.056 0.084 0.118 0.171 0.216 0.272  ||  -1.054 -0.751 -0.605 -0.196 0.153 0.519 0.753 0.985   || dis=0.06 || select=7/8
017/019-th : 0.081 0.099 0.116 0.129 0.129 0.128 0.160 0.158  ||  -0.406 -0.212 -0.052 0.055 0.053 0.051 0.273 0.259    || dis=0.00 || select=6/8
018/019-th : 0.097 0.105 0.127 0.144 0.129 0.130 0.132 0.137  ||  -0.243 -0.167 0.027 0.153 0.043 0.048 0.063 0.104     || dis=0.01 || select=3/8
[epoch=479/600] FLOP : 29.07 MB, ratio : 0.7122, Expected-ratio : 0.7000, Discrepancy : 0.230
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:56:57] [epoch=479/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 0.955 (0.955)  Prec@1 69.92 (69.92) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:57:04] [epoch=479/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.965 (2.360)  Prec@1 68.45 (46.14) Prec@5 95.83 (84.15) Size=[168, 3, 32, 32]
 **VALID** Prec@1 46.14 Prec@5 84.15 Error@1 53.86 Error@5 15.85 Loss:2.360
***[2020-01-29 09:57:04]*** VALID [epoch=479/600] loss = 2.360013, accuracy@1 = 46.14, accuracy@5 = 84.15 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:57:04]*** start epoch=480/600 Time Left: [01:04:00], LR=[0.009549 ~ 0.009549], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=480, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5679083637813791, FLOP=40.81
[Search] : epoch=480/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:57:05] [epoch=480/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.496 (0.496)  Prec@1 85.16 (85.16) Prec@5 99.61 (99.61) Acls-loss 0.607 (0.607) FLOP-Loss 2.964 (2.964) Arch-Loss 6.536 (6.536)
**TRAIN** [2020-01-29 09:57:31] [epoch=480/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 0.423 (0.559)  Prec@1 85.71 (81.14) Prec@5 100.00 (98.91) Acls-loss 0.498 (0.608) FLOP-Loss -2.965 (0.132) Arch-Loss -5.433 (0.872)
 **TRAIN** Prec@1 81.14 Prec@5 98.91 Error@1 18.86 Error@5 1.09 Base-Loss:0.559, Arch-Loss=0.872
***[2020-01-29 09:57:32]*** TRAIN [epoch=480/600] base-loss = 0.558835, arch-loss = 0.872238, accuracy-1 = 81.14, accuracy-5 = 98.91
[epoch=480/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 14, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.420988)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.264 0.368 0.368  ||  -0.0546 0.2773 0.2765  || discrepancy=0.00 || select=1/3
001/003-th : 0.322 0.242 0.436  ||  0.1006 -0.1840 0.4022  || discrepancy=0.11 || select=2/3
002/003-th : 0.006 0.029 0.966  ||  -2.3000 -0.6658 2.8468  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.016 0.026 0.030 0.033 0.045 0.077 0.155 0.618  ||  -1.392 -0.904 -0.757 -0.655 -0.346 0.188 0.890 2.270  || dis=0.46 || select=7/8
001/019-th : 0.096 0.122 0.145 0.129 0.137 0.127 0.128 0.116  ||  -0.248 -0.013 0.160 0.043 0.107 0.030 0.037 -0.062    || dis=0.01 || select=2/8
002/019-th : 0.121 0.129 0.130 0.140 0.125 0.128 0.118 0.109  ||  -0.023 0.041 0.046 0.125 0.011 0.036 -0.052 -0.125    || dis=0.01 || select=3/8
003/019-th : 0.100 0.114 0.118 0.128 0.131 0.139 0.138 0.133  ||  -0.219 -0.085 -0.053 0.031 0.052 0.112 0.108 0.067    || dis=0.00 || select=5/8
004/019-th : 0.110 0.108 0.110 0.112 0.127 0.131 0.150 0.154  ||  -0.124 -0.141 -0.126 -0.110 0.017 0.047 0.182 0.209   || dis=0.00 || select=7/8
005/019-th : 0.116 0.122 0.124 0.128 0.129 0.125 0.132 0.123  ||  -0.072 -0.020 -0.010 0.021 0.031 0.002 0.059 -0.012   || dis=0.00 || select=6/8
006/019-th : 0.143 0.129 0.118 0.128 0.124 0.113 0.123 0.122  ||  0.138 0.037 -0.054 0.026 -0.002 -0.092 -0.014 -0.020  || dis=0.01 || select=0/8
007/019-th : 0.012 0.018 0.027 0.033 0.052 0.077 0.152 0.628  ||  -1.566 -1.173 -0.763 -0.553 -0.101 0.289 0.968 2.386  || dis=0.48 || select=7/8
008/019-th : 0.011 0.015 0.022 0.037 0.055 0.090 0.230 0.540  ||  -1.653 -1.363 -0.941 -0.437 -0.047 0.443 1.388 2.239  || dis=0.31 || select=7/8
009/019-th : 0.078 0.083 0.098 0.109 0.119 0.138 0.168 0.207  ||  -0.426 -0.362 -0.200 -0.089 0.000 0.143 0.342 0.554   || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.100 0.120 0.132 0.148 0.157 0.164  ||  -0.340 -0.273 -0.196 -0.021 0.075 0.190 0.250 0.294   || dis=0.01 || select=7/8
011/019-th : 0.117 0.115 0.113 0.124 0.124 0.132 0.138 0.138  ||  -0.060 -0.080 -0.095 -0.003 -0.001 0.058 0.109 0.104  || dis=0.00 || select=6/8
012/019-th : 0.141 0.137 0.126 0.122 0.125 0.115 0.119 0.116  ||  0.122 0.095 0.010 -0.022 -0.000 -0.080 -0.048 -0.068  || dis=0.00 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.012 0.020 0.935  ||  -1.143 -1.052 -0.875 -0.806 -0.574 -0.318 0.256 4.078  || dis=0.92 || select=7/8
014/019-th : 0.006 0.008 0.009 0.011 0.015 0.025 0.059 0.868  ||  -1.417 -1.217 -1.039 -0.817 -0.557 -0.038 0.828 3.523  || dis=0.81 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.023 0.936  ||  -1.149 -1.101 -0.946 -0.782 -0.597 -0.308 0.421 4.145  || dis=0.91 || select=7/8
016/019-th : 0.036 0.048 0.056 0.082 0.116 0.170 0.217 0.275  ||  -1.044 -0.752 -0.602 -0.214 0.133 0.515 0.760 0.997   || dis=0.06 || select=7/8
017/019-th : 0.082 0.098 0.114 0.130 0.128 0.130 0.160 0.158  ||  -0.398 -0.217 -0.071 0.060 0.048 0.065 0.273 0.258    || dis=0.00 || select=6/8
018/019-th : 0.097 0.105 0.127 0.144 0.129 0.127 0.133 0.138  ||  -0.240 -0.165 0.026 0.153 0.046 0.025 0.070 0.107     || dis=0.01 || select=3/8
[epoch=480/600] FLOP : 26.42 MB, ratio : 0.6474, Expected-ratio : 0.7000, Discrepancy : 0.232
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:57:32] [epoch=480/600][000/098] Time 0.42 (0.42) Data 0.30 (0.30) Loss 1.036 (1.036)  Prec@1 67.97 (67.97) Prec@5 96.09 (96.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:57:39] [epoch=480/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 5.161 (2.233)  Prec@1 16.07 (47.39) Prec@5 76.79 (85.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.39 Prec@5 85.20 Error@1 52.61 Error@5 14.80 Loss:2.233
***[2020-01-29 09:57:39]*** VALID [epoch=480/600] loss = 2.233340, accuracy@1 = 47.39, accuracy@5 = 85.20 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:57:39]*** start epoch=481/600 Time Left: [01:03:29], LR=[0.009396 ~ 0.009396], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=481, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5603953591150747, FLOP=40.81
[Search] : epoch=481/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:57:39] [epoch=481/600][000/098] Time 0.69 (0.69) Data 0.39 (0.39) Base-Loss 0.501 (0.501)  Prec@1 83.59 (83.59) Prec@5 99.22 (99.22) Acls-loss 0.543 (0.543) FLOP-Loss -2.966 (-2.966) Arch-Loss -5.388 (-5.388)
**TRAIN** [2020-01-29 09:58:05] [epoch=481/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.519 (0.553)  Prec@1 80.36 (81.13) Prec@5 99.40 (98.92) Acls-loss 0.628 (0.637) FLOP-Loss 0.000 (0.122) Arch-Loss 0.628 (0.880)
 **TRAIN** Prec@1 81.13 Prec@5 98.92 Error@1 18.87 Error@5 1.08 Base-Loss:0.553, Arch-Loss=0.880
***[2020-01-29 09:58:06]*** TRAIN [epoch=481/600] base-loss = 0.552898, arch-loss = 0.880095, accuracy-1 = 81.13, accuracy-5 = 98.92
[epoch=481/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.798844)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.263 0.369 0.369  ||  -0.0598 0.2799 0.2790  || discrepancy=0.00 || select=1/3
001/003-th : 0.322 0.242 0.436  ||  0.0987 -0.1853 0.4034  || discrepancy=0.11 || select=2/3
002/003-th : 0.006 0.029 0.966  ||  -2.3065 -0.6615 2.8525  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.016 0.025 0.029 0.032 0.044 0.075 0.153 0.626  ||  -1.385 -0.923 -0.767 -0.684 -0.343 0.179 0.891 2.302  || dis=0.47 || select=7/8
001/019-th : 0.097 0.123 0.145 0.128 0.136 0.127 0.128 0.116  ||  -0.245 -0.006 0.159 0.038 0.099 0.028 0.033 -0.060    || dis=0.01 || select=2/8
002/019-th : 0.121 0.129 0.130 0.140 0.123 0.128 0.119 0.109  ||  -0.023 0.043 0.049 0.126 -0.007 0.036 -0.044 -0.127   || dis=0.01 || select=3/8
003/019-th : 0.099 0.114 0.119 0.126 0.132 0.140 0.139 0.132  ||  -0.230 -0.085 -0.044 0.018 0.062 0.123 0.111 0.063    || dis=0.00 || select=5/8
004/019-th : 0.110 0.108 0.109 0.112 0.126 0.129 0.149 0.156  ||  -0.121 -0.140 -0.133 -0.107 0.013 0.035 0.179 0.221   || dis=0.01 || select=7/8
005/019-th : 0.116 0.123 0.124 0.128 0.128 0.125 0.131 0.124  ||  -0.071 -0.013 -0.004 0.025 0.022 0.004 0.046 -0.009   || dis=0.00 || select=6/8
006/019-th : 0.143 0.129 0.116 0.129 0.124 0.113 0.123 0.123  ||  0.136 0.037 -0.068 0.035 -0.006 -0.093 -0.011 -0.015  || dis=0.01 || select=0/8
007/019-th : 0.012 0.017 0.026 0.032 0.051 0.076 0.150 0.636  ||  -1.568 -1.215 -0.763 -0.561 -0.104 0.289 0.974 2.417  || dis=0.49 || select=7/8
008/019-th : 0.011 0.015 0.023 0.037 0.055 0.089 0.228 0.544  ||  -1.658 -1.366 -0.930 -0.445 -0.046 0.442 1.380 2.251  || dis=0.32 || select=7/8
009/019-th : 0.079 0.084 0.098 0.109 0.119 0.137 0.168 0.208  ||  -0.419 -0.355 -0.201 -0.090 -0.004 0.134 0.340 0.555  || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.099 0.119 0.131 0.148 0.156 0.168  ||  -0.343 -0.275 -0.210 -0.028 0.067 0.192 0.246 0.318   || dis=0.01 || select=7/8
011/019-th : 0.117 0.115 0.113 0.124 0.124 0.131 0.137 0.139  ||  -0.061 -0.076 -0.092 -0.003 -0.001 0.053 0.100 0.110  || dis=0.00 || select=7/8
012/019-th : 0.141 0.137 0.125 0.122 0.124 0.115 0.118 0.117  ||  0.120 0.097 0.006 -0.022 -0.002 -0.077 -0.052 -0.064  || dis=0.00 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.011 0.020 0.935  ||  -1.139 -1.045 -0.869 -0.802 -0.569 -0.336 0.254 4.078  || dis=0.92 || select=7/8
014/019-th : 0.006 0.007 0.009 0.011 0.014 0.024 0.057 0.872  ||  -1.409 -1.210 -1.045 -0.821 -0.558 -0.061 0.813 3.548  || dis=0.81 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.022 0.938  ||  -1.161 -1.091 -0.954 -0.791 -0.593 -0.314 0.411 4.163  || dis=0.92 || select=7/8
016/019-th : 0.035 0.048 0.055 0.082 0.115 0.168 0.219 0.278  ||  -1.059 -0.746 -0.618 -0.205 0.124 0.510 0.774 1.009   || dis=0.06 || select=7/8
017/019-th : 0.081 0.098 0.111 0.130 0.129 0.131 0.161 0.160  ||  -0.405 -0.220 -0.096 0.063 0.053 0.072 0.276 0.270    || dis=0.00 || select=6/8
018/019-th : 0.096 0.104 0.127 0.144 0.128 0.128 0.133 0.138  ||  -0.250 -0.170 0.030 0.155 0.035 0.037 0.076 0.109     || dis=0.01 || select=3/8
[epoch=481/600] FLOP : 26.80 MB, ratio : 0.6566, Expected-ratio : 0.7000, Discrepancy : 0.234
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:58:06] [epoch=481/600][000/098] Time 0.40 (0.40) Data 0.32 (0.32) Loss 3.489 (3.489)  Prec@1 21.09 (21.09) Prec@5 74.61 (74.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:58:13] [epoch=481/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.790 (2.159)  Prec@1 10.71 (43.52) Prec@5 70.24 (82.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 43.52 Prec@5 82.70 Error@1 56.48 Error@5 17.30 Loss:2.159
***[2020-01-29 09:58:13]*** VALID [epoch=481/600] loss = 2.159217, accuracy@1 = 43.52, accuracy@5 = 82.70 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:58:13]*** start epoch=482/600 Time Left: [01:02:57], LR=[0.009244 ~ 0.009244], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=482, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.552936900465042, FLOP=40.81
[Search] : epoch=482/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:58:13] [epoch=482/600][000/098] Time 0.68 (0.68) Data 0.38 (0.38) Base-Loss 0.432 (0.432)  Prec@1 87.11 (87.11) Prec@5 99.22 (99.22) Acls-loss 0.717 (0.717) FLOP-Loss 0.000 (0.000) Arch-Loss 0.717 (0.717)
**TRAIN** [2020-01-29 09:58:39] [epoch=482/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.486 (0.529)  Prec@1 48.21 (82.08) Prec@5 94.05 (98.90) Acls-loss 0.733 (0.634) FLOP-Loss 0.000 (0.122) Arch-Loss 0.733 (0.877)
 **TRAIN** Prec@1 82.08 Prec@5 98.90 Error@1 17.92 Error@5 1.10 Base-Loss:0.529, Arch-Loss=0.877
***[2020-01-29 09:58:39]*** TRAIN [epoch=482/600] base-loss = 0.528864, arch-loss = 0.876818, accuracy-1 = 82.08, accuracy-5 = 98.90
[epoch=482/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.259644)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.259 0.371 0.370  ||  -0.0700 0.2869 0.2851  || discrepancy=0.00 || select=1/3
001/003-th : 0.321 0.241 0.438  ||  0.0965 -0.1925 0.4064  || discrepancy=0.12 || select=2/3
002/003-th : 0.006 0.029 0.965  ||  -2.2974 -0.6642 2.8449  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.015 0.025 0.029 0.031 0.044 0.074 0.153 0.630  ||  -1.398 -0.914 -0.774 -0.697 -0.342 0.174 0.902 2.318  || dis=0.48 || select=7/8
001/019-th : 0.097 0.121 0.144 0.129 0.134 0.129 0.128 0.117  ||  -0.243 -0.022 0.155 0.041 0.084 0.045 0.038 -0.052    || dis=0.01 || select=2/8
002/019-th : 0.121 0.130 0.131 0.138 0.122 0.128 0.120 0.110  ||  -0.024 0.045 0.051 0.109 -0.019 0.035 -0.029 -0.124   || dis=0.01 || select=3/8
003/019-th : 0.099 0.113 0.118 0.126 0.133 0.140 0.140 0.132  ||  -0.228 -0.095 -0.050 0.014 0.067 0.119 0.122 0.065    || dis=0.00 || select=6/8
004/019-th : 0.111 0.108 0.109 0.111 0.127 0.130 0.149 0.155  ||  -0.119 -0.139 -0.136 -0.114 0.023 0.040 0.177 0.218   || dis=0.01 || select=7/8
005/019-th : 0.115 0.123 0.125 0.129 0.128 0.124 0.130 0.126  ||  -0.079 -0.014 0.004 0.031 0.027 -0.008 0.037 0.005    || dis=0.00 || select=6/8
006/019-th : 0.143 0.129 0.115 0.129 0.124 0.114 0.124 0.122  ||  0.137 0.037 -0.076 0.034 -0.004 -0.086 -0.006 -0.021  || dis=0.01 || select=0/8
007/019-th : 0.012 0.017 0.026 0.032 0.050 0.074 0.145 0.644  ||  -1.564 -1.215 -0.754 -0.570 -0.107 0.282 0.949 2.442  || dis=0.50 || select=7/8
008/019-th : 0.011 0.015 0.022 0.036 0.054 0.090 0.229 0.544  ||  -1.669 -1.358 -0.930 -0.455 -0.061 0.456 1.389 2.256  || dis=0.32 || select=7/8
009/019-th : 0.078 0.084 0.098 0.107 0.118 0.135 0.168 0.211  ||  -0.428 -0.348 -0.196 -0.106 -0.008 0.127 0.343 0.568  || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.099 0.119 0.130 0.149 0.155 0.166  ||  -0.340 -0.272 -0.205 -0.022 0.065 0.202 0.238 0.309   || dis=0.01 || select=7/8
011/019-th : 0.115 0.114 0.113 0.125 0.127 0.130 0.137 0.139  ||  -0.075 -0.081 -0.093 0.007 0.022 0.045 0.099 0.112    || dis=0.00 || select=7/8
012/019-th : 0.139 0.137 0.126 0.122 0.126 0.115 0.118 0.116  ||  0.108 0.099 0.014 -0.019 0.014 -0.076 -0.049 -0.070   || dis=0.00 || select=0/8
013/019-th : 0.005 0.006 0.007 0.007 0.009 0.011 0.020 0.935  ||  -1.136 -1.049 -0.863 -0.799 -0.559 -0.336 0.242 4.079  || dis=0.92 || select=7/8
014/019-th : 0.006 0.007 0.009 0.010 0.014 0.023 0.053 0.878  ||  -1.410 -1.240 -1.045 -0.841 -0.551 -0.058 0.789 3.587  || dis=0.82 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.022 0.937  ||  -1.159 -1.080 -0.947 -0.784 -0.591 -0.313 0.398 4.159  || dis=0.92 || select=7/8
016/019-th : 0.035 0.047 0.055 0.082 0.110 0.169 0.222 0.281  ||  -1.061 -0.763 -0.611 -0.208 0.090 0.516 0.789 1.025   || dis=0.06 || select=7/8
017/019-th : 0.081 0.097 0.110 0.130 0.128 0.132 0.162 0.159  ||  -0.406 -0.226 -0.103 0.068 0.050 0.078 0.284 0.269    || dis=0.00 || select=6/8
018/019-th : 0.096 0.103 0.128 0.143 0.128 0.128 0.135 0.139  ||  -0.252 -0.179 0.031 0.143 0.032 0.035 0.089 0.116     || dis=0.00 || select=3/8
[epoch=482/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.235
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:58:40] [epoch=482/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 1.697 (1.697)  Prec@1 47.66 (47.66) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:58:46] [epoch=482/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.948 (2.080)  Prec@1 10.71 (47.58) Prec@5 54.76 (84.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.58 Prec@5 84.62 Error@1 52.42 Error@5 15.38 Loss:2.080
***[2020-01-29 09:58:46]*** VALID [epoch=482/600] loss = 2.080095, accuracy@1 = 47.58, accuracy@5 = 84.62 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:58:47]*** start epoch=483/600 Time Left: [01:02:25], LR=[0.009093 ~ 0.009093], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=483, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5455331923086921, FLOP=40.81
[Search] : epoch=483/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:58:47] [epoch=483/600][000/098] Time 0.66 (0.66) Data 0.39 (0.39) Base-Loss 0.563 (0.563)  Prec@1 80.47 (80.47) Prec@5 98.83 (98.83) Acls-loss 1.037 (1.037) FLOP-Loss 0.000 (0.000) Arch-Loss 1.037 (1.037)
**TRAIN** [2020-01-29 09:59:13] [epoch=483/600][097/098] Time 0.27 (0.27) Data 0.00 (0.00) Base-Loss 0.403 (0.536)  Prec@1 86.31 (81.65) Prec@5 100.00 (99.08) Acls-loss 0.597 (0.671) FLOP-Loss 0.000 (0.122) Arch-Loss 0.597 (0.915)
 **TRAIN** Prec@1 81.65 Prec@5 99.08 Error@1 18.35 Error@5 0.92 Base-Loss:0.536, Arch-Loss=0.915
***[2020-01-29 09:59:13]*** TRAIN [epoch=483/600] base-loss = 0.536107, arch-loss = 0.914940, accuracy-1 = 81.65, accuracy-5 = 99.08
[epoch=483/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.259644)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.259 0.370 0.370  ||  -0.0708 0.2847 0.2847  || discrepancy=0.00 || select=1/3
001/003-th : 0.321 0.244 0.436  ||  0.0963 -0.1789 0.4025  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.029 0.966  ||  -2.3173 -0.6517 2.8613  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.015 0.024 0.028 0.030 0.043 0.072 0.152 0.635  ||  -1.390 -0.932 -0.771 -0.705 -0.355 0.156 0.906 2.338  || dis=0.48 || select=7/8
001/019-th : 0.097 0.122 0.144 0.129 0.134 0.128 0.129 0.117  ||  -0.247 -0.016 0.152 0.043 0.080 0.035 0.046 -0.052    || dis=0.01 || select=2/8
002/019-th : 0.118 0.128 0.132 0.138 0.123 0.130 0.121 0.110  ||  -0.048 0.038 0.066 0.111 -0.009 0.051 -0.026 -0.122   || dis=0.01 || select=3/8
003/019-th : 0.100 0.111 0.119 0.125 0.133 0.138 0.140 0.133  ||  -0.219 -0.109 -0.045 0.011 0.073 0.105 0.123 0.072    || dis=0.00 || select=6/8
004/019-th : 0.111 0.110 0.110 0.108 0.126 0.131 0.151 0.154  ||  -0.117 -0.129 -0.127 -0.140 0.014 0.048 0.189 0.211   || dis=0.00 || select=7/8
005/019-th : 0.116 0.124 0.125 0.128 0.127 0.124 0.128 0.126  ||  -0.078 -0.006 0.004 0.028 0.019 -0.003 0.027 0.011    || dis=0.00 || select=3/8
006/019-th : 0.142 0.129 0.117 0.128 0.123 0.114 0.125 0.122  ||  0.134 0.036 -0.065 0.028 -0.016 -0.085 0.005 -0.024   || dis=0.01 || select=0/8
007/019-th : 0.012 0.017 0.026 0.031 0.050 0.073 0.142 0.651  ||  -1.556 -1.208 -0.763 -0.593 -0.111 0.273 0.942 2.464  || dis=0.51 || select=7/8
008/019-th : 0.011 0.015 0.023 0.036 0.053 0.090 0.228 0.544  ||  -1.664 -1.362 -0.926 -0.448 -0.069 0.458 1.387 2.254  || dis=0.32 || select=7/8
009/019-th : 0.078 0.085 0.099 0.108 0.118 0.135 0.168 0.210  ||  -0.430 -0.343 -0.190 -0.096 -0.010 0.122 0.343 0.563  || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.098 0.119 0.130 0.150 0.155 0.168  ||  -0.335 -0.275 -0.216 -0.024 0.061 0.205 0.236 0.317   || dis=0.01 || select=7/8
011/019-th : 0.115 0.114 0.113 0.126 0.127 0.129 0.137 0.139  ||  -0.077 -0.081 -0.095 0.012 0.019 0.040 0.100 0.116    || dis=0.00 || select=7/8
012/019-th : 0.139 0.137 0.125 0.123 0.126 0.115 0.118 0.117  ||  0.109 0.096 0.006 -0.015 0.012 -0.079 -0.050 -0.064   || dis=0.00 || select=0/8
013/019-th : 0.005 0.005 0.007 0.007 0.009 0.011 0.020 0.936  ||  -1.129 -1.060 -0.857 -0.811 -0.570 -0.348 0.239 4.095  || dis=0.92 || select=7/8
014/019-th : 0.006 0.007 0.008 0.010 0.013 0.022 0.051 0.883  ||  -1.418 -1.270 -1.039 -0.862 -0.555 -0.053 0.771 3.631  || dis=0.83 || select=7/8
015/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.022 0.938  ||  -1.156 -1.069 -0.939 -0.800 -0.589 -0.318 0.390 4.161  || dis=0.92 || select=7/8
016/019-th : 0.035 0.046 0.054 0.082 0.109 0.168 0.224 0.282  ||  -1.050 -0.781 -0.621 -0.209 0.085 0.511 0.804 1.031   || dis=0.06 || select=7/8
017/019-th : 0.080 0.097 0.109 0.130 0.128 0.133 0.164 0.161  ||  -0.418 -0.228 -0.114 0.064 0.048 0.086 0.296 0.278    || dis=0.00 || select=6/8
018/019-th : 0.095 0.104 0.125 0.144 0.126 0.128 0.134 0.144  ||  -0.260 -0.175 0.012 0.150 0.020 0.033 0.076 0.148     || dis=0.00 || select=3/8
[epoch=483/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.235
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:59:14] [epoch=483/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 1.289 (1.289)  Prec@1 66.02 (66.02) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:59:20] [epoch=483/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.732 (1.928)  Prec@1 41.67 (47.84) Prec@5 82.14 (85.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.84 Prec@5 85.62 Error@1 52.16 Error@5 14.38 Loss:1.928
***[2020-01-29 09:59:20]*** VALID [epoch=483/600] loss = 1.927565, accuracy@1 = 47.84, accuracy@5 = 85.62 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:59:20]*** start epoch=484/600 Time Left: [01:01:54], LR=[0.008943 ~ 0.008943], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=484, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5381844376224252, FLOP=40.81
[Search] : epoch=484/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:59:21] [epoch=484/600][000/098] Time 0.69 (0.69) Data 0.40 (0.40) Base-Loss 0.415 (0.415)  Prec@1 85.16 (85.16) Prec@5 99.61 (99.61) Acls-loss 0.563 (0.563) FLOP-Loss 0.000 (0.000) Arch-Loss 0.563 (0.563)
**TRAIN** [2020-01-29 09:59:47] [epoch=484/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.429 (0.531)  Prec@1 86.90 (81.77) Prec@5 99.40 (99.08) Acls-loss 0.553 (0.632) FLOP-Loss 0.000 (0.122) Arch-Loss 0.553 (0.875)
 **TRAIN** Prec@1 81.77 Prec@5 99.08 Error@1 18.23 Error@5 0.92 Base-Loss:0.531, Arch-Loss=0.875
***[2020-01-29 09:59:47]*** TRAIN [epoch=484/600] base-loss = 0.531286, arch-loss = 0.875201, accuracy-1 = 81.77, accuracy-5 = 99.08
[epoch=484/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.670908)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.256 0.373 0.371  ||  -0.0823 0.2955 0.2906  || discrepancy=0.00 || select=1/3
001/003-th : 0.321 0.245 0.435  ||  0.0968 -0.1746 0.4001  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.028 0.967  ||  -2.3429 -0.6567 2.8885  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.015 0.024 0.028 0.030 0.042 0.070 0.148 0.642  ||  -1.380 -0.935 -0.775 -0.701 -0.367 0.144 0.888 2.355  || dis=0.49 || select=7/8
001/019-th : 0.097 0.120 0.145 0.128 0.131 0.130 0.132 0.117  ||  -0.241 -0.032 0.159 0.038 0.057 0.049 0.066 -0.059    || dis=0.01 || select=2/8
002/019-th : 0.117 0.129 0.132 0.137 0.123 0.130 0.122 0.110  ||  -0.055 0.039 0.066 0.098 -0.009 0.049 -0.016 -0.115   || dis=0.01 || select=3/8
003/019-th : 0.099 0.110 0.118 0.125 0.136 0.137 0.143 0.133  ||  -0.224 -0.120 -0.053 0.009 0.090 0.099 0.140 0.070    || dis=0.01 || select=6/8
004/019-th : 0.111 0.110 0.110 0.108 0.128 0.129 0.149 0.155  ||  -0.113 -0.128 -0.127 -0.146 0.029 0.032 0.182 0.222   || dis=0.01 || select=7/8
005/019-th : 0.114 0.123 0.125 0.128 0.130 0.125 0.128 0.126  ||  -0.087 -0.011 0.003 0.026 0.038 0.004 0.026 0.010     || dis=0.00 || select=4/8
006/019-th : 0.142 0.129 0.117 0.126 0.122 0.115 0.127 0.122  ||  0.131 0.032 -0.063 0.012 -0.020 -0.079 0.016 -0.023   || dis=0.01 || select=0/8
007/019-th : 0.012 0.016 0.025 0.029 0.047 0.071 0.136 0.664  ||  -1.549 -1.201 -0.767 -0.628 -0.136 0.276 0.920 2.506  || dis=0.53 || select=7/8
008/019-th : 0.011 0.015 0.022 0.036 0.052 0.089 0.227 0.548  ||  -1.661 -1.357 -0.930 -0.456 -0.082 0.453 1.385 2.266  || dis=0.32 || select=7/8
009/019-th : 0.078 0.085 0.097 0.107 0.118 0.133 0.170 0.211  ||  -0.427 -0.335 -0.203 -0.107 -0.010 0.109 0.356 0.569  || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.099 0.117 0.130 0.150 0.156 0.169  ||  -0.341 -0.271 -0.212 -0.040 0.063 0.205 0.242 0.323   || dis=0.01 || select=7/8
011/019-th : 0.115 0.116 0.113 0.126 0.125 0.128 0.138 0.140  ||  -0.077 -0.072 -0.098 0.017 0.004 0.031 0.104 0.120    || dis=0.00 || select=7/8
012/019-th : 0.139 0.136 0.125 0.124 0.124 0.115 0.119 0.117  ||  0.108 0.091 0.007 -0.007 -0.002 -0.077 -0.041 -0.062  || dis=0.00 || select=0/8
013/019-th : 0.005 0.005 0.007 0.007 0.009 0.011 0.019 0.937  ||  -1.144 -1.054 -0.850 -0.805 -0.566 -0.331 0.211 4.103  || dis=0.92 || select=7/8
014/019-th : 0.006 0.006 0.008 0.010 0.013 0.021 0.048 0.889  ||  -1.412 -1.266 -1.041 -0.863 -0.553 -0.082 0.738 3.663  || dis=0.84 || select=7/8
015/019-th : 0.005 0.005 0.006 0.006 0.008 0.010 0.021 0.939  ||  -1.153 -1.057 -0.947 -0.805 -0.612 -0.328 0.387 4.172  || dis=0.92 || select=7/8
016/019-th : 0.035 0.045 0.053 0.081 0.109 0.168 0.224 0.286  ||  -1.060 -0.801 -0.626 -0.206 0.084 0.517 0.806 1.050   || dis=0.06 || select=7/8
017/019-th : 0.079 0.096 0.106 0.128 0.131 0.133 0.163 0.164  ||  -0.431 -0.237 -0.138 0.054 0.072 0.088 0.297 0.302    || dis=0.00 || select=7/8
018/019-th : 0.096 0.103 0.126 0.142 0.126 0.131 0.136 0.141  ||  -0.255 -0.184 0.018 0.134 0.016 0.056 0.091 0.132     || dis=0.00 || select=3/8
[epoch=484/600] FLOP : 27.67 MB, ratio : 0.6780, Expected-ratio : 0.7000, Discrepancy : 0.238
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 09:59:47] [epoch=484/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.447 (3.447)  Prec@1 17.58 (17.58) Prec@5 70.31 (70.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 09:59:54] [epoch=484/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.433 (2.411)  Prec@1 36.90 (45.74) Prec@5 86.31 (84.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 45.74 Prec@5 84.38 Error@1 54.26 Error@5 15.62 Loss:2.411
***[2020-01-29 09:59:54]*** VALID [epoch=484/600] loss = 2.410966, accuracy@1 = 45.74, accuracy@5 = 84.38 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 09:59:54]*** start epoch=485/600 Time Left: [01:01:22], LR=[0.008794 ~ 0.008794], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=485, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5308908378760616, FLOP=40.81
[Search] : epoch=485/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 09:59:55] [epoch=485/600][000/098] Time 0.69 (0.69) Data 0.39 (0.39) Base-Loss 0.446 (0.446)  Prec@1 84.77 (84.77) Prec@5 99.61 (99.61) Acls-loss 0.796 (0.796) FLOP-Loss 0.000 (0.000) Arch-Loss 0.796 (0.796)
**TRAIN** [2020-01-29 10:00:20] [epoch=485/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.387 (0.522)  Prec@1 87.50 (82.17) Prec@5 100.00 (99.09) Acls-loss 0.894 (0.668) FLOP-Loss 0.000 (0.152) Arch-Loss 0.894 (0.973)
 **TRAIN** Prec@1 82.17 Prec@5 99.09 Error@1 17.83 Error@5 0.91 Base-Loss:0.522, Arch-Loss=0.973
***[2020-01-29 10:00:20]*** TRAIN [epoch=485/600] base-loss = 0.521945, arch-loss = 0.972540, accuracy-1 = 82.17, accuracy-5 = 99.09
[epoch=485/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 14, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.670908)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.255 0.373 0.372  ||  -0.0861 0.2934 0.2930  || discrepancy=0.00 || select=1/3
001/003-th : 0.316 0.246 0.438  ||  0.0836 -0.1678 0.4106  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.028 0.966  ||  -2.3342 -0.6465 2.8780  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.015 0.023 0.027 0.029 0.042 0.069 0.142 0.652  ||  -1.391 -0.932 -0.781 -0.728 -0.356 0.146 0.870 2.392  || dis=0.51 || select=7/8
001/019-th : 0.095 0.120 0.144 0.128 0.132 0.130 0.135 0.116  ||  -0.265 -0.028 0.151 0.034 0.068 0.049 0.091 -0.059    || dis=0.01 || select=2/8
002/019-th : 0.117 0.128 0.134 0.136 0.122 0.130 0.123 0.110  ||  -0.056 0.031 0.075 0.092 -0.013 0.050 -0.009 -0.114   || dis=0.00 || select=3/8
003/019-th : 0.099 0.108 0.119 0.125 0.135 0.138 0.143 0.132  ||  -0.224 -0.134 -0.037 0.012 0.086 0.106 0.140 0.066    || dis=0.00 || select=6/8
004/019-th : 0.111 0.110 0.110 0.109 0.128 0.129 0.149 0.154  ||  -0.117 -0.123 -0.120 -0.135 0.031 0.032 0.178 0.214   || dis=0.01 || select=7/8
005/019-th : 0.115 0.123 0.126 0.128 0.130 0.124 0.129 0.125  ||  -0.083 -0.011 0.012 0.022 0.044 -0.005 0.032 -0.002   || dis=0.00 || select=4/8
006/019-th : 0.141 0.128 0.116 0.127 0.123 0.116 0.127 0.122  ||  0.124 0.030 -0.069 0.016 -0.013 -0.072 0.015 -0.021   || dis=0.01 || select=0/8
007/019-th : 0.010 0.015 0.024 0.028 0.045 0.067 0.129 0.681  ||  -1.602 -1.223 -0.768 -0.628 -0.147 0.266 0.917 2.579  || dis=0.55 || select=7/8
008/019-th : 0.011 0.015 0.022 0.036 0.052 0.089 0.228 0.548  ||  -1.671 -1.358 -0.928 -0.453 -0.079 0.449 1.394 2.270  || dis=0.32 || select=7/8
009/019-th : 0.077 0.086 0.097 0.107 0.116 0.134 0.172 0.212  ||  -0.443 -0.323 -0.203 -0.111 -0.027 0.115 0.368 0.574  || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.098 0.117 0.128 0.153 0.156 0.169  ||  -0.334 -0.277 -0.223 -0.043 0.048 0.225 0.246 0.325   || dis=0.01 || select=7/8
011/019-th : 0.116 0.116 0.113 0.122 0.124 0.128 0.139 0.141  ||  -0.069 -0.068 -0.093 -0.022 -0.001 0.031 0.115 0.128  || dis=0.00 || select=7/8
012/019-th : 0.139 0.133 0.125 0.126 0.126 0.115 0.120 0.116  ||  0.111 0.071 0.007 0.016 0.012 -0.073 -0.038 -0.069    || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.018 0.939  ||  -1.136 -1.047 -0.845 -0.802 -0.595 -0.344 0.190 4.129  || dis=0.92 || select=7/8
014/019-th : 0.005 0.006 0.008 0.009 0.013 0.021 0.046 0.891  ||  -1.405 -1.277 -1.044 -0.876 -0.565 -0.082 0.729 3.685  || dis=0.84 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.008 0.010 0.021 0.940  ||  -1.162 -1.045 -0.963 -0.798 -0.613 -0.329 0.368 4.188  || dis=0.92 || select=7/8
016/019-th : 0.034 0.044 0.053 0.082 0.107 0.167 0.222 0.291  ||  -1.060 -0.821 -0.629 -0.196 0.068 0.519 0.802 1.072   || dis=0.07 || select=7/8
017/019-th : 0.079 0.095 0.106 0.127 0.131 0.132 0.164 0.166  ||  -0.430 -0.243 -0.136 0.042 0.072 0.086 0.301 0.310    || dis=0.00 || select=7/8
018/019-th : 0.096 0.103 0.126 0.142 0.126 0.130 0.134 0.141  ||  -0.257 -0.180 0.020 0.138 0.020 0.051 0.083 0.133     || dis=0.00 || select=3/8
[epoch=485/600] FLOP : 27.67 MB, ratio : 0.6780, Expected-ratio : 0.7000, Discrepancy : 0.241
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:00:20] [epoch=485/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.375 (1.375)  Prec@1 52.34 (52.34) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:00:27] [epoch=485/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 0.862 (2.371)  Prec@1 75.60 (47.34) Prec@5 97.62 (85.29) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.34 Prec@5 85.29 Error@1 52.66 Error@5 14.71 Loss:2.371
***[2020-01-29 10:00:27]*** VALID [epoch=485/600] loss = 2.371045, accuracy@1 = 47.34, accuracy@5 = 85.29 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:00:27]*** start epoch=486/600 Time Left: [01:00:50], LR=[0.008646 ~ 0.008646], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=486, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5236525930273233, FLOP=40.81
[Search] : epoch=486/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:00:27] [epoch=486/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.471 (0.471)  Prec@1 85.55 (85.55) Prec@5 99.22 (99.22) Acls-loss 0.674 (0.674) FLOP-Loss 0.000 (0.000) Arch-Loss 0.674 (0.674)
**TRAIN** [2020-01-29 10:00:51] [epoch=486/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.584 (0.521)  Prec@1 82.14 (82.22) Prec@5 98.21 (99.04) Acls-loss 0.534 (0.641) FLOP-Loss 0.000 (0.122) Arch-Loss 0.534 (0.885)
 **TRAIN** Prec@1 82.22 Prec@5 99.04 Error@1 17.78 Error@5 0.96 Base-Loss:0.521, Arch-Loss=0.885
***[2020-01-29 10:00:51]*** TRAIN [epoch=486/600] base-loss = 0.520668, arch-loss = 0.885298, accuracy-1 = 82.22, accuracy-5 = 99.04
[epoch=486/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.435388)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.246 0.378 0.376  ||  -0.1136 0.3176 0.3101  || discrepancy=0.00 || select=1/3
001/003-th : 0.312 0.247 0.441  ||  0.0721 -0.1596 0.4191  || discrepancy=0.13 || select=2/3
002/003-th : 0.005 0.028 0.966  ||  -2.3389 -0.6446 2.8825  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.015 0.023 0.026 0.028 0.041 0.067 0.140 0.660  ||  -1.394 -0.944 -0.800 -0.723 -0.364 0.127 0.870 2.421  || dis=0.52 || select=7/8
001/019-th : 0.094 0.120 0.142 0.131 0.133 0.129 0.135 0.117  ||  -0.276 -0.029 0.140 0.059 0.073 0.046 0.088 -0.054    || dis=0.01 || select=2/8
002/019-th : 0.118 0.127 0.135 0.134 0.123 0.129 0.123 0.112  ||  -0.052 0.025 0.081 0.078 -0.012 0.042 -0.011 -0.105   || dis=0.00 || select=2/8
003/019-th : 0.099 0.108 0.119 0.126 0.136 0.137 0.142 0.133  ||  -0.227 -0.135 -0.038 0.014 0.091 0.102 0.138 0.073    || dis=0.00 || select=6/8
004/019-th : 0.110 0.109 0.111 0.110 0.127 0.127 0.149 0.156  ||  -0.122 -0.129 -0.116 -0.126 0.023 0.020 0.183 0.224   || dis=0.01 || select=7/8
005/019-th : 0.115 0.125 0.127 0.125 0.130 0.125 0.128 0.125  ||  -0.085 -0.002 0.014 0.001 0.041 0.005 0.028 0.002     || dis=0.00 || select=4/8
006/019-th : 0.141 0.130 0.116 0.129 0.124 0.115 0.125 0.122  ||  0.121 0.040 -0.071 0.033 -0.005 -0.076 0.001 -0.022   || dis=0.01 || select=0/8
007/019-th : 0.010 0.015 0.024 0.027 0.044 0.067 0.128 0.684  ||  -1.599 -1.228 -0.772 -0.635 -0.152 0.264 0.914 2.588  || dis=0.56 || select=7/8
008/019-th : 0.010 0.014 0.022 0.036 0.051 0.086 0.225 0.555  ||  -1.685 -1.362 -0.929 -0.447 -0.088 0.436 1.395 2.298  || dis=0.33 || select=7/8
009/019-th : 0.077 0.086 0.097 0.107 0.116 0.133 0.172 0.211  ||  -0.433 -0.322 -0.203 -0.104 -0.031 0.108 0.367 0.570  || dis=0.04 || select=7/8
010/019-th : 0.086 0.092 0.097 0.117 0.128 0.153 0.155 0.172  ||  -0.353 -0.280 -0.223 -0.044 0.050 0.230 0.239 0.344   || dis=0.02 || select=7/8
011/019-th : 0.117 0.117 0.114 0.122 0.123 0.128 0.139 0.140  ||  -0.064 -0.063 -0.087 -0.017 -0.010 0.031 0.114 0.119  || dis=0.00 || select=7/8
012/019-th : 0.139 0.134 0.123 0.127 0.125 0.115 0.119 0.117  ||  0.112 0.073 -0.008 0.024 0.009 -0.079 -0.040 -0.062   || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.018 0.940  ||  -1.129 -1.051 -0.853 -0.793 -0.597 -0.343 0.169 4.142  || dis=0.92 || select=7/8
014/019-th : 0.005 0.006 0.008 0.009 0.013 0.020 0.045 0.895  ||  -1.398 -1.275 -1.060 -0.889 -0.559 -0.082 0.706 3.707  || dis=0.85 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.020 0.941  ||  -1.160 -1.053 -0.957 -0.796 -0.644 -0.333 0.367 4.203  || dis=0.92 || select=7/8
016/019-th : 0.035 0.044 0.052 0.081 0.108 0.166 0.223 0.292  ||  -1.049 -0.813 -0.645 -0.206 0.077 0.510 0.806 1.075   || dis=0.07 || select=7/8
017/019-th : 0.078 0.094 0.106 0.127 0.131 0.133 0.164 0.166  ||  -0.439 -0.257 -0.133 0.044 0.078 0.094 0.303 0.316    || dis=0.00 || select=7/8
018/019-th : 0.094 0.104 0.126 0.144 0.126 0.128 0.136 0.142  ||  -0.273 -0.170 0.018 0.149 0.015 0.037 0.092 0.140     || dis=0.00 || select=3/8
[epoch=486/600] FLOP : 27.44 MB, ratio : 0.6722, Expected-ratio : 0.7000, Discrepancy : 0.243
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:00:52] [epoch=486/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.340 (1.340)  Prec@1 64.45 (64.45) Prec@5 94.53 (94.53) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:00:58] [epoch=486/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.422 (2.071)  Prec@1 51.79 (47.15) Prec@5 85.71 (85.61) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.15 Prec@5 85.61 Error@1 52.85 Error@5 14.39 Loss:2.071
***[2020-01-29 10:00:58]*** VALID [epoch=486/600] loss = 2.070545, accuracy@1 = 47.15, accuracy@5 = 85.61 | Best-Valid-Acc@1=48.59, Error@1=51.41
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:00:58]*** start epoch=487/600 Time Left: [01:00:18], LR=[0.008499 ~ 0.008499], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=487, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5164699015163499, FLOP=40.81
[Search] : epoch=487/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:00:59] [epoch=487/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.466 (0.466)  Prec@1 83.20 (83.20) Prec@5 99.22 (99.22) Acls-loss 0.379 (0.379) FLOP-Loss 0.000 (0.000) Arch-Loss 0.379 (0.379)
**TRAIN** [2020-01-29 10:01:23] [epoch=487/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.456 (0.557)  Prec@1 86.31 (81.20) Prec@5 99.40 (98.87) Acls-loss 0.588 (0.603) FLOP-Loss 0.000 (0.000) Arch-Loss 0.588 (0.603)
 **TRAIN** Prec@1 81.20 Prec@5 98.87 Error@1 18.80 Error@5 1.13 Base-Loss:0.557, Arch-Loss=0.603
***[2020-01-29 10:01:23]*** TRAIN [epoch=487/600] base-loss = 0.556804, arch-loss = 0.603487, accuracy-1 = 81.20, accuracy-5 = 98.87
[epoch=487/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 11, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.860608)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.241 0.380 0.379  ||  -0.1315 0.3251 0.3236  || discrepancy=0.00 || select=1/3
001/003-th : 0.309 0.248 0.444  ||  0.0633 -0.1572 0.4263  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.028 0.967  ||  -2.3554 -0.6470 2.8997  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.014 0.022 0.025 0.028 0.040 0.064 0.136 0.672  ||  -1.419 -0.945 -0.815 -0.726 -0.363 0.107 0.863 2.463  || dis=0.54 || select=7/8
001/019-th : 0.092 0.119 0.141 0.131 0.134 0.130 0.136 0.118  ||  -0.294 -0.036 0.136 0.063 0.082 0.053 0.099 -0.046    || dis=0.00 || select=2/8
002/019-th : 0.117 0.126 0.135 0.130 0.125 0.130 0.125 0.113  ||  -0.059 0.015 0.083 0.047 0.003 0.047 0.004 -0.098     || dis=0.01 || select=2/8
003/019-th : 0.099 0.108 0.118 0.126 0.135 0.136 0.143 0.134  ||  -0.223 -0.138 -0.048 0.018 0.088 0.094 0.142 0.080    || dis=0.01 || select=6/8
004/019-th : 0.110 0.109 0.111 0.111 0.126 0.126 0.151 0.156  ||  -0.122 -0.132 -0.118 -0.116 0.015 0.010 0.192 0.224   || dis=0.01 || select=7/8
005/019-th : 0.113 0.121 0.126 0.126 0.133 0.126 0.129 0.125  ||  -0.095 -0.027 0.010 0.008 0.066 0.007 0.036 0.006     || dis=0.00 || select=4/8
006/019-th : 0.138 0.128 0.116 0.131 0.124 0.116 0.125 0.122  ||  0.107 0.029 -0.067 0.056 -0.004 -0.073 0.006 -0.023   || dis=0.01 || select=0/8
007/019-th : 0.010 0.015 0.024 0.027 0.045 0.066 0.127 0.687  ||  -1.606 -1.226 -0.773 -0.634 -0.134 0.249 0.907 2.597  || dis=0.56 || select=7/8
008/019-th : 0.010 0.014 0.022 0.036 0.051 0.086 0.221 0.560  ||  -1.679 -1.355 -0.925 -0.449 -0.086 0.427 1.374 2.305  || dis=0.34 || select=7/8
009/019-th : 0.077 0.087 0.097 0.107 0.115 0.132 0.170 0.215  ||  -0.437 -0.319 -0.202 -0.109 -0.032 0.099 0.356 0.588  || dis=0.04 || select=7/8
010/019-th : 0.085 0.092 0.098 0.116 0.127 0.153 0.156 0.173  ||  -0.358 -0.284 -0.219 -0.046 0.044 0.228 0.246 0.352   || dis=0.02 || select=7/8
011/019-th : 0.115 0.116 0.113 0.121 0.124 0.130 0.140 0.140  ||  -0.075 -0.069 -0.094 -0.026 -0.002 0.045 0.123 0.122  || dis=0.00 || select=6/8
012/019-th : 0.138 0.131 0.122 0.127 0.126 0.116 0.121 0.119  ||  0.106 0.053 -0.021 0.022 0.011 -0.068 -0.026 -0.048   || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.011 0.018 0.940  ||  -1.122 -1.043 -0.846 -0.784 -0.610 -0.341 0.168 4.139  || dis=0.92 || select=7/8
014/019-th : 0.005 0.006 0.008 0.009 0.012 0.019 0.043 0.897  ||  -1.397 -1.272 -1.055 -0.885 -0.556 -0.108 0.690 3.724  || dis=0.85 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.019 0.943  ||  -1.158 -1.042 -0.972 -0.800 -0.641 -0.342 0.338 4.217  || dis=0.92 || select=7/8
016/019-th : 0.035 0.043 0.052 0.081 0.105 0.166 0.223 0.295  ||  -1.049 -0.826 -0.643 -0.203 0.060 0.512 0.809 1.089   || dis=0.07 || select=7/8
017/019-th : 0.078 0.093 0.105 0.127 0.129 0.133 0.166 0.169  ||  -0.443 -0.269 -0.142 0.048 0.064 0.096 0.312 0.333    || dis=0.00 || select=7/8
018/019-th : 0.093 0.102 0.126 0.143 0.126 0.129 0.137 0.144  ||  -0.282 -0.196 0.022 0.143 0.017 0.045 0.106 0.152     || dis=0.00 || select=7/8
[epoch=487/600] FLOP : 27.86 MB, ratio : 0.6826, Expected-ratio : 0.7000, Discrepancy : 0.245
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:01:23] [epoch=487/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.349 (1.349)  Prec@1 55.86 (55.86) Prec@5 92.58 (92.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:01:29] [epoch=487/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.128 (2.019)  Prec@1 61.31 (49.46) Prec@5 94.64 (86.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.46 Prec@5 86.13 Error@1 50.54 Error@5 13.87 Loss:2.019
***[2020-01-29 10:01:29]*** VALID [epoch=487/600] loss = 2.018758, accuracy@1 = 49.46, accuracy@5 = 86.13 | Best-Valid-Acc@1=48.59, Error@1=51.41
Currently, the best validation accuracy found at 487-epoch :: acc@1=49.46, acc@5=86.13, error@1=50.54, error@5=13.87, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:01:29]*** start epoch=488/600 Time Left: [00:59:46], LR=[0.008354 ~ 0.008354], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=488, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5093429602602564, FLOP=40.81
[Search] : epoch=488/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:01:30] [epoch=488/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.494 (0.494)  Prec@1 82.03 (82.03) Prec@5 99.22 (99.22) Acls-loss 0.512 (0.512) FLOP-Loss 0.000 (0.000) Arch-Loss 0.512 (0.512)
**TRAIN** [2020-01-29 10:01:54] [epoch=488/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.766 (0.478)  Prec@1 75.60 (83.64) Prec@5 97.62 (99.26) Acls-loss 0.626 (0.624) FLOP-Loss 0.000 (0.184) Arch-Loss 0.626 (0.991)
 **TRAIN** Prec@1 83.64 Prec@5 99.26 Error@1 16.36 Error@5 0.74 Base-Loss:0.478, Arch-Loss=0.991
***[2020-01-29 10:01:54]*** TRAIN [epoch=488/600] base-loss = 0.478428, arch-loss = 0.990620, accuracy-1 = 83.64, accuracy-5 = 99.26
[epoch=488/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.240 0.381 0.379  ||  -0.1345 0.3283 0.3232  || discrepancy=0.00 || select=1/3
001/003-th : 0.307 0.250 0.443  ||  0.0604 -0.1464 0.4254  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.028 0.967  ||  -2.3482 -0.6458 2.8926  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.014 0.021 0.025 0.027 0.038 0.063 0.133 0.679  ||  -1.426 -0.964 -0.811 -0.730 -0.387 0.105 0.863 2.490  || dis=0.55 || select=7/8
001/019-th : 0.093 0.119 0.143 0.132 0.134 0.128 0.134 0.117  ||  -0.282 -0.034 0.147 0.068 0.087 0.040 0.083 -0.055    || dis=0.01 || select=2/8
002/019-th : 0.117 0.127 0.135 0.132 0.126 0.128 0.124 0.113  ||  -0.062 0.019 0.082 0.059 0.015 0.029 -0.005 -0.092    || dis=0.00 || select=2/8
003/019-th : 0.099 0.110 0.119 0.127 0.135 0.135 0.144 0.132  ||  -0.226 -0.122 -0.044 0.023 0.085 0.085 0.147 0.065    || dis=0.01 || select=6/8
004/019-th : 0.109 0.110 0.111 0.112 0.127 0.125 0.151 0.155  ||  -0.131 -0.125 -0.117 -0.102 0.022 0.006 0.194 0.216   || dis=0.00 || select=7/8
005/019-th : 0.116 0.123 0.127 0.126 0.129 0.124 0.129 0.127  ||  -0.077 -0.016 0.016 0.011 0.031 -0.006 0.032 0.013    || dis=0.00 || select=6/8
006/019-th : 0.139 0.128 0.117 0.131 0.120 0.118 0.126 0.121  ||  0.114 0.029 -0.062 0.049 -0.038 -0.049 0.012 -0.028   || dis=0.01 || select=0/8
007/019-th : 0.010 0.015 0.023 0.027 0.044 0.065 0.126 0.690  ||  -1.608 -1.238 -0.772 -0.634 -0.144 0.252 0.906 2.608  || dis=0.56 || select=7/8
008/019-th : 0.010 0.014 0.021 0.035 0.050 0.085 0.218 0.564  ||  -1.671 -1.352 -0.954 -0.448 -0.101 0.432 1.370 2.319  || dis=0.35 || select=7/8
009/019-th : 0.078 0.087 0.097 0.107 0.116 0.131 0.170 0.214  ||  -0.426 -0.312 -0.204 -0.114 -0.027 0.095 0.354 0.582  || dis=0.04 || select=7/8
010/019-th : 0.086 0.091 0.099 0.116 0.128 0.152 0.156 0.172  ||  -0.350 -0.294 -0.212 -0.045 0.052 0.225 0.247 0.345   || dis=0.02 || select=7/8
011/019-th : 0.116 0.115 0.114 0.121 0.124 0.129 0.139 0.140  ||  -0.066 -0.075 -0.083 -0.029 0.001 0.041 0.114 0.120   || dis=0.00 || select=7/8
012/019-th : 0.140 0.132 0.122 0.125 0.126 0.116 0.121 0.118  ||  0.117 0.056 -0.020 0.007 0.011 -0.068 -0.026 -0.056   || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.010 0.017 0.941  ||  -1.117 -1.035 -0.839 -0.792 -0.607 -0.351 0.156 4.146  || dis=0.92 || select=7/8
014/019-th : 0.005 0.006 0.007 0.009 0.012 0.019 0.042 0.899  ||  -1.414 -1.270 -1.057 -0.884 -0.556 -0.114 0.683 3.742  || dis=0.86 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.019 0.943  ||  -1.157 -1.042 -0.966 -0.793 -0.636 -0.347 0.327 4.216  || dis=0.92 || select=7/8
016/019-th : 0.034 0.043 0.051 0.081 0.107 0.166 0.221 0.297  ||  -1.054 -0.831 -0.665 -0.196 0.075 0.516 0.806 1.099   || dis=0.08 || select=7/8
017/019-th : 0.079 0.092 0.106 0.127 0.131 0.133 0.164 0.168  ||  -0.428 -0.275 -0.136 0.048 0.074 0.088 0.302 0.328    || dis=0.00 || select=7/8
018/019-th : 0.093 0.103 0.127 0.143 0.124 0.129 0.137 0.145  ||  -0.283 -0.187 0.026 0.145 0.006 0.040 0.100 0.156     || dis=0.00 || select=7/8
[epoch=488/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.246
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:01:54] [epoch=488/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.242 (1.242)  Prec@1 67.97 (67.97) Prec@5 96.48 (96.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:02:00] [epoch=488/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 2.199 (2.147)  Prec@1 33.93 (47.83) Prec@5 77.38 (85.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.83 Prec@5 85.60 Error@1 52.17 Error@5 14.40 Loss:2.147
***[2020-01-29 10:02:00]*** VALID [epoch=488/600] loss = 2.147465, accuracy@1 = 47.83, accuracy@5 = 85.60 | Best-Valid-Acc@1=49.46, Error@1=50.54
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:02:00]*** start epoch=489/600 Time Left: [00:59:14], LR=[0.008210 ~ 0.008210], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=489, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.5022719646477384, FLOP=40.81
[Search] : epoch=489/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:02:01] [epoch=489/600][000/098] Time 0.64 (0.64) Data 0.38 (0.38) Base-Loss 0.422 (0.422)  Prec@1 83.98 (83.98) Prec@5 99.22 (99.22) Acls-loss 0.491 (0.491) FLOP-Loss 0.000 (0.000) Arch-Loss 0.491 (0.491)
**TRAIN** [2020-01-29 10:02:25] [epoch=489/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.819 (0.505)  Prec@1 72.62 (83.00) Prec@5 98.21 (99.12) Acls-loss 0.600 (0.602) FLOP-Loss 0.000 (0.000) Arch-Loss 0.600 (0.602)
 **TRAIN** Prec@1 83.00 Prec@5 99.12 Error@1 17.00 Error@5 0.88 Base-Loss:0.505, Arch-Loss=0.602
***[2020-01-29 10:02:25]*** TRAIN [epoch=489/600] base-loss = 0.504636, arch-loss = 0.601981, accuracy-1 = 83.00, accuracy-5 = 99.12
[epoch=489/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.235 0.384 0.381  ||  -0.1511 0.3394 0.3334  || discrepancy=0.00 || select=1/3
001/003-th : 0.305 0.250 0.445  ||  0.0522 -0.1445 0.4319  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.028 0.967  ||  -2.3493 -0.6395 2.8927  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.013 0.021 0.024 0.027 0.038 0.061 0.130 0.685  ||  -1.423 -0.959 -0.835 -0.729 -0.393 0.098 0.850 2.509  || dis=0.56 || select=7/8
001/019-th : 0.093 0.116 0.141 0.132 0.134 0.129 0.137 0.117  ||  -0.281 -0.060 0.136 0.068 0.087 0.045 0.108 -0.050    || dis=0.00 || select=2/8
002/019-th : 0.115 0.124 0.134 0.130 0.127 0.128 0.126 0.116  ||  -0.075 -0.003 0.074 0.048 0.022 0.033 0.018 -0.072    || dis=0.00 || select=2/8
003/019-th : 0.097 0.110 0.119 0.126 0.135 0.134 0.145 0.135  ||  -0.243 -0.123 -0.044 0.014 0.088 0.082 0.155 0.084    || dis=0.01 || select=6/8
004/019-th : 0.108 0.109 0.111 0.113 0.127 0.126 0.152 0.155  ||  -0.137 -0.136 -0.118 -0.096 0.019 0.009 0.202 0.220   || dis=0.00 || select=7/8
005/019-th : 0.116 0.122 0.125 0.127 0.129 0.126 0.129 0.127  ||  -0.078 -0.026 0.001 0.013 0.032 0.008 0.035 0.015     || dis=0.00 || select=6/8
006/019-th : 0.138 0.129 0.118 0.130 0.120 0.118 0.126 0.122  ||  0.102 0.033 -0.052 0.044 -0.040 -0.051 0.011 -0.020   || dis=0.01 || select=0/8
007/019-th : 0.010 0.015 0.023 0.026 0.043 0.064 0.122 0.698  ||  -1.614 -1.231 -0.766 -0.650 -0.151 0.238 0.885 2.633  || dis=0.58 || select=7/8
008/019-th : 0.010 0.014 0.021 0.035 0.050 0.084 0.218 0.567  ||  -1.663 -1.357 -0.961 -0.465 -0.097 0.424 1.374 2.329  || dis=0.35 || select=7/8
009/019-th : 0.077 0.084 0.097 0.105 0.115 0.131 0.170 0.219  ||  -0.432 -0.343 -0.206 -0.122 -0.030 0.099 0.356 0.612  || dis=0.05 || select=7/8
010/019-th : 0.085 0.090 0.099 0.118 0.126 0.152 0.156 0.174  ||  -0.362 -0.299 -0.211 -0.030 0.037 0.226 0.248 0.356   || dis=0.02 || select=7/8
011/019-th : 0.115 0.114 0.112 0.120 0.124 0.133 0.141 0.141  ||  -0.079 -0.083 -0.107 -0.035 -0.004 0.071 0.127 0.130  || dis=0.00 || select=7/8
012/019-th : 0.138 0.131 0.119 0.126 0.126 0.120 0.123 0.117  ||  0.103 0.053 -0.047 0.012 0.012 -0.035 -0.009 -0.059   || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.010 0.017 0.941  ||  -1.115 -1.028 -0.834 -0.785 -0.614 -0.352 0.152 4.147  || dis=0.92 || select=7/8
014/019-th : 0.005 0.006 0.007 0.009 0.012 0.019 0.041 0.902  ||  -1.426 -1.270 -1.071 -0.879 -0.569 -0.116 0.670 3.767  || dis=0.86 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.019 0.943  ||  -1.168 -1.032 -0.960 -0.789 -0.645 -0.331 0.313 4.225  || dis=0.92 || select=7/8
016/019-th : 0.034 0.042 0.051 0.080 0.106 0.165 0.220 0.301  ||  -1.055 -0.850 -0.654 -0.204 0.069 0.516 0.805 1.117   || dis=0.08 || select=7/8
017/019-th : 0.078 0.091 0.105 0.127 0.130 0.133 0.165 0.171  ||  -0.439 -0.286 -0.145 0.047 0.068 0.095 0.310 0.347    || dis=0.01 || select=7/8
018/019-th : 0.093 0.103 0.126 0.141 0.122 0.132 0.138 0.146  ||  -0.287 -0.186 0.021 0.129 -0.011 0.063 0.106 0.163    || dis=0.01 || select=7/8
[epoch=489/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.248
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:02:25] [epoch=489/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.297 (1.297)  Prec@1 65.23 (65.23) Prec@5 94.53 (94.53) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:02:31] [epoch=489/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 0.821 (2.208)  Prec@1 72.02 (48.95) Prec@5 98.81 (86.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 48.95 Prec@5 86.40 Error@1 51.05 Error@5 13.60 Loss:2.208
***[2020-01-29 10:02:31]*** VALID [epoch=489/600] loss = 2.207747, accuracy@1 = 48.95, accuracy@5 = 86.40 | Best-Valid-Acc@1=49.46, Error@1=50.54
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:02:31]*** start epoch=490/600 Time Left: [00:58:41], LR=[0.008066 ~ 0.008066], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=490, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4952571085337114, FLOP=40.81
[Search] : epoch=490/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:02:32] [epoch=490/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 1.002 (1.002)  Prec@1 68.36 (68.36) Prec@5 95.31 (95.31) Acls-loss 0.516 (0.516) FLOP-Loss 0.000 (0.000) Arch-Loss 0.516 (0.516)
**TRAIN** [2020-01-29 10:02:56] [epoch=490/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.439 (0.504)  Prec@1 83.93 (82.80) Prec@5 100.00 (99.06) Acls-loss 0.937 (0.607) FLOP-Loss 0.000 (0.061) Arch-Loss 0.937 (0.729)
 **TRAIN** Prec@1 82.80 Prec@5 99.06 Error@1 17.20 Error@5 0.94 Base-Loss:0.504, Arch-Loss=0.729
***[2020-01-29 10:02:56]*** TRAIN [epoch=490/600] base-loss = 0.503783, arch-loss = 0.729491, accuracy-1 = 82.80, accuracy-5 = 99.06
[epoch=490/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.229 0.387 0.384  ||  -0.1708 0.3544 0.3452  || discrepancy=0.00 || select=1/3
001/003-th : 0.300 0.257 0.442  ||  0.0433 -0.1111 0.4307  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.028 0.966  ||  -2.3424 -0.6379 2.8859  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.013 0.021 0.024 0.026 0.037 0.059 0.128 0.692  ||  -1.423 -0.956 -0.829 -0.739 -0.395 0.069 0.842 2.531  || dis=0.56 || select=7/8
001/019-th : 0.094 0.116 0.141 0.130 0.133 0.129 0.138 0.119  ||  -0.278 -0.062 0.130 0.051 0.077 0.045 0.113 -0.036    || dis=0.00 || select=2/8
002/019-th : 0.112 0.122 0.133 0.131 0.128 0.130 0.128 0.117  ||  -0.101 -0.015 0.068 0.052 0.030 0.050 0.029 -0.057    || dis=0.00 || select=2/8
003/019-th : 0.097 0.110 0.120 0.126 0.134 0.134 0.145 0.136  ||  -0.248 -0.118 -0.032 0.013 0.076 0.076 0.155 0.090    || dis=0.01 || select=6/8
004/019-th : 0.108 0.107 0.110 0.109 0.130 0.129 0.151 0.156  ||  -0.137 -0.150 -0.120 -0.128 0.046 0.034 0.194 0.227   || dis=0.01 || select=7/8
005/019-th : 0.115 0.121 0.125 0.126 0.130 0.127 0.130 0.127  ||  -0.086 -0.032 0.000 0.006 0.038 0.017 0.041 0.017     || dis=0.00 || select=6/8
006/019-th : 0.137 0.129 0.117 0.129 0.120 0.120 0.126 0.122  ||  0.092 0.033 -0.061 0.036 -0.034 -0.041 0.011 -0.018   || dis=0.01 || select=0/8
007/019-th : 0.010 0.015 0.023 0.026 0.043 0.063 0.120 0.701  ||  -1.609 -1.232 -0.760 -0.664 -0.147 0.233 0.873 2.641  || dis=0.58 || select=7/8
008/019-th : 0.010 0.014 0.021 0.035 0.049 0.082 0.216 0.573  ||  -1.662 -1.370 -0.954 -0.458 -0.113 0.408 1.371 2.348  || dis=0.36 || select=7/8
009/019-th : 0.076 0.082 0.096 0.105 0.117 0.132 0.170 0.221  ||  -0.443 -0.363 -0.216 -0.121 -0.014 0.109 0.362 0.624  || dis=0.05 || select=7/8
010/019-th : 0.085 0.090 0.098 0.117 0.126 0.153 0.154 0.178  ||  -0.363 -0.296 -0.214 -0.042 0.038 0.226 0.233 0.378   || dis=0.02 || select=7/8
011/019-th : 0.114 0.114 0.112 0.122 0.123 0.134 0.140 0.142  ||  -0.087 -0.089 -0.107 -0.019 -0.006 0.074 0.123 0.133  || dis=0.00 || select=7/8
012/019-th : 0.137 0.130 0.118 0.128 0.127 0.120 0.123 0.117  ||  0.099 0.044 -0.052 0.031 0.023 -0.031 -0.014 -0.058   || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.010 0.017 0.941  ||  -1.116 -1.032 -0.826 -0.777 -0.611 -0.361 0.141 4.155  || dis=0.92 || select=7/8
014/019-th : 0.005 0.006 0.007 0.009 0.012 0.018 0.040 0.903  ||  -1.424 -1.267 -1.067 -0.874 -0.564 -0.119 0.658 3.768  || dis=0.86 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.019 0.943  ||  -1.165 -1.021 -0.956 -0.781 -0.654 -0.329 0.302 4.226  || dis=0.92 || select=7/8
016/019-th : 0.034 0.041 0.051 0.080 0.106 0.166 0.223 0.300  ||  -1.065 -0.867 -0.660 -0.201 0.077 0.527 0.821 1.117   || dis=0.08 || select=7/8
017/019-th : 0.078 0.091 0.104 0.126 0.132 0.132 0.166 0.172  ||  -0.439 -0.290 -0.148 0.036 0.090 0.084 0.315 0.350    || dis=0.01 || select=7/8
018/019-th : 0.093 0.103 0.126 0.142 0.122 0.130 0.138 0.147  ||  -0.291 -0.184 0.017 0.135 -0.013 0.048 0.108 0.173    || dis=0.01 || select=7/8
[epoch=490/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.250
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:02:56] [epoch=490/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.018 (1.018)  Prec@1 77.34 (77.34) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:03:02] [epoch=490/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.056 (2.153)  Prec@1 69.05 (48.90) Prec@5 98.21 (85.97) Size=[168, 3, 32, 32]
 **VALID** Prec@1 48.90 Prec@5 85.97 Error@1 51.10 Error@5 14.03 Loss:2.153
***[2020-01-29 10:03:02]*** VALID [epoch=490/600] loss = 2.153301, accuracy@1 = 48.90, accuracy@5 = 85.97 | Best-Valid-Acc@1=49.46, Error@1=50.54
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:03:02]*** start epoch=491/600 Time Left: [00:58:09], LR=[0.007924 ~ 0.007924], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=491, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4882985842340002, FLOP=40.81
[Search] : epoch=491/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:03:03] [epoch=491/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.915 (0.915)  Prec@1 65.23 (65.23) Prec@5 98.05 (98.05) Acls-loss 0.656 (0.656) FLOP-Loss 0.000 (0.000) Arch-Loss 0.656 (0.656)
**TRAIN** [2020-01-29 10:03:27] [epoch=491/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.598 (0.486)  Prec@1 76.19 (83.36) Prec@5 100.00 (99.18) Acls-loss 0.619 (0.588) FLOP-Loss 0.000 (0.153) Arch-Loss 0.619 (0.895)
 **TRAIN** Prec@1 83.36 Prec@5 99.18 Error@1 16.64 Error@5 0.82 Base-Loss:0.486, Arch-Loss=0.895
***[2020-01-29 10:03:27]*** TRAIN [epoch=491/600] base-loss = 0.485832, arch-loss = 0.895164, accuracy-1 = 83.36, accuracy-5 = 99.18
[epoch=491/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.228 0.392 0.380  ||  -0.1723 0.3702 0.3378  || discrepancy=0.01 || select=1/3
001/003-th : 0.301 0.256 0.444  ||  0.0430 -0.1192 0.4325  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.029 0.966  ||  -2.3338 -0.6285 2.8757  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.013 0.021 0.024 0.026 0.037 0.058 0.125 0.695  ||  -1.435 -0.945 -0.818 -0.732 -0.396 0.065 0.828 2.542  || dis=0.57 || select=7/8
001/019-th : 0.095 0.114 0.140 0.130 0.135 0.128 0.139 0.119  ||  -0.267 -0.080 0.124 0.054 0.087 0.040 0.121 -0.037    || dis=0.00 || select=2/8
002/019-th : 0.113 0.123 0.133 0.130 0.125 0.132 0.127 0.117  ||  -0.095 -0.010 0.071 0.047 0.009 0.058 0.023 -0.056    || dis=0.00 || select=2/8
003/019-th : 0.098 0.110 0.119 0.124 0.132 0.134 0.144 0.138  ||  -0.236 -0.124 -0.040 0.000 0.061 0.078 0.152 0.105    || dis=0.01 || select=6/8
004/019-th : 0.107 0.106 0.110 0.110 0.132 0.128 0.150 0.156  ||  -0.145 -0.161 -0.122 -0.116 0.065 0.033 0.189 0.229   || dis=0.01 || select=7/8
005/019-th : 0.115 0.120 0.123 0.127 0.130 0.127 0.130 0.128  ||  -0.086 -0.037 -0.014 0.019 0.040 0.013 0.040 0.027    || dis=0.00 || select=6/8
006/019-th : 0.138 0.130 0.118 0.131 0.119 0.120 0.123 0.121  ||  0.105 0.042 -0.049 0.053 -0.045 -0.037 -0.008 -0.031  || dis=0.01 || select=0/8
007/019-th : 0.010 0.014 0.023 0.026 0.042 0.063 0.118 0.704  ||  -1.604 -1.234 -0.765 -0.664 -0.168 0.230 0.867 2.651  || dis=0.59 || select=7/8
008/019-th : 0.010 0.014 0.020 0.034 0.047 0.081 0.209 0.584  ||  -1.658 -1.371 -0.981 -0.456 -0.127 0.404 1.355 2.383  || dis=0.38 || select=7/8
009/019-th : 0.077 0.082 0.093 0.104 0.120 0.132 0.170 0.222  ||  -0.426 -0.368 -0.244 -0.130 0.010 0.111 0.362 0.627   || dis=0.05 || select=7/8
010/019-th : 0.085 0.090 0.100 0.117 0.127 0.153 0.153 0.175  ||  -0.361 -0.297 -0.195 -0.038 0.041 0.228 0.231 0.363   || dis=0.02 || select=7/8
011/019-th : 0.114 0.114 0.113 0.122 0.124 0.133 0.139 0.141  ||  -0.088 -0.083 -0.091 -0.020 -0.004 0.068 0.114 0.129  || dis=0.00 || select=7/8
012/019-th : 0.138 0.131 0.119 0.128 0.127 0.120 0.121 0.117  ||  0.105 0.051 -0.043 0.031 0.024 -0.036 -0.029 -0.063   || dis=0.01 || select=0/8
013/019-th : 0.005 0.005 0.006 0.007 0.008 0.010 0.016 0.943  ||  -1.127 -1.023 -0.822 -0.766 -0.607 -0.359 0.108 4.173  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.009 0.012 0.018 0.040 0.903  ||  -1.417 -1.262 -1.061 -0.886 -0.562 -0.119 0.646 3.771  || dis=0.86 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.019 0.943  ||  -1.164 -1.009 -0.951 -0.772 -0.661 -0.329 0.296 4.226  || dis=0.92 || select=7/8
016/019-th : 0.034 0.042 0.051 0.080 0.106 0.164 0.220 0.303  ||  -1.067 -0.854 -0.654 -0.202 0.077 0.514 0.809 1.127   || dis=0.08 || select=7/8
017/019-th : 0.078 0.092 0.104 0.125 0.132 0.130 0.167 0.173  ||  -0.437 -0.279 -0.152 0.029 0.083 0.073 0.319 0.354    || dis=0.01 || select=7/8
018/019-th : 0.094 0.106 0.125 0.141 0.123 0.129 0.136 0.147  ||  -0.276 -0.159 0.007 0.128 -0.011 0.040 0.092 0.169    || dis=0.01 || select=7/8
[epoch=491/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.252
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:03:27] [epoch=491/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.237 (2.237)  Prec@1 31.25 (31.25) Prec@5 78.52 (78.52) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:03:34] [epoch=491/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.618 (1.884)  Prec@1 80.95 (51.84) Prec@5 99.40 (87.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 51.84 Prec@5 87.02 Error@1 48.16 Error@5 12.98 Loss:1.884
***[2020-01-29 10:03:34]*** VALID [epoch=491/600] loss = 1.884019, accuracy@1 = 51.84, accuracy@5 = 87.02 | Best-Valid-Acc@1=49.46, Error@1=50.54
Currently, the best validation accuracy found at 491-epoch :: acc@1=51.84, acc@5=87.02, error@1=48.16, error@5=12.98, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:03:34]*** start epoch=492/600 Time Left: [00:57:37], LR=[0.007784 ~ 0.007784], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=492, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4813965825200637, FLOP=40.81
[Search] : epoch=492/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:03:34] [epoch=492/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.435 (0.435)  Prec@1 85.94 (85.94) Prec@5 99.61 (99.61) Acls-loss 0.558 (0.558) FLOP-Loss 0.000 (0.000) Arch-Loss 0.558 (0.558)
**TRAIN** [2020-01-29 10:03:59] [epoch=492/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.395 (0.471)  Prec@1 88.10 (84.14) Prec@5 100.00 (99.24) Acls-loss 0.516 (0.624) FLOP-Loss 0.000 (0.123) Arch-Loss 0.516 (0.869)
 **TRAIN** Prec@1 84.14 Prec@5 99.24 Error@1 15.86 Error@5 0.76 Base-Loss:0.471, Arch-Loss=0.869
***[2020-01-29 10:03:59]*** TRAIN [epoch=492/600] base-loss = 0.470754, arch-loss = 0.869215, accuracy-1 = 84.14, accuracy-5 = 99.24
[epoch=492/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.226 0.398 0.376  ||  -0.1766 0.3893 0.3317  || discrepancy=0.02 || select=1/3
001/003-th : 0.300 0.258 0.442  ||  0.0417 -0.1085 0.4291  || discrepancy=0.14 || select=2/3
002/003-th : 0.005 0.029 0.966  ||  -2.3317 -0.6417 2.8780  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.013 0.021 0.024 0.026 0.036 0.057 0.123 0.699  ||  -1.428 -0.955 -0.821 -0.735 -0.397 0.055 0.822 2.555  || dis=0.58 || select=7/8
001/019-th : 0.092 0.114 0.141 0.129 0.134 0.130 0.139 0.119  ||  -0.287 -0.078 0.136 0.046 0.087 0.055 0.121 -0.032    || dis=0.00 || select=2/8
002/019-th : 0.113 0.123 0.132 0.130 0.125 0.131 0.128 0.118  ||  -0.093 -0.012 0.063 0.042 0.004 0.053 0.032 -0.050    || dis=0.00 || select=2/8
003/019-th : 0.098 0.111 0.120 0.124 0.132 0.135 0.144 0.136  ||  -0.238 -0.113 -0.032 -0.002 0.064 0.081 0.150 0.092   || dis=0.01 || select=6/8
004/019-th : 0.107 0.105 0.111 0.111 0.134 0.127 0.150 0.156  ||  -0.151 -0.166 -0.113 -0.111 0.075 0.022 0.190 0.230   || dis=0.01 || select=7/8
005/019-th : 0.115 0.120 0.122 0.128 0.130 0.127 0.130 0.127  ||  -0.082 -0.037 -0.020 0.028 0.038 0.015 0.040 0.020    || dis=0.00 || select=6/8
006/019-th : 0.138 0.130 0.119 0.128 0.120 0.119 0.123 0.122  ||  0.104 0.045 -0.041 0.032 -0.039 -0.043 -0.010 -0.020  || dis=0.01 || select=0/8
007/019-th : 0.010 0.014 0.022 0.025 0.042 0.061 0.115 0.711  ||  -1.599 -1.241 -0.788 -0.666 -0.162 0.215 0.848 2.673  || dis=0.60 || select=7/8
008/019-th : 0.010 0.014 0.020 0.033 0.046 0.080 0.208 0.589  ||  -1.651 -1.368 -0.981 -0.478 -0.145 0.399 1.355 2.397  || dis=0.38 || select=7/8
009/019-th : 0.076 0.081 0.093 0.103 0.120 0.135 0.173 0.219  ||  -0.440 -0.373 -0.243 -0.135 0.011 0.129 0.380 0.619   || dis=0.05 || select=7/8
010/019-th : 0.086 0.089 0.098 0.115 0.126 0.155 0.152 0.178  ||  -0.350 -0.308 -0.215 -0.052 0.036 0.245 0.222 0.381   || dis=0.02 || select=7/8
011/019-th : 0.113 0.113 0.114 0.122 0.126 0.133 0.138 0.142  ||  -0.091 -0.092 -0.086 -0.021 0.012 0.070 0.103 0.134   || dis=0.00 || select=7/8
012/019-th : 0.138 0.131 0.120 0.128 0.127 0.120 0.119 0.117  ||  0.106 0.054 -0.033 0.028 0.025 -0.037 -0.040 -0.064   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.007 0.008 0.010 0.015 0.945  ||  -1.156 -1.014 -0.814 -0.768 -0.607 -0.349 0.072 4.204  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.009 0.012 0.018 0.039 0.905  ||  -1.412 -1.261 -1.062 -0.880 -0.568 -0.135 0.636 3.783  || dis=0.87 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.018 0.944  ||  -1.163 -1.020 -0.943 -0.775 -0.667 -0.328 0.283 4.235  || dis=0.93 || select=7/8
016/019-th : 0.033 0.041 0.052 0.079 0.105 0.162 0.218 0.310  ||  -1.091 -0.862 -0.631 -0.209 0.075 0.505 0.803 1.155   || dis=0.09 || select=7/8
017/019-th : 0.079 0.092 0.103 0.125 0.132 0.130 0.166 0.174  ||  -0.432 -0.278 -0.166 0.030 0.088 0.073 0.316 0.359    || dis=0.01 || select=7/8
018/019-th : 0.092 0.107 0.123 0.141 0.125 0.130 0.136 0.146  ||  -0.294 -0.143 -0.008 0.132 0.006 0.046 0.092 0.167    || dis=0.01 || select=7/8
[epoch=492/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.254
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:03:59] [epoch=492/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 5.042 (5.042)  Prec@1 37.89 (37.89) Prec@5 87.11 (87.11) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:04:05] [epoch=492/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.360 (1.823)  Prec@1 69.64 (53.32) Prec@5 97.62 (88.38) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.32 Prec@5 88.38 Error@1 46.68 Error@5 11.62 Loss:1.823
***[2020-01-29 10:04:05]*** VALID [epoch=492/600] loss = 1.822904, accuracy@1 = 53.32, accuracy@5 = 88.38 | Best-Valid-Acc@1=51.84, Error@1=48.16
Currently, the best validation accuracy found at 492-epoch :: acc@1=53.32, acc@5=88.38, error@1=46.68, error@5=11.62, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:04:05]*** start epoch=493/600 Time Left: [00:57:05], LR=[0.007644 ~ 0.007644], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=493, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4745512926137645, FLOP=40.81
[Search] : epoch=493/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:04:06] [epoch=493/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.502 (0.502)  Prec@1 85.55 (85.55) Prec@5 99.22 (99.22) Acls-loss 0.592 (0.592) FLOP-Loss 0.000 (0.000) Arch-Loss 0.592 (0.592)
**TRAIN** [2020-01-29 10:04:30] [epoch=493/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.572 (0.500)  Prec@1 80.36 (82.96) Prec@5 98.21 (99.20) Acls-loss 0.622 (0.623) FLOP-Loss 0.000 (0.460) Arch-Loss 0.622 (1.542)
 **TRAIN** Prec@1 82.96 Prec@5 99.20 Error@1 17.04 Error@5 0.80 Base-Loss:0.500, Arch-Loss=1.542
***[2020-01-29 10:04:30]*** TRAIN [epoch=493/600] base-loss = 0.500478, arch-loss = 1.541880, accuracy-1 = 82.96, accuracy-5 = 99.20
[epoch=493/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.228 0.411 0.361  ||  -0.1602 0.4268 0.2968  || discrepancy=0.05 || select=1/3
001/003-th : 0.314 0.259 0.428  ||  0.0803 -0.1132 0.3906  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.029 0.965  ||  -2.3271 -0.6274 2.8696  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.013 0.021 0.024 0.026 0.036 0.057 0.121 0.703  ||  -1.431 -0.958 -0.809 -0.719 -0.411 0.049 0.807 2.566  || dis=0.58 || select=7/8
001/019-th : 0.091 0.116 0.142 0.130 0.133 0.130 0.142 0.116  ||  -0.300 -0.063 0.143 0.058 0.079 0.057 0.140 -0.059    || dis=0.00 || select=2/8
002/019-th : 0.116 0.125 0.133 0.132 0.124 0.130 0.124 0.115  ||  -0.066 0.007 0.069 0.063 -0.003 0.044 0.002 -0.079    || dis=0.00 || select=2/8
003/019-th : 0.101 0.113 0.122 0.128 0.131 0.131 0.144 0.132  ||  -0.210 -0.096 -0.023 0.027 0.051 0.049 0.143 0.059    || dis=0.01 || select=6/8
004/019-th : 0.110 0.107 0.111 0.114 0.132 0.126 0.147 0.154  ||  -0.126 -0.147 -0.117 -0.090 0.062 0.013 0.169 0.216   || dis=0.01 || select=7/8
005/019-th : 0.116 0.123 0.125 0.128 0.131 0.126 0.126 0.125  ||  -0.073 -0.018 0.001 0.027 0.049 0.005 0.011 -0.002    || dis=0.00 || select=4/8
006/019-th : 0.144 0.134 0.121 0.128 0.119 0.118 0.120 0.117  ||  0.146 0.079 -0.026 0.033 -0.045 -0.046 -0.036 -0.060  || dis=0.01 || select=0/8
007/019-th : 0.010 0.014 0.022 0.025 0.041 0.059 0.114 0.714  ||  -1.593 -1.242 -0.781 -0.663 -0.175 0.186 0.849 2.680  || dis=0.60 || select=7/8
008/019-th : 0.010 0.013 0.020 0.033 0.047 0.081 0.208 0.587  ||  -1.655 -1.388 -0.986 -0.480 -0.124 0.418 1.361 2.397  || dis=0.38 || select=7/8
009/019-th : 0.078 0.082 0.094 0.105 0.119 0.134 0.172 0.215  ||  -0.413 -0.372 -0.231 -0.121 0.007 0.125 0.371 0.596   || dis=0.04 || select=7/8
010/019-th : 0.088 0.092 0.100 0.117 0.127 0.153 0.149 0.174  ||  -0.323 -0.282 -0.201 -0.039 0.037 0.224 0.200 0.355   || dis=0.02 || select=7/8
011/019-th : 0.115 0.114 0.116 0.122 0.125 0.133 0.135 0.140  ||  -0.080 -0.081 -0.066 -0.020 0.005 0.070 0.083 0.124   || dis=0.01 || select=7/8
012/019-th : 0.141 0.134 0.122 0.128 0.129 0.115 0.118 0.113  ||  0.125 0.077 -0.015 0.030 0.035 -0.076 -0.052 -0.092   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.007 0.008 0.010 0.015 0.945  ||  -1.151 -1.005 -0.827 -0.757 -0.617 -0.346 0.065 4.209  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.009 0.012 0.018 0.038 0.906  ||  -1.406 -1.253 -1.059 -0.873 -0.563 -0.137 0.609 3.787  || dis=0.87 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.018 0.945  ||  -1.172 -1.013 -0.941 -0.786 -0.663 -0.347 0.283 4.247  || dis=0.93 || select=7/8
016/019-th : 0.034 0.042 0.053 0.079 0.107 0.161 0.216 0.308  ||  -1.075 -0.854 -0.615 -0.218 0.089 0.493 0.790 1.144   || dis=0.09 || select=7/8
017/019-th : 0.080 0.094 0.103 0.126 0.133 0.130 0.162 0.172  ||  -0.415 -0.258 -0.166 0.034 0.094 0.067 0.291 0.347    || dis=0.01 || select=7/8
018/019-th : 0.094 0.109 0.123 0.143 0.125 0.128 0.133 0.146  ||  -0.273 -0.133 -0.008 0.139 0.008 0.030 0.066 0.163    || dis=0.00 || select=7/8
[epoch=493/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.255
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:04:31] [epoch=493/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.543 (2.543)  Prec@1 16.02 (16.02) Prec@5 58.98 (58.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:04:37] [epoch=493/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.826 (2.110)  Prec@1 72.02 (44.42) Prec@5 99.40 (84.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 44.42 Prec@5 84.28 Error@1 55.58 Error@5 15.72 Loss:2.110
***[2020-01-29 10:04:37]*** VALID [epoch=493/600] loss = 2.109521, accuracy@1 = 44.42, accuracy@5 = 84.28 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:04:37]*** start epoch=494/600 Time Left: [00:56:33], LR=[0.007505 ~ 0.007505], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=494, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.46776290218218386, FLOP=40.81
[Search] : epoch=494/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:04:37] [epoch=494/600][000/098] Time 0.66 (0.66) Data 0.35 (0.35) Base-Loss 0.318 (0.318)  Prec@1 88.67 (88.67) Prec@5 99.61 (99.61) Acls-loss 0.618 (0.618) FLOP-Loss 0.000 (0.000) Arch-Loss 0.618 (0.618)
**TRAIN** [2020-01-29 10:05:02] [epoch=494/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.540 (0.507)  Prec@1 80.95 (82.66) Prec@5 98.81 (99.19) Acls-loss 0.780 (0.639) FLOP-Loss 0.000 (0.214) Arch-Loss 0.780 (1.067)
 **TRAIN** Prec@1 82.66 Prec@5 99.19 Error@1 17.34 Error@5 0.81 Base-Loss:0.507, Arch-Loss=1.067
***[2020-01-29 10:05:02]*** TRAIN [epoch=494/600] base-loss = 0.506949, arch-loss = 1.067372, accuracy-1 = 82.66, accuracy-5 = 99.19
[epoch=494/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.224 0.415 0.362  ||  -0.1761 0.4414 0.3041  || discrepancy=0.05 || select=1/3
001/003-th : 0.313 0.262 0.425  ||  0.0802 -0.0998 0.3855  || discrepancy=0.11 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3176 -0.6198 2.8584  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.012 0.020 0.024 0.026 0.035 0.055 0.120 0.709  ||  -1.450 -0.972 -0.808 -0.727 -0.422 0.032 0.823 2.598  || dis=0.59 || select=7/8
001/019-th : 0.091 0.116 0.141 0.132 0.134 0.129 0.140 0.116  ||  -0.299 -0.059 0.133 0.072 0.085 0.051 0.131 -0.056    || dis=0.00 || select=2/8
002/019-th : 0.117 0.125 0.136 0.132 0.125 0.128 0.123 0.113  ||  -0.057 0.007 0.094 0.059 0.005 0.033 -0.009 -0.093    || dis=0.00 || select=2/8
003/019-th : 0.101 0.113 0.120 0.131 0.132 0.132 0.141 0.130  ||  -0.204 -0.094 -0.037 0.052 0.064 0.064 0.125 0.045    || dis=0.01 || select=6/8
004/019-th : 0.110 0.109 0.112 0.114 0.131 0.126 0.145 0.153  ||  -0.126 -0.131 -0.107 -0.083 0.057 0.012 0.158 0.209   || dis=0.01 || select=7/8
005/019-th : 0.118 0.123 0.125 0.130 0.131 0.124 0.125 0.123  ||  -0.055 -0.012 0.003 0.038 0.047 -0.006 -0.002 -0.017  || dis=0.00 || select=4/8
006/019-th : 0.144 0.136 0.121 0.128 0.120 0.118 0.118 0.115  ||  0.152 0.091 -0.019 0.034 -0.032 -0.045 -0.051 -0.076  || dis=0.01 || select=0/8
007/019-th : 0.010 0.014 0.022 0.025 0.041 0.059 0.115 0.712  ||  -1.597 -1.239 -0.780 -0.663 -0.170 0.191 0.856 2.678  || dis=0.60 || select=7/8
008/019-th : 0.010 0.013 0.020 0.031 0.047 0.081 0.203 0.595  ||  -1.673 -1.379 -0.993 -0.515 -0.105 0.429 1.348 2.425  || dis=0.39 || select=7/8
009/019-th : 0.079 0.083 0.094 0.105 0.120 0.133 0.171 0.216  ||  -0.412 -0.362 -0.233 -0.123 0.012 0.112 0.368 0.598   || dis=0.04 || select=7/8
010/019-th : 0.088 0.092 0.099 0.116 0.129 0.156 0.147 0.172  ||  -0.331 -0.278 -0.210 -0.048 0.060 0.245 0.190 0.347   || dis=0.02 || select=7/8
011/019-th : 0.115 0.114 0.118 0.121 0.124 0.133 0.133 0.141  ||  -0.077 -0.083 -0.048 -0.025 0.000 0.068 0.069 0.130   || dis=0.01 || select=7/8
012/019-th : 0.142 0.135 0.125 0.128 0.128 0.114 0.117 0.111  ||  0.135 0.086 0.008 0.029 0.027 -0.084 -0.062 -0.108    || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.007 0.008 0.010 0.015 0.946  ||  -1.165 -0.995 -0.820 -0.747 -0.613 -0.347 0.054 4.218  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.008 0.011 0.018 0.037 0.908  ||  -1.410 -1.246 -1.060 -0.867 -0.582 -0.141 0.593 3.805  || dis=0.87 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.018 0.945  ||  -1.173 -1.013 -0.933 -0.779 -0.671 -0.346 0.281 4.248  || dis=0.93 || select=7/8
016/019-th : 0.033 0.042 0.054 0.079 0.105 0.162 0.217 0.308  ||  -1.080 -0.849 -0.606 -0.222 0.072 0.503 0.792 1.145   || dis=0.09 || select=7/8
017/019-th : 0.081 0.095 0.104 0.125 0.132 0.130 0.163 0.171  ||  -0.405 -0.252 -0.160 0.030 0.085 0.063 0.291 0.338    || dis=0.01 || select=7/8
018/019-th : 0.095 0.107 0.123 0.142 0.125 0.129 0.132 0.145  ||  -0.264 -0.143 -0.010 0.134 0.012 0.042 0.066 0.160    || dis=0.00 || select=7/8
[epoch=494/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.255
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:05:02] [epoch=494/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.895 (2.895)  Prec@1 18.75 (18.75) Prec@5 82.03 (82.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:05:08] [epoch=494/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.218 (2.200)  Prec@1 13.69 (50.40) Prec@5 63.69 (85.65) Size=[168, 3, 32, 32]
 **VALID** Prec@1 50.40 Prec@5 85.65 Error@1 49.60 Error@5 14.35 Loss:2.200
***[2020-01-29 10:05:08]*** VALID [epoch=494/600] loss = 2.199817, accuracy@1 = 50.40, accuracy@5 = 85.65 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:05:08]*** start epoch=495/600 Time Left: [00:56:01], LR=[0.007368 ~ 0.007368], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=495, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.46103159733247423, FLOP=40.81
[Search] : epoch=495/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:05:09] [epoch=495/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.433 (0.433)  Prec@1 85.94 (85.94) Prec@5 99.22 (99.22) Acls-loss 0.569 (0.569) FLOP-Loss 0.000 (0.000) Arch-Loss 0.569 (0.569)
**TRAIN** [2020-01-29 10:05:33] [epoch=495/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.338 (0.456)  Prec@1 89.88 (84.18) Prec@5 100.00 (99.36) Acls-loss 0.511 (0.642) FLOP-Loss 0.000 (0.031) Arch-Loss 0.511 (0.704)
 **TRAIN** Prec@1 84.18 Prec@5 99.36 Error@1 15.82 Error@5 0.64 Base-Loss:0.456, Arch-Loss=0.704
***[2020-01-29 10:05:33]*** TRAIN [epoch=495/600] base-loss = 0.455760, arch-loss = 0.703634, accuracy-1 = 84.18, accuracy-5 = 99.36
[epoch=495/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.216 0.418 0.366  ||  -0.2025 0.4560 0.3220  || discrepancy=0.05 || select=1/3
001/003-th : 0.306 0.264 0.430  ||  0.0602 -0.0867 0.4003  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.029 0.966  ||  -2.3261 -0.6319 2.8703  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.012 0.020 0.024 0.025 0.034 0.053 0.117 0.714  ||  -1.449 -0.967 -0.797 -0.727 -0.423 0.014 0.806 2.612  || dis=0.60 || select=7/8
001/019-th : 0.091 0.113 0.142 0.132 0.134 0.131 0.140 0.117  ||  -0.303 -0.080 0.142 0.070 0.088 0.064 0.134 -0.050    || dis=0.00 || select=2/8
002/019-th : 0.116 0.124 0.136 0.133 0.124 0.129 0.125 0.114  ||  -0.070 -0.001 0.090 0.066 0.001 0.036 0.007 -0.086    || dis=0.00 || select=2/8
003/019-th : 0.102 0.113 0.119 0.131 0.131 0.132 0.141 0.131  ||  -0.201 -0.099 -0.042 0.057 0.051 0.060 0.129 0.056    || dis=0.01 || select=6/8
004/019-th : 0.107 0.108 0.111 0.115 0.134 0.126 0.147 0.153  ||  -0.148 -0.142 -0.109 -0.078 0.077 0.017 0.170 0.209   || dis=0.01 || select=7/8
005/019-th : 0.118 0.122 0.123 0.130 0.130 0.125 0.125 0.127  ||  -0.058 -0.026 -0.015 0.040 0.041 0.002 -0.002 0.013   || dis=0.00 || select=4/8
006/019-th : 0.142 0.135 0.122 0.129 0.120 0.119 0.119 0.114  ||  0.135 0.088 -0.013 0.041 -0.032 -0.039 -0.041 -0.081  || dis=0.01 || select=0/8
007/019-th : 0.010 0.014 0.022 0.025 0.041 0.057 0.112 0.718  ||  -1.591 -1.236 -0.795 -0.668 -0.159 0.166 0.840 2.694  || dis=0.61 || select=7/8
008/019-th : 0.010 0.012 0.019 0.031 0.046 0.080 0.202 0.600  ||  -1.673 -1.422 -0.998 -0.511 -0.117 0.444 1.363 2.452  || dis=0.40 || select=7/8
009/019-th : 0.079 0.083 0.095 0.105 0.118 0.134 0.170 0.217  ||  -0.412 -0.358 -0.226 -0.125 -0.006 0.120 0.361 0.602  || dis=0.05 || select=7/8
010/019-th : 0.087 0.092 0.101 0.115 0.129 0.153 0.148 0.176  ||  -0.335 -0.281 -0.187 -0.058 0.056 0.225 0.192 0.365   || dis=0.02 || select=7/8
011/019-th : 0.114 0.115 0.116 0.122 0.123 0.134 0.133 0.143  ||  -0.084 -0.081 -0.071 -0.018 -0.009 0.075 0.072 0.144  || dis=0.01 || select=7/8
012/019-th : 0.142 0.135 0.124 0.128 0.131 0.115 0.114 0.112  ||  0.132 0.083 -0.002 0.035 0.052 -0.078 -0.086 -0.098   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.007 0.008 0.010 0.015 0.945  ||  -1.161 -0.985 -0.813 -0.738 -0.609 -0.345 0.046 4.213  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.008 0.011 0.017 0.036 0.909  ||  -1.423 -1.243 -1.055 -0.879 -0.578 -0.149 0.598 3.815  || dis=0.87 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.018 0.945  ||  -1.170 -1.003 -0.934 -0.782 -0.669 -0.349 0.286 4.244  || dis=0.93 || select=7/8
016/019-th : 0.033 0.042 0.053 0.076 0.104 0.163 0.220 0.310  ||  -1.096 -0.840 -0.617 -0.244 0.062 0.514 0.813 1.157   || dis=0.09 || select=7/8
017/019-th : 0.082 0.094 0.103 0.121 0.131 0.133 0.165 0.171  ||  -0.395 -0.256 -0.169 -0.001 0.074 0.088 0.308 0.341   || dis=0.01 || select=7/8
018/019-th : 0.095 0.108 0.121 0.143 0.127 0.128 0.132 0.145  ||  -0.268 -0.135 -0.020 0.140 0.025 0.033 0.066 0.158    || dis=0.00 || select=7/8
[epoch=495/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.257
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:05:34] [epoch=495/600][000/098] Time 0.40 (0.40) Data 0.29 (0.29) Loss 4.588 (4.588)  Prec@1 29.30 (29.30) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:05:40] [epoch=495/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.741 (2.214)  Prec@1 48.21 (47.65) Prec@5 83.33 (84.78) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.65 Prec@5 84.78 Error@1 52.35 Error@5 15.22 Loss:2.214
***[2020-01-29 10:05:40]*** VALID [epoch=495/600] loss = 2.213808, accuracy@1 = 47.65, accuracy@5 = 84.78 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:05:40]*** start epoch=496/600 Time Left: [00:55:29], LR=[0.007232 ~ 0.007232], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=496, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.45435756260675886, FLOP=40.81
[Search] : epoch=496/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:05:41] [epoch=496/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.382 (0.382)  Prec@1 86.33 (86.33) Prec@5 100.00 (100.00) Acls-loss 1.459 (1.459) FLOP-Loss 0.000 (0.000) Arch-Loss 1.459 (1.459)
**TRAIN** [2020-01-29 10:06:05] [epoch=496/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.619 (0.517)  Prec@1 82.14 (82.53) Prec@5 97.02 (99.05) Acls-loss 0.424 (0.599) FLOP-Loss 0.000 (0.214) Arch-Loss 0.424 (1.027)
 **TRAIN** Prec@1 82.53 Prec@5 99.05 Error@1 17.47 Error@5 0.95 Base-Loss:0.517, Arch-Loss=1.027
***[2020-01-29 10:06:05]*** TRAIN [epoch=496/600] base-loss = 0.517498, arch-loss = 1.027350, accuracy-1 = 82.53, accuracy-5 = 99.05
[epoch=496/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.219 0.420 0.361  ||  -0.1930 0.4578 0.3087  || discrepancy=0.06 || select=1/3
001/003-th : 0.308 0.269 0.424  ||  0.0671 -0.0695 0.3867  || discrepancy=0.12 || select=2/3
002/003-th : 0.005 0.029 0.965  ||  -2.3189 -0.6290 2.8628  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.012 0.020 0.023 0.025 0.034 0.051 0.113 0.723  ||  -1.453 -0.959 -0.810 -0.729 -0.417 -0.014 0.787 2.641  || dis=0.61 || select=7/8
001/019-th : 0.092 0.115 0.141 0.132 0.133 0.130 0.141 0.116  ||  -0.295 -0.070 0.139 0.068 0.075 0.058 0.137 -0.060    || dis=0.00 || select=2/8
002/019-th : 0.117 0.124 0.135 0.132 0.125 0.128 0.126 0.112  ||  -0.055 0.002 0.082 0.063 0.010 0.031 0.011 -0.105     || dis=0.00 || select=2/8
003/019-th : 0.102 0.113 0.120 0.132 0.132 0.132 0.140 0.130  ||  -0.194 -0.098 -0.038 0.063 0.059 0.063 0.119 0.042    || dis=0.01 || select=6/8
004/019-th : 0.107 0.107 0.111 0.114 0.133 0.125 0.149 0.152  ||  -0.145 -0.143 -0.108 -0.082 0.072 0.011 0.187 0.201   || dis=0.00 || select=7/8
005/019-th : 0.119 0.123 0.122 0.130 0.129 0.126 0.124 0.126  ||  -0.050 -0.016 -0.022 0.042 0.032 0.009 -0.005 0.005   || dis=0.00 || select=3/8
006/019-th : 0.142 0.136 0.123 0.130 0.119 0.119 0.117 0.114  ||  0.139 0.094 -0.009 0.051 -0.036 -0.042 -0.051 -0.084  || dis=0.01 || select=0/8
007/019-th : 0.010 0.014 0.022 0.025 0.041 0.057 0.111 0.721  ||  -1.585 -1.228 -0.808 -0.663 -0.175 0.160 0.831 2.704  || dis=0.61 || select=7/8
008/019-th : 0.010 0.012 0.019 0.030 0.045 0.078 0.198 0.608  ||  -1.665 -1.433 -0.991 -0.536 -0.122 0.428 1.361 2.481  || dis=0.41 || select=7/8
009/019-th : 0.079 0.084 0.094 0.105 0.119 0.135 0.169 0.215  ||  -0.410 -0.347 -0.233 -0.127 -0.002 0.131 0.354 0.594  || dis=0.05 || select=7/8
010/019-th : 0.087 0.092 0.101 0.116 0.127 0.154 0.146 0.176  ||  -0.335 -0.277 -0.185 -0.054 0.042 0.231 0.183 0.368   || dis=0.02 || select=7/8
011/019-th : 0.116 0.117 0.115 0.121 0.124 0.133 0.133 0.141  ||  -0.073 -0.062 -0.076 -0.024 0.001 0.065 0.071 0.127   || dis=0.01 || select=7/8
012/019-th : 0.143 0.136 0.124 0.128 0.130 0.114 0.113 0.112  ||  0.139 0.091 -0.003 0.035 0.045 -0.082 -0.090 -0.101   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.007 0.007 0.010 0.014 0.947  ||  -1.156 -0.973 -0.830 -0.737 -0.640 -0.342 0.030 4.238  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.008 0.011 0.017 0.036 0.910  ||  -1.417 -1.240 -1.051 -0.884 -0.577 -0.148 0.580 3.822  || dis=0.87 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.010 0.018 0.945  ||  -1.166 -0.992 -0.935 -0.777 -0.674 -0.347 0.285 4.241  || dis=0.93 || select=7/8
016/019-th : 0.033 0.041 0.052 0.074 0.103 0.159 0.222 0.315  ||  -1.087 -0.850 -0.617 -0.272 0.060 0.496 0.826 1.178   || dis=0.09 || select=7/8
017/019-th : 0.081 0.095 0.103 0.123 0.132 0.133 0.164 0.169  ||  -0.410 -0.246 -0.165 0.010 0.085 0.092 0.300 0.331    || dis=0.01 || select=7/8
018/019-th : 0.096 0.109 0.122 0.143 0.127 0.125 0.132 0.144  ||  -0.259 -0.130 -0.014 0.144 0.027 0.011 0.066 0.151    || dis=0.00 || select=7/8
[epoch=496/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.258
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:06:06] [epoch=496/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.293 (2.293)  Prec@1 16.80 (16.80) Prec@5 67.19 (67.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:06:12] [epoch=496/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.987 (2.002)  Prec@1 24.40 (49.34) Prec@5 57.74 (85.36) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.34 Prec@5 85.36 Error@1 50.66 Error@5 14.64 Loss:2.002
***[2020-01-29 10:06:12]*** VALID [epoch=496/600] loss = 2.001949, accuracy@1 = 49.34, accuracy@5 = 85.36 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:06:12]*** start epoch=497/600 Time Left: [00:54:57], LR=[0.007097 ~ 0.007097], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=497, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4477409809770708, FLOP=40.81
[Search] : epoch=497/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:06:13] [epoch=497/600][000/098] Time 0.62 (0.62) Data 0.34 (0.34) Base-Loss 0.463 (0.463)  Prec@1 83.98 (83.98) Prec@5 100.00 (100.00) Acls-loss 0.673 (0.673) FLOP-Loss 0.000 (0.000) Arch-Loss 0.673 (0.673)
**TRAIN** [2020-01-29 10:06:37] [epoch=497/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 1.259 (0.499)  Prec@1 64.88 (83.07) Prec@5 94.64 (99.14) Acls-loss 0.531 (0.627) FLOP-Loss 0.000 (0.092) Arch-Loss 0.531 (0.811)
 **TRAIN** Prec@1 83.07 Prec@5 99.14 Error@1 16.93 Error@5 0.86 Base-Loss:0.499, Arch-Loss=0.811
***[2020-01-29 10:06:37]*** TRAIN [epoch=497/600] base-loss = 0.498738, arch-loss = 0.810701, accuracy-1 = 83.07, accuracy-5 = 99.14
[epoch=497/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.213 0.419 0.368  ||  -0.2180 0.4604 0.3303  || discrepancy=0.05 || select=1/3
001/003-th : 0.303 0.269 0.428  ||  0.0541 -0.0670 0.3975  || discrepancy=0.12 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3100 -0.6150 2.8504  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.012 0.019 0.022 0.024 0.033 0.048 0.108 0.734  ||  -1.452 -0.968 -0.814 -0.733 -0.426 -0.048 0.762 2.683  || dis=0.63 || select=7/8
001/019-th : 0.091 0.114 0.142 0.131 0.134 0.131 0.142 0.115  ||  -0.298 -0.075 0.143 0.061 0.089 0.060 0.141 -0.063    || dis=0.00 || select=2/8
002/019-th : 0.118 0.121 0.135 0.129 0.126 0.128 0.128 0.113  ||  -0.053 -0.024 0.081 0.040 0.017 0.032 0.033 -0.094    || dis=0.01 || select=2/8
003/019-th : 0.100 0.112 0.119 0.131 0.131 0.136 0.140 0.131  ||  -0.215 -0.100 -0.042 0.057 0.054 0.089 0.117 0.052    || dis=0.00 || select=6/8
004/019-th : 0.107 0.108 0.109 0.115 0.133 0.127 0.149 0.153  ||  -0.151 -0.141 -0.133 -0.076 0.066 0.025 0.186 0.210   || dis=0.00 || select=7/8
005/019-th : 0.118 0.123 0.123 0.131 0.129 0.126 0.125 0.126  ||  -0.059 -0.016 -0.018 0.047 0.031 0.010 -0.002 0.006   || dis=0.00 || select=3/8
006/019-th : 0.139 0.135 0.124 0.129 0.120 0.122 0.118 0.113  ||  0.117 0.084 -0.000 0.040 -0.034 -0.015 -0.046 -0.088  || dis=0.00 || select=0/8
007/019-th : 0.010 0.014 0.021 0.024 0.040 0.055 0.109 0.728  ||  -1.594 -1.228 -0.831 -0.669 -0.168 0.144 0.830 2.730  || dis=0.62 || select=7/8
008/019-th : 0.009 0.012 0.018 0.029 0.044 0.075 0.196 0.616  ||  -1.671 -1.441 -0.999 -0.541 -0.133 0.412 1.365 2.512  || dis=0.42 || select=7/8
009/019-th : 0.079 0.084 0.093 0.105 0.118 0.134 0.171 0.215  ||  -0.404 -0.345 -0.243 -0.127 -0.004 0.122 0.365 0.593  || dis=0.04 || select=7/8
010/019-th : 0.087 0.093 0.100 0.115 0.128 0.153 0.147 0.176  ||  -0.333 -0.268 -0.195 -0.061 0.047 0.228 0.190 0.366   || dis=0.02 || select=7/8
011/019-th : 0.115 0.117 0.115 0.123 0.124 0.132 0.133 0.140  ||  -0.076 -0.058 -0.078 -0.010 -0.003 0.064 0.071 0.122  || dis=0.01 || select=7/8
012/019-th : 0.140 0.135 0.124 0.130 0.129 0.115 0.114 0.113  ||  0.122 0.087 -0.002 0.048 0.042 -0.077 -0.084 -0.095   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.014 0.948  ||  -1.151 -0.962 -0.826 -0.778 -0.638 -0.355 0.017 4.254  || dis=0.93 || select=7/8
014/019-th : 0.005 0.006 0.007 0.008 0.011 0.017 0.034 0.913  ||  -1.411 -1.235 -1.063 -0.878 -0.588 -0.163 0.563 3.845  || dis=0.88 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.017 0.946  ||  -1.163 -0.993 -0.927 -0.798 -0.672 -0.358 0.255 4.262  || dis=0.93 || select=7/8
016/019-th : 0.033 0.040 0.051 0.073 0.101 0.163 0.220 0.319  ||  -1.069 -0.882 -0.638 -0.284 0.050 0.527 0.822 1.195   || dis=0.10 || select=7/8
017/019-th : 0.080 0.095 0.103 0.124 0.131 0.133 0.164 0.170  ||  -0.415 -0.248 -0.168 0.017 0.075 0.090 0.303 0.339    || dis=0.01 || select=7/8
018/019-th : 0.094 0.108 0.123 0.144 0.128 0.124 0.135 0.145  ||  -0.276 -0.135 -0.012 0.148 0.030 0.000 0.085 0.156    || dis=0.00 || select=7/8
[epoch=497/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.260
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:06:38] [epoch=497/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.679 (1.679)  Prec@1 39.84 (39.84) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:06:44] [epoch=497/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.253 (2.009)  Prec@1 23.21 (46.91) Prec@5 65.48 (84.36) Size=[168, 3, 32, 32]
 **VALID** Prec@1 46.91 Prec@5 84.36 Error@1 53.09 Error@5 15.64 Loss:2.009
***[2020-01-29 10:06:44]*** VALID [epoch=497/600] loss = 2.008874, accuracy@1 = 46.91, accuracy@5 = 84.36 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:06:44]*** start epoch=498/600 Time Left: [00:54:25], LR=[0.006963 ~ 0.006963], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=498, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4411820338403384, FLOP=40.81
[Search] : epoch=498/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:06:45] [epoch=498/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.444 (0.444)  Prec@1 84.77 (84.77) Prec@5 98.83 (98.83) Acls-loss 1.022 (1.022) FLOP-Loss 0.000 (0.000) Arch-Loss 1.022 (1.022)
**TRAIN** [2020-01-29 10:07:10] [epoch=498/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.476 (0.504)  Prec@1 83.93 (82.92) Prec@5 99.40 (99.19) Acls-loss 0.519 (0.616) FLOP-Loss 0.000 (0.337) Arch-Loss 0.519 (1.290)
 **TRAIN** Prec@1 82.92 Prec@5 99.19 Error@1 17.08 Error@5 0.81 Base-Loss:0.504, Arch-Loss=1.290
***[2020-01-29 10:07:10]*** TRAIN [epoch=498/600] base-loss = 0.503917, arch-loss = 1.290202, accuracy-1 = 82.92, accuracy-5 = 99.19
[epoch=498/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 14, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.238464)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.213 0.427 0.360  ||  -0.2137 0.4839 0.3128  || discrepancy=0.07 || select=1/3
001/003-th : 0.308 0.273 0.419  ||  0.0700 -0.0526 0.3759  || discrepancy=0.11 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.2999 -0.6114 2.8399  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.012 0.019 0.022 0.024 0.033 0.048 0.108 0.735  ||  -1.445 -0.960 -0.834 -0.738 -0.408 -0.055 0.763 2.683  || dis=0.63 || select=7/8
001/019-th : 0.091 0.116 0.143 0.130 0.135 0.129 0.142 0.113  ||  -0.302 -0.056 0.150 0.053 0.096 0.051 0.146 -0.084    || dis=0.00 || select=2/8
002/019-th : 0.118 0.123 0.137 0.131 0.126 0.127 0.126 0.112  ||  -0.049 -0.008 0.097 0.049 0.011 0.019 0.012 -0.100    || dis=0.01 || select=2/8
003/019-th : 0.102 0.113 0.120 0.132 0.130 0.136 0.138 0.129  ||  -0.198 -0.092 -0.037 0.061 0.046 0.090 0.102 0.035    || dis=0.00 || select=6/8
004/019-th : 0.108 0.110 0.111 0.117 0.132 0.124 0.147 0.152  ||  -0.141 -0.122 -0.112 -0.063 0.063 0.003 0.169 0.201   || dis=0.01 || select=7/8
005/019-th : 0.118 0.126 0.125 0.132 0.129 0.125 0.122 0.123  ||  -0.053 0.008 -0.003 0.058 0.036 -0.003 -0.024 -0.018  || dis=0.00 || select=3/8
006/019-th : 0.142 0.136 0.124 0.129 0.119 0.121 0.117 0.111  ||  0.141 0.094 0.006 0.042 -0.040 -0.023 -0.053 -0.105   || dis=0.01 || select=0/8
007/019-th : 0.009 0.014 0.020 0.024 0.039 0.054 0.104 0.736  ||  -1.605 -1.235 -0.836 -0.659 -0.169 0.137 0.803 2.758  || dis=0.63 || select=7/8
008/019-th : 0.009 0.012 0.018 0.029 0.043 0.075 0.191 0.624  ||  -1.664 -1.445 -1.030 -0.548 -0.135 0.417 1.354 2.537  || dis=0.43 || select=7/8
009/019-th : 0.080 0.084 0.094 0.104 0.119 0.133 0.169 0.216  ||  -0.394 -0.349 -0.231 -0.133 -0.001 0.114 0.352 0.598  || dis=0.05 || select=7/8
010/019-th : 0.087 0.095 0.105 0.116 0.126 0.153 0.146 0.173  ||  -0.334 -0.254 -0.154 -0.049 0.029 0.223 0.180 0.350   || dis=0.02 || select=7/8
011/019-th : 0.117 0.119 0.115 0.125 0.124 0.131 0.132 0.138  ||  -0.062 -0.039 -0.080 0.006 -0.005 0.050 0.063 0.105   || dis=0.01 || select=7/8
012/019-th : 0.144 0.138 0.125 0.129 0.126 0.114 0.113 0.111  ||  0.148 0.106 0.009 0.038 0.017 -0.082 -0.094 -0.113    || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.013 0.949  ||  -1.150 -0.975 -0.820 -0.771 -0.634 -0.356 0.001 4.264  || dis=0.94 || select=7/8
014/019-th : 0.005 0.006 0.007 0.008 0.011 0.016 0.034 0.914  ||  -1.404 -1.231 -1.058 -0.891 -0.586 -0.169 0.550 3.854  || dis=0.88 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.017 0.946  ||  -1.158 -0.981 -0.915 -0.793 -0.677 -0.356 0.246 4.258  || dis=0.93 || select=7/8
016/019-th : 0.033 0.040 0.052 0.072 0.102 0.164 0.219 0.318  ||  -1.077 -0.877 -0.624 -0.288 0.055 0.528 0.819 1.193   || dis=0.10 || select=7/8
017/019-th : 0.082 0.096 0.103 0.124 0.130 0.133 0.163 0.168  ||  -0.393 -0.241 -0.164 0.015 0.065 0.092 0.295 0.325    || dis=0.01 || select=7/8
018/019-th : 0.094 0.111 0.125 0.143 0.129 0.123 0.133 0.143  ||  -0.272 -0.114 0.006 0.140 0.036 -0.006 0.067 0.142    || dis=0.00 || select=7/8
[epoch=498/600] FLOP : 28.24 MB, ratio : 0.6919, Expected-ratio : 0.7000, Discrepancy : 0.262
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:07:10] [epoch=498/600][000/098] Time 0.38 (0.38) Data 0.27 (0.27) Loss 1.006 (1.006)  Prec@1 66.41 (66.41) Prec@5 94.92 (94.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:07:16] [epoch=498/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.159 (1.963)  Prec@1 20.24 (49.36) Prec@5 75.60 (87.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.36 Prec@5 87.02 Error@1 50.64 Error@5 12.98 Loss:1.963
***[2020-01-29 10:07:16]*** VALID [epoch=498/600] loss = 1.963220, accuracy@1 = 49.36, accuracy@5 = 87.02 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:07:16]*** start epoch=499/600 Time Left: [00:53:53], LR=[0.006830 ~ 0.006830], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=499, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4346809010134095, FLOP=40.81
[Search] : epoch=499/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:07:17] [epoch=499/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 0.398 (0.398)  Prec@1 86.72 (86.72) Prec@5 99.22 (99.22) Acls-loss 0.727 (0.727) FLOP-Loss 0.000 (0.000) Arch-Loss 0.727 (0.727)
**TRAIN** [2020-01-29 10:07:41] [epoch=499/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.551 (0.475)  Prec@1 82.14 (83.79) Prec@5 100.00 (99.25) Acls-loss 0.471 (0.613) FLOP-Loss 0.000 (0.337) Arch-Loss 0.471 (1.287)
 **TRAIN** Prec@1 83.79 Prec@5 99.25 Error@1 16.21 Error@5 0.75 Base-Loss:0.475, Arch-Loss=1.287
***[2020-01-29 10:07:41]*** TRAIN [epoch=499/600] base-loss = 0.474619, arch-loss = 1.286598, accuracy-1 = 83.79, accuracy-5 = 99.25
[epoch=499/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 12, 16, 9, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.1232)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.212 0.431 0.356  ||  -0.2131 0.4950 0.3047  || discrepancy=0.08 || select=1/3
001/003-th : 0.315 0.272 0.413  ||  0.0883 -0.0597 0.3583  || discrepancy=0.10 || select=2/3
002/003-th : 0.006 0.031 0.963  ||  -2.2909 -0.6068 2.8302  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.011 0.019 0.021 0.023 0.033 0.046 0.104 0.743  ||  -1.458 -0.957 -0.839 -0.765 -0.408 -0.056 0.752 2.718  || dis=0.64 || select=7/8
001/019-th : 0.092 0.114 0.143 0.129 0.137 0.129 0.143 0.115  ||  -0.294 -0.078 0.147 0.045 0.109 0.044 0.147 -0.070    || dis=0.00 || select=6/8
002/019-th : 0.118 0.125 0.137 0.134 0.126 0.126 0.123 0.113  ||  -0.054 0.002 0.095 0.076 0.012 0.014 -0.014 -0.099    || dis=0.00 || select=2/8
003/019-th : 0.104 0.115 0.121 0.132 0.129 0.136 0.136 0.126  ||  -0.183 -0.081 -0.026 0.058 0.036 0.091 0.091 0.015    || dis=0.00 || select=5/8
004/019-th : 0.109 0.111 0.112 0.117 0.132 0.124 0.146 0.150  ||  -0.129 -0.113 -0.104 -0.058 0.065 -0.003 0.161 0.188  || dis=0.00 || select=7/8
005/019-th : 0.122 0.128 0.125 0.132 0.129 0.124 0.120 0.120  ||  -0.029 0.023 0.001 0.055 0.032 -0.012 -0.039 -0.039   || dis=0.00 || select=3/8
006/019-th : 0.145 0.136 0.125 0.128 0.119 0.120 0.116 0.110  ||  0.159 0.095 0.008 0.037 -0.036 -0.027 -0.062 -0.116   || dis=0.01 || select=0/8
007/019-th : 0.009 0.014 0.020 0.024 0.039 0.053 0.102 0.739  ||  -1.600 -1.225 -0.846 -0.666 -0.166 0.126 0.786 2.768  || dis=0.64 || select=7/8
008/019-th : 0.009 0.012 0.017 0.028 0.042 0.074 0.187 0.631  ||  -1.657 -1.441 -1.045 -0.549 -0.145 0.412 1.339 2.557  || dis=0.44 || select=7/8
009/019-th : 0.081 0.085 0.096 0.104 0.119 0.133 0.168 0.214  ||  -0.389 -0.338 -0.212 -0.135 -0.004 0.109 0.344 0.586  || dis=0.05 || select=7/8
010/019-th : 0.089 0.095 0.106 0.116 0.127 0.151 0.145 0.171  ||  -0.318 -0.254 -0.141 -0.049 0.036 0.213 0.171 0.335   || dis=0.02 || select=7/8
011/019-th : 0.119 0.121 0.114 0.124 0.124 0.130 0.131 0.137  ||  -0.040 -0.026 -0.088 -0.000 -0.006 0.045 0.053 0.098  || dis=0.01 || select=7/8
012/019-th : 0.148 0.139 0.126 0.127 0.123 0.115 0.112 0.109  ||  0.176 0.115 0.015 0.024 -0.009 -0.077 -0.098 -0.126   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.013 0.950  ||  -1.146 -0.991 -0.837 -0.764 -0.630 -0.347 -0.016 4.281  || dis=0.94 || select=7/8
014/019-th : 0.005 0.006 0.007 0.008 0.011 0.016 0.033 0.915  ||  -1.398 -1.222 -1.053 -0.890 -0.584 -0.186 0.535 3.863  || dis=0.88 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.017 0.947  ||  -1.155 -0.970 -0.909 -0.815 -0.678 -0.368 0.233 4.274  || dis=0.93 || select=7/8
016/019-th : 0.033 0.040 0.051 0.072 0.103 0.165 0.222 0.314  ||  -1.074 -0.881 -0.640 -0.288 0.069 0.539 0.832 1.180   || dis=0.09 || select=7/8
017/019-th : 0.084 0.098 0.102 0.124 0.130 0.135 0.161 0.166  ||  -0.378 -0.218 -0.175 0.015 0.066 0.099 0.280 0.309    || dis=0.01 || select=7/8
018/019-th : 0.093 0.113 0.127 0.143 0.128 0.125 0.129 0.144  ||  -0.288 -0.096 0.023 0.143 0.031 0.005 0.037 0.148     || dis=0.00 || select=7/8
[epoch=499/600] FLOP : 29.12 MB, ratio : 0.7136, Expected-ratio : 0.7000, Discrepancy : 0.262
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:07:41] [epoch=499/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 2.251 (2.251)  Prec@1 33.20 (33.20) Prec@5 83.98 (83.98) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:07:47] [epoch=499/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.923 (2.168)  Prec@1 54.17 (47.42) Prec@5 90.48 (83.85) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.42 Prec@5 83.85 Error@1 52.58 Error@5 16.15 Loss:2.168
***[2020-01-29 10:07:47]*** VALID [epoch=499/600] loss = 2.168137, accuracy@1 = 47.42, accuracy@5 = 83.85 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:07:47]*** start epoch=500/600 Time Left: [00:53:20], LR=[0.006699 ~ 0.006699], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=500, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.42823776072812525, FLOP=40.81
[Search] : epoch=500/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:07:48] [epoch=500/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.347 (0.347)  Prec@1 87.89 (87.89) Prec@5 100.00 (100.00) Acls-loss 0.614 (0.614) FLOP-Loss 2.986 (2.986) Arch-Loss 6.585 (6.585)
**TRAIN** [2020-01-29 10:08:12] [epoch=500/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 0.324 (0.507)  Prec@1 91.67 (82.64) Prec@5 100.00 (99.12) Acls-loss 0.549 (0.634) FLOP-Loss 0.000 (0.214) Arch-Loss 0.549 (1.062)
 **TRAIN** Prec@1 82.64 Prec@5 99.12 Error@1 17.36 Error@5 0.88 Base-Loss:0.507, Arch-Loss=1.062
***[2020-01-29 10:08:12]*** TRAIN [epoch=500/600] base-loss = 0.506906, arch-loss = 1.061821, accuracy-1 = 82.64, accuracy-5 = 99.12
[epoch=500/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 12, 16, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.320124)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.212 0.437 0.350  ||  -0.2100 0.5129 0.2914  || discrepancy=0.09 || select=1/3
001/003-th : 0.314 0.273 0.413  ||  0.0860 -0.0554 0.3580  || discrepancy=0.10 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.2997 -0.6147 2.8419  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.011 0.018 0.021 0.023 0.031 0.046 0.102 0.748  ||  -1.470 -0.963 -0.846 -0.755 -0.438 -0.046 0.750 2.740  || dis=0.65 || select=7/8
001/019-th : 0.093 0.114 0.142 0.131 0.137 0.127 0.143 0.114  ||  -0.285 -0.079 0.141 0.058 0.106 0.032 0.151 -0.077    || dis=0.00 || select=6/8
002/019-th : 0.116 0.126 0.137 0.134 0.126 0.125 0.124 0.111  ||  -0.064 0.014 0.098 0.077 0.016 0.010 -0.002 -0.110    || dis=0.00 || select=2/8
003/019-th : 0.103 0.114 0.122 0.133 0.129 0.138 0.136 0.125  ||  -0.190 -0.084 -0.015 0.070 0.034 0.102 0.088 0.003    || dis=0.00 || select=5/8
004/019-th : 0.110 0.112 0.113 0.117 0.133 0.122 0.145 0.148  ||  -0.119 -0.102 -0.091 -0.062 0.067 -0.014 0.157 0.177  || dis=0.00 || select=7/8
005/019-th : 0.123 0.129 0.123 0.129 0.129 0.126 0.121 0.119  ||  -0.019 0.032 -0.014 0.030 0.031 0.010 -0.032 -0.047   || dis=0.00 || select=1/8
006/019-th : 0.147 0.136 0.126 0.129 0.118 0.119 0.117 0.108  ||  0.175 0.098 0.022 0.043 -0.044 -0.038 -0.058 -0.134   || dis=0.01 || select=0/8
007/019-th : 0.009 0.013 0.020 0.023 0.038 0.052 0.099 0.745  ||  -1.593 -1.229 -0.840 -0.702 -0.176 0.121 0.773 2.789  || dis=0.65 || select=7/8
008/019-th : 0.009 0.012 0.017 0.029 0.042 0.073 0.186 0.633  ||  -1.668 -1.437 -1.046 -0.534 -0.155 0.404 1.341 2.567  || dis=0.45 || select=7/8
009/019-th : 0.081 0.083 0.097 0.104 0.119 0.133 0.172 0.210  ||  -0.379 -0.360 -0.199 -0.131 -0.001 0.114 0.367 0.570  || dis=0.04 || select=7/8
010/019-th : 0.089 0.095 0.106 0.117 0.128 0.150 0.146 0.169  ||  -0.313 -0.251 -0.145 -0.040 0.045 0.205 0.176 0.325   || dis=0.02 || select=7/8
011/019-th : 0.120 0.121 0.114 0.125 0.124 0.129 0.131 0.137  ||  -0.039 -0.028 -0.084 0.002 -0.000 0.037 0.049 0.096   || dis=0.01 || select=7/8
012/019-th : 0.150 0.139 0.127 0.127 0.123 0.114 0.111 0.109  ||  0.189 0.112 0.021 0.027 -0.007 -0.080 -0.110 -0.131   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.013 0.951  ||  -1.139 -0.985 -0.848 -0.776 -0.626 -0.346 -0.034 4.294  || dis=0.94 || select=7/8
014/019-th : 0.004 0.006 0.007 0.008 0.010 0.015 0.032 0.919  ||  -1.430 -1.217 -1.047 -0.886 -0.593 -0.193 0.523 3.895  || dis=0.89 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.016 0.948  ||  -1.150 -0.956 -0.900 -0.810 -0.690 -0.381 0.220 4.282  || dis=0.93 || select=7/8
016/019-th : 0.033 0.041 0.051 0.073 0.102 0.165 0.219 0.316  ||  -1.066 -0.866 -0.637 -0.285 0.053 0.537 0.816 1.185   || dis=0.10 || select=7/8
017/019-th : 0.084 0.101 0.104 0.125 0.131 0.133 0.158 0.165  ||  -0.374 -0.195 -0.165 0.020 0.069 0.085 0.258 0.300    || dis=0.01 || select=7/8
018/019-th : 0.093 0.112 0.129 0.142 0.128 0.124 0.129 0.142  ||  -0.282 -0.098 0.039 0.138 0.033 0.003 0.037 0.136     || dis=0.00 || select=3/8
[epoch=500/600] FLOP : 28.32 MB, ratio : 0.6939, Expected-ratio : 0.7000, Discrepancy : 0.264
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:08:13] [epoch=500/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 4.877 (4.877)  Prec@1 9.38 (9.38) Prec@5 57.81 (57.81) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:08:19] [epoch=500/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.640 (2.102)  Prec@1 77.98 (49.90) Prec@5 98.81 (86.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.90 Prec@5 86.40 Error@1 50.10 Error@5 13.60 Loss:2.102
***[2020-01-29 10:08:19]*** VALID [epoch=500/600] loss = 2.101859, accuracy@1 = 49.90, accuracy@5 = 86.40 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:08:19]*** start epoch=501/600 Time Left: [00:52:48], LR=[0.006568 ~ 0.006568], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=501, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4218527896264319, FLOP=40.81
[Search] : epoch=501/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:08:20] [epoch=501/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.299 (0.299)  Prec@1 88.28 (88.28) Prec@5 100.00 (100.00) Acls-loss 0.984 (0.984) FLOP-Loss 0.000 (0.000) Arch-Loss 0.984 (0.984)
**TRAIN** [2020-01-29 10:08:46] [epoch=501/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.317 (0.457)  Prec@1 87.50 (84.32) Prec@5 100.00 (99.32) Acls-loss 0.624 (0.631) FLOP-Loss 0.000 (0.214) Arch-Loss 0.624 (1.059)
 **TRAIN** Prec@1 84.32 Prec@5 99.32 Error@1 15.68 Error@5 0.68 Base-Loss:0.457, Arch-Loss=1.059
***[2020-01-29 10:08:46]*** TRAIN [epoch=501/600] base-loss = 0.456947, arch-loss = 1.059253, accuracy-1 = 84.32, accuracy-5 = 99.32
[epoch=501/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.970492)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.213 0.441 0.346  ||  -0.2043 0.5225 0.2789  || discrepancy=0.10 || select=1/3
001/003-th : 0.316 0.277 0.407  ||  0.0921 -0.0413 0.3461  || discrepancy=0.09 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.2974 -0.6064 2.8376  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.011 0.018 0.020 0.022 0.030 0.045 0.099 0.754  ||  -1.479 -0.965 -0.858 -0.751 -0.443 -0.056 0.737 2.768  || dis=0.66 || select=7/8
001/019-th : 0.093 0.114 0.142 0.133 0.134 0.129 0.142 0.113  ||  -0.282 -0.077 0.144 0.077 0.084 0.045 0.143 -0.083    || dis=0.00 || select=2/8
002/019-th : 0.116 0.124 0.136 0.137 0.126 0.125 0.123 0.111  ||  -0.065 -0.000 0.094 0.101 0.018 0.009 -0.009 -0.108   || dis=0.00 || select=3/8
003/019-th : 0.103 0.116 0.124 0.132 0.128 0.138 0.134 0.124  ||  -0.189 -0.067 -0.003 0.062 0.026 0.105 0.072 -0.004   || dis=0.00 || select=5/8
004/019-th : 0.112 0.110 0.114 0.117 0.130 0.124 0.147 0.146  ||  -0.104 -0.123 -0.084 -0.057 0.050 -0.000 0.167 0.165  || dis=0.00 || select=6/8
005/019-th : 0.125 0.129 0.124 0.128 0.128 0.125 0.121 0.119  ||  -0.002 0.033 -0.008 0.020 0.023 0.002 -0.031 -0.050   || dis=0.00 || select=1/8
006/019-th : 0.148 0.136 0.125 0.127 0.119 0.120 0.116 0.108  ||  0.179 0.099 0.013 0.029 -0.034 -0.032 -0.066 -0.133   || dis=0.01 || select=0/8
007/019-th : 0.009 0.013 0.019 0.022 0.037 0.051 0.099 0.749  ||  -1.587 -1.231 -0.866 -0.707 -0.196 0.120 0.781 2.804  || dis=0.65 || select=7/8
008/019-th : 0.009 0.011 0.017 0.028 0.042 0.072 0.181 0.640  ||  -1.660 -1.445 -1.043 -0.547 -0.146 0.395 1.319 2.584  || dis=0.46 || select=7/8
009/019-th : 0.082 0.083 0.095 0.107 0.120 0.132 0.172 0.208  ||  -0.368 -0.358 -0.222 -0.102 0.005 0.104 0.368 0.561   || dis=0.04 || select=7/8
010/019-th : 0.090 0.096 0.106 0.118 0.130 0.150 0.145 0.166  ||  -0.306 -0.241 -0.143 -0.039 0.060 0.205 0.171 0.304   || dis=0.02 || select=7/8
011/019-th : 0.121 0.120 0.116 0.125 0.125 0.127 0.130 0.135  ||  -0.025 -0.033 -0.068 0.004 0.003 0.023 0.047 0.083    || dis=0.01 || select=7/8
012/019-th : 0.151 0.139 0.126 0.129 0.122 0.114 0.110 0.108  ||  0.197 0.115 0.016 0.043 -0.013 -0.081 -0.116 -0.138   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.012 0.951  ||  -1.138 -0.992 -0.844 -0.770 -0.622 -0.363 -0.038 4.301  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.008 0.010 0.016 0.032 0.919  ||  -1.432 -1.263 -1.048 -0.894 -0.604 -0.168 0.542 3.911  || dis=0.89 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.006 0.009 0.016 0.948  ||  -1.148 -0.944 -0.905 -0.818 -0.694 -0.388 0.218 4.289  || dis=0.93 || select=7/8
016/019-th : 0.033 0.041 0.051 0.073 0.101 0.166 0.222 0.314  ||  -1.074 -0.863 -0.636 -0.284 0.045 0.545 0.832 1.179   || dis=0.09 || select=7/8
017/019-th : 0.084 0.101 0.106 0.127 0.130 0.132 0.156 0.163  ||  -0.371 -0.196 -0.141 0.040 0.060 0.075 0.246 0.289    || dis=0.01 || select=7/8
018/019-th : 0.094 0.115 0.131 0.142 0.127 0.122 0.129 0.140  ||  -0.279 -0.074 0.055 0.137 0.022 -0.014 0.036 0.121    || dis=0.00 || select=3/8
[epoch=501/600] FLOP : 26.97 MB, ratio : 0.6608, Expected-ratio : 0.7000, Discrepancy : 0.265
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:08:47] [epoch=501/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.663 (1.663)  Prec@1 54.69 (54.69) Prec@5 92.19 (92.19) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:08:53] [epoch=501/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.936 (2.099)  Prec@1 33.33 (49.44) Prec@5 84.52 (86.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.44 Prec@5 86.26 Error@1 50.56 Error@5 13.74 Loss:2.099
***[2020-01-29 10:08:53]*** VALID [epoch=501/600] loss = 2.098594, accuracy@1 = 49.44, accuracy@5 = 86.26 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:08:53]*** start epoch=502/600 Time Left: [00:52:17], LR=[0.006439 ~ 0.006439], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=502, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4155261627555361, FLOP=40.81
[Search] : epoch=502/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:08:54] [epoch=502/600][000/098] Time 0.70 (0.70) Data 0.39 (0.39) Base-Loss 0.958 (0.958)  Prec@1 68.75 (68.75) Prec@5 97.27 (97.27) Acls-loss 0.672 (0.672) FLOP-Loss 0.000 (0.000) Arch-Loss 0.672 (0.672)
**TRAIN** [2020-01-29 10:09:20] [epoch=502/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.447 (0.459)  Prec@1 83.93 (84.29) Prec@5 98.81 (99.30) Acls-loss 0.877 (0.593) FLOP-Loss 0.000 (0.244) Arch-Loss 0.877 (1.081)
 **TRAIN** Prec@1 84.29 Prec@5 99.30 Error@1 15.71 Error@5 0.70 Base-Loss:0.459, Arch-Loss=1.081
***[2020-01-29 10:09:20]*** TRAIN [epoch=502/600] base-loss = 0.458582, arch-loss = 1.081410, accuracy-1 = 84.29, accuracy-5 = 99.30
[epoch=502/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 16, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.592508)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.212 0.448 0.340  ||  -0.2053 0.5433 0.2682  || discrepancy=0.11 || select=1/3
001/003-th : 0.320 0.277 0.402  ||  0.1037 -0.0401 0.3324  || discrepancy=0.08 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.3021 -0.6021 2.8411  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.011 0.017 0.020 0.022 0.030 0.044 0.096 0.760  ||  -1.471 -0.993 -0.848 -0.755 -0.445 -0.061 0.715 2.787  || dis=0.66 || select=7/8
001/019-th : 0.092 0.116 0.141 0.133 0.135 0.129 0.142 0.113  ||  -0.287 -0.059 0.134 0.074 0.094 0.044 0.139 -0.090    || dis=0.00 || select=6/8
002/019-th : 0.118 0.125 0.135 0.138 0.126 0.126 0.123 0.109  ||  -0.053 0.007 0.087 0.105 0.011 0.012 -0.010 -0.127    || dis=0.00 || select=3/8
003/019-th : 0.105 0.119 0.125 0.131 0.129 0.138 0.131 0.123  ||  -0.176 -0.049 0.002 0.047 0.032 0.102 0.048 -0.010    || dis=0.01 || select=5/8
004/019-th : 0.112 0.108 0.115 0.118 0.132 0.121 0.145 0.148  ||  -0.104 -0.133 -0.070 -0.051 0.066 -0.020 0.161 0.175  || dis=0.00 || select=7/8
005/019-th : 0.127 0.131 0.125 0.127 0.128 0.125 0.119 0.117  ||  0.017 0.047 -0.004 0.013 0.026 0.000 -0.047 -0.066    || dis=0.00 || select=1/8
006/019-th : 0.149 0.137 0.126 0.128 0.119 0.120 0.113 0.107  ||  0.190 0.107 0.019 0.040 -0.035 -0.030 -0.088 -0.141   || dis=0.01 || select=0/8
007/019-th : 0.009 0.013 0.018 0.022 0.037 0.050 0.097 0.753  ||  -1.589 -1.232 -0.884 -0.707 -0.192 0.114 0.778 2.822  || dis=0.66 || select=7/8
008/019-th : 0.009 0.011 0.017 0.027 0.040 0.070 0.178 0.648  ||  -1.686 -1.438 -1.046 -0.551 -0.159 0.384 1.321 2.616  || dis=0.47 || select=7/8
009/019-th : 0.080 0.083 0.096 0.109 0.120 0.132 0.173 0.207  ||  -0.391 -0.356 -0.217 -0.087 0.008 0.102 0.373 0.556   || dis=0.03 || select=7/8
010/019-th : 0.091 0.096 0.107 0.119 0.129 0.151 0.144 0.164  ||  -0.299 -0.246 -0.137 -0.024 0.055 0.211 0.164 0.294   || dis=0.01 || select=7/8
011/019-th : 0.122 0.122 0.116 0.122 0.126 0.128 0.129 0.134  ||  -0.015 -0.018 -0.065 -0.015 0.013 0.025 0.038 0.074   || dis=0.01 || select=7/8
012/019-th : 0.152 0.140 0.126 0.128 0.122 0.113 0.110 0.108  ||  0.206 0.124 0.019 0.032 -0.020 -0.089 -0.120 -0.139   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.013 0.951  ||  -1.132 -0.985 -0.839 -0.763 -0.617 -0.360 -0.038 4.291  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.010 0.016 0.031 0.920  ||  -1.428 -1.259 -1.040 -0.898 -0.600 -0.166 0.525 3.914  || dis=0.89 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.016 0.948  ||  -1.152 -0.934 -0.896 -0.813 -0.690 -0.386 0.208 4.288  || dis=0.93 || select=7/8
016/019-th : 0.033 0.040 0.051 0.073 0.100 0.167 0.225 0.312  ||  -1.082 -0.866 -0.635 -0.279 0.035 0.548 0.848 1.177   || dis=0.09 || select=7/8
017/019-th : 0.086 0.102 0.105 0.127 0.130 0.134 0.155 0.161  ||  -0.353 -0.186 -0.156 0.038 0.064 0.088 0.239 0.273    || dis=0.01 || select=7/8
018/019-th : 0.094 0.117 0.132 0.143 0.125 0.120 0.129 0.140  ||  -0.278 -0.058 0.062 0.139 0.006 -0.032 0.040 0.121    || dis=0.00 || select=3/8
[epoch=502/600] FLOP : 28.59 MB, ratio : 0.7006, Expected-ratio : 0.7000, Discrepancy : 0.266
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:09:21] [epoch=502/600][000/098] Time 0.40 (0.40) Data 0.32 (0.32) Loss 2.968 (2.968)  Prec@1 23.83 (23.83) Prec@5 70.70 (70.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:09:27] [epoch=502/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.823 (2.546)  Prec@1 81.55 (44.96) Prec@5 97.62 (83.50) Size=[168, 3, 32, 32]
 **VALID** Prec@1 44.96 Prec@5 83.50 Error@1 55.04 Error@5 16.50 Loss:2.546
***[2020-01-29 10:09:27]*** VALID [epoch=502/600] loss = 2.546352, accuracy@1 = 44.96, accuracy@5 = 83.50 | Best-Valid-Acc@1=53.32, Error@1=46.68
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:09:27]*** start epoch=503/600 Time Left: [00:51:45], LR=[0.006311 ~ 0.006311], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=503, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.4092580535631103, FLOP=40.81
[Search] : epoch=503/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:09:28] [epoch=503/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.737 (0.737)  Prec@1 70.70 (70.70) Prec@5 100.00 (100.00) Acls-loss 0.544 (0.544) FLOP-Loss 2.981 (2.981) Arch-Loss 6.506 (6.506)
**TRAIN** [2020-01-29 10:09:54] [epoch=503/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 1.010 (0.462)  Prec@1 66.07 (84.30) Prec@5 96.43 (99.32) Acls-loss 0.621 (0.624) FLOP-Loss 0.000 (0.214) Arch-Loss 0.621 (1.051)
 **TRAIN** Prec@1 84.30 Prec@5 99.32 Error@1 15.70 Error@5 0.68 Base-Loss:0.462, Arch-Loss=1.051
***[2020-01-29 10:09:54]*** TRAIN [epoch=503/600] base-loss = 0.461941, arch-loss = 1.051056, accuracy-1 = 84.30, accuracy-5 = 99.32
[epoch=503/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.352892)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.209 0.452 0.339  ||  -0.2146 0.5564 0.2687  || discrepancy=0.11 || select=1/3
001/003-th : 0.325 0.275 0.400  ||  0.1140 -0.0501 0.3234  || discrepancy=0.08 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3393 -0.6049 2.8784  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.011 0.017 0.020 0.022 0.030 0.044 0.096 0.760  ||  -1.468 -0.985 -0.838 -0.747 -0.460 -0.066 0.714 2.786  || dis=0.66 || select=7/8
001/019-th : 0.092 0.117 0.142 0.133 0.134 0.128 0.143 0.112  ||  -0.293 -0.053 0.141 0.076 0.084 0.042 0.148 -0.097    || dis=0.00 || select=6/8
002/019-th : 0.119 0.126 0.136 0.138 0.123 0.125 0.123 0.110  ||  -0.048 0.013 0.090 0.104 -0.011 0.006 -0.013 -0.120   || dis=0.00 || select=3/8
003/019-th : 0.106 0.120 0.124 0.130 0.130 0.137 0.131 0.122  ||  -0.167 -0.040 -0.003 0.040 0.038 0.095 0.051 -0.021   || dis=0.01 || select=5/8
004/019-th : 0.112 0.108 0.115 0.116 0.134 0.122 0.147 0.146  ||  -0.100 -0.134 -0.074 -0.062 0.077 -0.014 0.172 0.162  || dis=0.00 || select=6/8
005/019-th : 0.128 0.131 0.127 0.127 0.128 0.125 0.118 0.116  ||  0.026 0.047 0.013 0.015 0.019 -0.005 -0.058 -0.074    || dis=0.00 || select=1/8
006/019-th : 0.150 0.139 0.126 0.128 0.117 0.120 0.113 0.106  ||  0.198 0.123 0.024 0.037 -0.049 -0.030 -0.091 -0.149   || dis=0.01 || select=0/8
007/019-th : 0.009 0.013 0.018 0.021 0.036 0.049 0.095 0.759  ||  -1.583 -1.223 -0.900 -0.723 -0.216 0.109 0.772 2.846  || dis=0.66 || select=7/8
008/019-th : 0.009 0.011 0.017 0.027 0.040 0.069 0.173 0.654  ||  -1.680 -1.432 -1.041 -0.553 -0.166 0.381 1.293 2.624  || dis=0.48 || select=7/8
009/019-th : 0.081 0.083 0.095 0.110 0.121 0.133 0.172 0.205  ||  -0.382 -0.355 -0.223 -0.075 0.016 0.109 0.366 0.543   || dis=0.03 || select=7/8
010/019-th : 0.091 0.097 0.106 0.117 0.130 0.151 0.146 0.164  ||  -0.296 -0.236 -0.146 -0.044 0.058 0.212 0.176 0.292   || dis=0.01 || select=7/8
011/019-th : 0.122 0.124 0.117 0.124 0.125 0.129 0.128 0.132  ||  -0.018 -0.003 -0.064 -0.006 0.006 0.040 0.030 0.059   || dis=0.00 || select=7/8
012/019-th : 0.154 0.142 0.126 0.128 0.119 0.112 0.109 0.109  ||  0.216 0.132 0.017 0.030 -0.038 -0.099 -0.126 -0.130   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.006 0.006 0.007 0.009 0.012 0.951  ||  -1.126 -0.984 -0.849 -0.756 -0.628 -0.359 -0.042 4.298  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.010 0.015 0.030 0.923  ||  -1.433 -1.256 -1.032 -0.910 -0.599 -0.192 0.504 3.946  || dis=0.89 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.016 0.949  ||  -1.147 -0.923 -0.929 -0.813 -0.684 -0.387 0.207 4.294  || dis=0.93 || select=7/8
016/019-th : 0.032 0.041 0.051 0.071 0.100 0.167 0.226 0.311  ||  -1.093 -0.857 -0.640 -0.298 0.043 0.557 0.858 1.178   || dis=0.08 || select=7/8
017/019-th : 0.087 0.101 0.104 0.128 0.132 0.134 0.153 0.160  ||  -0.340 -0.191 -0.165 0.048 0.075 0.093 0.224 0.269    || dis=0.01 || select=7/8
018/019-th : 0.094 0.116 0.133 0.143 0.124 0.121 0.128 0.141  ||  -0.275 -0.065 0.067 0.138 -0.002 -0.023 0.030 0.126   || dis=0.00 || select=3/8
[epoch=503/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.267
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:09:54] [epoch=503/600][000/098] Time 0.38 (0.38) Data 0.27 (0.27) Loss 1.507 (1.507)  Prec@1 65.62 (65.62) Prec@5 94.92 (94.92) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:10:01] [epoch=503/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.420 (1.761)  Prec@1 62.50 (54.28) Prec@5 90.48 (89.22) Size=[168, 3, 32, 32]
 **VALID** Prec@1 54.28 Prec@5 89.22 Error@1 45.72 Error@5 10.78 Loss:1.761
***[2020-01-29 10:10:01]*** VALID [epoch=503/600] loss = 1.760714, accuracy@1 = 54.28, accuracy@5 = 89.22 | Best-Valid-Acc@1=53.32, Error@1=46.68
Currently, the best validation accuracy found at 503-epoch :: acc@1=54.28, acc@5=89.22, error@1=45.72, error@5=10.78, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:10:01]*** start epoch=504/600 Time Left: [00:51:13], LR=[0.006185 ~ 0.006185], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=504, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.40304863389253476, FLOP=40.81
[Search] : epoch=504/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:10:01] [epoch=504/600][000/098] Time 0.68 (0.68) Data 0.39 (0.39) Base-Loss 0.467 (0.467)  Prec@1 83.98 (83.98) Prec@5 98.44 (98.44) Acls-loss 0.505 (0.505) FLOP-Loss 0.000 (0.000) Arch-Loss 0.505 (0.505)
**TRAIN** [2020-01-29 10:10:27] [epoch=504/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.884 (0.487)  Prec@1 67.26 (83.21) Prec@5 98.81 (99.28) Acls-loss 1.026 (0.617) FLOP-Loss 0.000 (0.000) Arch-Loss 1.026 (0.617)
 **TRAIN** Prec@1 83.21 Prec@5 99.28 Error@1 16.79 Error@5 0.72 Base-Loss:0.487, Arch-Loss=0.617
***[2020-01-29 10:10:28]*** TRAIN [epoch=504/600] base-loss = 0.486683, arch-loss = 0.617468, accuracy-1 = 83.21, accuracy-5 = 99.28
[epoch=504/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 12, 16, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.796096)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.205 0.452 0.343  ||  -0.2342 0.5586 0.2837  || discrepancy=0.11 || select=1/3
001/003-th : 0.320 0.274 0.407  ||  0.0991 -0.0569 0.3392  || discrepancy=0.09 || select=2/3
002/003-th : 0.005 0.029 0.966  ||  -2.3347 -0.6209 2.8783  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.011 0.017 0.019 0.021 0.029 0.042 0.094 0.767  ||  -1.461 -0.995 -0.862 -0.779 -0.464 -0.081 0.714 2.818  || dis=0.67 || select=7/8
001/019-th : 0.090 0.114 0.143 0.133 0.133 0.130 0.143 0.114  ||  -0.313 -0.078 0.154 0.078 0.080 0.060 0.153 -0.074    || dis=0.00 || select=2/8
002/019-th : 0.117 0.123 0.136 0.135 0.127 0.126 0.123 0.112  ||  -0.059 -0.008 0.090 0.085 0.024 0.012 -0.007 -0.108   || dis=0.00 || select=2/8
003/019-th : 0.105 0.118 0.121 0.129 0.130 0.140 0.134 0.123  ||  -0.176 -0.052 -0.034 0.036 0.038 0.119 0.069 -0.010   || dis=0.01 || select=5/8
004/019-th : 0.111 0.109 0.115 0.115 0.134 0.123 0.147 0.147  ||  -0.109 -0.132 -0.072 -0.077 0.076 -0.007 0.171 0.171  || dis=0.00 || select=7/8
005/019-th : 0.127 0.130 0.124 0.126 0.130 0.127 0.119 0.117  ||  0.012 0.042 -0.007 0.007 0.040 0.019 -0.051 -0.069    || dis=0.00 || select=1/8
006/019-th : 0.149 0.138 0.126 0.128 0.118 0.120 0.113 0.109  ||  0.190 0.108 0.018 0.033 -0.046 -0.033 -0.088 -0.128   || dis=0.01 || select=0/8
007/019-th : 0.009 0.013 0.017 0.021 0.035 0.048 0.093 0.765  ||  -1.584 -1.237 -0.912 -0.723 -0.221 0.097 0.766 2.872  || dis=0.67 || select=7/8
008/019-th : 0.009 0.011 0.017 0.027 0.039 0.068 0.173 0.657  ||  -1.674 -1.429 -1.035 -0.567 -0.185 0.361 1.299 2.636  || dis=0.48 || select=7/8
009/019-th : 0.081 0.083 0.094 0.110 0.121 0.133 0.172 0.206  ||  -0.387 -0.357 -0.232 -0.075 0.018 0.111 0.371 0.551   || dis=0.03 || select=7/8
010/019-th : 0.090 0.094 0.104 0.117 0.130 0.152 0.148 0.166  ||  -0.300 -0.260 -0.162 -0.044 0.060 0.217 0.191 0.306   || dis=0.01 || select=7/8
011/019-th : 0.122 0.121 0.116 0.124 0.124 0.132 0.129 0.132  ||  -0.018 -0.028 -0.069 0.001 -0.003 0.061 0.039 0.064   || dis=0.00 || select=7/8
012/019-th : 0.152 0.140 0.128 0.127 0.120 0.114 0.109 0.110  ||  0.201 0.117 0.030 0.021 -0.034 -0.082 -0.128 -0.120   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.012 0.952  ||  -1.144 -0.989 -0.854 -0.749 -0.624 -0.356 -0.044 4.310  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.009 0.014 0.028 0.926  ||  -1.428 -1.272 -1.025 -0.923 -0.614 -0.202 0.485 3.981  || dis=0.90 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.016 0.948  ||  -1.141 -0.922 -0.931 -0.811 -0.678 -0.384 0.205 4.290  || dis=0.93 || select=7/8
016/019-th : 0.032 0.040 0.049 0.069 0.099 0.168 0.227 0.316  ||  -1.092 -0.858 -0.665 -0.322 0.036 0.568 0.870 1.198   || dis=0.09 || select=7/8
017/019-th : 0.085 0.100 0.102 0.127 0.133 0.137 0.155 0.161  ||  -0.363 -0.194 -0.180 0.036 0.084 0.118 0.241 0.276    || dis=0.01 || select=7/8
018/019-th : 0.094 0.116 0.132 0.140 0.124 0.123 0.129 0.142  ||  -0.278 -0.070 0.064 0.118 0.002 -0.009 0.036 0.134    || dis=0.00 || select=7/8
[epoch=504/600] FLOP : 27.80 MB, ratio : 0.6811, Expected-ratio : 0.7000, Discrepancy : 0.269
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:10:28] [epoch=504/600][000/098] Time 0.38 (0.38) Data 0.29 (0.29) Loss 1.341 (1.341)  Prec@1 62.89 (62.89) Prec@5 96.09 (96.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:10:34] [epoch=504/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.321 (1.943)  Prec@1 62.50 (53.01) Prec@5 95.24 (88.28) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.01 Prec@5 88.28 Error@1 46.99 Error@5 11.72 Loss:1.943
***[2020-01-29 10:10:34]*** VALID [epoch=504/600] loss = 1.943223, accuracy@1 = 53.01, accuracy@5 = 88.28 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:10:34]*** start epoch=505/600 Time Left: [00:50:42], LR=[0.006059 ~ 0.006059], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=505, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3968980739781851, FLOP=40.81
[Search] : epoch=505/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:10:35] [epoch=505/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.529 (0.529)  Prec@1 81.64 (81.64) Prec@5 99.22 (99.22) Acls-loss 0.539 (0.539) FLOP-Loss 0.000 (0.000) Arch-Loss 0.539 (0.539)
**TRAIN** [2020-01-29 10:11:01] [epoch=505/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 0.467 (0.488)  Prec@1 83.33 (83.30) Prec@5 99.40 (99.19) Acls-loss 0.559 (0.597) FLOP-Loss 0.000 (0.183) Arch-Loss 0.559 (0.964)
 **TRAIN** Prec@1 83.30 Prec@5 99.19 Error@1 16.70 Error@5 0.81 Base-Loss:0.488, Arch-Loss=0.964
***[2020-01-29 10:11:01]*** TRAIN [epoch=505/600] base-loss = 0.487752, arch-loss = 0.963654, accuracy-1 = 83.30, accuracy-5 = 99.19
[epoch=505/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 8, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.558528)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.202 0.459 0.339  ||  -0.2400 0.5804 0.2764  || discrepancy=0.12 || select=1/3
001/003-th : 0.322 0.276 0.402  ||  0.1071 -0.0481 0.3266  || discrepancy=0.08 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3279 -0.6092 2.8688  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.016 0.019 0.021 0.027 0.041 0.091 0.775  ||  -1.471 -1.002 -0.865 -0.775 -0.503 -0.094 0.713 2.850  || dis=0.68 || select=7/8
001/019-th : 0.089 0.113 0.143 0.132 0.134 0.130 0.143 0.116  ||  -0.321 -0.080 0.150 0.072 0.089 0.054 0.148 -0.056    || dis=0.00 || select=2/8
002/019-th : 0.117 0.125 0.137 0.134 0.129 0.125 0.122 0.111  ||  -0.061 0.004 0.094 0.076 0.034 0.006 -0.016 -0.111    || dis=0.00 || select=2/8
003/019-th : 0.106 0.115 0.122 0.130 0.129 0.139 0.134 0.125  ||  -0.166 -0.078 -0.022 0.038 0.034 0.108 0.074 0.002    || dis=0.01 || select=5/8
004/019-th : 0.111 0.109 0.115 0.113 0.134 0.124 0.148 0.146  ||  -0.109 -0.127 -0.071 -0.088 0.076 0.003 0.176 0.162   || dis=0.00 || select=6/8
005/019-th : 0.128 0.131 0.124 0.126 0.130 0.127 0.118 0.115  ||  0.027 0.049 -0.008 0.008 0.037 0.019 -0.060 -0.084    || dis=0.00 || select=1/8
006/019-th : 0.149 0.144 0.125 0.128 0.119 0.118 0.111 0.107  ||  0.192 0.153 0.016 0.034 -0.039 -0.048 -0.107 -0.144   || dis=0.01 || select=0/8
007/019-th : 0.009 0.013 0.017 0.021 0.034 0.048 0.091 0.767  ||  -1.580 -1.232 -0.925 -0.732 -0.218 0.106 0.756 2.884  || dis=0.68 || select=7/8
008/019-th : 0.008 0.011 0.016 0.026 0.038 0.067 0.169 0.665  ||  -1.704 -1.447 -1.057 -0.564 -0.186 0.376 1.305 2.674  || dis=0.50 || select=7/8
009/019-th : 0.080 0.083 0.095 0.110 0.121 0.133 0.171 0.206  ||  -0.394 -0.360 -0.222 -0.076 0.021 0.116 0.366 0.552   || dis=0.03 || select=7/8
010/019-th : 0.091 0.097 0.105 0.115 0.129 0.152 0.147 0.166  ||  -0.300 -0.234 -0.156 -0.061 0.052 0.216 0.184 0.304   || dis=0.01 || select=7/8
011/019-th : 0.123 0.120 0.116 0.124 0.123 0.130 0.129 0.135  ||  -0.012 -0.032 -0.064 -0.003 -0.007 0.043 0.035 0.086  || dis=0.01 || select=7/8
012/019-th : 0.154 0.139 0.128 0.128 0.121 0.112 0.109 0.110  ||  0.214 0.112 0.033 0.031 -0.026 -0.105 -0.134 -0.123   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.012 0.952  ||  -1.139 -1.005 -0.849 -0.742 -0.643 -0.353 -0.051 4.324  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.009 0.014 0.028 0.926  ||  -1.427 -1.279 -1.017 -0.918 -0.614 -0.186 0.482 3.977  || dis=0.90 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.016 0.948  ||  -1.141 -0.910 -0.925 -0.806 -0.673 -0.381 0.198 4.284  || dis=0.93 || select=7/8
016/019-th : 0.032 0.040 0.048 0.067 0.099 0.168 0.228 0.318  ||  -1.087 -0.854 -0.686 -0.341 0.042 0.570 0.877 1.209   || dis=0.09 || select=7/8
017/019-th : 0.086 0.101 0.102 0.125 0.135 0.138 0.155 0.158  ||  -0.355 -0.188 -0.175 0.022 0.101 0.124 0.236 0.260    || dis=0.00 || select=7/8
018/019-th : 0.094 0.116 0.133 0.139 0.124 0.123 0.128 0.143  ||  -0.275 -0.067 0.067 0.113 -0.000 -0.014 0.029 0.138   || dis=0.00 || select=7/8
[epoch=505/600] FLOP : 27.56 MB, ratio : 0.6752, Expected-ratio : 0.7000, Discrepancy : 0.270
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:11:02] [epoch=505/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 1.877 (1.877)  Prec@1 41.80 (41.80) Prec@5 85.94 (85.94) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:11:08] [epoch=505/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.437 (2.373)  Prec@1 49.40 (47.86) Prec@5 93.45 (84.87) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.86 Prec@5 84.87 Error@1 52.14 Error@5 15.13 Loss:2.373
***[2020-01-29 10:11:08]*** VALID [epoch=505/600] loss = 2.373042, accuracy@1 = 47.86, accuracy@5 = 84.87 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:11:08]*** start epoch=506/600 Time Left: [00:50:10], LR=[0.005935 ~ 0.005935], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=506, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3908065424407692, FLOP=40.81
[Search] : epoch=506/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:11:09] [epoch=506/600][000/098] Time 0.71 (0.71) Data 0.38 (0.38) Base-Loss 0.557 (0.557)  Prec@1 84.77 (84.77) Prec@5 98.05 (98.05) Acls-loss 0.561 (0.561) FLOP-Loss 0.000 (0.000) Arch-Loss 0.561 (0.561)
**TRAIN** [2020-01-29 10:11:35] [epoch=506/600][097/098] Time 0.27 (0.28) Data 0.00 (0.00) Base-Loss 0.435 (0.484)  Prec@1 82.74 (83.69) Prec@5 100.00 (99.12) Acls-loss 1.220 (0.625) FLOP-Loss 0.000 (0.214) Arch-Loss 1.220 (1.053)
 **TRAIN** Prec@1 83.69 Prec@5 99.12 Error@1 16.31 Error@5 0.88 Base-Loss:0.484, Arch-Loss=1.053
***[2020-01-29 10:11:36]*** TRAIN [epoch=506/600] base-loss = 0.484293, arch-loss = 1.052842, accuracy-1 = 83.69, accuracy-5 = 99.12
[epoch=506/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.155968)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.201 0.464 0.334  ||  -0.2402 0.5947 0.2669  || discrepancy=0.13 || select=1/3
001/003-th : 0.324 0.279 0.397  ||  0.1124 -0.0370 0.3160  || discrepancy=0.07 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3224 -0.6070 2.8632  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.017 0.019 0.021 0.027 0.041 0.092 0.774  ||  -1.469 -0.995 -0.856 -0.775 -0.509 -0.094 0.713 2.849  || dis=0.68 || select=7/8
001/019-th : 0.090 0.115 0.141 0.131 0.135 0.130 0.142 0.117  ||  -0.316 -0.072 0.138 0.061 0.092 0.053 0.143 -0.053    || dis=0.00 || select=6/8
002/019-th : 0.118 0.126 0.134 0.136 0.126 0.126 0.122 0.112  ||  -0.054 0.013 0.071 0.089 0.012 0.011 -0.021 -0.103    || dis=0.00 || select=3/8
003/019-th : 0.106 0.116 0.123 0.130 0.128 0.138 0.134 0.125  ||  -0.160 -0.070 -0.018 0.037 0.025 0.103 0.070 -0.001   || dis=0.00 || select=5/8
004/019-th : 0.112 0.110 0.113 0.113 0.134 0.125 0.147 0.145  ||  -0.097 -0.116 -0.089 -0.094 0.074 0.012 0.171 0.157   || dis=0.00 || select=6/8
005/019-th : 0.130 0.132 0.125 0.126 0.129 0.126 0.118 0.113  ||  0.035 0.054 -0.002 0.007 0.035 0.011 -0.054 -0.097    || dis=0.00 || select=1/8
006/019-th : 0.151 0.144 0.126 0.129 0.118 0.117 0.110 0.105  ||  0.203 0.159 0.021 0.044 -0.046 -0.052 -0.113 -0.156   || dis=0.01 || select=0/8
007/019-th : 0.009 0.012 0.017 0.020 0.034 0.046 0.089 0.774  ||  -1.576 -1.222 -0.937 -0.754 -0.220 0.088 0.747 2.909  || dis=0.69 || select=7/8
008/019-th : 0.008 0.011 0.016 0.026 0.038 0.065 0.167 0.669  ||  -1.705 -1.439 -1.056 -0.567 -0.194 0.353 1.301 2.686  || dis=0.50 || select=7/8
009/019-th : 0.081 0.084 0.096 0.111 0.121 0.132 0.170 0.205  ||  -0.385 -0.354 -0.218 -0.073 0.018 0.106 0.360 0.545   || dis=0.03 || select=7/8
010/019-th : 0.092 0.098 0.106 0.115 0.129 0.151 0.145 0.165  ||  -0.289 -0.225 -0.144 -0.063 0.051 0.209 0.172 0.297   || dis=0.01 || select=7/8
011/019-th : 0.124 0.120 0.118 0.121 0.123 0.131 0.128 0.135  ||  -0.003 -0.032 -0.051 -0.022 -0.007 0.053 0.035 0.081  || dis=0.00 || select=7/8
012/019-th : 0.155 0.140 0.129 0.126 0.121 0.112 0.108 0.109  ||  0.224 0.120 0.037 0.018 -0.028 -0.104 -0.136 -0.132   || dis=0.01 || select=0/8
013/019-th : 0.004 0.005 0.005 0.006 0.006 0.009 0.011 0.955  ||  -1.134 -1.000 -0.844 -0.771 -0.679 -0.359 -0.072 4.357  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.009 0.014 0.027 0.927  ||  -1.422 -1.281 -1.011 -0.914 -0.628 -0.186 0.467 3.986  || dis=0.90 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.016 0.948  ||  -1.135 -0.902 -0.918 -0.829 -0.666 -0.380 0.196 4.286  || dis=0.93 || select=7/8
016/019-th : 0.031 0.040 0.047 0.067 0.098 0.168 0.233 0.316  ||  -1.119 -0.858 -0.697 -0.339 0.038 0.582 0.909 1.214   || dis=0.08 || select=7/8
017/019-th : 0.086 0.104 0.102 0.124 0.137 0.137 0.155 0.156  ||  -0.350 -0.165 -0.179 0.011 0.111 0.117 0.238 0.242    || dis=0.00 || select=7/8
018/019-th : 0.095 0.113 0.133 0.138 0.126 0.122 0.131 0.141  ||  -0.267 -0.091 0.071 0.104 0.018 -0.014 0.055 0.127    || dis=0.00 || select=7/8
[epoch=506/600] FLOP : 29.16 MB, ratio : 0.7144, Expected-ratio : 0.7000, Discrepancy : 0.271
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:11:36] [epoch=506/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 2.103 (2.103)  Prec@1 25.00 (25.00) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:11:43] [epoch=506/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.827 (2.425)  Prec@1 72.62 (47.30) Prec@5 97.02 (84.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 47.30 Prec@5 84.42 Error@1 52.70 Error@5 15.58 Loss:2.425
***[2020-01-29 10:11:43]*** VALID [epoch=506/600] loss = 2.425440, accuracy@1 = 47.30, accuracy@5 = 84.42 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:11:43]*** start epoch=507/600 Time Left: [00:49:38], LR=[0.005812 ~ 0.005812], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=507, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.384774206282701, FLOP=40.81
[Search] : epoch=507/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:11:43] [epoch=507/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.364 (0.364)  Prec@1 88.67 (88.67) Prec@5 100.00 (100.00) Acls-loss 0.628 (0.628) FLOP-Loss 2.984 (2.984) Arch-Loss 6.596 (6.596)
**TRAIN** [2020-01-29 10:12:10] [epoch=507/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.408 (0.438)  Prec@1 87.50 (85.20) Prec@5 98.81 (99.44) Acls-loss 0.503 (0.580) FLOP-Loss 0.000 (0.214) Arch-Loss 0.503 (1.008)
 **TRAIN** Prec@1 85.20 Prec@5 99.44 Error@1 14.80 Error@5 0.56 Base-Loss:0.438, Arch-Loss=1.008
***[2020-01-29 10:12:10]*** TRAIN [epoch=507/600] base-loss = 0.437660, arch-loss = 1.007923, accuracy-1 = 85.20, accuracy-5 = 99.44
[epoch=507/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.257472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.199 0.468 0.333  ||  -0.2466 0.6066 0.2647  || discrepancy=0.14 || select=1/3
001/003-th : 0.323 0.284 0.392  ||  0.1133 -0.0160 0.3066  || discrepancy=0.07 || select=2/3
002/003-th : 0.005 0.030 0.964  ||  -2.3151 -0.6058 2.8560  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.016 0.019 0.020 0.027 0.039 0.088 0.782  ||  -1.461 -0.999 -0.863 -0.791 -0.497 -0.133 0.693 2.878  || dis=0.69 || select=7/8
001/019-th : 0.089 0.114 0.143 0.134 0.134 0.128 0.142 0.116  ||  -0.321 -0.073 0.149 0.087 0.084 0.037 0.144 -0.058    || dis=0.00 || select=2/8
002/019-th : 0.119 0.127 0.134 0.136 0.126 0.126 0.122 0.111  ||  -0.049 0.022 0.077 0.085 0.008 0.009 -0.024 -0.111    || dis=0.00 || select=3/8
003/019-th : 0.108 0.117 0.124 0.128 0.129 0.138 0.133 0.125  ||  -0.149 -0.068 -0.011 0.024 0.029 0.099 0.059 -0.001   || dis=0.01 || select=5/8
004/019-th : 0.112 0.110 0.115 0.112 0.133 0.125 0.147 0.144  ||  -0.100 -0.116 -0.074 -0.100 0.073 0.012 0.172 0.154   || dis=0.00 || select=6/8
005/019-th : 0.130 0.136 0.125 0.126 0.128 0.127 0.116 0.113  ||  0.037 0.082 -0.002 0.010 0.026 0.013 -0.075 -0.103    || dis=0.01 || select=1/8
006/019-th : 0.151 0.144 0.125 0.130 0.117 0.118 0.110 0.105  ||  0.202 0.158 0.016 0.053 -0.051 -0.046 -0.111 -0.161   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.016 0.019 0.033 0.045 0.086 0.779  ||  -1.590 -1.213 -0.938 -0.767 -0.234 0.091 0.733 2.933  || dis=0.69 || select=7/8
008/019-th : 0.008 0.011 0.016 0.026 0.037 0.064 0.165 0.674  ||  -1.702 -1.431 -1.047 -0.568 -0.211 0.340 1.287 2.695  || dis=0.51 || select=7/8
009/019-th : 0.082 0.084 0.095 0.112 0.121 0.132 0.170 0.203  ||  -0.375 -0.346 -0.225 -0.061 0.019 0.102 0.357 0.532   || dis=0.03 || select=7/8
010/019-th : 0.092 0.099 0.106 0.114 0.127 0.153 0.144 0.164  ||  -0.285 -0.212 -0.145 -0.069 0.036 0.221 0.164 0.294   || dis=0.01 || select=7/8
011/019-th : 0.125 0.121 0.118 0.121 0.123 0.129 0.128 0.134  ||  0.006 -0.022 -0.048 -0.021 -0.011 0.041 0.035 0.078   || dis=0.01 || select=7/8
012/019-th : 0.155 0.141 0.129 0.127 0.121 0.112 0.108 0.108  ||  0.225 0.128 0.038 0.021 -0.024 -0.104 -0.143 -0.138   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.005 0.006 0.006 0.009 0.011 0.955  ||  -1.143 -1.011 -0.839 -0.764 -0.677 -0.355 -0.075 4.362  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.009 0.014 0.027 0.927  ||  -1.419 -1.293 -1.004 -0.909 -0.625 -0.185 0.464 3.994  || dis=0.90 || select=7/8
015/019-th : 0.004 0.005 0.005 0.006 0.007 0.009 0.015 0.949  ||  -1.128 -0.897 -0.912 -0.839 -0.678 -0.391 0.180 4.301  || dis=0.93 || select=7/8
016/019-th : 0.031 0.039 0.047 0.066 0.098 0.167 0.231 0.321  ||  -1.106 -0.867 -0.702 -0.355 0.045 0.577 0.901 1.229   || dis=0.09 || select=7/8
017/019-th : 0.087 0.104 0.102 0.121 0.137 0.140 0.154 0.154  ||  -0.340 -0.160 -0.178 -0.008 0.115 0.135 0.233 0.232   || dis=0.00 || select=6/8
018/019-th : 0.095 0.111 0.135 0.138 0.126 0.122 0.131 0.142  ||  -0.263 -0.110 0.082 0.104 0.016 -0.017 0.057 0.136    || dis=0.00 || select=7/8
[epoch=507/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.272
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:12:11] [epoch=507/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.574 (1.574)  Prec@1 53.52 (53.52) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:12:17] [epoch=507/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.410 (1.920)  Prec@1 36.90 (51.12) Prec@5 82.74 (85.88) Size=[168, 3, 32, 32]
 **VALID** Prec@1 51.12 Prec@5 85.88 Error@1 48.88 Error@5 14.12 Loss:1.920
***[2020-01-29 10:12:17]*** VALID [epoch=507/600] loss = 1.919591, accuracy@1 = 51.12, accuracy@5 = 85.88 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:12:18]*** start epoch=508/600 Time Left: [00:49:07], LR=[0.005690 ~ 0.005690], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=508, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3788012308835239, FLOP=40.81
[Search] : epoch=508/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:12:18] [epoch=508/600][000/098] Time 0.74 (0.74) Data 0.42 (0.42) Base-Loss 0.358 (0.358)  Prec@1 87.11 (87.11) Prec@5 100.00 (100.00) Acls-loss 0.558 (0.558) FLOP-Loss 0.000 (0.000) Arch-Loss 0.558 (0.558)
**TRAIN** [2020-01-29 10:12:44] [epoch=508/600][097/098] Time 0.28 (0.27) Data 0.00 (0.00) Base-Loss 0.416 (0.481)  Prec@1 86.31 (83.55) Prec@5 100.00 (99.11) Acls-loss 0.618 (0.581) FLOP-Loss 0.000 (0.153) Arch-Loss 0.618 (0.886)
 **TRAIN** Prec@1 83.55 Prec@5 99.11 Error@1 16.45 Error@5 0.89 Base-Loss:0.481, Arch-Loss=0.886
***[2020-01-29 10:12:44]*** TRAIN [epoch=508/600] base-loss = 0.481342, arch-loss = 0.886189, accuracy-1 = 83.55, accuracy-5 = 99.11
[epoch=508/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.257472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.199 0.471 0.331  ||  -0.2488 0.6132 0.2604  || discrepancy=0.14 || select=1/3
001/003-th : 0.327 0.283 0.390  ||  0.1225 -0.0214 0.2972  || discrepancy=0.06 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3087 -0.6046 2.8497  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.016 0.019 0.020 0.026 0.038 0.085 0.787  ||  -1.474 -1.006 -0.851 -0.791 -0.504 -0.134 0.680 2.899  || dis=0.70 || select=7/8
001/019-th : 0.090 0.115 0.143 0.133 0.134 0.126 0.143 0.116  ||  -0.312 -0.067 0.147 0.073 0.087 0.022 0.146 -0.059    || dis=0.00 || select=2/8
002/019-th : 0.117 0.128 0.134 0.137 0.125 0.126 0.121 0.111  ||  -0.057 0.030 0.077 0.097 0.004 0.015 -0.031 -0.115    || dis=0.00 || select=3/8
003/019-th : 0.109 0.117 0.123 0.128 0.128 0.139 0.131 0.125  ||  -0.139 -0.068 -0.017 0.024 0.026 0.105 0.050 -0.001   || dis=0.01 || select=5/8
004/019-th : 0.113 0.110 0.115 0.110 0.132 0.126 0.148 0.145  ||  -0.094 -0.116 -0.078 -0.115 0.066 0.015 0.180 0.155   || dis=0.00 || select=6/8
005/019-th : 0.130 0.135 0.125 0.126 0.127 0.126 0.116 0.113  ||  0.042 0.078 0.002 0.008 0.019 0.011 -0.075 -0.099     || dis=0.01 || select=1/8
006/019-th : 0.152 0.144 0.125 0.128 0.118 0.117 0.111 0.105  ||  0.207 0.154 0.014 0.035 -0.041 -0.051 -0.109 -0.157   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.016 0.019 0.031 0.044 0.083 0.786  ||  -1.582 -1.201 -0.947 -0.772 -0.261 0.080 0.714 2.959  || dis=0.70 || select=7/8
008/019-th : 0.008 0.011 0.016 0.025 0.036 0.061 0.160 0.684  ||  -1.726 -1.427 -1.043 -0.569 -0.223 0.319 1.278 2.731  || dis=0.52 || select=7/8
009/019-th : 0.083 0.084 0.096 0.111 0.120 0.133 0.169 0.204  ||  -0.366 -0.347 -0.221 -0.071 0.010 0.110 0.348 0.537   || dis=0.03 || select=7/8
010/019-th : 0.092 0.099 0.107 0.115 0.126 0.151 0.147 0.164  ||  -0.290 -0.209 -0.138 -0.067 0.028 0.210 0.181 0.292   || dis=0.01 || select=7/8
011/019-th : 0.126 0.122 0.118 0.122 0.123 0.130 0.128 0.132  ||  0.013 -0.019 -0.047 -0.018 -0.007 0.043 0.029 0.064   || dis=0.00 || select=7/8
012/019-th : 0.155 0.142 0.129 0.125 0.122 0.112 0.107 0.108  ||  0.224 0.137 0.036 0.009 -0.020 -0.104 -0.144 -0.139   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.005 0.006 0.006 0.009 0.011 0.954  ||  -1.139 -1.006 -0.833 -0.759 -0.674 -0.356 -0.075 4.355  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.009 0.014 0.027 0.928  ||  -1.434 -1.290 -0.995 -0.904 -0.621 -0.199 0.462 4.003  || dis=0.90 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.015 0.951  ||  -1.138 -0.891 -0.905 -0.834 -0.674 -0.413 0.156 4.319  || dis=0.94 || select=7/8
016/019-th : 0.031 0.037 0.045 0.065 0.098 0.166 0.236 0.322  ||  -1.101 -0.907 -0.734 -0.355 0.055 0.581 0.932 1.242   || dis=0.09 || select=7/8
017/019-th : 0.088 0.105 0.103 0.119 0.136 0.141 0.155 0.154  ||  -0.332 -0.157 -0.174 -0.027 0.110 0.142 0.236 0.229   || dis=0.00 || select=6/8
018/019-th : 0.095 0.109 0.134 0.136 0.127 0.124 0.131 0.143  ||  -0.264 -0.124 0.079 0.094 0.027 -0.003 0.056 0.145    || dis=0.01 || select=7/8
[epoch=508/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.274
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:12:45] [epoch=508/600][000/098] Time 0.42 (0.42) Data 0.31 (0.31) Loss 3.613 (3.613)  Prec@1 26.17 (26.17) Prec@5 71.88 (71.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:12:52] [epoch=508/600][097/098] Time 0.15 (0.07) Data 0.00 (0.00) Loss 3.637 (1.869)  Prec@1 13.69 (53.41) Prec@5 61.31 (87.55) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.41 Prec@5 87.55 Error@1 46.59 Error@5 12.45 Loss:1.869
***[2020-01-29 10:12:52]*** VALID [epoch=508/600] loss = 1.869429, accuracy@1 = 53.41, accuracy@5 = 87.55 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:12:52]*** start epoch=509/600 Time Left: [00:48:35], LR=[0.005569 ~ 0.005569], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=509, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.37288777999537503, FLOP=40.81
[Search] : epoch=509/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:12:53] [epoch=509/600][000/098] Time 0.70 (0.70) Data 0.38 (0.38) Base-Loss 0.372 (0.372)  Prec@1 85.55 (85.55) Prec@5 99.61 (99.61) Acls-loss 0.885 (0.885) FLOP-Loss 0.000 (0.000) Arch-Loss 0.885 (0.885)
**TRAIN** [2020-01-29 10:13:19] [epoch=509/600][097/098] Time 0.27 (0.28) Data 0.00 (0.00) Base-Loss 0.733 (0.435)  Prec@1 76.79 (85.22) Prec@5 98.81 (99.40) Acls-loss 0.603 (0.609) FLOP-Loss 0.000 (0.275) Arch-Loss 0.603 (1.158)
 **TRAIN** Prec@1 85.22 Prec@5 99.40 Error@1 14.78 Error@5 0.60 Base-Loss:0.435, Arch-Loss=1.158
***[2020-01-29 10:13:20]*** TRAIN [epoch=509/600] base-loss = 0.434583, arch-loss = 1.158463, accuracy-1 = 85.22, accuracy-5 = 99.40
[epoch=509/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 8, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.257472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.199 0.476 0.326  ||  -0.2462 0.6266 0.2483  || discrepancy=0.15 || select=1/3
001/003-th : 0.330 0.283 0.387  ||  0.1298 -0.0226 0.2883  || discrepancy=0.06 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.2999 -0.6191 2.8465  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.016 0.019 0.020 0.026 0.037 0.084 0.789  ||  -1.467 -1.003 -0.846 -0.787 -0.508 -0.142 0.664 2.905  || dis=0.71 || select=7/8
001/019-th : 0.090 0.116 0.142 0.134 0.134 0.126 0.142 0.115  ||  -0.314 -0.059 0.144 0.082 0.085 0.021 0.142 -0.066    || dis=0.00 || select=2/8
002/019-th : 0.118 0.127 0.135 0.138 0.128 0.126 0.119 0.110  ||  -0.052 0.022 0.085 0.104 0.026 0.009 -0.045 -0.127    || dis=0.00 || select=3/8
003/019-th : 0.110 0.118 0.125 0.126 0.128 0.138 0.133 0.122  ||  -0.128 -0.055 -0.004 0.009 0.021 0.095 0.062 -0.023   || dis=0.01 || select=5/8
004/019-th : 0.113 0.109 0.116 0.112 0.133 0.127 0.147 0.143  ||  -0.090 -0.129 -0.065 -0.098 0.069 0.024 0.174 0.144   || dis=0.00 || select=6/8
005/019-th : 0.132 0.137 0.125 0.126 0.127 0.125 0.116 0.111  ||  0.053 0.092 0.002 0.008 0.016 0.004 -0.076 -0.115     || dis=0.01 || select=1/8
006/019-th : 0.153 0.145 0.126 0.128 0.117 0.116 0.109 0.105  ||  0.220 0.165 0.025 0.040 -0.052 -0.062 -0.118 -0.164   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.016 0.019 0.031 0.044 0.082 0.788  ||  -1.577 -1.207 -0.950 -0.767 -0.260 0.074 0.707 2.966  || dis=0.71 || select=7/8
008/019-th : 0.008 0.011 0.015 0.025 0.035 0.060 0.160 0.685  ||  -1.721 -1.430 -1.052 -0.576 -0.224 0.307 1.285 2.737  || dis=0.53 || select=7/8
009/019-th : 0.084 0.085 0.096 0.111 0.120 0.134 0.165 0.205  ||  -0.350 -0.342 -0.219 -0.070 0.006 0.112 0.326 0.539   || dis=0.04 || select=7/8
010/019-th : 0.090 0.099 0.107 0.114 0.126 0.152 0.151 0.162  ||  -0.301 -0.211 -0.137 -0.070 0.027 0.218 0.208 0.279   || dis=0.01 || select=7/8
011/019-th : 0.128 0.121 0.120 0.120 0.122 0.131 0.127 0.131  ||  0.030 -0.021 -0.028 -0.035 -0.012 0.054 0.023 0.056   || dis=0.00 || select=7/8
012/019-th : 0.157 0.145 0.127 0.125 0.121 0.111 0.108 0.107  ||  0.234 0.157 0.024 0.005 -0.027 -0.113 -0.139 -0.144   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.005 0.005 0.006 0.009 0.011 0.956  ||  -1.133 -1.023 -0.876 -0.779 -0.671 -0.333 -0.078 4.383  || dis=0.94 || select=7/8
014/019-th : 0.004 0.005 0.006 0.007 0.009 0.014 0.026 0.929  ||  -1.429 -1.301 -0.985 -0.899 -0.618 -0.213 0.456 4.017  || dis=0.90 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.015 0.951  ||  -1.131 -0.878 -0.898 -0.833 -0.670 -0.430 0.154 4.320  || dis=0.94 || select=7/8
016/019-th : 0.030 0.038 0.044 0.064 0.098 0.166 0.237 0.323  ||  -1.116 -0.901 -0.739 -0.362 0.059 0.584 0.939 1.249   || dis=0.09 || select=7/8
017/019-th : 0.089 0.106 0.103 0.119 0.137 0.140 0.155 0.151  ||  -0.317 -0.145 -0.176 -0.030 0.114 0.136 0.237 0.211   || dis=0.00 || select=6/8
018/019-th : 0.095 0.111 0.133 0.136 0.128 0.123 0.130 0.143  ||  -0.262 -0.114 0.073 0.096 0.029 -0.010 0.049 0.145    || dis=0.01 || select=7/8
[epoch=509/600] FLOP : 27.26 MB, ratio : 0.6679, Expected-ratio : 0.7000, Discrepancy : 0.275
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:13:20] [epoch=509/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 0.964 (0.964)  Prec@1 64.06 (64.06) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:13:26] [epoch=509/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.026 (2.050)  Prec@1 69.05 (49.62) Prec@5 96.43 (87.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.62 Prec@5 87.20 Error@1 50.38 Error@5 12.80 Loss:2.050
***[2020-01-29 10:13:27]*** VALID [epoch=509/600] loss = 2.049595, accuracy@1 = 49.62, accuracy@5 = 87.20 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:13:27]*** start epoch=510/600 Time Left: [00:48:04], LR=[0.005450 ~ 0.005450], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=510, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3670340157384989, FLOP=40.81
[Search] : epoch=510/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:13:27] [epoch=510/600][000/098] Time 0.69 (0.69) Data 0.38 (0.38) Base-Loss 0.436 (0.436)  Prec@1 85.94 (85.94) Prec@5 98.83 (98.83) Acls-loss 0.647 (0.647) FLOP-Loss 0.000 (0.000) Arch-Loss 0.647 (0.647)
**TRAIN** [2020-01-29 10:13:54] [epoch=510/600][097/098] Time 0.27 (0.28) Data 0.00 (0.00) Base-Loss 0.383 (0.432)  Prec@1 85.71 (85.26) Prec@5 99.40 (99.34) Acls-loss 0.410 (0.571) FLOP-Loss 0.000 (0.153) Arch-Loss 0.410 (0.876)
 **TRAIN** Prec@1 85.26 Prec@5 99.34 Error@1 14.74 Error@5 0.66 Base-Loss:0.432, Arch-Loss=0.876
***[2020-01-29 10:13:54]*** TRAIN [epoch=510/600] base-loss = 0.431827, arch-loss = 0.876242, accuracy-1 = 85.26, accuracy-5 = 99.34
[epoch=510/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.978624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.196 0.482 0.322  ||  -0.2525 0.6467 0.2419  || discrepancy=0.16 || select=1/3
001/003-th : 0.332 0.283 0.385  ||  0.1355 -0.0273 0.2823  || discrepancy=0.05 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.2930 -0.6079 2.8365  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.016 0.019 0.020 0.025 0.037 0.082 0.792  ||  -1.479 -0.993 -0.836 -0.780 -0.519 -0.146 0.651 2.920  || dis=0.71 || select=7/8
001/019-th : 0.091 0.116 0.142 0.134 0.135 0.125 0.142 0.116  ||  -0.308 -0.064 0.140 0.082 0.088 0.017 0.140 -0.060    || dis=0.00 || select=6/8
002/019-th : 0.118 0.125 0.134 0.139 0.128 0.124 0.121 0.109  ||  -0.049 0.009 0.078 0.113 0.026 0.001 -0.027 -0.129    || dis=0.01 || select=3/8
003/019-th : 0.111 0.119 0.125 0.126 0.127 0.137 0.133 0.123  ||  -0.124 -0.049 -0.001 0.003 0.012 0.088 0.061 -0.019   || dis=0.00 || select=5/8
004/019-th : 0.113 0.108 0.116 0.112 0.131 0.128 0.147 0.145  ||  -0.091 -0.139 -0.069 -0.098 0.056 0.034 0.173 0.161   || dis=0.00 || select=6/8
005/019-th : 0.133 0.136 0.126 0.127 0.128 0.125 0.115 0.110  ||  0.062 0.082 0.009 0.012 0.024 0.003 -0.080 -0.128     || dis=0.00 || select=1/8
006/019-th : 0.151 0.147 0.127 0.127 0.117 0.116 0.111 0.104  ||  0.206 0.173 0.028 0.031 -0.056 -0.057 -0.101 -0.172   || dis=0.00 || select=0/8
007/019-th : 0.008 0.012 0.016 0.019 0.031 0.043 0.081 0.790  ||  -1.569 -1.201 -0.945 -0.776 -0.263 0.068 0.691 2.974  || dis=0.71 || select=7/8
008/019-th : 0.008 0.011 0.015 0.024 0.035 0.059 0.158 0.689  ||  -1.725 -1.430 -1.044 -0.591 -0.223 0.297 1.279 2.751  || dis=0.53 || select=7/8
009/019-th : 0.084 0.085 0.096 0.113 0.121 0.133 0.165 0.203  ||  -0.349 -0.340 -0.215 -0.059 0.009 0.109 0.320 0.532   || dis=0.04 || select=7/8
010/019-th : 0.092 0.100 0.107 0.114 0.126 0.151 0.150 0.159  ||  -0.284 -0.202 -0.132 -0.070 0.030 0.209 0.204 0.261   || dis=0.01 || select=7/8
011/019-th : 0.128 0.122 0.120 0.120 0.122 0.130 0.128 0.130  ||  0.036 -0.014 -0.028 -0.031 -0.015 0.046 0.030 0.045   || dis=0.00 || select=5/8
012/019-th : 0.159 0.145 0.128 0.125 0.121 0.110 0.108 0.105  ||  0.250 0.157 0.032 0.007 -0.026 -0.121 -0.137 -0.163   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.005 0.005 0.006 0.008 0.011 0.957  ||  -1.128 -1.022 -0.872 -0.775 -0.693 -0.330 -0.104 4.402  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.007 0.009 0.013 0.026 0.931  ||  -1.423 -1.310 -0.975 -0.896 -0.631 -0.224 0.453 4.031  || dis=0.91 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.015 0.951  ||  -1.125 -0.864 -0.891 -0.844 -0.686 -0.438 0.166 4.325  || dis=0.94 || select=7/8
016/019-th : 0.031 0.037 0.044 0.064 0.098 0.164 0.240 0.322  ||  -1.103 -0.911 -0.747 -0.361 0.055 0.576 0.955 1.249   || dis=0.08 || select=7/8
017/019-th : 0.089 0.106 0.103 0.119 0.138 0.141 0.155 0.150  ||  -0.316 -0.143 -0.176 -0.028 0.117 0.139 0.235 0.204   || dis=0.01 || select=6/8
018/019-th : 0.095 0.110 0.134 0.136 0.128 0.123 0.130 0.145  ||  -0.266 -0.124 0.076 0.093 0.034 -0.007 0.046 0.155    || dis=0.01 || select=7/8
[epoch=510/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.275
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:13:55] [epoch=510/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 2.228 (2.228)  Prec@1 22.27 (22.27) Prec@5 65.62 (65.62) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:14:01] [epoch=510/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.647 (2.164)  Prec@1 80.36 (48.02) Prec@5 98.81 (85.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 48.02 Prec@5 85.16 Error@1 51.98 Error@5 14.84 Loss:2.164
***[2020-01-29 10:14:01]*** VALID [epoch=510/600] loss = 2.163634, accuracy@1 = 48.02, accuracy@5 = 85.16 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:14:01]*** start epoch=511/600 Time Left: [00:47:32], LR=[0.005331 ~ 0.005331], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=511, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.36124009859679795, FLOP=40.81
[Search] : epoch=511/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:14:02] [epoch=511/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 0.441 (0.441)  Prec@1 85.94 (85.94) Prec@5 99.61 (99.61) Acls-loss 0.472 (0.472) FLOP-Loss 0.000 (0.000) Arch-Loss 0.472 (0.472)
**TRAIN** [2020-01-29 10:14:30] [epoch=511/600][097/098] Time 0.29 (0.29) Data 0.00 (0.00) Base-Loss 0.517 (0.456)  Prec@1 81.55 (84.30) Prec@5 97.62 (99.25) Acls-loss 0.492 (0.605) FLOP-Loss 0.000 (0.031) Arch-Loss 0.492 (0.666)
 **TRAIN** Prec@1 84.30 Prec@5 99.25 Error@1 15.70 Error@5 0.75 Base-Loss:0.456, Arch-Loss=0.666
***[2020-01-29 10:14:30]*** TRAIN [epoch=511/600] base-loss = 0.455649, arch-loss = 0.666018, accuracy-1 = 84.30, accuracy-5 = 99.25
[epoch=511/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.49472)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.193 0.486 0.320  ||  -0.2637 0.6603 0.2429  || discrepancy=0.17 || select=1/3
001/003-th : 0.330 0.285 0.386  ||  0.1283 -0.0181 0.2852  || discrepancy=0.06 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3324 -0.6051 2.8740  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.016 0.019 0.019 0.026 0.037 0.080 0.794  ||  -1.484 -0.996 -0.828 -0.797 -0.495 -0.146 0.636 2.929  || dis=0.71 || select=7/8
001/019-th : 0.090 0.115 0.141 0.134 0.133 0.124 0.144 0.119  ||  -0.313 -0.071 0.133 0.079 0.074 0.007 0.157 -0.040    || dis=0.00 || select=6/8
002/019-th : 0.116 0.124 0.134 0.139 0.128 0.125 0.122 0.111  ||  -0.067 0.000 0.072 0.113 0.029 0.008 -0.015 -0.112    || dis=0.01 || select=3/8
003/019-th : 0.111 0.119 0.126 0.126 0.126 0.136 0.133 0.123  ||  -0.122 -0.050 0.005 0.008 0.004 0.084 0.058 -0.017    || dis=0.00 || select=5/8
004/019-th : 0.114 0.107 0.115 0.112 0.130 0.129 0.146 0.146  ||  -0.081 -0.145 -0.073 -0.101 0.053 0.039 0.167 0.166   || dis=0.00 || select=6/8
005/019-th : 0.132 0.135 0.126 0.126 0.126 0.126 0.117 0.112  ||  0.054 0.078 0.006 0.009 0.009 0.011 -0.070 -0.112     || dis=0.00 || select=1/8
006/019-th : 0.151 0.145 0.126 0.128 0.117 0.117 0.111 0.104  ||  0.201 0.164 0.023 0.037 -0.053 -0.054 -0.101 -0.167   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.016 0.018 0.031 0.042 0.080 0.794  ||  -1.564 -1.200 -0.940 -0.787 -0.269 0.041 0.690 2.988  || dis=0.71 || select=7/8
008/019-th : 0.008 0.010 0.015 0.024 0.035 0.058 0.154 0.696  ||  -1.720 -1.440 -1.053 -0.598 -0.228 0.287 1.264 2.771  || dis=0.54 || select=7/8
009/019-th : 0.085 0.085 0.094 0.112 0.119 0.135 0.164 0.205  ||  -0.341 -0.336 -0.238 -0.064 -0.002 0.124 0.319 0.542  || dis=0.04 || select=7/8
010/019-th : 0.092 0.098 0.107 0.114 0.125 0.152 0.151 0.159  ||  -0.280 -0.219 -0.137 -0.068 0.022 0.218 0.213 0.262   || dis=0.01 || select=7/8
011/019-th : 0.128 0.122 0.121 0.118 0.124 0.130 0.128 0.129  ||  0.035 -0.016 -0.025 -0.047 0.005 0.046 0.032 0.043    || dis=0.00 || select=5/8
012/019-th : 0.158 0.144 0.126 0.125 0.122 0.110 0.109 0.106  ||  0.240 0.151 0.020 0.008 -0.020 -0.118 -0.128 -0.155   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.005 0.005 0.006 0.008 0.011 0.957  ||  -1.121 -1.018 -0.871 -0.777 -0.691 -0.330 -0.102 4.398  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.007 0.009 0.013 0.025 0.932  ||  -1.418 -1.306 -0.965 -0.914 -0.630 -0.226 0.436 4.043  || dis=0.91 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.015 0.951  ||  -1.147 -0.850 -0.897 -0.839 -0.683 -0.437 0.157 4.337  || dis=0.94 || select=7/8
016/019-th : 0.031 0.037 0.043 0.065 0.097 0.162 0.240 0.325  ||  -1.096 -0.915 -0.755 -0.353 0.052 0.561 0.957 1.259   || dis=0.09 || select=7/8
017/019-th : 0.086 0.104 0.104 0.119 0.137 0.144 0.152 0.154  ||  -0.350 -0.159 -0.162 -0.029 0.118 0.164 0.222 0.231   || dis=0.00 || select=7/8
018/019-th : 0.095 0.108 0.132 0.134 0.129 0.124 0.130 0.148  ||  -0.270 -0.135 0.065 0.082 0.039 -0.001 0.048 0.175    || dis=0.01 || select=7/8
[epoch=511/600] FLOP : 28.49 MB, ratio : 0.6982, Expected-ratio : 0.7000, Discrepancy : 0.277
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:14:30] [epoch=511/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.907 (0.907)  Prec@1 73.44 (73.44) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:14:36] [epoch=511/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 1.544 (1.926)  Prec@1 45.83 (53.12) Prec@5 89.29 (88.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.12 Prec@5 88.21 Error@1 46.88 Error@5 11.79 Loss:1.926
***[2020-01-29 10:14:36]*** VALID [epoch=511/600] loss = 1.925942, accuracy@1 = 53.12, accuracy@5 = 88.21 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:14:36]*** start epoch=512/600 Time Left: [00:47:01], LR=[0.005214 ~ 0.005214], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=512, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3555061874134384, FLOP=40.81
[Search] : epoch=512/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:14:37] [epoch=512/600][000/098] Time 0.68 (0.68) Data 0.37 (0.37) Base-Loss 0.413 (0.413)  Prec@1 87.89 (87.89) Prec@5 99.61 (99.61) Acls-loss 0.946 (0.946) FLOP-Loss 0.000 (0.000) Arch-Loss 0.946 (0.946)
**TRAIN** [2020-01-29 10:15:04] [epoch=512/600][097/098] Time 0.25 (0.28) Data 0.00 (0.00) Base-Loss 0.330 (0.463)  Prec@1 88.10 (84.36) Prec@5 100.00 (99.27) Acls-loss 0.530 (0.620) FLOP-Loss 0.000 (0.153) Arch-Loss 0.530 (0.926)
 **TRAIN** Prec@1 84.36 Prec@5 99.27 Error@1 15.64 Error@5 0.73 Base-Loss:0.463, Arch-Loss=0.926
***[2020-01-29 10:15:04]*** TRAIN [epoch=512/600] base-loss = 0.462580, arch-loss = 0.925596, accuracy-1 = 84.36, accuracy-5 = 99.27
[epoch=512/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 16, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.21824)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.190 0.498 0.313  ||  -0.2704 0.6955 0.2297  || discrepancy=0.18 || select=1/3
001/003-th : 0.333 0.282 0.384  ||  0.1364 -0.0290 0.2787  || discrepancy=0.05 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3482 -0.5959 2.8875  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.015 0.019 0.019 0.026 0.036 0.078 0.797  ||  -1.476 -1.013 -0.818 -0.794 -0.499 -0.146 0.620 2.939  || dis=0.72 || select=7/8
001/019-th : 0.090 0.113 0.141 0.136 0.133 0.125 0.143 0.118  ||  -0.316 -0.083 0.135 0.096 0.080 0.018 0.152 -0.043    || dis=0.00 || select=6/8
002/019-th : 0.118 0.125 0.133 0.139 0.126 0.126 0.123 0.111  ||  -0.056 0.002 0.067 0.114 0.015 0.010 -0.014 -0.113    || dis=0.01 || select=3/8
003/019-th : 0.112 0.119 0.126 0.126 0.127 0.136 0.132 0.122  ||  -0.114 -0.049 0.007 0.010 0.012 0.082 0.055 -0.029    || dis=0.00 || select=5/8
004/019-th : 0.115 0.107 0.117 0.113 0.131 0.126 0.146 0.146  ||  -0.071 -0.144 -0.060 -0.094 0.053 0.016 0.162 0.167   || dis=0.00 || select=7/8
005/019-th : 0.133 0.136 0.127 0.126 0.125 0.127 0.115 0.111  ||  0.063 0.087 0.016 0.008 0.001 0.014 -0.084 -0.121     || dis=0.00 || select=1/8
006/019-th : 0.153 0.144 0.127 0.126 0.117 0.117 0.113 0.104  ||  0.214 0.153 0.027 0.021 -0.052 -0.052 -0.091 -0.174   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.016 0.018 0.030 0.041 0.078 0.797  ||  -1.555 -1.212 -0.935 -0.780 -0.266 0.026 0.670 3.000  || dis=0.72 || select=7/8
008/019-th : 0.008 0.010 0.015 0.024 0.034 0.057 0.153 0.699  ||  -1.715 -1.444 -1.058 -0.601 -0.242 0.278 1.263 2.782  || dis=0.55 || select=7/8
009/019-th : 0.083 0.084 0.095 0.115 0.119 0.134 0.166 0.204  ||  -0.363 -0.345 -0.227 -0.033 -0.003 0.114 0.329 0.536  || dis=0.04 || select=7/8
010/019-th : 0.093 0.100 0.105 0.115 0.126 0.151 0.150 0.160  ||  -0.275 -0.201 -0.158 -0.059 0.028 0.211 0.200 0.265   || dis=0.01 || select=7/8
011/019-th : 0.129 0.123 0.120 0.117 0.124 0.130 0.128 0.129  ||  0.040 -0.009 -0.028 -0.056 0.003 0.049 0.034 0.042    || dis=0.00 || select=5/8
012/019-th : 0.158 0.144 0.127 0.125 0.121 0.110 0.109 0.106  ||  0.245 0.148 0.028 0.009 -0.025 -0.120 -0.127 -0.158   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.005 0.005 0.006 0.008 0.010 0.958  ||  -1.120 -1.014 -0.903 -0.810 -0.689 -0.352 -0.090 4.425  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.009 0.013 0.025 0.932  ||  -1.413 -1.303 -0.985 -0.925 -0.626 -0.225 0.433 4.051  || dis=0.91 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.014 0.953  ||  -1.141 -0.863 -0.902 -0.834 -0.697 -0.456 0.153 4.357  || dis=0.94 || select=7/8
016/019-th : 0.031 0.036 0.044 0.064 0.096 0.161 0.239 0.330  ||  -1.103 -0.932 -0.746 -0.355 0.044 0.558 0.955 1.279   || dis=0.09 || select=7/8
017/019-th : 0.086 0.104 0.103 0.119 0.137 0.143 0.155 0.152  ||  -0.349 -0.156 -0.175 -0.023 0.116 0.160 0.242 0.219   || dis=0.00 || select=6/8
018/019-th : 0.095 0.109 0.130 0.134 0.129 0.126 0.130 0.147  ||  -0.266 -0.128 0.046 0.080 0.040 0.016 0.044 0.171     || dis=0.01 || select=7/8
[epoch=512/600] FLOP : 28.22 MB, ratio : 0.6914, Expected-ratio : 0.7000, Discrepancy : 0.279
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:15:05] [epoch=512/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 1.883 (1.883)  Prec@1 57.81 (57.81) Prec@5 87.50 (87.50) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:15:11] [epoch=512/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.124 (2.357)  Prec@1 65.48 (49.94) Prec@5 95.24 (84.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.94 Prec@5 84.70 Error@1 50.06 Error@5 15.30 Loss:2.357
***[2020-01-29 10:15:11]*** VALID [epoch=512/600] loss = 2.356718, accuracy@1 = 49.94, accuracy@5 = 84.70 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:15:11]*** start epoch=513/600 Time Left: [00:46:29], LR=[0.005099 ~ 0.005099], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=513, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.34983243938649194, FLOP=40.81
[Search] : epoch=513/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:15:12] [epoch=513/600][000/098] Time 0.71 (0.71) Data 0.37 (0.37) Base-Loss 0.398 (0.398)  Prec@1 86.33 (86.33) Prec@5 99.61 (99.61) Acls-loss 0.555 (0.555) FLOP-Loss 0.000 (0.000) Arch-Loss 0.555 (0.555)
**TRAIN** [2020-01-29 10:15:39] [epoch=513/600][097/098] Time 0.35 (0.28) Data 0.00 (0.00) Base-Loss 0.434 (0.449)  Prec@1 85.12 (84.80) Prec@5 100.00 (99.32) Acls-loss 0.524 (0.595) FLOP-Loss 0.000 (0.122) Arch-Loss 0.524 (0.840)
 **TRAIN** Prec@1 84.80 Prec@5 99.32 Error@1 15.20 Error@5 0.68 Base-Loss:0.449, Arch-Loss=0.840
***[2020-01-29 10:15:39]*** TRAIN [epoch=513/600] base-loss = 0.449038, arch-loss = 0.840070, accuracy-1 = 84.80, accuracy-5 = 99.32
[epoch=513/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.978624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.187 0.500 0.313  ||  -0.2817 0.7036 0.2333  || discrepancy=0.19 || select=1/3
001/003-th : 0.333 0.284 0.383  ||  0.1361 -0.0216 0.2751  || discrepancy=0.05 || select=2/3
002/003-th : 0.005 0.029 0.966  ||  -2.3428 -0.6112 2.8859  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.010 0.015 0.018 0.019 0.025 0.036 0.077 0.800  ||  -1.469 -1.010 -0.832 -0.786 -0.518 -0.146 0.608 2.953  || dis=0.72 || select=7/8
001/019-th : 0.090 0.114 0.140 0.135 0.133 0.124 0.146 0.118  ||  -0.316 -0.081 0.127 0.089 0.079 0.007 0.168 -0.040    || dis=0.01 || select=6/8
002/019-th : 0.117 0.125 0.133 0.140 0.126 0.126 0.123 0.111  ||  -0.059 0.003 0.065 0.115 0.011 0.015 -0.009 -0.116    || dis=0.01 || select=3/8
003/019-th : 0.111 0.117 0.126 0.126 0.130 0.135 0.132 0.123  ||  -0.116 -0.068 0.004 0.012 0.041 0.078 0.052 -0.020    || dis=0.00 || select=5/8
004/019-th : 0.115 0.108 0.118 0.111 0.132 0.126 0.145 0.145  ||  -0.073 -0.138 -0.051 -0.108 0.066 0.018 0.160 0.156   || dis=0.00 || select=6/8
005/019-th : 0.134 0.137 0.127 0.126 0.125 0.126 0.115 0.110  ||  0.066 0.091 0.018 0.007 -0.003 0.011 -0.082 -0.123    || dis=0.00 || select=1/8
006/019-th : 0.154 0.145 0.127 0.123 0.117 0.117 0.112 0.104  ||  0.221 0.158 0.032 -0.006 -0.051 -0.050 -0.094 -0.171  || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.015 0.018 0.030 0.040 0.075 0.802  ||  -1.546 -1.203 -0.948 -0.784 -0.276 0.017 0.654 3.019  || dis=0.73 || select=7/8
008/019-th : 0.008 0.010 0.015 0.023 0.034 0.057 0.150 0.704  ||  -1.710 -1.448 -1.057 -0.615 -0.239 0.277 1.247 2.795  || dis=0.55 || select=7/8
009/019-th : 0.083 0.085 0.093 0.116 0.118 0.135 0.165 0.205  ||  -0.359 -0.339 -0.244 -0.029 -0.008 0.125 0.327 0.541  || dis=0.04 || select=7/8
010/019-th : 0.093 0.101 0.104 0.118 0.125 0.150 0.151 0.158  ||  -0.275 -0.192 -0.168 -0.035 0.018 0.201 0.208 0.256   || dis=0.01 || select=7/8
011/019-th : 0.130 0.120 0.118 0.119 0.125 0.131 0.127 0.130  ||  0.044 -0.030 -0.052 -0.037 0.009 0.052 0.022 0.050    || dis=0.00 || select=5/8
012/019-th : 0.157 0.144 0.128 0.124 0.120 0.109 0.111 0.107  ||  0.236 0.148 0.034 -0.001 -0.029 -0.129 -0.115 -0.150  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.006 0.008 0.010 0.960  ||  -1.127 -1.024 -0.917 -0.806 -0.698 -0.373 -0.099 4.454  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.008 0.012 0.024 0.934  ||  -1.406 -1.308 -0.982 -0.922 -0.638 -0.244 0.416 4.073  || dis=0.91 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.014 0.952  ||  -1.135 -0.853 -0.895 -0.829 -0.693 -0.455 0.144 4.350  || dis=0.94 || select=7/8
016/019-th : 0.030 0.036 0.043 0.063 0.095 0.161 0.238 0.333  ||  -1.112 -0.935 -0.748 -0.369 0.038 0.568 0.958 1.294   || dis=0.10 || select=7/8
017/019-th : 0.084 0.104 0.102 0.118 0.136 0.145 0.158 0.153  ||  -0.373 -0.154 -0.179 -0.031 0.112 0.174 0.259 0.226   || dis=0.01 || select=6/8
018/019-th : 0.094 0.109 0.129 0.132 0.130 0.128 0.130 0.147  ||  -0.272 -0.130 0.039 0.067 0.049 0.034 0.051 0.170     || dis=0.01 || select=7/8
[epoch=513/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.281
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:15:39] [epoch=513/600][000/098] Time 0.41 (0.41) Data 0.32 (0.32) Loss 0.816 (0.816)  Prec@1 80.47 (80.47) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:15:46] [epoch=513/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.681 (2.152)  Prec@1 75.00 (52.78) Prec@5 100.00 (86.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 52.78 Prec@5 86.58 Error@1 47.22 Error@5 13.42 Loss:2.152
***[2020-01-29 10:15:46]*** VALID [epoch=513/600] loss = 2.151699, accuracy@1 = 52.78, accuracy@5 = 86.58 | Best-Valid-Acc@1=54.28, Error@1=45.72
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:15:46]*** start epoch=514/600 Time Left: [00:45:57], LR=[0.004984 ~ 0.004984], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=514, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3442190100646259, FLOP=40.81
[Search] : epoch=514/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:15:47] [epoch=514/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.391 (0.391)  Prec@1 88.28 (88.28) Prec@5 98.83 (98.83) Acls-loss 0.441 (0.441) FLOP-Loss 0.000 (0.000) Arch-Loss 0.441 (0.441)
**TRAIN** [2020-01-29 10:16:14] [epoch=514/600][097/098] Time 0.29 (0.29) Data 0.00 (0.00) Base-Loss 1.054 (0.442)  Prec@1 63.69 (84.92) Prec@5 94.05 (99.32) Acls-loss 0.778 (0.594) FLOP-Loss 2.982 (0.295) Arch-Loss 6.742 (1.184)
 **TRAIN** Prec@1 84.92 Prec@5 99.32 Error@1 15.08 Error@5 0.68 Base-Loss:0.442, Arch-Loss=1.184
***[2020-01-29 10:16:14]*** TRAIN [epoch=514/600] base-loss = 0.441752, arch-loss = 1.184333, accuracy-1 = 84.92, accuracy-5 = 99.32
[epoch=514/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 9, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.4672)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.187 0.506 0.307  ||  -0.2754 0.7175 0.2172  || discrepancy=0.20 || select=1/3
001/003-th : 0.336 0.289 0.375  ||  0.1474 -0.0023 0.2561  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3363 -0.6019 2.8774  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.015 0.018 0.019 0.024 0.035 0.076 0.803  ||  -1.479 -1.001 -0.838 -0.783 -0.526 -0.166 0.613 2.970  || dis=0.73 || select=7/8
001/019-th : 0.091 0.114 0.140 0.136 0.132 0.124 0.146 0.118  ||  -0.309 -0.082 0.130 0.095 0.070 0.003 0.168 -0.046    || dis=0.01 || select=6/8
002/019-th : 0.119 0.127 0.133 0.140 0.125 0.125 0.122 0.110  ||  -0.046 0.020 0.065 0.115 0.003 0.003 -0.023 -0.124    || dis=0.01 || select=3/8
003/019-th : 0.113 0.116 0.126 0.128 0.130 0.132 0.131 0.122  ||  -0.098 -0.071 0.009 0.026 0.038 0.055 0.047 -0.022    || dis=0.00 || select=5/8
004/019-th : 0.116 0.109 0.118 0.112 0.131 0.125 0.145 0.144  ||  -0.062 -0.131 -0.052 -0.101 0.054 0.007 0.160 0.152   || dis=0.00 || select=6/8
005/019-th : 0.135 0.137 0.127 0.126 0.124 0.127 0.114 0.110  ||  0.079 0.089 0.016 0.010 -0.006 0.014 -0.088 -0.131    || dis=0.00 || select=1/8
006/019-th : 0.156 0.147 0.127 0.124 0.117 0.116 0.111 0.102  ||  0.237 0.178 0.029 0.004 -0.056 -0.063 -0.104 -0.187   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.015 0.018 0.029 0.039 0.074 0.805  ||  -1.542 -1.194 -0.939 -0.795 -0.296 0.011 0.643 3.033  || dis=0.73 || select=7/8
008/019-th : 0.008 0.010 0.015 0.023 0.034 0.056 0.150 0.705  ||  -1.697 -1.456 -1.048 -0.636 -0.236 0.265 1.249 2.798  || dis=0.55 || select=7/8
009/019-th : 0.085 0.085 0.094 0.117 0.117 0.136 0.164 0.201  ||  -0.340 -0.335 -0.237 -0.018 -0.020 0.131 0.317 0.521  || dis=0.04 || select=7/8
010/019-th : 0.095 0.101 0.105 0.118 0.126 0.148 0.150 0.158  ||  -0.259 -0.192 -0.160 -0.039 0.029 0.185 0.198 0.251   || dis=0.01 || select=7/8
011/019-th : 0.131 0.121 0.118 0.120 0.125 0.128 0.127 0.131  ||  0.056 -0.025 -0.049 -0.032 0.005 0.032 0.022 0.054    || dis=0.00 || select=0/8
012/019-th : 0.160 0.145 0.128 0.124 0.120 0.108 0.110 0.105  ||  0.255 0.159 0.031 -0.003 -0.030 -0.137 -0.121 -0.165  || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.008 0.010 0.960  ||  -1.121 -1.023 -0.930 -0.803 -0.711 -0.370 -0.098 4.464  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.008 0.012 0.024 0.936  ||  -1.409 -1.304 -0.982 -0.943 -0.641 -0.263 0.416 4.093  || dis=0.91 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.014 0.952  ||  -1.136 -0.841 -0.887 -0.825 -0.687 -0.453 0.120 4.351  || dis=0.94 || select=7/8
016/019-th : 0.031 0.036 0.044 0.064 0.095 0.163 0.238 0.330  ||  -1.092 -0.929 -0.746 -0.366 0.035 0.571 0.953 1.279   || dis=0.09 || select=7/8
017/019-th : 0.084 0.106 0.103 0.117 0.137 0.145 0.157 0.150  ||  -0.367 -0.138 -0.167 -0.039 0.117 0.171 0.252 0.209   || dis=0.01 || select=6/8
018/019-th : 0.097 0.109 0.130 0.130 0.131 0.128 0.129 0.145  ||  -0.242 -0.127 0.046 0.050 0.056 0.029 0.042 0.158     || dis=0.01 || select=7/8
[epoch=514/600] FLOP : 26.47 MB, ratio : 0.6485, Expected-ratio : 0.7000, Discrepancy : 0.281
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:16:15] [epoch=514/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.775 (2.775)  Prec@1 27.34 (27.34) Prec@5 58.59 (58.59) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:16:21] [epoch=514/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 5.244 (2.021)  Prec@1 14.88 (54.57) Prec@5 76.79 (88.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 54.57 Prec@5 88.10 Error@1 45.43 Error@5 11.90 Loss:2.021
***[2020-01-29 10:16:21]*** VALID [epoch=514/600] loss = 2.020844, accuracy@1 = 54.57, accuracy@5 = 88.10 | Best-Valid-Acc@1=54.28, Error@1=45.72
Currently, the best validation accuracy found at 514-epoch :: acc@1=54.57, acc@5=88.10, error@1=45.43, error@5=11.90, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:16:21]*** start epoch=515/600 Time Left: [00:45:26], LR=[0.004871 ~ 0.004871], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=515, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.33866605334284205, FLOP=40.81
[Search] : epoch=515/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:16:22] [epoch=515/600][000/098] Time 0.82 (0.82) Data 0.37 (0.37) Base-Loss 0.305 (0.305)  Prec@1 89.06 (89.06) Prec@5 100.00 (100.00) Acls-loss 0.522 (0.522) FLOP-Loss -2.981 (-2.981) Arch-Loss -5.440 (-5.440)
**TRAIN** [2020-01-29 10:16:50] [epoch=515/600][097/098] Time 0.27 (0.29) Data 0.00 (0.00) Base-Loss 0.629 (0.448)  Prec@1 78.57 (84.62) Prec@5 98.81 (99.28) Acls-loss 0.644 (0.572) FLOP-Loss -2.981 (0.133) Arch-Loss -5.318 (0.837)
 **TRAIN** Prec@1 84.62 Prec@5 99.28 Error@1 15.38 Error@5 0.72 Base-Loss:0.448, Arch-Loss=0.837
***[2020-01-29 10:16:50]*** TRAIN [epoch=515/600] base-loss = 0.447984, arch-loss = 0.837361, accuracy-1 = 84.62, accuracy-5 = 99.28
[epoch=515/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.639872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.187 0.505 0.308  ||  -0.2793 0.7137 0.2193  || discrepancy=0.20 || select=1/3
001/003-th : 0.337 0.291 0.372  ||  0.1506 0.0031 0.2501  || discrepancy=0.03 || select=2/3
002/003-th : 0.005 0.030 0.964  ||  -2.3301 -0.5942 2.8696  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.015 0.018 0.019 0.024 0.034 0.075 0.805  ||  -1.476 -1.005 -0.838 -0.777 -0.522 -0.185 0.610 2.979  || dis=0.73 || select=7/8
001/019-th : 0.089 0.113 0.142 0.137 0.132 0.123 0.146 0.118  ||  -0.322 -0.086 0.142 0.103 0.068 0.002 0.168 -0.042    || dis=0.00 || select=6/8
002/019-th : 0.119 0.126 0.135 0.139 0.125 0.124 0.122 0.110  ||  -0.041 0.013 0.080 0.108 0.003 -0.001 -0.021 -0.128   || dis=0.00 || select=3/8
003/019-th : 0.113 0.117 0.127 0.127 0.131 0.133 0.132 0.121  ||  -0.099 -0.069 0.013 0.018 0.046 0.063 0.051 -0.034    || dis=0.00 || select=5/8
004/019-th : 0.116 0.109 0.118 0.111 0.131 0.123 0.147 0.145  ||  -0.071 -0.130 -0.051 -0.108 0.052 -0.004 0.174 0.159  || dis=0.00 || select=6/8
005/019-th : 0.135 0.137 0.126 0.127 0.125 0.126 0.115 0.110  ||  0.075 0.091 0.011 0.018 0.000 0.010 -0.086 -0.131     || dis=0.00 || select=1/8
006/019-th : 0.156 0.148 0.127 0.124 0.117 0.116 0.111 0.102  ||  0.237 0.181 0.030 0.002 -0.055 -0.060 -0.107 -0.189   || dis=0.01 || select=0/8
007/019-th : 0.008 0.012 0.015 0.017 0.028 0.039 0.071 0.810  ||  -1.531 -1.204 -0.933 -0.789 -0.303 0.004 0.613 3.049  || dis=0.74 || select=7/8
008/019-th : 0.008 0.010 0.015 0.022 0.033 0.055 0.147 0.710  ||  -1.691 -1.458 -1.062 -0.659 -0.241 0.264 1.244 2.819  || dis=0.56 || select=7/8
009/019-th : 0.084 0.085 0.094 0.116 0.117 0.139 0.164 0.201  ||  -0.344 -0.343 -0.238 -0.027 -0.017 0.151 0.317 0.524  || dis=0.04 || select=7/8
010/019-th : 0.095 0.101 0.106 0.116 0.126 0.149 0.148 0.157  ||  -0.254 -0.197 -0.144 -0.052 0.030 0.197 0.189 0.247   || dis=0.01 || select=7/8
011/019-th : 0.131 0.122 0.118 0.120 0.124 0.127 0.126 0.132  ||  0.058 -0.017 -0.053 -0.031 -0.001 0.027 0.016 0.059   || dis=0.00 || select=7/8
012/019-th : 0.160 0.146 0.129 0.123 0.120 0.108 0.110 0.105  ||  0.256 0.163 0.039 -0.011 -0.034 -0.137 -0.121 -0.168  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.008 0.010 0.961  ||  -1.118 -1.039 -0.928 -0.799 -0.719 -0.373 -0.100 4.474  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.008 0.012 0.023 0.937  ||  -1.403 -1.300 -0.980 -0.944 -0.637 -0.277 0.397 4.105  || dis=0.91 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.014 0.953  ||  -1.141 -0.832 -0.888 -0.820 -0.685 -0.451 0.112 4.352  || dis=0.94 || select=7/8
016/019-th : 0.031 0.037 0.044 0.064 0.095 0.164 0.235 0.332  ||  -1.081 -0.920 -0.749 -0.368 0.027 0.579 0.937 1.282   || dis=0.10 || select=7/8
017/019-th : 0.085 0.106 0.105 0.118 0.137 0.144 0.156 0.150  ||  -0.366 -0.136 -0.155 -0.037 0.117 0.165 0.246 0.206   || dis=0.01 || select=6/8
018/019-th : 0.098 0.110 0.131 0.131 0.132 0.127 0.128 0.144  ||  -0.240 -0.120 0.057 0.051 0.061 0.025 0.036 0.147     || dis=0.01 || select=7/8
[epoch=515/600] FLOP : 28.64 MB, ratio : 0.7017, Expected-ratio : 0.7000, Discrepancy : 0.282
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:16:50] [epoch=515/600][000/098] Time 0.61 (0.61) Data 0.41 (0.41) Loss 0.993 (0.993)  Prec@1 70.70 (70.70) Prec@5 94.14 (94.14) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:16:57] [epoch=515/600][097/098] Time 0.06 (0.07) Data 0.00 (0.01) Loss 5.264 (1.933)  Prec@1 17.26 (51.70) Prec@5 67.86 (87.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 51.70 Prec@5 87.58 Error@1 48.30 Error@5 12.42 Loss:1.933
***[2020-01-29 10:16:57]*** VALID [epoch=515/600] loss = 1.932677, accuracy@1 = 51.70, accuracy@5 = 87.58 | Best-Valid-Acc@1=54.57, Error@1=45.43
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:16:57]*** start epoch=516/600 Time Left: [00:44:54], LR=[0.004759 ~ 0.004759], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=516, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.33317372145825264, FLOP=40.81
[Search] : epoch=516/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:16:58] [epoch=516/600][000/098] Time 0.72 (0.72) Data 0.36 (0.36) Base-Loss 0.322 (0.322)  Prec@1 89.06 (89.06) Prec@5 100.00 (100.00) Acls-loss 0.502 (0.502) FLOP-Loss 2.981 (2.981) Arch-Loss 6.464 (6.464)
**TRAIN** [2020-01-29 10:17:24] [epoch=516/600][097/098] Time 0.26 (0.28) Data 0.00 (0.00) Base-Loss 0.255 (0.437)  Prec@1 89.88 (85.04) Prec@5 100.00 (99.47) Acls-loss 0.396 (0.628) FLOP-Loss 2.984 (0.112) Arch-Loss 6.363 (0.852)
 **TRAIN** Prec@1 85.04 Prec@5 99.47 Error@1 14.96 Error@5 0.53 Base-Loss:0.437, Arch-Loss=0.852
***[2020-01-29 10:17:24]*** TRAIN [epoch=516/600] base-loss = 0.437116, arch-loss = 0.851524, accuracy-1 = 85.04, accuracy-5 = 99.47
[epoch=516/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 9, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.4672)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.186 0.505 0.309  ||  -0.2847 0.7122 0.2222  || discrepancy=0.20 || select=1/3
001/003-th : 0.335 0.291 0.373  ||  0.1464 0.0058 0.2530  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.031 0.964  ||  -2.3254 -0.5873 2.8634  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.015 0.018 0.019 0.024 0.033 0.073 0.809  ||  -1.472 -1.012 -0.824 -0.784 -0.519 -0.203 0.590 2.995  || dis=0.74 || select=7/8
001/019-th : 0.088 0.113 0.141 0.136 0.133 0.123 0.147 0.118  ||  -0.338 -0.082 0.138 0.102 0.081 0.003 0.176 -0.041    || dis=0.01 || select=6/8
002/019-th : 0.121 0.126 0.134 0.137 0.123 0.125 0.122 0.110  ||  -0.033 0.008 0.074 0.097 -0.010 0.004 -0.019 -0.122   || dis=0.00 || select=3/8
003/019-th : 0.112 0.117 0.125 0.128 0.131 0.134 0.131 0.121  ||  -0.108 -0.062 -0.002 0.023 0.050 0.069 0.049 -0.030   || dis=0.00 || select=5/8
004/019-th : 0.115 0.108 0.117 0.111 0.133 0.125 0.147 0.145  ||  -0.074 -0.138 -0.060 -0.109 0.069 0.008 0.174 0.155   || dis=0.00 || select=6/8
005/019-th : 0.137 0.135 0.126 0.125 0.128 0.126 0.114 0.109  ||  0.094 0.077 0.006 -0.003 0.022 0.008 -0.089 -0.133    || dis=0.00 || select=0/8
006/019-th : 0.155 0.147 0.128 0.124 0.117 0.116 0.110 0.102  ||  0.232 0.178 0.040 0.010 -0.047 -0.062 -0.110 -0.191   || dis=0.01 || select=0/8
007/019-th : 0.008 0.011 0.015 0.017 0.028 0.038 0.068 0.815  ||  -1.537 -1.213 -0.928 -0.797 -0.299 -0.006 0.592 3.071  || dis=0.75 || select=7/8
008/019-th : 0.008 0.010 0.015 0.022 0.033 0.055 0.145 0.712  ||  -1.690 -1.453 -1.055 -0.664 -0.239 0.256 1.233 2.823  || dis=0.57 || select=7/8
009/019-th : 0.084 0.082 0.093 0.116 0.120 0.140 0.162 0.203  ||  -0.343 -0.367 -0.243 -0.023 0.005 0.161 0.307 0.532   || dis=0.04 || select=7/8
010/019-th : 0.096 0.100 0.106 0.116 0.127 0.149 0.150 0.156  ||  -0.248 -0.200 -0.143 -0.060 0.034 0.196 0.198 0.238   || dis=0.01 || select=7/8
011/019-th : 0.131 0.122 0.118 0.120 0.124 0.127 0.125 0.131  ||  0.059 -0.014 -0.046 -0.033 -0.001 0.025 0.012 0.058   || dis=0.00 || select=0/8
012/019-th : 0.157 0.145 0.131 0.124 0.120 0.108 0.110 0.106  ||  0.236 0.158 0.053 -0.002 -0.032 -0.132 -0.119 -0.156  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.010 0.961  ||  -1.111 -1.035 -0.928 -0.815 -0.723 -0.393 -0.100 4.488  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.008 0.011 0.021 0.941  ||  -1.397 -1.298 -0.981 -0.974 -0.651 -0.296 0.369 4.148  || dis=0.92 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.013 0.954  ||  -1.163 -0.820 -0.880 -0.815 -0.697 -0.448 0.089 4.373  || dis=0.94 || select=7/8
016/019-th : 0.030 0.036 0.043 0.064 0.096 0.166 0.233 0.332  ||  -1.101 -0.924 -0.767 -0.364 0.049 0.597 0.932 1.287   || dis=0.10 || select=7/8
017/019-th : 0.085 0.104 0.105 0.119 0.132 0.147 0.157 0.152  ||  -0.368 -0.161 -0.147 -0.024 0.076 0.184 0.251 0.218   || dis=0.01 || select=6/8
018/019-th : 0.098 0.110 0.130 0.130 0.132 0.129 0.130 0.143  ||  -0.237 -0.122 0.044 0.045 0.060 0.042 0.044 0.143     || dis=0.01 || select=7/8
[epoch=516/600] FLOP : 26.47 MB, ratio : 0.6485, Expected-ratio : 0.7000, Discrepancy : 0.283
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:17:24] [epoch=516/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.986 (3.986)  Prec@1 21.48 (21.48) Prec@5 67.58 (67.58) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:17:31] [epoch=516/600][097/098] Time 0.07 (0.07) Data 0.00 (0.00) Loss 0.703 (2.421)  Prec@1 78.57 (49.75) Prec@5 97.62 (85.93) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.75 Prec@5 85.93 Error@1 50.25 Error@5 14.07 Loss:2.421
***[2020-01-29 10:17:31]*** VALID [epoch=516/600] loss = 2.421044, accuracy@1 = 49.75, accuracy@5 = 85.93 | Best-Valid-Acc@1=54.57, Error@1=45.43
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:17:31]*** start epoch=517/600 Time Left: [00:44:23], LR=[0.004648 ~ 0.004648], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=517, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.32774216498591113, FLOP=40.81
[Search] : epoch=517/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:17:32] [epoch=517/600][000/098] Time 0.67 (0.67) Data 0.38 (0.38) Base-Loss 0.287 (0.287)  Prec@1 91.02 (91.02) Prec@5 99.61 (99.61) Acls-loss 0.372 (0.372) FLOP-Loss -2.983 (-2.983) Arch-Loss -5.595 (-5.595)
**TRAIN** [2020-01-29 10:17:59] [epoch=517/600][097/098] Time 0.29 (0.28) Data 0.00 (0.00) Base-Loss 0.705 (0.425)  Prec@1 75.00 (85.50) Prec@5 98.21 (99.40) Acls-loss 0.718 (0.571) FLOP-Loss 2.985 (0.112) Arch-Loss 6.688 (0.795)
 **TRAIN** Prec@1 85.50 Prec@5 99.40 Error@1 14.50 Error@5 0.60 Base-Loss:0.425, Arch-Loss=0.795
***[2020-01-29 10:17:59]*** TRAIN [epoch=517/600] base-loss = 0.425043, arch-loss = 0.795353, accuracy-1 = 85.50, accuracy-5 = 99.40
[epoch=517/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 9, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 26.4672)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.184 0.510 0.307  ||  -0.2924 0.7292 0.2212  || discrepancy=0.20 || select=1/3
001/003-th : 0.334 0.294 0.372  ||  0.1453 0.0165 0.2514  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.031 0.964  ||  -2.3204 -0.5877 2.8589  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.014 0.018 0.018 0.024 0.033 0.073 0.811  ||  -1.472 -1.018 -0.813 -0.798 -0.533 -0.209 0.599 3.006  || dis=0.74 || select=7/8
001/019-th : 0.087 0.113 0.141 0.136 0.135 0.123 0.148 0.118  ||  -0.342 -0.085 0.134 0.098 0.092 0.002 0.185 -0.042    || dis=0.01 || select=6/8
002/019-th : 0.120 0.126 0.134 0.137 0.123 0.127 0.122 0.111  ||  -0.039 0.010 0.069 0.094 -0.012 0.018 -0.019 -0.118   || dis=0.00 || select=3/8
003/019-th : 0.113 0.117 0.123 0.130 0.128 0.136 0.131 0.122  ||  -0.101 -0.065 -0.015 0.037 0.025 0.080 0.047 -0.027   || dis=0.01 || select=5/8
004/019-th : 0.115 0.108 0.116 0.111 0.133 0.126 0.147 0.144  ||  -0.073 -0.138 -0.065 -0.111 0.072 0.014 0.172 0.153   || dis=0.00 || select=6/8
005/019-th : 0.138 0.134 0.126 0.125 0.127 0.126 0.116 0.109  ||  0.096 0.070 0.006 -0.002 0.020 0.007 -0.076 -0.138    || dis=0.00 || select=0/8
006/019-th : 0.154 0.147 0.128 0.124 0.118 0.116 0.111 0.102  ||  0.225 0.176 0.040 0.004 -0.043 -0.056 -0.104 -0.191   || dis=0.01 || select=0/8
007/019-th : 0.008 0.011 0.014 0.017 0.027 0.036 0.066 0.822  ||  -1.528 -1.223 -0.958 -0.792 -0.323 -0.020 0.585 3.107  || dis=0.76 || select=7/8
008/019-th : 0.008 0.010 0.015 0.022 0.033 0.053 0.143 0.718  ||  -1.704 -1.445 -1.049 -0.663 -0.249 0.232 1.231 2.841  || dis=0.57 || select=7/8
009/019-th : 0.084 0.082 0.093 0.116 0.119 0.139 0.164 0.203  ||  -0.346 -0.367 -0.244 -0.025 -0.002 0.158 0.321 0.533  || dis=0.04 || select=7/8
010/019-th : 0.096 0.102 0.105 0.115 0.127 0.152 0.148 0.156  ||  -0.247 -0.189 -0.155 -0.065 0.031 0.213 0.189 0.239   || dis=0.00 || select=7/8
011/019-th : 0.130 0.123 0.119 0.120 0.126 0.127 0.125 0.130  ||  0.051 -0.011 -0.037 -0.032 0.015 0.024 0.004 0.049    || dis=0.00 || select=0/8
012/019-th : 0.157 0.145 0.129 0.122 0.121 0.108 0.110 0.107  ||  0.235 0.155 0.043 -0.013 -0.025 -0.138 -0.120 -0.143  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.010 0.961  ||  -1.105 -1.031 -0.925 -0.811 -0.721 -0.395 -0.099 4.483  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.008 0.011 0.021 0.942  ||  -1.397 -1.294 -0.977 -0.974 -0.652 -0.298 0.353 4.156  || dis=0.92 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.013 0.954  ||  -1.159 -0.809 -0.873 -0.836 -0.693 -0.453 0.088 4.382  || dis=0.94 || select=7/8
016/019-th : 0.031 0.036 0.043 0.063 0.096 0.165 0.238 0.330  ||  -1.094 -0.933 -0.761 -0.367 0.045 0.588 0.954 1.282   || dis=0.09 || select=7/8
017/019-th : 0.084 0.104 0.105 0.120 0.131 0.147 0.158 0.151  ||  -0.372 -0.157 -0.148 -0.018 0.070 0.184 0.255 0.213   || dis=0.01 || select=6/8
018/019-th : 0.097 0.110 0.130 0.130 0.134 0.128 0.129 0.142  ||  -0.242 -0.119 0.052 0.048 0.077 0.037 0.041 0.134     || dis=0.01 || select=7/8
[epoch=517/600] FLOP : 26.47 MB, ratio : 0.6485, Expected-ratio : 0.7000, Discrepancy : 0.284
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:17:59] [epoch=517/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 2.007 (2.007)  Prec@1 27.34 (27.34) Prec@5 78.91 (78.91) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:18:06] [epoch=517/600][097/098] Time 0.06 (0.08) Data 0.00 (0.00) Loss 0.944 (1.830)  Prec@1 71.43 (53.96) Prec@5 98.21 (87.71) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.96 Prec@5 87.71 Error@1 46.04 Error@5 12.29 Loss:1.830
***[2020-01-29 10:18:06]*** VALID [epoch=517/600] loss = 1.829849, accuracy@1 = 53.96, accuracy@5 = 87.71 | Best-Valid-Acc@1=54.57, Error@1=45.43
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:18:06]*** start epoch=518/600 Time Left: [00:43:51], LR=[0.004538 ~ 0.004538], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=518, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3223715328346821, FLOP=40.81
[Search] : epoch=518/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:18:07] [epoch=518/600][000/098] Time 0.70 (0.70) Data 0.36 (0.36) Base-Loss 0.261 (0.261)  Prec@1 91.80 (91.80) Prec@5 99.22 (99.22) Acls-loss 1.052 (1.052) FLOP-Loss -2.984 (-2.984) Arch-Loss -4.917 (-4.917)
**TRAIN** [2020-01-29 10:18:35] [epoch=518/600][097/098] Time 0.31 (0.29) Data 0.00 (0.00) Base-Loss 0.537 (0.470)  Prec@1 84.52 (83.80) Prec@5 99.40 (99.07) Acls-loss 0.604 (0.598) FLOP-Loss 2.986 (0.112) Arch-Loss 6.575 (0.822)
 **TRAIN** Prec@1 83.80 Prec@5 99.07 Error@1 16.20 Error@5 0.93 Base-Loss:0.470, Arch-Loss=0.822
***[2020-01-29 10:18:35]*** TRAIN [epoch=518/600] base-loss = 0.469826, arch-loss = 0.822313, accuracy-1 = 83.80, accuracy-5 = 99.07
[epoch=518/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.639872)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.183 0.512 0.305  ||  -0.2946 0.7358 0.2190  || discrepancy=0.21 || select=1/3
001/003-th : 0.332 0.297 0.372  ||  0.1400 0.0288 0.2541  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.030 0.964  ||  -2.3287 -0.5883 2.8672  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.014 0.018 0.018 0.023 0.032 0.071 0.814  ||  -1.465 -1.018 -0.819 -0.801 -0.540 -0.209 0.585 3.018  || dis=0.74 || select=7/8
001/019-th : 0.087 0.114 0.141 0.132 0.137 0.125 0.147 0.117  ||  -0.344 -0.079 0.138 0.075 0.110 0.016 0.178 -0.047    || dis=0.01 || select=6/8
002/019-th : 0.119 0.126 0.133 0.136 0.125 0.128 0.123 0.112  ||  -0.050 0.007 0.064 0.083 -0.001 0.022 -0.012 -0.111   || dis=0.00 || select=3/8
003/019-th : 0.112 0.117 0.125 0.130 0.127 0.136 0.130 0.123  ||  -0.110 -0.067 0.003 0.039 0.013 0.082 0.040 -0.016    || dis=0.01 || select=5/8
004/019-th : 0.116 0.107 0.115 0.110 0.133 0.126 0.147 0.146  ||  -0.065 -0.145 -0.074 -0.121 0.071 0.012 0.172 0.161   || dis=0.00 || select=6/8
005/019-th : 0.138 0.134 0.126 0.125 0.128 0.125 0.116 0.109  ||  0.097 0.070 0.007 -0.004 0.022 0.002 -0.075 -0.139    || dis=0.00 || select=0/8
006/019-th : 0.154 0.146 0.128 0.123 0.118 0.117 0.111 0.101  ||  0.225 0.172 0.039 0.000 -0.039 -0.053 -0.101 -0.193   || dis=0.01 || select=0/8
007/019-th : 0.008 0.011 0.014 0.017 0.026 0.036 0.066 0.823  ||  -1.517 -1.216 -0.956 -0.796 -0.328 -0.030 0.581 3.110  || dis=0.76 || select=7/8
008/019-th : 0.007 0.010 0.015 0.021 0.032 0.052 0.139 0.724  ||  -1.716 -1.440 -1.041 -0.662 -0.267 0.222 1.214 2.864  || dis=0.58 || select=7/8
009/019-th : 0.083 0.083 0.093 0.116 0.118 0.143 0.164 0.201  ||  -0.362 -0.363 -0.240 -0.026 -0.004 0.183 0.322 0.527  || dis=0.04 || select=7/8
010/019-th : 0.095 0.102 0.104 0.114 0.127 0.154 0.149 0.155  ||  -0.251 -0.188 -0.169 -0.074 0.038 0.231 0.196 0.235   || dis=0.00 || select=7/8
011/019-th : 0.130 0.121 0.120 0.120 0.125 0.127 0.126 0.130  ||  0.049 -0.023 -0.029 -0.033 0.011 0.023 0.013 0.050    || dis=0.00 || select=7/8
012/019-th : 0.157 0.144 0.129 0.123 0.122 0.108 0.110 0.108  ||  0.237 0.149 0.036 -0.012 -0.020 -0.142 -0.120 -0.137  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.010 0.961  ||  -1.098 -1.026 -0.929 -0.814 -0.719 -0.403 -0.109 4.488  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.006 0.006 0.008 0.011 0.021 0.942  ||  -1.391 -1.315 -0.969 -0.971 -0.649 -0.309 0.352 4.170  || dis=0.92 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.008 0.013 0.954  ||  -1.154 -0.797 -0.886 -0.832 -0.689 -0.461 0.086 4.383  || dis=0.94 || select=7/8
016/019-th : 0.031 0.036 0.043 0.062 0.096 0.166 0.234 0.331  ||  -1.080 -0.935 -0.758 -0.383 0.048 0.596 0.940 1.285   || dis=0.10 || select=7/8
017/019-th : 0.085 0.105 0.105 0.120 0.131 0.146 0.157 0.151  ||  -0.366 -0.152 -0.150 -0.015 0.066 0.175 0.252 0.213   || dis=0.01 || select=6/8
018/019-th : 0.098 0.110 0.132 0.129 0.133 0.129 0.128 0.141  ||  -0.237 -0.115 0.062 0.041 0.074 0.044 0.034 0.128     || dis=0.01 || select=7/8
[epoch=518/600] FLOP : 28.64 MB, ratio : 0.7017, Expected-ratio : 0.7000, Discrepancy : 0.285
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:18:36] [epoch=518/600][000/098] Time 0.42 (0.42) Data 0.32 (0.32) Loss 0.738 (0.738)  Prec@1 76.17 (76.17) Prec@5 96.48 (96.48) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:18:43] [epoch=518/600][097/098] Time 0.07 (0.08) Data 0.00 (0.00) Loss 0.826 (1.933)  Prec@1 74.40 (50.90) Prec@5 97.62 (86.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 50.90 Prec@5 86.54 Error@1 49.10 Error@5 13.46 Loss:1.933
***[2020-01-29 10:18:43]*** VALID [epoch=518/600] loss = 1.932672, accuracy@1 = 50.90, accuracy@5 = 86.54 | Best-Valid-Acc@1=54.57, Error@1=45.43
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:18:43]*** start epoch=519/600 Time Left: [00:43:20], LR=[0.004430 ~ 0.004430], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=519, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.317061972243159, FLOP=40.81
[Search] : epoch=519/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:18:44] [epoch=519/600][000/098] Time 0.70 (0.70) Data 0.38 (0.38) Base-Loss 0.448 (0.448)  Prec@1 83.59 (83.59) Prec@5 99.22 (99.22) Acls-loss 0.539 (0.539) FLOP-Loss 2.985 (2.985) Arch-Loss 6.510 (6.510)
**TRAIN** [2020-01-29 10:19:11] [epoch=519/600][097/098] Time 0.28 (0.28) Data 0.00 (0.00) Base-Loss 0.411 (0.437)  Prec@1 86.90 (85.20) Prec@5 98.81 (99.31) Acls-loss 0.774 (0.597) FLOP-Loss 0.000 (0.061) Arch-Loss 0.774 (0.719)
 **TRAIN** Prec@1 85.20 Prec@5 99.31 Error@1 14.80 Error@5 0.69 Base-Loss:0.437, Arch-Loss=0.719
***[2020-01-29 10:19:11]*** TRAIN [epoch=519/600] base-loss = 0.437437, arch-loss = 0.719097, accuracy-1 = 85.20, accuracy-5 = 99.31
[epoch=519/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 25, 32, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.796352)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.181 0.514 0.305  ||  -0.2996 0.7424 0.2190  || discrepancy=0.21 || select=1/3
001/003-th : 0.329 0.299 0.372  ||  0.1354 0.0398 0.2564  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.031 0.964  ||  -2.3220 -0.5788 2.8583  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.014 0.017 0.017 0.023 0.032 0.069 0.819  ||  -1.472 -1.009 -0.821 -0.817 -0.547 -0.197 0.561 3.040  || dis=0.75 || select=7/8
001/019-th : 0.086 0.113 0.142 0.131 0.137 0.125 0.147 0.119  ||  -0.355 -0.084 0.144 0.064 0.112 0.016 0.180 -0.035    || dis=0.01 || select=6/8
002/019-th : 0.119 0.126 0.134 0.136 0.124 0.127 0.123 0.112  ||  -0.048 0.007 0.072 0.089 -0.009 0.019 -0.017 -0.110   || dis=0.00 || select=3/8
003/019-th : 0.111 0.116 0.126 0.131 0.127 0.136 0.131 0.123  ||  -0.115 -0.072 0.005 0.044 0.013 0.083 0.044 -0.014    || dis=0.01 || select=5/8
004/019-th : 0.116 0.107 0.113 0.112 0.132 0.125 0.149 0.146  ||  -0.063 -0.152 -0.093 -0.100 0.060 0.005 0.183 0.165   || dis=0.00 || select=6/8
005/019-th : 0.138 0.135 0.125 0.124 0.129 0.124 0.116 0.109  ||  0.098 0.074 0.002 -0.009 0.031 -0.005 -0.076 -0.136   || dis=0.00 || select=0/8
006/019-th : 0.154 0.145 0.130 0.120 0.119 0.117 0.112 0.103  ||  0.222 0.165 0.050 -0.023 -0.036 -0.050 -0.100 -0.177  || dis=0.01 || select=0/8
007/019-th : 0.008 0.011 0.014 0.017 0.026 0.035 0.065 0.825  ||  -1.516 -1.209 -0.952 -0.793 -0.350 -0.030 0.571 3.119  || dis=0.76 || select=7/8
008/019-th : 0.007 0.010 0.014 0.021 0.031 0.051 0.136 0.729  ||  -1.711 -1.447 -1.050 -0.672 -0.274 0.224 1.200 2.878  || dis=0.59 || select=7/8
009/019-th : 0.083 0.083 0.094 0.115 0.118 0.143 0.164 0.201  ||  -0.363 -0.363 -0.234 -0.035 -0.006 0.186 0.325 0.525  || dis=0.04 || select=7/8
010/019-th : 0.096 0.103 0.103 0.113 0.125 0.156 0.149 0.155  ||  -0.249 -0.179 -0.171 -0.084 0.015 0.242 0.197 0.237   || dis=0.00 || select=5/8
011/019-th : 0.130 0.120 0.119 0.120 0.126 0.128 0.126 0.131  ||  0.047 -0.032 -0.037 -0.029 0.012 0.028 0.017 0.053    || dis=0.00 || select=7/8
012/019-th : 0.157 0.142 0.129 0.123 0.123 0.108 0.110 0.108  ||  0.239 0.133 0.040 -0.004 -0.007 -0.138 -0.120 -0.138  || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.010 0.961  ||  -1.090 -1.022 -0.936 -0.812 -0.717 -0.414 -0.107 4.492  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.020 0.944  ||  -1.384 -1.331 -0.971 -0.972 -0.670 -0.314 0.349 4.193  || dis=0.92 || select=7/8
015/019-th : 0.004 0.005 0.004 0.005 0.006 0.007 0.012 0.957  ||  -1.157 -0.785 -0.925 -0.896 -0.685 -0.460 0.086 4.438  || dis=0.94 || select=7/8
016/019-th : 0.031 0.036 0.042 0.062 0.096 0.167 0.235 0.332  ||  -1.074 -0.936 -0.776 -0.392 0.047 0.603 0.946 1.292   || dis=0.10 || select=7/8
017/019-th : 0.084 0.105 0.103 0.120 0.128 0.147 0.160 0.152  ||  -0.374 -0.149 -0.167 -0.015 0.050 0.183 0.267 0.217   || dis=0.01 || select=6/8
018/019-th : 0.098 0.109 0.131 0.130 0.133 0.128 0.127 0.143  ||  -0.232 -0.127 0.060 0.047 0.072 0.034 0.028 0.141     || dis=0.01 || select=7/8
[epoch=519/600] FLOP : 27.80 MB, ratio : 0.6811, Expected-ratio : 0.7000, Discrepancy : 0.287
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:19:11] [epoch=519/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 4.539 (4.539)  Prec@1 17.19 (17.19) Prec@5 63.28 (63.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:19:18] [epoch=519/600][097/098] Time 0.07 (0.08) Data 0.00 (0.00) Loss 0.806 (1.926)  Prec@1 76.79 (56.27) Prec@5 97.62 (89.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.27 Prec@5 89.30 Error@1 43.73 Error@5 10.70 Loss:1.926
***[2020-01-29 10:19:18]*** VALID [epoch=519/600] loss = 1.925756, accuracy@1 = 56.27, accuracy@5 = 89.30 | Best-Valid-Acc@1=54.57, Error@1=45.43
Currently, the best validation accuracy found at 519-epoch :: acc@1=56.27, acc@5=89.30, error@1=43.73, error@5=10.70, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:19:18]*** start epoch=520/600 Time Left: [00:42:48], LR=[0.004323 ~ 0.004323], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=520, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.3118136287756276, FLOP=40.81
[Search] : epoch=520/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:19:19] [epoch=520/600][000/098] Time 0.71 (0.71) Data 0.37 (0.37) Base-Loss 0.343 (0.343)  Prec@1 86.72 (86.72) Prec@5 99.22 (99.22) Acls-loss 0.466 (0.466) FLOP-Loss 0.000 (0.000) Arch-Loss 0.466 (0.466)
**TRAIN** [2020-01-29 10:19:47] [epoch=520/600][097/098] Time 0.30 (0.29) Data 0.00 (0.00) Base-Loss 0.486 (0.449)  Prec@1 83.33 (84.76) Prec@5 99.40 (99.21) Acls-loss 0.664 (0.566) FLOP-Loss 0.000 (0.122) Arch-Loss 0.664 (0.810)
 **TRAIN** Prec@1 84.76 Prec@5 99.21 Error@1 15.24 Error@5 0.79 Base-Loss:0.449, Arch-Loss=0.810
***[2020-01-29 10:19:47]*** TRAIN [epoch=520/600] base-loss = 0.449270, arch-loss = 0.810431, accuracy-1 = 84.76, accuracy-5 = 99.21
[epoch=520/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.978624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.181 0.516 0.303  ||  -0.3018 0.7480 0.2171  || discrepancy=0.21 || select=1/3
001/003-th : 0.330 0.299 0.372  ||  0.1361 0.0364 0.2554  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.031 0.964  ||  -2.3214 -0.5894 2.8610  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.014 0.017 0.017 0.022 0.032 0.068 0.820  ||  -1.483 -0.998 -0.825 -0.812 -0.551 -0.185 0.555 3.048  || dis=0.75 || select=7/8
001/019-th : 0.085 0.112 0.142 0.132 0.136 0.127 0.148 0.119  ||  -0.367 -0.089 0.144 0.070 0.106 0.035 0.185 -0.032    || dis=0.01 || select=6/8
002/019-th : 0.118 0.125 0.135 0.137 0.123 0.127 0.123 0.112  ||  -0.054 0.003 0.079 0.097 -0.009 0.018 -0.016 -0.106   || dis=0.00 || select=3/8
003/019-th : 0.112 0.117 0.125 0.130 0.126 0.136 0.131 0.124  ||  -0.108 -0.070 -0.005 0.035 0.009 0.083 0.044 -0.012   || dis=0.01 || select=5/8
004/019-th : 0.117 0.107 0.113 0.114 0.129 0.124 0.150 0.146  ||  -0.059 -0.152 -0.092 -0.088 0.041 0.003 0.188 0.161   || dis=0.00 || select=6/8
005/019-th : 0.138 0.135 0.124 0.125 0.129 0.124 0.115 0.110  ||  0.098 0.078 -0.010 -0.003 0.030 -0.006 -0.080 -0.129  || dis=0.00 || select=0/8
006/019-th : 0.154 0.145 0.130 0.121 0.118 0.118 0.111 0.103  ||  0.224 0.167 0.056 -0.021 -0.042 -0.041 -0.106 -0.183  || dis=0.01 || select=0/8
007/019-th : 0.008 0.011 0.014 0.016 0.025 0.035 0.063 0.829  ||  -1.528 -1.213 -0.957 -0.786 -0.349 -0.039 0.553 3.138  || dis=0.77 || select=7/8
008/019-th : 0.007 0.010 0.014 0.021 0.031 0.050 0.135 0.731  ||  -1.706 -1.448 -1.049 -0.678 -0.267 0.208 1.193 2.883  || dis=0.60 || select=7/8
009/019-th : 0.083 0.082 0.095 0.114 0.118 0.143 0.165 0.200  ||  -0.359 -0.367 -0.226 -0.042 -0.005 0.186 0.327 0.522  || dis=0.04 || select=7/8
010/019-th : 0.095 0.103 0.104 0.112 0.126 0.155 0.149 0.156  ||  -0.253 -0.176 -0.168 -0.087 0.029 0.236 0.192 0.239   || dis=0.00 || select=7/8
011/019-th : 0.127 0.117 0.118 0.120 0.128 0.131 0.128 0.130  ||  0.027 -0.053 -0.049 -0.030 0.034 0.053 0.036 0.046    || dis=0.00 || select=5/8
012/019-th : 0.158 0.141 0.130 0.123 0.122 0.108 0.111 0.108  ||  0.243 0.129 0.044 -0.011 -0.020 -0.139 -0.115 -0.137  || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.962  ||  -1.084 -1.017 -0.934 -0.808 -0.715 -0.435 -0.120 4.500  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.020 0.945  ||  -1.386 -1.329 -0.963 -0.971 -0.666 -0.331 0.341 4.201  || dis=0.92 || select=7/8
015/019-th : 0.004 0.005 0.004 0.005 0.006 0.007 0.012 0.958  ||  -1.151 -0.773 -0.920 -0.894 -0.680 -0.476 0.057 4.446  || dis=0.95 || select=7/8
016/019-th : 0.031 0.036 0.041 0.061 0.096 0.168 0.237 0.330  ||  -1.073 -0.936 -0.792 -0.396 0.056 0.615 0.955 1.287   || dis=0.09 || select=7/8
017/019-th : 0.084 0.105 0.103 0.120 0.130 0.146 0.161 0.152  ||  -0.373 -0.152 -0.167 -0.022 0.059 0.176 0.274 0.218   || dis=0.01 || select=6/8
018/019-th : 0.099 0.109 0.130 0.128 0.136 0.127 0.127 0.144  ||  -0.227 -0.133 0.048 0.034 0.092 0.026 0.028 0.151     || dis=0.01 || select=7/8
[epoch=520/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.287
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:19:47] [epoch=520/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 0.565 (0.565)  Prec@1 81.25 (81.25) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:19:54] [epoch=520/600][097/098] Time 0.06 (0.08) Data 0.00 (0.00) Loss 1.058 (1.781)  Prec@1 68.45 (55.36) Prec@5 95.24 (88.59) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.36 Prec@5 88.59 Error@1 44.64 Error@5 11.41 Loss:1.781
***[2020-01-29 10:19:54]*** VALID [epoch=520/600] loss = 1.780552, accuracy@1 = 55.36, accuracy@5 = 88.59 | Best-Valid-Acc@1=56.27, Error@1=43.73
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:19:54]*** start epoch=521/600 Time Left: [00:42:17], LR=[0.004217 ~ 0.004217], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=521, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.30662664631807557, FLOP=40.81
[Search] : epoch=521/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:19:55] [epoch=521/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.522 (0.522)  Prec@1 82.81 (82.81) Prec@5 98.05 (98.05) Acls-loss 0.552 (0.552) FLOP-Loss 0.000 (0.000) Arch-Loss 0.552 (0.552)
**TRAIN** [2020-01-29 10:20:20] [epoch=521/600][097/098] Time 0.28 (0.27) Data 0.00 (0.00) Base-Loss 0.375 (0.455)  Prec@1 86.31 (84.38) Prec@5 99.40 (99.30) Acls-loss 0.517 (0.602) FLOP-Loss 0.000 (0.000) Arch-Loss 0.517 (0.602)
 **TRAIN** Prec@1 84.38 Prec@5 99.30 Error@1 15.62 Error@5 0.70 Base-Loss:0.455, Arch-Loss=0.602
***[2020-01-29 10:20:21]*** TRAIN [epoch=521/600] base-loss = 0.455022, arch-loss = 0.602408, accuracy-1 = 84.38, accuracy-5 = 99.30
[epoch=521/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.978624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.176 0.521 0.303  ||  -0.3205 0.7658 0.2248  || discrepancy=0.22 || select=1/3
001/003-th : 0.326 0.301 0.374  ||  0.1260 0.0455 0.2637  || discrepancy=0.05 || select=2/3
002/003-th : 0.005 0.031 0.964  ||  -2.3148 -0.5919 2.8556  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.014 0.016 0.017 0.022 0.032 0.064 0.826  ||  -1.476 -1.005 -0.845 -0.822 -0.549 -0.187 0.522 3.076  || dis=0.76 || select=7/8
001/019-th : 0.085 0.112 0.141 0.130 0.135 0.128 0.150 0.119  ||  -0.363 -0.096 0.136 0.056 0.091 0.041 0.200 -0.028    || dis=0.01 || select=6/8
002/019-th : 0.116 0.125 0.135 0.136 0.124 0.129 0.123 0.113  ||  -0.072 0.002 0.081 0.087 -0.005 0.033 -0.010 -0.099   || dis=0.00 || select=3/8
003/019-th : 0.113 0.116 0.124 0.130 0.126 0.135 0.132 0.124  ||  -0.105 -0.076 -0.013 0.036 0.005 0.076 0.056 -0.010   || dis=0.00 || select=5/8
004/019-th : 0.115 0.106 0.113 0.113 0.129 0.126 0.150 0.147  ||  -0.072 -0.159 -0.090 -0.089 0.043 0.013 0.188 0.171   || dis=0.00 || select=6/8
005/019-th : 0.137 0.135 0.123 0.125 0.129 0.125 0.116 0.110  ||  0.090 0.076 -0.015 0.001 0.030 0.002 -0.075 -0.125    || dis=0.00 || select=0/8
006/019-th : 0.153 0.145 0.128 0.121 0.119 0.119 0.112 0.104  ||  0.218 0.159 0.039 -0.023 -0.039 -0.039 -0.095 -0.173  || dis=0.01 || select=0/8
007/019-th : 0.007 0.010 0.013 0.016 0.025 0.033 0.061 0.834  ||  -1.548 -1.236 -0.961 -0.783 -0.347 -0.048 0.559 3.170  || dis=0.77 || select=7/8
008/019-th : 0.007 0.010 0.015 0.020 0.031 0.050 0.133 0.734  ||  -1.701 -1.441 -1.036 -0.691 -0.265 0.196 1.180 2.887  || dis=0.60 || select=7/8
009/019-th : 0.083 0.082 0.095 0.113 0.117 0.144 0.165 0.201  ||  -0.359 -0.366 -0.223 -0.053 -0.012 0.192 0.327 0.526  || dis=0.04 || select=7/8
010/019-th : 0.095 0.103 0.103 0.112 0.126 0.155 0.150 0.157  ||  -0.257 -0.177 -0.176 -0.092 0.027 0.234 0.201 0.246   || dis=0.00 || select=7/8
011/019-th : 0.127 0.117 0.117 0.121 0.127 0.130 0.130 0.130  ||  0.026 -0.056 -0.056 -0.025 0.027 0.049 0.048 0.048    || dis=0.00 || select=5/8
012/019-th : 0.156 0.140 0.129 0.124 0.124 0.108 0.111 0.108  ||  0.233 0.121 0.040 -0.000 -0.001 -0.133 -0.113 -0.133  || dis=0.02 || select=0/8
013/019-th : 0.003 0.004 0.004 0.005 0.005 0.007 0.009 0.962  ||  -1.111 -1.020 -0.931 -0.804 -0.714 -0.433 -0.123 4.509  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.019 0.946  ||  -1.382 -1.326 -0.984 -0.979 -0.664 -0.330 0.325 4.212  || dis=0.93 || select=7/8
015/019-th : 0.004 0.005 0.005 0.005 0.006 0.007 0.012 0.957  ||  -1.148 -0.761 -0.915 -0.892 -0.678 -0.483 0.057 4.443  || dis=0.94 || select=7/8
016/019-th : 0.030 0.036 0.041 0.061 0.095 0.165 0.238 0.334  ||  -1.090 -0.935 -0.790 -0.403 0.043 0.602 0.968 1.305   || dis=0.10 || select=7/8
017/019-th : 0.083 0.104 0.101 0.121 0.130 0.148 0.160 0.153  ||  -0.386 -0.160 -0.185 -0.006 0.063 0.192 0.270 0.228   || dis=0.01 || select=6/8
018/019-th : 0.097 0.107 0.128 0.126 0.137 0.127 0.131 0.146  ||  -0.243 -0.145 0.033 0.021 0.104 0.028 0.055 0.164     || dis=0.01 || select=7/8
[epoch=521/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.289
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:20:21] [epoch=521/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 2.374 (2.374)  Prec@1 40.62 (40.62) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:20:27] [epoch=521/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.582 (1.903)  Prec@1 82.14 (53.74) Prec@5 97.02 (87.62) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.74 Prec@5 87.62 Error@1 46.26 Error@5 12.38 Loss:1.903
***[2020-01-29 10:20:27]*** VALID [epoch=521/600] loss = 1.902931, accuracy@1 = 53.74, accuracy@5 = 87.62 | Best-Valid-Acc@1=56.27, Error@1=43.73
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:20:27]*** start epoch=522/600 Time Left: [00:41:45], LR=[0.004112 ~ 0.004112], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=522, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.30150116707424623, FLOP=40.81
[Search] : epoch=522/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:20:28] [epoch=522/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.407 (0.407)  Prec@1 85.55 (85.55) Prec@5 100.00 (100.00) Acls-loss 0.655 (0.655) FLOP-Loss 0.000 (0.000) Arch-Loss 0.655 (0.655)
**TRAIN** [2020-01-29 10:20:53] [epoch=522/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.445 (0.422)  Prec@1 83.33 (85.88) Prec@5 99.40 (99.42) Acls-loss 0.682 (0.593) FLOP-Loss 0.000 (0.123) Arch-Loss 0.682 (0.838)
 **TRAIN** Prec@1 85.88 Prec@5 99.42 Error@1 14.12 Error@5 0.58 Base-Loss:0.422, Arch-Loss=0.838
***[2020-01-29 10:20:53]*** TRAIN [epoch=522/600] base-loss = 0.421977, arch-loss = 0.838027, accuracy-1 = 85.88, accuracy-5 = 99.42
[epoch=522/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.978624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.173 0.525 0.302  ||  -0.3314 0.7809 0.2268  || discrepancy=0.22 || select=1/3
001/003-th : 0.332 0.296 0.372  ||  0.1408 0.0267 0.2560  || discrepancy=0.04 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.3072 -0.5969 2.8502  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.013 0.016 0.017 0.022 0.031 0.063 0.830  ||  -1.469 -1.035 -0.849 -0.817 -0.547 -0.198 0.513 3.098  || dis=0.77 || select=7/8
001/019-th : 0.086 0.111 0.140 0.130 0.135 0.127 0.152 0.119  ||  -0.357 -0.099 0.127 0.051 0.090 0.031 0.214 -0.030    || dis=0.01 || select=6/8
002/019-th : 0.117 0.125 0.133 0.136 0.124 0.128 0.125 0.112  ||  -0.065 0.005 0.066 0.084 -0.008 0.030 0.001 -0.104    || dis=0.00 || select=3/8
003/019-th : 0.112 0.117 0.125 0.130 0.124 0.137 0.131 0.124  ||  -0.111 -0.068 -0.005 0.040 -0.008 0.093 0.047 -0.013  || dis=0.01 || select=5/8
004/019-th : 0.116 0.105 0.114 0.113 0.128 0.123 0.154 0.148  ||  -0.071 -0.166 -0.084 -0.092 0.030 -0.011 0.215 0.174  || dis=0.01 || select=6/8
005/019-th : 0.135 0.136 0.120 0.125 0.129 0.126 0.118 0.111  ||  0.075 0.082 -0.039 0.002 0.036 0.009 -0.060 -0.114    || dis=0.00 || select=1/8
006/019-th : 0.152 0.144 0.128 0.122 0.120 0.118 0.112 0.104  ||  0.207 0.159 0.038 -0.008 -0.026 -0.042 -0.098 -0.173  || dis=0.01 || select=0/8
007/019-th : 0.007 0.010 0.013 0.016 0.024 0.032 0.060 0.838  ||  -1.542 -1.232 -0.968 -0.787 -0.362 -0.080 0.553 3.187  || dis=0.78 || select=7/8
008/019-th : 0.007 0.010 0.014 0.020 0.031 0.049 0.131 0.737  ||  -1.700 -1.450 -1.033 -0.697 -0.270 0.190 1.175 2.899  || dis=0.61 || select=7/8
009/019-th : 0.083 0.082 0.095 0.112 0.117 0.143 0.165 0.202  ||  -0.357 -0.365 -0.222 -0.058 -0.011 0.183 0.328 0.529  || dis=0.04 || select=7/8
010/019-th : 0.095 0.100 0.103 0.108 0.130 0.155 0.151 0.159  ||  -0.252 -0.205 -0.176 -0.120 0.058 0.236 0.210 0.261   || dis=0.00 || select=7/8
011/019-th : 0.128 0.116 0.117 0.121 0.128 0.131 0.130 0.130  ||  0.029 -0.062 -0.059 -0.026 0.028 0.054 0.045 0.046    || dis=0.00 || select=5/8
012/019-th : 0.156 0.140 0.127 0.125 0.124 0.108 0.111 0.109  ||  0.229 0.125 0.028 0.011 0.002 -0.135 -0.111 -0.130    || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.962  ||  -1.105 -1.017 -0.927 -0.800 -0.712 -0.432 -0.122 4.502  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.019 0.946  ||  -1.373 -1.323 -0.978 -0.975 -0.660 -0.328 0.296 4.216  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.006 0.007 0.012 0.959  ||  -1.157 -0.748 -0.933 -0.909 -0.673 -0.481 0.045 4.467  || dis=0.95 || select=7/8
016/019-th : 0.030 0.036 0.041 0.061 0.093 0.166 0.239 0.334  ||  -1.089 -0.933 -0.794 -0.397 0.027 0.608 0.970 1.308   || dis=0.10 || select=7/8
017/019-th : 0.083 0.101 0.103 0.120 0.130 0.150 0.158 0.155  ||  -0.387 -0.183 -0.171 -0.011 0.068 0.208 0.262 0.241   || dis=0.00 || select=6/8
018/019-th : 0.095 0.106 0.126 0.126 0.138 0.128 0.131 0.149  ||  -0.262 -0.150 0.021 0.020 0.113 0.031 0.056 0.187     || dis=0.01 || select=7/8
[epoch=522/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.290
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:20:53] [epoch=522/600][000/098] Time 0.39 (0.39) Data 0.28 (0.28) Loss 0.630 (0.630)  Prec@1 80.08 (80.08) Prec@5 98.05 (98.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:21:00] [epoch=522/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.380 (2.135)  Prec@1 26.19 (51.37) Prec@5 83.33 (87.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 51.37 Prec@5 87.72 Error@1 48.63 Error@5 12.28 Loss:2.135
***[2020-01-29 10:21:00]*** VALID [epoch=522/600] loss = 2.134895, accuracy@1 = 51.37, accuracy@5 = 87.72 | Best-Valid-Acc@1=56.27, Error@1=43.73
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:21:00]*** start epoch=523/600 Time Left: [00:41:13], LR=[0.004009 ~ 0.004009], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=523, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.2964373315617427, FLOP=40.81
[Search] : epoch=523/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:21:01] [epoch=523/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 0.265 (0.265)  Prec@1 91.80 (91.80) Prec@5 100.00 (100.00) Acls-loss 0.588 (0.588) FLOP-Loss 0.000 (0.000) Arch-Loss 0.588 (0.588)
**TRAIN** [2020-01-29 10:21:26] [epoch=523/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.314 (0.400)  Prec@1 91.67 (86.39) Prec@5 99.40 (99.36) Acls-loss 0.613 (0.588) FLOP-Loss 0.000 (0.000) Arch-Loss 0.613 (0.588)
 **TRAIN** Prec@1 86.39 Prec@5 99.36 Error@1 13.61 Error@5 0.64 Base-Loss:0.400, Arch-Loss=0.588
***[2020-01-29 10:21:26]*** TRAIN [epoch=523/600] base-loss = 0.399809, arch-loss = 0.587955, accuracy-1 = 86.39, accuracy-5 = 99.36
[epoch=523/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.978624)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.170 0.526 0.304  ||  -0.3450 0.7852 0.2348  || discrepancy=0.22 || select=1/3
001/003-th : 0.330 0.297 0.373  ||  0.1365 0.0292 0.2592  || discrepancy=0.04 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3244 -0.6002 2.8687  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.013 0.016 0.016 0.021 0.030 0.061 0.833  ||  -1.461 -1.029 -0.847 -0.831 -0.562 -0.200 0.498 3.111  || dis=0.77 || select=7/8
001/019-th : 0.085 0.111 0.139 0.125 0.138 0.128 0.155 0.120  ||  -0.371 -0.105 0.123 0.020 0.112 0.036 0.229 -0.022    || dis=0.02 || select=6/8
002/019-th : 0.116 0.124 0.134 0.136 0.123 0.128 0.126 0.113  ||  -0.070 -0.003 0.073 0.086 -0.013 0.028 0.009 -0.101   || dis=0.00 || select=3/8
003/019-th : 0.112 0.116 0.124 0.130 0.124 0.139 0.132 0.124  ||  -0.115 -0.073 -0.008 0.039 -0.013 0.102 0.050 -0.010  || dis=0.01 || select=5/8
004/019-th : 0.116 0.104 0.114 0.114 0.128 0.123 0.154 0.148  ||  -0.070 -0.173 -0.089 -0.088 0.028 -0.007 0.216 0.175  || dis=0.01 || select=6/8
005/019-th : 0.135 0.135 0.121 0.125 0.129 0.126 0.118 0.112  ||  0.074 0.075 -0.033 0.003 0.029 0.009 -0.053 -0.113    || dis=0.00 || select=1/8
006/019-th : 0.150 0.144 0.128 0.121 0.123 0.120 0.111 0.104  ||  0.196 0.155 0.036 -0.016 -0.004 -0.023 -0.101 -0.171  || dis=0.01 || select=0/8
007/019-th : 0.007 0.010 0.013 0.015 0.024 0.031 0.059 0.841  ||  -1.537 -1.228 -0.972 -0.798 -0.367 -0.099 0.539 3.204  || dis=0.78 || select=7/8
008/019-th : 0.007 0.009 0.014 0.020 0.029 0.048 0.126 0.747  ||  -1.747 -1.442 -1.025 -0.692 -0.315 0.204 1.167 2.943  || dis=0.62 || select=7/8
009/019-th : 0.083 0.082 0.095 0.112 0.117 0.143 0.166 0.201  ||  -0.355 -0.365 -0.224 -0.062 -0.017 0.185 0.335 0.528  || dis=0.04 || select=7/8
010/019-th : 0.096 0.100 0.102 0.109 0.130 0.153 0.151 0.160  ||  -0.247 -0.206 -0.180 -0.117 0.059 0.224 0.209 0.266   || dis=0.01 || select=7/8
011/019-th : 0.126 0.115 0.117 0.122 0.127 0.133 0.131 0.130  ||  0.016 -0.079 -0.061 -0.019 0.025 0.071 0.055 0.047    || dis=0.00 || select=5/8
012/019-th : 0.155 0.139 0.127 0.125 0.123 0.109 0.112 0.110  ||  0.225 0.117 0.021 0.006 -0.012 -0.125 -0.105 -0.119   || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.962  ||  -1.099 -1.012 -0.924 -0.796 -0.710 -0.437 -0.143 4.506  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.947  ||  -1.365 -1.329 -0.982 -0.987 -0.657 -0.327 0.291 4.227  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.006 0.007 0.011 0.958  ||  -1.151 -0.735 -0.928 -0.907 -0.668 -0.479 0.037 4.462  || dis=0.95 || select=7/8
016/019-th : 0.030 0.035 0.041 0.061 0.092 0.167 0.238 0.336  ||  -1.100 -0.941 -0.783 -0.396 0.020 0.615 0.968 1.315   || dis=0.10 || select=7/8
017/019-th : 0.083 0.101 0.102 0.121 0.130 0.151 0.157 0.155  ||  -0.387 -0.186 -0.174 -0.008 0.068 0.217 0.255 0.244   || dis=0.00 || select=6/8
018/019-th : 0.093 0.105 0.124 0.128 0.140 0.128 0.131 0.152  ||  -0.281 -0.163 0.001 0.034 0.127 0.035 0.062 0.205     || dis=0.01 || select=7/8
[epoch=523/600] FLOP : 27.98 MB, ratio : 0.6855, Expected-ratio : 0.7000, Discrepancy : 0.292
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:21:26] [epoch=523/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 0.588 (0.588)  Prec@1 80.86 (80.86) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:21:32] [epoch=523/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.912 (1.917)  Prec@1 70.24 (55.63) Prec@5 96.43 (88.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.63 Prec@5 88.54 Error@1 44.37 Error@5 11.46 Loss:1.917
***[2020-01-29 10:21:33]*** VALID [epoch=523/600] loss = 1.916654, accuracy@1 = 55.63, accuracy@5 = 88.54 | Best-Valid-Acc@1=56.27, Error@1=43.73
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:21:33]*** start epoch=524/600 Time Left: [00:40:41], LR=[0.003907 ~ 0.003907], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=524, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.29143527860817403, FLOP=40.81
[Search] : epoch=524/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:21:33] [epoch=524/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.470 (0.470)  Prec@1 82.81 (82.81) Prec@5 98.83 (98.83) Acls-loss 0.539 (0.539) FLOP-Loss 0.000 (0.000) Arch-Loss 0.539 (0.539)
**TRAIN** [2020-01-29 10:21:58] [epoch=524/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.714 (0.433)  Prec@1 77.38 (85.36) Prec@5 98.81 (99.32) Acls-loss 0.782 (0.580) FLOP-Loss 0.000 (0.000) Arch-Loss 0.782 (0.580)
 **TRAIN** Prec@1 85.36 Prec@5 99.32 Error@1 14.64 Error@5 0.68 Base-Loss:0.433, Arch-Loss=0.580
***[2020-01-29 10:21:58]*** TRAIN [epoch=524/600] base-loss = 0.432884, arch-loss = 0.580036, accuracy-1 = 85.36, accuracy-5 = 99.32
[epoch=524/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.166 0.530 0.303  ||  -0.3602 0.7985 0.2407  || discrepancy=0.23 || select=1/3
001/003-th : 0.327 0.299 0.375  ||  0.1272 0.0377 0.2654  || discrepancy=0.05 || select=2/3
002/003-th : 0.005 0.029 0.965  ||  -2.3176 -0.6244 2.8683  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.013 0.016 0.016 0.021 0.030 0.059 0.838  ||  -1.454 -1.042 -0.839 -0.845 -0.557 -0.212 0.477 3.133  || dis=0.78 || select=7/8
001/019-th : 0.085 0.110 0.139 0.125 0.137 0.127 0.155 0.122  ||  -0.373 -0.110 0.124 0.017 0.107 0.032 0.230 -0.010    || dis=0.02 || select=6/8
002/019-th : 0.115 0.123 0.133 0.137 0.124 0.129 0.127 0.113  ||  -0.081 -0.011 0.066 0.097 -0.007 0.036 0.017 -0.097   || dis=0.00 || select=3/8
003/019-th : 0.112 0.117 0.123 0.127 0.123 0.140 0.132 0.126  ||  -0.117 -0.069 -0.018 0.013 -0.018 0.109 0.049 0.006   || dis=0.01 || select=5/8
004/019-th : 0.114 0.103 0.112 0.115 0.126 0.124 0.157 0.149  ||  -0.083 -0.183 -0.103 -0.078 0.015 -0.000 0.234 0.184  || dis=0.01 || select=6/8
005/019-th : 0.132 0.133 0.120 0.126 0.127 0.126 0.121 0.114  ||  0.058 0.065 -0.042 0.006 0.020 0.011 -0.033 -0.092    || dis=0.00 || select=1/8
006/019-th : 0.148 0.142 0.126 0.123 0.125 0.119 0.113 0.104  ||  0.183 0.143 0.026 -0.003 0.018 -0.030 -0.088 -0.171   || dis=0.01 || select=0/8
007/019-th : 0.007 0.010 0.012 0.015 0.023 0.030 0.057 0.846  ||  -1.531 -1.237 -0.987 -0.797 -0.393 -0.099 0.531 3.231  || dis=0.79 || select=7/8
008/019-th : 0.007 0.009 0.014 0.019 0.028 0.047 0.124 0.752  ||  -1.754 -1.452 -1.018 -0.695 -0.318 0.199 1.157 2.962  || dis=0.63 || select=7/8
009/019-th : 0.083 0.082 0.095 0.110 0.118 0.140 0.170 0.201  ||  -0.353 -0.366 -0.224 -0.075 -0.009 0.163 0.358 0.527  || dis=0.03 || select=7/8
010/019-th : 0.094 0.099 0.102 0.110 0.128 0.152 0.151 0.163  ||  -0.268 -0.209 -0.183 -0.102 0.049 0.218 0.214 0.287   || dis=0.01 || select=7/8
011/019-th : 0.125 0.113 0.115 0.121 0.127 0.134 0.135 0.130  ||  0.006 -0.093 -0.073 -0.027 0.025 0.080 0.087 0.049    || dis=0.00 || select=6/8
012/019-th : 0.155 0.139 0.126 0.125 0.123 0.110 0.112 0.110  ||  0.221 0.113 0.015 0.007 -0.007 -0.116 -0.104 -0.117   || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.094 -1.006 -0.925 -0.791 -0.710 -0.438 -0.178 4.519  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.947  ||  -1.360 -1.327 -0.977 -0.984 -0.678 -0.334 0.287 4.235  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.006 0.007 0.011 0.959  ||  -1.146 -0.721 -0.938 -0.915 -0.675 -0.477 0.032 4.472  || dis=0.95 || select=7/8
016/019-th : 0.030 0.035 0.041 0.061 0.091 0.166 0.239 0.336  ||  -1.094 -0.940 -0.795 -0.392 0.014 0.612 0.977 1.316   || dis=0.10 || select=7/8
017/019-th : 0.082 0.099 0.103 0.119 0.131 0.151 0.159 0.156  ||  -0.396 -0.201 -0.168 -0.017 0.079 0.220 0.271 0.249   || dis=0.00 || select=6/8
018/019-th : 0.092 0.105 0.123 0.127 0.141 0.128 0.132 0.153  ||  -0.295 -0.165 -0.005 0.031 0.134 0.034 0.070 0.216    || dis=0.01 || select=7/8
[epoch=524/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.293
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:21:59] [epoch=524/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.202 (1.202)  Prec@1 66.41 (66.41) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:22:05] [epoch=524/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.205 (2.103)  Prec@1 54.17 (52.30) Prec@5 91.67 (86.37) Size=[168, 3, 32, 32]
 **VALID** Prec@1 52.30 Prec@5 86.37 Error@1 47.70 Error@5 13.63 Loss:2.103
***[2020-01-29 10:22:05]*** VALID [epoch=524/600] loss = 2.103235, accuracy@1 = 52.30, accuracy@5 = 86.37 | Best-Valid-Acc@1=56.27, Error@1=43.73
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:22:05]*** start epoch=525/600 Time Left: [00:40:08], LR=[0.003806 ~ 0.003806], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=525, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.28649514534734755, FLOP=40.81
[Search] : epoch=525/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:22:06] [epoch=525/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.667 (0.667)  Prec@1 78.12 (78.12) Prec@5 98.44 (98.44) Acls-loss 0.747 (0.747) FLOP-Loss 0.000 (0.000) Arch-Loss 0.747 (0.747)
**TRAIN** [2020-01-29 10:22:32] [epoch=525/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.310 (0.404)  Prec@1 92.26 (86.46) Prec@5 99.40 (99.42) Acls-loss 0.546 (0.555) FLOP-Loss 0.000 (0.000) Arch-Loss 0.546 (0.555)
 **TRAIN** Prec@1 86.46 Prec@5 99.42 Error@1 13.54 Error@5 0.58 Base-Loss:0.404, Arch-Loss=0.555
***[2020-01-29 10:22:32]*** TRAIN [epoch=525/600] base-loss = 0.403784, arch-loss = 0.554813, accuracy-1 = 86.46, accuracy-5 = 99.42
[epoch=525/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.165 0.531 0.303  ||  -0.3661 0.8023 0.2418  || discrepancy=0.23 || select=1/3
001/003-th : 0.324 0.299 0.377  ||  0.1210 0.0402 0.2707  || discrepancy=0.05 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3136 -0.6221 2.8639  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.013 0.016 0.015 0.021 0.029 0.057 0.841  ||  -1.445 -1.045 -0.831 -0.848 -0.561 -0.229 0.454 3.149  || dis=0.78 || select=7/8
001/019-th : 0.084 0.110 0.138 0.124 0.138 0.128 0.155 0.123  ||  -0.380 -0.109 0.113 0.012 0.112 0.041 0.230 -0.002    || dis=0.02 || select=6/8
002/019-th : 0.113 0.121 0.133 0.135 0.124 0.131 0.129 0.114  ||  -0.098 -0.028 0.069 0.081 -0.002 0.051 0.034 -0.086   || dis=0.00 || select=3/8
003/019-th : 0.111 0.116 0.122 0.125 0.126 0.140 0.133 0.127  ||  -0.124 -0.080 -0.024 -0.001 0.005 0.112 0.058 0.014   || dis=0.01 || select=5/8
004/019-th : 0.112 0.104 0.113 0.114 0.126 0.124 0.159 0.149  ||  -0.101 -0.180 -0.094 -0.088 0.015 0.000 0.249 0.186   || dis=0.01 || select=6/8
005/019-th : 0.130 0.133 0.119 0.128 0.127 0.127 0.121 0.115  ||  0.040 0.063 -0.044 0.025 0.020 0.015 -0.030 -0.085    || dis=0.00 || select=1/8
006/019-th : 0.148 0.141 0.126 0.123 0.126 0.121 0.113 0.103  ||  0.185 0.137 0.022 -0.002 0.020 -0.020 -0.086 -0.178   || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.015 0.022 0.029 0.055 0.850  ||  -1.526 -1.262 -0.983 -0.791 -0.397 -0.120 0.522 3.253  || dis=0.79 || select=7/8
008/019-th : 0.007 0.009 0.014 0.019 0.028 0.047 0.121 0.755  ||  -1.762 -1.447 -1.009 -0.693 -0.326 0.194 1.144 2.975  || dis=0.63 || select=7/8
009/019-th : 0.084 0.083 0.094 0.110 0.118 0.141 0.169 0.201  ||  -0.350 -0.361 -0.230 -0.077 -0.008 0.168 0.351 0.526  || dis=0.03 || select=7/8
010/019-th : 0.093 0.099 0.102 0.111 0.128 0.154 0.150 0.163  ||  -0.274 -0.209 -0.181 -0.100 0.050 0.234 0.202 0.289   || dis=0.01 || select=7/8
011/019-th : 0.124 0.113 0.116 0.120 0.128 0.134 0.135 0.131  ||  0.001 -0.094 -0.067 -0.036 0.032 0.078 0.086 0.053    || dis=0.00 || select=6/8
012/019-th : 0.155 0.140 0.124 0.123 0.125 0.111 0.112 0.111  ||  0.219 0.117 0.003 -0.009 0.007 -0.113 -0.103 -0.115   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.087 -1.024 -0.925 -0.786 -0.717 -0.436 -0.179 4.527  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.948  ||  -1.351 -1.324 -0.999 -0.980 -0.675 -0.334 0.276 4.245  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.006 0.007 0.011 0.959  ||  -1.144 -0.707 -0.934 -0.913 -0.674 -0.491 0.014 4.478  || dis=0.95 || select=7/8
016/019-th : 0.029 0.035 0.040 0.059 0.091 0.167 0.242 0.338  ||  -1.109 -0.947 -0.813 -0.414 0.015 0.626 0.996 1.332   || dis=0.10 || select=7/8
017/019-th : 0.081 0.098 0.102 0.119 0.133 0.151 0.159 0.155  ||  -0.399 -0.209 -0.170 -0.016 0.096 0.221 0.275 0.248   || dis=0.00 || select=6/8
018/019-th : 0.092 0.105 0.123 0.129 0.141 0.125 0.132 0.153  ||  -0.294 -0.164 -0.002 0.043 0.135 0.017 0.066 0.218    || dis=0.01 || select=7/8
[epoch=525/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.294
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:22:32] [epoch=525/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.665 (0.665)  Prec@1 78.12 (78.12) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:22:38] [epoch=525/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 5.155 (1.640)  Prec@1 14.29 (57.53) Prec@5 68.45 (89.08) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.53 Prec@5 89.08 Error@1 42.47 Error@5 10.92 Loss:1.640
***[2020-01-29 10:22:38]*** VALID [epoch=525/600] loss = 1.639757, accuracy@1 = 57.53, accuracy@5 = 89.08 | Best-Valid-Acc@1=56.27, Error@1=43.73
Currently, the best validation accuracy found at 525-epoch :: acc@1=57.53, acc@5=89.08, error@1=42.47, error@5=10.92, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:22:39]*** start epoch=526/600 Time Left: [00:39:37], LR=[0.003706 ~ 0.003706], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=526, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.28161706721551294, FLOP=40.81
[Search] : epoch=526/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:22:39] [epoch=526/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.304 (0.304)  Prec@1 90.23 (90.23) Prec@5 100.00 (100.00) Acls-loss 0.534 (0.534) FLOP-Loss 0.000 (0.000) Arch-Loss 0.534 (0.534)
**TRAIN** [2020-01-29 10:23:04] [epoch=526/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.342 (0.408)  Prec@1 86.31 (86.06) Prec@5 100.00 (99.44) Acls-loss 0.564 (0.551) FLOP-Loss 0.000 (0.000) Arch-Loss 0.564 (0.551)
 **TRAIN** Prec@1 86.06 Prec@5 99.44 Error@1 13.94 Error@5 0.56 Base-Loss:0.408, Arch-Loss=0.551
***[2020-01-29 10:23:04]*** TRAIN [epoch=526/600] base-loss = 0.408222, arch-loss = 0.550872, accuracy-1 = 86.06, accuracy-5 = 99.44
[epoch=526/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.163 0.534 0.303  ||  -0.3743 0.8114 0.2429  || discrepancy=0.23 || select=1/3
001/003-th : 0.324 0.298 0.378  ||  0.1191 0.0373 0.2733  || discrepancy=0.05 || select=2/3
002/003-th : 0.005 0.029 0.965  ||  -2.3162 -0.6215 2.8665  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.009 0.013 0.016 0.016 0.021 0.029 0.056 0.842  ||  -1.442 -1.039 -0.831 -0.842 -0.550 -0.226 0.436 3.148  || dis=0.79 || select=7/8
001/019-th : 0.084 0.110 0.138 0.124 0.135 0.130 0.156 0.123  ||  -0.383 -0.114 0.114 0.008 0.095 0.059 0.237 -0.002    || dis=0.02 || select=6/8
002/019-th : 0.113 0.120 0.134 0.135 0.124 0.130 0.129 0.115  ||  -0.099 -0.034 0.074 0.084 -0.003 0.044 0.035 -0.080   || dis=0.00 || select=3/8
003/019-th : 0.108 0.116 0.122 0.125 0.127 0.140 0.133 0.129  ||  -0.145 -0.077 -0.024 -0.000 0.012 0.113 0.061 0.027   || dis=0.01 || select=5/8
004/019-th : 0.110 0.104 0.112 0.116 0.126 0.124 0.160 0.149  ||  -0.116 -0.176 -0.101 -0.069 0.020 -0.000 0.254 0.184  || dis=0.01 || select=6/8
005/019-th : 0.130 0.133 0.118 0.128 0.126 0.128 0.122 0.115  ||  0.042 0.060 -0.055 0.024 0.011 0.022 -0.023 -0.079    || dis=0.00 || select=1/8
006/019-th : 0.148 0.141 0.124 0.123 0.127 0.120 0.114 0.104  ||  0.181 0.135 0.007 -0.002 0.029 -0.024 -0.081 -0.173   || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.015 0.022 0.029 0.055 0.850  ||  -1.519 -1.258 -0.982 -0.787 -0.395 -0.138 0.517 3.255  || dis=0.79 || select=7/8
008/019-th : 0.007 0.009 0.014 0.019 0.028 0.046 0.119 0.758  ||  -1.760 -1.440 -1.004 -0.707 -0.326 0.189 1.130 2.982  || dis=0.64 || select=7/8
009/019-th : 0.084 0.083 0.094 0.109 0.118 0.141 0.169 0.202  ||  -0.346 -0.359 -0.236 -0.088 -0.006 0.169 0.349 0.529  || dis=0.03 || select=7/8
010/019-th : 0.092 0.099 0.102 0.110 0.128 0.155 0.149 0.164  ||  -0.282 -0.209 -0.181 -0.103 0.048 0.238 0.201 0.296   || dis=0.01 || select=7/8
011/019-th : 0.124 0.113 0.115 0.120 0.128 0.134 0.135 0.131  ||  -0.002 -0.096 -0.073 -0.029 0.031 0.079 0.085 0.056   || dis=0.00 || select=6/8
012/019-th : 0.153 0.139 0.123 0.124 0.125 0.113 0.112 0.111  ||  0.213 0.115 -0.011 0.001 0.008 -0.097 -0.103 -0.112   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.081 -1.020 -0.922 -0.782 -0.714 -0.445 -0.178 4.524  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.948  ||  -1.342 -1.323 -0.996 -0.976 -0.692 -0.333 0.293 4.241  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.006 0.007 0.011 0.959  ||  -1.138 -0.708 -0.944 -0.911 -0.667 -0.491 0.009 4.480  || dis=0.95 || select=7/8
016/019-th : 0.030 0.034 0.039 0.059 0.091 0.165 0.243 0.338  ||  -1.100 -0.954 -0.817 -0.410 0.023 0.614 1.003 1.332   || dis=0.10 || select=7/8
017/019-th : 0.080 0.097 0.101 0.119 0.134 0.151 0.162 0.156  ||  -0.407 -0.222 -0.177 -0.015 0.105 0.220 0.291 0.255   || dis=0.01 || select=6/8
018/019-th : 0.092 0.104 0.123 0.132 0.140 0.126 0.132 0.150  ||  -0.292 -0.168 0.002 0.073 0.131 0.022 0.071 0.195     || dis=0.01 || select=7/8
[epoch=526/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.295
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:23:04] [epoch=526/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.758 (2.758)  Prec@1 31.64 (31.64) Prec@5 78.52 (78.52) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:23:11] [epoch=526/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.202 (1.812)  Prec@1 70.24 (54.56) Prec@5 98.21 (88.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 54.56 Prec@5 88.58 Error@1 45.44 Error@5 11.42 Loss:1.812
***[2020-01-29 10:23:11]*** VALID [epoch=526/600] loss = 1.812499, accuracy@1 = 54.56, accuracy@5 = 88.58 | Best-Valid-Acc@1=57.53, Error@1=42.47
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:23:11]*** start epoch=527/600 Time Left: [00:39:04], LR=[0.003608 ~ 0.003608], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=527, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.2768011779476463, FLOP=40.81
[Search] : epoch=527/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:23:12] [epoch=527/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 1.254 (1.254)  Prec@1 66.41 (66.41) Prec@5 95.70 (95.70) Acls-loss 0.519 (0.519) FLOP-Loss 0.000 (0.000) Arch-Loss 0.519 (0.519)
**TRAIN** [2020-01-29 10:23:36] [epoch=527/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.577 (0.458)  Prec@1 79.17 (84.42) Prec@5 98.81 (99.23) Acls-loss 0.398 (0.574) FLOP-Loss 0.000 (0.000) Arch-Loss 0.398 (0.574)
 **TRAIN** Prec@1 84.42 Prec@5 99.23 Error@1 15.58 Error@5 0.77 Base-Loss:0.458, Arch-Loss=0.574
***[2020-01-29 10:23:36]*** TRAIN [epoch=527/600] base-loss = 0.458380, arch-loss = 0.573816, accuracy-1 = 84.42, accuracy-5 = 99.23
[epoch=527/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.99168)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.164 0.532 0.304  ||  -0.3758 0.8031 0.2453  || discrepancy=0.23 || select=1/3
001/003-th : 0.322 0.298 0.380  ||  0.1126 0.0369 0.2803  || discrepancy=0.06 || select=2/3
002/003-th : 0.005 0.030 0.965  ||  -2.3118 -0.6138 2.8604  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.013 0.015 0.015 0.021 0.028 0.056 0.844  ||  -1.443 -1.043 -0.853 -0.836 -0.553 -0.228 0.441 3.162  || dis=0.79 || select=7/8
001/019-th : 0.083 0.108 0.136 0.123 0.136 0.130 0.160 0.125  ||  -0.393 -0.131 0.100 0.001 0.098 0.055 0.260 0.015     || dis=0.02 || select=6/8
002/019-th : 0.111 0.120 0.134 0.133 0.126 0.130 0.130 0.115  ||  -0.111 -0.033 0.071 0.071 0.015 0.043 0.045 -0.078    || dis=0.00 || select=2/8
003/019-th : 0.107 0.115 0.121 0.123 0.128 0.139 0.135 0.131  ||  -0.155 -0.083 -0.038 -0.015 0.025 0.107 0.078 0.042   || dis=0.00 || select=5/8
004/019-th : 0.110 0.104 0.112 0.116 0.128 0.123 0.159 0.149  ||  -0.118 -0.177 -0.102 -0.067 0.030 -0.003 0.249 0.187  || dis=0.01 || select=6/8
005/019-th : 0.130 0.133 0.118 0.127 0.125 0.127 0.124 0.117  ||  0.036 0.060 -0.060 0.015 -0.004 0.019 -0.008 -0.063   || dis=0.00 || select=1/8
006/019-th : 0.147 0.140 0.122 0.122 0.129 0.120 0.114 0.105  ||  0.178 0.129 -0.008 -0.007 0.042 -0.026 -0.078 -0.166  || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.015 0.022 0.029 0.054 0.851  ||  -1.513 -1.260 -0.978 -0.791 -0.393 -0.137 0.510 3.260  || dis=0.80 || select=7/8
008/019-th : 0.007 0.009 0.014 0.019 0.028 0.046 0.117 0.760  ||  -1.757 -1.433 -1.005 -0.712 -0.326 0.184 1.115 2.986  || dis=0.64 || select=7/8
009/019-th : 0.084 0.083 0.094 0.109 0.118 0.140 0.168 0.203  ||  -0.349 -0.357 -0.233 -0.089 -0.005 0.162 0.346 0.535  || dis=0.04 || select=7/8
010/019-th : 0.092 0.098 0.103 0.111 0.128 0.155 0.149 0.164  ||  -0.287 -0.215 -0.172 -0.096 0.049 0.239 0.203 0.295   || dis=0.01 || select=7/8
011/019-th : 0.124 0.113 0.115 0.120 0.128 0.133 0.135 0.132  ||  -0.002 -0.093 -0.075 -0.033 0.029 0.072 0.085 0.065   || dis=0.00 || select=6/8
012/019-th : 0.151 0.138 0.122 0.123 0.127 0.115 0.113 0.112  ||  0.195 0.103 -0.021 -0.009 0.023 -0.074 -0.093 -0.102  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.074 -1.015 -0.917 -0.798 -0.711 -0.443 -0.178 4.523  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.949  ||  -1.333 -1.335 -1.003 -0.992 -0.693 -0.331 0.286 4.263  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.011 0.961  ||  -1.151 -0.721 -0.940 -0.927 -0.686 -0.489 -0.005 4.507  || dis=0.95 || select=7/8
016/019-th : 0.030 0.034 0.039 0.060 0.091 0.164 0.243 0.338  ||  -1.093 -0.957 -0.817 -0.400 0.021 0.608 1.001 1.330   || dis=0.10 || select=7/8
017/019-th : 0.078 0.097 0.099 0.120 0.133 0.150 0.163 0.160  ||  -0.438 -0.220 -0.196 -0.007 0.097 0.220 0.298 0.280   || dis=0.00 || select=6/8
018/019-th : 0.093 0.105 0.124 0.133 0.140 0.125 0.132 0.149  ||  -0.283 -0.159 0.002 0.073 0.124 0.017 0.065 0.191     || dis=0.01 || select=7/8
[epoch=527/600] FLOP : 27.99 MB, ratio : 0.6858, Expected-ratio : 0.7000, Discrepancy : 0.295
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:23:36] [epoch=527/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.729 (0.729)  Prec@1 74.61 (74.61) Prec@5 98.05 (98.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:23:42] [epoch=527/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.124 (1.744)  Prec@1 67.86 (55.85) Prec@5 97.62 (89.22) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.85 Prec@5 89.22 Error@1 44.15 Error@5 10.78 Loss:1.744
***[2020-01-29 10:23:42]*** VALID [epoch=527/600] loss = 1.744241, accuracy@1 = 55.85, accuracy@5 = 89.22 | Best-Valid-Acc@1=57.53, Error@1=42.47
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:23:43]*** start epoch=528/600 Time Left: [00:38:32], LR=[0.003511 ~ 0.003511], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=528, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.2720476095737842, FLOP=40.81
[Search] : epoch=528/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:23:43] [epoch=528/600][000/098] Time 0.63 (0.63) Data 0.36 (0.36) Base-Loss 0.359 (0.359)  Prec@1 88.67 (88.67) Prec@5 99.61 (99.61) Acls-loss 0.463 (0.463) FLOP-Loss 0.000 (0.000) Arch-Loss 0.463 (0.463)
**TRAIN** [2020-01-29 10:24:08] [epoch=528/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.401 (0.470)  Prec@1 88.69 (84.00) Prec@5 99.40 (99.11) Acls-loss 0.530 (0.581) FLOP-Loss 0.000 (0.000) Arch-Loss 0.530 (0.581)
 **TRAIN** Prec@1 84.00 Prec@5 99.11 Error@1 16.00 Error@5 0.89 Base-Loss:0.470, Arch-Loss=0.581
***[2020-01-29 10:24:08]*** TRAIN [epoch=528/600] base-loss = 0.469858, arch-loss = 0.581473, accuracy-1 = 84.00, accuracy-5 = 99.11
[epoch=528/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.99168)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.160 0.534 0.305  ||  -0.3912 0.8124 0.2519  || discrepancy=0.23 || select=1/3
001/003-th : 0.319 0.299 0.382  ||  0.1054 0.0391 0.2867  || discrepancy=0.06 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3060 -0.6065 2.8531  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.012 0.015 0.015 0.020 0.027 0.053 0.850  ||  -1.462 -1.048 -0.865 -0.846 -0.569 -0.237 0.434 3.204  || dis=0.80 || select=7/8
001/019-th : 0.083 0.109 0.133 0.123 0.134 0.132 0.162 0.125  ||  -0.399 -0.124 0.080 0.002 0.084 0.071 0.273 0.012     || dis=0.03 || select=6/8
002/019-th : 0.111 0.119 0.133 0.132 0.126 0.131 0.131 0.117  ||  -0.113 -0.043 0.062 0.059 0.011 0.051 0.050 -0.063    || dis=0.00 || select=2/8
003/019-th : 0.107 0.114 0.121 0.123 0.124 0.140 0.138 0.132  ||  -0.159 -0.096 -0.031 -0.016 -0.008 0.112 0.099 0.051  || dis=0.00 || select=5/8
004/019-th : 0.108 0.104 0.112 0.115 0.127 0.125 0.160 0.149  ||  -0.135 -0.172 -0.103 -0.068 0.029 0.007 0.257 0.186   || dis=0.01 || select=6/8
005/019-th : 0.131 0.130 0.119 0.126 0.124 0.127 0.125 0.118  ||  0.041 0.041 -0.051 0.005 -0.013 0.014 0.001 -0.058    || dis=0.00 || select=0/8
006/019-th : 0.146 0.140 0.123 0.123 0.129 0.119 0.115 0.105  ||  0.172 0.125 -0.000 -0.004 0.046 -0.038 -0.073 -0.163  || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.015 0.021 0.028 0.054 0.853  ||  -1.507 -1.259 -0.973 -0.797 -0.415 -0.142 0.507 3.270  || dis=0.80 || select=7/8
008/019-th : 0.007 0.009 0.014 0.019 0.028 0.045 0.112 0.766  ||  -1.752 -1.425 -0.997 -0.714 -0.328 0.172 1.077 2.997  || dis=0.65 || select=7/8
009/019-th : 0.084 0.083 0.093 0.109 0.118 0.140 0.166 0.206  ||  -0.352 -0.355 -0.249 -0.085 -0.010 0.163 0.336 0.551  || dis=0.04 || select=7/8
010/019-th : 0.090 0.098 0.103 0.111 0.128 0.154 0.151 0.166  ||  -0.305 -0.222 -0.172 -0.091 0.046 0.232 0.216 0.309   || dis=0.01 || select=7/8
011/019-th : 0.124 0.112 0.114 0.120 0.129 0.133 0.135 0.132  ||  -0.001 -0.101 -0.081 -0.033 0.038 0.073 0.086 0.066   || dis=0.00 || select=6/8
012/019-th : 0.149 0.136 0.122 0.124 0.127 0.116 0.114 0.113  ||  0.186 0.093 -0.020 -0.003 0.024 -0.070 -0.084 -0.097  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.067 -1.016 -0.916 -0.793 -0.709 -0.465 -0.177 4.529  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.949  ||  -1.323 -1.332 -1.000 -0.989 -0.692 -0.337 0.285 4.259  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.962  ||  -1.145 -0.782 -0.935 -0.925 -0.704 -0.487 -0.028 4.532  || dis=0.95 || select=7/8
016/019-th : 0.030 0.035 0.039 0.060 0.091 0.164 0.241 0.340  ||  -1.091 -0.950 -0.819 -0.406 0.020 0.609 0.991 1.337   || dis=0.10 || select=7/8
017/019-th : 0.078 0.096 0.100 0.119 0.132 0.150 0.164 0.160  ||  -0.433 -0.234 -0.188 -0.011 0.092 0.219 0.308 0.283   || dis=0.00 || select=6/8
018/019-th : 0.092 0.104 0.124 0.135 0.138 0.125 0.132 0.150  ||  -0.296 -0.168 0.011 0.090 0.112 0.016 0.069 0.197     || dis=0.01 || select=7/8
[epoch=528/600] FLOP : 27.99 MB, ratio : 0.6858, Expected-ratio : 0.7000, Discrepancy : 0.297
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:24:08] [epoch=528/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.599 (0.599)  Prec@1 79.69 (79.69) Prec@5 98.05 (98.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:24:14] [epoch=528/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.990 (2.058)  Prec@1 65.48 (49.88) Prec@5 97.02 (85.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 49.88 Prec@5 85.80 Error@1 50.12 Error@5 14.20 Loss:2.058
***[2020-01-29 10:24:15]*** VALID [epoch=528/600] loss = 2.058298, accuracy@1 = 49.88, accuracy@5 = 85.80 | Best-Valid-Acc@1=57.53, Error@1=42.47
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:24:15]*** start epoch=529/600 Time Left: [00:38:00], LR=[0.003415 ~ 0.003415], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=529, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.2673564924154052, FLOP=40.81
[Search] : epoch=529/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:24:15] [epoch=529/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.336 (0.336)  Prec@1 88.67 (88.67) Prec@5 99.61 (99.61) Acls-loss 0.554 (0.554) FLOP-Loss 0.000 (0.000) Arch-Loss 0.554 (0.554)
**TRAIN** [2020-01-29 10:24:40] [epoch=529/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.371 (0.402)  Prec@1 85.12 (86.11) Prec@5 100.00 (99.46) Acls-loss 0.692 (0.589) FLOP-Loss 3.010 (0.020) Arch-Loss 6.712 (0.630)
 **TRAIN** Prec@1 86.11 Prec@5 99.46 Error@1 13.89 Error@5 0.54 Base-Loss:0.402, Arch-Loss=0.630
***[2020-01-29 10:24:40]*** TRAIN [epoch=529/600] base-loss = 0.402437, arch-loss = 0.629510, accuracy-1 = 86.11, accuracy-5 = 99.46
[epoch=529/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.412992)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.158 0.535 0.307  ||  -0.4038 0.8146 0.2593  || discrepancy=0.23 || select=1/3
001/003-th : 0.318 0.300 0.383  ||  0.1018 0.0437 0.2878  || discrepancy=0.07 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3099 -0.6037 2.8564  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.012 0.014 0.014 0.019 0.026 0.051 0.856  ||  -1.464 -1.057 -0.883 -0.857 -0.578 -0.248 0.423 3.238  || dis=0.80 || select=7/8
001/019-th : 0.082 0.109 0.133 0.123 0.134 0.131 0.162 0.125  ||  -0.409 -0.124 0.082 -0.001 0.088 0.067 0.277 0.019    || dis=0.03 || select=6/8
002/019-th : 0.109 0.117 0.133 0.131 0.126 0.130 0.134 0.119  ||  -0.131 -0.066 0.069 0.051 0.012 0.047 0.073 -0.044    || dis=0.00 || select=6/8
003/019-th : 0.107 0.114 0.121 0.122 0.123 0.141 0.138 0.134  ||  -0.155 -0.096 -0.040 -0.024 -0.017 0.117 0.093 0.063  || dis=0.00 || select=5/8
004/019-th : 0.108 0.104 0.111 0.117 0.126 0.123 0.160 0.151  ||  -0.135 -0.170 -0.111 -0.058 0.021 -0.003 0.257 0.196  || dis=0.01 || select=6/8
005/019-th : 0.129 0.131 0.119 0.124 0.124 0.129 0.126 0.119  ||  0.034 0.046 -0.054 -0.007 -0.013 0.026 0.003 -0.051   || dis=0.00 || select=1/8
006/019-th : 0.146 0.140 0.123 0.123 0.129 0.119 0.115 0.104  ||  0.166 0.125 0.000 -0.001 0.044 -0.032 -0.068 -0.166   || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.015 0.021 0.028 0.054 0.853  ||  -1.503 -1.255 -0.980 -0.787 -0.419 -0.140 0.507 3.269  || dis=0.80 || select=7/8
008/019-th : 0.007 0.009 0.014 0.019 0.028 0.044 0.110 0.771  ||  -1.752 -1.449 -1.013 -0.713 -0.316 0.161 1.066 3.017  || dis=0.66 || select=7/8
009/019-th : 0.082 0.083 0.090 0.110 0.119 0.141 0.168 0.207  ||  -0.366 -0.357 -0.277 -0.080 0.005 0.174 0.345 0.555   || dis=0.04 || select=7/8
010/019-th : 0.088 0.098 0.100 0.111 0.127 0.153 0.157 0.166  ||  -0.321 -0.220 -0.196 -0.094 0.045 0.229 0.254 0.309   || dis=0.01 || select=7/8
011/019-th : 0.124 0.112 0.113 0.119 0.129 0.134 0.135 0.133  ||  -0.000 -0.100 -0.092 -0.039 0.037 0.078 0.085 0.073   || dis=0.00 || select=6/8
012/019-th : 0.147 0.138 0.119 0.123 0.130 0.116 0.114 0.113  ||  0.167 0.104 -0.040 -0.008 0.049 -0.066 -0.082 -0.090  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.060 -1.011 -0.912 -0.789 -0.705 -0.463 -0.188 4.526  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.949  ||  -1.315 -1.329 -0.997 -0.989 -0.690 -0.337 0.281 4.257  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.962  ||  -1.147 -0.778 -0.931 -0.922 -0.701 -0.484 -0.029 4.528  || dis=0.95 || select=7/8
016/019-th : 0.030 0.035 0.039 0.059 0.091 0.164 0.243 0.339  ||  -1.094 -0.949 -0.827 -0.406 0.021 0.611 1.002 1.336   || dis=0.10 || select=7/8
017/019-th : 0.078 0.096 0.100 0.118 0.132 0.151 0.166 0.161  ||  -0.436 -0.232 -0.192 -0.025 0.089 0.222 0.320 0.286   || dis=0.01 || select=6/8
018/019-th : 0.090 0.104 0.122 0.137 0.136 0.125 0.136 0.149  ||  -0.308 -0.166 -0.010 0.111 0.102 0.016 0.098 0.192    || dis=0.01 || select=7/8
[epoch=529/600] FLOP : 29.41 MB, ratio : 0.7207, Expected-ratio : 0.7000, Discrepancy : 0.298
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:24:40] [epoch=529/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 1.003 (1.003)  Prec@1 67.58 (67.58) Prec@5 95.31 (95.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:24:46] [epoch=529/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.825 (1.622)  Prec@1 72.62 (58.84) Prec@5 98.21 (90.34) Size=[168, 3, 32, 32]
 **VALID** Prec@1 58.84 Prec@5 90.34 Error@1 41.16 Error@5 9.66 Loss:1.622
***[2020-01-29 10:24:46]*** VALID [epoch=529/600] loss = 1.622070, accuracy@1 = 58.84, accuracy@5 = 90.34 | Best-Valid-Acc@1=57.53, Error@1=42.47
Currently, the best validation accuracy found at 529-epoch :: acc@1=58.84, acc@5=90.34, error@1=41.16, error@5=9.66, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:24:47]*** start epoch=530/600 Time Left: [00:37:28], LR=[0.003321 ~ 0.003321], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=530, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.262727955081856, FLOP=40.81
[Search] : epoch=530/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:24:47] [epoch=530/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.410 (0.410)  Prec@1 86.33 (86.33) Prec@5 99.61 (99.61) Acls-loss 0.466 (0.466) FLOP-Loss 3.010 (3.010) Arch-Loss 6.486 (6.486)
**TRAIN** [2020-01-29 10:25:12] [epoch=530/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.509 (0.433)  Prec@1 80.36 (85.44) Prec@5 98.81 (99.28) Acls-loss 0.556 (0.551) FLOP-Loss 0.000 (0.154) Arch-Loss 0.556 (0.859)
 **TRAIN** Prec@1 85.44 Prec@5 99.28 Error@1 14.56 Error@5 0.72 Base-Loss:0.433, Arch-Loss=0.859
***[2020-01-29 10:25:12]*** TRAIN [epoch=530/600] base-loss = 0.433347, arch-loss = 0.858981, accuracy-1 = 85.44, accuracy-5 = 99.28
[epoch=530/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 12, 14, 4, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.708288)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.159 0.537 0.305  ||  -0.3998 0.8175 0.2513  || discrepancy=0.23 || select=1/3
001/003-th : 0.319 0.299 0.381  ||  0.1051 0.0417 0.2835  || discrepancy=0.06 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3040 -0.6041 2.8510  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.014 0.014 0.019 0.026 0.049 0.859  ||  -1.456 -1.077 -0.877 -0.853 -0.571 -0.253 0.399 3.253  || dis=0.81 || select=7/8
001/019-th : 0.081 0.109 0.133 0.122 0.137 0.130 0.163 0.124  ||  -0.412 -0.118 0.076 -0.006 0.109 0.060 0.282 0.011    || dis=0.03 || select=6/8
002/019-th : 0.109 0.116 0.134 0.131 0.126 0.131 0.133 0.119  ||  -0.134 -0.067 0.073 0.054 0.016 0.048 0.070 -0.044    || dis=0.00 || select=2/8
003/019-th : 0.108 0.115 0.121 0.122 0.125 0.139 0.139 0.132  ||  -0.153 -0.090 -0.034 -0.028 -0.006 0.104 0.102 0.052  || dis=0.00 || select=5/8
004/019-th : 0.108 0.105 0.109 0.118 0.124 0.125 0.160 0.151  ||  -0.135 -0.164 -0.125 -0.051 0.001 0.007 0.260 0.202   || dis=0.01 || select=6/8
005/019-th : 0.132 0.131 0.119 0.122 0.125 0.128 0.125 0.118  ||  0.050 0.043 -0.053 -0.022 -0.000 0.021 -0.001 -0.058  || dis=0.00 || select=0/8
006/019-th : 0.147 0.140 0.124 0.123 0.128 0.119 0.115 0.104  ||  0.176 0.125 0.006 -0.004 0.037 -0.033 -0.074 -0.170   || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.015 0.021 0.028 0.052 0.856  ||  -1.501 -1.265 -0.975 -0.779 -0.420 -0.142 0.490 3.283  || dis=0.80 || select=7/8
008/019-th : 0.007 0.009 0.014 0.018 0.027 0.044 0.106 0.775  ||  -1.749 -1.442 -1.017 -0.714 -0.320 0.153 1.041 3.028  || dis=0.67 || select=7/8
009/019-th : 0.082 0.084 0.091 0.109 0.119 0.138 0.170 0.206  ||  -0.370 -0.342 -0.267 -0.086 0.005 0.153 0.356 0.551   || dis=0.04 || select=7/8
010/019-th : 0.089 0.098 0.100 0.110 0.127 0.155 0.156 0.165  ||  -0.315 -0.220 -0.193 -0.102 0.041 0.244 0.249 0.306   || dis=0.01 || select=7/8
011/019-th : 0.124 0.114 0.113 0.120 0.129 0.134 0.133 0.133  ||  -0.003 -0.085 -0.092 -0.035 0.039 0.074 0.072 0.071   || dis=0.00 || select=5/8
012/019-th : 0.148 0.137 0.119 0.124 0.128 0.117 0.115 0.113  ||  0.174 0.103 -0.041 0.002 0.029 -0.061 -0.076 -0.095   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.007 0.009 0.963  ||  -1.067 -1.006 -0.908 -0.786 -0.701 -0.461 -0.188 4.522  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.007 0.010 0.018 0.949  ||  -1.332 -1.325 -0.995 -0.986 -0.707 -0.335 0.293 4.265  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.962  ||  -1.141 -0.774 -0.925 -0.920 -0.698 -0.481 -0.031 4.521  || dis=0.95 || select=7/8
016/019-th : 0.030 0.034 0.038 0.059 0.091 0.169 0.241 0.338  ||  -1.086 -0.956 -0.844 -0.405 0.019 0.640 0.995 1.335   || dis=0.10 || select=7/8
017/019-th : 0.079 0.096 0.099 0.116 0.131 0.151 0.167 0.160  ||  -0.425 -0.229 -0.194 -0.037 0.078 0.224 0.323 0.282   || dis=0.01 || select=6/8
018/019-th : 0.092 0.104 0.124 0.137 0.136 0.123 0.136 0.148  ||  -0.294 -0.167 0.008 0.104 0.101 0.000 0.099 0.183     || dis=0.01 || select=7/8
[epoch=530/600] FLOP : 27.71 MB, ratio : 0.6789, Expected-ratio : 0.7000, Discrepancy : 0.298
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:25:12] [epoch=530/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.420 (3.420)  Prec@1 22.27 (22.27) Prec@5 81.64 (81.64) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:25:18] [epoch=530/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.034 (2.031)  Prec@1 25.60 (53.33) Prec@5 77.38 (87.36) Size=[168, 3, 32, 32]
 **VALID** Prec@1 53.33 Prec@5 87.36 Error@1 46.67 Error@5 12.64 Loss:2.031
***[2020-01-29 10:25:18]*** VALID [epoch=530/600] loss = 2.031335, accuracy@1 = 53.33, accuracy@5 = 87.36 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:25:18]*** start epoch=531/600 Time Left: [00:36:56], LR=[0.003228 ~ 0.003228], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=531, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.2581621244668252, FLOP=40.81
[Search] : epoch=531/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:25:19] [epoch=531/600][000/098] Time 0.63 (0.63) Data 0.35 (0.35) Base-Loss 0.388 (0.388)  Prec@1 89.45 (89.45) Prec@5 100.00 (100.00) Acls-loss 0.452 (0.452) FLOP-Loss 0.000 (0.000) Arch-Loss 0.452 (0.452)
**TRAIN** [2020-01-29 10:25:43] [epoch=531/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.550 (0.412)  Prec@1 79.76 (86.22) Prec@5 97.62 (99.35) Acls-loss 0.473 (0.568) FLOP-Loss 0.000 (0.123) Arch-Loss 0.473 (0.814)
 **TRAIN** Prec@1 86.22 Prec@5 99.35 Error@1 13.78 Error@5 0.65 Base-Loss:0.412, Arch-Loss=0.814
***[2020-01-29 10:25:43]*** TRAIN [epoch=531/600] base-loss = 0.412113, arch-loss = 0.814373, accuracy-1 = 86.22, accuracy-5 = 99.35
[epoch=531/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.99168)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.159 0.537 0.304  ||  -0.4004 0.8187 0.2481  || discrepancy=0.23 || select=1/3
001/003-th : 0.319 0.300 0.381  ||  0.1043 0.0431 0.2826  || discrepancy=0.06 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.2952 -0.6198 2.8470  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.014 0.014 0.019 0.025 0.049 0.861  ||  -1.447 -1.081 -0.869 -0.848 -0.569 -0.270 0.385 3.260  || dis=0.81 || select=7/8
001/019-th : 0.081 0.110 0.133 0.124 0.135 0.131 0.162 0.125  ||  -0.417 -0.115 0.079 0.007 0.098 0.064 0.276 0.015     || dis=0.03 || select=6/8
002/019-th : 0.108 0.115 0.134 0.132 0.126 0.133 0.133 0.119  ||  -0.140 -0.075 0.073 0.063 0.011 0.066 0.067 -0.043    || dis=0.00 || select=2/8
003/019-th : 0.108 0.115 0.121 0.123 0.124 0.139 0.138 0.132  ||  -0.149 -0.084 -0.038 -0.020 -0.015 0.101 0.098 0.052  || dis=0.00 || select=5/8
004/019-th : 0.108 0.106 0.110 0.118 0.123 0.124 0.159 0.151  ||  -0.134 -0.154 -0.118 -0.049 -0.002 0.002 0.253 0.201  || dis=0.01 || select=6/8
005/019-th : 0.130 0.131 0.119 0.123 0.125 0.127 0.125 0.118  ||  0.040 0.047 -0.051 -0.014 -0.002 0.016 0.001 -0.056   || dis=0.00 || select=1/8
006/019-th : 0.147 0.140 0.124 0.124 0.126 0.119 0.115 0.104  ||  0.177 0.129 0.005 0.003 0.023 -0.035 -0.070 -0.172    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.028 0.051 0.858  ||  -1.497 -1.265 -0.972 -0.798 -0.396 -0.143 0.463 3.294  || dis=0.81 || select=7/8
008/019-th : 0.006 0.009 0.013 0.018 0.027 0.043 0.103 0.780  ||  -1.748 -1.440 -1.045 -0.711 -0.318 0.155 1.021 3.042  || dis=0.68 || select=7/8
009/019-th : 0.081 0.083 0.092 0.109 0.120 0.139 0.171 0.205  ||  -0.380 -0.354 -0.258 -0.087 0.010 0.159 0.364 0.549   || dis=0.03 || select=7/8
010/019-th : 0.089 0.098 0.100 0.111 0.127 0.154 0.157 0.164  ||  -0.317 -0.220 -0.194 -0.092 0.044 0.234 0.255 0.298   || dis=0.01 || select=7/8
011/019-th : 0.122 0.113 0.114 0.118 0.129 0.134 0.136 0.135  ||  -0.017 -0.094 -0.087 -0.047 0.037 0.074 0.089 0.087   || dis=0.00 || select=6/8
012/019-th : 0.148 0.138 0.120 0.124 0.127 0.116 0.115 0.112  ||  0.177 0.108 -0.035 -0.004 0.023 -0.063 -0.078 -0.098  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.009 0.964  ||  -1.069 -1.000 -0.903 -0.781 -0.697 -0.502 -0.187 4.542  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.006 0.009 0.018 0.950  ||  -1.328 -1.322 -0.989 -0.984 -0.723 -0.333 0.281 4.273  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.962  ||  -1.158 -0.771 -0.937 -0.919 -0.696 -0.478 -0.031 4.529  || dis=0.95 || select=7/8
016/019-th : 0.029 0.034 0.038 0.059 0.089 0.168 0.240 0.343  ||  -1.109 -0.952 -0.841 -0.405 0.004 0.641 0.996 1.354   || dis=0.10 || select=7/8
017/019-th : 0.080 0.096 0.099 0.116 0.129 0.149 0.169 0.162  ||  -0.418 -0.229 -0.205 -0.042 0.064 0.210 0.337 0.291   || dis=0.01 || select=6/8
018/019-th : 0.092 0.106 0.123 0.137 0.136 0.123 0.137 0.148  ||  -0.292 -0.153 -0.000 0.104 0.097 -0.005 0.103 0.180   || dis=0.01 || select=7/8
[epoch=531/600] FLOP : 27.99 MB, ratio : 0.6858, Expected-ratio : 0.7000, Discrepancy : 0.299
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:25:44] [epoch=531/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 1.761 (1.761)  Prec@1 43.36 (43.36) Prec@5 89.45 (89.45) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:25:50] [epoch=531/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.550 (1.626)  Prec@1 80.95 (58.12) Prec@5 98.81 (89.53) Size=[168, 3, 32, 32]
 **VALID** Prec@1 58.12 Prec@5 89.53 Error@1 41.88 Error@5 10.47 Loss:1.626
***[2020-01-29 10:25:50]*** VALID [epoch=531/600] loss = 1.625733, accuracy@1 = 58.12, accuracy@5 = 89.53 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:25:50]*** start epoch=532/600 Time Left: [00:36:24], LR=[0.003136 ~ 0.003136], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=532, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.25365912574486593, FLOP=40.81
[Search] : epoch=532/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:25:51] [epoch=532/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.517 (0.517)  Prec@1 84.38 (84.38) Prec@5 99.22 (99.22) Acls-loss 0.691 (0.691) FLOP-Loss 0.000 (0.000) Arch-Loss 0.691 (0.691)
**TRAIN** [2020-01-29 10:26:15] [epoch=532/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.329 (0.447)  Prec@1 86.90 (84.83) Prec@5 100.00 (99.34) Acls-loss 0.411 (0.538) FLOP-Loss 0.000 (0.216) Arch-Loss 0.411 (0.969)
 **TRAIN** Prec@1 84.83 Prec@5 99.34 Error@1 15.17 Error@5 0.66 Base-Loss:0.447, Arch-Loss=0.969
***[2020-01-29 10:26:15]*** TRAIN [epoch=532/600] base-loss = 0.446986, arch-loss = 0.969316, accuracy-1 = 84.83, accuracy-5 = 99.34
[epoch=532/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 8, 14, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.397184)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.159 0.539 0.302  ||  -0.4006 0.8220 0.2436  || discrepancy=0.24 || select=1/3
001/003-th : 0.322 0.301 0.377  ||  0.1125 0.0467 0.2700  || discrepancy=0.05 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.2999 -0.6162 2.8507  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.013 0.014 0.018 0.025 0.047 0.865  ||  -1.439 -1.081 -0.899 -0.864 -0.566 -0.274 0.364 3.286  || dis=0.82 || select=7/8
001/019-th : 0.081 0.111 0.134 0.125 0.134 0.133 0.159 0.124  ||  -0.411 -0.105 0.084 0.015 0.085 0.082 0.256 0.007     || dis=0.02 || select=6/8
002/019-th : 0.108 0.114 0.133 0.133 0.126 0.132 0.132 0.121  ||  -0.137 -0.083 0.071 0.064 0.013 0.060 0.062 -0.030    || dis=0.00 || select=2/8
003/019-th : 0.110 0.116 0.121 0.123 0.124 0.137 0.139 0.130  ||  -0.135 -0.081 -0.034 -0.022 -0.010 0.091 0.100 0.038  || dis=0.00 || select=6/8
004/019-th : 0.108 0.107 0.111 0.118 0.123 0.125 0.158 0.150  ||  -0.134 -0.148 -0.110 -0.044 -0.006 0.010 0.245 0.194  || dis=0.01 || select=6/8
005/019-th : 0.131 0.131 0.119 0.124 0.126 0.126 0.124 0.117  ||  0.049 0.049 -0.054 -0.008 0.010 0.009 -0.006 -0.065   || dis=0.00 || select=1/8
006/019-th : 0.150 0.141 0.124 0.124 0.127 0.117 0.114 0.103  ||  0.191 0.133 0.007 0.000 0.024 -0.054 -0.076 -0.179    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.027 0.050 0.860  ||  -1.488 -1.270 -0.984 -0.799 -0.393 -0.153 0.455 3.310  || dis=0.81 || select=7/8
008/019-th : 0.006 0.009 0.013 0.018 0.027 0.043 0.100 0.784  ||  -1.743 -1.431 -1.053 -0.705 -0.330 0.149 0.994 3.053  || dis=0.68 || select=7/8
009/019-th : 0.082 0.085 0.092 0.109 0.120 0.139 0.171 0.202  ||  -0.369 -0.341 -0.256 -0.083 0.008 0.154 0.362 0.531   || dis=0.03 || select=7/8
010/019-th : 0.090 0.098 0.101 0.112 0.128 0.153 0.156 0.163  ||  -0.308 -0.218 -0.185 -0.088 0.047 0.226 0.245 0.292   || dis=0.01 || select=7/8
011/019-th : 0.121 0.112 0.115 0.119 0.129 0.135 0.136 0.133  ||  -0.025 -0.100 -0.076 -0.043 0.036 0.087 0.092 0.073   || dis=0.00 || select=6/8
012/019-th : 0.149 0.139 0.120 0.125 0.126 0.114 0.114 0.112  ||  0.186 0.116 -0.031 0.009 0.014 -0.080 -0.081 -0.102   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.009 0.964  ||  -1.062 -0.993 -0.906 -0.775 -0.709 -0.501 -0.186 4.543  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.006 0.010 0.018 0.949  ||  -1.321 -1.318 -0.984 -0.980 -0.721 -0.330 0.276 4.268  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.963  ||  -1.178 -0.766 -0.938 -0.916 -0.692 -0.509 -0.031 4.550  || dis=0.95 || select=7/8
016/019-th : 0.030 0.035 0.039 0.059 0.090 0.168 0.239 0.342  ||  -1.102 -0.946 -0.827 -0.415 0.009 0.638 0.989 1.348   || dis=0.10 || select=7/8
017/019-th : 0.080 0.096 0.099 0.113 0.129 0.151 0.169 0.162  ||  -0.411 -0.229 -0.199 -0.067 0.066 0.220 0.333 0.291   || dis=0.01 || select=6/8
018/019-th : 0.092 0.105 0.124 0.138 0.138 0.121 0.135 0.147  ||  -0.294 -0.155 0.010 0.112 0.111 -0.017 0.093 0.177    || dis=0.01 || select=7/8
[epoch=532/600] FLOP : 28.40 MB, ratio : 0.6958, Expected-ratio : 0.7000, Discrepancy : 0.299
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:26:15] [epoch=532/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.355 (1.355)  Prec@1 52.34 (52.34) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:26:22] [epoch=532/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 7.649 (1.756)  Prec@1 16.07 (56.02) Prec@5 45.24 (87.93) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.02 Prec@5 87.93 Error@1 43.98 Error@5 12.07 Loss:1.756
***[2020-01-29 10:26:22]*** VALID [epoch=532/600] loss = 1.756329, accuracy@1 = 56.02, accuracy@5 = 87.93 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:26:22]*** start epoch=533/600 Time Left: [00:35:51], LR=[0.003045 ~ 0.003045], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=533, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.24921908236796275, FLOP=40.81
[Search] : epoch=533/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:26:22] [epoch=533/600][000/098] Time 0.65 (0.65) Data 0.38 (0.38) Base-Loss 0.346 (0.346)  Prec@1 88.28 (88.28) Prec@5 99.61 (99.61) Acls-loss 0.616 (0.616) FLOP-Loss 0.000 (0.000) Arch-Loss 0.616 (0.616)
**TRAIN** [2020-01-29 10:26:47] [epoch=533/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.285 (0.381)  Prec@1 88.69 (87.06) Prec@5 100.00 (99.47) Acls-loss 0.482 (0.547) FLOP-Loss 0.000 (0.369) Arch-Loss 0.482 (1.286)
 **TRAIN** Prec@1 87.06 Prec@5 99.47 Error@1 12.94 Error@5 0.53 Base-Loss:0.381, Arch-Loss=1.286
***[2020-01-29 10:26:47]*** TRAIN [epoch=533/600] base-loss = 0.380658, arch-loss = 1.286344, accuracy-1 = 87.06, accuracy-5 = 99.47
[epoch=533/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.161 0.542 0.297  ||  -0.3851 0.8260 0.2245  || discrepancy=0.25 || select=1/3
001/003-th : 0.329 0.302 0.368  ||  0.1328 0.0471 0.2445  || discrepancy=0.04 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.2923 -0.6115 2.8424  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.013 0.014 0.018 0.025 0.046 0.866  ||  -1.438 -1.081 -0.896 -0.860 -0.560 -0.270 0.351 3.289  || dis=0.82 || select=7/8
001/019-th : 0.081 0.112 0.137 0.126 0.135 0.132 0.155 0.123  ||  -0.415 -0.091 0.106 0.025 0.094 0.070 0.235 -0.000    || dis=0.02 || select=6/8
002/019-th : 0.110 0.116 0.133 0.135 0.125 0.131 0.130 0.119  ||  -0.119 -0.070 0.071 0.079 0.008 0.055 0.045 -0.048    || dis=0.00 || select=3/8
003/019-th : 0.111 0.117 0.122 0.125 0.123 0.138 0.137 0.127  ||  -0.121 -0.073 -0.028 -0.001 -0.021 0.096 0.089 0.015  || dis=0.00 || select=5/8
004/019-th : 0.110 0.109 0.111 0.120 0.123 0.124 0.156 0.147  ||  -0.120 -0.122 -0.108 -0.034 -0.007 0.006 0.231 0.175  || dis=0.01 || select=6/8
005/019-th : 0.133 0.133 0.114 0.125 0.128 0.129 0.123 0.116  ||  0.060 0.063 -0.088 -0.003 0.023 0.033 -0.018 -0.072   || dis=0.00 || select=1/8
006/019-th : 0.150 0.144 0.127 0.125 0.125 0.115 0.112 0.103  ||  0.194 0.153 0.026 0.010 0.010 -0.070 -0.099 -0.181    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.027 0.049 0.861  ||  -1.479 -1.264 -0.978 -0.797 -0.400 -0.151 0.445 3.309  || dis=0.81 || select=7/8
008/019-th : 0.007 0.009 0.013 0.018 0.027 0.043 0.098 0.786  ||  -1.738 -1.421 -1.047 -0.697 -0.333 0.141 0.973 3.054  || dis=0.69 || select=7/8
009/019-th : 0.084 0.086 0.094 0.110 0.121 0.139 0.168 0.200  ||  -0.345 -0.333 -0.240 -0.085 0.012 0.149 0.340 0.515   || dis=0.03 || select=7/8
010/019-th : 0.091 0.099 0.102 0.113 0.128 0.151 0.155 0.161  ||  -0.291 -0.210 -0.176 -0.081 0.047 0.213 0.236 0.274   || dis=0.01 || select=7/8
011/019-th : 0.122 0.113 0.116 0.120 0.127 0.135 0.135 0.131  ||  -0.014 -0.091 -0.068 -0.036 0.026 0.083 0.087 0.055   || dis=0.00 || select=6/8
012/019-th : 0.152 0.141 0.120 0.126 0.124 0.113 0.113 0.110  ||  0.204 0.132 -0.030 0.020 0.002 -0.091 -0.089 -0.120   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.009 0.964  ||  -1.054 -0.986 -0.909 -0.770 -0.705 -0.499 -0.185 4.536  || dis=0.95 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.006 0.009 0.017 0.950  ||  -1.321 -1.313 -0.999 -0.971 -0.719 -0.333 0.264 4.277  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.963  ||  -1.174 -0.761 -0.956 -0.913 -0.689 -0.507 -0.030 4.551  || dis=0.95 || select=7/8
016/019-th : 0.030 0.035 0.039 0.059 0.088 0.166 0.238 0.347  ||  -1.093 -0.940 -0.832 -0.414 -0.012 0.626 0.987 1.364  || dis=0.11 || select=7/8
017/019-th : 0.080 0.097 0.101 0.113 0.130 0.149 0.168 0.161  ||  -0.409 -0.225 -0.184 -0.067 0.074 0.207 0.329 0.287   || dis=0.01 || select=6/8
018/019-th : 0.093 0.107 0.126 0.139 0.137 0.120 0.132 0.145  ||  -0.284 -0.145 0.022 0.123 0.109 -0.023 0.071 0.165    || dis=0.01 || select=7/8
[epoch=533/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.299
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:26:47] [epoch=533/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.764 (0.764)  Prec@1 74.22 (74.22) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:26:53] [epoch=533/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.808 (1.707)  Prec@1 45.24 (55.82) Prec@5 85.71 (87.98) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.82 Prec@5 87.98 Error@1 44.18 Error@5 12.02 Loss:1.707
***[2020-01-29 10:26:53]*** VALID [epoch=533/600] loss = 1.707171, accuracy@1 = 55.82, accuracy@5 = 87.98 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:26:53]*** start epoch=534/600 Time Left: [00:35:19], LR=[0.002956 ~ 0.002956], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=534, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.24484211606214765, FLOP=40.81
[Search] : epoch=534/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:26:54] [epoch=534/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.548 (0.548)  Prec@1 85.16 (85.16) Prec@5 99.61 (99.61) Acls-loss 1.080 (1.080) FLOP-Loss 0.000 (0.000) Arch-Loss 1.080 (1.080)
**TRAIN** [2020-01-29 10:27:18] [epoch=534/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.315 (0.399)  Prec@1 88.69 (86.49) Prec@5 100.00 (99.45) Acls-loss 0.443 (0.589) FLOP-Loss 0.000 (0.031) Arch-Loss 0.443 (0.650)
 **TRAIN** Prec@1 86.49 Prec@5 99.45 Error@1 13.51 Error@5 0.55 Base-Loss:0.399, Arch-Loss=0.650
***[2020-01-29 10:27:18]*** TRAIN [epoch=534/600] base-loss = 0.399307, arch-loss = 0.650224, accuracy-1 = 86.49, accuracy-5 = 99.45
[epoch=534/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 6, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.158 0.539 0.303  ||  -0.4060 0.8195 0.2433  || discrepancy=0.24 || select=1/3
001/003-th : 0.327 0.304 0.370  ||  0.1255 0.0536 0.2490  || discrepancy=0.04 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.2945 -0.6053 2.8430  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.013 0.013 0.018 0.024 0.045 0.869  ||  -1.429 -1.075 -0.893 -0.869 -0.595 -0.289 0.345 3.309  || dis=0.82 || select=7/8
001/019-th : 0.081 0.109 0.136 0.126 0.134 0.133 0.156 0.124  ||  -0.417 -0.115 0.100 0.028 0.090 0.082 0.239 0.014     || dis=0.02 || select=6/8
002/019-th : 0.109 0.116 0.132 0.133 0.127 0.131 0.133 0.119  ||  -0.128 -0.074 0.062 0.068 0.017 0.051 0.067 -0.044    || dis=0.00 || select=3/8
003/019-th : 0.109 0.116 0.121 0.126 0.125 0.140 0.137 0.127  ||  -0.138 -0.079 -0.035 0.011 -0.001 0.109 0.089 0.015   || dis=0.00 || select=5/8
004/019-th : 0.109 0.109 0.108 0.118 0.121 0.127 0.159 0.149  ||  -0.123 -0.123 -0.138 -0.046 -0.024 0.025 0.253 0.190  || dis=0.01 || select=6/8
005/019-th : 0.131 0.133 0.114 0.125 0.130 0.129 0.123 0.116  ||  0.050 0.061 -0.087 -0.000 0.038 0.031 -0.018 -0.071   || dis=0.00 || select=1/8
006/019-th : 0.150 0.142 0.125 0.124 0.127 0.114 0.113 0.104  ||  0.193 0.142 0.013 0.006 0.030 -0.078 -0.093 -0.176    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.027 0.048 0.863  ||  -1.473 -1.259 -0.979 -0.792 -0.401 -0.163 0.426 3.319  || dis=0.81 || select=7/8
008/019-th : 0.006 0.009 0.013 0.018 0.026 0.041 0.094 0.793  ||  -1.741 -1.430 -1.040 -0.709 -0.330 0.119 0.954 3.081  || dis=0.70 || select=7/8
009/019-th : 0.083 0.085 0.094 0.109 0.120 0.140 0.167 0.202  ||  -0.365 -0.336 -0.234 -0.092 0.008 0.161 0.338 0.530   || dis=0.04 || select=7/8
010/019-th : 0.091 0.098 0.102 0.113 0.128 0.153 0.154 0.161  ||  -0.298 -0.217 -0.176 -0.079 0.051 0.226 0.231 0.279   || dis=0.01 || select=7/8
011/019-th : 0.122 0.113 0.116 0.118 0.128 0.135 0.136 0.132  ||  -0.017 -0.095 -0.066 -0.047 0.029 0.084 0.092 0.060   || dis=0.00 || select=6/8
012/019-th : 0.150 0.140 0.118 0.128 0.124 0.113 0.115 0.111  ||  0.195 0.122 -0.045 0.034 0.001 -0.090 -0.075 -0.108   || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.008 0.964  ||  -1.048 -0.979 -0.933 -0.764 -0.720 -0.498 -0.184 4.550  || dis=0.96 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.006 0.009 0.017 0.951  ||  -1.315 -1.309 -0.995 -0.994 -0.717 -0.345 0.252 4.290  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.963  ||  -1.171 -0.757 -0.952 -0.911 -0.686 -0.505 -0.033 4.545  || dis=0.95 || select=7/8
016/019-th : 0.029 0.035 0.038 0.058 0.086 0.169 0.241 0.345  ||  -1.106 -0.929 -0.832 -0.427 -0.033 0.646 1.004 1.361  || dis=0.10 || select=7/8
017/019-th : 0.081 0.096 0.100 0.113 0.129 0.149 0.168 0.164  ||  -0.402 -0.232 -0.196 -0.067 0.063 0.209 0.325 0.301   || dis=0.00 || select=6/8
018/019-th : 0.093 0.108 0.126 0.142 0.136 0.119 0.131 0.144  ||  -0.284 -0.130 0.024 0.145 0.099 -0.033 0.060 0.159    || dis=0.00 || select=7/8
[epoch=534/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.300
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:27:19] [epoch=534/600][000/098] Time 0.47 (0.47) Data 0.28 (0.28) Loss 0.713 (0.713)  Prec@1 79.30 (79.30) Prec@5 98.05 (98.05) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:27:25] [epoch=534/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 12.555 (1.655)  Prec@1 11.90 (57.38) Prec@5 52.38 (89.73) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.38 Prec@5 89.73 Error@1 42.62 Error@5 10.27 Loss:1.655
***[2020-01-29 10:27:25]*** VALID [epoch=534/600] loss = 1.654696, accuracy@1 = 57.38, accuracy@5 = 89.73 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:27:25]*** start epoch=535/600 Time Left: [00:34:47], LR=[0.002868 ~ 0.002868], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=535, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.24052834682416285, FLOP=40.81
[Search] : epoch=535/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:27:25] [epoch=535/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.925 (0.925)  Prec@1 67.19 (67.19) Prec@5 98.83 (98.83) Acls-loss 0.566 (0.566) FLOP-Loss 0.000 (0.000) Arch-Loss 0.566 (0.566)
**TRAIN** [2020-01-29 10:27:50] [epoch=535/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.617 (0.433)  Prec@1 80.95 (85.41) Prec@5 97.62 (99.34) Acls-loss 0.514 (0.562) FLOP-Loss 0.000 (0.277) Arch-Loss 0.514 (1.116)
 **TRAIN** Prec@1 85.41 Prec@5 99.34 Error@1 14.59 Error@5 0.66 Base-Loss:0.433, Arch-Loss=1.116
***[2020-01-29 10:27:50]*** TRAIN [epoch=535/600] base-loss = 0.433296, arch-loss = 1.116223, accuracy-1 = 85.41, accuracy-5 = 99.34
[epoch=535/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.159 0.546 0.296  ||  -0.3985 0.8380 0.2242  || discrepancy=0.25 || select=1/3
001/003-th : 0.333 0.302 0.365  ||  0.1421 0.0423 0.2330  || discrepancy=0.03 || select=2/3
002/003-th : 0.006 0.030 0.964  ||  -2.3058 -0.6064 2.8545  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.013 0.013 0.017 0.024 0.043 0.871  ||  -1.422 -1.078 -0.889 -0.861 -0.608 -0.285 0.318 3.321  || dis=0.83 || select=7/8
001/019-th : 0.081 0.107 0.137 0.123 0.132 0.134 0.158 0.128  ||  -0.422 -0.138 0.112 0.005 0.069 0.087 0.253 0.041     || dis=0.02 || select=6/8
002/019-th : 0.110 0.117 0.130 0.134 0.127 0.131 0.133 0.117  ||  -0.125 -0.059 0.046 0.071 0.021 0.053 0.067 -0.058    || dis=0.00 || select=3/8
003/019-th : 0.111 0.118 0.121 0.127 0.124 0.137 0.136 0.126  ||  -0.120 -0.060 -0.032 0.014 -0.013 0.090 0.084 0.003   || dis=0.00 || select=5/8
004/019-th : 0.110 0.111 0.108 0.119 0.120 0.125 0.159 0.149  ||  -0.114 -0.107 -0.137 -0.037 -0.027 0.010 0.249 0.184  || dis=0.01 || select=6/8
005/019-th : 0.133 0.132 0.114 0.124 0.130 0.128 0.123 0.115  ||  0.062 0.059 -0.087 -0.004 0.039 0.025 -0.013 -0.079   || dis=0.00 || select=0/8
006/019-th : 0.152 0.142 0.125 0.124 0.130 0.115 0.111 0.102  ||  0.205 0.139 0.013 0.007 0.050 -0.074 -0.107 -0.195    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.027 0.048 0.862  ||  -1.464 -1.252 -0.973 -0.785 -0.397 -0.167 0.423 3.311  || dis=0.81 || select=7/8
008/019-th : 0.006 0.009 0.013 0.017 0.025 0.040 0.091 0.799  ||  -1.736 -1.427 -1.029 -0.737 -0.344 0.109 0.929 3.102  || dis=0.71 || select=7/8
009/019-th : 0.083 0.086 0.094 0.110 0.121 0.139 0.166 0.200  ||  -0.360 -0.329 -0.233 -0.081 0.016 0.156 0.331 0.517   || dis=0.03 || select=7/8
010/019-th : 0.088 0.099 0.103 0.114 0.127 0.156 0.154 0.160  ||  -0.326 -0.210 -0.167 -0.067 0.039 0.247 0.237 0.274   || dis=0.00 || select=7/8
011/019-th : 0.124 0.114 0.116 0.120 0.127 0.133 0.135 0.131  ||  0.001 -0.084 -0.072 -0.037 0.026 0.066 0.086 0.051    || dis=0.00 || select=6/8
012/019-th : 0.152 0.141 0.120 0.128 0.124 0.112 0.113 0.110  ||  0.205 0.132 -0.034 0.033 -0.002 -0.097 -0.087 -0.120  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.008 0.964  ||  -1.039 -0.971 -0.933 -0.781 -0.720 -0.496 -0.185 4.551  || dis=0.96 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.006 0.009 0.017 0.951  ||  -1.307 -1.305 -0.991 -0.990 -0.715 -0.361 0.249 4.289  || dis=0.93 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.963  ||  -1.167 -0.751 -0.966 -0.908 -0.682 -0.511 -0.033 4.549  || dis=0.95 || select=7/8
016/019-th : 0.029 0.035 0.039 0.059 0.086 0.170 0.240 0.342  ||  -1.103 -0.924 -0.824 -0.412 -0.035 0.650 0.994 1.351  || dis=0.10 || select=7/8
017/019-th : 0.082 0.097 0.100 0.114 0.131 0.148 0.166 0.162  ||  -0.394 -0.224 -0.193 -0.058 0.078 0.197 0.315 0.289   || dis=0.00 || select=6/8
018/019-th : 0.093 0.110 0.128 0.141 0.134 0.119 0.132 0.143  ||  -0.277 -0.118 0.037 0.136 0.082 -0.036 0.065 0.150    || dis=0.00 || select=7/8
[epoch=535/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.301
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:27:50] [epoch=535/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.467 (1.467)  Prec@1 62.89 (62.89) Prec@5 92.97 (92.97) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:27:56] [epoch=535/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.642 (1.608)  Prec@1 78.57 (57.42) Prec@5 98.81 (90.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.42 Prec@5 90.16 Error@1 42.58 Error@5 9.84 Loss:1.608
***[2020-01-29 10:27:57]*** VALID [epoch=535/600] loss = 1.608144, accuracy@1 = 57.42, accuracy@5 = 90.16 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:27:57]*** start epoch=536/600 Time Left: [00:34:15], LR=[0.002781 ~ 0.002781], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=536, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.23627789291817156, FLOP=40.81
[Search] : epoch=536/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:27:57] [epoch=536/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.289 (0.289)  Prec@1 91.41 (91.41) Prec@5 99.22 (99.22) Acls-loss 0.560 (0.560) FLOP-Loss 0.000 (0.000) Arch-Loss 0.560 (0.560)
**TRAIN** [2020-01-29 10:28:22] [epoch=536/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.541 (0.433)  Prec@1 86.90 (85.41) Prec@5 99.40 (99.31) Acls-loss 1.371 (0.548) FLOP-Loss 0.000 (0.307) Arch-Loss 1.371 (1.163)
 **TRAIN** Prec@1 85.41 Prec@5 99.31 Error@1 14.59 Error@5 0.69 Base-Loss:0.433, Arch-Loss=1.163
***[2020-01-29 10:28:22]*** TRAIN [epoch=536/600] base-loss = 0.432930, arch-loss = 1.162972, accuracy-1 = 85.41, accuracy-5 = 99.31
[epoch=536/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.262016)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.160 0.552 0.288  ||  -0.3856 0.8513 0.2027  || discrepancy=0.26 || select=1/3
001/003-th : 0.341 0.300 0.358  ||  0.1627 0.0348 0.2110  || discrepancy=0.02 || select=2/3
002/003-th : 0.006 0.031 0.964  ||  -2.3019 -0.5938 2.8480  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.008 0.011 0.013 0.013 0.017 0.023 0.042 0.875  ||  -1.412 -1.072 -0.881 -0.886 -0.613 -0.307 0.294 3.342  || dis=0.83 || select=7/8
001/019-th : 0.082 0.108 0.136 0.125 0.132 0.133 0.157 0.126  ||  -0.407 -0.129 0.099 0.020 0.071 0.082 0.247 0.028     || dis=0.02 || select=6/8
002/019-th : 0.111 0.119 0.130 0.133 0.125 0.132 0.133 0.117  ||  -0.118 -0.050 0.042 0.069 0.006 0.057 0.069 -0.065    || dis=0.00 || select=3/8
003/019-th : 0.112 0.117 0.121 0.128 0.126 0.136 0.136 0.124  ||  -0.108 -0.065 -0.035 0.018 0.005 0.086 0.080 -0.011   || dis=0.00 || select=5/8
004/019-th : 0.110 0.112 0.107 0.122 0.121 0.125 0.156 0.147  ||  -0.117 -0.097 -0.142 -0.013 -0.015 0.015 0.238 0.175  || dis=0.01 || select=6/8
005/019-th : 0.135 0.132 0.115 0.125 0.127 0.127 0.123 0.115  ||  0.076 0.059 -0.079 -0.002 0.020 0.017 -0.012 -0.083   || dis=0.00 || select=0/8
006/019-th : 0.152 0.142 0.127 0.124 0.129 0.116 0.109 0.100  ||  0.212 0.145 0.028 0.009 0.043 -0.064 -0.119 -0.208    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.026 0.047 0.864  ||  -1.469 -1.245 -0.971 -0.779 -0.407 -0.173 0.409 3.323  || dis=0.82 || select=7/8
008/019-th : 0.006 0.008 0.013 0.017 0.025 0.039 0.090 0.801  ||  -1.730 -1.439 -1.019 -0.731 -0.349 0.099 0.921 3.110  || dis=0.71 || select=7/8
009/019-th : 0.084 0.087 0.096 0.111 0.122 0.137 0.161 0.202  ||  -0.349 -0.322 -0.219 -0.074 0.020 0.134 0.301 0.524   || dis=0.04 || select=7/8
010/019-th : 0.088 0.100 0.103 0.114 0.127 0.155 0.154 0.159  ||  -0.323 -0.196 -0.171 -0.066 0.037 0.242 0.233 0.268   || dis=0.00 || select=7/8
011/019-th : 0.126 0.116 0.116 0.120 0.128 0.132 0.133 0.129  ||  0.012 -0.071 -0.067 -0.036 0.030 0.058 0.071 0.040    || dis=0.00 || select=6/8
012/019-th : 0.153 0.142 0.121 0.130 0.123 0.111 0.112 0.108  ||  0.217 0.137 -0.017 0.048 -0.003 -0.106 -0.101 -0.136  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.008 0.965  ||  -1.030 -0.964 -0.929 -0.783 -0.716 -0.495 -0.214 4.557  || dis=0.96 || select=7/8
014/019-th : 0.004 0.004 0.005 0.005 0.006 0.009 0.016 0.952  ||  -1.299 -1.300 -1.017 -0.985 -0.712 -0.364 0.243 4.301  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.010 0.964  ||  -1.175 -0.759 -0.962 -0.905 -0.697 -0.514 -0.039 4.562  || dis=0.95 || select=7/8
016/019-th : 0.028 0.036 0.039 0.059 0.085 0.172 0.238 0.343  ||  -1.155 -0.906 -0.816 -0.403 -0.033 0.671 0.996 1.358  || dis=0.11 || select=7/8
017/019-th : 0.083 0.099 0.101 0.115 0.132 0.148 0.164 0.160  ||  -0.380 -0.209 -0.187 -0.059 0.080 0.195 0.300 0.275   || dis=0.00 || select=6/8
018/019-th : 0.095 0.111 0.128 0.142 0.135 0.118 0.130 0.142  ||  -0.264 -0.104 0.037 0.139 0.087 -0.046 0.050 0.141    || dis=0.00 || select=7/8
[epoch=536/600] FLOP : 28.26 MB, ratio : 0.6925, Expected-ratio : 0.7000, Discrepancy : 0.301
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:28:22] [epoch=536/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.775 (0.775)  Prec@1 74.22 (74.22) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:28:28] [epoch=536/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.835 (1.998)  Prec@1 77.98 (55.47) Prec@5 98.21 (88.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.47 Prec@5 88.13 Error@1 44.53 Error@5 11.87 Loss:1.998
***[2020-01-29 10:28:28]*** VALID [epoch=536/600] loss = 1.998095, accuracy@1 = 55.47, accuracy@5 = 88.13 | Best-Valid-Acc@1=58.84, Error@1=41.16
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:28:29]*** start epoch=537/600 Time Left: [00:33:43], LR=[0.002696 ~ 0.002696], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=537, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.23209087087251404, FLOP=40.81
[Search] : epoch=537/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:28:29] [epoch=537/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.229 (0.229)  Prec@1 91.02 (91.02) Prec@5 100.00 (100.00) Acls-loss 0.531 (0.531) FLOP-Loss 0.000 (0.000) Arch-Loss 0.531 (0.531)
**TRAIN** [2020-01-29 10:28:54] [epoch=537/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.375 (0.419)  Prec@1 88.10 (85.76) Prec@5 99.40 (99.38) Acls-loss 0.675 (0.565) FLOP-Loss 0.000 (0.368) Arch-Loss 0.675 (1.301)
 **TRAIN** Prec@1 85.76 Prec@5 99.38 Error@1 14.24 Error@5 0.62 Base-Loss:0.419, Arch-Loss=1.301
***[2020-01-29 10:28:54]*** TRAIN [epoch=537/600] base-loss = 0.418509, arch-loss = 1.301341, accuracy-1 = 85.76, accuracy-5 = 99.38
[epoch=537/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 14, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.987708)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.156 0.563 0.281  ||  -0.3973 0.8874 0.1910  || discrepancy=0.28 || select=1/3
001/003-th : 0.346 0.302 0.352  ||  0.1760 0.0383 0.1927  || discrepancy=0.01 || select=2/3
002/003-th : 0.006 0.031 0.963  ||  -2.3036 -0.5759 2.8457  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.010 0.012 0.012 0.016 0.021 0.039 0.882  ||  -1.401 -1.076 -0.902 -0.910 -0.610 -0.336 0.261 3.386  || dis=0.84 || select=7/8
001/019-th : 0.083 0.109 0.136 0.126 0.131 0.132 0.159 0.125  ||  -0.399 -0.124 0.103 0.026 0.066 0.069 0.255 0.015     || dis=0.02 || select=6/8
002/019-th : 0.110 0.117 0.131 0.135 0.125 0.134 0.134 0.116  ||  -0.122 -0.062 0.049 0.079 0.003 0.073 0.073 -0.074    || dis=0.00 || select=3/8
003/019-th : 0.115 0.118 0.121 0.127 0.127 0.134 0.135 0.123  ||  -0.082 -0.062 -0.036 0.016 0.009 0.064 0.076 -0.022   || dis=0.00 || select=6/8
004/019-th : 0.112 0.114 0.108 0.122 0.121 0.124 0.155 0.144  ||  -0.096 -0.078 -0.134 -0.012 -0.019 0.007 0.230 0.154  || dis=0.01 || select=6/8
005/019-th : 0.137 0.134 0.116 0.124 0.127 0.126 0.123 0.113  ||  0.090 0.071 -0.071 -0.005 0.013 0.007 -0.015 -0.100   || dis=0.00 || select=0/8
006/019-th : 0.155 0.144 0.128 0.125 0.128 0.114 0.107 0.099  ||  0.228 0.159 0.041 0.013 0.041 -0.080 -0.142 -0.222    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.012 0.014 0.021 0.026 0.046 0.864  ||  -1.465 -1.239 -0.969 -0.770 -0.407 -0.172 0.396 3.324  || dis=0.82 || select=7/8
008/019-th : 0.006 0.009 0.013 0.017 0.025 0.039 0.089 0.802  ||  -1.726 -1.432 -1.010 -0.724 -0.352 0.082 0.914 3.111  || dis=0.71 || select=7/8
009/019-th : 0.086 0.087 0.095 0.112 0.125 0.138 0.159 0.198  ||  -0.331 -0.315 -0.234 -0.066 0.042 0.140 0.283 0.503   || dis=0.04 || select=7/8
010/019-th : 0.089 0.099 0.105 0.115 0.127 0.155 0.153 0.157  ||  -0.312 -0.207 -0.152 -0.061 0.040 0.237 0.229 0.253   || dis=0.00 || select=7/8
011/019-th : 0.128 0.116 0.117 0.120 0.127 0.132 0.134 0.126  ||  0.028 -0.065 -0.064 -0.036 0.024 0.057 0.073 0.015    || dis=0.00 || select=6/8
012/019-th : 0.156 0.143 0.123 0.132 0.123 0.108 0.110 0.106  ||  0.237 0.148 -0.005 0.067 -0.006 -0.131 -0.118 -0.153  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.008 0.965  ||  -1.021 -0.958 -0.926 -0.777 -0.719 -0.509 -0.214 4.561  || dis=0.96 || select=7/8
014/019-th : 0.004 0.003 0.005 0.005 0.006 0.009 0.016 0.953  ||  -1.291 -1.296 -1.033 -0.981 -0.709 -0.369 0.228 4.313  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.964  ||  -1.172 -0.754 -0.959 -0.902 -0.703 -0.511 -0.076 4.569  || dis=0.95 || select=7/8
016/019-th : 0.028 0.036 0.039 0.058 0.085 0.172 0.236 0.347  ||  -1.155 -0.898 -0.819 -0.414 -0.034 0.668 0.987 1.372  || dis=0.11 || select=7/8
017/019-th : 0.084 0.100 0.102 0.116 0.133 0.146 0.161 0.158  ||  -0.372 -0.192 -0.176 -0.046 0.086 0.182 0.281 0.260   || dis=0.00 || select=6/8
018/019-th : 0.095 0.113 0.131 0.145 0.132 0.116 0.128 0.141  ||  -0.261 -0.090 0.057 0.159 0.070 -0.058 0.034 0.132    || dis=0.00 || select=3/8
[epoch=537/600] FLOP : 27.99 MB, ratio : 0.6858, Expected-ratio : 0.7000, Discrepancy : 0.303
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:28:54] [epoch=537/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.770 (3.770)  Prec@1 26.56 (26.56) Prec@5 70.31 (70.31) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:29:00] [epoch=537/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.899 (1.600)  Prec@1 69.64 (59.25) Prec@5 96.43 (89.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 59.25 Prec@5 89.84 Error@1 40.75 Error@5 10.16 Loss:1.600
***[2020-01-29 10:29:01]*** VALID [epoch=537/600] loss = 1.599993, accuracy@1 = 59.25, accuracy@5 = 89.84 | Best-Valid-Acc@1=58.84, Error@1=41.16
Currently, the best validation accuracy found at 537-epoch :: acc@1=59.25, acc@5=89.84, error@1=40.75, error@5=10.16, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:29:01]*** start epoch=538/600 Time Left: [00:33:11], LR=[0.002612 ~ 0.002612], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=538, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.2279673954765154, FLOP=40.81
[Search] : epoch=538/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:29:01] [epoch=538/600][000/098] Time 0.74 (0.74) Data 0.34 (0.34) Base-Loss 0.389 (0.389)  Prec@1 86.72 (86.72) Prec@5 99.61 (99.61) Acls-loss 1.188 (1.188) FLOP-Loss 0.000 (0.000) Arch-Loss 1.188 (1.188)
**TRAIN** [2020-01-29 10:29:26] [epoch=538/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.604 (0.439)  Prec@1 80.95 (85.02) Prec@5 97.02 (99.34) Acls-loss 0.388 (0.565) FLOP-Loss 2.994 (0.204) Arch-Loss 6.376 (0.973)
 **TRAIN** Prec@1 85.02 Prec@5 99.34 Error@1 14.98 Error@5 0.66 Base-Loss:0.439, Arch-Loss=0.973
***[2020-01-29 10:29:26]*** TRAIN [epoch=538/600] base-loss = 0.438786, arch-loss = 0.973230, accuracy-1 = 85.02, accuracy-5 = 99.34
[epoch=538/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.714748)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.155 0.566 0.279  ||  -0.3986 0.8930 0.1858  || discrepancy=0.29 || select=1/3
001/003-th : 0.349 0.301 0.349  ||  0.1835 0.0364 0.1837  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2967 -0.5704 2.8379  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.010 0.012 0.012 0.016 0.021 0.038 0.885  ||  -1.396 -1.070 -0.905 -0.911 -0.630 -0.356 0.247 3.406  || dis=0.85 || select=7/8
001/019-th : 0.081 0.110 0.134 0.127 0.132 0.131 0.158 0.127  ||  -0.418 -0.115 0.088 0.035 0.071 0.064 0.252 0.029     || dis=0.02 || select=6/8
002/019-th : 0.111 0.118 0.132 0.133 0.125 0.132 0.134 0.115  ||  -0.115 -0.054 0.057 0.069 0.001 0.061 0.071 -0.079    || dis=0.00 || select=6/8
003/019-th : 0.117 0.118 0.121 0.129 0.124 0.135 0.134 0.122  ||  -0.070 -0.059 -0.033 0.024 -0.011 0.070 0.070 -0.029  || dis=0.00 || select=5/8
004/019-th : 0.113 0.115 0.108 0.121 0.122 0.123 0.156 0.143  ||  -0.092 -0.070 -0.136 -0.022 -0.013 -0.002 0.235 0.150  || dis=0.01 || select=6/8
005/019-th : 0.138 0.132 0.117 0.123 0.126 0.127 0.123 0.113  ||  0.097 0.058 -0.062 -0.013 0.006 0.019 -0.019 -0.101   || dis=0.01 || select=0/8
006/019-th : 0.156 0.144 0.130 0.124 0.128 0.113 0.106 0.099  ||  0.236 0.157 0.052 0.009 0.041 -0.088 -0.151 -0.222    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.011 0.014 0.021 0.026 0.045 0.866  ||  -1.460 -1.232 -1.003 -0.755 -0.403 -0.180 0.389 3.338  || dis=0.82 || select=7/8
008/019-th : 0.006 0.009 0.013 0.017 0.025 0.039 0.087 0.805  ||  -1.720 -1.425 -1.023 -0.719 -0.367 0.081 0.893 3.121  || dis=0.72 || select=7/8
009/019-th : 0.086 0.086 0.095 0.112 0.125 0.141 0.157 0.197  ||  -0.325 -0.330 -0.229 -0.068 0.046 0.161 0.272 0.498   || dis=0.04 || select=7/8
010/019-th : 0.089 0.099 0.106 0.115 0.128 0.154 0.153 0.157  ||  -0.310 -0.213 -0.141 -0.055 0.045 0.230 0.225 0.252   || dis=0.00 || select=7/8
011/019-th : 0.128 0.118 0.117 0.120 0.127 0.131 0.133 0.126  ||  0.030 -0.053 -0.058 -0.037 0.018 0.051 0.069 0.011    || dis=0.00 || select=6/8
012/019-th : 0.158 0.143 0.122 0.132 0.123 0.108 0.110 0.105  ||  0.245 0.150 -0.009 0.064 -0.006 -0.129 -0.117 -0.162  || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.005 0.005 0.006 0.008 0.966  ||  -1.018 -0.981 -0.922 -0.771 -0.715 -0.508 -0.232 4.581  || dis=0.96 || select=7/8
014/019-th : 0.004 0.003 0.005 0.005 0.006 0.009 0.016 0.953  ||  -1.283 -1.292 -1.030 -0.977 -0.717 -0.366 0.216 4.315  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.168 -0.775 -0.979 -0.899 -0.703 -0.508 -0.075 4.586  || dis=0.96 || select=7/8
016/019-th : 0.028 0.036 0.039 0.058 0.086 0.169 0.236 0.348  ||  -1.145 -0.887 -0.815 -0.417 -0.027 0.648 0.983 1.372  || dis=0.11 || select=7/8
017/019-th : 0.084 0.101 0.101 0.115 0.134 0.144 0.162 0.157  ||  -0.365 -0.187 -0.183 -0.053 0.097 0.171 0.289 0.254   || dis=0.01 || select=6/8
018/019-th : 0.096 0.114 0.129 0.144 0.131 0.118 0.126 0.142  ||  -0.251 -0.083 0.045 0.151 0.060 -0.049 0.020 0.140    || dis=0.00 || select=3/8
[epoch=538/600] FLOP : 28.71 MB, ratio : 0.7036, Expected-ratio : 0.7000, Discrepancy : 0.304
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:29:26] [epoch=538/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.543 (0.543)  Prec@1 82.03 (82.03) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:29:32] [epoch=538/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.574 (1.816)  Prec@1 45.83 (54.82) Prec@5 90.48 (87.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 54.82 Prec@5 87.30 Error@1 45.18 Error@5 12.70 Loss:1.816
***[2020-01-29 10:29:32]*** VALID [epoch=538/600] loss = 1.816159, accuracy@1 = 54.82, accuracy@5 = 87.30 | Best-Valid-Acc@1=59.25, Error@1=40.75
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:29:32]*** start epoch=539/600 Time Left: [00:32:39], LR=[0.002529 ~ 0.002529], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=539, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.22390757977733577, FLOP=40.81
[Search] : epoch=539/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:29:33] [epoch=539/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.268 (0.268)  Prec@1 89.06 (89.06) Prec@5 100.00 (100.00) Acls-loss 0.723 (0.723) FLOP-Loss 2.994 (2.994) Arch-Loss 6.710 (6.710)
**TRAIN** [2020-01-29 10:29:58] [epoch=539/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.330 (0.396)  Prec@1 87.50 (86.46) Prec@5 100.00 (99.42) Acls-loss 0.570 (0.583) FLOP-Loss 2.995 (0.112) Arch-Loss 6.560 (0.808)
 **TRAIN** Prec@1 86.46 Prec@5 99.42 Error@1 13.54 Error@5 0.58 Base-Loss:0.396, Arch-Loss=0.808
***[2020-01-29 10:29:58]*** TRAIN [epoch=539/600] base-loss = 0.396125, arch-loss = 0.807896, accuracy-1 = 86.46, accuracy-5 = 99.42
[epoch=539/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 22.63104)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.156 0.565 0.279  ||  -0.3974 0.8888 0.1837  || discrepancy=0.29 || select=1/3
001/003-th : 0.347 0.305 0.347  ||  0.1812 0.0524 0.1798  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.032 0.963  ||  -2.3013 -0.5678 2.8417  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.010 0.012 0.012 0.016 0.020 0.037 0.885  ||  -1.402 -1.064 -0.903 -0.906 -0.625 -0.357 0.244 3.410  || dis=0.85 || select=7/8
001/019-th : 0.081 0.110 0.133 0.128 0.131 0.132 0.159 0.128  ||  -0.418 -0.116 0.074 0.036 0.066 0.067 0.255 0.036     || dis=0.03 || select=6/8
002/019-th : 0.109 0.117 0.132 0.133 0.124 0.135 0.134 0.115  ||  -0.132 -0.057 0.062 0.066 -0.001 0.085 0.072 -0.077   || dis=0.00 || select=5/8
003/019-th : 0.118 0.119 0.122 0.130 0.125 0.132 0.134 0.121  ||  -0.065 -0.055 -0.030 0.037 -0.007 0.051 0.068 -0.033  || dis=0.00 || select=6/8
004/019-th : 0.110 0.115 0.108 0.120 0.122 0.124 0.159 0.143  ||  -0.112 -0.070 -0.136 -0.027 -0.015 0.001 0.251 0.148  || dis=0.02 || select=6/8
005/019-th : 0.138 0.133 0.118 0.122 0.125 0.128 0.122 0.113  ||  0.097 0.064 -0.057 -0.023 0.003 0.027 -0.025 -0.105   || dis=0.01 || select=0/8
006/019-th : 0.156 0.146 0.129 0.126 0.127 0.113 0.105 0.098  ||  0.238 0.167 0.050 0.021 0.032 -0.084 -0.164 -0.227    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.011 0.015 0.020 0.026 0.045 0.867  ||  -1.451 -1.227 -1.004 -0.750 -0.418 -0.178 0.389 3.339  || dis=0.82 || select=7/8
008/019-th : 0.006 0.009 0.013 0.017 0.024 0.038 0.084 0.809  ||  -1.714 -1.425 -1.026 -0.714 -0.367 0.078 0.864 3.130  || dis=0.73 || select=7/8
009/019-th : 0.087 0.085 0.095 0.112 0.125 0.141 0.158 0.196  ||  -0.317 -0.341 -0.228 -0.068 0.047 0.163 0.277 0.494   || dis=0.04 || select=7/8
010/019-th : 0.090 0.099 0.106 0.115 0.128 0.153 0.152 0.158  ||  -0.309 -0.209 -0.139 -0.062 0.046 0.224 0.222 0.257   || dis=0.01 || select=7/8
011/019-th : 0.129 0.118 0.119 0.119 0.127 0.131 0.132 0.126  ||  0.033 -0.050 -0.044 -0.046 0.020 0.048 0.056 0.013    || dis=0.00 || select=6/8
012/019-th : 0.158 0.143 0.123 0.132 0.122 0.109 0.109 0.105  ||  0.246 0.152 -0.006 0.067 -0.012 -0.126 -0.121 -0.165  || dis=0.02 || select=0/8
013/019-th : 0.004 0.004 0.004 0.004 0.005 0.006 0.008 0.966  ||  -1.008 -0.998 -0.919 -0.797 -0.710 -0.508 -0.232 4.600  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.009 0.016 0.954  ||  -1.305 -1.286 -1.046 -0.993 -0.713 -0.366 0.230 4.340  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.164 -0.774 -0.977 -0.896 -0.703 -0.507 -0.075 4.583  || dis=0.96 || select=7/8
016/019-th : 0.028 0.036 0.039 0.058 0.083 0.170 0.235 0.351  ||  -1.131 -0.883 -0.817 -0.424 -0.059 0.657 0.978 1.382  || dis=0.12 || select=7/8
017/019-th : 0.083 0.099 0.101 0.115 0.134 0.145 0.161 0.162  ||  -0.377 -0.205 -0.186 -0.060 0.095 0.178 0.279 0.285   || dis=0.00 || select=7/8
018/019-th : 0.094 0.113 0.130 0.144 0.131 0.117 0.126 0.145  ||  -0.270 -0.090 0.051 0.155 0.059 -0.053 0.017 0.161    || dis=0.00 || select=7/8
[epoch=539/600] FLOP : 22.63 MB, ratio : 0.5545, Expected-ratio : 0.7000, Discrepancy : 0.305
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:29:59] [epoch=539/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 0.958 (0.958)  Prec@1 76.17 (76.17) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:30:05] [epoch=539/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.139 (2.114)  Prec@1 63.69 (56.08) Prec@5 96.43 (88.88) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.08 Prec@5 88.88 Error@1 43.92 Error@5 11.12 Loss:2.114
***[2020-01-29 10:30:05]*** VALID [epoch=539/600] loss = 2.114330, accuracy@1 = 56.08, accuracy@5 = 88.88 | Best-Valid-Acc@1=59.25, Error@1=40.75
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:30:05]*** start epoch=540/600 Time Left: [00:32:06], LR=[0.002447 ~ 0.002447], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=540, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.21991153507687386, FLOP=40.81
[Search] : epoch=540/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:30:06] [epoch=540/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.303 (0.303)  Prec@1 91.41 (91.41) Prec@5 99.61 (99.61) Acls-loss 0.562 (0.562) FLOP-Loss -2.995 (-2.995) Arch-Loss -5.427 (-5.427)
**TRAIN** [2020-01-29 10:30:31] [epoch=540/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.343 (0.397)  Prec@1 86.31 (86.64) Prec@5 100.00 (99.47) Acls-loss 0.648 (0.578) FLOP-Loss 2.996 (0.112) Arch-Loss 6.639 (0.803)
 **TRAIN** Prec@1 86.64 Prec@5 99.47 Error@1 13.36 Error@5 0.53 Base-Loss:0.397, Arch-Loss=0.803
***[2020-01-29 10:30:31]*** TRAIN [epoch=540/600] base-loss = 0.396755, arch-loss = 0.802842, accuracy-1 = 86.64, accuracy-5 = 99.47
[epoch=540/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.3408)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.156 0.565 0.279  ||  -0.3975 0.8886 0.1812  || discrepancy=0.29 || select=1/3
001/003-th : 0.348 0.305 0.347  ||  0.1810 0.0518 0.1793  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.032 0.963  ||  -2.2932 -0.5813 2.8377  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.010 0.012 0.012 0.016 0.020 0.036 0.888  ||  -1.406 -1.059 -0.903 -0.902 -0.619 -0.373 0.218 3.425  || dis=0.85 || select=7/8
001/019-th : 0.081 0.110 0.132 0.127 0.131 0.131 0.158 0.128  ||  -0.416 -0.113 0.072 0.033 0.066 0.065 0.249 0.040     || dis=0.03 || select=6/8
002/019-th : 0.108 0.118 0.132 0.135 0.125 0.134 0.134 0.114  ||  -0.138 -0.054 0.064 0.081 0.009 0.078 0.075 -0.083    || dis=0.00 || select=3/8
003/019-th : 0.117 0.119 0.119 0.133 0.125 0.134 0.133 0.120  ||  -0.068 -0.049 -0.054 0.062 -0.002 0.069 0.059 -0.040  || dis=0.00 || select=5/8
004/019-th : 0.111 0.115 0.108 0.118 0.122 0.126 0.158 0.141  ||  -0.106 -0.070 -0.129 -0.042 -0.014 0.017 0.249 0.136  || dis=0.02 || select=6/8
005/019-th : 0.138 0.134 0.120 0.122 0.124 0.129 0.121 0.113  ||  0.097 0.068 -0.044 -0.024 -0.011 0.027 -0.034 -0.102  || dis=0.00 || select=0/8
006/019-th : 0.157 0.145 0.130 0.126 0.126 0.112 0.104 0.099  ||  0.241 0.164 0.056 0.024 0.024 -0.093 -0.168 -0.218    || dis=0.01 || select=0/8
007/019-th : 0.007 0.009 0.011 0.014 0.019 0.025 0.044 0.872  ||  -1.440 -1.234 -1.021 -0.774 -0.431 -0.180 0.382 3.375  || dis=0.83 || select=7/8
008/019-th : 0.006 0.008 0.012 0.017 0.024 0.038 0.081 0.813  ||  -1.707 -1.418 -1.048 -0.749 -0.364 0.086 0.845 3.148  || dis=0.73 || select=7/8
009/019-th : 0.087 0.086 0.097 0.112 0.124 0.141 0.158 0.195  ||  -0.315 -0.336 -0.208 -0.070 0.035 0.161 0.279 0.485   || dis=0.04 || select=7/8
010/019-th : 0.090 0.097 0.107 0.114 0.127 0.152 0.151 0.162  ||  -0.307 -0.227 -0.129 -0.068 0.039 0.220 0.217 0.284   || dis=0.01 || select=7/8
011/019-th : 0.128 0.118 0.120 0.120 0.126 0.129 0.132 0.127  ||  0.030 -0.050 -0.036 -0.041 0.012 0.033 0.056 0.020    || dis=0.00 || select=6/8
012/019-th : 0.157 0.143 0.123 0.129 0.120 0.112 0.109 0.106  ||  0.242 0.148 -0.002 0.045 -0.027 -0.099 -0.123 -0.157  || dis=0.01 || select=0/8
013/019-th : 0.004 0.004 0.004 0.004 0.005 0.006 0.008 0.966  ||  -0.998 -0.998 -0.915 -0.794 -0.712 -0.506 -0.231 4.596  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.009 0.016 0.954  ||  -1.302 -1.282 -1.043 -0.993 -0.724 -0.364 0.232 4.339  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.176 -0.771 -0.974 -0.892 -0.699 -0.505 -0.073 4.583  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.039 0.058 0.081 0.167 0.232 0.358  ||  -1.148 -0.866 -0.819 -0.414 -0.081 0.646 0.971 1.407  || dis=0.13 || select=7/8
017/019-th : 0.084 0.098 0.101 0.115 0.134 0.147 0.159 0.161  ||  -0.373 -0.215 -0.184 -0.052 0.098 0.187 0.271 0.283   || dis=0.00 || select=7/8
018/019-th : 0.094 0.112 0.130 0.143 0.132 0.116 0.125 0.147  ||  -0.269 -0.098 0.050 0.147 0.069 -0.060 0.008 0.173    || dis=0.00 || select=7/8
[epoch=540/600] FLOP : 21.34 MB, ratio : 0.5229, Expected-ratio : 0.7000, Discrepancy : 0.306
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:30:31] [epoch=540/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 0.893 (0.893)  Prec@1 71.09 (71.09) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:30:38] [epoch=540/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.612 (1.356)  Prec@1 78.57 (62.78) Prec@5 98.81 (92.21) Size=[168, 3, 32, 32]
 **VALID** Prec@1 62.78 Prec@5 92.21 Error@1 37.22 Error@5 7.79 Loss:1.356
***[2020-01-29 10:30:38]*** VALID [epoch=540/600] loss = 1.355546, accuracy@1 = 62.78, accuracy@5 = 92.21 | Best-Valid-Acc@1=59.25, Error@1=40.75
Currently, the best validation accuracy found at 540-epoch :: acc@1=62.78, acc@5=92.21, error@1=37.22, error@5=7.79, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:30:38]*** start epoch=541/600 Time Left: [00:31:34], LR=[0.002367 ~ 0.002367], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=541, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.21597937092871386, FLOP=40.81
[Search] : epoch=541/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:30:38] [epoch=541/600][000/098] Time 0.65 (0.65) Data 0.35 (0.35) Base-Loss 0.318 (0.318)  Prec@1 90.23 (90.23) Prec@5 99.61 (99.61) Acls-loss 0.448 (0.448) FLOP-Loss -2.995 (-2.995) Arch-Loss -5.543 (-5.543)
**TRAIN** [2020-01-29 10:31:03] [epoch=541/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.384 (0.386)  Prec@1 83.93 (86.84) Prec@5 100.00 (99.56) Acls-loss 0.681 (0.556) FLOP-Loss 2.997 (0.051) Arch-Loss 6.676 (0.658)
 **TRAIN** Prec@1 86.84 Prec@5 99.56 Error@1 13.16 Error@5 0.44 Base-Loss:0.386, Arch-Loss=0.658
***[2020-01-29 10:31:04]*** TRAIN [epoch=541/600] base-loss = 0.385874, arch-loss = 0.657915, accuracy-1 = 86.84, accuracy-5 = 99.56
[epoch=541/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.43296)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.151 0.574 0.275  ||  -0.4169 0.9193 0.1813  || discrepancy=0.30 || select=1/3
001/003-th : 0.347 0.306 0.347  ||  0.1799 0.0538 0.1792  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.032 0.963  ||  -2.2851 -0.5827 2.8305  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.010 0.012 0.012 0.016 0.020 0.036 0.888  ||  -1.398 -1.058 -0.896 -0.906 -0.616 -0.372 0.210 3.426  || dis=0.85 || select=7/8
001/019-th : 0.080 0.110 0.130 0.127 0.132 0.132 0.160 0.128  ||  -0.427 -0.114 0.058 0.032 0.071 0.073 0.262 0.043     || dis=0.03 || select=6/8
002/019-th : 0.108 0.117 0.130 0.135 0.126 0.135 0.135 0.115  ||  -0.143 -0.056 0.050 0.083 0.013 0.083 0.082 -0.080    || dis=0.00 || select=5/8
003/019-th : 0.116 0.117 0.118 0.134 0.129 0.133 0.133 0.120  ||  -0.075 -0.064 -0.055 0.069 0.029 0.065 0.060 -0.038   || dis=0.00 || select=3/8
004/019-th : 0.110 0.113 0.109 0.119 0.123 0.126 0.159 0.143  ||  -0.118 -0.090 -0.128 -0.039 -0.006 0.019 0.252 0.147  || dis=0.02 || select=6/8
005/019-th : 0.137 0.134 0.121 0.122 0.123 0.126 0.122 0.115  ||  0.091 0.068 -0.037 -0.028 -0.014 0.004 -0.026 -0.082  || dis=0.00 || select=0/8
006/019-th : 0.157 0.146 0.131 0.126 0.125 0.113 0.104 0.099  ||  0.243 0.167 0.058 0.024 0.015 -0.090 -0.172 -0.218    || dis=0.01 || select=0/8
007/019-th : 0.007 0.008 0.010 0.013 0.019 0.024 0.042 0.877  ||  -1.432 -1.244 -1.038 -0.786 -0.440 -0.190 0.362 3.412  || dis=0.83 || select=7/8
008/019-th : 0.006 0.008 0.012 0.016 0.024 0.038 0.080 0.815  ||  -1.700 -1.431 -1.048 -0.749 -0.369 0.081 0.839 3.160  || dis=0.73 || select=7/8
009/019-th : 0.088 0.086 0.097 0.111 0.124 0.140 0.159 0.196  ||  -0.306 -0.336 -0.214 -0.079 0.032 0.152 0.285 0.490   || dis=0.04 || select=7/8
010/019-th : 0.088 0.097 0.108 0.114 0.125 0.151 0.154 0.164  ||  -0.329 -0.228 -0.122 -0.067 0.029 0.214 0.236 0.298   || dis=0.01 || select=7/8
011/019-th : 0.128 0.116 0.121 0.121 0.124 0.128 0.132 0.130  ||  0.027 -0.073 -0.032 -0.029 -0.001 0.030 0.059 0.043   || dis=0.00 || select=6/8
012/019-th : 0.157 0.143 0.124 0.127 0.120 0.113 0.110 0.105  ||  0.239 0.149 0.004 0.027 -0.033 -0.087 -0.114 -0.162   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.004 0.004 0.005 0.006 0.007 0.968  ||  -1.014 -1.009 -0.934 -0.818 -0.708 -0.504 -0.245 4.634  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.009 0.016 0.954  ||  -1.299 -1.276 -1.041 -0.992 -0.721 -0.369 0.230 4.336  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.192 -0.768 -0.972 -0.888 -0.696 -0.505 -0.073 4.586  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.039 0.058 0.081 0.169 0.230 0.358  ||  -1.140 -0.867 -0.825 -0.407 -0.085 0.655 0.962 1.405  || dis=0.13 || select=7/8
017/019-th : 0.083 0.098 0.102 0.115 0.133 0.147 0.159 0.164  ||  -0.381 -0.217 -0.179 -0.055 0.089 0.189 0.265 0.296   || dis=0.01 || select=7/8
018/019-th : 0.093 0.111 0.129 0.144 0.132 0.117 0.126 0.147  ||  -0.279 -0.102 0.043 0.151 0.070 -0.051 0.017 0.176    || dis=0.00 || select=7/8
[epoch=541/600] FLOP : 21.43 MB, ratio : 0.5251, Expected-ratio : 0.7000, Discrepancy : 0.307
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:31:04] [epoch=541/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.175 (3.175)  Prec@1 28.91 (28.91) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:31:10] [epoch=541/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.614 (1.980)  Prec@1 80.36 (55.42) Prec@5 98.81 (87.44) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.42 Prec@5 87.44 Error@1 44.58 Error@5 12.56 Loss:1.980
***[2020-01-29 10:31:10]*** VALID [epoch=541/600] loss = 1.980027, accuracy@1 = 55.42, accuracy@5 = 87.44 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:31:10]*** start epoch=542/600 Time Left: [00:31:02], LR=[0.002288 ~ 0.002288], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=542, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.21211119513512178, FLOP=40.81
[Search] : epoch=542/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:31:11] [epoch=542/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.211 (0.211)  Prec@1 92.97 (92.97) Prec@5 100.00 (100.00) Acls-loss 0.631 (0.631) FLOP-Loss -2.997 (-2.997) Arch-Loss -5.363 (-5.363)
**TRAIN** [2020-01-29 10:31:36] [epoch=542/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.465 (0.418)  Prec@1 85.71 (86.14) Prec@5 98.21 (99.36) Acls-loss 0.727 (0.560) FLOP-Loss 2.997 (0.112) Arch-Loss 6.722 (0.785)
 **TRAIN** Prec@1 86.14 Prec@5 99.36 Error@1 13.86 Error@5 0.64 Base-Loss:0.418, Arch-Loss=0.785
***[2020-01-29 10:31:36]*** TRAIN [epoch=542/600] base-loss = 0.418075, arch-loss = 0.784962, accuracy-1 = 86.14, accuracy-5 = 99.36
[epoch=542/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.3408)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.151 0.575 0.274  ||  -0.4179 0.9214 0.1791  || discrepancy=0.30 || select=1/3
001/003-th : 0.347 0.306 0.347  ||  0.1797 0.0530 0.1788  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.032 0.962  ||  -2.2773 -0.5714 2.8199  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.010 0.012 0.011 0.016 0.020 0.034 0.890  ||  -1.389 -1.068 -0.889 -0.914 -0.611 -0.372 0.187 3.439  || dis=0.86 || select=7/8
001/019-th : 0.081 0.108 0.130 0.130 0.132 0.132 0.159 0.129  ||  -0.421 -0.132 0.055 0.060 0.070 0.072 0.257 0.048     || dis=0.03 || select=6/8
002/019-th : 0.108 0.117 0.132 0.135 0.126 0.134 0.134 0.115  ||  -0.138 -0.059 0.059 0.082 0.016 0.077 0.075 -0.079    || dis=0.00 || select=3/8
003/019-th : 0.115 0.117 0.117 0.134 0.128 0.135 0.132 0.121  ||  -0.080 -0.066 -0.063 0.067 0.026 0.080 0.054 -0.030   || dis=0.00 || select=5/8
004/019-th : 0.107 0.114 0.109 0.117 0.124 0.126 0.159 0.144  ||  -0.139 -0.081 -0.125 -0.054 0.007 0.020 0.257 0.155   || dis=0.02 || select=6/8
005/019-th : 0.138 0.133 0.122 0.122 0.123 0.125 0.122 0.115  ||  0.094 0.060 -0.024 -0.022 -0.016 -0.003 -0.028 -0.082  || dis=0.01 || select=0/8
006/019-th : 0.157 0.146 0.131 0.127 0.124 0.113 0.103 0.099  ||  0.245 0.171 0.065 0.028 0.006 -0.084 -0.181 -0.220    || dis=0.01 || select=0/8
007/019-th : 0.007 0.008 0.010 0.013 0.018 0.023 0.040 0.881  ||  -1.452 -1.243 -1.039 -0.784 -0.462 -0.189 0.354 3.439  || dis=0.84 || select=7/8
008/019-th : 0.006 0.008 0.012 0.016 0.024 0.037 0.078 0.819  ||  -1.704 -1.423 -1.049 -0.757 -0.375 0.073 0.823 3.175  || dis=0.74 || select=7/8
009/019-th : 0.088 0.086 0.097 0.111 0.124 0.141 0.155 0.199  ||  -0.314 -0.339 -0.209 -0.080 0.031 0.161 0.257 0.506   || dis=0.04 || select=7/8
010/019-th : 0.087 0.097 0.108 0.114 0.124 0.150 0.156 0.164  ||  -0.338 -0.226 -0.120 -0.066 0.020 0.211 0.251 0.297   || dis=0.01 || select=7/8
011/019-th : 0.128 0.116 0.121 0.121 0.125 0.128 0.132 0.129  ||  0.029 -0.071 -0.030 -0.033 0.006 0.029 0.055 0.039    || dis=0.00 || select=6/8
012/019-th : 0.157 0.143 0.125 0.127 0.120 0.113 0.110 0.105  ||  0.241 0.147 0.010 0.023 -0.027 -0.091 -0.118 -0.162   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.004 0.004 0.005 0.005 0.007 0.968  ||  -1.007 -1.007 -0.940 -0.835 -0.703 -0.524 -0.234 4.649  || dis=0.96 || select=7/8
014/019-th : 0.003 0.004 0.004 0.005 0.006 0.009 0.016 0.953  ||  -1.297 -1.270 -1.039 -0.989 -0.719 -0.366 0.227 4.332  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.188 -0.765 -0.971 -0.896 -0.696 -0.506 -0.074 4.588  || dis=0.96 || select=7/8
016/019-th : 0.029 0.038 0.039 0.058 0.081 0.170 0.229 0.357  ||  -1.126 -0.855 -0.817 -0.416 -0.086 0.654 0.953 1.399  || dis=0.13 || select=7/8
017/019-th : 0.084 0.099 0.102 0.116 0.132 0.147 0.158 0.163  ||  -0.374 -0.210 -0.177 -0.053 0.083 0.185 0.260 0.291   || dis=0.01 || select=7/8
018/019-th : 0.094 0.111 0.128 0.144 0.134 0.118 0.125 0.146  ||  -0.272 -0.107 0.033 0.156 0.079 -0.043 0.014 0.168    || dis=0.00 || select=7/8
[epoch=542/600] FLOP : 21.34 MB, ratio : 0.5229, Expected-ratio : 0.7000, Discrepancy : 0.308
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:31:36] [epoch=542/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 6.138 (6.138)  Prec@1 33.98 (33.98) Prec@5 72.27 (72.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:31:42] [epoch=542/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.147 (1.904)  Prec@1 69.05 (56.85) Prec@5 93.45 (90.10) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.85 Prec@5 90.10 Error@1 43.15 Error@5 9.90 Loss:1.904
***[2020-01-29 10:31:42]*** VALID [epoch=542/600] loss = 1.903880, accuracy@1 = 56.85, accuracy@5 = 90.10 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:31:42]*** start epoch=543/600 Time Left: [00:30:30], LR=[0.002210 ~ 0.002210], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=543, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.20830711374409122, FLOP=40.81
[Search] : epoch=543/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:31:43] [epoch=543/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.397 (0.397)  Prec@1 86.33 (86.33) Prec@5 99.61 (99.61) Acls-loss 0.607 (0.607) FLOP-Loss -2.997 (-2.997) Arch-Loss -5.387 (-5.387)
**TRAIN** [2020-01-29 10:32:08] [epoch=543/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.194 (0.407)  Prec@1 92.86 (86.43) Prec@5 100.00 (99.49) Acls-loss 0.624 (0.573) FLOP-Loss 0.000 (0.123) Arch-Loss 0.624 (0.818)
 **TRAIN** Prec@1 86.43 Prec@5 99.49 Error@1 13.57 Error@5 0.51 Base-Loss:0.407, Arch-Loss=0.818
***[2020-01-29 10:32:08]*** TRAIN [epoch=543/600] base-loss = 0.407467, arch-loss = 0.818250, accuracy-1 = 86.43, accuracy-5 = 99.49
[epoch=543/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.975036)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.150 0.577 0.273  ||  -0.4206 0.9268 0.1768  || discrepancy=0.30 || select=1/3
001/003-th : 0.345 0.307 0.347  ||  0.1759 0.0596 0.1808  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2691 -0.5663 2.8107  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.015 0.019 0.033 0.893  ||  -1.381 -1.111 -0.880 -0.910 -0.600 -0.376 0.172 3.462  || dis=0.86 || select=7/8
001/019-th : 0.081 0.106 0.130 0.131 0.134 0.131 0.159 0.128  ||  -0.417 -0.147 0.058 0.068 0.085 0.069 0.259 0.046     || dis=0.02 || select=6/8
002/019-th : 0.109 0.118 0.131 0.135 0.124 0.133 0.134 0.115  ||  -0.129 -0.051 0.051 0.080 -0.002 0.070 0.076 -0.082   || dis=0.00 || select=3/8
003/019-th : 0.116 0.117 0.118 0.133 0.127 0.137 0.131 0.121  ||  -0.073 -0.069 -0.058 0.066 0.018 0.092 0.046 -0.033   || dis=0.00 || select=5/8
004/019-th : 0.108 0.113 0.109 0.118 0.124 0.124 0.158 0.145  ||  -0.133 -0.090 -0.120 -0.048 0.005 0.005 0.250 0.164   || dis=0.01 || select=6/8
005/019-th : 0.138 0.132 0.122 0.125 0.122 0.125 0.121 0.115  ||  0.101 0.054 -0.022 -0.001 -0.027 -0.003 -0.033 -0.084  || dis=0.01 || select=0/8
006/019-th : 0.158 0.146 0.132 0.126 0.124 0.113 0.103 0.099  ||  0.247 0.168 0.068 0.026 0.004 -0.085 -0.178 -0.221    || dis=0.01 || select=0/8
007/019-th : 0.007 0.008 0.010 0.013 0.017 0.023 0.039 0.884  ||  -1.447 -1.239 -1.056 -0.781 -0.488 -0.197 0.346 3.461  || dis=0.84 || select=7/8
008/019-th : 0.006 0.008 0.012 0.016 0.023 0.035 0.075 0.825  ||  -1.694 -1.448 -1.042 -0.767 -0.392 0.052 0.814 3.206  || dis=0.75 || select=7/8
009/019-th : 0.087 0.085 0.098 0.111 0.123 0.142 0.155 0.200  ||  -0.326 -0.341 -0.205 -0.075 0.023 0.172 0.255 0.511   || dis=0.05 || select=7/8
010/019-th : 0.087 0.097 0.107 0.115 0.124 0.150 0.157 0.163  ||  -0.339 -0.222 -0.128 -0.058 0.018 0.208 0.254 0.295   || dis=0.01 || select=7/8
011/019-th : 0.128 0.116 0.120 0.122 0.125 0.128 0.132 0.129  ||  0.031 -0.071 -0.036 -0.021 0.004 0.027 0.058 0.033    || dis=0.00 || select=6/8
012/019-th : 0.158 0.144 0.123 0.126 0.121 0.113 0.109 0.106  ||  0.245 0.149 -0.004 0.019 -0.019 -0.091 -0.129 -0.156  || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.004 0.004 0.005 0.005 0.007 0.968  ||  -1.001 -1.005 -0.936 -0.837 -0.698 -0.526 -0.237 4.649  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.009 0.016 0.954  ||  -1.293 -1.274 -1.036 -0.997 -0.716 -0.368 0.227 4.335  || dis=0.94 || select=7/8
015/019-th : 0.003 0.004 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.220 -0.762 -0.968 -0.893 -0.695 -0.505 -0.104 4.614  || dis=0.96 || select=7/8
016/019-th : 0.029 0.038 0.039 0.059 0.081 0.169 0.228 0.358  ||  -1.119 -0.850 -0.807 -0.413 -0.091 0.646 0.946 1.398  || dis=0.13 || select=7/8
017/019-th : 0.084 0.099 0.102 0.117 0.133 0.144 0.158 0.163  ||  -0.369 -0.211 -0.176 -0.038 0.084 0.168 0.261 0.289   || dis=0.01 || select=7/8
018/019-th : 0.095 0.111 0.129 0.145 0.132 0.118 0.126 0.145  ||  -0.266 -0.107 0.043 0.163 0.063 -0.046 0.018 0.161    || dis=0.00 || select=3/8
[epoch=543/600] FLOP : 27.98 MB, ratio : 0.6854, Expected-ratio : 0.7000, Discrepancy : 0.309
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:32:08] [epoch=543/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.467 (0.467)  Prec@1 83.59 (83.59) Prec@5 99.61 (99.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:32:14] [epoch=543/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.423 (1.774)  Prec@1 63.69 (57.52) Prec@5 95.24 (89.25) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.52 Prec@5 89.25 Error@1 42.48 Error@5 10.75 Loss:1.774
***[2020-01-29 10:32:14]*** VALID [epoch=543/600] loss = 1.773574, accuracy@1 = 57.52, accuracy@5 = 89.25 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:32:14]*** start epoch=544/600 Time Left: [00:29:58], LR=[0.002134 ~ 0.002134], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=544, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.20456723104643526, FLOP=40.81
[Search] : epoch=544/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:32:15] [epoch=544/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.310 (0.310)  Prec@1 89.84 (89.84) Prec@5 100.00 (100.00) Acls-loss 0.500 (0.500) FLOP-Loss 0.000 (0.000) Arch-Loss 0.500 (0.500)
**TRAIN** [2020-01-29 10:32:40] [epoch=544/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.439 (0.386)  Prec@1 85.71 (86.98) Prec@5 98.81 (99.49) Acls-loss 0.552 (0.570) FLOP-Loss 0.000 (0.092) Arch-Loss 0.552 (0.755)
 **TRAIN** Prec@1 86.98 Prec@5 99.49 Error@1 13.02 Error@5 0.51 Base-Loss:0.386, Arch-Loss=0.755
***[2020-01-29 10:32:40]*** TRAIN [epoch=544/600] base-loss = 0.386098, arch-loss = 0.754518, accuracy-1 = 86.98, accuracy-5 = 99.49
[epoch=544/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 9, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.351868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.149 0.577 0.275  ||  -0.4290 0.9246 0.1824  || discrepancy=0.30 || select=1/3
001/003-th : 0.346 0.307 0.347  ||  0.1760 0.0583 0.1803  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2608 -0.5691 2.8040  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.015 0.019 0.033 0.893  ||  -1.372 -1.106 -0.873 -0.906 -0.614 -0.372 0.164 3.462  || dis=0.86 || select=7/8
001/019-th : 0.081 0.104 0.131 0.130 0.135 0.131 0.159 0.129  ||  -0.414 -0.163 0.064 0.059 0.095 0.068 0.258 0.053     || dis=0.02 || select=6/8
002/019-th : 0.109 0.118 0.131 0.135 0.123 0.133 0.136 0.115  ||  -0.130 -0.054 0.053 0.081 -0.010 0.063 0.089 -0.082   || dis=0.00 || select=6/8
003/019-th : 0.115 0.116 0.118 0.137 0.126 0.135 0.132 0.121  ||  -0.078 -0.075 -0.053 0.091 0.006 0.077 0.055 -0.029   || dis=0.00 || select=3/8
004/019-th : 0.108 0.113 0.109 0.117 0.124 0.125 0.160 0.145  ||  -0.135 -0.088 -0.126 -0.056 0.008 0.013 0.257 0.159   || dis=0.02 || select=6/8
005/019-th : 0.139 0.131 0.123 0.125 0.122 0.124 0.122 0.115  ||  0.103 0.045 -0.019 -0.003 -0.025 -0.007 -0.028 -0.083  || dis=0.01 || select=0/8
006/019-th : 0.158 0.146 0.132 0.123 0.125 0.113 0.104 0.099  ||  0.246 0.168 0.067 -0.005 0.011 -0.084 -0.167 -0.218   || dis=0.01 || select=0/8
007/019-th : 0.007 0.008 0.010 0.013 0.017 0.023 0.039 0.885  ||  -1.440 -1.233 -1.052 -0.783 -0.502 -0.195 0.340 3.464  || dis=0.85 || select=7/8
008/019-th : 0.006 0.008 0.012 0.016 0.023 0.035 0.073 0.828  ||  -1.686 -1.442 -1.035 -0.767 -0.393 0.053 0.776 3.210  || dis=0.76 || select=7/8
009/019-th : 0.087 0.086 0.099 0.111 0.121 0.142 0.155 0.200  ||  -0.320 -0.334 -0.197 -0.081 0.008 0.168 0.257 0.508   || dis=0.05 || select=7/8
010/019-th : 0.087 0.097 0.107 0.116 0.124 0.151 0.156 0.162  ||  -0.339 -0.221 -0.132 -0.046 0.023 0.214 0.248 0.289   || dis=0.01 || select=7/8
011/019-th : 0.129 0.114 0.120 0.121 0.126 0.128 0.132 0.130  ||  0.037 -0.089 -0.040 -0.025 0.011 0.032 0.058 0.045    || dis=0.00 || select=6/8
012/019-th : 0.158 0.144 0.123 0.127 0.121 0.114 0.108 0.105  ||  0.243 0.151 -0.002 0.025 -0.019 -0.084 -0.132 -0.159  || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.004 0.004 0.005 0.005 0.007 0.968  ||  -0.993 -1.002 -0.933 -0.841 -0.699 -0.524 -0.236 4.648  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.006 0.008 0.015 0.956  ||  -1.289 -1.296 -1.042 -0.994 -0.754 -0.366 0.204 4.373  || dis=0.94 || select=7/8
015/019-th : 0.003 0.004 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.217 -0.765 -0.966 -0.892 -0.691 -0.503 -0.109 4.613  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.038 0.059 0.080 0.167 0.228 0.362  ||  -1.136 -0.860 -0.829 -0.391 -0.094 0.640 0.955 1.415  || dis=0.13 || select=7/8
017/019-th : 0.085 0.099 0.103 0.116 0.134 0.142 0.157 0.164  ||  -0.364 -0.208 -0.167 -0.052 0.094 0.154 0.254 0.294   || dis=0.01 || select=7/8
018/019-th : 0.095 0.111 0.127 0.148 0.131 0.119 0.126 0.143  ||  -0.264 -0.110 0.031 0.183 0.063 -0.036 0.019 0.150    || dis=0.01 || select=3/8
[epoch=544/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.310
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:32:40] [epoch=544/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.242 (2.242)  Prec@1 22.66 (22.66) Prec@5 62.89 (62.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:32:46] [epoch=544/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.464 (1.632)  Prec@1 83.93 (61.62) Prec@5 99.40 (90.87) Size=[168, 3, 32, 32]
 **VALID** Prec@1 61.62 Prec@5 90.87 Error@1 38.38 Error@5 9.13 Loss:1.632
***[2020-01-29 10:32:46]*** VALID [epoch=544/600] loss = 1.631838, accuracy@1 = 61.62, accuracy@5 = 90.87 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:32:46]*** start epoch=545/600 Time Left: [00:29:26], LR=[0.002059 ~ 0.002059], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=545, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.20089164957292704, FLOP=40.81
[Search] : epoch=545/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:32:47] [epoch=545/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.282 (0.282)  Prec@1 91.41 (91.41) Prec@5 99.61 (99.61) Acls-loss 0.408 (0.408) FLOP-Loss 0.000 (0.000) Arch-Loss 0.408 (0.408)
**TRAIN** [2020-01-29 10:33:12] [epoch=545/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.348 (0.385)  Prec@1 90.48 (86.88) Prec@5 100.00 (99.42) Acls-loss 0.372 (0.584) FLOP-Loss 0.000 (0.000) Arch-Loss 0.372 (0.584)
 **TRAIN** Prec@1 86.88 Prec@5 99.42 Error@1 13.12 Error@5 0.58 Base-Loss:0.385, Arch-Loss=0.584
***[2020-01-29 10:33:12]*** TRAIN [epoch=545/600] base-loss = 0.385241, arch-loss = 0.583835, accuracy-1 = 86.88, accuracy-5 = 99.42
[epoch=545/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 9, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.351868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.148 0.577 0.275  ||  -0.4356 0.9245 0.1857  || discrepancy=0.30 || select=1/3
001/003-th : 0.343 0.309 0.347  ||  0.1707 0.0675 0.1835  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2515 -0.5682 2.7952  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.015 0.019 0.033 0.894  ||  -1.373 -1.101 -0.865 -0.901 -0.624 -0.391 0.168 3.469  || dis=0.86 || select=7/8
001/019-th : 0.080 0.103 0.130 0.129 0.135 0.133 0.159 0.131  ||  -0.422 -0.172 0.057 0.051 0.096 0.083 0.262 0.064     || dis=0.02 || select=6/8
002/019-th : 0.109 0.117 0.131 0.133 0.125 0.132 0.136 0.116  ||  -0.131 -0.066 0.052 0.069 0.006 0.059 0.090 -0.071    || dis=0.00 || select=6/8
003/019-th : 0.115 0.115 0.118 0.137 0.126 0.135 0.132 0.123  ||  -0.082 -0.083 -0.057 0.092 0.006 0.077 0.058 -0.018   || dis=0.00 || select=3/8
004/019-th : 0.107 0.112 0.109 0.114 0.125 0.126 0.161 0.146  ||  -0.142 -0.095 -0.123 -0.076 0.011 0.019 0.263 0.167   || dis=0.02 || select=6/8
005/019-th : 0.137 0.131 0.122 0.127 0.122 0.124 0.121 0.116  ||  0.094 0.045 -0.025 0.019 -0.022 -0.007 -0.032 -0.078  || dis=0.01 || select=0/8
006/019-th : 0.157 0.145 0.131 0.122 0.127 0.114 0.105 0.100  ||  0.242 0.160 0.058 -0.015 0.029 -0.081 -0.162 -0.215   || dis=0.01 || select=0/8
007/019-th : 0.006 0.008 0.010 0.013 0.017 0.022 0.040 0.884  ||  -1.463 -1.235 -1.060 -0.763 -0.504 -0.204 0.364 3.469  || dis=0.84 || select=7/8
008/019-th : 0.006 0.008 0.012 0.016 0.023 0.035 0.072 0.829  ||  -1.679 -1.436 -1.027 -0.762 -0.390 0.036 0.768 3.209  || dis=0.76 || select=7/8
009/019-th : 0.085 0.086 0.096 0.110 0.122 0.142 0.156 0.203  ||  -0.343 -0.335 -0.220 -0.083 0.020 0.167 0.265 0.527   || dis=0.05 || select=7/8
010/019-th : 0.086 0.097 0.107 0.116 0.126 0.150 0.156 0.162  ||  -0.350 -0.221 -0.131 -0.043 0.038 0.212 0.248 0.290   || dis=0.01 || select=7/8
011/019-th : 0.129 0.113 0.119 0.122 0.127 0.128 0.131 0.130  ||  0.035 -0.092 -0.045 -0.016 0.024 0.031 0.056 0.043    || dis=0.00 || select=6/8
012/019-th : 0.156 0.143 0.122 0.127 0.122 0.114 0.108 0.107  ||  0.234 0.146 -0.009 0.026 -0.014 -0.078 -0.132 -0.148  || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.004 0.004 0.005 0.005 0.007 0.968  ||  -0.985 -0.999 -0.936 -0.844 -0.694 -0.541 -0.240 4.658  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.008 0.015 0.956  ||  -1.285 -1.292 -1.039 -0.990 -0.751 -0.365 0.203 4.368  || dis=0.94 || select=7/8
015/019-th : 0.003 0.004 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.219 -0.762 -0.963 -0.899 -0.679 -0.502 -0.109 4.611  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.038 0.060 0.079 0.166 0.229 0.363  ||  -1.132 -0.857 -0.837 -0.388 -0.110 0.638 0.960 1.420  || dis=0.13 || select=7/8
017/019-th : 0.085 0.097 0.102 0.116 0.133 0.143 0.158 0.166  ||  -0.365 -0.226 -0.177 -0.052 0.085 0.159 0.262 0.310   || dis=0.01 || select=7/8
018/019-th : 0.094 0.109 0.127 0.146 0.133 0.118 0.129 0.144  ||  -0.275 -0.121 0.028 0.169 0.076 -0.042 0.048 0.154    || dis=0.00 || select=3/8
[epoch=545/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.310
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:33:12] [epoch=545/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.811 (0.811)  Prec@1 73.83 (73.83) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:33:18] [epoch=545/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.504 (1.787)  Prec@1 83.33 (55.49) Prec@5 98.21 (88.55) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.49 Prec@5 88.55 Error@1 44.51 Error@5 11.45 Loss:1.787
***[2020-01-29 10:33:18]*** VALID [epoch=545/600] loss = 1.786786, accuracy@1 = 55.49, accuracy@5 = 88.55 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:33:18]*** start epoch=546/600 Time Left: [00:28:54], LR=[0.001985 ~ 0.001985], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=546, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.19728047009148952, FLOP=40.81
[Search] : epoch=546/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:33:19] [epoch=546/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 0.367 (0.367)  Prec@1 89.06 (89.06) Prec@5 100.00 (100.00) Acls-loss 0.585 (0.585) FLOP-Loss 0.000 (0.000) Arch-Loss 0.585 (0.585)
**TRAIN** [2020-01-29 10:33:43] [epoch=546/600][097/098] Time 0.25 (0.25) Data 0.00 (0.00) Base-Loss 1.057 (0.383)  Prec@1 64.29 (87.14) Prec@5 95.83 (99.49) Acls-loss 0.551 (0.549) FLOP-Loss 0.000 (0.000) Arch-Loss 0.551 (0.549)
 **TRAIN** Prec@1 87.14 Prec@5 99.49 Error@1 12.86 Error@5 0.51 Base-Loss:0.383, Arch-Loss=0.549
***[2020-01-29 10:33:43]*** TRAIN [epoch=546/600] base-loss = 0.383479, arch-loss = 0.548711, accuracy-1 = 87.14, accuracy-5 = 99.49
[epoch=546/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 9, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.351868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.147 0.578 0.275  ||  -0.4395 0.9277 0.1853  || discrepancy=0.30 || select=1/3
001/003-th : 0.341 0.311 0.349  ||  0.1652 0.0722 0.1878  || discrepancy=0.01 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2728 -0.5665 2.8173  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.015 0.019 0.032 0.895  ||  -1.379 -1.094 -0.866 -0.894 -0.639 -0.387 0.157 3.479  || dis=0.86 || select=7/8
001/019-th : 0.080 0.102 0.128 0.130 0.134 0.135 0.160 0.131  ||  -0.424 -0.179 0.044 0.057 0.094 0.096 0.266 0.069     || dis=0.02 || select=6/8
002/019-th : 0.108 0.116 0.130 0.131 0.126 0.133 0.138 0.117  ||  -0.140 -0.074 0.046 0.053 0.009 0.068 0.101 -0.061    || dis=0.01 || select=6/8
003/019-th : 0.114 0.114 0.118 0.136 0.125 0.135 0.133 0.124  ||  -0.090 -0.088 -0.057 0.086 -0.002 0.076 0.065 -0.004  || dis=0.00 || select=3/8
004/019-th : 0.106 0.112 0.108 0.112 0.125 0.128 0.161 0.149  ||  -0.152 -0.100 -0.130 -0.099 0.013 0.035 0.264 0.190   || dis=0.01 || select=6/8
005/019-th : 0.136 0.131 0.122 0.127 0.123 0.124 0.121 0.115  ||  0.088 0.044 -0.024 0.020 -0.016 -0.006 -0.030 -0.079  || dis=0.01 || select=0/8
006/019-th : 0.156 0.145 0.132 0.121 0.127 0.114 0.105 0.100  ||  0.236 0.163 0.064 -0.024 0.031 -0.083 -0.159 -0.210   || dis=0.01 || select=0/8
007/019-th : 0.006 0.008 0.009 0.012 0.016 0.022 0.038 0.888  ||  -1.460 -1.241 -1.066 -0.793 -0.499 -0.210 0.354 3.500  || dis=0.85 || select=7/8
008/019-th : 0.006 0.008 0.012 0.015 0.022 0.033 0.068 0.836  ||  -1.671 -1.463 -1.020 -0.769 -0.399 0.020 0.741 3.244  || dis=0.77 || select=7/8
009/019-th : 0.085 0.086 0.097 0.110 0.122 0.141 0.155 0.203  ||  -0.343 -0.332 -0.216 -0.082 0.019 0.166 0.259 0.528   || dis=0.05 || select=7/8
010/019-th : 0.086 0.097 0.106 0.117 0.127 0.150 0.155 0.162  ||  -0.347 -0.223 -0.135 -0.041 0.048 0.212 0.244 0.286   || dis=0.01 || select=7/8
011/019-th : 0.127 0.113 0.119 0.122 0.128 0.128 0.132 0.131  ||  0.019 -0.094 -0.046 -0.016 0.029 0.028 0.059 0.056    || dis=0.00 || select=6/8
012/019-th : 0.156 0.143 0.123 0.126 0.122 0.114 0.109 0.107  ||  0.232 0.144 -0.009 0.021 -0.016 -0.082 -0.124 -0.146  || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.007 0.970  ||  -1.034 -0.996 -0.932 -0.843 -0.743 -0.540 -0.250 4.696  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.008 0.015 0.955  ||  -1.281 -1.288 -1.035 -0.989 -0.749 -0.359 0.200 4.363  || dis=0.94 || select=7/8
015/019-th : 0.003 0.004 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.216 -0.762 -0.959 -0.895 -0.676 -0.523 -0.108 4.613  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.038 0.059 0.078 0.167 0.228 0.364  ||  -1.128 -0.850 -0.845 -0.392 -0.112 0.645 0.955 1.423  || dis=0.14 || select=7/8
017/019-th : 0.085 0.097 0.103 0.117 0.131 0.141 0.160 0.168  ||  -0.366 -0.231 -0.173 -0.044 0.068 0.144 0.269 0.320   || dis=0.01 || select=7/8
018/019-th : 0.094 0.109 0.128 0.146 0.133 0.117 0.128 0.145  ||  -0.273 -0.126 0.035 0.168 0.077 -0.049 0.037 0.163    || dis=0.00 || select=3/8
[epoch=546/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.311
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:33:44] [epoch=546/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 2.737 (2.737)  Prec@1 28.91 (28.91) Prec@5 78.52 (78.52) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:33:50] [epoch=546/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.782 (1.736)  Prec@1 79.76 (55.21) Prec@5 97.02 (89.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.21 Prec@5 89.04 Error@1 44.79 Error@5 10.96 Loss:1.736
***[2020-01-29 10:33:50]*** VALID [epoch=546/600] loss = 1.736162, accuracy@1 = 55.21, accuracy@5 = 89.04 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:33:50]*** start epoch=547/600 Time Left: [00:28:22], LR=[0.001913 ~ 0.001913], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=547, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.19373379160443224, FLOP=40.81
[Search] : epoch=547/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:33:50] [epoch=547/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.287 (0.287)  Prec@1 91.02 (91.02) Prec@5 100.00 (100.00) Acls-loss 0.507 (0.507) FLOP-Loss 0.000 (0.000) Arch-Loss 0.507 (0.507)
**TRAIN** [2020-01-29 10:34:15] [epoch=547/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.308 (0.402)  Prec@1 89.88 (86.54) Prec@5 100.00 (99.36) Acls-loss 0.589 (0.550) FLOP-Loss 0.000 (0.031) Arch-Loss 0.589 (0.612)
 **TRAIN** Prec@1 86.54 Prec@5 99.36 Error@1 13.46 Error@5 0.64 Base-Loss:0.402, Arch-Loss=0.612
***[2020-01-29 10:34:15]*** TRAIN [epoch=547/600] base-loss = 0.402295, arch-loss = 0.611711, accuracy-1 = 86.54, accuracy-5 = 99.36
[epoch=547/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 9, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.351868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.144 0.583 0.273  ||  -0.4511 0.9439 0.1855  || discrepancy=0.31 || select=1/3
001/003-th : 0.340 0.310 0.350  ||  0.1617 0.0710 0.1911  || discrepancy=0.01 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2854 -0.5745 2.8311  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.015 0.019 0.032 0.895  ||  -1.369 -1.090 -0.857 -0.887 -0.635 -0.394 0.142 3.477  || dis=0.86 || select=7/8
001/019-th : 0.080 0.103 0.127 0.129 0.133 0.136 0.160 0.132  ||  -0.424 -0.177 0.039 0.049 0.083 0.102 0.268 0.073     || dis=0.02 || select=6/8
002/019-th : 0.109 0.115 0.131 0.131 0.126 0.133 0.137 0.117  ||  -0.137 -0.076 0.051 0.051 0.015 0.065 0.098 -0.063    || dis=0.00 || select=6/8
003/019-th : 0.114 0.114 0.119 0.136 0.124 0.134 0.134 0.124  ||  -0.093 -0.094 -0.046 0.089 -0.007 0.073 0.072 -0.006  || dis=0.00 || select=3/8
004/019-th : 0.106 0.111 0.108 0.112 0.126 0.128 0.161 0.149  ||  -0.155 -0.105 -0.137 -0.096 0.018 0.035 0.269 0.190   || dis=0.01 || select=6/8
005/019-th : 0.135 0.131 0.123 0.125 0.124 0.124 0.123 0.116  ||  0.081 0.047 -0.016 -0.003 -0.008 -0.010 -0.019 -0.076  || dis=0.00 || select=0/8
006/019-th : 0.156 0.145 0.128 0.121 0.131 0.113 0.106 0.100  ||  0.235 0.161 0.036 -0.024 0.057 -0.085 -0.156 -0.209   || dis=0.01 || select=0/8
007/019-th : 0.006 0.008 0.009 0.012 0.016 0.022 0.038 0.889  ||  -1.457 -1.234 -1.078 -0.792 -0.496 -0.208 0.348 3.507  || dis=0.85 || select=7/8
008/019-th : 0.006 0.008 0.012 0.015 0.022 0.033 0.067 0.838  ||  -1.663 -1.458 -1.012 -0.762 -0.411 0.010 0.722 3.248  || dis=0.77 || select=7/8
009/019-th : 0.085 0.087 0.096 0.110 0.118 0.142 0.156 0.207  ||  -0.341 -0.325 -0.220 -0.086 -0.012 0.168 0.263 0.548  || dis=0.05 || select=7/8
010/019-th : 0.086 0.097 0.107 0.118 0.126 0.152 0.154 0.161  ||  -0.349 -0.227 -0.129 -0.024 0.035 0.224 0.240 0.283   || dis=0.01 || select=7/8
011/019-th : 0.128 0.113 0.120 0.121 0.126 0.130 0.132 0.132  ||  0.027 -0.095 -0.040 -0.032 0.009 0.045 0.056 0.056    || dis=0.00 || select=6/8
012/019-th : 0.156 0.141 0.123 0.127 0.123 0.114 0.109 0.108  ||  0.230 0.130 -0.006 0.024 -0.008 -0.084 -0.123 -0.137  || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.007 0.971  ||  -1.032 -0.993 -0.936 -0.846 -0.741 -0.559 -0.265 4.709  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.009 0.015 0.955  ||  -1.277 -1.284 -1.043 -0.985 -0.748 -0.356 0.200 4.362  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.213 -0.759 -0.956 -0.891 -0.672 -0.520 -0.107 4.606  || dis=0.96 || select=7/8
016/019-th : 0.029 0.038 0.038 0.059 0.078 0.166 0.228 0.364  ||  -1.120 -0.839 -0.849 -0.398 -0.116 0.641 0.957 1.423  || dis=0.14 || select=7/8
017/019-th : 0.085 0.097 0.102 0.115 0.132 0.141 0.159 0.168  ||  -0.364 -0.229 -0.181 -0.055 0.079 0.147 0.266 0.322   || dis=0.01 || select=7/8
018/019-th : 0.094 0.109 0.127 0.148 0.132 0.118 0.128 0.145  ||  -0.269 -0.126 0.026 0.181 0.065 -0.045 0.037 0.162    || dis=0.00 || select=3/8
[epoch=547/600] FLOP : 28.35 MB, ratio : 0.6947, Expected-ratio : 0.7000, Discrepancy : 0.312
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:34:15] [epoch=547/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.536 (1.536)  Prec@1 57.81 (57.81) Prec@5 93.36 (93.36) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:34:21] [epoch=547/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.995 (1.696)  Prec@1 63.69 (56.96) Prec@5 98.21 (89.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.96 Prec@5 89.80 Error@1 43.04 Error@5 10.20 Loss:1.696
***[2020-01-29 10:34:21]*** VALID [epoch=547/600] loss = 1.696204, accuracy@1 = 56.96, accuracy@5 = 89.80 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:34:21]*** start epoch=548/600 Time Left: [00:27:49], LR=[0.001842 ~ 0.001842], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=548, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.19025171134573765, FLOP=40.81
[Search] : epoch=548/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:34:22] [epoch=548/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.364 (0.364)  Prec@1 87.11 (87.11) Prec@5 98.44 (98.44) Acls-loss 0.582 (0.582) FLOP-Loss 0.000 (0.000) Arch-Loss 0.582 (0.582)
**TRAIN** [2020-01-29 10:34:47] [epoch=548/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.314 (0.376)  Prec@1 88.10 (87.12) Prec@5 100.00 (99.41) Acls-loss 0.692 (0.572) FLOP-Loss 3.000 (0.358) Arch-Loss 6.692 (1.289)
 **TRAIN** Prec@1 87.12 Prec@5 99.41 Error@1 12.88 Error@5 0.59 Base-Loss:0.376, Arch-Loss=1.289
***[2020-01-29 10:34:47]*** TRAIN [epoch=548/600] base-loss = 0.376284, arch-loss = 1.289121, accuracy-1 = 87.12, accuracy-5 = 99.41
[epoch=548/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 9, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.729724)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.146 0.587 0.267  ||  -0.4391 0.9547 0.1684  || discrepancy=0.32 || select=1/3
001/003-th : 0.345 0.309 0.345  ||  0.1757 0.0651 0.1759  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2803 -0.5581 2.8231  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.015 0.018 0.032 0.896  ||  -1.359 -1.083 -0.847 -0.879 -0.641 -0.408 0.136 3.478  || dis=0.86 || select=7/8
001/019-th : 0.081 0.104 0.129 0.129 0.134 0.134 0.158 0.131  ||  -0.413 -0.170 0.047 0.047 0.086 0.091 0.255 0.068     || dis=0.02 || select=6/8
002/019-th : 0.110 0.116 0.132 0.132 0.126 0.132 0.136 0.115  ||  -0.128 -0.068 0.062 0.062 0.011 0.059 0.090 -0.077    || dis=0.00 || select=6/8
003/019-th : 0.115 0.115 0.121 0.138 0.123 0.132 0.132 0.124  ||  -0.081 -0.082 -0.031 0.097 -0.019 0.056 0.055 -0.012  || dis=0.01 || select=3/8
004/019-th : 0.106 0.112 0.109 0.113 0.125 0.127 0.160 0.148  ||  -0.148 -0.093 -0.128 -0.087 0.013 0.026 0.260 0.180   || dis=0.01 || select=6/8
005/019-th : 0.135 0.132 0.124 0.124 0.124 0.125 0.122 0.114  ||  0.081 0.054 -0.005 -0.010 -0.009 0.000 -0.022 -0.091  || dis=0.00 || select=0/8
006/019-th : 0.159 0.146 0.128 0.121 0.130 0.112 0.104 0.099  ||  0.251 0.169 0.037 -0.023 0.053 -0.097 -0.169 -0.217   || dis=0.01 || select=0/8
007/019-th : 0.006 0.008 0.009 0.012 0.016 0.022 0.038 0.889  ||  -1.453 -1.254 -1.075 -0.791 -0.503 -0.197 0.356 3.508  || dis=0.85 || select=7/8
008/019-th : 0.006 0.007 0.012 0.015 0.021 0.032 0.065 0.841  ||  -1.678 -1.459 -1.010 -0.743 -0.433 0.005 0.710 3.264  || dis=0.78 || select=7/8
009/019-th : 0.086 0.087 0.093 0.111 0.119 0.139 0.161 0.205  ||  -0.334 -0.315 -0.251 -0.078 -0.008 0.147 0.294 0.540  || dis=0.04 || select=7/8
010/019-th : 0.087 0.098 0.107 0.120 0.123 0.151 0.155 0.159  ||  -0.337 -0.217 -0.129 -0.012 0.016 0.219 0.247 0.267   || dis=0.00 || select=7/8
011/019-th : 0.130 0.114 0.120 0.121 0.126 0.129 0.129 0.131  ||  0.040 -0.086 -0.034 -0.029 0.016 0.035 0.035 0.047    || dis=0.00 || select=7/8
012/019-th : 0.158 0.143 0.125 0.125 0.122 0.112 0.109 0.108  ||  0.241 0.140 0.012 0.005 -0.015 -0.104 -0.129 -0.141   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.007 0.971  ||  -1.029 -0.990 -0.944 -0.844 -0.739 -0.559 -0.288 4.716  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.008 0.015 0.956  ||  -1.273 -1.279 -1.052 -0.982 -0.746 -0.370 0.195 4.369  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.210 -0.754 -0.951 -0.885 -0.687 -0.517 -0.088 4.597  || dis=0.96 || select=7/8
016/019-th : 0.029 0.038 0.038 0.058 0.079 0.168 0.229 0.361  ||  -1.120 -0.834 -0.840 -0.408 -0.110 0.648 0.959 1.413  || dis=0.13 || select=7/8
017/019-th : 0.086 0.098 0.101 0.117 0.135 0.139 0.157 0.167  ||  -0.347 -0.216 -0.186 -0.047 0.098 0.126 0.249 0.314   || dis=0.01 || select=7/8
018/019-th : 0.096 0.112 0.126 0.149 0.130 0.118 0.126 0.144  ||  -0.254 -0.102 0.021 0.186 0.048 -0.043 0.020 0.154    || dis=0.01 || select=3/8
[epoch=548/600] FLOP : 28.73 MB, ratio : 0.7039, Expected-ratio : 0.7000, Discrepancy : 0.312
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:34:47] [epoch=548/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.367 (2.367)  Prec@1 12.89 (12.89) Prec@5 57.03 (57.03) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:34:53] [epoch=548/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.520 (1.793)  Prec@1 83.33 (55.31) Prec@5 99.40 (87.75) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.31 Prec@5 87.75 Error@1 44.69 Error@5 12.25 Loss:1.793
***[2020-01-29 10:34:53]*** VALID [epoch=548/600] loss = 1.792566, accuracy@1 = 55.31, accuracy@5 = 87.75 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:34:53]*** start epoch=549/600 Time Left: [00:27:17], LR=[0.001772 ~ 0.001772], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=549, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.18683432477839473, FLOP=40.81
[Search] : epoch=549/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:34:54] [epoch=549/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.260 (0.260)  Prec@1 91.80 (91.80) Prec@5 100.00 (100.00) Acls-loss 0.535 (0.535) FLOP-Loss 3.000 (3.000) Arch-Loss 6.534 (6.534)
**TRAIN** [2020-01-29 10:35:19] [epoch=549/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.408 (0.411)  Prec@1 87.50 (86.19) Prec@5 99.40 (99.34) Acls-loss 0.690 (0.559) FLOP-Loss -3.000 (0.041) Arch-Loss -5.310 (0.642)
 **TRAIN** Prec@1 86.19 Prec@5 99.34 Error@1 13.81 Error@5 0.66 Base-Loss:0.411, Arch-Loss=0.642
***[2020-01-29 10:35:19]*** TRAIN [epoch=549/600] base-loss = 0.410780, arch-loss = 0.641640, accuracy-1 = 86.19, accuracy-5 = 99.34
[epoch=549/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 9, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.729724)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.144 0.588 0.268  ||  -0.4461 0.9578 0.1705  || discrepancy=0.32 || select=1/3
001/003-th : 0.345 0.309 0.346  ||  0.1747 0.0643 0.1763  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.962  ||  -2.2825 -0.5585 2.8254  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.012 0.011 0.014 0.018 0.030 0.898  ||  -1.349 -1.078 -0.862 -0.882 -0.645 -0.408 0.109 3.495  || dis=0.87 || select=7/8
001/019-th : 0.081 0.103 0.129 0.128 0.133 0.135 0.160 0.131  ||  -0.415 -0.170 0.049 0.043 0.079 0.094 0.266 0.064     || dis=0.02 || select=6/8
002/019-th : 0.108 0.116 0.133 0.134 0.124 0.135 0.136 0.115  ||  -0.136 -0.071 0.064 0.074 -0.004 0.080 0.090 -0.079   || dis=0.00 || select=6/8
003/019-th : 0.116 0.114 0.122 0.137 0.122 0.132 0.133 0.124  ||  -0.078 -0.092 -0.024 0.092 -0.028 0.055 0.060 -0.009  || dis=0.00 || select=3/8
004/019-th : 0.106 0.113 0.110 0.113 0.125 0.124 0.160 0.149  ||  -0.149 -0.087 -0.117 -0.090 0.008 0.001 0.259 0.189   || dis=0.01 || select=6/8
005/019-th : 0.135 0.133 0.125 0.123 0.123 0.124 0.122 0.114  ||  0.079 0.065 -0.001 -0.013 -0.014 -0.003 -0.026 -0.088  || dis=0.00 || select=0/8
006/019-th : 0.158 0.145 0.129 0.121 0.130 0.112 0.104 0.099  ||  0.249 0.161 0.043 -0.021 0.055 -0.094 -0.170 -0.216   || dis=0.01 || select=0/8
007/019-th : 0.006 0.008 0.009 0.012 0.016 0.022 0.038 0.890  ||  -1.449 -1.249 -1.072 -0.788 -0.511 -0.207 0.351 3.511  || dis=0.85 || select=7/8
008/019-th : 0.006 0.008 0.012 0.015 0.021 0.032 0.066 0.840  ||  -1.672 -1.455 -1.013 -0.750 -0.431 0.008 0.716 3.263  || dis=0.77 || select=7/8
009/019-th : 0.086 0.088 0.093 0.110 0.119 0.138 0.161 0.205  ||  -0.332 -0.309 -0.250 -0.081 -0.007 0.141 0.296 0.536  || dis=0.04 || select=7/8
010/019-th : 0.086 0.098 0.108 0.118 0.123 0.151 0.157 0.159  ||  -0.343 -0.219 -0.120 -0.028 0.016 0.218 0.255 0.272   || dis=0.00 || select=7/8
011/019-th : 0.129 0.113 0.121 0.119 0.130 0.130 0.129 0.131  ||  0.035 -0.098 -0.030 -0.046 0.043 0.044 0.040 0.053    || dis=0.00 || select=7/8
012/019-th : 0.157 0.141 0.124 0.125 0.122 0.114 0.109 0.108  ||  0.234 0.131 0.004 0.011 -0.014 -0.087 -0.128 -0.137   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.027 -0.987 -0.940 -0.863 -0.736 -0.557 -0.287 4.722  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.008 0.014 0.957  ||  -1.281 -1.274 -1.049 -0.977 -0.744 -0.382 0.169 4.381  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.965  ||  -1.207 -0.747 -0.947 -0.880 -0.683 -0.514 -0.088 4.588  || dis=0.96 || select=7/8
016/019-th : 0.029 0.038 0.039 0.058 0.078 0.166 0.229 0.364  ||  -1.112 -0.837 -0.826 -0.412 -0.118 0.632 0.955 1.420  || dis=0.13 || select=7/8
017/019-th : 0.086 0.098 0.100 0.118 0.135 0.138 0.157 0.168  ||  -0.349 -0.218 -0.199 -0.031 0.099 0.121 0.249 0.317   || dis=0.01 || select=7/8
018/019-th : 0.094 0.112 0.124 0.153 0.129 0.118 0.125 0.145  ||  -0.268 -0.095 0.008 0.216 0.042 -0.040 0.011 0.159    || dis=0.01 || select=3/8
[epoch=549/600] FLOP : 28.73 MB, ratio : 0.7039, Expected-ratio : 0.7000, Discrepancy : 0.313
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:35:19] [epoch=549/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.543 (0.543)  Prec@1 81.25 (81.25) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:35:25] [epoch=549/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.103 (1.819)  Prec@1 32.14 (58.56) Prec@5 81.55 (90.72) Size=[168, 3, 32, 32]
 **VALID** Prec@1 58.56 Prec@5 90.72 Error@1 41.44 Error@5 9.28 Loss:1.819
***[2020-01-29 10:35:25]*** VALID [epoch=549/600] loss = 1.819042, accuracy@1 = 58.56, accuracy@5 = 90.72 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:35:26]*** start epoch=550/600 Time Left: [00:26:45], LR=[0.001704 ~ 0.001704], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=550, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1834817255917829, FLOP=40.81
[Search] : epoch=550/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:35:26] [epoch=550/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.237 (0.237)  Prec@1 92.58 (92.58) Prec@5 99.61 (99.61) Acls-loss 0.474 (0.474) FLOP-Loss 3.000 (3.000) Arch-Loss 6.474 (6.474)
**TRAIN** [2020-01-29 10:35:51] [epoch=550/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.290 (0.381)  Prec@1 87.50 (86.94) Prec@5 99.40 (99.44) Acls-loss 0.525 (0.536) FLOP-Loss 0.000 (0.031) Arch-Loss 0.525 (0.598)
 **TRAIN** Prec@1 86.94 Prec@5 99.44 Error@1 13.06 Error@5 0.56 Base-Loss:0.381, Arch-Loss=0.598
***[2020-01-29 10:35:51]*** TRAIN [epoch=550/600] base-loss = 0.381255, arch-loss = 0.597513, accuracy-1 = 86.94, accuracy-5 = 99.44
[epoch=550/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.445052)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.144 0.586 0.270  ||  -0.4504 0.9499 0.1749  || discrepancy=0.32 || select=1/3
001/003-th : 0.343 0.311 0.346  ||  0.1705 0.0712 0.1788  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.962  ||  -2.2779 -0.5622 2.8218  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.011 0.011 0.014 0.018 0.030 0.900  ||  -1.340 -1.073 -0.857 -0.884 -0.647 -0.429 0.092 3.507  || dis=0.87 || select=7/8
001/019-th : 0.081 0.104 0.128 0.127 0.131 0.135 0.161 0.133  ||  -0.420 -0.168 0.038 0.036 0.065 0.094 0.272 0.079     || dis=0.03 || select=6/8
002/019-th : 0.106 0.114 0.132 0.133 0.125 0.138 0.137 0.115  ||  -0.153 -0.089 0.062 0.073 0.009 0.104 0.096 -0.073    || dis=0.00 || select=5/8
003/019-th : 0.116 0.114 0.122 0.135 0.122 0.132 0.134 0.125  ||  -0.077 -0.096 -0.027 0.075 -0.023 0.055 0.071 -0.006  || dis=0.00 || select=3/8
004/019-th : 0.107 0.114 0.110 0.112 0.126 0.124 0.160 0.148  ||  -0.147 -0.084 -0.118 -0.095 0.016 0.007 0.256 0.185   || dis=0.01 || select=6/8
005/019-th : 0.135 0.133 0.125 0.122 0.122 0.124 0.122 0.116  ||  0.078 0.064 -0.003 -0.026 -0.023 -0.005 -0.025 -0.072  || dis=0.00 || select=0/8
006/019-th : 0.157 0.144 0.130 0.120 0.132 0.112 0.106 0.099  ||  0.241 0.155 0.047 -0.032 0.064 -0.099 -0.152 -0.219   || dis=0.01 || select=0/8
007/019-th : 0.006 0.008 0.009 0.012 0.016 0.022 0.038 0.890  ||  -1.445 -1.249 -1.077 -0.785 -0.508 -0.208 0.350 3.513  || dis=0.85 || select=7/8
008/019-th : 0.006 0.007 0.011 0.015 0.021 0.032 0.064 0.843  ||  -1.675 -1.449 -1.030 -0.748 -0.427 0.004 0.704 3.274  || dis=0.78 || select=7/8
009/019-th : 0.086 0.087 0.093 0.110 0.118 0.138 0.161 0.206  ||  -0.332 -0.325 -0.249 -0.086 -0.013 0.145 0.296 0.544  || dis=0.04 || select=7/8
010/019-th : 0.086 0.096 0.108 0.119 0.124 0.150 0.157 0.160  ||  -0.343 -0.230 -0.116 -0.019 0.023 0.211 0.254 0.273   || dis=0.00 || select=7/8
011/019-th : 0.129 0.112 0.119 0.119 0.129 0.131 0.130 0.132  ||  0.034 -0.105 -0.041 -0.045 0.040 0.056 0.043 0.058    || dis=0.00 || select=7/8
012/019-th : 0.155 0.140 0.125 0.126 0.123 0.114 0.109 0.107  ||  0.229 0.125 0.012 0.017 -0.004 -0.078 -0.128 -0.141   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.025 -0.991 -0.956 -0.861 -0.734 -0.555 -0.284 4.725  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.008 0.014 0.956  ||  -1.277 -1.269 -1.046 -0.973 -0.741 -0.379 0.165 4.376  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.206 -0.743 -0.943 -0.875 -0.708 -0.511 -0.114 4.604  || dis=0.96 || select=7/8
016/019-th : 0.029 0.038 0.039 0.056 0.077 0.168 0.228 0.366  ||  -1.111 -0.840 -0.819 -0.452 -0.125 0.653 0.957 1.429  || dis=0.14 || select=7/8
017/019-th : 0.087 0.098 0.100 0.117 0.135 0.137 0.158 0.168  ||  -0.342 -0.218 -0.199 -0.041 0.103 0.113 0.255 0.316   || dis=0.01 || select=7/8
018/019-th : 0.094 0.113 0.125 0.153 0.128 0.119 0.124 0.145  ||  -0.275 -0.089 0.011 0.216 0.038 -0.032 0.006 0.159    || dis=0.01 || select=3/8
[epoch=550/600] FLOP : 28.45 MB, ratio : 0.6970, Expected-ratio : 0.7000, Discrepancy : 0.313
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:35:51] [epoch=550/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 1.062 (1.062)  Prec@1 72.27 (72.27) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:35:57] [epoch=550/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.789 (1.809)  Prec@1 73.81 (56.92) Prec@5 98.21 (88.96) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.92 Prec@5 88.96 Error@1 43.08 Error@5 11.04 Loss:1.809
***[2020-01-29 10:35:57]*** VALID [epoch=550/600] loss = 1.809024, accuracy@1 = 56.92, accuracy@5 = 88.96 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:35:57]*** start epoch=551/600 Time Left: [00:26:13], LR=[0.001637 ~ 0.001637], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=551, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.18019400569910202, FLOP=40.81
[Search] : epoch=551/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:35:58] [epoch=551/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.292 (0.292)  Prec@1 91.02 (91.02) Prec@5 99.61 (99.61) Acls-loss 0.651 (0.651) FLOP-Loss 0.000 (0.000) Arch-Loss 0.651 (0.651)
**TRAIN** [2020-01-29 10:36:23] [epoch=551/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.254 (0.372)  Prec@1 93.45 (87.51) Prec@5 100.00 (99.52) Acls-loss 0.608 (0.564) FLOP-Loss 0.000 (0.123) Arch-Loss 0.608 (0.810)
 **TRAIN** Prec@1 87.51 Prec@5 99.52 Error@1 12.49 Error@5 0.48 Base-Loss:0.372, Arch-Loss=0.810
***[2020-01-29 10:36:23]*** TRAIN [epoch=551/600] base-loss = 0.371557, arch-loss = 0.809904, accuracy-1 = 87.51, accuracy-5 = 99.52
[epoch=551/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.445052)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.144 0.586 0.270  ||  -0.4515 0.9498 0.1735  || discrepancy=0.32 || select=1/3
001/003-th : 0.343 0.312 0.345  ||  0.1698 0.0754 0.1778  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.962  ||  -2.2758 -0.5642 2.8203  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.011 0.011 0.014 0.017 0.029 0.902  ||  -1.338 -1.065 -0.864 -0.895 -0.671 -0.426 0.092 3.525  || dis=0.87 || select=7/8
001/019-th : 0.081 0.104 0.128 0.131 0.131 0.132 0.161 0.133  ||  -0.416 -0.171 0.040 0.060 0.060 0.071 0.266 0.082     || dis=0.03 || select=6/8
002/019-th : 0.106 0.113 0.131 0.135 0.126 0.137 0.137 0.115  ||  -0.153 -0.089 0.056 0.085 0.017 0.099 0.097 -0.076    || dis=0.00 || select=5/8
003/019-th : 0.116 0.113 0.122 0.136 0.122 0.132 0.134 0.124  ||  -0.078 -0.100 -0.024 0.084 -0.026 0.056 0.072 -0.009  || dis=0.00 || select=3/8
004/019-th : 0.105 0.110 0.109 0.113 0.129 0.124 0.162 0.148  ||  -0.156 -0.110 -0.127 -0.090 0.044 0.003 0.276 0.182   || dis=0.01 || select=6/8
005/019-th : 0.135 0.134 0.125 0.122 0.122 0.124 0.120 0.117  ||  0.078 0.068 0.001 -0.021 -0.023 -0.007 -0.044 -0.063  || dis=0.00 || select=0/8
006/019-th : 0.157 0.145 0.130 0.120 0.132 0.111 0.107 0.099  ||  0.239 0.160 0.050 -0.031 0.064 -0.103 -0.147 -0.224   || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.009 0.012 0.016 0.021 0.037 0.892  ||  -1.441 -1.272 -1.084 -0.793 -0.510 -0.208 0.352 3.536  || dis=0.85 || select=7/8
008/019-th : 0.006 0.008 0.011 0.015 0.021 0.032 0.063 0.845  ||  -1.668 -1.442 -1.026 -0.745 -0.430 0.002 0.677 3.277  || dis=0.78 || select=7/8
009/019-th : 0.086 0.087 0.094 0.109 0.118 0.138 0.161 0.206  ||  -0.327 -0.317 -0.248 -0.095 -0.014 0.143 0.295 0.541  || dis=0.04 || select=7/8
010/019-th : 0.086 0.097 0.107 0.119 0.123 0.150 0.158 0.160  ||  -0.341 -0.222 -0.131 -0.023 0.010 0.207 0.264 0.277   || dis=0.00 || select=7/8
011/019-th : 0.129 0.113 0.119 0.118 0.129 0.131 0.130 0.131  ||  0.036 -0.097 -0.039 -0.051 0.040 0.050 0.042 0.055    || dis=0.00 || select=7/8
012/019-th : 0.156 0.140 0.126 0.125 0.123 0.114 0.109 0.107  ||  0.230 0.126 0.015 0.012 -0.002 -0.078 -0.129 -0.143   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.022 -0.991 -0.974 -0.859 -0.731 -0.555 -0.283 4.730  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.006 0.008 0.014 0.957  ||  -1.272 -1.264 -1.042 -0.968 -0.743 -0.404 0.164 4.381  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.009 0.966  ||  -1.212 -0.738 -0.938 -0.895 -0.704 -0.508 -0.113 4.612  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.038 0.055 0.077 0.166 0.234 0.364  ||  -1.120 -0.847 -0.831 -0.451 -0.127 0.647 0.988 1.430  || dis=0.13 || select=7/8
017/019-th : 0.084 0.098 0.101 0.119 0.135 0.137 0.160 0.167  ||  -0.373 -0.218 -0.190 -0.023 0.101 0.118 0.272 0.314   || dis=0.01 || select=7/8
018/019-th : 0.094 0.111 0.126 0.153 0.128 0.119 0.125 0.143  ||  -0.273 -0.101 0.025 0.215 0.038 -0.031 0.014 0.149    || dis=0.01 || select=3/8
[epoch=551/600] FLOP : 28.45 MB, ratio : 0.6970, Expected-ratio : 0.7000, Discrepancy : 0.313
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:36:23] [epoch=551/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 4.829 (4.829)  Prec@1 11.33 (11.33) Prec@5 50.78 (50.78) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:36:29] [epoch=551/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.652 (1.984)  Prec@1 78.57 (56.98) Prec@5 98.81 (88.04) Size=[168, 3, 32, 32]
 **VALID** Prec@1 56.98 Prec@5 88.04 Error@1 43.02 Error@5 11.96 Loss:1.984
***[2020-01-29 10:36:29]*** VALID [epoch=551/600] loss = 1.983855, accuracy@1 = 56.98, accuracy@5 = 88.04 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:36:30]*** start epoch=552/600 Time Left: [00:25:41], LR=[0.001571 ~ 0.001571], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=552, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.17697125523485388, FLOP=40.81
[Search] : epoch=552/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:36:30] [epoch=552/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.305 (0.305)  Prec@1 91.02 (91.02) Prec@5 99.61 (99.61) Acls-loss 0.574 (0.574) FLOP-Loss 0.000 (0.000) Arch-Loss 0.574 (0.574)
**TRAIN** [2020-01-29 10:36:55] [epoch=552/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.538 (0.368)  Prec@1 79.76 (87.36) Prec@5 100.00 (99.58) Acls-loss 0.625 (0.564) FLOP-Loss 3.003 (0.174) Arch-Loss 6.632 (0.912)
 **TRAIN** Prec@1 87.36 Prec@5 99.58 Error@1 12.64 Error@5 0.42 Base-Loss:0.368, Arch-Loss=0.912
***[2020-01-29 10:36:55]*** TRAIN [epoch=552/600] base-loss = 0.367936, arch-loss = 0.911514, accuracy-1 = 87.36, accuracy-5 = 99.58
[epoch=552/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 9, 14, 14, 4, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.11558)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.144 0.588 0.268  ||  -0.4532 0.9546 0.1703  || discrepancy=0.32 || select=1/3
001/003-th : 0.343 0.313 0.344  ||  0.1706 0.0788 0.1754  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2920 -0.5699 2.8370  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.011 0.011 0.013 0.017 0.028 0.904  ||  -1.341 -1.058 -0.858 -0.894 -0.667 -0.447 0.080 3.539  || dis=0.88 || select=7/8
001/019-th : 0.081 0.104 0.127 0.128 0.131 0.133 0.162 0.134  ||  -0.422 -0.168 0.034 0.041 0.063 0.080 0.278 0.083     || dis=0.03 || select=6/8
002/019-th : 0.107 0.113 0.133 0.136 0.126 0.136 0.135 0.115  ||  -0.148 -0.092 0.068 0.091 0.017 0.091 0.085 -0.073    || dis=0.00 || select=3/8
003/019-th : 0.116 0.113 0.121 0.136 0.124 0.131 0.136 0.125  ||  -0.080 -0.106 -0.036 0.082 -0.011 0.048 0.082 -0.004  || dis=0.00 || select=6/8
004/019-th : 0.106 0.111 0.110 0.113 0.129 0.123 0.161 0.147  ||  -0.152 -0.102 -0.117 -0.088 0.042 0.000 0.267 0.177   || dis=0.01 || select=6/8
005/019-th : 0.135 0.134 0.125 0.124 0.122 0.123 0.119 0.117  ||  0.077 0.072 0.003 -0.006 -0.024 -0.015 -0.048 -0.064  || dis=0.00 || select=0/8
006/019-th : 0.157 0.145 0.130 0.120 0.132 0.111 0.107 0.098  ||  0.243 0.163 0.047 -0.032 0.065 -0.107 -0.146 -0.228   || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.009 0.012 0.015 0.021 0.037 0.894  ||  -1.437 -1.269 -1.083 -0.790 -0.525 -0.224 0.347 3.544  || dis=0.86 || select=7/8
008/019-th : 0.006 0.007 0.011 0.015 0.020 0.031 0.060 0.850  ||  -1.660 -1.470 -1.046 -0.745 -0.425 -0.003 0.654 3.311  || dis=0.79 || select=7/8
009/019-th : 0.087 0.088 0.094 0.109 0.119 0.138 0.161 0.205  ||  -0.319 -0.314 -0.247 -0.099 -0.012 0.140 0.294 0.537  || dis=0.04 || select=7/8
010/019-th : 0.087 0.098 0.107 0.119 0.122 0.149 0.158 0.159  ||  -0.330 -0.216 -0.130 -0.021 0.004 0.204 0.263 0.267   || dis=0.00 || select=7/8
011/019-th : 0.129 0.113 0.119 0.119 0.129 0.131 0.129 0.131  ||  0.039 -0.097 -0.040 -0.047 0.035 0.055 0.036 0.052    || dis=0.00 || select=5/8
012/019-th : 0.156 0.140 0.127 0.124 0.123 0.116 0.108 0.107  ||  0.232 0.126 0.024 0.006 -0.006 -0.065 -0.139 -0.148   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -1.020 -0.988 -0.972 -0.875 -0.747 -0.553 -0.282 4.742  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.014 0.958  ||  -1.266 -1.258 -1.039 -0.962 -0.776 -0.396 0.146 4.396  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.008 0.966  ||  -1.208 -0.733 -0.953 -0.917 -0.701 -0.505 -0.112 4.626  || dis=0.96 || select=7/8
016/019-th : 0.028 0.037 0.037 0.055 0.075 0.166 0.235 0.368  ||  -1.126 -0.846 -0.842 -0.458 -0.149 0.648 0.997 1.447  || dis=0.13 || select=7/8
017/019-th : 0.084 0.097 0.102 0.119 0.134 0.136 0.160 0.167  ||  -0.368 -0.227 -0.177 -0.022 0.096 0.112 0.272 0.314   || dis=0.01 || select=7/8
018/019-th : 0.095 0.112 0.126 0.153 0.128 0.119 0.125 0.143  ||  -0.263 -0.095 0.022 0.213 0.034 -0.037 0.016 0.144    || dis=0.01 || select=3/8
[epoch=552/600] FLOP : 28.12 MB, ratio : 0.6889, Expected-ratio : 0.7000, Discrepancy : 0.314
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:36:55] [epoch=552/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.687 (0.687)  Prec@1 77.73 (77.73) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:37:01] [epoch=552/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.858 (1.504)  Prec@1 48.21 (60.30) Prec@5 85.12 (90.05) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.30 Prec@5 90.05 Error@1 39.70 Error@5 9.95 Loss:1.504
***[2020-01-29 10:37:01]*** VALID [epoch=552/600] loss = 1.504330, accuracy@1 = 60.30, accuracy@5 = 90.05 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:37:01]*** start epoch=553/600 Time Left: [00:25:09], LR=[0.001506 ~ 0.001506], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=553, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.17381356255237046, FLOP=40.81
[Search] : epoch=553/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:37:02] [epoch=553/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.257 (0.257)  Prec@1 91.02 (91.02) Prec@5 100.00 (100.00) Acls-loss 0.630 (0.630) FLOP-Loss 0.000 (0.000) Arch-Loss 0.630 (0.630)
**TRAIN** [2020-01-29 10:37:27] [epoch=553/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.470 (0.430)  Prec@1 83.93 (85.44) Prec@5 100.00 (99.33) Acls-loss 0.548 (0.542) FLOP-Loss 0.000 (0.062) Arch-Loss 0.548 (0.665)
 **TRAIN** Prec@1 85.44 Prec@5 99.33 Error@1 14.56 Error@5 0.67 Base-Loss:0.430, Arch-Loss=0.665
***[2020-01-29 10:37:27]*** TRAIN [epoch=553/600] base-loss = 0.429930, arch-loss = 0.664928, accuracy-1 = 85.44, accuracy-5 = 99.33
[epoch=553/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 4, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.783804)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.142 0.591 0.268  ||  -0.4638 0.9639 0.1727  || discrepancy=0.32 || select=1/3
001/003-th : 0.343 0.312 0.345  ||  0.1703 0.0772 0.1752  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2880 -0.5724 2.8336  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.011 0.010 0.013 0.016 0.028 0.906  ||  -1.332 -1.074 -0.874 -0.896 -0.681 -0.454 0.080 3.564  || dis=0.88 || select=7/8
001/019-th : 0.080 0.103 0.127 0.128 0.130 0.132 0.164 0.136  ||  -0.429 -0.176 0.034 0.042 0.053 0.070 0.286 0.099     || dis=0.03 || select=6/8
002/019-th : 0.107 0.113 0.131 0.135 0.124 0.137 0.136 0.117  ||  -0.147 -0.096 0.052 0.081 0.000 0.098 0.089 -0.059    || dis=0.00 || select=5/8
003/019-th : 0.116 0.112 0.121 0.136 0.123 0.133 0.135 0.124  ||  -0.079 -0.107 -0.037 0.084 -0.014 0.061 0.077 -0.007  || dis=0.00 || select=3/8
004/019-th : 0.106 0.111 0.109 0.114 0.129 0.124 0.160 0.148  ||  -0.155 -0.106 -0.120 -0.082 0.043 0.007 0.258 0.184   || dis=0.01 || select=6/8
005/019-th : 0.134 0.134 0.125 0.125 0.122 0.123 0.119 0.117  ||  0.073 0.073 0.002 -0.002 -0.022 -0.015 -0.047 -0.064  || dis=0.00 || select=0/8
006/019-th : 0.158 0.146 0.129 0.120 0.131 0.112 0.106 0.098  ||  0.246 0.167 0.047 -0.028 0.056 -0.099 -0.152 -0.229   || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.009 0.012 0.015 0.021 0.037 0.893  ||  -1.432 -1.266 -1.080 -0.788 -0.525 -0.228 0.344 3.541  || dis=0.86 || select=7/8
008/019-th : 0.006 0.007 0.011 0.015 0.020 0.031 0.059 0.852  ||  -1.665 -1.465 -1.040 -0.740 -0.423 -0.012 0.641 3.315  || dis=0.79 || select=7/8
009/019-th : 0.087 0.089 0.094 0.109 0.118 0.137 0.161 0.204  ||  -0.318 -0.303 -0.247 -0.102 -0.015 0.134 0.295 0.532  || dis=0.04 || select=7/8
010/019-th : 0.088 0.098 0.107 0.119 0.122 0.149 0.157 0.160  ||  -0.327 -0.215 -0.128 -0.023 0.003 0.200 0.256 0.273   || dis=0.00 || select=7/8
011/019-th : 0.128 0.113 0.120 0.118 0.128 0.133 0.128 0.131  ||  0.026 -0.099 -0.032 -0.048 0.033 0.067 0.032 0.055    || dis=0.00 || select=5/8
012/019-th : 0.155 0.140 0.126 0.125 0.123 0.116 0.107 0.107  ||  0.229 0.125 0.022 0.012 -0.008 -0.066 -0.143 -0.142   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -1.015 -0.984 -0.969 -0.874 -0.744 -0.552 -0.289 4.738  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.013 0.958  ||  -1.261 -1.257 -1.037 -0.957 -0.775 -0.396 0.130 4.400  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.008 0.967  ||  -1.204 -0.727 -0.949 -0.915 -0.725 -0.501 -0.117 4.635  || dis=0.96 || select=7/8
016/019-th : 0.028 0.036 0.037 0.054 0.075 0.169 0.232 0.369  ||  -1.129 -0.872 -0.837 -0.461 -0.139 0.669 0.988 1.451  || dis=0.14 || select=7/8
017/019-th : 0.085 0.097 0.103 0.119 0.133 0.134 0.161 0.168  ||  -0.365 -0.228 -0.172 -0.022 0.090 0.093 0.280 0.317   || dis=0.01 || select=7/8
018/019-th : 0.095 0.112 0.125 0.153 0.128 0.121 0.123 0.143  ||  -0.262 -0.100 0.015 0.214 0.041 -0.015 -0.003 0.148   || dis=0.01 || select=3/8
[epoch=553/600] FLOP : 27.78 MB, ratio : 0.6808, Expected-ratio : 0.7000, Discrepancy : 0.315
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:37:27] [epoch=553/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.648 (0.648)  Prec@1 77.73 (77.73) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:37:34] [epoch=553/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.436 (1.593)  Prec@1 32.14 (60.87) Prec@5 82.74 (90.07) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.87 Prec@5 90.07 Error@1 39.13 Error@5 9.93 Loss:1.593
***[2020-01-29 10:37:34]*** VALID [epoch=553/600] loss = 1.592802, accuracy@1 = 60.87, accuracy@5 = 90.07 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:37:34]*** start epoch=554/600 Time Left: [00:24:37], LR=[0.001443 ~ 0.001443], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=554, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1707210142213919, FLOP=40.81
[Search] : epoch=554/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:37:34] [epoch=554/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.492 (0.492)  Prec@1 83.98 (83.98) Prec@5 98.44 (98.44) Acls-loss 0.636 (0.636) FLOP-Loss 0.000 (0.000) Arch-Loss 0.636 (0.636)
**TRAIN** [2020-01-29 10:37:59] [epoch=554/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.299 (0.370)  Prec@1 92.26 (87.40) Prec@5 98.81 (99.56) Acls-loss 0.420 (0.549) FLOP-Loss 0.000 (0.062) Arch-Loss 0.420 (0.672)
 **TRAIN** Prec@1 87.40 Prec@5 99.56 Error@1 12.60 Error@5 0.44 Base-Loss:0.370, Arch-Loss=0.672
***[2020-01-29 10:37:59]*** TRAIN [epoch=554/600] base-loss = 0.370333, arch-loss = 0.672293, accuracy-1 = 87.40, accuracy-5 = 99.56
[epoch=554/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.783804)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.142 0.587 0.270  ||  -0.4643 0.9523 0.1756  || discrepancy=0.32 || select=1/3
001/003-th : 0.340 0.317 0.343  ||  0.1660 0.0957 0.1745  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.963  ||  -2.2838 -0.5816 2.8313  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.011 0.011 0.013 0.016 0.028 0.906  ||  -1.324 -1.066 -0.879 -0.888 -0.687 -0.457 0.082 3.566  || dis=0.88 || select=7/8
001/019-th : 0.080 0.102 0.128 0.128 0.128 0.132 0.164 0.137  ||  -0.426 -0.184 0.038 0.038 0.042 0.066 0.288 0.109     || dis=0.03 || select=6/8
002/019-th : 0.107 0.113 0.131 0.134 0.123 0.138 0.136 0.117  ||  -0.146 -0.100 0.052 0.078 -0.009 0.102 0.091 -0.057   || dis=0.00 || select=5/8
003/019-th : 0.116 0.112 0.121 0.136 0.122 0.132 0.136 0.125  ||  -0.076 -0.108 -0.035 0.085 -0.025 0.053 0.083 -0.004  || dis=0.00 || select=3/8
004/019-th : 0.106 0.111 0.107 0.113 0.132 0.126 0.158 0.147  ||  -0.154 -0.105 -0.139 -0.086 0.073 0.022 0.250 0.178   || dis=0.01 || select=6/8
005/019-th : 0.134 0.135 0.123 0.124 0.123 0.123 0.121 0.118  ||  0.069 0.075 -0.012 -0.009 -0.014 -0.019 -0.033 -0.060  || dis=0.00 || select=1/8
006/019-th : 0.158 0.146 0.129 0.121 0.130 0.112 0.106 0.098  ||  0.244 0.169 0.042 -0.018 0.054 -0.101 -0.151 -0.227   || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.009 0.011 0.015 0.021 0.035 0.896  ||  -1.429 -1.270 -1.076 -0.819 -0.522 -0.210 0.330 3.561  || dis=0.86 || select=7/8
008/019-th : 0.006 0.007 0.011 0.014 0.021 0.029 0.057 0.856  ||  -1.681 -1.467 -1.050 -0.747 -0.395 -0.033 0.619 3.336  || dis=0.80 || select=7/8
009/019-th : 0.087 0.089 0.094 0.107 0.119 0.140 0.161 0.204  ||  -0.322 -0.294 -0.247 -0.114 -0.012 0.152 0.292 0.533  || dis=0.04 || select=7/8
010/019-th : 0.088 0.099 0.107 0.119 0.122 0.148 0.157 0.160  ||  -0.323 -0.210 -0.131 -0.021 0.004 0.194 0.251 0.273   || dis=0.00 || select=7/8
011/019-th : 0.128 0.113 0.119 0.119 0.129 0.133 0.128 0.131  ||  0.028 -0.094 -0.042 -0.047 0.037 0.063 0.029 0.053    || dis=0.00 || select=5/8
012/019-th : 0.156 0.140 0.127 0.125 0.123 0.115 0.107 0.107  ||  0.231 0.122 0.027 0.012 -0.006 -0.070 -0.141 -0.145   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.012 -0.980 -0.969 -0.872 -0.742 -0.550 -0.289 4.734  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.013 0.958  ||  -1.255 -1.256 -1.062 -0.925 -0.772 -0.394 0.127 4.396  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.005 0.006 0.008 0.967  ||  -1.200 -0.722 -0.945 -0.924 -0.723 -0.498 -0.116 4.635  || dis=0.96 || select=7/8
016/019-th : 0.028 0.036 0.037 0.054 0.074 0.170 0.231 0.369  ||  -1.118 -0.875 -0.839 -0.464 -0.160 0.679 0.987 1.454  || dis=0.14 || select=7/8
017/019-th : 0.085 0.097 0.103 0.119 0.135 0.133 0.160 0.168  ||  -0.361 -0.231 -0.173 -0.024 0.103 0.087 0.274 0.319   || dis=0.01 || select=7/8
018/019-th : 0.094 0.111 0.126 0.151 0.128 0.121 0.125 0.143  ||  -0.271 -0.105 0.021 0.203 0.037 -0.018 0.015 0.151    || dis=0.01 || select=3/8
[epoch=554/600] FLOP : 27.78 MB, ratio : 0.6808, Expected-ratio : 0.7000, Discrepancy : 0.315
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:37:59] [epoch=554/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 1.074 (1.074)  Prec@1 62.89 (62.89) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:38:05] [epoch=554/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.963 (1.468)  Prec@1 73.21 (62.00) Prec@5 96.43 (90.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 62.00 Prec@5 90.42 Error@1 38.00 Error@5 9.58 Loss:1.468
***[2020-01-29 10:38:05]*** VALID [epoch=554/600] loss = 1.468379, accuracy@1 = 62.00, accuracy@5 = 90.42 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:38:05]*** start epoch=555/600 Time Left: [00:24:05], LR=[0.001382 ~ 0.001382], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=555, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.16769369502569245, FLOP=40.81
[Search] : epoch=555/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:38:06] [epoch=555/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.255 (0.255)  Prec@1 90.23 (90.23) Prec@5 99.61 (99.61) Acls-loss 0.571 (0.571) FLOP-Loss 0.000 (0.000) Arch-Loss 0.571 (0.571)
**TRAIN** [2020-01-29 10:38:31] [epoch=555/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.230 (0.414)  Prec@1 91.07 (86.18) Prec@5 100.00 (99.34) Acls-loss 0.391 (0.561) FLOP-Loss 0.000 (0.000) Arch-Loss 0.391 (0.561)
 **TRAIN** Prec@1 86.18 Prec@5 99.34 Error@1 13.82 Error@5 0.66 Base-Loss:0.414, Arch-Loss=0.561
***[2020-01-29 10:38:31]*** TRAIN [epoch=555/600] base-loss = 0.414471, arch-loss = 0.561025, accuracy-1 = 86.18, accuracy-5 = 99.34
[epoch=555/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 6, 4, 32, 32, 32, 32, 25, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 27.783804)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.141 0.588 0.271  ||  -0.4725 0.9550 0.1788  || discrepancy=0.32 || select=1/3
001/003-th : 0.338 0.319 0.343  ||  0.1619 0.1044 0.1758  || discrepancy=0.01 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2794 -0.5811 2.8269  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.010 0.010 0.012 0.016 0.027 0.909  ||  -1.345 -1.059 -0.874 -0.899 -0.707 -0.455 0.062 3.592  || dis=0.88 || select=7/8
001/019-th : 0.079 0.102 0.128 0.127 0.128 0.133 0.165 0.139  ||  -0.440 -0.191 0.036 0.032 0.036 0.075 0.295 0.125     || dis=0.03 || select=6/8
002/019-th : 0.108 0.111 0.131 0.133 0.124 0.138 0.138 0.118  ||  -0.146 -0.116 0.049 0.069 -0.004 0.104 0.101 -0.049   || dis=0.00 || select=5/8
003/019-th : 0.116 0.112 0.121 0.137 0.121 0.130 0.136 0.126  ||  -0.079 -0.109 -0.032 0.091 -0.034 0.036 0.085 0.007   || dis=0.00 || select=3/8
004/019-th : 0.104 0.111 0.107 0.113 0.132 0.126 0.159 0.149  ||  -0.171 -0.102 -0.140 -0.087 0.071 0.020 0.254 0.191   || dis=0.01 || select=6/8
005/019-th : 0.133 0.134 0.124 0.125 0.122 0.122 0.123 0.118  ||  0.064 0.070 -0.011 0.000 -0.023 -0.026 -0.020 -0.058  || dis=0.00 || select=1/8
006/019-th : 0.159 0.145 0.129 0.123 0.130 0.111 0.106 0.098  ||  0.252 0.163 0.043 -0.003 0.049 -0.108 -0.150 -0.234   || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.015 0.020 0.035 0.898  ||  -1.425 -1.279 -1.087 -0.825 -0.520 -0.225 0.326 3.583  || dis=0.86 || select=7/8
008/019-th : 0.006 0.007 0.010 0.014 0.020 0.029 0.055 0.859  ||  -1.675 -1.475 -1.068 -0.743 -0.404 -0.027 0.605 3.356  || dis=0.80 || select=7/8
009/019-th : 0.086 0.088 0.094 0.106 0.117 0.141 0.160 0.208  ||  -0.327 -0.306 -0.247 -0.125 -0.021 0.164 0.291 0.550  || dis=0.05 || select=7/8
010/019-th : 0.087 0.100 0.108 0.117 0.124 0.149 0.155 0.161  ||  -0.332 -0.197 -0.122 -0.043 0.015 0.201 0.239 0.277   || dis=0.01 || select=7/8
011/019-th : 0.128 0.114 0.118 0.116 0.128 0.133 0.131 0.132  ||  0.029 -0.092 -0.053 -0.070 0.028 0.067 0.054 0.059    || dis=0.00 || select=5/8
012/019-th : 0.155 0.139 0.127 0.125 0.123 0.116 0.108 0.108  ||  0.226 0.117 0.024 0.007 -0.009 -0.063 -0.137 -0.138   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.009 -0.976 -0.966 -0.870 -0.739 -0.548 -0.288 4.729  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.013 0.957  ||  -1.249 -1.254 -1.060 -0.923 -0.775 -0.392 0.127 4.392  || dis=0.94 || select=7/8
015/019-th : 0.003 0.004 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.196 -0.718 -0.948 -0.952 -0.737 -0.494 -0.123 4.660  || dis=0.96 || select=7/8
016/019-th : 0.028 0.035 0.037 0.054 0.073 0.168 0.232 0.373  ||  -1.124 -0.904 -0.832 -0.469 -0.162 0.676 0.996 1.472  || dis=0.14 || select=7/8
017/019-th : 0.085 0.094 0.102 0.120 0.131 0.132 0.167 0.169  ||  -0.365 -0.258 -0.175 -0.018 0.072 0.082 0.317 0.329   || dis=0.00 || select=7/8
018/019-th : 0.094 0.114 0.124 0.150 0.130 0.117 0.125 0.144  ||  -0.271 -0.078 0.009 0.197 0.054 -0.050 0.016 0.155    || dis=0.01 || select=3/8
[epoch=555/600] FLOP : 27.78 MB, ratio : 0.6808, Expected-ratio : 0.7000, Discrepancy : 0.316
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:38:32] [epoch=555/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.963 (0.963)  Prec@1 67.97 (67.97) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:38:38] [epoch=555/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 6.237 (1.751)  Prec@1 10.12 (59.58) Prec@5 57.74 (90.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 59.58 Prec@5 90.20 Error@1 40.42 Error@5 9.80 Loss:1.751
***[2020-01-29 10:38:38]*** VALID [epoch=555/600] loss = 1.751073, accuracy@1 = 59.58, accuracy@5 = 90.20 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:38:38]*** start epoch=556/600 Time Left: [00:23:33], LR=[0.001321 ~ 0.001321], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=556, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1647316879607573, FLOP=40.81
[Search] : epoch=556/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:38:39] [epoch=556/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.351 (0.351)  Prec@1 87.50 (87.50) Prec@5 99.61 (99.61) Acls-loss 0.635 (0.635) FLOP-Loss 0.000 (0.000) Arch-Loss 0.635 (0.635)
**TRAIN** [2020-01-29 10:39:03] [epoch=556/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.269 (0.364)  Prec@1 88.10 (87.85) Prec@5 100.00 (99.58) Acls-loss 0.584 (0.563) FLOP-Loss -3.006 (0.165) Arch-Loss -5.428 (0.892)
 **TRAIN** Prec@1 87.85 Prec@5 99.58 Error@1 12.15 Error@5 0.42 Base-Loss:0.364, Arch-Loss=0.892
***[2020-01-29 10:39:03]*** TRAIN [epoch=556/600] base-loss = 0.363809, arch-loss = 0.891745, accuracy-1 = 87.85, accuracy-5 = 99.58
[epoch=556/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 14, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 30.019964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.140 0.590 0.269  ||  -0.4751 0.9606 0.1754  || discrepancy=0.32 || select=1/3
001/003-th : 0.341 0.318 0.341  ||  0.1679 0.1002 0.1691  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.963  ||  -2.2827 -0.5840 2.8308  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.010 0.010 0.012 0.016 0.026 0.910  ||  -1.337 -1.066 -0.869 -0.893 -0.703 -0.452 0.028 3.598  || dis=0.88 || select=7/8
001/019-th : 0.080 0.101 0.128 0.127 0.127 0.132 0.165 0.139  ||  -0.428 -0.194 0.037 0.033 0.029 0.073 0.292 0.124     || dis=0.03 || select=6/8
002/019-th : 0.108 0.111 0.131 0.131 0.125 0.138 0.138 0.118  ||  -0.145 -0.112 0.050 0.050 0.008 0.106 0.107 -0.057    || dis=0.00 || select=6/8
003/019-th : 0.117 0.113 0.123 0.136 0.122 0.128 0.137 0.125  ||  -0.066 -0.106 -0.020 0.080 -0.024 0.017 0.086 -0.004  || dis=0.00 || select=6/8
004/019-th : 0.104 0.112 0.108 0.114 0.131 0.125 0.159 0.147  ||  -0.167 -0.093 -0.134 -0.080 0.060 0.018 0.257 0.178   || dis=0.01 || select=6/8
005/019-th : 0.134 0.132 0.124 0.126 0.122 0.123 0.123 0.117  ||  0.068 0.055 -0.007 0.005 -0.024 -0.014 -0.017 -0.068  || dis=0.00 || select=0/8
006/019-th : 0.159 0.144 0.129 0.126 0.128 0.110 0.106 0.097  ||  0.256 0.154 0.045 0.022 0.040 -0.112 -0.150 -0.235    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.015 0.020 0.034 0.899  ||  -1.440 -1.275 -1.083 -0.823 -0.521 -0.223 0.319 3.593  || dis=0.86 || select=7/8
008/019-th : 0.006 0.007 0.010 0.014 0.020 0.029 0.054 0.860  ||  -1.661 -1.484 -1.064 -0.739 -0.404 -0.035 0.594 3.358  || dis=0.81 || select=7/8
009/019-th : 0.087 0.089 0.094 0.106 0.117 0.142 0.160 0.206  ||  -0.325 -0.294 -0.245 -0.124 -0.027 0.168 0.290 0.544  || dis=0.05 || select=7/8
010/019-th : 0.088 0.100 0.109 0.117 0.123 0.149 0.155 0.158  ||  -0.327 -0.196 -0.110 -0.041 0.010 0.199 0.242 0.262   || dis=0.00 || select=7/8
011/019-th : 0.128 0.115 0.118 0.116 0.127 0.131 0.131 0.134  ||  0.028 -0.081 -0.051 -0.071 0.021 0.049 0.052 0.072    || dis=0.00 || select=7/8
012/019-th : 0.156 0.139 0.127 0.125 0.122 0.116 0.108 0.107  ||  0.230 0.118 0.025 0.011 -0.012 -0.064 -0.138 -0.143   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.006 -0.972 -0.976 -0.869 -0.736 -0.547 -0.286 4.729  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.013 0.958  ||  -1.250 -1.249 -1.068 -0.921 -0.773 -0.389 0.127 4.396  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.192 -0.712 -0.944 -0.949 -0.735 -0.493 -0.132 4.657  || dis=0.96 || select=7/8
016/019-th : 0.027 0.035 0.038 0.054 0.073 0.171 0.228 0.374  ||  -1.140 -0.907 -0.813 -0.467 -0.161 0.693 0.977 1.474  || dis=0.15 || select=7/8
017/019-th : 0.084 0.092 0.102 0.123 0.132 0.131 0.166 0.169  ||  -0.371 -0.276 -0.171 0.013 0.084 0.075 0.313 0.331    || dis=0.00 || select=7/8
018/019-th : 0.096 0.115 0.125 0.149 0.132 0.117 0.124 0.142  ||  -0.248 -0.072 0.014 0.185 0.065 -0.057 0.007 0.140    || dis=0.01 || select=3/8
[epoch=556/600] FLOP : 30.02 MB, ratio : 0.7355, Expected-ratio : 0.7000, Discrepancy : 0.316
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:39:03] [epoch=556/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 2.355 (2.355)  Prec@1 31.64 (31.64) Prec@5 87.89 (87.89) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:39:09] [epoch=556/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.743 (1.885)  Prec@1 27.38 (57.12) Prec@5 73.81 (89.17) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.12 Prec@5 89.17 Error@1 42.88 Error@5 10.83 Loss:1.885
***[2020-01-29 10:39:09]*** VALID [epoch=556/600] loss = 1.884510, accuracy@1 = 57.12, accuracy@5 = 89.17 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:39:10]*** start epoch=557/600 Time Left: [00:23:00], LR=[0.001262 ~ 0.001262], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=557, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1618350742315067, FLOP=40.81
[Search] : epoch=557/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:39:10] [epoch=557/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 0.273 (0.273)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00) Acls-loss 0.568 (0.568) FLOP-Loss 3.006 (3.006) Arch-Loss 6.580 (6.580)
**TRAIN** [2020-01-29 10:39:35] [epoch=557/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.692 (0.412)  Prec@1 75.00 (86.17) Prec@5 99.40 (99.38) Acls-loss 0.495 (0.538) FLOP-Loss -3.006 (0.072) Arch-Loss -5.516 (0.682)
 **TRAIN** Prec@1 86.17 Prec@5 99.38 Error@1 13.83 Error@5 0.62 Base-Loss:0.412, Arch-Loss=0.682
***[2020-01-29 10:39:35]*** TRAIN [epoch=557/600] base-loss = 0.412250, arch-loss = 0.682431, accuracy-1 = 86.17, accuracy-5 = 99.38
[epoch=557/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 14, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 30.019964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.141 0.591 0.268  ||  -0.4733 0.9599 0.1715  || discrepancy=0.32 || select=1/3
001/003-th : 0.340 0.319 0.340  ||  0.1676 0.1034 0.1678  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2792 -0.5859 2.8279  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.010 0.010 0.012 0.016 0.025 0.911  ||  -1.328 -1.059 -0.891 -0.892 -0.710 -0.455 0.032 3.609  || dis=0.89 || select=7/8
001/019-th : 0.080 0.101 0.129 0.128 0.126 0.133 0.164 0.139  ||  -0.432 -0.193 0.045 0.036 0.026 0.077 0.288 0.123     || dis=0.02 || select=6/8
002/019-th : 0.107 0.112 0.132 0.130 0.126 0.137 0.138 0.117  ||  -0.147 -0.105 0.058 0.041 0.014 0.100 0.107 -0.058    || dis=0.00 || select=6/8
003/019-th : 0.117 0.112 0.122 0.136 0.122 0.128 0.137 0.124  ||  -0.070 -0.108 -0.025 0.084 -0.024 0.023 0.092 -0.007  || dis=0.00 || select=6/8
004/019-th : 0.104 0.112 0.108 0.114 0.131 0.125 0.159 0.147  ||  -0.173 -0.092 -0.131 -0.078 0.066 0.012 0.258 0.176   || dis=0.01 || select=6/8
005/019-th : 0.133 0.131 0.129 0.122 0.122 0.124 0.123 0.117  ||  0.062 0.047 0.030 -0.023 -0.019 -0.011 -0.017 -0.068  || dis=0.00 || select=0/8
006/019-th : 0.159 0.144 0.131 0.125 0.128 0.109 0.106 0.099  ||  0.255 0.152 0.058 0.010 0.034 -0.120 -0.151 -0.224    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.015 0.020 0.034 0.900  ||  -1.436 -1.272 -1.079 -0.826 -0.532 -0.223 0.317 3.595  || dis=0.87 || select=7/8
008/019-th : 0.006 0.007 0.010 0.014 0.020 0.028 0.053 0.863  ||  -1.655 -1.487 -1.073 -0.731 -0.411 -0.047 0.580 3.374  || dis=0.81 || select=7/8
009/019-th : 0.087 0.090 0.093 0.105 0.116 0.140 0.159 0.209  ||  -0.318 -0.286 -0.253 -0.125 -0.026 0.159 0.287 0.561  || dis=0.05 || select=7/8
010/019-th : 0.089 0.100 0.110 0.117 0.123 0.149 0.154 0.158  ||  -0.318 -0.195 -0.105 -0.042 0.008 0.199 0.236 0.257   || dis=0.00 || select=7/8
011/019-th : 0.127 0.115 0.119 0.115 0.127 0.130 0.131 0.137  ||  0.017 -0.076 -0.046 -0.079 0.017 0.042 0.050 0.094    || dis=0.01 || select=7/8
012/019-th : 0.156 0.139 0.127 0.125 0.122 0.116 0.108 0.107  ||  0.230 0.116 0.024 0.009 -0.011 -0.064 -0.138 -0.141   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.002 -0.967 -0.984 -0.867 -0.734 -0.545 -0.285 4.728  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.014 0.957  ||  -1.244 -1.242 -1.066 -0.919 -0.796 -0.387 0.145 4.396  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.188 -0.706 -0.939 -0.949 -0.733 -0.491 -0.157 4.663  || dis=0.96 || select=7/8
016/019-th : 0.027 0.035 0.038 0.054 0.075 0.171 0.228 0.372  ||  -1.145 -0.900 -0.823 -0.462 -0.140 0.692 0.980 1.467  || dis=0.14 || select=7/8
017/019-th : 0.084 0.092 0.102 0.123 0.133 0.132 0.165 0.169  ||  -0.365 -0.281 -0.173 0.014 0.087 0.081 0.308 0.330    || dis=0.00 || select=7/8
018/019-th : 0.097 0.113 0.126 0.149 0.132 0.117 0.124 0.141  ||  -0.242 -0.091 0.021 0.190 0.066 -0.051 0.008 0.135    || dis=0.01 || select=3/8
[epoch=557/600] FLOP : 30.02 MB, ratio : 0.7355, Expected-ratio : 0.7000, Discrepancy : 0.317
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:39:35] [epoch=557/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.713 (0.713)  Prec@1 75.00 (75.00) Prec@5 99.22 (99.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:39:41] [epoch=557/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.892 (1.517)  Prec@1 70.83 (59.53) Prec@5 95.83 (90.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 59.53 Prec@5 90.54 Error@1 40.47 Error@5 9.46 Loss:1.517
***[2020-01-29 10:39:41]*** VALID [epoch=557/600] loss = 1.516760, accuracy@1 = 59.53, accuracy@5 = 90.54 | Best-Valid-Acc@1=62.78, Error@1=37.22
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:39:42]*** start epoch=558/600 Time Left: [00:22:28], LR=[0.001204 ~ 0.001204], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=558, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.15900393325006879, FLOP=40.81
[Search] : epoch=558/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:39:42] [epoch=558/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.503 (0.503)  Prec@1 82.03 (82.03) Prec@5 99.61 (99.61) Acls-loss 0.506 (0.506) FLOP-Loss 3.006 (3.006) Arch-Loss 6.518 (6.518)
**TRAIN** [2020-01-29 10:40:07] [epoch=558/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.376 (0.383)  Prec@1 89.29 (87.02) Prec@5 100.00 (99.47) Acls-loss 0.502 (0.573) FLOP-Loss -3.007 (0.134) Arch-Loss -5.511 (0.840)
 **TRAIN** Prec@1 87.02 Prec@5 99.47 Error@1 12.98 Error@5 0.53 Base-Loss:0.383, Arch-Loss=0.840
***[2020-01-29 10:40:08]*** TRAIN [epoch=558/600] base-loss = 0.383210, arch-loss = 0.840359, accuracy-1 = 87.02, accuracy-5 = 99.47
[epoch=558/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.643132)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.140 0.592 0.268  ||  -0.4768 0.9641 0.1701  || discrepancy=0.32 || select=1/3
001/003-th : 0.339 0.322 0.339  ||  0.1660 0.1129 0.1665  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.963  ||  -2.2822 -0.5877 2.8313  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.010 0.010 0.012 0.015 0.025 0.912  ||  -1.318 -1.051 -0.885 -0.887 -0.706 -0.479 0.027 3.614  || dis=0.89 || select=7/8
001/019-th : 0.080 0.099 0.127 0.127 0.125 0.134 0.169 0.140  ||  -0.436 -0.216 0.034 0.033 0.015 0.084 0.318 0.128     || dis=0.03 || select=6/8
002/019-th : 0.104 0.111 0.133 0.129 0.126 0.142 0.137 0.117  ||  -0.173 -0.108 0.070 0.039 0.019 0.133 0.102 -0.061    || dis=0.00 || select=5/8
003/019-th : 0.117 0.113 0.123 0.135 0.120 0.130 0.137 0.124  ||  -0.068 -0.101 -0.023 0.076 -0.044 0.037 0.092 -0.010  || dis=0.00 || select=6/8
004/019-th : 0.102 0.113 0.108 0.115 0.130 0.127 0.158 0.147  ||  -0.184 -0.082 -0.130 -0.065 0.054 0.031 0.253 0.176   || dis=0.01 || select=6/8
005/019-th : 0.133 0.128 0.126 0.123 0.124 0.123 0.123 0.121  ||  0.065 0.022 0.011 -0.020 -0.011 -0.013 -0.019 -0.035  || dis=0.01 || select=0/8
006/019-th : 0.160 0.144 0.130 0.125 0.126 0.110 0.107 0.098  ||  0.260 0.154 0.050 0.013 0.024 -0.115 -0.145 -0.230    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.020 0.034 0.900  ||  -1.436 -1.268 -1.077 -0.822 -0.537 -0.225 0.314 3.596  || dis=0.87 || select=7/8
008/019-th : 0.006 0.007 0.010 0.014 0.019 0.028 0.052 0.865  ||  -1.649 -1.491 -1.069 -0.727 -0.419 -0.059 0.568 3.382  || dis=0.81 || select=7/8
009/019-th : 0.086 0.091 0.093 0.105 0.116 0.139 0.159 0.212  ||  -0.326 -0.276 -0.253 -0.128 -0.027 0.153 0.284 0.574  || dis=0.05 || select=7/8
010/019-th : 0.089 0.100 0.110 0.118 0.123 0.147 0.154 0.159  ||  -0.320 -0.199 -0.102 -0.031 0.011 0.189 0.232 0.262   || dis=0.01 || select=7/8
011/019-th : 0.125 0.115 0.119 0.115 0.131 0.129 0.129 0.136  ||  0.007 -0.076 -0.049 -0.077 0.049 0.039 0.036 0.089    || dis=0.01 || select=7/8
012/019-th : 0.156 0.140 0.124 0.124 0.126 0.116 0.108 0.106  ||  0.232 0.121 0.002 0.002 0.019 -0.063 -0.136 -0.150    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.015 -0.963 -0.992 -0.865 -0.731 -0.543 -0.284 4.734  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.005 0.005 0.008 0.013 0.958  ||  -1.237 -1.235 -1.064 -0.916 -0.794 -0.397 0.118 4.408  || dis=0.94 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.183 -0.700 -0.933 -0.947 -0.730 -0.487 -0.160 4.657  || dis=0.96 || select=7/8
016/019-th : 0.027 0.034 0.038 0.054 0.073 0.170 0.232 0.372  ||  -1.158 -0.910 -0.803 -0.459 -0.162 0.688 0.998 1.470  || dis=0.14 || select=7/8
017/019-th : 0.084 0.091 0.104 0.123 0.131 0.135 0.164 0.167  ||  -0.365 -0.285 -0.159 0.014 0.080 0.105 0.304 0.320    || dis=0.00 || select=7/8
018/019-th : 0.097 0.114 0.127 0.149 0.131 0.116 0.127 0.140  ||  -0.240 -0.083 0.026 0.188 0.056 -0.060 0.026 0.123    || dis=0.01 || select=3/8
[epoch=558/600] FLOP : 29.64 MB, ratio : 0.7263, Expected-ratio : 0.7000, Discrepancy : 0.318
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:40:08] [epoch=558/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 4.083 (4.083)  Prec@1 15.23 (15.23) Prec@5 66.80 (66.80) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:40:14] [epoch=558/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 2.076 (1.681)  Prec@1 53.57 (62.85) Prec@5 88.69 (91.66) Size=[168, 3, 32, 32]
 **VALID** Prec@1 62.85 Prec@5 91.66 Error@1 37.15 Error@5 8.34 Loss:1.681
***[2020-01-29 10:40:14]*** VALID [epoch=558/600] loss = 1.681434, accuracy@1 = 62.85, accuracy@5 = 91.66 | Best-Valid-Acc@1=62.78, Error@1=37.22
Currently, the best validation accuracy found at 558-epoch :: acc@1=62.85, acc@5=91.66, error@1=37.15, error@5=8.34, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:40:14]*** start epoch=559/600 Time Left: [00:21:56], LR=[0.001148 ~ 0.001148], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=559, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.15623834263360412, FLOP=40.81
[Search] : epoch=559/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:40:15] [epoch=559/600][000/098] Time 0.67 (0.67) Data 0.38 (0.38) Base-Loss 0.197 (0.197)  Prec@1 92.58 (92.58) Prec@5 100.00 (100.00) Acls-loss 0.492 (0.492) FLOP-Loss 3.007 (3.007) Arch-Loss 6.505 (6.505)
**TRAIN** [2020-01-29 10:40:40] [epoch=559/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.445 (0.375)  Prec@1 83.93 (87.21) Prec@5 100.00 (99.54) Acls-loss 0.480 (0.552) FLOP-Loss 3.006 (0.174) Arch-Loss 6.493 (0.901)
 **TRAIN** Prec@1 87.21 Prec@5 99.54 Error@1 12.79 Error@5 0.46 Base-Loss:0.375, Arch-Loss=0.901
***[2020-01-29 10:40:40]*** TRAIN [epoch=559/600] base-loss = 0.374545, arch-loss = 0.900998, accuracy-1 = 87.21, accuracy-5 = 99.54
[epoch=559/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.643132)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.140 0.594 0.266  ||  -0.4778 0.9697 0.1661  || discrepancy=0.33 || select=1/3
001/003-th : 0.340 0.320 0.340  ||  0.1664 0.1060 0.1666  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2771 -0.5764 2.8240  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.009 0.010 0.010 0.012 0.015 0.025 0.912  ||  -1.307 -1.046 -0.878 -0.884 -0.703 -0.484 0.018 3.613  || dis=0.89 || select=7/8
001/019-th : 0.080 0.100 0.126 0.127 0.125 0.134 0.168 0.139  ||  -0.427 -0.210 0.025 0.032 0.018 0.085 0.313 0.125     || dis=0.03 || select=6/8
002/019-th : 0.104 0.112 0.134 0.127 0.126 0.141 0.138 0.117  ||  -0.172 -0.101 0.078 0.027 0.015 0.127 0.106 -0.063    || dis=0.00 || select=5/8
003/019-th : 0.117 0.114 0.121 0.136 0.119 0.132 0.136 0.124  ||  -0.069 -0.091 -0.033 0.081 -0.048 0.053 0.085 -0.012  || dis=0.00 || select=6/8
004/019-th : 0.103 0.113 0.108 0.117 0.127 0.126 0.158 0.148  ||  -0.180 -0.085 -0.128 -0.053 0.034 0.020 0.253 0.184   || dis=0.01 || select=6/8
005/019-th : 0.134 0.127 0.128 0.125 0.124 0.122 0.120 0.121  ||  0.067 0.015 0.025 0.002 -0.010 -0.024 -0.038 -0.035   || dis=0.01 || select=0/8
006/019-th : 0.158 0.144 0.130 0.126 0.126 0.114 0.105 0.098  ||  0.251 0.153 0.050 0.019 0.019 -0.080 -0.161 -0.230    || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.033 0.902  ||  -1.432 -1.264 -1.099 -0.820 -0.533 -0.234 0.313 3.611  || dis=0.87 || select=7/8
008/019-th : 0.006 0.007 0.010 0.014 0.019 0.027 0.051 0.868  ||  -1.642 -1.486 -1.079 -0.719 -0.434 -0.082 0.560 3.400  || dis=0.82 || select=7/8
009/019-th : 0.086 0.091 0.093 0.105 0.115 0.140 0.158 0.212  ||  -0.328 -0.265 -0.253 -0.124 -0.037 0.158 0.282 0.575  || dis=0.05 || select=7/8
010/019-th : 0.089 0.101 0.109 0.118 0.123 0.147 0.155 0.157  ||  -0.311 -0.194 -0.113 -0.030 0.008 0.187 0.238 0.252   || dis=0.00 || select=7/8
011/019-th : 0.126 0.116 0.120 0.116 0.131 0.128 0.129 0.135  ||  0.009 -0.074 -0.040 -0.070 0.052 0.024 0.036 0.081    || dis=0.00 || select=7/8
012/019-th : 0.157 0.140 0.124 0.124 0.126 0.113 0.108 0.108  ||  0.234 0.125 0.000 0.001 0.019 -0.091 -0.136 -0.138    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -1.012 -0.958 -0.994 -0.863 -0.728 -0.540 -0.301 4.736  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.008 0.013 0.959  ||  -1.230 -1.227 -1.062 -0.938 -0.792 -0.409 0.118 4.425  || dis=0.95 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.967  ||  -1.178 -0.695 -0.928 -0.944 -0.728 -0.483 -0.172 4.655  || dis=0.96 || select=7/8
016/019-th : 0.027 0.035 0.038 0.054 0.073 0.168 0.233 0.372  ||  -1.152 -0.901 -0.813 -0.453 -0.162 0.676 1.003 1.470  || dis=0.14 || select=7/8
017/019-th : 0.084 0.091 0.104 0.121 0.133 0.136 0.165 0.166  ||  -0.366 -0.284 -0.156 -0.002 0.088 0.110 0.306 0.315   || dis=0.00 || select=7/8
018/019-th : 0.097 0.114 0.128 0.152 0.130 0.114 0.125 0.139  ||  -0.237 -0.083 0.039 0.209 0.055 -0.080 0.017 0.119    || dis=0.01 || select=3/8
[epoch=559/600] FLOP : 29.64 MB, ratio : 0.7263, Expected-ratio : 0.7000, Discrepancy : 0.318
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:40:40] [epoch=559/600][000/098] Time 0.38 (0.38) Data 0.27 (0.27) Loss 0.783 (0.783)  Prec@1 75.00 (75.00) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:40:46] [epoch=559/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 1.211 (1.654)  Prec@1 63.69 (61.49) Prec@5 94.05 (90.60) Size=[168, 3, 32, 32]
 **VALID** Prec@1 61.49 Prec@5 90.60 Error@1 38.51 Error@5 9.40 Loss:1.654
***[2020-01-29 10:40:46]*** VALID [epoch=559/600] loss = 1.654066, accuracy@1 = 61.49, accuracy@5 = 90.60 | Best-Valid-Acc@1=62.85, Error@1=37.15
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:40:46]*** start epoch=560/600 Time Left: [00:21:24], LR=[0.001093 ~ 0.001093], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=560, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.15353837820217608, FLOP=40.81
[Search] : epoch=560/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:40:47] [epoch=560/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.475 (0.475)  Prec@1 83.59 (83.59) Prec@5 99.61 (99.61) Acls-loss 0.452 (0.452) FLOP-Loss 3.006 (3.006) Arch-Loss 6.465 (6.465)
**TRAIN** [2020-01-29 10:41:12] [epoch=560/600][097/098] Time 0.26 (0.26) Data 0.00 (0.00) Base-Loss 0.525 (0.373)  Prec@1 83.33 (87.29) Prec@5 97.62 (99.46) Acls-loss 0.668 (0.586) FLOP-Loss 3.007 (0.051) Arch-Loss 6.682 (0.689)
 **TRAIN** Prec@1 87.29 Prec@5 99.46 Error@1 12.71 Error@5 0.54 Base-Loss:0.373, Arch-Loss=0.689
***[2020-01-29 10:41:12]*** TRAIN [epoch=560/600] base-loss = 0.373431, arch-loss = 0.688563, accuracy-1 = 87.29, accuracy-5 = 99.46
[epoch=560/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.827964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.138 0.600 0.263  ||  -0.4838 0.9868 0.1614  || discrepancy=0.34 || select=1/3
001/003-th : 0.339 0.321 0.339  ||  0.1660 0.1111 0.1652  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.033 0.961  ||  -2.2720 -0.5649 2.8167  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.012 0.015 0.025 0.913  ||  -1.297 -1.062 -0.871 -0.898 -0.699 -0.485 0.017 3.623  || dis=0.89 || select=7/8
001/019-th : 0.080 0.100 0.128 0.127 0.126 0.133 0.166 0.140  ||  -0.429 -0.207 0.037 0.030 0.024 0.078 0.302 0.129     || dis=0.03 || select=6/8
002/019-th : 0.104 0.112 0.130 0.128 0.130 0.141 0.138 0.117  ||  -0.174 -0.106 0.050 0.034 0.044 0.132 0.104 -0.058    || dis=0.00 || select=5/8
003/019-th : 0.116 0.114 0.119 0.135 0.123 0.134 0.136 0.123  ||  -0.076 -0.091 -0.047 0.074 -0.019 0.068 0.082 -0.014  || dis=0.00 || select=6/8
004/019-th : 0.103 0.112 0.108 0.116 0.127 0.124 0.160 0.150  ||  -0.182 -0.096 -0.130 -0.063 0.034 0.010 0.262 0.198   || dis=0.01 || select=6/8
005/019-th : 0.133 0.127 0.126 0.125 0.124 0.123 0.121 0.121  ||  0.062 0.015 0.012 0.003 -0.010 -0.013 -0.030 -0.035   || dis=0.01 || select=0/8
006/019-th : 0.158 0.143 0.129 0.126 0.128 0.114 0.105 0.097  ||  0.249 0.152 0.046 0.022 0.037 -0.078 -0.159 -0.240    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.033 0.902  ||  -1.457 -1.248 -1.096 -0.817 -0.530 -0.238 0.315 3.616  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.010 0.014 0.018 0.026 0.048 0.874  ||  -1.668 -1.497 -1.078 -0.716 -0.454 -0.091 0.545 3.440  || dis=0.83 || select=7/8
009/019-th : 0.086 0.091 0.093 0.106 0.112 0.137 0.157 0.218  ||  -0.326 -0.267 -0.251 -0.119 -0.064 0.140 0.278 0.604  || dis=0.06 || select=7/8
010/019-th : 0.090 0.100 0.109 0.120 0.123 0.148 0.155 0.157  ||  -0.309 -0.202 -0.114 -0.021 0.005 0.190 0.236 0.254   || dis=0.00 || select=7/8
011/019-th : 0.126 0.116 0.117 0.117 0.131 0.129 0.129 0.135  ||  0.013 -0.069 -0.064 -0.065 0.051 0.035 0.037 0.077    || dis=0.00 || select=7/8
012/019-th : 0.156 0.140 0.125 0.124 0.126 0.113 0.109 0.108  ||  0.231 0.124 0.006 -0.002 0.017 -0.092 -0.132 -0.138   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -1.008 -0.953 -0.993 -0.861 -0.724 -0.543 -0.315 4.738  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.008 0.013 0.960  ||  -1.226 -1.236 -1.059 -0.936 -0.801 -0.407 0.100 4.439  || dis=0.95 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.172 -0.690 -0.952 -0.942 -0.742 -0.479 -0.171 4.670  || dis=0.96 || select=7/8
016/019-th : 0.027 0.035 0.038 0.055 0.072 0.167 0.231 0.375  ||  -1.151 -0.895 -0.814 -0.448 -0.167 0.669 0.992 1.479  || dis=0.14 || select=7/8
017/019-th : 0.084 0.092 0.104 0.121 0.130 0.136 0.165 0.168  ||  -0.367 -0.279 -0.159 -0.005 0.070 0.113 0.306 0.324   || dis=0.00 || select=7/8
018/019-th : 0.096 0.114 0.130 0.151 0.132 0.114 0.124 0.139  ||  -0.250 -0.083 0.053 0.206 0.065 -0.077 0.007 0.121    || dis=0.01 || select=3/8
[epoch=560/600] FLOP : 21.83 MB, ratio : 0.5348, Expected-ratio : 0.7000, Discrepancy : 0.319
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:41:13] [epoch=560/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 4.386 (4.386)  Prec@1 13.28 (13.28) Prec@5 57.42 (57.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:41:19] [epoch=560/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 6.440 (1.869)  Prec@1 17.26 (57.28) Prec@5 53.57 (89.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.28 Prec@5 89.02 Error@1 42.72 Error@5 10.98 Loss:1.869
***[2020-01-29 10:41:19]*** VALID [epoch=560/600] loss = 1.868552, accuracy@1 = 57.28, accuracy@5 = 89.02 | Best-Valid-Acc@1=62.85, Error@1=37.15
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:41:19]*** start epoch=561/600 Time Left: [00:20:52], LR=[0.001039 ~ 0.001039], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=561, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.15090411397667364, FLOP=40.81
[Search] : epoch=561/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:41:20] [epoch=561/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.310 (0.310)  Prec@1 90.23 (90.23) Prec@5 99.61 (99.61) Acls-loss 0.480 (0.480) FLOP-Loss -3.007 (-3.007) Arch-Loss -5.535 (-5.535)
**TRAIN** [2020-01-29 10:41:45] [epoch=561/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.211 (0.364)  Prec@1 92.26 (87.72) Prec@5 100.00 (99.55) Acls-loss 0.423 (0.537) FLOP-Loss 0.000 (0.031) Arch-Loss 0.423 (0.599)
 **TRAIN** Prec@1 87.72 Prec@5 99.55 Error@1 12.28 Error@5 0.45 Base-Loss:0.364, Arch-Loss=0.599
***[2020-01-29 10:41:45]*** TRAIN [epoch=561/600] base-loss = 0.364018, arch-loss = 0.599061, accuracy-1 = 87.72, accuracy-5 = 99.55
[epoch=561/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 9, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.445052)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.137 0.600 0.263  ||  -0.4914 0.9887 0.1645  || discrepancy=0.34 || select=1/3
001/003-th : 0.340 0.318 0.342  ||  0.1633 0.0986 0.1697  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2769 -0.5550 2.8193  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.012 0.015 0.024 0.914  ||  -1.286 -1.055 -0.871 -0.892 -0.707 -0.491 -0.003 3.631  || dis=0.89 || select=7/8
001/019-th : 0.080 0.100 0.128 0.127 0.125 0.133 0.167 0.141  ||  -0.429 -0.212 0.037 0.030 0.016 0.077 0.304 0.136     || dis=0.03 || select=6/8
002/019-th : 0.104 0.112 0.131 0.127 0.129 0.141 0.137 0.118  ||  -0.177 -0.101 0.052 0.027 0.040 0.129 0.101 -0.049    || dis=0.00 || select=5/8
003/019-th : 0.116 0.113 0.118 0.136 0.124 0.135 0.135 0.123  ||  -0.074 -0.100 -0.056 0.081 -0.010 0.075 0.080 -0.013  || dis=0.00 || select=3/8
004/019-th : 0.103 0.111 0.106 0.112 0.129 0.128 0.160 0.151  ||  -0.178 -0.106 -0.148 -0.090 0.047 0.037 0.264 0.203   || dis=0.01 || select=6/8
005/019-th : 0.133 0.127 0.126 0.124 0.125 0.124 0.121 0.121  ||  0.061 0.015 0.007 -0.010 0.004 -0.004 -0.030 -0.034   || dis=0.01 || select=0/8
006/019-th : 0.158 0.144 0.129 0.125 0.127 0.114 0.105 0.097  ||  0.250 0.154 0.049 0.014 0.033 -0.080 -0.160 -0.237    || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.020 0.033 0.902  ||  -1.453 -1.261 -1.093 -0.814 -0.534 -0.217 0.313 3.614  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.010 0.014 0.018 0.026 0.048 0.874  ||  -1.663 -1.492 -1.074 -0.717 -0.463 -0.090 0.538 3.441  || dis=0.83 || select=7/8
009/019-th : 0.086 0.092 0.092 0.108 0.112 0.137 0.157 0.217  ||  -0.322 -0.260 -0.259 -0.100 -0.063 0.138 0.277 0.600  || dis=0.06 || select=7/8
010/019-th : 0.088 0.100 0.108 0.118 0.124 0.148 0.157 0.157  ||  -0.325 -0.198 -0.119 -0.033 0.019 0.194 0.250 0.250   || dis=0.00 || select=7/8
011/019-th : 0.126 0.114 0.118 0.117 0.130 0.129 0.132 0.134  ||  0.014 -0.090 -0.054 -0.064 0.041 0.039 0.056 0.076    || dis=0.00 || select=7/8
012/019-th : 0.156 0.139 0.124 0.124 0.127 0.113 0.108 0.108  ||  0.228 0.119 0.003 0.003 0.024 -0.089 -0.133 -0.135    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -1.005 -0.947 -0.990 -0.871 -0.721 -0.541 -0.332 4.745  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.008 0.012 0.960  ||  -1.218 -1.233 -1.056 -0.934 -0.799 -0.408 0.087 4.441  || dis=0.95 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.167 -0.683 -0.949 -0.939 -0.741 -0.475 -0.172 4.665  || dis=0.96 || select=7/8
016/019-th : 0.027 0.035 0.037 0.055 0.073 0.167 0.230 0.376  ||  -1.163 -0.886 -0.842 -0.439 -0.150 0.671 0.996 1.486  || dis=0.15 || select=7/8
017/019-th : 0.083 0.091 0.103 0.121 0.128 0.138 0.167 0.168  ||  -0.375 -0.288 -0.161 -0.007 0.051 0.132 0.319 0.327   || dis=0.00 || select=7/8
018/019-th : 0.097 0.112 0.129 0.154 0.131 0.111 0.124 0.141  ||  -0.239 -0.092 0.045 0.220 0.062 -0.102 0.002 0.136    || dis=0.01 || select=3/8
[epoch=561/600] FLOP : 28.45 MB, ratio : 0.6970, Expected-ratio : 0.7000, Discrepancy : 0.319
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:41:45] [epoch=561/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 0.761 (0.761)  Prec@1 70.31 (70.31) Prec@5 99.61 (99.61) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:41:51] [epoch=561/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.221 (1.785)  Prec@1 31.55 (57.68) Prec@5 63.10 (89.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.68 Prec@5 89.58 Error@1 42.32 Error@5 10.42 Loss:1.785
***[2020-01-29 10:41:51]*** VALID [epoch=561/600] loss = 1.785042, accuracy@1 = 57.68, accuracy@5 = 89.58 | Best-Valid-Acc@1=62.85, Error@1=37.15
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:41:51]*** start epoch=562/600 Time Left: [00:20:20], LR=[0.000986 ~ 0.000986], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=562, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1483356221767817, FLOP=40.81
[Search] : epoch=562/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:41:52] [epoch=562/600][000/098] Time 0.67 (0.67) Data 0.35 (0.35) Base-Loss 0.298 (0.298)  Prec@1 89.45 (89.45) Prec@5 98.83 (98.83) Acls-loss 0.555 (0.555) FLOP-Loss 0.000 (0.000) Arch-Loss 0.555 (0.555)
**TRAIN** [2020-01-29 10:42:17] [epoch=562/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.734 (0.391)  Prec@1 76.79 (86.91) Prec@5 98.21 (99.47) Acls-loss 0.418 (0.540) FLOP-Loss 3.008 (0.174) Arch-Loss 6.435 (0.889)
 **TRAIN** Prec@1 86.91 Prec@5 99.47 Error@1 13.09 Error@5 0.53 Base-Loss:0.391, Arch-Loss=0.889
***[2020-01-29 10:42:17]*** TRAIN [epoch=562/600] base-loss = 0.391179, arch-loss = 0.888603, accuracy-1 = 86.91, accuracy-5 = 99.47
[epoch=562/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.348732)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.133 0.610 0.257  ||  -0.5028 1.0224 0.1570  || discrepancy=0.35 || select=1/3
001/003-th : 0.340 0.320 0.340  ||  0.1659 0.1030 0.1653  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.033 0.961  ||  -2.2740 -0.5510 2.8157  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.012 0.015 0.024 0.914  ||  -1.281 -1.047 -0.864 -0.885 -0.722 -0.488 -0.011 3.634  || dis=0.89 || select=7/8
001/019-th : 0.079 0.099 0.127 0.127 0.124 0.135 0.167 0.142  ||  -0.444 -0.212 0.031 0.035 0.010 0.093 0.305 0.143     || dis=0.03 || select=6/8
002/019-th : 0.104 0.110 0.131 0.129 0.128 0.141 0.139 0.117  ||  -0.177 -0.117 0.052 0.043 0.033 0.130 0.116 -0.055    || dis=0.00 || select=5/8
003/019-th : 0.116 0.114 0.119 0.133 0.126 0.135 0.134 0.123  ||  -0.075 -0.096 -0.049 0.065 0.006 0.081 0.073 -0.017   || dis=0.00 || select=5/8
004/019-th : 0.103 0.111 0.106 0.111 0.129 0.129 0.159 0.152  ||  -0.179 -0.105 -0.148 -0.100 0.046 0.050 0.256 0.209   || dis=0.01 || select=6/8
005/019-th : 0.133 0.126 0.127 0.125 0.126 0.123 0.121 0.120  ||  0.066 0.010 0.015 -0.001 0.009 -0.016 -0.031 -0.041   || dis=0.01 || select=0/8
006/019-th : 0.159 0.144 0.129 0.124 0.127 0.114 0.105 0.097  ||  0.255 0.157 0.048 0.009 0.030 -0.078 -0.162 -0.242    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.032 0.903  ||  -1.449 -1.257 -1.090 -0.811 -0.530 -0.232 0.294 3.623  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.010 0.014 0.018 0.026 0.047 0.875  ||  -1.657 -1.487 -1.069 -0.711 -0.463 -0.091 0.516 3.438  || dis=0.83 || select=7/8
009/019-th : 0.087 0.092 0.092 0.108 0.112 0.135 0.157 0.217  ||  -0.318 -0.258 -0.257 -0.097 -0.065 0.128 0.275 0.601  || dis=0.06 || select=7/8
010/019-th : 0.088 0.099 0.108 0.117 0.126 0.151 0.156 0.156  ||  -0.324 -0.206 -0.119 -0.042 0.030 0.215 0.244 0.244   || dis=0.00 || select=6/8
011/019-th : 0.126 0.114 0.117 0.117 0.130 0.129 0.132 0.134  ||  0.011 -0.086 -0.059 -0.064 0.045 0.037 0.061 0.070    || dis=0.00 || select=7/8
012/019-th : 0.155 0.138 0.125 0.125 0.127 0.113 0.109 0.109  ||  0.227 0.105 0.009 0.007 0.029 -0.090 -0.131 -0.130    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -1.001 -0.941 -0.987 -0.872 -0.717 -0.539 -0.331 4.741  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.007 0.012 0.961  ||  -1.210 -1.226 -1.061 -0.934 -0.796 -0.407 0.071 4.450  || dis=0.95 || select=7/8
015/019-th : 0.003 0.005 0.004 0.004 0.004 0.006 0.008 0.968  ||  -1.190 -0.675 -0.946 -0.937 -0.739 -0.470 -0.171 4.672  || dis=0.96 || select=7/8
016/019-th : 0.027 0.036 0.037 0.056 0.074 0.165 0.230 0.377  ||  -1.159 -0.877 -0.839 -0.429 -0.144 0.657 0.989 1.484  || dis=0.15 || select=7/8
017/019-th : 0.084 0.091 0.102 0.122 0.128 0.138 0.167 0.168  ||  -0.372 -0.292 -0.169 0.003 0.056 0.130 0.317 0.326    || dis=0.00 || select=7/8
018/019-th : 0.096 0.113 0.130 0.154 0.131 0.111 0.123 0.142  ||  -0.251 -0.088 0.056 0.222 0.059 -0.102 -0.004 0.144   || dis=0.01 || select=3/8
[epoch=562/600] FLOP : 21.35 MB, ratio : 0.5231, Expected-ratio : 0.7000, Discrepancy : 0.320
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:42:18] [epoch=562/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.783 (0.783)  Prec@1 75.78 (75.78) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:42:24] [epoch=562/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.525 (1.733)  Prec@1 82.74 (60.64) Prec@5 98.21 (89.86) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.64 Prec@5 89.86 Error@1 39.36 Error@5 10.14 Loss:1.733
***[2020-01-29 10:42:24]*** VALID [epoch=562/600] loss = 1.732804, accuracy@1 = 60.64, accuracy@5 = 89.86 | Best-Valid-Acc@1=62.85, Error@1=37.15
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:42:24]*** start epoch=563/600 Time Left: [00:19:48], LR=[0.000935 ~ 0.000935], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=563, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.14583297321899943, FLOP=40.81
[Search] : epoch=563/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:42:25] [epoch=563/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.300 (0.300)  Prec@1 89.84 (89.84) Prec@5 99.61 (99.61) Acls-loss 0.455 (0.455) FLOP-Loss -3.008 (-3.008) Arch-Loss -5.561 (-5.561)
**TRAIN** [2020-01-29 10:42:49] [epoch=563/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.367 (0.355)  Prec@1 87.50 (88.17) Prec@5 98.81 (99.52) Acls-loss 0.803 (0.559) FLOP-Loss 0.000 (-0.154) Arch-Loss 0.803 (0.251)
 **TRAIN** Prec@1 88.17 Prec@5 99.52 Error@1 11.83 Error@5 0.48 Base-Loss:0.355, Arch-Loss=0.251
***[2020-01-29 10:42:49]*** TRAIN [epoch=563/600] base-loss = 0.355309, arch-loss = 0.250684, accuracy-1 = 88.17, accuracy-5 = 99.52
[epoch=563/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.37478)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.133 0.607 0.261  ||  -0.5087 1.0099 0.1649  || discrepancy=0.35 || select=1/3
001/003-th : 0.337 0.325 0.338  ||  0.1628 0.1241 0.1642  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.034 0.961  ||  -2.2691 -0.5458 2.8098  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.012 0.014 0.023 0.916  ||  -1.270 -1.065 -0.858 -0.884 -0.717 -0.507 -0.020 3.655  || dis=0.89 || select=7/8
001/019-th : 0.078 0.099 0.126 0.128 0.124 0.135 0.166 0.144  ||  -0.450 -0.219 0.024 0.041 0.005 0.096 0.303 0.155     || dis=0.02 || select=6/8
002/019-th : 0.103 0.109 0.130 0.128 0.129 0.142 0.141 0.118  ||  -0.186 -0.129 0.049 0.033 0.037 0.139 0.129 -0.049    || dis=0.00 || select=5/8
003/019-th : 0.114 0.113 0.118 0.131 0.125 0.138 0.136 0.125  ||  -0.091 -0.101 -0.058 0.050 0.000 0.096 0.085 -0.001   || dis=0.00 || select=5/8
004/019-th : 0.102 0.107 0.107 0.112 0.130 0.130 0.159 0.154  ||  -0.189 -0.137 -0.143 -0.097 0.055 0.052 0.257 0.228   || dis=0.01 || select=6/8
005/019-th : 0.133 0.126 0.126 0.124 0.126 0.123 0.122 0.121  ||  0.061 0.006 0.012 -0.004 0.010 -0.015 -0.026 -0.034   || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.129 0.127 0.128 0.115 0.106 0.097  ||  0.243 0.143 0.042 0.027 0.034 -0.072 -0.150 -0.236    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.032 0.903  ||  -1.444 -1.254 -1.096 -0.808 -0.528 -0.239 0.292 3.626  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.010 0.014 0.017 0.025 0.046 0.876  ||  -1.654 -1.487 -1.065 -0.707 -0.479 -0.092 0.501 3.449  || dis=0.83 || select=7/8
009/019-th : 0.086 0.092 0.092 0.108 0.112 0.135 0.157 0.218  ||  -0.329 -0.258 -0.259 -0.096 -0.063 0.128 0.278 0.604  || dis=0.06 || select=7/8
010/019-th : 0.088 0.099 0.107 0.117 0.126 0.152 0.155 0.157  ||  -0.327 -0.209 -0.126 -0.043 0.031 0.220 0.242 0.252   || dis=0.00 || select=7/8
011/019-th : 0.126 0.114 0.115 0.117 0.129 0.130 0.135 0.134  ||  0.010 -0.088 -0.085 -0.064 0.037 0.042 0.079 0.074    || dis=0.00 || select=6/8
012/019-th : 0.154 0.136 0.124 0.125 0.128 0.114 0.109 0.110  ||  0.217 0.095 0.001 0.014 0.036 -0.083 -0.124 -0.122    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -0.997 -0.936 -0.984 -0.874 -0.739 -0.549 -0.330 4.751  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.007 0.012 0.961  ||  -1.203 -1.219 -1.058 -0.932 -0.799 -0.405 0.059 4.453  || dis=0.95 || select=7/8
015/019-th : 0.003 0.005 0.003 0.004 0.004 0.006 0.008 0.968  ||  -1.187 -0.669 -0.965 -0.934 -0.737 -0.465 -0.171 4.678  || dis=0.96 || select=7/8
016/019-th : 0.026 0.036 0.037 0.056 0.074 0.165 0.227 0.380  ||  -1.181 -0.865 -0.841 -0.425 -0.145 0.660 0.982 1.495  || dis=0.15 || select=7/8
017/019-th : 0.083 0.091 0.102 0.122 0.127 0.137 0.169 0.169  ||  -0.378 -0.293 -0.174 0.002 0.046 0.123 0.333 0.333    || dis=0.00 || select=6/8
018/019-th : 0.096 0.111 0.129 0.153 0.131 0.111 0.123 0.145  ||  -0.249 -0.104 0.044 0.215 0.061 -0.104 -0.001 0.161   || dis=0.01 || select=3/8
[epoch=563/600] FLOP : 28.37 MB, ratio : 0.6952, Expected-ratio : 0.7000, Discrepancy : 0.320
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:42:50] [epoch=563/600][000/098] Time 0.40 (0.40) Data 0.29 (0.29) Loss 2.531 (2.531)  Prec@1 32.81 (32.81) Prec@5 77.34 (77.34) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:42:56] [epoch=563/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 10.516 (1.569)  Prec@1 5.36 (60.79) Prec@5 51.79 (90.43) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.79 Prec@5 90.43 Error@1 39.21 Error@5 9.57 Loss:1.569
***[2020-01-29 10:42:56]*** VALID [epoch=563/600] loss = 1.568546, accuracy@1 = 60.79, accuracy@5 = 90.43 | Best-Valid-Acc@1=62.85, Error@1=37.15
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:42:56]*** start epoch=564/600 Time Left: [00:19:16], LR=[0.000886 ~ 0.000886], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=564, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1433962357147129, FLOP=40.81
[Search] : epoch=564/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:42:57] [epoch=564/600][000/098] Time 0.65 (0.65) Data 0.34 (0.34) Base-Loss 0.313 (0.313)  Prec@1 89.84 (89.84) Prec@5 100.00 (100.00) Acls-loss 0.803 (0.803) FLOP-Loss 0.000 (0.000) Arch-Loss 0.803 (0.803)
**TRAIN** [2020-01-29 10:43:21] [epoch=564/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.393 (0.402)  Prec@1 86.90 (86.60) Prec@5 100.00 (99.30) Acls-loss 0.501 (0.552) FLOP-Loss 3.011 (0.144) Arch-Loss 6.523 (0.839)
 **TRAIN** Prec@1 86.60 Prec@5 99.30 Error@1 13.40 Error@5 0.70 Base-Loss:0.402, Arch-Loss=0.839
***[2020-01-29 10:43:22]*** TRAIN [epoch=564/600] base-loss = 0.402150, arch-loss = 0.839414, accuracy-1 = 86.60, accuracy-5 = 99.30
[epoch=564/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.348732)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.132 0.607 0.261  ||  -0.5154 1.0104 0.1679  || discrepancy=0.35 || select=1/3
001/003-th : 0.337 0.327 0.336  ||  0.1628 0.1324 0.1619  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.034 0.959  ||  -2.2628 -0.5272 2.7994  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.011 0.014 0.023 0.917  ||  -1.266 -1.060 -0.862 -0.877 -0.727 -0.504 -0.025 3.659  || dis=0.89 || select=7/8
001/019-th : 0.077 0.099 0.126 0.129 0.124 0.136 0.166 0.143  ||  -0.463 -0.217 0.030 0.047 0.011 0.106 0.301 0.153     || dis=0.02 || select=6/8
002/019-th : 0.102 0.109 0.129 0.127 0.130 0.143 0.142 0.118  ||  -0.192 -0.130 0.038 0.027 0.048 0.147 0.136 -0.047    || dis=0.00 || select=5/8
003/019-th : 0.115 0.113 0.119 0.131 0.125 0.137 0.135 0.125  ||  -0.086 -0.099 -0.051 0.049 0.000 0.091 0.079 -0.004   || dis=0.00 || select=5/8
004/019-th : 0.102 0.107 0.107 0.112 0.129 0.131 0.158 0.154  ||  -0.188 -0.142 -0.137 -0.096 0.049 0.062 0.254 0.226   || dis=0.00 || select=6/8
005/019-th : 0.133 0.126 0.126 0.125 0.125 0.124 0.122 0.121  ||  0.063 0.006 0.012 -0.001 -0.002 -0.010 -0.026 -0.035  || dis=0.01 || select=0/8
006/019-th : 0.157 0.141 0.128 0.127 0.128 0.115 0.107 0.097  ||  0.244 0.133 0.034 0.027 0.040 -0.072 -0.146 -0.235    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.031 0.904  ||  -1.439 -1.250 -1.093 -0.819 -0.522 -0.238 0.272 3.633  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.010 0.013 0.017 0.025 0.045 0.878  ||  -1.648 -1.482 -1.064 -0.722 -0.489 -0.092 0.487 3.458  || dis=0.83 || select=7/8
009/019-th : 0.086 0.092 0.092 0.108 0.112 0.137 0.157 0.216  ||  -0.322 -0.252 -0.259 -0.096 -0.062 0.139 0.277 0.595  || dis=0.06 || select=7/8
010/019-th : 0.089 0.099 0.108 0.117 0.126 0.151 0.154 0.156  ||  -0.320 -0.208 -0.120 -0.040 0.032 0.216 0.237 0.246   || dis=0.00 || select=7/8
011/019-th : 0.126 0.115 0.115 0.117 0.129 0.129 0.134 0.134  ||  0.011 -0.084 -0.081 -0.063 0.038 0.035 0.075 0.074    || dis=0.00 || select=6/8
012/019-th : 0.154 0.136 0.125 0.125 0.128 0.113 0.109 0.109  ||  0.218 0.095 0.007 0.012 0.034 -0.088 -0.125 -0.123    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -0.996 -0.935 -0.981 -0.875 -0.736 -0.555 -0.328 4.751  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.007 0.012 0.962  ||  -1.232 -1.211 -1.055 -0.945 -0.797 -0.402 0.058 4.480  || dis=0.95 || select=7/8
015/019-th : 0.003 0.005 0.003 0.004 0.004 0.006 0.008 0.968  ||  -1.184 -0.662 -0.963 -0.931 -0.735 -0.460 -0.170 4.671  || dis=0.96 || select=7/8
016/019-th : 0.026 0.035 0.037 0.056 0.073 0.161 0.227 0.386  ||  -1.189 -0.895 -0.838 -0.418 -0.143 0.644 0.988 1.516  || dis=0.16 || select=7/8
017/019-th : 0.084 0.091 0.102 0.122 0.127 0.136 0.168 0.169  ||  -0.367 -0.293 -0.178 0.008 0.048 0.114 0.327 0.333    || dis=0.00 || select=7/8
018/019-th : 0.096 0.111 0.129 0.155 0.132 0.111 0.123 0.144  ||  -0.251 -0.107 0.045 0.229 0.065 -0.106 -0.002 0.155   || dis=0.01 || select=3/8
[epoch=564/600] FLOP : 21.35 MB, ratio : 0.5231, Expected-ratio : 0.7000, Discrepancy : 0.321
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:43:22] [epoch=564/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.631 (0.631)  Prec@1 78.52 (78.52) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:43:28] [epoch=564/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 0.396 (1.469)  Prec@1 85.71 (62.13) Prec@5 99.40 (90.80) Size=[168, 3, 32, 32]
 **VALID** Prec@1 62.13 Prec@5 90.80 Error@1 37.87 Error@5 9.20 Loss:1.469
***[2020-01-29 10:43:28]*** VALID [epoch=564/600] loss = 1.469136, accuracy@1 = 62.13, accuracy@5 = 90.80 | Best-Valid-Acc@1=62.85, Error@1=37.15
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:43:28]*** start epoch=565/600 Time Left: [00:18:44], LR=[0.000837 ~ 0.000837], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=565, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.14102547646831148, FLOP=40.81
[Search] : epoch=565/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:43:29] [epoch=565/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.420 (0.420)  Prec@1 86.72 (86.72) Prec@5 99.22 (99.22) Acls-loss 0.485 (0.485) FLOP-Loss -3.011 (-3.011) Arch-Loss -5.536 (-5.536)
**TRAIN** [2020-01-29 10:43:53] [epoch=565/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.251 (0.353)  Prec@1 91.07 (88.15) Prec@5 99.40 (99.58) Acls-loss 0.558 (0.557) FLOP-Loss 3.012 (0.051) Arch-Loss 6.581 (0.659)
 **TRAIN** Prec@1 88.15 Prec@5 99.58 Error@1 11.85 Error@5 0.42 Base-Loss:0.353, Arch-Loss=0.659
***[2020-01-29 10:43:53]*** TRAIN [epoch=565/600] base-loss = 0.352841, arch-loss = 0.659290, accuracy-1 = 88.15, accuracy-5 = 99.58
[epoch=565/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 32, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.827964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.132 0.606 0.262  ||  -0.5185 1.0071 0.1697  || discrepancy=0.34 || select=1/3
001/003-th : 0.337 0.327 0.337  ||  0.1624 0.1316 0.1617  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.035 0.959  ||  -2.2568 -0.5226 2.7925  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.011 0.014 0.023 0.917  ||  -1.253 -1.055 -0.890 -0.873 -0.722 -0.501 -0.031 3.666  || dis=0.89 || select=7/8
001/019-th : 0.077 0.099 0.127 0.127 0.126 0.136 0.165 0.142  ||  -0.463 -0.211 0.034 0.039 0.024 0.103 0.298 0.150     || dis=0.02 || select=6/8
002/019-th : 0.102 0.108 0.128 0.127 0.130 0.144 0.143 0.118  ||  -0.190 -0.139 0.033 0.023 0.050 0.148 0.144 -0.048    || dis=0.00 || select=5/8
003/019-th : 0.113 0.113 0.120 0.131 0.126 0.136 0.136 0.124  ||  -0.097 -0.095 -0.041 0.050 0.011 0.086 0.086 -0.008   || dis=0.00 || select=6/8
004/019-th : 0.102 0.107 0.107 0.112 0.127 0.132 0.159 0.154  ||  -0.185 -0.142 -0.136 -0.092 0.035 0.070 0.255 0.223   || dis=0.01 || select=6/8
005/019-th : 0.133 0.125 0.123 0.125 0.128 0.124 0.121 0.122  ||  0.063 0.005 -0.015 -0.002 0.022 -0.011 -0.034 -0.024  || dis=0.01 || select=0/8
006/019-th : 0.158 0.141 0.123 0.128 0.126 0.116 0.109 0.098  ||  0.248 0.132 -0.002 0.036 0.020 -0.063 -0.122 -0.233   || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.031 0.905  ||  -1.435 -1.259 -1.089 -0.815 -0.522 -0.237 0.262 3.638  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.010 0.013 0.017 0.025 0.045 0.879  ||  -1.641 -1.476 -1.059 -0.739 -0.487 -0.108 0.487 3.461  || dis=0.83 || select=7/8
009/019-th : 0.087 0.091 0.092 0.108 0.112 0.137 0.157 0.216  ||  -0.317 -0.264 -0.258 -0.099 -0.059 0.140 0.278 0.594  || dis=0.06 || select=7/8
010/019-th : 0.089 0.099 0.106 0.120 0.127 0.152 0.152 0.155  ||  -0.315 -0.209 -0.138 -0.015 0.040 0.219 0.224 0.244   || dis=0.00 || select=7/8
011/019-th : 0.124 0.115 0.115 0.117 0.131 0.130 0.135 0.134  ||  -0.003 -0.084 -0.077 -0.064 0.052 0.039 0.076 0.070   || dis=0.00 || select=6/8
012/019-th : 0.154 0.135 0.124 0.125 0.129 0.114 0.109 0.109  ||  0.217 0.090 0.005 0.009 0.040 -0.079 -0.124 -0.124    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -0.992 -0.928 -0.977 -0.872 -0.734 -0.552 -0.327 4.744  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.007 0.011 0.963  ||  -1.230 -1.204 -1.052 -0.947 -0.794 -0.451 0.049 4.499  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.004 0.004 0.006 0.007 0.969  ||  -1.180 -0.703 -0.960 -0.928 -0.732 -0.453 -0.192 4.687  || dis=0.96 || select=7/8
016/019-th : 0.026 0.034 0.036 0.056 0.074 0.161 0.224 0.389  ||  -1.197 -0.898 -0.844 -0.413 -0.134 0.646 0.974 1.528  || dis=0.17 || select=7/8
017/019-th : 0.084 0.091 0.102 0.119 0.130 0.135 0.169 0.170  ||  -0.371 -0.289 -0.177 -0.017 0.065 0.108 0.331 0.338   || dis=0.00 || select=7/8
018/019-th : 0.097 0.110 0.128 0.152 0.131 0.113 0.124 0.145  ||  -0.244 -0.115 0.036 0.209 0.062 -0.089 0.003 0.161    || dis=0.01 || select=3/8
[epoch=565/600] FLOP : 21.83 MB, ratio : 0.5348, Expected-ratio : 0.7000, Discrepancy : 0.321
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:43:54] [epoch=565/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 3.373 (3.373)  Prec@1 31.25 (31.25) Prec@5 75.00 (75.00) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:44:00] [epoch=565/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.616 (1.393)  Prec@1 80.95 (64.80) Prec@5 99.40 (92.14) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.80 Prec@5 92.14 Error@1 35.20 Error@5 7.86 Loss:1.393
***[2020-01-29 10:44:00]*** VALID [epoch=565/600] loss = 1.393426, accuracy@1 = 64.80, accuracy@5 = 92.14 | Best-Valid-Acc@1=62.85, Error@1=37.15
Currently, the best validation accuracy found at 565-epoch :: acc@1=64.80, acc@5=92.14, error@1=35.20, error@5=7.86, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:44:00]*** start epoch=566/600 Time Left: [00:18:11], LR=[0.000790 ~ 0.000790], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=566, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1387207604753574, FLOP=40.81
[Search] : epoch=566/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:44:01] [epoch=566/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.309 (0.309)  Prec@1 89.06 (89.06) Prec@5 99.61 (99.61) Acls-loss 0.476 (0.476) FLOP-Loss -3.012 (-3.012) Arch-Loss -5.547 (-5.547)
**TRAIN** [2020-01-29 10:44:26] [epoch=566/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.358 (0.327)  Prec@1 86.90 (88.89) Prec@5 99.40 (99.59) Acls-loss 0.592 (0.543) FLOP-Loss 3.012 (0.051) Arch-Loss 6.617 (0.646)
 **TRAIN** Prec@1 88.89 Prec@5 99.59 Error@1 11.11 Error@5 0.41 Base-Loss:0.327, Arch-Loss=0.646
***[2020-01-29 10:44:26]*** TRAIN [epoch=566/600] base-loss = 0.327439, arch-loss = 0.645819, accuracy-1 = 88.89, accuracy-5 = 99.59
[epoch=566/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.932476)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.130 0.610 0.260  ||  -0.5274 1.0212 0.1688  || discrepancy=0.35 || select=1/3
001/003-th : 0.337 0.325 0.338  ||  0.1618 0.1258 0.1627  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.035 0.958  ||  -2.2504 -0.5137 2.7841  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.011 0.014 0.023 0.918  ||  -1.271 -1.058 -0.885 -0.865 -0.716 -0.502 -0.031 3.677  || dis=0.90 || select=7/8
001/019-th : 0.077 0.098 0.128 0.125 0.126 0.135 0.167 0.144  ||  -0.463 -0.228 0.041 0.019 0.030 0.098 0.310 0.158     || dis=0.02 || select=6/8
002/019-th : 0.102 0.108 0.129 0.127 0.131 0.143 0.143 0.117  ||  -0.191 -0.141 0.043 0.024 0.054 0.146 0.145 -0.053    || dis=0.00 || select=5/8
003/019-th : 0.114 0.112 0.120 0.132 0.126 0.134 0.137 0.125  ||  -0.095 -0.109 -0.038 0.052 0.010 0.072 0.094 -0.001   || dis=0.00 || select=6/8
004/019-th : 0.103 0.107 0.107 0.113 0.128 0.132 0.158 0.153  ||  -0.180 -0.143 -0.137 -0.088 0.038 0.069 0.250 0.220   || dis=0.01 || select=6/8
005/019-th : 0.134 0.125 0.121 0.125 0.129 0.124 0.121 0.121  ||  0.069 0.005 -0.029 0.002 0.033 -0.009 -0.027 -0.030   || dis=0.01 || select=0/8
006/019-th : 0.158 0.141 0.124 0.128 0.126 0.116 0.109 0.098  ||  0.248 0.133 0.002 0.037 0.021 -0.064 -0.128 -0.232    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.014 0.019 0.031 0.906  ||  -1.430 -1.255 -1.086 -0.818 -0.544 -0.243 0.264 3.642  || dis=0.88 || select=7/8
008/019-th : 0.005 0.006 0.009 0.013 0.017 0.025 0.044 0.881  ||  -1.636 -1.480 -1.066 -0.745 -0.487 -0.105 0.467 3.475  || dis=0.84 || select=7/8
009/019-th : 0.086 0.092 0.092 0.108 0.112 0.135 0.157 0.217  ||  -0.322 -0.263 -0.258 -0.101 -0.060 0.127 0.279 0.601  || dis=0.06 || select=7/8
010/019-th : 0.088 0.097 0.107 0.116 0.128 0.153 0.156 0.154  ||  -0.319 -0.220 -0.129 -0.044 0.049 0.230 0.253 0.239   || dis=0.00 || select=6/8
011/019-th : 0.125 0.115 0.116 0.117 0.130 0.129 0.135 0.134  ||  0.003 -0.083 -0.073 -0.061 0.040 0.033 0.077 0.070    || dis=0.00 || select=6/8
012/019-th : 0.154 0.136 0.124 0.125 0.128 0.115 0.109 0.109  ||  0.216 0.097 -0.000 0.008 0.036 -0.077 -0.123 -0.125   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -0.988 -0.921 -0.974 -0.870 -0.731 -0.550 -0.326 4.736  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.007 0.011 0.963  ||  -1.228 -1.196 -1.049 -0.954 -0.791 -0.453 0.038 4.505  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.006 0.007 0.969  ||  -1.176 -0.700 -0.957 -0.947 -0.730 -0.449 -0.202 4.697  || dis=0.96 || select=7/8
016/019-th : 0.025 0.034 0.036 0.057 0.074 0.160 0.223 0.391  ||  -1.203 -0.897 -0.844 -0.398 -0.138 0.639 0.971 1.534  || dis=0.17 || select=7/8
017/019-th : 0.084 0.091 0.101 0.119 0.132 0.135 0.169 0.170  ||  -0.371 -0.289 -0.186 -0.023 0.085 0.106 0.332 0.336   || dis=0.00 || select=7/8
018/019-th : 0.096 0.109 0.128 0.152 0.133 0.112 0.124 0.146  ||  -0.250 -0.121 0.038 0.207 0.071 -0.096 0.004 0.168    || dis=0.01 || select=3/8
[epoch=566/600] FLOP : 28.93 MB, ratio : 0.7089, Expected-ratio : 0.7000, Discrepancy : 0.321
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:44:26] [epoch=566/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 3.910 (3.910)  Prec@1 30.47 (30.47) Prec@5 85.55 (85.55) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:44:32] [epoch=566/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.709 (1.785)  Prec@1 34.52 (57.53) Prec@5 82.74 (88.26) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.53 Prec@5 88.26 Error@1 42.47 Error@5 11.74 Loss:1.785
***[2020-01-29 10:44:32]*** VALID [epoch=566/600] loss = 1.785290, accuracy@1 = 57.53, accuracy@5 = 88.26 | Best-Valid-Acc@1=64.80, Error@1=35.20
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:44:32]*** start epoch=567/600 Time Left: [00:17:39], LR=[0.000745 ~ 0.000745], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=567, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.13648215092080404, FLOP=40.81
[Search] : epoch=567/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:44:33] [epoch=567/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.497 (0.497)  Prec@1 83.59 (83.59) Prec@5 99.22 (99.22) Acls-loss 0.457 (0.457) FLOP-Loss 3.012 (3.012) Arch-Loss 6.481 (6.481)
**TRAIN** [2020-01-29 10:44:57] [epoch=567/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.512 (0.361)  Prec@1 85.12 (87.88) Prec@5 100.00 (99.61) Acls-loss 1.323 (0.549) FLOP-Loss -3.013 (0.072) Arch-Loss -4.702 (0.693)
 **TRAIN** Prec@1 87.88 Prec@5 99.61 Error@1 12.12 Error@5 0.39 Base-Loss:0.361, Arch-Loss=0.693
***[2020-01-29 10:44:57]*** TRAIN [epoch=567/600] base-loss = 0.360662, arch-loss = 0.693284, accuracy-1 = 87.88, accuracy-5 = 99.61
[epoch=567/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.932476)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.131 0.610 0.260  ||  -0.5235 1.0176 0.1656  || discrepancy=0.35 || select=1/3
001/003-th : 0.337 0.326 0.337  ||  0.1617 0.1285 0.1617  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.035 0.959  ||  -2.2487 -0.5229 2.7849  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.011 0.014 0.022 0.918  ||  -1.264 -1.053 -0.880 -0.868 -0.707 -0.503 -0.040 3.673  || dis=0.90 || select=7/8
001/019-th : 0.077 0.096 0.129 0.125 0.126 0.136 0.168 0.143  ||  -0.463 -0.246 0.050 0.021 0.026 0.108 0.314 0.158     || dis=0.03 || select=6/8
002/019-th : 0.103 0.108 0.129 0.126 0.131 0.143 0.142 0.118  ||  -0.187 -0.140 0.043 0.021 0.058 0.143 0.140 -0.052    || dis=0.00 || select=5/8
003/019-th : 0.114 0.112 0.120 0.132 0.127 0.134 0.137 0.124  ||  -0.093 -0.111 -0.036 0.052 0.021 0.069 0.091 -0.003   || dis=0.00 || select=6/8
004/019-th : 0.102 0.107 0.107 0.110 0.128 0.133 0.160 0.154  ||  -0.188 -0.140 -0.136 -0.112 0.039 0.080 0.261 0.224   || dis=0.01 || select=6/8
005/019-th : 0.133 0.125 0.121 0.125 0.129 0.124 0.121 0.121  ||  0.067 0.006 -0.027 0.000 0.034 -0.005 -0.028 -0.031   || dis=0.00 || select=0/8
006/019-th : 0.158 0.141 0.124 0.128 0.126 0.117 0.109 0.098  ||  0.245 0.135 0.002 0.036 0.018 -0.057 -0.129 -0.230    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.014 0.019 0.031 0.906  ||  -1.430 -1.250 -1.085 -0.829 -0.528 -0.242 0.262 3.642  || dis=0.88 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.017 0.024 0.043 0.883  ||  -1.628 -1.474 -1.061 -0.779 -0.485 -0.114 0.459 3.488  || dis=0.84 || select=7/8
009/019-th : 0.085 0.091 0.092 0.107 0.113 0.136 0.159 0.218  ||  -0.334 -0.269 -0.260 -0.107 -0.054 0.129 0.287 0.602  || dis=0.06 || select=7/8
010/019-th : 0.088 0.097 0.107 0.115 0.128 0.153 0.156 0.156  ||  -0.318 -0.226 -0.127 -0.050 0.051 0.234 0.250 0.249   || dis=0.00 || select=6/8
011/019-th : 0.125 0.116 0.116 0.118 0.129 0.128 0.135 0.133  ||  0.003 -0.075 -0.071 -0.057 0.036 0.025 0.077 0.068    || dis=0.00 || select=6/8
012/019-th : 0.154 0.137 0.125 0.123 0.128 0.115 0.109 0.110  ||  0.217 0.098 0.004 -0.012 0.032 -0.078 -0.124 -0.121   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -0.983 -0.914 -0.978 -0.867 -0.728 -0.547 -0.338 4.738  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.004 0.004 0.005 0.007 0.011 0.964  ||  -1.225 -1.187 -1.066 -0.952 -0.785 -0.468 0.022 4.522  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.969  ||  -1.172 -0.695 -0.954 -0.944 -0.727 -0.477 -0.216 4.709  || dis=0.96 || select=7/8
016/019-th : 0.025 0.034 0.035 0.054 0.073 0.163 0.224 0.392  ||  -1.214 -0.897 -0.867 -0.428 -0.140 0.671 0.985 1.545  || dis=0.17 || select=7/8
017/019-th : 0.084 0.091 0.101 0.117 0.132 0.136 0.170 0.170  ||  -0.365 -0.289 -0.189 -0.038 0.080 0.111 0.336 0.338   || dis=0.00 || select=7/8
018/019-th : 0.097 0.109 0.128 0.152 0.131 0.112 0.123 0.147  ||  -0.242 -0.122 0.036 0.210 0.062 -0.099 -0.003 0.172   || dis=0.01 || select=3/8
[epoch=567/600] FLOP : 28.93 MB, ratio : 0.7089, Expected-ratio : 0.7000, Discrepancy : 0.322
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:44:58] [epoch=567/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.901 (0.901)  Prec@1 70.70 (70.70) Prec@5 95.70 (95.70) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:45:04] [epoch=567/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.214 (1.353)  Prec@1 20.83 (64.77) Prec@5 67.26 (92.95) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.77 Prec@5 92.95 Error@1 35.23 Error@5 7.05 Loss:1.353
***[2020-01-29 10:45:04]*** VALID [epoch=567/600] loss = 1.352659, accuracy@1 = 64.77, accuracy@5 = 92.95 | Best-Valid-Acc@1=64.80, Error@1=35.20
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:45:04]*** start epoch=568/600 Time Left: [00:17:07], LR=[0.000700 ~ 0.000700], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=568, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.13430970917726306, FLOP=40.81
[Search] : epoch=568/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:45:05] [epoch=568/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 1.005 (1.005)  Prec@1 71.48 (71.48) Prec@5 97.27 (97.27) Acls-loss 0.490 (0.490) FLOP-Loss 3.013 (3.013) Arch-Loss 6.516 (6.516)
**TRAIN** [2020-01-29 10:45:30] [epoch=568/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.251 (0.392)  Prec@1 91.67 (86.79) Prec@5 100.00 (99.40) Acls-loss 0.396 (0.546) FLOP-Loss 3.013 (0.175) Arch-Loss 6.422 (0.895)
 **TRAIN** Prec@1 86.79 Prec@5 99.40 Error@1 13.21 Error@5 0.60 Base-Loss:0.392, Arch-Loss=0.895
***[2020-01-29 10:45:30]*** TRAIN [epoch=568/600] base-loss = 0.391990, arch-loss = 0.894800, accuracy-1 = 86.79, accuracy-5 = 99.40
[epoch=568/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.827964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.129 0.613 0.258  ||  -0.5290 1.0289 0.1631  || discrepancy=0.35 || select=1/3
001/003-th : 0.336 0.328 0.336  ||  0.1610 0.1351 0.1605  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.035 0.959  ||  -2.2543 -0.5239 2.7906  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.010 0.010 0.011 0.014 0.022 0.919  ||  -1.270 -1.056 -0.874 -0.859 -0.714 -0.500 -0.065 3.688  || dis=0.90 || select=7/8
001/019-th : 0.078 0.096 0.130 0.125 0.124 0.136 0.168 0.143  ||  -0.457 -0.248 0.061 0.021 0.009 0.108 0.318 0.154     || dis=0.03 || select=6/8
002/019-th : 0.103 0.107 0.130 0.128 0.130 0.143 0.142 0.118  ||  -0.186 -0.146 0.046 0.031 0.046 0.143 0.135 -0.046    || dis=0.00 || select=5/8
003/019-th : 0.113 0.111 0.121 0.132 0.128 0.134 0.136 0.125  ||  -0.102 -0.115 -0.028 0.059 0.030 0.072 0.085 0.000    || dis=0.00 || select=6/8
004/019-th : 0.101 0.106 0.108 0.106 0.132 0.133 0.160 0.155  ||  -0.192 -0.148 -0.130 -0.146 0.072 0.079 0.266 0.233   || dis=0.01 || select=6/8
005/019-th : 0.135 0.125 0.122 0.124 0.129 0.122 0.122 0.121  ||  0.077 0.005 -0.023 -0.010 0.036 -0.027 -0.022 -0.034  || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.123 0.129 0.127 0.117 0.108 0.098  ||  0.240 0.138 -0.001 0.041 0.026 -0.055 -0.131 -0.230   || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.014 0.019 0.031 0.905  ||  -1.425 -1.246 -1.083 -0.825 -0.528 -0.245 0.260 3.638  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.016 0.024 0.041 0.886  ||  -1.621 -1.469 -1.054 -0.775 -0.502 -0.119 0.431 3.498  || dis=0.84 || select=7/8
009/019-th : 0.086 0.091 0.092 0.107 0.113 0.135 0.158 0.217  ||  -0.332 -0.267 -0.258 -0.108 -0.049 0.125 0.284 0.601  || dis=0.06 || select=7/8
010/019-th : 0.089 0.096 0.107 0.116 0.129 0.153 0.156 0.154  ||  -0.310 -0.230 -0.126 -0.049 0.064 0.233 0.248 0.237   || dis=0.00 || select=6/8
011/019-th : 0.127 0.116 0.117 0.118 0.129 0.127 0.134 0.133  ||  0.015 -0.073 -0.065 -0.052 0.030 0.014 0.072 0.063    || dis=0.00 || select=6/8
012/019-th : 0.154 0.137 0.125 0.123 0.127 0.114 0.109 0.110  ||  0.219 0.100 0.007 -0.007 0.026 -0.080 -0.125 -0.124   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -0.978 -0.908 -0.974 -0.864 -0.723 -0.544 -0.337 4.729  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.965  ||  -1.223 -1.178 -1.098 -0.949 -0.782 -0.468 0.012 4.542  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.969  ||  -1.171 -0.691 -0.951 -0.942 -0.724 -0.475 -0.218 4.704  || dis=0.96 || select=7/8
016/019-th : 0.025 0.034 0.036 0.054 0.072 0.164 0.221 0.394  ||  -1.207 -0.893 -0.857 -0.441 -0.147 0.674 0.970 1.549  || dis=0.17 || select=7/8
017/019-th : 0.084 0.091 0.100 0.117 0.131 0.137 0.169 0.171  ||  -0.365 -0.286 -0.196 -0.041 0.079 0.123 0.329 0.340   || dis=0.00 || select=7/8
018/019-th : 0.097 0.109 0.130 0.150 0.132 0.111 0.123 0.147  ||  -0.237 -0.123 0.049 0.197 0.065 -0.105 -0.002 0.172   || dis=0.00 || select=3/8
[epoch=568/600] FLOP : 21.83 MB, ratio : 0.5348, Expected-ratio : 0.7000, Discrepancy : 0.322
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:45:30] [epoch=568/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.031 (1.031)  Prec@1 69.14 (69.14) Prec@5 96.09 (96.09) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:45:36] [epoch=568/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 0.556 (1.422)  Prec@1 82.74 (64.93) Prec@5 99.40 (93.03) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.93 Prec@5 93.03 Error@1 35.07 Error@5 6.97 Loss:1.422
***[2020-01-29 10:45:36]*** VALID [epoch=568/600] loss = 1.422099, accuracy@1 = 64.93, accuracy@5 = 93.03 | Best-Valid-Acc@1=64.80, Error@1=35.20
Currently, the best validation accuracy found at 568-epoch :: acc@1=64.93, acc@5=93.03, error@1=35.07, error@5=6.97, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:45:37]*** start epoch=569/600 Time Left: [00:16:35], LR=[0.000657 ~ 0.000657], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=569, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.13220349480332225, FLOP=40.81
[Search] : epoch=569/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:45:37] [epoch=569/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.351 (0.351)  Prec@1 89.84 (89.84) Prec@5 99.61 (99.61) Acls-loss 0.484 (0.484) FLOP-Loss -3.013 (-3.013) Arch-Loss -5.541 (-5.541)
**TRAIN** [2020-01-29 10:46:02] [epoch=569/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.189 (0.366)  Prec@1 93.45 (87.91) Prec@5 100.00 (99.58) Acls-loss 0.358 (0.544) FLOP-Loss -3.013 (0.072) Arch-Loss -5.668 (0.689)
 **TRAIN** Prec@1 87.91 Prec@5 99.58 Error@1 12.09 Error@5 0.42 Base-Loss:0.366, Arch-Loss=0.689
***[2020-01-29 10:46:02]*** TRAIN [epoch=569/600] base-loss = 0.366380, arch-loss = 0.689013, accuracy-1 = 87.91, accuracy-5 = 99.58
[epoch=569/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.932476)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.129 0.611 0.260  ||  -0.5330 1.0230 0.1670  || discrepancy=0.35 || select=1/3
001/003-th : 0.336 0.328 0.336  ||  0.1603 0.1359 0.1605  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.035 0.958  ||  -2.2475 -0.5158 2.7817  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.010 0.010 0.011 0.014 0.021 0.921  ||  -1.271 -1.049 -0.868 -0.866 -0.709 -0.496 -0.092 3.705  || dis=0.90 || select=7/8
001/019-th : 0.078 0.096 0.130 0.124 0.124 0.138 0.167 0.143  ||  -0.453 -0.246 0.057 0.014 0.015 0.118 0.312 0.152     || dis=0.02 || select=6/8
002/019-th : 0.103 0.107 0.129 0.128 0.128 0.143 0.142 0.120  ||  -0.187 -0.147 0.038 0.030 0.031 0.143 0.131 -0.030    || dis=0.00 || select=5/8
003/019-th : 0.113 0.112 0.121 0.132 0.127 0.133 0.135 0.125  ||  -0.099 -0.108 -0.027 0.058 0.018 0.067 0.081 0.004    || dis=0.00 || select=6/8
004/019-th : 0.102 0.105 0.108 0.106 0.132 0.133 0.160 0.154  ||  -0.184 -0.152 -0.126 -0.149 0.071 0.079 0.267 0.229   || dis=0.01 || select=6/8
005/019-th : 0.135 0.126 0.122 0.124 0.130 0.122 0.122 0.120  ||  0.077 0.008 -0.024 -0.004 0.038 -0.024 -0.024 -0.039  || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.123 0.128 0.127 0.116 0.108 0.098  ||  0.243 0.141 -0.001 0.038 0.027 -0.059 -0.135 -0.229   || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.031 0.904  ||  -1.419 -1.216 -1.079 -0.822 -0.525 -0.244 0.248 3.618  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.016 0.023 0.041 0.886  ||  -1.613 -1.462 -1.055 -0.770 -0.505 -0.133 0.427 3.500  || dis=0.84 || select=7/8
009/019-th : 0.084 0.092 0.092 0.110 0.114 0.133 0.159 0.216  ||  -0.349 -0.258 -0.260 -0.081 -0.049 0.110 0.285 0.595  || dis=0.06 || select=7/8
010/019-th : 0.090 0.097 0.108 0.116 0.128 0.153 0.155 0.153  ||  -0.304 -0.223 -0.120 -0.049 0.053 0.232 0.245 0.233   || dis=0.00 || select=6/8
011/019-th : 0.126 0.116 0.112 0.119 0.132 0.128 0.134 0.134  ||  0.010 -0.070 -0.112 -0.050 0.055 0.023 0.074 0.070    || dis=0.00 || select=6/8
012/019-th : 0.154 0.136 0.125 0.124 0.127 0.115 0.110 0.110  ||  0.218 0.095 0.007 -0.002 0.021 -0.076 -0.122 -0.122   || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.971  ||  -0.973 -0.900 -0.970 -0.880 -0.720 -0.541 -0.335 4.732  || dis=0.96 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.965  ||  -1.221 -1.168 -1.096 -0.947 -0.779 -0.466 0.012 4.537  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.969  ||  -1.172 -0.687 -0.948 -0.935 -0.721 -0.473 -0.222 4.700  || dis=0.96 || select=7/8
016/019-th : 0.025 0.034 0.036 0.053 0.071 0.162 0.221 0.399  ||  -1.213 -0.906 -0.851 -0.451 -0.157 0.663 0.978 1.567  || dis=0.18 || select=7/8
017/019-th : 0.084 0.092 0.099 0.117 0.131 0.136 0.170 0.171  ||  -0.368 -0.273 -0.201 -0.038 0.074 0.112 0.334 0.339   || dis=0.00 || select=7/8
018/019-th : 0.098 0.110 0.128 0.151 0.132 0.111 0.124 0.147  ||  -0.232 -0.121 0.038 0.201 0.062 -0.111 0.002 0.170    || dis=0.00 || select=3/8
[epoch=569/600] FLOP : 28.93 MB, ratio : 0.7089, Expected-ratio : 0.7000, Discrepancy : 0.322
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:46:03] [epoch=569/600][000/098] Time 0.38 (0.38) Data 0.30 (0.30) Loss 0.719 (0.719)  Prec@1 76.17 (76.17) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:46:09] [epoch=569/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 3.681 (1.460)  Prec@1 27.38 (62.38) Prec@5 68.45 (91.92) Size=[168, 3, 32, 32]
 **VALID** Prec@1 62.38 Prec@5 91.92 Error@1 37.62 Error@5 8.08 Loss:1.460
***[2020-01-29 10:46:09]*** VALID [epoch=569/600] loss = 1.460278, accuracy@1 = 62.38, accuracy@5 = 91.92 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:46:09]*** start epoch=570/600 Time Left: [00:16:03], LR=[0.000616 ~ 0.000616], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=570, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.13016356554191275, FLOP=40.81
[Search] : epoch=570/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:46:10] [epoch=570/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.263 (0.263)  Prec@1 90.23 (90.23) Prec@5 100.00 (100.00) Acls-loss 0.411 (0.411) FLOP-Loss 3.013 (3.013) Arch-Loss 6.437 (6.437)
**TRAIN** [2020-01-29 10:46:35] [epoch=570/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.569 (0.374)  Prec@1 81.55 (87.47) Prec@5 98.21 (99.41) Acls-loss 0.768 (0.567) FLOP-Loss 3.014 (0.051) Arch-Loss 6.795 (0.670)
 **TRAIN** Prec@1 87.47 Prec@5 99.41 Error@1 12.53 Error@5 0.59 Base-Loss:0.374, Arch-Loss=0.670
***[2020-01-29 10:46:35]*** TRAIN [epoch=570/600] base-loss = 0.373992, arch-loss = 0.669854, accuracy-1 = 87.47, accuracy-5 = 99.41
[epoch=570/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 28, 28, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.932476)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.128 0.614 0.258  ||  -0.5393 1.0321 0.1660  || discrepancy=0.36 || select=1/3
001/003-th : 0.336 0.327 0.337  ||  0.1592 0.1295 0.1615  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.035 0.958  ||  -2.2404 -0.5237 2.7777  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.010 0.010 0.011 0.014 0.021 0.921  ||  -1.264 -1.043 -0.862 -0.862 -0.704 -0.493 -0.100 3.703  || dis=0.90 || select=7/8
001/019-th : 0.078 0.096 0.130 0.122 0.126 0.138 0.167 0.145  ||  -0.455 -0.250 0.055 -0.009 0.026 0.119 0.306 0.167    || dis=0.02 || select=6/8
002/019-th : 0.101 0.107 0.128 0.128 0.128 0.146 0.141 0.122  ||  -0.201 -0.151 0.028 0.030 0.032 0.160 0.131 -0.018    || dis=0.01 || select=5/8
003/019-th : 0.114 0.112 0.121 0.132 0.128 0.133 0.136 0.125  ||  -0.092 -0.108 -0.035 0.056 0.024 0.062 0.083 0.001    || dis=0.00 || select=6/8
004/019-th : 0.102 0.106 0.109 0.106 0.132 0.132 0.159 0.154  ||  -0.183 -0.149 -0.118 -0.146 0.071 0.076 0.261 0.226   || dis=0.01 || select=6/8
005/019-th : 0.134 0.123 0.121 0.125 0.129 0.122 0.124 0.121  ||  0.072 -0.014 -0.032 -0.002 0.036 -0.018 -0.003 -0.028  || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.123 0.128 0.128 0.118 0.106 0.098  ||  0.242 0.140 -0.001 0.037 0.038 -0.046 -0.149 -0.226   || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.019 0.031 0.905  ||  -1.420 -1.212 -1.075 -0.819 -0.521 -0.263 0.236 3.626  || dis=0.87 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.016 0.022 0.040 0.889  ||  -1.605 -1.483 -1.064 -0.766 -0.513 -0.159 0.435 3.527  || dis=0.85 || select=7/8
009/019-th : 0.084 0.093 0.092 0.110 0.114 0.132 0.159 0.216  ||  -0.346 -0.252 -0.262 -0.082 -0.048 0.103 0.285 0.592  || dis=0.06 || select=7/8
010/019-th : 0.089 0.098 0.108 0.116 0.129 0.152 0.156 0.153  ||  -0.309 -0.219 -0.121 -0.044 0.056 0.220 0.248 0.231   || dis=0.00 || select=6/8
011/019-th : 0.126 0.116 0.111 0.119 0.132 0.128 0.134 0.134  ||  0.012 -0.071 -0.111 -0.046 0.055 0.027 0.071 0.070    || dis=0.00 || select=6/8
012/019-th : 0.154 0.136 0.126 0.124 0.125 0.115 0.110 0.110  ||  0.216 0.093 0.018 0.004 0.006 -0.073 -0.121 -0.121    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.006 0.972  ||  -0.967 -0.911 -0.966 -0.877 -0.716 -0.569 -0.333 4.739  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.007 0.010 0.964  ||  -1.218 -1.159 -1.094 -0.946 -0.775 -0.465 0.011 4.533  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.006 0.007 0.969  ||  -1.170 -0.683 -0.945 -0.932 -0.718 -0.472 -0.221 4.694  || dis=0.96 || select=7/8
016/019-th : 0.025 0.034 0.035 0.053 0.071 0.161 0.223 0.399  ||  -1.211 -0.900 -0.865 -0.454 -0.161 0.665 0.987 1.569  || dis=0.18 || select=7/8
017/019-th : 0.084 0.093 0.099 0.117 0.130 0.138 0.169 0.170  ||  -0.366 -0.271 -0.203 -0.038 0.068 0.128 0.327 0.335   || dis=0.00 || select=7/8
018/019-th : 0.100 0.109 0.128 0.150 0.132 0.112 0.124 0.146  ||  -0.218 -0.128 0.034 0.195 0.061 -0.104 -0.000 0.169   || dis=0.00 || select=3/8
[epoch=570/600] FLOP : 28.93 MB, ratio : 0.7089, Expected-ratio : 0.7000, Discrepancy : 0.323
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:46:35] [epoch=570/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.044 (1.044)  Prec@1 72.27 (72.27) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:46:41] [epoch=570/600][097/098] Time 0.05 (0.06) Data 0.00 (0.00) Loss 0.747 (1.542)  Prec@1 76.79 (64.16) Prec@5 98.81 (91.70) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.16 Prec@5 91.70 Error@1 35.84 Error@5 8.30 Loss:1.542
***[2020-01-29 10:46:41]*** VALID [epoch=570/600] loss = 1.542129, accuracy@1 = 64.16, accuracy@5 = 91.70 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:46:41]*** start epoch=571/600 Time Left: [00:15:31], LR=[0.000575 ~ 0.000575], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=571, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1281899773187253, FLOP=40.81
[Search] : epoch=571/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:46:42] [epoch=571/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.250 (0.250)  Prec@1 91.80 (91.80) Prec@5 100.00 (100.00) Acls-loss 0.526 (0.526) FLOP-Loss 3.014 (3.014) Arch-Loss 6.554 (6.554)
**TRAIN** [2020-01-29 10:47:07] [epoch=571/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.285 (0.434)  Prec@1 89.88 (85.58) Prec@5 99.40 (99.29) Acls-loss 0.366 (0.549) FLOP-Loss -3.013 (0.072) Arch-Loss -5.661 (0.693)
 **TRAIN** Prec@1 85.58 Prec@5 99.29 Error@1 14.42 Error@5 0.71 Base-Loss:0.434, Arch-Loss=0.693
***[2020-01-29 10:47:07]*** TRAIN [epoch=571/600] base-loss = 0.434228, arch-loss = 0.693455, accuracy-1 = 85.58, accuracy-5 = 99.29
[epoch=571/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 28, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.273468)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.127 0.617 0.256  ||  -0.5425 1.0411 0.1628  || discrepancy=0.36 || select=1/3
001/003-th : 0.336 0.328 0.336  ||  0.1592 0.1335 0.1598  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.035 0.958  ||  -2.2329 -0.5281 2.7725  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.010 0.010 0.011 0.014 0.021 0.920  ||  -1.257 -1.036 -0.856 -0.864 -0.699 -0.490 -0.101 3.698  || dis=0.90 || select=7/8
001/019-th : 0.078 0.095 0.130 0.122 0.125 0.139 0.166 0.144  ||  -0.455 -0.250 0.062 -0.004 0.018 0.125 0.306 0.162    || dis=0.02 || select=6/8
002/019-th : 0.101 0.107 0.127 0.126 0.128 0.147 0.142 0.121  ||  -0.202 -0.147 0.027 0.018 0.030 0.169 0.135 -0.022    || dis=0.01 || select=5/8
003/019-th : 0.113 0.112 0.120 0.130 0.130 0.134 0.136 0.125  ||  -0.098 -0.104 -0.043 0.038 0.038 0.070 0.089 0.002    || dis=0.00 || select=6/8
004/019-th : 0.101 0.105 0.109 0.106 0.132 0.132 0.160 0.154  ||  -0.191 -0.159 -0.116 -0.143 0.076 0.074 0.266 0.229   || dis=0.01 || select=6/8
005/019-th : 0.134 0.122 0.121 0.125 0.129 0.123 0.124 0.122  ||  0.070 -0.018 -0.031 -0.000 0.030 -0.011 -0.006 -0.023  || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.124 0.128 0.127 0.118 0.106 0.098  ||  0.244 0.141 0.007 0.037 0.026 -0.042 -0.149 -0.231    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.018 0.030 0.906  ||  -1.416 -1.208 -1.070 -0.814 -0.522 -0.263 0.216 3.629  || dis=0.88 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.022 0.040 0.891  ||  -1.619 -1.479 -1.081 -0.762 -0.510 -0.163 0.431 3.543  || dis=0.85 || select=7/8
009/019-th : 0.085 0.091 0.092 0.110 0.114 0.134 0.159 0.216  ||  -0.343 -0.270 -0.260 -0.083 -0.050 0.113 0.288 0.594  || dis=0.06 || select=7/8
010/019-th : 0.089 0.098 0.107 0.116 0.129 0.153 0.155 0.153  ||  -0.316 -0.213 -0.129 -0.043 0.058 0.233 0.244 0.229   || dis=0.00 || select=6/8
011/019-th : 0.126 0.116 0.112 0.120 0.132 0.128 0.133 0.134  ||  0.013 -0.077 -0.111 -0.043 0.056 0.022 0.066 0.070    || dis=0.00 || select=7/8
012/019-th : 0.154 0.136 0.126 0.125 0.125 0.114 0.110 0.110  ||  0.215 0.094 0.020 0.006 0.006 -0.080 -0.117 -0.122    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.972  ||  -0.961 -0.904 -0.961 -0.900 -0.713 -0.566 -0.332 4.750  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.007 0.011 0.964  ||  -1.215 -1.149 -1.098 -0.944 -0.771 -0.464 0.011 4.531  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.969  ||  -1.165 -0.708 -0.941 -0.930 -0.714 -0.470 -0.239 4.709  || dis=0.96 || select=7/8
016/019-th : 0.025 0.034 0.035 0.053 0.070 0.161 0.221 0.400  ||  -1.210 -0.896 -0.858 -0.450 -0.166 0.663 0.975 1.571  || dis=0.18 || select=7/8
017/019-th : 0.085 0.093 0.100 0.118 0.131 0.138 0.168 0.169  ||  -0.363 -0.270 -0.198 -0.032 0.072 0.125 0.323 0.330   || dis=0.00 || select=7/8
018/019-th : 0.100 0.110 0.126 0.152 0.132 0.111 0.124 0.145  ||  -0.212 -0.120 0.019 0.205 0.067 -0.112 0.005 0.160    || dis=0.01 || select=3/8
[epoch=571/600] FLOP : 29.27 MB, ratio : 0.7173, Expected-ratio : 0.7000, Discrepancy : 0.323
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:47:07] [epoch=571/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.456 (0.456)  Prec@1 85.55 (85.55) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:47:13] [epoch=571/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 3.149 (1.590)  Prec@1 31.55 (59.86) Prec@5 88.10 (89.54) Size=[168, 3, 32, 32]
 **VALID** Prec@1 59.86 Prec@5 89.54 Error@1 40.14 Error@5 10.46 Loss:1.590
***[2020-01-29 10:47:13]*** VALID [epoch=571/600] loss = 1.589536, accuracy@1 = 59.86, accuracy@5 = 89.54 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:47:13]*** start epoch=572/600 Time Left: [00:14:59], LR=[0.000536 ~ 0.000536], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=572, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1262827842406786, FLOP=40.81
[Search] : epoch=572/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:47:14] [epoch=572/600][000/098] Time 0.67 (0.67) Data 0.36 (0.36) Base-Loss 0.683 (0.683)  Prec@1 73.44 (73.44) Prec@5 99.22 (99.22) Acls-loss 0.446 (0.446) FLOP-Loss 3.014 (3.014) Arch-Loss 6.473 (6.473)
**TRAIN** [2020-01-29 10:47:39] [epoch=572/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.490 (0.346)  Prec@1 79.17 (88.06) Prec@5 100.00 (99.57) Acls-loss 1.225 (0.523) FLOP-Loss 3.015 (0.113) Arch-Loss 7.254 (0.749)
 **TRAIN** Prec@1 88.06 Prec@5 99.57 Error@1 11.94 Error@5 0.43 Base-Loss:0.346, Arch-Loss=0.749
***[2020-01-29 10:47:39]*** TRAIN [epoch=572/600] base-loss = 0.345845, arch-loss = 0.749229, accuracy-1 = 88.06, accuracy-5 = 99.57
[epoch=572/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 25, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.827964)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.125 0.619 0.255  ||  -0.5483 1.0477 0.1626  || discrepancy=0.36 || select=1/3
001/003-th : 0.335 0.331 0.334  ||  0.1578 0.1468 0.1574  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.035 0.959  ||  -2.2492 -0.5194 2.7857  || discrepancy=0.92 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.010 0.010 0.011 0.014 0.020 0.921  ||  -1.249 -1.028 -0.855 -0.855 -0.693 -0.495 -0.113 3.702  || dis=0.90 || select=7/8
001/019-th : 0.077 0.093 0.130 0.122 0.128 0.139 0.166 0.145  ||  -0.464 -0.272 0.060 -0.005 0.044 0.132 0.308 0.173    || dis=0.02 || select=6/8
002/019-th : 0.099 0.107 0.129 0.127 0.127 0.146 0.142 0.123  ||  -0.220 -0.146 0.038 0.026 0.027 0.162 0.134 -0.007    || dis=0.00 || select=5/8
003/019-th : 0.113 0.112 0.120 0.129 0.130 0.134 0.136 0.125  ||  -0.097 -0.108 -0.036 0.036 0.038 0.071 0.086 0.002    || dis=0.00 || select=6/8
004/019-th : 0.101 0.105 0.109 0.107 0.132 0.132 0.159 0.154  ||  -0.192 -0.151 -0.116 -0.141 0.077 0.071 0.262 0.228   || dis=0.01 || select=6/8
005/019-th : 0.134 0.122 0.121 0.127 0.128 0.124 0.123 0.122  ||  0.071 -0.019 -0.032 0.015 0.025 -0.002 -0.014 -0.024  || dis=0.01 || select=0/8
006/019-th : 0.158 0.142 0.124 0.126 0.127 0.117 0.107 0.100  ||  0.244 0.142 0.007 0.017 0.027 -0.055 -0.145 -0.211    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.011 0.014 0.018 0.029 0.908  ||  -1.410 -1.214 -1.066 -0.810 -0.518 -0.281 0.194 3.645  || dis=0.88 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.022 0.039 0.892  ||  -1.613 -1.475 -1.083 -0.758 -0.509 -0.176 0.417 3.547  || dis=0.85 || select=7/8
009/019-th : 0.085 0.091 0.091 0.110 0.114 0.133 0.159 0.217  ||  -0.338 -0.268 -0.266 -0.083 -0.050 0.107 0.287 0.596  || dis=0.06 || select=7/8
010/019-th : 0.088 0.097 0.108 0.117 0.130 0.154 0.154 0.153  ||  -0.316 -0.228 -0.119 -0.039 0.072 0.236 0.236 0.230   || dis=0.00 || select=5/8
011/019-th : 0.127 0.116 0.112 0.119 0.132 0.128 0.133 0.134  ||  0.013 -0.075 -0.110 -0.051 0.056 0.026 0.063 0.070    || dis=0.00 || select=7/8
012/019-th : 0.154 0.135 0.127 0.124 0.126 0.114 0.110 0.109  ||  0.216 0.088 0.024 0.004 0.015 -0.079 -0.115 -0.124    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.972  ||  -0.956 -0.897 -0.957 -0.898 -0.717 -0.564 -0.330 4.746  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.965  ||  -1.212 -1.143 -1.096 -0.941 -0.767 -0.493 -0.009 4.549  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.970  ||  -1.160 -0.717 -0.938 -0.927 -0.710 -0.492 -0.239 4.720  || dis=0.96 || select=7/8
016/019-th : 0.024 0.034 0.036 0.053 0.070 0.165 0.220 0.398  ||  -1.237 -0.888 -0.848 -0.454 -0.167 0.690 0.974 1.569  || dis=0.18 || select=7/8
017/019-th : 0.082 0.093 0.099 0.121 0.130 0.136 0.168 0.170  ||  -0.391 -0.266 -0.199 -0.001 0.072 0.113 0.324 0.339   || dis=0.00 || select=7/8
018/019-th : 0.100 0.110 0.123 0.153 0.133 0.112 0.124 0.145  ||  -0.212 -0.113 -0.008 0.214 0.073 -0.102 -0.000 0.159  || dis=0.01 || select=3/8
[epoch=572/600] FLOP : 21.83 MB, ratio : 0.5348, Expected-ratio : 0.7000, Discrepancy : 0.324
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:47:39] [epoch=572/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.043 (1.043)  Prec@1 72.66 (72.66) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:47:45] [epoch=572/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 0.788 (1.681)  Prec@1 75.00 (60.82) Prec@5 99.40 (90.86) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.82 Prec@5 90.86 Error@1 39.18 Error@5 9.14 Loss:1.681
***[2020-01-29 10:47:45]*** VALID [epoch=572/600] loss = 1.681188, accuracy@1 = 60.82, accuracy@5 = 90.86 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:47:45]*** start epoch=573/600 Time Left: [00:14:27], LR=[0.000499 ~ 0.000499], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=573, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.12444203859443403, FLOP=40.81
[Search] : epoch=573/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:47:46] [epoch=573/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.295 (0.295)  Prec@1 90.62 (90.62) Prec@5 99.22 (99.22) Acls-loss 0.567 (0.567) FLOP-Loss -3.014 (-3.014) Arch-Loss -5.462 (-5.462)
**TRAIN** [2020-01-29 10:48:11] [epoch=573/600][097/098] Time 0.23 (0.26) Data 0.00 (0.00) Base-Loss 0.938 (0.355)  Prec@1 71.43 (88.29) Prec@5 97.62 (99.61) Acls-loss 0.672 (0.579) FLOP-Loss 0.000 (0.000) Arch-Loss 0.672 (0.579)
 **TRAIN** Prec@1 88.29 Prec@5 99.61 Error@1 11.71 Error@5 0.39 Base-Loss:0.355, Arch-Loss=0.579
***[2020-01-29 10:48:11]*** TRAIN [epoch=573/600] base-loss = 0.355286, arch-loss = 0.579182, accuracy-1 = 88.29, accuracy-5 = 99.61
[epoch=573/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 25, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.32038)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.125 0.618 0.257  ||  -0.5515 1.0436 0.1650  || discrepancy=0.36 || select=1/3
001/003-th : 0.335 0.330 0.335  ||  0.1570 0.1436 0.1584  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.034 0.960  ||  -2.2697 -0.5275 2.8088  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.007 0.008 0.009 0.010 0.011 0.014 0.020 0.921  ||  -1.242 -1.025 -0.874 -0.847 -0.691 -0.498 -0.112 3.707  || dis=0.90 || select=7/8
001/019-th : 0.077 0.094 0.129 0.120 0.128 0.139 0.167 0.146  ||  -0.462 -0.269 0.055 -0.017 0.043 0.128 0.314 0.175    || dis=0.02 || select=6/8
002/019-th : 0.100 0.107 0.129 0.126 0.128 0.145 0.142 0.123  ||  -0.218 -0.147 0.042 0.018 0.033 0.157 0.137 -0.007    || dis=0.00 || select=5/8
003/019-th : 0.113 0.112 0.121 0.128 0.129 0.135 0.135 0.126  ||  -0.099 -0.112 -0.030 0.026 0.036 0.080 0.079 0.011    || dis=0.00 || select=5/8
004/019-th : 0.100 0.106 0.108 0.106 0.132 0.133 0.159 0.155  ||  -0.203 -0.146 -0.127 -0.143 0.071 0.084 0.263 0.235   || dis=0.00 || select=6/8
005/019-th : 0.134 0.122 0.120 0.127 0.128 0.122 0.123 0.124  ||  0.072 -0.023 -0.042 0.020 0.022 -0.026 -0.015 -0.003  || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.125 0.125 0.128 0.117 0.106 0.100  ||  0.241 0.139 0.009 0.017 0.035 -0.056 -0.148 -0.209    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.014 0.017 0.027 0.911  ||  -1.404 -1.210 -1.061 -0.837 -0.528 -0.295 0.169 3.675  || dis=0.88 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.016 0.022 0.039 0.892  ||  -1.606 -1.472 -1.080 -0.754 -0.508 -0.176 0.413 3.543  || dis=0.85 || select=7/8
009/019-th : 0.085 0.091 0.092 0.109 0.113 0.133 0.159 0.217  ||  -0.338 -0.267 -0.266 -0.088 -0.055 0.108 0.289 0.599  || dis=0.06 || select=7/8
010/019-th : 0.089 0.097 0.108 0.116 0.130 0.155 0.153 0.153  ||  -0.315 -0.227 -0.118 -0.046 0.065 0.245 0.235 0.233   || dis=0.00 || select=5/8
011/019-th : 0.127 0.116 0.112 0.118 0.132 0.127 0.133 0.135  ||  0.014 -0.074 -0.112 -0.058 0.056 0.020 0.066 0.082    || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.127 0.124 0.126 0.115 0.111 0.110  ||  0.214 0.081 0.025 0.003 0.015 -0.075 -0.113 -0.121    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.972  ||  -0.950 -0.904 -0.952 -0.896 -0.715 -0.559 -0.356 4.755  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.965  ||  -1.209 -1.130 -1.096 -0.938 -0.763 -0.493 -0.009 4.545  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.971  ||  -1.158 -0.759 -0.934 -0.922 -0.707 -0.503 -0.237 4.748  || dis=0.96 || select=7/8
016/019-th : 0.023 0.034 0.035 0.050 0.069 0.167 0.227 0.396  ||  -1.260 -0.887 -0.863 -0.497 -0.172 0.713 1.019 1.578  || dis=0.17 || select=7/8
017/019-th : 0.079 0.092 0.099 0.124 0.131 0.135 0.169 0.172  ||  -0.422 -0.278 -0.200 0.021 0.079 0.108 0.336 0.350    || dis=0.00 || select=7/8
018/019-th : 0.100 0.110 0.121 0.154 0.132 0.113 0.125 0.145  ||  -0.212 -0.115 -0.021 0.216 0.063 -0.095 0.012 0.161   || dis=0.01 || select=3/8
[epoch=573/600] FLOP : 28.32 MB, ratio : 0.6939, Expected-ratio : 0.7000, Discrepancy : 0.324
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:48:11] [epoch=573/600][000/098] Time 0.37 (0.37) Data 0.27 (0.27) Loss 2.414 (2.414)  Prec@1 31.64 (31.64) Prec@5 76.95 (76.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:48:17] [epoch=573/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.927 (1.688)  Prec@1 71.43 (57.22) Prec@5 96.43 (89.32) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.22 Prec@5 89.32 Error@1 42.78 Error@5 10.68 Loss:1.688
***[2020-01-29 10:48:17]*** VALID [epoch=573/600] loss = 1.687823, accuracy@1 = 57.22, accuracy@5 = 89.32 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:48:17]*** start epoch=574/600 Time Left: [00:13:55], LR=[0.000463 ~ 0.000463], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=574, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1226677908449632, FLOP=40.81
[Search] : epoch=574/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:48:18] [epoch=574/600][000/098] Time 0.64 (0.64) Data 0.34 (0.34) Base-Loss 0.449 (0.449)  Prec@1 82.42 (82.42) Prec@5 100.00 (100.00) Acls-loss 0.659 (0.659) FLOP-Loss 0.000 (0.000) Arch-Loss 0.659 (0.659)
**TRAIN** [2020-01-29 10:48:42] [epoch=574/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.621 (0.358)  Prec@1 79.76 (87.92) Prec@5 99.40 (99.58) Acls-loss 0.503 (0.546) FLOP-Loss -3.017 (0.042) Arch-Loss -5.531 (0.629)
 **TRAIN** Prec@1 87.92 Prec@5 99.58 Error@1 12.08 Error@5 0.42 Base-Loss:0.358, Arch-Loss=0.629
***[2020-01-29 10:48:43]*** TRAIN [epoch=574/600] base-loss = 0.358403, arch-loss = 0.628830, accuracy-1 = 87.92, accuracy-5 = 99.58
[epoch=574/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 25, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.799612)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.123 0.622 0.255  ||  -0.5626 1.0585 0.1650  || discrepancy=0.37 || select=1/3
001/003-th : 0.334 0.331 0.334  ||  0.1567 0.1483 0.1569  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.3031 -0.5277 2.8420  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.009 0.010 0.011 0.014 0.020 0.922  ||  -1.244 -1.017 -0.899 -0.846 -0.710 -0.495 -0.106 3.725  || dis=0.90 || select=7/8
001/019-th : 0.077 0.094 0.129 0.120 0.127 0.139 0.165 0.148  ||  -0.461 -0.266 0.053 -0.017 0.033 0.128 0.299 0.188    || dis=0.02 || select=6/8
002/019-th : 0.099 0.106 0.132 0.124 0.129 0.144 0.142 0.124  ||  -0.228 -0.152 0.062 0.004 0.039 0.154 0.138 -0.000    || dis=0.00 || select=5/8
003/019-th : 0.113 0.111 0.122 0.129 0.129 0.134 0.135 0.127  ||  -0.100 -0.115 -0.025 0.033 0.035 0.068 0.078 0.016    || dis=0.00 || select=6/8
004/019-th : 0.100 0.106 0.108 0.106 0.132 0.132 0.162 0.155  ||  -0.207 -0.144 -0.130 -0.144 0.071 0.073 0.279 0.233   || dis=0.01 || select=6/8
005/019-th : 0.134 0.122 0.120 0.128 0.127 0.122 0.123 0.125  ||  0.067 -0.024 -0.039 0.024 0.019 -0.024 -0.018 -0.000  || dis=0.01 || select=0/8
006/019-th : 0.157 0.142 0.125 0.126 0.127 0.117 0.106 0.100  ||  0.238 0.138 0.012 0.020 0.031 -0.056 -0.148 -0.207    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.014 0.017 0.027 0.912  ||  -1.397 -1.207 -1.077 -0.834 -0.525 -0.293 0.168 3.679  || dis=0.89 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.016 0.021 0.039 0.892  ||  -1.599 -1.467 -1.076 -0.765 -0.505 -0.182 0.405 3.545  || dis=0.85 || select=7/8
009/019-th : 0.085 0.090 0.092 0.110 0.113 0.131 0.161 0.219  ||  -0.341 -0.282 -0.262 -0.087 -0.059 0.090 0.299 0.606  || dis=0.06 || select=7/8
010/019-th : 0.088 0.097 0.108 0.116 0.129 0.155 0.153 0.154  ||  -0.319 -0.222 -0.115 -0.046 0.064 0.243 0.233 0.236   || dis=0.00 || select=5/8
011/019-th : 0.128 0.116 0.112 0.118 0.132 0.128 0.133 0.134  ||  0.022 -0.074 -0.112 -0.056 0.056 0.022 0.064 0.073    || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.126 0.124 0.127 0.115 0.111 0.110  ||  0.211 0.079 0.021 0.005 0.023 -0.069 -0.112 -0.121    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.972  ||  -0.943 -0.897 -0.949 -0.905 -0.713 -0.561 -0.355 4.758  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.965  ||  -1.206 -1.151 -1.093 -0.935 -0.759 -0.492 -0.013 4.549  || dis=0.95 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.971  ||  -1.152 -0.759 -0.930 -0.925 -0.703 -0.502 -0.236 4.745  || dis=0.96 || select=7/8
016/019-th : 0.023 0.034 0.035 0.050 0.068 0.166 0.230 0.396  ||  -1.261 -0.889 -0.856 -0.493 -0.188 0.708 1.034 1.577  || dis=0.17 || select=7/8
017/019-th : 0.079 0.089 0.099 0.123 0.131 0.136 0.171 0.172  ||  -0.422 -0.301 -0.197 0.019 0.078 0.116 0.349 0.353    || dis=0.00 || select=7/8
018/019-th : 0.100 0.108 0.120 0.153 0.134 0.113 0.126 0.147  ||  -0.217 -0.133 -0.029 0.212 0.077 -0.090 0.021 0.170   || dis=0.01 || select=3/8
[epoch=574/600] FLOP : 28.80 MB, ratio : 0.7056, Expected-ratio : 0.7000, Discrepancy : 0.324
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:48:43] [epoch=574/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 0.514 (0.514)  Prec@1 83.59 (83.59) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:48:49] [epoch=574/600][097/098] Time 0.05 (0.07) Data 0.00 (0.00) Loss 0.670 (1.867)  Prec@1 79.17 (64.40) Prec@5 98.81 (91.13) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.40 Prec@5 91.13 Error@1 35.60 Error@5 8.87 Loss:1.867
***[2020-01-29 10:48:49]*** VALID [epoch=574/600] loss = 1.867349, accuracy@1 = 64.40, accuracy@5 = 91.13 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:48:49]*** start epoch=575/600 Time Left: [00:13:22], LR=[0.000428 ~ 0.000428], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=575, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.12096008963416457, FLOP=40.81
[Search] : epoch=575/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:48:50] [epoch=575/600][000/098] Time 0.64 (0.64) Data 0.36 (0.36) Base-Loss 0.683 (0.683)  Prec@1 76.56 (76.56) Prec@5 99.61 (99.61) Acls-loss 1.111 (1.111) FLOP-Loss 3.017 (3.017) Arch-Loss 7.146 (7.146)
**TRAIN** [2020-01-29 10:49:14] [epoch=575/600][097/098] Time 0.24 (0.25) Data 0.00 (0.00) Base-Loss 0.290 (0.369)  Prec@1 91.67 (87.64) Prec@5 100.00 (99.52) Acls-loss 1.011 (0.556) FLOP-Loss 0.000 (0.124) Arch-Loss 1.011 (0.804)
 **TRAIN** Prec@1 87.64 Prec@5 99.52 Error@1 12.36 Error@5 0.48 Base-Loss:0.369, Arch-Loss=0.804
***[2020-01-29 10:49:14]*** TRAIN [epoch=575/600] base-loss = 0.368638, arch-loss = 0.803524, accuracy-1 = 87.64, accuracy-5 = 99.52
[epoch=575/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 25, 32, 9, 64, 64, 64, 64, 57, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 28.388348)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.122 0.624 0.253  ||  -0.5651 1.0639 0.1628  || discrepancy=0.37 || select=1/3
001/003-th : 0.333 0.330 0.337  ||  0.1520 0.1440 0.1626  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2996 -0.5295 2.8387  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.009 0.010 0.011 0.013 0.020 0.924  ||  -1.238 -1.035 -0.904 -0.837 -0.707 -0.504 -0.108 3.737  || dis=0.90 || select=7/8
001/019-th : 0.077 0.094 0.127 0.119 0.127 0.140 0.166 0.149  ||  -0.460 -0.264 0.033 -0.034 0.037 0.135 0.303 0.197    || dis=0.02 || select=6/8
002/019-th : 0.098 0.106 0.132 0.124 0.129 0.144 0.142 0.124  ||  -0.231 -0.151 0.063 0.004 0.045 0.151 0.136 0.005     || dis=0.00 || select=5/8
003/019-th : 0.113 0.109 0.123 0.130 0.129 0.134 0.135 0.127  ||  -0.098 -0.137 -0.014 0.044 0.032 0.075 0.078 0.015    || dis=0.00 || select=6/8
004/019-th : 0.099 0.105 0.109 0.106 0.132 0.132 0.163 0.154  ||  -0.217 -0.153 -0.120 -0.141 0.075 0.077 0.289 0.228   || dis=0.01 || select=6/8
005/019-th : 0.131 0.121 0.120 0.127 0.127 0.123 0.125 0.125  ||  0.052 -0.031 -0.039 0.020 0.021 -0.017 0.002 0.001    || dis=0.00 || select=0/8
006/019-th : 0.158 0.143 0.125 0.126 0.125 0.116 0.107 0.100  ||  0.244 0.143 0.016 0.021 0.011 -0.059 -0.147 -0.207    || dis=0.02 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.014 0.017 0.027 0.911  ||  -1.390 -1.203 -1.075 -0.831 -0.520 -0.298 0.163 3.677  || dis=0.88 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.021 0.038 0.893  ||  -1.609 -1.465 -1.071 -0.760 -0.504 -0.181 0.395 3.550  || dis=0.85 || select=7/8
009/019-th : 0.085 0.090 0.091 0.109 0.112 0.131 0.162 0.219  ||  -0.343 -0.283 -0.269 -0.087 -0.059 0.096 0.306 0.606  || dis=0.06 || select=7/8
010/019-th : 0.088 0.098 0.110 0.116 0.129 0.153 0.153 0.153  ||  -0.324 -0.219 -0.100 -0.042 0.060 0.234 0.233 0.232   || dis=0.00 || select=5/8
011/019-th : 0.124 0.116 0.112 0.118 0.132 0.132 0.133 0.134  ||  -0.007 -0.074 -0.111 -0.058 0.056 0.056 0.067 0.068   || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.125 0.126 0.124 0.115 0.113 0.110  ||  0.210 0.075 0.008 0.019 0.002 -0.074 -0.094 -0.118    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.973  ||  -0.966 -0.917 -0.943 -0.904 -0.740 -0.543 -0.364 4.785  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.966  ||  -1.202 -1.146 -1.117 -0.931 -0.762 -0.495 -0.021 4.569  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.007 0.971  ||  -1.153 -0.758 -0.926 -0.922 -0.699 -0.500 -0.246 4.746  || dis=0.96 || select=7/8
016/019-th : 0.023 0.032 0.034 0.049 0.067 0.164 0.233 0.397  ||  -1.277 -0.922 -0.854 -0.496 -0.187 0.707 1.058 1.590  || dis=0.16 || select=7/8
017/019-th : 0.079 0.089 0.099 0.124 0.131 0.133 0.174 0.172  ||  -0.425 -0.302 -0.201 0.025 0.078 0.100 0.363 0.352    || dis=0.00 || select=6/8
018/019-th : 0.098 0.109 0.121 0.152 0.134 0.112 0.127 0.147  ||  -0.236 -0.128 -0.019 0.207 0.082 -0.098 0.027 0.175   || dis=0.01 || select=3/8
[epoch=575/600] FLOP : 28.39 MB, ratio : 0.6956, Expected-ratio : 0.7000, Discrepancy : 0.324
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:49:14] [epoch=575/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 5.162 (5.162)  Prec@1 15.62 (15.62) Prec@5 51.95 (51.95) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:49:20] [epoch=575/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 0.531 (1.868)  Prec@1 79.76 (57.18) Prec@5 99.40 (87.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 57.18 Prec@5 87.99 Error@1 42.82 Error@5 12.01 Loss:1.868
***[2020-01-29 10:49:20]*** VALID [epoch=575/600] loss = 1.867609, accuracy@1 = 57.18, accuracy@5 = 87.99 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:49:20]*** start epoch=576/600 Time Left: [00:12:50], LR=[0.000394 ~ 0.000394], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=576, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11931898177952949, FLOP=40.81
[Search] : epoch=576/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:49:21] [epoch=576/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.422 (0.422)  Prec@1 83.98 (83.98) Prec@5 100.00 (100.00) Acls-loss 0.494 (0.494) FLOP-Loss 0.000 (0.000) Arch-Loss 0.494 (0.494)
**TRAIN** [2020-01-29 10:49:46] [epoch=576/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.397 (0.406)  Prec@1 85.71 (86.16) Prec@5 98.81 (99.34) Acls-loss 0.887 (0.567) FLOP-Loss -3.018 (0.165) Arch-Loss -5.149 (0.897)
 **TRAIN** Prec@1 86.16 Prec@5 99.34 Error@1 13.84 Error@5 0.66 Base-Loss:0.406, Arch-Loss=0.897
***[2020-01-29 10:49:46]*** TRAIN [epoch=576/600] base-loss = 0.405958, arch-loss = 0.897367, accuracy-1 = 86.16, accuracy-5 = 99.34
[epoch=576/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 14, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.643132)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.124 0.624 0.252  ||  -0.5579 1.0620 0.1564  || discrepancy=0.37 || select=1/3
001/003-th : 0.335 0.330 0.335  ||  0.1567 0.1398 0.1576  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.962  ||  -2.2970 -0.5406 2.8376  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.009 0.009 0.011 0.013 0.019 0.924  ||  -1.230 -1.035 -0.919 -0.839 -0.705 -0.502 -0.111 3.748  || dis=0.91 || select=7/8
001/019-th : 0.078 0.093 0.127 0.120 0.127 0.139 0.166 0.150  ||  -0.453 -0.275 0.034 -0.026 0.031 0.127 0.304 0.201    || dis=0.02 || select=6/8
002/019-th : 0.098 0.107 0.132 0.123 0.132 0.143 0.142 0.123  ||  -0.234 -0.146 0.067 -0.008 0.066 0.150 0.140 -0.002   || dis=0.00 || select=5/8
003/019-th : 0.113 0.110 0.124 0.130 0.128 0.134 0.135 0.126  ||  -0.099 -0.127 -0.006 0.044 0.023 0.069 0.077 0.013    || dis=0.00 || select=6/8
004/019-th : 0.099 0.106 0.109 0.108 0.132 0.130 0.164 0.153  ||  -0.211 -0.147 -0.119 -0.127 0.071 0.060 0.290 0.222   || dis=0.01 || select=6/8
005/019-th : 0.132 0.121 0.120 0.129 0.126 0.123 0.125 0.124  ||  0.053 -0.027 -0.036 0.033 0.012 -0.017 -0.002 -0.003  || dis=0.00 || select=0/8
006/019-th : 0.158 0.144 0.125 0.127 0.125 0.116 0.107 0.100  ||  0.247 0.152 0.012 0.025 0.011 -0.060 -0.147 -0.214    || dis=0.01 || select=0/8
007/019-th : 0.006 0.007 0.008 0.010 0.013 0.017 0.027 0.913  ||  -1.382 -1.198 -1.070 -0.832 -0.539 -0.296 0.145 3.685  || dis=0.89 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.021 0.037 0.895  ||  -1.609 -1.475 -1.068 -0.755 -0.508 -0.177 0.382 3.561  || dis=0.86 || select=7/8
009/019-th : 0.085 0.090 0.092 0.110 0.113 0.130 0.162 0.217  ||  -0.336 -0.286 -0.266 -0.081 -0.056 0.087 0.305 0.598  || dis=0.05 || select=7/8
010/019-th : 0.089 0.098 0.111 0.117 0.125 0.153 0.152 0.155  ||  -0.316 -0.210 -0.094 -0.038 0.028 0.228 0.225 0.245   || dis=0.00 || select=7/8
011/019-th : 0.125 0.117 0.112 0.119 0.132 0.131 0.132 0.133  ||  -0.002 -0.068 -0.110 -0.044 0.056 0.049 0.060 0.062   || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.125 0.127 0.125 0.113 0.113 0.109  ||  0.212 0.079 0.012 0.023 0.011 -0.089 -0.089 -0.125    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.973  ||  -0.968 -0.911 -0.938 -0.902 -0.738 -0.565 -0.366 4.791  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.966  ||  -1.199 -1.172 -1.116 -0.928 -0.757 -0.493 -0.021 4.577  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.971  ||  -1.154 -0.765 -0.919 -0.932 -0.695 -0.499 -0.254 4.755  || dis=0.96 || select=7/8
016/019-th : 0.022 0.031 0.035 0.049 0.067 0.164 0.233 0.399  ||  -1.288 -0.948 -0.845 -0.499 -0.182 0.711 1.065 1.602  || dis=0.17 || select=7/8
017/019-th : 0.079 0.089 0.100 0.124 0.130 0.135 0.172 0.172  ||  -0.429 -0.304 -0.191 0.027 0.077 0.110 0.353 0.355    || dis=0.00 || select=7/8
018/019-th : 0.097 0.109 0.121 0.154 0.133 0.113 0.126 0.148  ||  -0.242 -0.127 -0.025 0.219 0.073 -0.091 0.023 0.179   || dis=0.01 || select=3/8
[epoch=576/600] FLOP : 29.64 MB, ratio : 0.7263, Expected-ratio : 0.7000, Discrepancy : 0.324
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:49:46] [epoch=576/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.709 (0.709)  Prec@1 80.08 (80.08) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:49:52] [epoch=576/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 3.902 (1.551)  Prec@1 15.48 (63.30) Prec@5 60.12 (92.20) Size=[168, 3, 32, 32]
 **VALID** Prec@1 63.30 Prec@5 92.20 Error@1 36.70 Error@5 7.80 Loss:1.551
***[2020-01-29 10:49:52]*** VALID [epoch=576/600] loss = 1.550728, accuracy@1 = 63.30, accuracy@5 = 92.20 | Best-Valid-Acc@1=64.93, Error@1=35.07
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:49:52]*** start epoch=577/600 Time Left: [00:12:18], LR=[0.000362 ~ 0.000362], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=577, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11774451227285844, FLOP=40.81
[Search] : epoch=577/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:49:53] [epoch=577/600][000/098] Time 0.64 (0.64) Data 0.35 (0.35) Base-Loss 0.252 (0.252)  Prec@1 91.80 (91.80) Prec@5 99.61 (99.61) Acls-loss 0.525 (0.525) FLOP-Loss 3.018 (3.018) Arch-Loss 6.561 (6.561)
**TRAIN** [2020-01-29 10:50:18] [epoch=577/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.391 (0.377)  Prec@1 86.31 (87.30) Prec@5 99.40 (99.54) Acls-loss 0.476 (0.537) FLOP-Loss -3.019 (0.134) Arch-Loss -5.562 (0.805)
 **TRAIN** Prec@1 87.30 Prec@5 99.54 Error@1 12.70 Error@5 0.46 Base-Loss:0.377, Arch-Loss=0.805
***[2020-01-29 10:50:18]*** TRAIN [epoch=577/600] base-loss = 0.377374, arch-loss = 0.805324, accuracy-1 = 87.30, accuracy-5 = 99.54
[epoch=577/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.348732)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.122 0.625 0.253  ||  -0.5666 1.0643 0.1603  || discrepancy=0.37 || select=1/3
001/003-th : 0.334 0.333 0.334  ||  0.1557 0.1521 0.1551  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.033 0.961  ||  -2.2943 -0.5363 2.8344  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.009 0.009 0.011 0.013 0.019 0.925  ||  -1.221 -1.053 -0.918 -0.833 -0.701 -0.506 -0.116 3.759  || dis=0.91 || select=7/8
001/019-th : 0.077 0.093 0.126 0.119 0.130 0.139 0.164 0.151  ||  -0.461 -0.276 0.031 -0.030 0.063 0.128 0.292 0.206    || dis=0.01 || select=6/8
002/019-th : 0.098 0.107 0.132 0.123 0.132 0.142 0.142 0.124  ||  -0.232 -0.144 0.064 -0.008 0.068 0.140 0.138 0.003    || dis=0.00 || select=5/8
003/019-th : 0.112 0.109 0.125 0.130 0.128 0.136 0.135 0.126  ||  -0.106 -0.133 -0.000 0.043 0.023 0.085 0.082 0.010    || dis=0.00 || select=5/8
004/019-th : 0.099 0.106 0.110 0.108 0.132 0.130 0.163 0.152  ||  -0.211 -0.147 -0.112 -0.122 0.071 0.062 0.288 0.215   || dis=0.01 || select=6/8
005/019-th : 0.132 0.122 0.121 0.129 0.126 0.122 0.124 0.124  ||  0.055 -0.023 -0.033 0.034 0.012 -0.024 -0.003 -0.004  || dis=0.00 || select=0/8
006/019-th : 0.158 0.143 0.126 0.127 0.125 0.116 0.106 0.100  ||  0.248 0.145 0.017 0.028 0.010 -0.062 -0.152 -0.210    || dis=0.02 || select=0/8
007/019-th : 0.005 0.007 0.008 0.009 0.013 0.016 0.025 0.916  ||  -1.432 -1.194 -1.066 -0.853 -0.534 -0.294 0.136 3.726  || dis=0.89 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.021 0.036 0.897  ||  -1.618 -1.471 -1.063 -0.766 -0.516 -0.177 0.361 3.576  || dis=0.86 || select=7/8
009/019-th : 0.086 0.089 0.090 0.111 0.112 0.130 0.162 0.221  ||  -0.331 -0.298 -0.278 -0.078 -0.066 0.081 0.305 0.614  || dis=0.06 || select=7/8
010/019-th : 0.087 0.099 0.110 0.118 0.126 0.152 0.152 0.156  ||  -0.337 -0.209 -0.097 -0.025 0.035 0.223 0.225 0.252   || dis=0.00 || select=7/8
011/019-th : 0.124 0.116 0.112 0.119 0.131 0.132 0.132 0.135  ||  -0.000 -0.072 -0.109 -0.041 0.050 0.055 0.059 0.078   || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.125 0.127 0.125 0.113 0.113 0.109  ||  0.212 0.080 0.010 0.025 0.012 -0.092 -0.089 -0.126    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.006 0.973  ||  -0.965 -0.904 -0.932 -0.900 -0.741 -0.563 -0.365 4.787  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.966  ||  -1.196 -1.180 -1.114 -0.924 -0.752 -0.490 -0.020 4.577  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.148 -0.764 -0.914 -0.956 -0.691 -0.512 -0.253 4.767  || dis=0.97 || select=7/8
016/019-th : 0.022 0.031 0.034 0.047 0.067 0.167 0.232 0.400  ||  -1.297 -0.943 -0.848 -0.535 -0.171 0.734 1.064 1.610  || dis=0.17 || select=7/8
017/019-th : 0.079 0.090 0.099 0.123 0.130 0.136 0.171 0.172  ||  -0.429 -0.298 -0.196 0.022 0.075 0.123 0.347 0.356    || dis=0.00 || select=7/8
018/019-th : 0.097 0.108 0.121 0.154 0.134 0.113 0.125 0.148  ||  -0.239 -0.132 -0.022 0.219 0.080 -0.086 0.015 0.179   || dis=0.01 || select=3/8
[epoch=577/600] FLOP : 21.35 MB, ratio : 0.5231, Expected-ratio : 0.7000, Discrepancy : 0.325
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:50:19] [epoch=577/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.644 (0.644)  Prec@1 76.95 (76.95) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:50:25] [epoch=577/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.450 (1.309)  Prec@1 38.69 (67.32) Prec@5 79.76 (93.33) Size=[168, 3, 32, 32]
 **VALID** Prec@1 67.32 Prec@5 93.33 Error@1 32.68 Error@5 6.67 Loss:1.309
***[2020-01-29 10:50:25]*** VALID [epoch=577/600] loss = 1.308637, accuracy@1 = 67.32, accuracy@5 = 93.33 | Best-Valid-Acc@1=64.93, Error@1=35.07
Currently, the best validation accuracy found at 577-epoch :: acc@1=67.32, acc@5=93.33, error@1=32.68, error@5=6.67, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:50:25]*** start epoch=578/600 Time Left: [00:11:46], LR=[0.000331 ~ 0.000331], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=578, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11623672427902872, FLOP=40.81
[Search] : epoch=578/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:50:26] [epoch=578/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 0.230 (0.230)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00) Acls-loss 0.638 (0.638) FLOP-Loss -3.019 (-3.019) Arch-Loss -5.400 (-5.400)
**TRAIN** [2020-01-29 10:50:51] [epoch=578/600][097/098] Time 0.26 (0.27) Data 0.00 (0.00) Base-Loss 1.148 (0.356)  Prec@1 66.67 (88.19) Prec@5 98.21 (99.54) Acls-loss 0.573 (0.534) FLOP-Loss -3.021 (-0.051) Arch-Loss -5.469 (0.431)
 **TRAIN** Prec@1 88.19 Prec@5 99.54 Error@1 11.81 Error@5 0.46 Base-Loss:0.356, Arch-Loss=0.431
***[2020-01-29 10:50:52]*** TRAIN [epoch=578/600] base-loss = 0.356019, arch-loss = 0.431249, accuracy-1 = 88.19, accuracy-5 = 99.54
[epoch=578/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.122 0.622 0.256  ||  -0.5711 1.0547 0.1661  || discrepancy=0.37 || select=1/3
001/003-th : 0.331 0.334 0.334  ||  0.1498 0.1592 0.1595  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.2917 -0.5352 2.8317  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.009 0.009 0.011 0.013 0.019 0.925  ||  -1.213 -1.048 -0.914 -0.834 -0.696 -0.507 -0.117 3.755  || dis=0.91 || select=7/8
001/019-th : 0.077 0.093 0.127 0.119 0.131 0.139 0.164 0.151  ||  -0.464 -0.275 0.035 -0.033 0.066 0.125 0.291 0.209    || dis=0.01 || select=6/8
002/019-th : 0.098 0.107 0.129 0.122 0.134 0.141 0.143 0.126  ||  -0.237 -0.145 0.041 -0.013 0.081 0.135 0.144 0.021    || dis=0.00 || select=6/8
003/019-th : 0.112 0.109 0.126 0.129 0.129 0.136 0.135 0.126  ||  -0.108 -0.137 0.009 0.032 0.037 0.086 0.079 0.011     || dis=0.00 || select=5/8
004/019-th : 0.099 0.105 0.110 0.107 0.132 0.127 0.167 0.153  ||  -0.216 -0.153 -0.112 -0.134 0.078 0.038 0.312 0.220   || dis=0.01 || select=6/8
005/019-th : 0.130 0.122 0.122 0.129 0.126 0.124 0.124 0.124  ||  0.039 -0.023 -0.020 0.032 0.010 -0.009 -0.007 -0.003  || dis=0.00 || select=0/8
006/019-th : 0.158 0.142 0.126 0.127 0.125 0.117 0.107 0.100  ||  0.243 0.138 0.017 0.026 0.009 -0.057 -0.148 -0.207    || dis=0.02 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.016 0.025 0.919  ||  -1.452 -1.189 -1.061 -0.852 -0.529 -0.329 0.134 3.751  || dis=0.89 || select=7/8
008/019-th : 0.005 0.006 0.008 0.012 0.015 0.021 0.035 0.899  ||  -1.612 -1.466 -1.072 -0.766 -0.532 -0.184 0.344 3.590  || dis=0.86 || select=7/8
009/019-th : 0.086 0.088 0.091 0.111 0.112 0.129 0.162 0.221  ||  -0.329 -0.301 -0.276 -0.073 -0.069 0.075 0.305 0.614  || dis=0.06 || select=7/8
010/019-th : 0.087 0.098 0.110 0.118 0.126 0.152 0.153 0.156  ||  -0.337 -0.214 -0.096 -0.027 0.033 0.221 0.230 0.253   || dis=0.00 || select=7/8
011/019-th : 0.125 0.116 0.112 0.120 0.131 0.131 0.132 0.135  ||  0.001 -0.072 -0.109 -0.040 0.050 0.049 0.057 0.078    || dis=0.00 || select=7/8
012/019-th : 0.152 0.133 0.125 0.126 0.126 0.115 0.114 0.109  ||  0.207 0.072 0.008 0.015 0.013 -0.076 -0.083 -0.124    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.005 0.974  ||  -0.961 -0.898 -0.926 -0.924 -0.763 -0.561 -0.363 4.815  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.010 0.966  ||  -1.192 -1.178 -1.112 -0.921 -0.748 -0.490 -0.021 4.573  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.971  ||  -1.142 -0.763 -0.910 -0.954 -0.686 -0.513 -0.252 4.763  || dis=0.96 || select=7/8
016/019-th : 0.021 0.031 0.034 0.047 0.066 0.164 0.235 0.402  ||  -1.328 -0.942 -0.853 -0.524 -0.180 0.729 1.087 1.622  || dis=0.17 || select=7/8
017/019-th : 0.078 0.089 0.100 0.122 0.130 0.137 0.171 0.173  ||  -0.441 -0.299 -0.183 0.013 0.076 0.126 0.351 0.359    || dis=0.00 || select=7/8
018/019-th : 0.097 0.107 0.121 0.154 0.134 0.114 0.126 0.148  ||  -0.240 -0.147 -0.023 0.224 0.085 -0.082 0.019 0.180   || dis=0.01 || select=3/8
[epoch=578/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.325
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:50:52] [epoch=578/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.823 (0.823)  Prec@1 70.70 (70.70) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:50:58] [epoch=578/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.658 (1.285)  Prec@1 79.76 (69.00) Prec@5 97.62 (94.30) Size=[168, 3, 32, 32]
 **VALID** Prec@1 69.00 Prec@5 94.30 Error@1 31.00 Error@5 5.70 Loss:1.285
***[2020-01-29 10:50:58]*** VALID [epoch=578/600] loss = 1.285048, accuracy@1 = 69.00, accuracy@5 = 94.30 | Best-Valid-Acc@1=67.32, Error@1=32.68
Currently, the best validation accuracy found at 578-epoch :: acc@1=69.00, acc@5=94.30, error@1=31.00, error@5=5.70, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:50:58]*** start epoch=579/600 Time Left: [00:11:14], LR=[0.000302 ~ 0.000302], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=579, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11479565913480999, FLOP=40.81
[Search] : epoch=579/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:50:59] [epoch=579/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.229 (0.229)  Prec@1 90.62 (90.62) Prec@5 100.00 (100.00) Acls-loss 0.405 (0.405) FLOP-Loss 3.021 (3.021) Arch-Loss 6.446 (6.446)
**TRAIN** [2020-01-29 10:51:25] [epoch=579/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.703 (0.353)  Prec@1 76.19 (88.33) Prec@5 99.40 (99.55) Acls-loss 0.537 (0.578) FLOP-Loss 3.019 (0.299) Arch-Loss 6.575 (1.175)
 **TRAIN** Prec@1 88.33 Prec@5 99.55 Error@1 11.67 Error@5 0.45 Base-Loss:0.353, Arch-Loss=1.175
***[2020-01-29 10:51:25]*** TRAIN [epoch=579/600] base-loss = 0.352846, arch-loss = 1.175159, accuracy-1 = 88.33, accuracy-5 = 99.55
[epoch=579/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.122 0.626 0.252  ||  -0.5684 1.0657 0.1576  || discrepancy=0.37 || select=1/3
001/003-th : 0.333 0.333 0.334  ||  0.1544 0.1531 0.1550  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.962  ||  -2.3102 -0.5299 2.8493  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.009 0.010 0.013 0.019 0.926  ||  -1.203 -1.043 -0.931 -0.825 -0.710 -0.502 -0.122 3.769  || dis=0.91 || select=7/8
001/019-th : 0.078 0.093 0.128 0.118 0.132 0.134 0.164 0.153  ||  -0.454 -0.273 0.040 -0.042 0.069 0.090 0.287 0.220    || dis=0.01 || select=6/8
002/019-th : 0.098 0.107 0.128 0.124 0.132 0.142 0.144 0.125  ||  -0.229 -0.144 0.034 0.000 0.061 0.138 0.149 0.012     || dis=0.00 || select=6/8
003/019-th : 0.112 0.108 0.128 0.128 0.129 0.136 0.133 0.125  ||  -0.102 -0.137 0.025 0.031 0.040 0.089 0.064 0.007     || dis=0.00 || select=5/8
004/019-th : 0.099 0.105 0.111 0.108 0.132 0.125 0.168 0.152  ||  -0.208 -0.156 -0.099 -0.131 0.073 0.023 0.313 0.218   || dis=0.02 || select=6/8
005/019-th : 0.131 0.123 0.123 0.128 0.126 0.123 0.123 0.124  ||  0.046 -0.017 -0.012 0.028 0.012 -0.015 -0.014 -0.009  || dis=0.00 || select=0/8
006/019-th : 0.157 0.142 0.126 0.127 0.126 0.116 0.106 0.100  ||  0.243 0.144 0.021 0.030 0.018 -0.059 -0.153 -0.212    || dis=0.02 || select=0/8
007/019-th : 0.005 0.007 0.008 0.009 0.013 0.015 0.025 0.919  ||  -1.449 -1.184 -1.056 -0.850 -0.523 -0.340 0.132 3.750  || dis=0.89 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.020 0.035 0.899  ||  -1.605 -1.460 -1.070 -0.760 -0.530 -0.193 0.340 3.588  || dis=0.86 || select=7/8
009/019-th : 0.085 0.089 0.091 0.112 0.114 0.128 0.162 0.219  ||  -0.342 -0.292 -0.273 -0.069 -0.046 0.067 0.303 0.604  || dis=0.06 || select=7/8
010/019-th : 0.087 0.098 0.112 0.119 0.126 0.149 0.152 0.157  ||  -0.330 -0.211 -0.086 -0.024 0.032 0.206 0.223 0.252   || dis=0.01 || select=7/8
011/019-th : 0.125 0.117 0.112 0.120 0.131 0.130 0.130 0.134  ||  0.006 -0.064 -0.107 -0.035 0.050 0.043 0.046 0.074    || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.125 0.126 0.126 0.114 0.113 0.108  ||  0.211 0.082 0.014 0.022 0.020 -0.085 -0.086 -0.136    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.004 0.005 0.974  ||  -0.957 -0.921 -0.920 -0.923 -0.762 -0.564 -0.386 4.830  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.009 0.967  ||  -1.189 -1.175 -1.110 -0.946 -0.743 -0.489 -0.057 4.597  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.136 -0.762 -0.904 -0.969 -0.691 -0.513 -0.254 4.769  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.034 0.047 0.066 0.164 0.236 0.401  ||  -1.322 -0.934 -0.851 -0.519 -0.183 0.721 1.087 1.617  || dis=0.17 || select=7/8
017/019-th : 0.078 0.089 0.101 0.123 0.130 0.138 0.169 0.172  ||  -0.436 -0.300 -0.179 0.020 0.072 0.135 0.339 0.357    || dis=0.00 || select=7/8
018/019-th : 0.097 0.106 0.121 0.153 0.136 0.115 0.124 0.147  ||  -0.236 -0.148 -0.016 0.217 0.095 -0.069 0.003 0.178   || dis=0.01 || select=3/8
[epoch=579/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.326
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:51:25] [epoch=579/600][000/098] Time 0.40 (0.40) Data 0.31 (0.31) Loss 0.763 (0.763)  Prec@1 78.12 (78.12) Prec@5 99.22 (99.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:51:31] [epoch=579/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.354 (1.576)  Prec@1 39.29 (60.46) Prec@5 82.14 (90.02) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.46 Prec@5 90.02 Error@1 39.54 Error@5 9.98 Loss:1.576
***[2020-01-29 10:51:32]*** VALID [epoch=579/600] loss = 1.575916, accuracy@1 = 60.46, accuracy@5 = 90.02 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:51:32]*** start epoch=580/600 Time Left: [00:10:42], LR=[0.000274 ~ 0.000274], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=580, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11342135634773044, FLOP=40.81
[Search] : epoch=580/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:51:32] [epoch=580/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 0.439 (0.439)  Prec@1 85.16 (85.16) Prec@5 98.83 (98.83) Acls-loss 0.516 (0.516) FLOP-Loss 3.019 (3.019) Arch-Loss 6.554 (6.554)
**TRAIN** [2020-01-29 10:51:58] [epoch=580/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.202 (0.367)  Prec@1 93.45 (87.63) Prec@5 100.00 (99.48) Acls-loss 0.418 (0.547) FLOP-Loss 3.020 (0.051) Arch-Loss 6.458 (0.650)
 **TRAIN** Prec@1 87.63 Prec@5 99.48 Error@1 12.37 Error@5 0.52 Base-Loss:0.367, Arch-Loss=0.650
***[2020-01-29 10:51:58]*** TRAIN [epoch=580/600] base-loss = 0.367320, arch-loss = 0.650125, accuracy-1 = 87.63, accuracy-5 = 99.48
[epoch=580/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.348732)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.120 0.629 0.251  ||  -0.5761 1.0761 0.1573  || discrepancy=0.38 || select=1/3
001/003-th : 0.334 0.333 0.333  ||  0.1546 0.1533 0.1540  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.033 0.961  ||  -2.3080 -0.5233 2.8463  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.009 0.010 0.013 0.019 0.927  ||  -1.194 -1.041 -0.926 -0.838 -0.738 -0.509 -0.122 3.782  || dis=0.91 || select=7/8
001/019-th : 0.079 0.093 0.128 0.117 0.132 0.133 0.165 0.153  ||  -0.447 -0.276 0.044 -0.053 0.068 0.082 0.294 0.218    || dis=0.01 || select=6/8
002/019-th : 0.099 0.107 0.128 0.123 0.129 0.144 0.144 0.126  ||  -0.228 -0.149 0.036 -0.010 0.040 0.152 0.149 0.017    || dis=0.00 || select=5/8
003/019-th : 0.112 0.109 0.127 0.125 0.130 0.138 0.133 0.126  ||  -0.109 -0.135 0.023 0.008 0.041 0.105 0.070 0.013     || dis=0.01 || select=5/8
004/019-th : 0.099 0.105 0.112 0.108 0.130 0.126 0.168 0.153  ||  -0.214 -0.152 -0.094 -0.129 0.058 0.024 0.313 0.222   || dis=0.02 || select=6/8
005/019-th : 0.130 0.123 0.123 0.128 0.126 0.124 0.123 0.123  ||  0.042 -0.017 -0.014 0.028 0.012 -0.008 -0.011 -0.010  || dis=0.00 || select=0/8
006/019-th : 0.157 0.142 0.126 0.126 0.125 0.116 0.107 0.100  ||  0.242 0.140 0.022 0.021 0.015 -0.064 -0.145 -0.206    || dis=0.02 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.015 0.025 0.919  ||  -1.448 -1.179 -1.059 -0.847 -0.518 -0.338 0.127 3.750  || dis=0.89 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.015 0.020 0.034 0.900  ||  -1.598 -1.466 -1.065 -0.756 -0.526 -0.198 0.315 3.595  || dis=0.87 || select=7/8
009/019-th : 0.085 0.090 0.091 0.111 0.115 0.128 0.163 0.218  ||  -0.344 -0.287 -0.273 -0.071 -0.043 0.066 0.307 0.602  || dis=0.05 || select=7/8
010/019-th : 0.087 0.099 0.112 0.119 0.125 0.148 0.153 0.157  ||  -0.337 -0.206 -0.087 -0.019 0.027 0.197 0.228 0.254   || dis=0.00 || select=7/8
011/019-th : 0.124 0.117 0.112 0.121 0.131 0.129 0.130 0.135  ||  -0.003 -0.062 -0.104 -0.031 0.049 0.033 0.044 0.081   || dis=0.00 || select=7/8
012/019-th : 0.152 0.134 0.126 0.126 0.126 0.114 0.113 0.108  ||  0.207 0.079 0.020 0.018 0.015 -0.081 -0.087 -0.132    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.004 0.005 0.974  ||  -0.953 -0.917 -0.914 -0.921 -0.760 -0.562 -0.385 4.825  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.009 0.968  ||  -1.185 -1.198 -1.109 -0.958 -0.738 -0.489 -0.057 4.617  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.130 -0.761 -0.930 -0.967 -0.686 -0.511 -0.266 4.782  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.034 0.048 0.066 0.163 0.238 0.398  ||  -1.328 -0.939 -0.838 -0.501 -0.186 0.715 1.096 1.608  || dis=0.16 || select=7/8
017/019-th : 0.077 0.090 0.101 0.123 0.129 0.137 0.168 0.174  ||  -0.447 -0.290 -0.175 0.021 0.070 0.129 0.330 0.367    || dis=0.01 || select=7/8
018/019-th : 0.099 0.105 0.118 0.154 0.137 0.115 0.123 0.149  ||  -0.218 -0.159 -0.043 0.219 0.102 -0.072 -0.002 0.188  || dis=0.01 || select=3/8
[epoch=580/600] FLOP : 21.35 MB, ratio : 0.5231, Expected-ratio : 0.7000, Discrepancy : 0.326
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:51:58] [epoch=580/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 1.601 (1.601)  Prec@1 44.92 (44.92) Prec@5 89.06 (89.06) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:52:04] [epoch=580/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.456 (1.514)  Prec@1 85.71 (61.29) Prec@5 99.40 (90.58) Size=[168, 3, 32, 32]
 **VALID** Prec@1 61.29 Prec@5 90.58 Error@1 38.71 Error@5 9.42 Loss:1.514
***[2020-01-29 10:52:04]*** VALID [epoch=580/600] loss = 1.513728, accuracy@1 = 61.29, accuracy@5 = 90.58 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:52:05]*** start epoch=581/600 Time Left: [00:10:10], LR=[0.000247 ~ 0.000247], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=581, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11211385359499572, FLOP=40.81
[Search] : epoch=581/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:52:05] [epoch=581/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.310 (0.310)  Prec@1 89.06 (89.06) Prec@5 100.00 (100.00) Acls-loss 0.468 (0.468) FLOP-Loss -3.020 (-3.020) Arch-Loss -5.572 (-5.572)
**TRAIN** [2020-01-29 10:52:31] [epoch=581/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.936 (0.381)  Prec@1 66.07 (87.47) Prec@5 98.21 (99.31) Acls-loss 0.652 (0.543) FLOP-Loss -3.020 (0.073) Arch-Loss -5.389 (0.689)
 **TRAIN** Prec@1 87.47 Prec@5 99.31 Error@1 12.53 Error@5 0.69 Base-Loss:0.381, Arch-Loss=0.689
***[2020-01-29 10:52:31]*** TRAIN [epoch=581/600] base-loss = 0.380973, arch-loss = 0.688660, accuracy-1 = 87.47, accuracy-5 = 99.31
[epoch=581/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.348732)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.121 0.628 0.251  ||  -0.5727 1.0711 0.1552  || discrepancy=0.38 || select=1/3
001/003-th : 0.334 0.333 0.333  ||  0.1544 0.1527 0.1537  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.033 0.961  ||  -2.3056 -0.5187 2.8435  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.009 0.010 0.013 0.019 0.927  ||  -1.185 -1.036 -0.922 -0.851 -0.734 -0.506 -0.122 3.780  || dis=0.91 || select=7/8
001/019-th : 0.079 0.094 0.128 0.116 0.132 0.134 0.165 0.153  ||  -0.445 -0.273 0.041 -0.056 0.071 0.082 0.292 0.218    || dis=0.01 || select=6/8
002/019-th : 0.095 0.107 0.128 0.122 0.133 0.145 0.144 0.126  ||  -0.258 -0.143 0.035 -0.011 0.070 0.159 0.151 0.021    || dis=0.00 || select=5/8
003/019-th : 0.112 0.107 0.129 0.124 0.128 0.138 0.135 0.127  ||  -0.106 -0.151 0.037 -0.005 0.029 0.100 0.079 0.021    || dis=0.00 || select=5/8
004/019-th : 0.097 0.106 0.111 0.108 0.130 0.128 0.165 0.154  ||  -0.231 -0.145 -0.095 -0.122 0.058 0.043 0.299 0.228   || dis=0.01 || select=6/8
005/019-th : 0.130 0.123 0.122 0.129 0.126 0.123 0.123 0.123  ||  0.045 -0.013 -0.019 0.038 0.012 -0.012 -0.014 -0.012  || dis=0.00 || select=0/8
006/019-th : 0.157 0.142 0.128 0.124 0.125 0.115 0.107 0.101  ||  0.240 0.139 0.031 0.006 0.013 -0.069 -0.144 -0.199    || dis=0.02 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.015 0.024 0.920  ||  -1.452 -1.174 -1.068 -0.845 -0.513 -0.359 0.127 3.762  || dis=0.90 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.014 0.020 0.033 0.902  ||  -1.590 -1.461 -1.059 -0.750 -0.545 -0.198 0.299 3.601  || dis=0.87 || select=7/8
009/019-th : 0.084 0.090 0.092 0.111 0.114 0.127 0.162 0.220  ||  -0.349 -0.286 -0.267 -0.076 -0.046 0.059 0.305 0.611  || dis=0.06 || select=7/8
010/019-th : 0.088 0.099 0.109 0.119 0.126 0.147 0.153 0.159  ||  -0.331 -0.207 -0.111 -0.021 0.036 0.187 0.228 0.264   || dis=0.01 || select=7/8
011/019-th : 0.125 0.118 0.113 0.121 0.131 0.129 0.130 0.135  ||  -0.001 -0.056 -0.103 -0.034 0.050 0.030 0.039 0.077   || dis=0.00 || select=7/8
012/019-th : 0.153 0.134 0.127 0.125 0.126 0.114 0.113 0.108  ||  0.208 0.080 0.022 0.005 0.015 -0.079 -0.088 -0.133    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.004 0.005 0.974  ||  -0.949 -0.924 -0.907 -0.920 -0.759 -0.560 -0.384 4.823  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.009 0.968  ||  -1.180 -1.197 -1.107 -0.956 -0.763 -0.487 -0.072 4.626  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.123 -0.760 -0.928 -0.965 -0.681 -0.512 -0.275 4.781  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.034 0.048 0.066 0.165 0.237 0.397  ||  -1.328 -0.933 -0.858 -0.502 -0.188 0.731 1.094 1.608  || dis=0.16 || select=7/8
017/019-th : 0.077 0.090 0.101 0.123 0.129 0.138 0.167 0.175  ||  -0.444 -0.289 -0.177 0.016 0.067 0.132 0.323 0.372    || dis=0.01 || select=7/8
018/019-th : 0.099 0.106 0.118 0.152 0.135 0.115 0.126 0.150  ||  -0.225 -0.151 -0.050 0.207 0.087 -0.073 0.019 0.191   || dis=0.00 || select=3/8
[epoch=581/600] FLOP : 21.35 MB, ratio : 0.5231, Expected-ratio : 0.7000, Discrepancy : 0.326
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:52:31] [epoch=581/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 3.231 (3.231)  Prec@1 30.47 (30.47) Prec@5 82.42 (82.42) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:52:37] [epoch=581/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 2.073 (1.495)  Prec@1 36.31 (62.51) Prec@5 82.74 (91.00) Size=[168, 3, 32, 32]
 **VALID** Prec@1 62.51 Prec@5 91.00 Error@1 37.49 Error@5 9.00 Loss:1.495
***[2020-01-29 10:52:37]*** VALID [epoch=581/600] loss = 1.495417, accuracy@1 = 62.51, accuracy@5 = 91.00 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:52:37]*** start epoch=582/600 Time Left: [00:09:38], LR=[0.000222 ~ 0.000222], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=582, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.11087318672245401, FLOP=40.81
[Search] : epoch=582/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:52:38] [epoch=582/600][000/098] Time 0.68 (0.68) Data 0.36 (0.36) Base-Loss 0.257 (0.257)  Prec@1 92.19 (92.19) Prec@5 100.00 (100.00) Acls-loss 0.402 (0.402) FLOP-Loss -3.020 (-3.020) Arch-Loss -5.639 (-5.639)
**TRAIN** [2020-01-29 10:53:04] [epoch=582/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.332 (0.337)  Prec@1 89.29 (88.83) Prec@5 100.00 (99.64) Acls-loss 0.733 (0.510) FLOP-Loss -3.020 (0.073) Arch-Loss -5.307 (0.655)
 **TRAIN** Prec@1 88.83 Prec@5 99.64 Error@1 11.17 Error@5 0.36 Base-Loss:0.337, Arch-Loss=0.655
***[2020-01-29 10:53:04]*** TRAIN [epoch=582/600] base-loss = 0.336691, arch-loss = 0.655005, accuracy-1 = 88.83, accuracy-5 = 99.64
[epoch=582/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 1, 3]), ('estimated_FLOP', 21.348732)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.121 0.628 0.251  ||  -0.5779 1.0728 0.1566  || discrepancy=0.38 || select=1/3
001/003-th : 0.334 0.333 0.334  ||  0.1539 0.1517 0.1538  || discrepancy=0.00 || select=0/3
002/003-th : 0.006 0.033 0.961  ||  -2.3027 -0.5282 2.8418  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.009 0.010 0.013 0.019 0.927  ||  -1.174 -1.030 -0.921 -0.844 -0.758 -0.501 -0.122 3.787  || dis=0.91 || select=7/8
001/019-th : 0.079 0.093 0.128 0.116 0.134 0.134 0.164 0.153  ||  -0.446 -0.276 0.038 -0.058 0.086 0.089 0.288 0.217    || dis=0.01 || select=6/8
002/019-th : 0.095 0.107 0.128 0.123 0.132 0.146 0.144 0.125  ||  -0.261 -0.142 0.038 -0.006 0.069 0.166 0.153 0.015    || dis=0.00 || select=5/8
003/019-th : 0.112 0.107 0.129 0.124 0.129 0.138 0.134 0.127  ||  -0.104 -0.152 0.033 -0.004 0.037 0.102 0.076 0.019    || dis=0.00 || select=5/8
004/019-th : 0.096 0.107 0.111 0.109 0.131 0.126 0.166 0.153  ||  -0.239 -0.138 -0.094 -0.112 0.066 0.032 0.303 0.225   || dis=0.01 || select=6/8
005/019-th : 0.130 0.121 0.123 0.127 0.128 0.123 0.123 0.124  ||  0.045 -0.028 -0.016 0.020 0.028 -0.012 -0.011 -0.005  || dis=0.00 || select=0/8
006/019-th : 0.157 0.142 0.128 0.122 0.128 0.115 0.107 0.101  ||  0.239 0.139 0.032 -0.013 0.035 -0.076 -0.140 -0.197   || dis=0.02 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.015 0.024 0.920  ||  -1.452 -1.168 -1.076 -0.842 -0.508 -0.357 0.124 3.763  || dis=0.90 || select=7/8
008/019-th : 0.005 0.006 0.009 0.012 0.014 0.020 0.033 0.901  ||  -1.587 -1.455 -1.059 -0.743 -0.542 -0.197 0.290 3.599  || dis=0.87 || select=7/8
009/019-th : 0.085 0.090 0.092 0.111 0.114 0.126 0.162 0.220  ||  -0.346 -0.282 -0.267 -0.076 -0.046 0.051 0.303 0.610  || dis=0.06 || select=7/8
010/019-th : 0.088 0.100 0.109 0.119 0.126 0.146 0.153 0.159  ||  -0.326 -0.203 -0.111 -0.027 0.035 0.183 0.224 0.266   || dis=0.01 || select=7/8
011/019-th : 0.126 0.118 0.113 0.123 0.130 0.127 0.129 0.134  ||  0.013 -0.053 -0.101 -0.010 0.044 0.021 0.032 0.069    || dis=0.00 || select=7/8
012/019-th : 0.151 0.134 0.128 0.125 0.125 0.114 0.113 0.109  ||  0.201 0.080 0.032 0.013 0.012 -0.082 -0.087 -0.130    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.005 0.005 0.974  ||  -0.945 -0.920 -0.900 -0.918 -0.757 -0.557 -0.384 4.818  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.009 0.969  ||  -1.175 -1.196 -1.105 -0.954 -0.760 -0.509 -0.085 4.634  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.116 -0.758 -0.926 -0.962 -0.693 -0.511 -0.274 4.778  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.033 0.048 0.067 0.168 0.236 0.396  ||  -1.329 -0.933 -0.879 -0.499 -0.176 0.750 1.090 1.607  || dis=0.16 || select=7/8
017/019-th : 0.077 0.091 0.103 0.122 0.129 0.138 0.165 0.175  ||  -0.443 -0.283 -0.162 0.014 0.066 0.133 0.315 0.369    || dis=0.01 || select=7/8
018/019-th : 0.099 0.105 0.119 0.151 0.136 0.115 0.128 0.148  ||  -0.226 -0.165 -0.039 0.203 0.098 -0.074 0.033 0.183   || dis=0.00 || select=3/8
[epoch=582/600] FLOP : 21.35 MB, ratio : 0.5231, Expected-ratio : 0.7000, Discrepancy : 0.326
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:53:04] [epoch=582/600][000/098] Time 0.38 (0.38) Data 0.28 (0.28) Loss 1.182 (1.182)  Prec@1 60.94 (60.94) Prec@5 96.88 (96.88) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:53:10] [epoch=582/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.591 (1.375)  Prec@1 77.98 (66.07) Prec@5 98.21 (92.89) Size=[168, 3, 32, 32]
 **VALID** Prec@1 66.07 Prec@5 92.89 Error@1 33.93 Error@5 7.11 Loss:1.375
***[2020-01-29 10:53:10]*** VALID [epoch=582/600] loss = 1.375057, accuracy@1 = 66.07, accuracy@5 = 92.89 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:53:10]*** start epoch=583/600 Time Left: [00:09:06], LR=[0.000198 ~ 0.000198], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=583, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10969938974361465, FLOP=40.81
[Search] : epoch=583/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:53:11] [epoch=583/600][000/098] Time 0.67 (0.67) Data 0.37 (0.37) Base-Loss 0.199 (0.199)  Prec@1 92.97 (92.97) Prec@5 100.00 (100.00) Acls-loss 0.477 (0.477) FLOP-Loss -3.020 (-3.020) Arch-Loss -5.563 (-5.563)
**TRAIN** [2020-01-29 10:53:37] [epoch=583/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.349 (0.373)  Prec@1 88.69 (87.35) Prec@5 100.00 (99.48) Acls-loss 0.331 (0.539) FLOP-Loss 3.024 (-0.196) Arch-Loss 6.379 (0.146)
 **TRAIN** Prec@1 87.35 Prec@5 99.48 Error@1 12.65 Error@5 0.52 Base-Loss:0.373, Arch-Loss=0.146
***[2020-01-29 10:53:37]*** TRAIN [epoch=583/600] base-loss = 0.373068, arch-loss = 0.146229, accuracy-1 = 87.35, accuracy-5 = 99.48
[epoch=583/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.1639)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.118 0.629 0.253  ||  -0.5935 1.0768 0.1649  || discrepancy=0.38 || select=1/3
001/003-th : 0.328 0.336 0.336  ||  0.1409 0.1645 0.1652  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.033 0.961  ||  -2.3002 -0.5253 2.8389  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.009 0.010 0.012 0.018 0.928  ||  -1.193 -1.025 -0.919 -0.843 -0.754 -0.511 -0.122 3.798  || dis=0.91 || select=7/8
001/019-th : 0.076 0.091 0.126 0.115 0.136 0.135 0.168 0.153  ||  -0.471 -0.296 0.026 -0.064 0.104 0.100 0.314 0.224    || dis=0.02 || select=6/8
002/019-th : 0.094 0.106 0.128 0.122 0.132 0.147 0.145 0.125  ||  -0.267 -0.149 0.041 -0.011 0.069 0.175 0.160 0.017    || dis=0.00 || select=5/8
003/019-th : 0.111 0.105 0.125 0.122 0.131 0.141 0.137 0.128  ||  -0.117 -0.168 0.005 -0.022 0.055 0.129 0.094 0.032    || dis=0.00 || select=5/8
004/019-th : 0.096 0.105 0.111 0.109 0.133 0.127 0.165 0.154  ||  -0.246 -0.151 -0.097 -0.117 0.087 0.037 0.302 0.230   || dis=0.01 || select=6/8
005/019-th : 0.129 0.121 0.122 0.127 0.128 0.125 0.124 0.125  ||  0.034 -0.032 -0.023 0.017 0.029 0.006 -0.007 0.000    || dis=0.00 || select=0/8
006/019-th : 0.155 0.141 0.127 0.121 0.130 0.115 0.108 0.103  ||  0.228 0.129 0.027 -0.024 0.049 -0.069 -0.132 -0.188   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.015 0.024 0.921  ||  -1.449 -1.163 -1.072 -0.863 -0.504 -0.357 0.117 3.773  || dis=0.90 || select=7/8
008/019-th : 0.005 0.006 0.008 0.011 0.014 0.020 0.032 0.905  ||  -1.596 -1.450 -1.094 -0.762 -0.545 -0.203 0.287 3.634  || dis=0.87 || select=7/8
009/019-th : 0.084 0.089 0.093 0.110 0.115 0.126 0.162 0.221  ||  -0.356 -0.294 -0.254 -0.081 -0.042 0.055 0.303 0.616  || dis=0.06 || select=7/8
010/019-th : 0.087 0.099 0.109 0.118 0.127 0.147 0.153 0.162  ||  -0.340 -0.209 -0.115 -0.034 0.041 0.186 0.225 0.282   || dis=0.01 || select=7/8
011/019-th : 0.125 0.118 0.113 0.123 0.130 0.128 0.129 0.134  ||  0.005 -0.057 -0.101 -0.010 0.044 0.028 0.037 0.076    || dis=0.00 || select=7/8
012/019-th : 0.149 0.132 0.126 0.128 0.126 0.115 0.114 0.110  ||  0.189 0.069 0.017 0.034 0.023 -0.075 -0.080 -0.119    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -0.941 -0.917 -0.928 -0.917 -0.775 -0.555 -0.393 4.845  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.009 0.969  ||  -1.171 -1.195 -1.103 -0.952 -0.758 -0.508 -0.085 4.631  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.109 -0.757 -0.924 -0.960 -0.690 -0.537 -0.278 4.790  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.033 0.048 0.066 0.167 0.235 0.398  ||  -1.325 -0.930 -0.878 -0.502 -0.180 0.744 1.085 1.614  || dis=0.16 || select=7/8
017/019-th : 0.077 0.091 0.101 0.122 0.127 0.138 0.165 0.178  ||  -0.446 -0.287 -0.175 0.010 0.052 0.136 0.312 0.388    || dis=0.01 || select=7/8
018/019-th : 0.098 0.103 0.118 0.153 0.135 0.116 0.128 0.149  ||  -0.228 -0.181 -0.043 0.213 0.091 -0.058 0.035 0.189   || dis=0.00 || select=3/8
[epoch=583/600] FLOP : 29.16 MB, ratio : 0.7146, Expected-ratio : 0.7000, Discrepancy : 0.327
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:53:37] [epoch=583/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.834 (0.834)  Prec@1 75.00 (75.00) Prec@5 97.27 (97.27) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:53:43] [epoch=583/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.959 (1.394)  Prec@1 51.19 (61.28) Prec@5 95.83 (90.96) Size=[168, 3, 32, 32]
 **VALID** Prec@1 61.28 Prec@5 90.96 Error@1 38.72 Error@5 9.04 Loss:1.394
***[2020-01-29 10:53:43]*** VALID [epoch=583/600] loss = 1.393722, accuracy@1 = 61.28, accuracy@5 = 90.96 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:53:43]*** start epoch=584/600 Time Left: [00:08:33], LR=[0.000175 ~ 0.000175], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=584, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1085924948387143, FLOP=40.81
[Search] : epoch=584/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:53:44] [epoch=584/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.260 (0.260)  Prec@1 91.80 (91.80) Prec@5 100.00 (100.00) Acls-loss 0.414 (0.414) FLOP-Loss 3.024 (3.024) Arch-Loss 6.463 (6.463)
**TRAIN** [2020-01-29 10:54:09] [epoch=584/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.582 (0.341)  Prec@1 81.55 (88.62) Prec@5 96.43 (99.57) Acls-loss 0.583 (0.528) FLOP-Loss 3.025 (-0.010) Arch-Loss 6.632 (0.507)
 **TRAIN** Prec@1 88.62 Prec@5 99.57 Error@1 11.38 Error@5 0.43 Base-Loss:0.341, Arch-Loss=0.507
***[2020-01-29 10:54:09]*** TRAIN [epoch=584/600] base-loss = 0.341271, arch-loss = 0.507104, accuracy-1 = 88.62, accuracy-5 = 99.57
[epoch=584/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 4, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.118 0.629 0.253  ||  -0.5949 1.0754 0.1649  || discrepancy=0.38 || select=1/3
001/003-th : 0.326 0.337 0.337  ||  0.1367 0.1681 0.1685  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2976 -0.5493 2.8397  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.009 0.010 0.012 0.018 0.928  ||  -1.189 -1.019 -0.915 -0.842 -0.751 -0.519 -0.122 3.796  || dis=0.91 || select=7/8
001/019-th : 0.076 0.092 0.124 0.115 0.135 0.136 0.168 0.154  ||  -0.472 -0.288 0.013 -0.068 0.097 0.107 0.314 0.227    || dis=0.01 || select=6/8
002/019-th : 0.095 0.105 0.128 0.122 0.133 0.146 0.146 0.126  ||  -0.263 -0.160 0.037 -0.012 0.072 0.165 0.170 0.018    || dis=0.00 || select=6/8
003/019-th : 0.110 0.105 0.124 0.121 0.131 0.141 0.137 0.129  ||  -0.121 -0.170 0.001 -0.024 0.055 0.126 0.099 0.039    || dis=0.00 || select=5/8
004/019-th : 0.096 0.105 0.110 0.109 0.134 0.123 0.166 0.158  ||  -0.247 -0.156 -0.104 -0.116 0.089 0.009 0.303 0.253   || dis=0.01 || select=6/8
005/019-th : 0.129 0.121 0.122 0.128 0.128 0.124 0.124 0.124  ||  0.036 -0.030 -0.024 0.027 0.027 -0.005 -0.005 -0.002  || dis=0.00 || select=0/8
006/019-th : 0.155 0.141 0.127 0.120 0.130 0.115 0.109 0.103  ||  0.225 0.133 0.029 -0.027 0.048 -0.072 -0.131 -0.185   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.015 0.024 0.921  ||  -1.450 -1.157 -1.070 -0.862 -0.521 -0.355 0.117 3.776  || dis=0.90 || select=7/8
008/019-th : 0.005 0.006 0.008 0.011 0.014 0.019 0.031 0.906  ||  -1.597 -1.450 -1.090 -0.774 -0.542 -0.209 0.283 3.643  || dis=0.88 || select=7/8
009/019-th : 0.084 0.089 0.093 0.110 0.115 0.125 0.161 0.222  ||  -0.358 -0.292 -0.252 -0.082 -0.040 0.048 0.298 0.621  || dis=0.06 || select=7/8
010/019-th : 0.087 0.098 0.109 0.118 0.125 0.148 0.153 0.162  ||  -0.335 -0.214 -0.111 -0.036 0.025 0.191 0.229 0.283   || dis=0.01 || select=7/8
011/019-th : 0.125 0.118 0.112 0.123 0.130 0.128 0.129 0.134  ||  0.004 -0.054 -0.101 -0.009 0.044 0.026 0.037 0.076    || dis=0.00 || select=7/8
012/019-th : 0.149 0.132 0.126 0.129 0.126 0.115 0.114 0.110  ||  0.187 0.067 0.018 0.041 0.017 -0.074 -0.082 -0.115    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -0.937 -0.913 -0.927 -0.915 -0.773 -0.552 -0.393 4.842  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.009 0.969  ||  -1.166 -1.193 -1.101 -0.950 -0.755 -0.520 -0.094 4.634  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.972  ||  -1.101 -0.756 -0.921 -0.957 -0.708 -0.536 -0.277 4.790  || dis=0.97 || select=7/8
016/019-th : 0.021 0.032 0.033 0.048 0.067 0.167 0.235 0.397  ||  -1.319 -0.922 -0.873 -0.509 -0.166 0.739 1.083 1.606  || dis=0.16 || select=7/8
017/019-th : 0.077 0.091 0.102 0.121 0.127 0.138 0.165 0.178  ||  -0.448 -0.288 -0.167 0.004 0.054 0.132 0.315 0.388    || dis=0.01 || select=7/8
018/019-th : 0.098 0.104 0.118 0.150 0.136 0.118 0.129 0.148  ||  -0.225 -0.176 -0.048 0.196 0.096 -0.047 0.046 0.179   || dis=0.00 || select=3/8
[epoch=584/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.327
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:54:10] [epoch=584/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 3.590 (3.590)  Prec@1 23.83 (23.83) Prec@5 66.02 (66.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:54:16] [epoch=584/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.899 (1.520)  Prec@1 33.93 (63.98) Prec@5 74.40 (91.68) Size=[168, 3, 32, 32]
 **VALID** Prec@1 63.98 Prec@5 91.68 Error@1 36.02 Error@5 8.32 Loss:1.520
***[2020-01-29 10:54:16]*** VALID [epoch=584/600] loss = 1.519639, accuracy@1 = 63.98, accuracy@5 = 91.68 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:54:16]*** start epoch=585/600 Time Left: [00:08:01], LR=[0.000154 ~ 0.000154], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=585, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.1075525323538365, FLOP=40.81
[Search] : epoch=585/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:54:17] [epoch=585/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.199 (0.199)  Prec@1 94.14 (94.14) Prec@5 100.00 (100.00) Acls-loss 0.643 (0.643) FLOP-Loss 3.025 (3.025) Arch-Loss 6.693 (6.693)
**TRAIN** [2020-01-29 10:54:42] [epoch=585/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.250 (0.338)  Prec@1 92.86 (88.64) Prec@5 100.00 (99.60) Acls-loss 0.531 (0.523) FLOP-Loss 3.029 (-0.320) Arch-Loss 6.589 (-0.118)
 **TRAIN** Prec@1 88.64 Prec@5 99.60 Error@1 11.36 Error@5 0.40 Base-Loss:0.338, Arch-Loss=-0.118
***[2020-01-29 10:54:42]*** TRAIN [epoch=585/600] base-loss = 0.337567, arch-loss = -0.118308, accuracy-1 = 88.64, accuracy-5 = 99.60
[epoch=585/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.118 0.624 0.258  ||  -0.6085 1.0607 0.1795  || discrepancy=0.37 || select=1/3
001/003-th : 0.320 0.339 0.341  ||  0.1214 0.1789 0.1828  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2953 -0.5675 2.8408  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.009 0.010 0.012 0.018 0.928  ||  -1.184 -1.013 -0.911 -0.835 -0.754 -0.519 -0.122 3.793  || dis=0.91 || select=7/8
001/019-th : 0.076 0.091 0.124 0.114 0.134 0.138 0.168 0.156  ||  -0.481 -0.294 0.009 -0.072 0.093 0.116 0.314 0.241    || dis=0.01 || select=6/8
002/019-th : 0.094 0.104 0.127 0.120 0.132 0.147 0.149 0.127  ||  -0.276 -0.174 0.032 -0.025 0.071 0.175 0.190 0.030    || dis=0.00 || select=6/8
003/019-th : 0.108 0.104 0.122 0.122 0.131 0.144 0.139 0.130  ||  -0.140 -0.177 -0.017 -0.017 0.054 0.146 0.110 0.049   || dis=0.00 || select=5/8
004/019-th : 0.094 0.103 0.110 0.108 0.133 0.123 0.169 0.160  ||  -0.260 -0.173 -0.102 -0.123 0.081 0.007 0.322 0.267   || dis=0.01 || select=6/8
005/019-th : 0.128 0.120 0.119 0.127 0.131 0.123 0.125 0.125  ||  0.030 -0.037 -0.047 0.022 0.049 -0.009 0.006 0.005    || dis=0.00 || select=4/8
006/019-th : 0.153 0.139 0.128 0.120 0.130 0.116 0.110 0.104  ||  0.211 0.119 0.031 -0.032 0.052 -0.069 -0.120 -0.172   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.012 0.015 0.023 0.922  ||  -1.448 -1.155 -1.075 -0.860 -0.518 -0.367 0.101 3.783  || dis=0.90 || select=7/8
008/019-th : 0.005 0.006 0.008 0.011 0.013 0.019 0.031 0.908  ||  -1.591 -1.445 -1.088 -0.775 -0.560 -0.214 0.262 3.654  || dis=0.88 || select=7/8
009/019-th : 0.083 0.088 0.092 0.109 0.115 0.126 0.162 0.224  ||  -0.362 -0.311 -0.258 -0.087 -0.039 0.057 0.306 0.631  || dis=0.06 || select=7/8
010/019-th : 0.086 0.098 0.108 0.117 0.125 0.148 0.156 0.163  ||  -0.345 -0.223 -0.124 -0.044 0.028 0.192 0.248 0.291   || dis=0.01 || select=7/8
011/019-th : 0.123 0.116 0.112 0.124 0.130 0.128 0.131 0.136  ||  -0.008 -0.065 -0.104 -0.002 0.044 0.029 0.050 0.087   || dis=0.01 || select=7/8
012/019-th : 0.147 0.131 0.125 0.128 0.127 0.116 0.115 0.112  ||  0.175 0.055 0.009 0.031 0.028 -0.066 -0.071 -0.102    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -0.932 -0.913 -0.925 -0.913 -0.778 -0.549 -0.392 4.841  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.009 0.969  ||  -1.161 -1.191 -1.098 -0.948 -0.753 -0.521 -0.094 4.631  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.973  ||  -1.126 -0.754 -0.921 -0.977 -0.705 -0.535 -0.276 4.806  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.033 0.048 0.067 0.166 0.232 0.401  ||  -1.316 -0.934 -0.870 -0.509 -0.169 0.738 1.072 1.619  || dis=0.17 || select=7/8
017/019-th : 0.076 0.090 0.102 0.123 0.127 0.137 0.165 0.180  ||  -0.457 -0.296 -0.173 0.017 0.050 0.127 0.313 0.402    || dis=0.01 || select=7/8
018/019-th : 0.098 0.102 0.117 0.151 0.136 0.118 0.129 0.148  ||  -0.231 -0.187 -0.048 0.205 0.100 -0.041 0.044 0.183   || dis=0.00 || select=3/8
[epoch=585/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.327
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:54:43] [epoch=585/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 4.308 (4.308)  Prec@1 26.17 (26.17) Prec@5 73.44 (73.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:54:49] [epoch=585/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.372 (1.302)  Prec@1 85.71 (66.94) Prec@5 99.40 (93.40) Size=[168, 3, 32, 32]
 **VALID** Prec@1 66.94 Prec@5 93.40 Error@1 33.06 Error@5 6.60 Loss:1.302
***[2020-01-29 10:54:49]*** VALID [epoch=585/600] loss = 1.302466, accuracy@1 = 66.94, accuracy@5 = 93.40 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:54:49]*** start epoch=586/600 Time Left: [00:07:29], LR=[0.000134 ~ 0.000134], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=586, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10657953080007768, FLOP=40.81
[Search] : epoch=586/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:54:50] [epoch=586/600][000/098] Time 0.66 (0.66) Data 0.38 (0.38) Base-Loss 0.304 (0.304)  Prec@1 90.23 (90.23) Prec@5 100.00 (100.00) Acls-loss 0.498 (0.498) FLOP-Loss 3.029 (3.029) Arch-Loss 6.556 (6.556)
**TRAIN** [2020-01-29 10:55:15] [epoch=586/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.448 (0.322)  Prec@1 82.14 (89.16) Prec@5 99.40 (99.66) Acls-loss 0.606 (0.547) FLOP-Loss 3.028 (0.238) Arch-Loss 6.662 (1.022)
 **TRAIN** Prec@1 89.16 Prec@5 99.66 Error@1 10.84 Error@5 0.34 Base-Loss:0.322, Arch-Loss=1.022
***[2020-01-29 10:55:15]*** TRAIN [epoch=586/600] base-loss = 0.321691, arch-loss = 1.022154, accuracy-1 = 89.16, accuracy-5 = 99.66
[epoch=586/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 12, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.1639)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.118 0.624 0.257  ||  -0.6029 1.0607 0.1738  || discrepancy=0.37 || select=1/3
001/003-th : 0.322 0.339 0.339  ||  0.1266 0.1763 0.1769  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.032 0.962  ||  -2.2919 -0.5710 2.8382  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.009 0.010 0.012 0.018 0.930  ||  -1.178 -1.006 -0.926 -0.870 -0.750 -0.513 -0.141 3.817  || dis=0.91 || select=7/8
001/019-th : 0.076 0.092 0.123 0.115 0.135 0.137 0.166 0.156  ||  -0.474 -0.288 0.002 -0.060 0.096 0.108 0.306 0.239    || dis=0.01 || select=6/8
002/019-th : 0.094 0.104 0.127 0.121 0.132 0.148 0.147 0.126  ||  -0.268 -0.173 0.032 -0.022 0.070 0.183 0.178 0.024    || dis=0.00 || select=5/8
003/019-th : 0.108 0.104 0.123 0.123 0.132 0.143 0.137 0.130  ||  -0.142 -0.173 -0.011 -0.007 0.062 0.140 0.101 0.045   || dis=0.01 || select=5/8
004/019-th : 0.093 0.104 0.111 0.108 0.132 0.123 0.169 0.161  ||  -0.270 -0.167 -0.101 -0.127 0.080 0.005 0.321 0.275   || dis=0.01 || select=6/8
005/019-th : 0.130 0.120 0.120 0.127 0.131 0.123 0.125 0.125  ||  0.042 -0.041 -0.042 0.016 0.048 -0.017 0.006 0.002    || dis=0.00 || select=4/8
006/019-th : 0.154 0.143 0.128 0.120 0.129 0.115 0.107 0.104  ||  0.217 0.144 0.035 -0.030 0.045 -0.070 -0.143 -0.176   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.015 0.023 0.922  ||  -1.448 -1.149 -1.070 -0.858 -0.513 -0.370 0.101 3.781  || dis=0.90 || select=7/8
008/019-th : 0.005 0.005 0.008 0.011 0.013 0.019 0.030 0.909  ||  -1.592 -1.457 -1.083 -0.771 -0.563 -0.211 0.255 3.663  || dis=0.88 || select=7/8
009/019-th : 0.084 0.088 0.092 0.110 0.114 0.126 0.161 0.224  ||  -0.355 -0.304 -0.258 -0.086 -0.044 0.054 0.300 0.629  || dis=0.06 || select=7/8
010/019-th : 0.087 0.098 0.105 0.118 0.123 0.151 0.155 0.162  ||  -0.335 -0.213 -0.146 -0.036 0.009 0.217 0.240 0.286   || dis=0.01 || select=7/8
011/019-th : 0.124 0.117 0.112 0.124 0.130 0.128 0.130 0.135  ||  -0.001 -0.064 -0.103 -0.001 0.043 0.031 0.044 0.080   || dis=0.01 || select=7/8
012/019-th : 0.147 0.131 0.125 0.127 0.127 0.116 0.115 0.111  ||  0.174 0.062 0.015 0.031 0.029 -0.064 -0.076 -0.108    || dis=0.02 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.928 -0.948 -0.924 -0.911 -0.788 -0.547 -0.392 4.858  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.009 0.968  ||  -1.155 -1.188 -1.096 -0.942 -0.749 -0.519 -0.093 4.625  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.973  ||  -1.122 -0.775 -0.919 -0.975 -0.701 -0.533 -0.303 4.822  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.033 0.046 0.065 0.166 0.232 0.404  ||  -1.308 -0.938 -0.865 -0.532 -0.191 0.741 1.075 1.631  || dis=0.17 || select=7/8
017/019-th : 0.077 0.091 0.101 0.121 0.126 0.139 0.164 0.181  ||  -0.453 -0.288 -0.177 0.005 0.044 0.141 0.307 0.402    || dis=0.02 || select=7/8
018/019-th : 0.098 0.102 0.119 0.151 0.135 0.118 0.129 0.148  ||  -0.229 -0.186 -0.034 0.200 0.087 -0.044 0.048 0.181   || dis=0.00 || select=3/8
[epoch=586/600] FLOP : 29.16 MB, ratio : 0.7146, Expected-ratio : 0.7000, Discrepancy : 0.327
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:55:16] [epoch=586/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.549 (0.549)  Prec@1 80.86 (80.86) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:55:22] [epoch=586/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.684 (1.481)  Prec@1 48.21 (63.58) Prec@5 88.10 (92.03) Size=[168, 3, 32, 32]
 **VALID** Prec@1 63.58 Prec@5 92.03 Error@1 36.42 Error@5 7.97 Loss:1.481
***[2020-01-29 10:55:22]*** VALID [epoch=586/600] loss = 1.480931, accuracy@1 = 63.58, accuracy@5 = 92.03 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:55:22]*** start epoch=587/600 Time Left: [00:06:57], LR=[0.000116 ~ 0.000116], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=587, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10567351685276705, FLOP=40.81
[Search] : epoch=587/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:55:23] [epoch=587/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.338 (0.338)  Prec@1 88.67 (88.67) Prec@5 99.22 (99.22) Acls-loss 0.649 (0.649) FLOP-Loss 3.028 (3.028) Arch-Loss 6.705 (6.705)
**TRAIN** [2020-01-29 10:55:48] [epoch=587/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.296 (0.338)  Prec@1 90.48 (88.56) Prec@5 99.40 (99.58) Acls-loss 0.713 (0.533) FLOP-Loss -3.030 (-0.237) Arch-Loss -5.348 (0.058)
 **TRAIN** Prec@1 88.56 Prec@5 99.58 Error@1 11.44 Error@5 0.42 Base-Loss:0.338, Arch-Loss=0.058
***[2020-01-29 10:55:48]*** TRAIN [epoch=587/600] base-loss = 0.338120, arch-loss = 0.058318, accuracy-1 = 88.56, accuracy-5 = 99.58
[epoch=587/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 26.407292)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.116 0.626 0.258  ||  -0.6164 1.0675 0.1790  || discrepancy=0.37 || select=1/3
001/003-th : 0.318 0.341 0.340  ||  0.1178 0.1871 0.1840  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.031 0.963  ||  -2.2964 -0.5785 2.8440  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.009 0.010 0.012 0.018 0.929  ||  -1.173 -1.000 -0.922 -0.863 -0.747 -0.508 -0.147 3.812  || dis=0.91 || select=7/8
001/019-th : 0.075 0.091 0.121 0.115 0.137 0.137 0.167 0.157  ||  -0.485 -0.295 -0.011 -0.065 0.109 0.109 0.310 0.251   || dis=0.01 || select=6/8
002/019-th : 0.093 0.101 0.127 0.120 0.132 0.148 0.149 0.128  ||  -0.278 -0.195 0.034 -0.024 0.071 0.185 0.189 0.040    || dis=0.00 || select=6/8
003/019-th : 0.107 0.104 0.123 0.123 0.131 0.143 0.137 0.131  ||  -0.150 -0.173 -0.013 -0.005 0.057 0.138 0.100 0.056   || dis=0.01 || select=5/8
004/019-th : 0.093 0.102 0.109 0.108 0.132 0.123 0.171 0.162  ||  -0.274 -0.180 -0.115 -0.126 0.080 0.008 0.336 0.279   || dis=0.01 || select=6/8
005/019-th : 0.129 0.119 0.119 0.125 0.131 0.123 0.127 0.126  ||  0.035 -0.045 -0.044 0.004 0.047 -0.014 0.014 0.011    || dis=0.00 || select=4/8
006/019-th : 0.153 0.142 0.128 0.120 0.130 0.115 0.109 0.105  ||  0.209 0.134 0.031 -0.029 0.045 -0.073 -0.130 -0.169   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.012 0.015 0.023 0.922  ||  -1.445 -1.143 -1.065 -0.860 -0.527 -0.368 0.100 3.782  || dis=0.90 || select=7/8
008/019-th : 0.005 0.005 0.008 0.011 0.013 0.018 0.030 0.910  ||  -1.599 -1.452 -1.079 -0.771 -0.559 -0.230 0.253 3.669  || dis=0.88 || select=7/8
009/019-th : 0.083 0.087 0.092 0.109 0.115 0.125 0.162 0.226  ||  -0.365 -0.311 -0.259 -0.090 -0.036 0.047 0.303 0.640  || dis=0.06 || select=7/8
010/019-th : 0.087 0.098 0.104 0.117 0.124 0.151 0.155 0.164  ||  -0.335 -0.215 -0.155 -0.042 0.014 0.217 0.239 0.296   || dis=0.01 || select=7/8
011/019-th : 0.123 0.115 0.112 0.123 0.130 0.130 0.129 0.136  ||  -0.008 -0.074 -0.105 -0.008 0.045 0.046 0.039 0.091   || dis=0.01 || select=7/8
012/019-th : 0.144 0.130 0.124 0.128 0.127 0.118 0.115 0.112  ||  0.156 0.055 0.003 0.040 0.031 -0.045 -0.067 -0.098    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.923 -0.946 -0.922 -0.930 -0.789 -0.557 -0.391 4.868  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.178 -1.186 -1.098 -0.940 -0.746 -0.518 -0.103 4.636  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.974  ||  -1.137 -0.774 -0.916 -0.973 -0.697 -0.532 -0.302 4.824  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.033 0.047 0.065 0.164 0.231 0.407  ||  -1.303 -0.939 -0.864 -0.530 -0.192 0.730 1.071 1.637  || dis=0.18 || select=7/8
017/019-th : 0.077 0.089 0.103 0.121 0.126 0.137 0.166 0.181  ||  -0.448 -0.303 -0.163 -0.001 0.042 0.126 0.316 0.405   || dis=0.01 || select=7/8
018/019-th : 0.098 0.102 0.120 0.149 0.135 0.117 0.130 0.148  ||  -0.228 -0.194 -0.031 0.189 0.093 -0.049 0.055 0.185   || dis=0.00 || select=3/8
[epoch=587/600] FLOP : 26.41 MB, ratio : 0.6470, Expected-ratio : 0.7000, Discrepancy : 0.328
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:55:49] [epoch=587/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.570 (0.570)  Prec@1 83.98 (83.98) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:55:55] [epoch=587/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.797 (1.421)  Prec@1 72.62 (64.84) Prec@5 97.62 (92.42) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.84 Prec@5 92.42 Error@1 35.16 Error@5 7.58 Loss:1.421
***[2020-01-29 10:55:55]*** VALID [epoch=587/600] loss = 1.421430, accuracy@1 = 64.84, accuracy@5 = 92.42 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:55:55]*** start epoch=588/600 Time Left: [00:06:25], LR=[0.000099 ~ 0.000099], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=588, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10483451535073468, FLOP=40.81
[Search] : epoch=588/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:55:56] [epoch=588/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.241 (0.241)  Prec@1 91.80 (91.80) Prec@5 100.00 (100.00) Acls-loss 0.509 (0.509) FLOP-Loss -3.031 (-3.031) Arch-Loss -5.553 (-5.553)
**TRAIN** [2020-01-29 10:56:21] [epoch=588/600][097/098] Time 0.24 (0.27) Data 0.00 (0.00) Base-Loss 0.269 (0.342)  Prec@1 90.48 (88.71) Prec@5 99.40 (99.59) Acls-loss 0.427 (0.561) FLOP-Loss 0.000 (-0.155) Arch-Loss 0.427 (0.251)
 **TRAIN** Prec@1 88.71 Prec@5 99.59 Error@1 11.29 Error@5 0.41 Base-Loss:0.342, Arch-Loss=0.251
***[2020-01-29 10:56:21]*** TRAIN [epoch=588/600] base-loss = 0.341856, arch-loss = 0.250625, accuracy-1 = 88.71, accuracy-5 = 99.59
[epoch=588/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 27.210368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.113 0.621 0.266  ||  -0.6456 1.0537 0.2051  || discrepancy=0.35 || select=1/3
001/003-th : 0.314 0.344 0.342  ||  0.1066 0.1973 0.1939  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.031 0.963  ||  -2.3001 -0.5876 2.8495  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.010 0.012 0.017 0.931  ||  -1.181 -0.993 -0.919 -0.877 -0.753 -0.503 -0.159 3.828  || dis=0.91 || select=7/8
001/019-th : 0.072 0.090 0.120 0.113 0.136 0.139 0.169 0.159  ||  -0.526 -0.301 -0.017 -0.072 0.112 0.131 0.328 0.268   || dis=0.01 || select=6/8
002/019-th : 0.093 0.101 0.127 0.120 0.132 0.148 0.150 0.129  ||  -0.280 -0.199 0.029 -0.024 0.066 0.186 0.196 0.045    || dis=0.00 || select=6/8
003/019-th : 0.106 0.103 0.122 0.123 0.132 0.144 0.138 0.132  ||  -0.156 -0.188 -0.018 -0.008 0.060 0.153 0.107 0.062   || dis=0.01 || select=5/8
004/019-th : 0.092 0.101 0.109 0.107 0.131 0.124 0.174 0.163  ||  -0.286 -0.187 -0.114 -0.136 0.072 0.012 0.352 0.287   || dis=0.01 || select=6/8
005/019-th : 0.128 0.119 0.120 0.125 0.131 0.123 0.127 0.127  ||  0.029 -0.048 -0.043 0.002 0.046 -0.012 0.018 0.017    || dis=0.00 || select=4/8
006/019-th : 0.151 0.141 0.127 0.120 0.130 0.116 0.109 0.106  ||  0.197 0.127 0.023 -0.029 0.052 -0.070 -0.125 -0.156   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.012 0.015 0.023 0.922  ||  -1.441 -1.145 -1.059 -0.858 -0.523 -0.368 0.098 3.780  || dis=0.90 || select=7/8
008/019-th : 0.005 0.005 0.008 0.010 0.013 0.018 0.029 0.912  ||  -1.593 -1.447 -1.075 -0.780 -0.584 -0.240 0.243 3.685  || dis=0.88 || select=7/8
009/019-th : 0.082 0.087 0.092 0.109 0.115 0.124 0.162 0.227  ||  -0.370 -0.313 -0.260 -0.087 -0.038 0.040 0.308 0.644  || dis=0.07 || select=7/8
010/019-th : 0.087 0.095 0.106 0.116 0.125 0.151 0.154 0.165  ||  -0.335 -0.244 -0.139 -0.045 0.022 0.218 0.235 0.303   || dis=0.01 || select=7/8
011/019-th : 0.122 0.115 0.112 0.123 0.130 0.132 0.129 0.138  ||  -0.023 -0.082 -0.108 -0.013 0.046 0.060 0.040 0.108   || dis=0.01 || select=7/8
012/019-th : 0.142 0.130 0.123 0.128 0.129 0.119 0.116 0.113  ||  0.141 0.053 -0.002 0.040 0.043 -0.039 -0.059 -0.090   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.918 -0.944 -0.920 -0.928 -0.787 -0.555 -0.390 4.864  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.175 -1.184 -1.095 -0.938 -0.743 -0.526 -0.103 4.634  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.005 0.006 0.973  ||  -1.134 -0.772 -0.913 -0.971 -0.692 -0.531 -0.301 4.819  || dis=0.97 || select=7/8
016/019-th : 0.022 0.031 0.033 0.047 0.065 0.164 0.231 0.408  ||  -1.299 -0.938 -0.871 -0.531 -0.196 0.730 1.074 1.640  || dis=0.18 || select=7/8
017/019-th : 0.077 0.089 0.103 0.117 0.128 0.136 0.166 0.183  ||  -0.446 -0.305 -0.164 -0.032 0.055 0.122 0.320 0.417   || dis=0.02 || select=7/8
018/019-th : 0.100 0.101 0.117 0.148 0.135 0.117 0.132 0.149  ||  -0.213 -0.197 -0.051 0.183 0.088 -0.052 0.064 0.186   || dis=0.00 || select=7/8
[epoch=588/600] FLOP : 27.21 MB, ratio : 0.6667, Expected-ratio : 0.7000, Discrepancy : 0.328
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:56:22] [epoch=588/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 0.422 (0.422)  Prec@1 86.33 (86.33) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:56:28] [epoch=588/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.915 (1.596)  Prec@1 69.05 (61.80) Prec@5 95.83 (90.44) Size=[168, 3, 32, 32]
 **VALID** Prec@1 61.80 Prec@5 90.44 Error@1 38.20 Error@5 9.56 Loss:1.596
***[2020-01-29 10:56:28]*** VALID [epoch=588/600] loss = 1.596225, accuracy@1 = 61.80, accuracy@5 = 90.44 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:56:28]*** start epoch=589/600 Time Left: [00:05:53], LR=[0.000083 ~ 0.000083], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=589, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10406254929563062, FLOP=40.81
[Search] : epoch=589/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:56:29] [epoch=589/600][000/098] Time 0.66 (0.66) Data 0.36 (0.36) Base-Loss 0.341 (0.341)  Prec@1 85.94 (85.94) Prec@5 100.00 (100.00) Acls-loss 0.436 (0.436) FLOP-Loss 0.000 (0.000) Arch-Loss 0.436 (0.436)
**TRAIN** [2020-01-29 10:56:54] [epoch=589/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.372 (0.359)  Prec@1 91.07 (87.83) Prec@5 99.40 (99.59) Acls-loss 0.499 (0.538) FLOP-Loss 0.000 (0.062) Arch-Loss 0.499 (0.663)
 **TRAIN** Prec@1 87.83 Prec@5 99.59 Error@1 12.17 Error@5 0.41 Base-Loss:0.359, Arch-Loss=0.663
***[2020-01-29 10:56:54]*** TRAIN [epoch=589/600] base-loss = 0.358810, arch-loss = 0.662526, accuracy-1 = 87.83, accuracy-5 = 99.59
[epoch=589/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 27.210368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.114 0.621 0.265  ||  -0.6446 1.0531 0.2032  || discrepancy=0.36 || select=1/3
001/003-th : 0.314 0.343 0.342  ||  0.1071 0.1956 0.1930  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.031 0.963  ||  -2.2958 -0.5822 2.8443  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.008 0.010 0.012 0.017 0.931  ||  -1.189 -0.986 -0.932 -0.873 -0.749 -0.498 -0.159 3.836  || dis=0.91 || select=7/8
001/019-th : 0.072 0.090 0.119 0.114 0.136 0.139 0.169 0.160  ||  -0.521 -0.307 -0.027 -0.068 0.112 0.134 0.328 0.270   || dis=0.01 || select=6/8
002/019-th : 0.094 0.101 0.127 0.119 0.131 0.147 0.152 0.129  ||  -0.276 -0.202 0.032 -0.038 0.059 0.178 0.207 0.048    || dis=0.01 || select=6/8
003/019-th : 0.106 0.103 0.120 0.122 0.132 0.147 0.138 0.132  ||  -0.155 -0.186 -0.029 -0.018 0.059 0.173 0.108 0.060   || dis=0.01 || select=5/8
004/019-th : 0.092 0.102 0.108 0.107 0.132 0.123 0.173 0.164  ||  -0.287 -0.181 -0.121 -0.137 0.074 0.005 0.345 0.296   || dis=0.01 || select=6/8
005/019-th : 0.129 0.119 0.120 0.123 0.131 0.122 0.128 0.128  ||  0.031 -0.048 -0.038 -0.015 0.044 -0.026 0.027 0.025   || dis=0.00 || select=4/8
006/019-th : 0.151 0.141 0.126 0.121 0.130 0.116 0.110 0.106  ||  0.196 0.127 0.019 -0.027 0.048 -0.069 -0.122 -0.155   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.013 0.014 0.023 0.922  ||  -1.438 -1.140 -1.053 -0.855 -0.519 -0.378 0.095 3.779  || dis=0.90 || select=7/8
008/019-th : 0.004 0.005 0.008 0.010 0.012 0.017 0.028 0.915  ||  -1.609 -1.441 -1.071 -0.805 -0.596 -0.264 0.238 3.716  || dis=0.89 || select=7/8
009/019-th : 0.082 0.088 0.092 0.110 0.115 0.123 0.164 0.226  ||  -0.374 -0.303 -0.257 -0.086 -0.036 0.027 0.316 0.639  || dis=0.06 || select=7/8
010/019-th : 0.088 0.095 0.106 0.118 0.124 0.150 0.154 0.165  ||  -0.322 -0.246 -0.143 -0.035 0.018 0.208 0.235 0.304   || dis=0.01 || select=7/8
011/019-th : 0.122 0.115 0.111 0.123 0.130 0.132 0.128 0.139  ||  -0.016 -0.078 -0.112 -0.014 0.047 0.057 0.032 0.112   || dis=0.01 || select=7/8
012/019-th : 0.142 0.130 0.124 0.129 0.129 0.118 0.115 0.112  ||  0.141 0.053 0.009 0.042 0.048 -0.040 -0.068 -0.091    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.912 -0.941 -0.918 -0.927 -0.804 -0.552 -0.389 4.869  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.008 0.969  ||  -1.172 -1.182 -1.092 -0.935 -0.740 -0.524 -0.110 4.632  || dis=0.96 || select=7/8
015/019-th : 0.003 0.004 0.003 0.003 0.004 0.004 0.006 0.974  ||  -1.131 -0.771 -0.910 -0.968 -0.712 -0.553 -0.306 4.834  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.033 0.046 0.064 0.161 0.233 0.410  ||  -1.312 -0.934 -0.866 -0.529 -0.201 0.715 1.082 1.649  || dis=0.18 || select=7/8
017/019-th : 0.077 0.089 0.103 0.115 0.129 0.138 0.166 0.184  ||  -0.447 -0.308 -0.163 -0.050 0.067 0.135 0.317 0.420   || dis=0.02 || select=7/8
018/019-th : 0.099 0.101 0.117 0.147 0.136 0.119 0.132 0.148  ||  -0.218 -0.200 -0.051 0.176 0.095 -0.035 0.064 0.179   || dis=0.00 || select=7/8
[epoch=589/600] FLOP : 27.21 MB, ratio : 0.6667, Expected-ratio : 0.7000, Discrepancy : 0.328
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:56:54] [epoch=589/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 1.858 (1.858)  Prec@1 49.61 (49.61) Prec@5 89.84 (89.84) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:57:00] [epoch=589/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.980 (1.669)  Prec@1 10.71 (64.12) Prec@5 64.88 (91.16) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.12 Prec@5 91.16 Error@1 35.88 Error@5 8.84 Loss:1.669
***[2020-01-29 10:57:01]*** VALID [epoch=589/600] loss = 1.668504, accuracy@1 = 64.12, accuracy@5 = 91.16 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:57:01]*** start epoch=590/600 Time Left: [00:05:21], LR=[0.000069 ~ 0.000069], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=590, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10335763985129412, FLOP=40.81
[Search] : epoch=590/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:57:01] [epoch=590/600][000/098] Time 0.69 (0.69) Data 0.41 (0.41) Base-Loss 0.320 (0.320)  Prec@1 89.45 (89.45) Prec@5 99.22 (99.22) Acls-loss 0.522 (0.522) FLOP-Loss 0.000 (0.000) Arch-Loss 0.522 (0.522)
**TRAIN** [2020-01-29 10:57:27] [epoch=590/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.633 (0.314)  Prec@1 84.52 (89.52) Prec@5 99.40 (99.67) Acls-loss 0.703 (0.534) FLOP-Loss 3.036 (0.021) Arch-Loss 6.774 (0.575)
 **TRAIN** Prec@1 89.52 Prec@5 99.67 Error@1 10.48 Error@5 0.33 Base-Loss:0.314, Arch-Loss=0.575
***[2020-01-29 10:57:27]*** TRAIN [epoch=590/600] base-loss = 0.314166, arch-loss = 0.574783, accuracy-1 = 89.52, accuracy-5 = 99.67
[epoch=590/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.114 0.621 0.265  ||  -0.6443 1.0515 0.2022  || discrepancy=0.36 || select=1/3
001/003-th : 0.314 0.343 0.343  ||  0.1055 0.1942 0.1943  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.031 0.963  ||  -2.2924 -0.5824 2.8411  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.008 0.010 0.012 0.017 0.931  ||  -1.200 -0.977 -0.928 -0.866 -0.745 -0.494 -0.158 3.834  || dis=0.91 || select=7/8
001/019-th : 0.072 0.089 0.117 0.114 0.141 0.139 0.169 0.159  ||  -0.525 -0.313 -0.043 -0.065 0.144 0.136 0.330 0.267   || dis=0.01 || select=6/8
002/019-th : 0.093 0.100 0.126 0.118 0.131 0.148 0.152 0.130  ||  -0.277 -0.206 0.024 -0.045 0.062 0.185 0.209 0.053    || dis=0.00 || select=6/8
003/019-th : 0.106 0.103 0.121 0.121 0.131 0.147 0.139 0.131  ||  -0.153 -0.182 -0.028 -0.021 0.059 0.168 0.118 0.053   || dis=0.01 || select=5/8
004/019-th : 0.092 0.102 0.106 0.107 0.132 0.124 0.172 0.164  ||  -0.280 -0.177 -0.139 -0.137 0.074 0.013 0.342 0.296   || dis=0.01 || select=6/8
005/019-th : 0.129 0.119 0.120 0.123 0.130 0.121 0.129 0.128  ||  0.031 -0.045 -0.040 -0.012 0.041 -0.030 0.034 0.023   || dis=0.00 || select=4/8
006/019-th : 0.152 0.141 0.126 0.121 0.128 0.117 0.110 0.106  ||  0.202 0.125 0.013 -0.026 0.030 -0.061 -0.122 -0.155   || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.012 0.014 0.023 0.922  ||  -1.434 -1.133 -1.047 -0.853 -0.536 -0.382 0.094 3.780  || dis=0.90 || select=7/8
008/019-th : 0.004 0.005 0.008 0.010 0.012 0.017 0.028 0.916  ||  -1.603 -1.440 -1.069 -0.802 -0.595 -0.278 0.226 3.720  || dis=0.89 || select=7/8
009/019-th : 0.082 0.088 0.093 0.109 0.115 0.124 0.164 0.225  ||  -0.376 -0.301 -0.253 -0.089 -0.039 0.037 0.319 0.635  || dis=0.06 || select=7/8
010/019-th : 0.089 0.095 0.106 0.117 0.125 0.150 0.154 0.165  ||  -0.318 -0.245 -0.142 -0.037 0.023 0.207 0.232 0.301   || dis=0.01 || select=7/8
011/019-th : 0.123 0.115 0.112 0.119 0.130 0.131 0.130 0.140  ||  -0.014 -0.077 -0.110 -0.044 0.046 0.052 0.044 0.114   || dis=0.01 || select=7/8
012/019-th : 0.142 0.129 0.124 0.129 0.129 0.120 0.116 0.112  ||  0.139 0.045 0.010 0.043 0.043 -0.028 -0.059 -0.097    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.907 -0.939 -0.916 -0.925 -0.802 -0.572 -0.389 4.870  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.005 0.006 0.008 0.969  ||  -1.168 -1.179 -1.089 -0.933 -0.736 -0.522 -0.112 4.627  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.006 0.975  ||  -1.127 -0.791 -0.933 -0.966 -0.718 -0.557 -0.304 4.859  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.032 0.046 0.064 0.162 0.229 0.414  ||  -1.307 -0.928 -0.902 -0.526 -0.201 0.727 1.073 1.662  || dis=0.18 || select=7/8
017/019-th : 0.078 0.088 0.103 0.115 0.127 0.140 0.166 0.184  ||  -0.440 -0.320 -0.161 -0.050 0.049 0.149 0.318 0.421   || dis=0.02 || select=7/8
018/019-th : 0.099 0.103 0.118 0.149 0.135 0.117 0.131 0.147  ||  -0.217 -0.181 -0.047 0.189 0.088 -0.054 0.060 0.177   || dis=0.00 || select=3/8
[epoch=590/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:57:27] [epoch=590/600][000/098] Time 0.39 (0.39) Data 0.31 (0.31) Loss 0.609 (0.609)  Prec@1 80.86 (80.86) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:57:34] [epoch=590/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.684 (1.257)  Prec@1 73.81 (65.38) Prec@5 98.21 (92.31) Size=[168, 3, 32, 32]
 **VALID** Prec@1 65.38 Prec@5 92.31 Error@1 34.62 Error@5 7.69 Loss:1.257
***[2020-01-29 10:57:34]*** VALID [epoch=590/600] loss = 1.257344, accuracy@1 = 65.38, accuracy@5 = 92.31 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:57:34]*** start epoch=591/600 Time Left: [00:04:49], LR=[0.000056 ~ 0.000056], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=591, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10271980634317374, FLOP=40.81
[Search] : epoch=591/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:57:34] [epoch=591/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.336 (0.336)  Prec@1 89.06 (89.06) Prec@5 99.61 (99.61) Acls-loss 0.760 (0.760) FLOP-Loss 3.035 (3.035) Arch-Loss 6.831 (6.831)
**TRAIN** [2020-01-29 10:58:00] [epoch=591/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.336 (0.344)  Prec@1 90.48 (88.54) Prec@5 98.81 (99.59) Acls-loss 0.490 (0.561) FLOP-Loss -3.038 (-0.176) Arch-Loss -5.587 (0.210)
 **TRAIN** Prec@1 88.54 Prec@5 99.59 Error@1 11.46 Error@5 0.41 Base-Loss:0.344, Arch-Loss=0.210
***[2020-01-29 10:58:00]*** TRAIN [epoch=591/600] base-loss = 0.343517, arch-loss = 0.209868, accuracy-1 = 88.54, accuracy-5 = 99.59
[epoch=591/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.113 0.618 0.268  ||  -0.6519 1.0440 0.2095  || discrepancy=0.35 || select=1/3
001/003-th : 0.310 0.345 0.345  ||  0.0947 0.2037 0.2038  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.031 0.963  ||  -2.2892 -0.5850 2.8386  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.008 0.008 0.008 0.010 0.012 0.017 0.931  ||  -1.202 -0.973 -0.936 -0.866 -0.741 -0.488 -0.162 3.841  || dis=0.91 || select=7/8
001/019-th : 0.071 0.089 0.113 0.115 0.139 0.140 0.170 0.162  ||  -0.536 -0.313 -0.069 -0.055 0.138 0.145 0.334 0.289   || dis=0.01 || select=6/8
002/019-th : 0.093 0.099 0.124 0.118 0.132 0.150 0.153 0.131  ||  -0.281 -0.219 0.006 -0.043 0.065 0.195 0.217 0.061    || dis=0.00 || select=6/8
003/019-th : 0.105 0.103 0.119 0.121 0.132 0.147 0.141 0.132  ||  -0.169 -0.186 -0.040 -0.027 0.066 0.173 0.129 0.066   || dis=0.01 || select=5/8
004/019-th : 0.092 0.101 0.107 0.107 0.130 0.124 0.173 0.165  ||  -0.284 -0.189 -0.136 -0.132 0.064 0.014 0.349 0.300   || dis=0.01 || select=6/8
005/019-th : 0.127 0.119 0.119 0.124 0.130 0.122 0.130 0.129  ||  0.020 -0.051 -0.044 -0.008 0.037 -0.022 0.040 0.031   || dis=0.00 || select=6/8
006/019-th : 0.151 0.139 0.122 0.124 0.128 0.118 0.111 0.108  ||  0.194 0.113 -0.018 -0.004 0.033 -0.055 -0.114 -0.143  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.012 0.014 0.023 0.922  ||  -1.433 -1.126 -1.059 -0.850 -0.532 -0.386 0.089 3.784  || dis=0.90 || select=7/8
008/019-th : 0.004 0.005 0.008 0.010 0.012 0.017 0.027 0.917  ||  -1.598 -1.434 -1.079 -0.799 -0.591 -0.286 0.209 3.726  || dis=0.89 || select=7/8
009/019-th : 0.082 0.088 0.092 0.108 0.114 0.124 0.164 0.227  ||  -0.377 -0.307 -0.262 -0.096 -0.042 0.043 0.321 0.646  || dis=0.06 || select=7/8
010/019-th : 0.088 0.095 0.105 0.115 0.126 0.150 0.154 0.166  ||  -0.323 -0.245 -0.146 -0.053 0.032 0.211 0.234 0.309   || dis=0.01 || select=7/8
011/019-th : 0.122 0.113 0.111 0.122 0.130 0.132 0.130 0.140  ||  -0.019 -0.099 -0.110 -0.020 0.044 0.061 0.042 0.118   || dis=0.01 || select=7/8
012/019-th : 0.141 0.128 0.123 0.129 0.129 0.121 0.117 0.113  ||  0.132 0.038 -0.004 0.041 0.043 -0.022 -0.052 -0.087   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.919 -0.937 -0.914 -0.923 -0.805 -0.569 -0.390 4.871  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.178 -1.185 -1.086 -0.946 -0.760 -0.513 -0.112 4.652  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.124 -0.790 -0.931 -0.984 -0.715 -0.558 -0.322 4.869  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.032 0.046 0.064 0.164 0.227 0.417  ||  -1.315 -0.940 -0.902 -0.532 -0.200 0.739 1.066 1.674  || dis=0.19 || select=7/8
017/019-th : 0.079 0.086 0.102 0.114 0.126 0.140 0.168 0.184  ||  -0.424 -0.335 -0.165 -0.059 0.042 0.150 0.329 0.420   || dis=0.02 || select=7/8
018/019-th : 0.099 0.102 0.120 0.149 0.136 0.116 0.131 0.148  ||  -0.224 -0.189 -0.030 0.187 0.095 -0.059 0.059 0.179   || dis=0.00 || select=3/8
[epoch=591/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.328
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:58:00] [epoch=591/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 2.647 (2.647)  Prec@1 34.38 (34.38) Prec@5 79.69 (79.69) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:58:07] [epoch=591/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 1.084 (1.471)  Prec@1 64.88 (64.33) Prec@5 97.02 (92.49) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.33 Prec@5 92.49 Error@1 35.67 Error@5 7.51 Loss:1.471
***[2020-01-29 10:58:07]*** VALID [epoch=591/600] loss = 1.470700, accuracy@1 = 64.33, accuracy@5 = 92.49 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:58:07]*** start epoch=592/600 Time Left: [00:04:17], LR=[0.000044 ~ 0.000044], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=592, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10214906625779696, FLOP=40.81
[Search] : epoch=592/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:58:08] [epoch=592/600][000/098] Time 0.67 (0.67) Data 0.38 (0.38) Base-Loss 0.318 (0.318)  Prec@1 87.89 (87.89) Prec@5 100.00 (100.00) Acls-loss 0.460 (0.460) FLOP-Loss 3.039 (3.039) Arch-Loss 6.537 (6.537)
**TRAIN** [2020-01-29 10:58:33] [epoch=592/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.224 (0.352)  Prec@1 94.05 (88.14) Prec@5 100.00 (99.59) Acls-loss 0.595 (0.519) FLOP-Loss 0.000 (-0.093) Arch-Loss 0.595 (0.333)
 **TRAIN** Prec@1 88.14 Prec@5 99.59 Error@1 11.86 Error@5 0.41 Base-Loss:0.352, Arch-Loss=0.333
***[2020-01-29 10:58:33]*** TRAIN [epoch=592/600] base-loss = 0.351725, arch-loss = 0.332658, accuracy-1 = 88.14, accuracy-5 = 99.59
[epoch=592/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 27.210368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.113 0.617 0.270  ||  -0.6562 1.0402 0.2128  || discrepancy=0.35 || select=1/3
001/003-th : 0.306 0.348 0.345  ||  0.0877 0.2173 0.2083  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.031 0.963  ||  -2.2857 -0.5982 2.8391  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.012 0.017 0.932  ||  -1.196 -0.976 -0.940 -0.882 -0.738 -0.495 -0.162 3.853  || dis=0.92 || select=7/8
001/019-th : 0.070 0.088 0.113 0.113 0.139 0.140 0.173 0.164  ||  -0.552 -0.315 -0.073 -0.074 0.135 0.145 0.356 0.302   || dis=0.01 || select=6/8
002/019-th : 0.093 0.099 0.123 0.117 0.132 0.150 0.155 0.132  ||  -0.285 -0.221 0.000 -0.049 0.064 0.196 0.226 0.065    || dis=0.01 || select=6/8
003/019-th : 0.104 0.103 0.118 0.120 0.134 0.147 0.142 0.134  ||  -0.177 -0.188 -0.048 -0.034 0.082 0.168 0.134 0.076   || dis=0.01 || select=5/8
004/019-th : 0.092 0.101 0.106 0.109 0.129 0.125 0.173 0.166  ||  -0.287 -0.190 -0.144 -0.120 0.052 0.019 0.348 0.306   || dis=0.01 || select=6/8
005/019-th : 0.127 0.118 0.120 0.124 0.130 0.121 0.130 0.131  ||  0.016 -0.058 -0.045 -0.009 0.037 -0.033 0.042 0.047   || dis=0.00 || select=7/8
006/019-th : 0.150 0.138 0.121 0.123 0.130 0.118 0.112 0.108  ||  0.188 0.108 -0.025 -0.014 0.041 -0.050 -0.108 -0.138  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.011 0.014 0.022 0.925  ||  -1.429 -1.118 -1.054 -0.873 -0.578 -0.385 0.083 3.813  || dis=0.90 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.012 0.016 0.027 0.918  ||  -1.593 -1.439 -1.074 -0.810 -0.588 -0.305 0.207 3.737  || dis=0.89 || select=7/8
009/019-th : 0.081 0.087 0.091 0.107 0.113 0.125 0.165 0.230  ||  -0.390 -0.308 -0.265 -0.109 -0.048 0.050 0.329 0.659  || dis=0.07 || select=7/8
010/019-th : 0.087 0.095 0.105 0.115 0.125 0.153 0.154 0.167  ||  -0.339 -0.251 -0.151 -0.059 0.024 0.231 0.238 0.318   || dis=0.01 || select=7/8
011/019-th : 0.122 0.112 0.112 0.122 0.130 0.131 0.130 0.140  ||  -0.017 -0.103 -0.108 -0.017 0.046 0.048 0.044 0.119   || dis=0.01 || select=7/8
012/019-th : 0.140 0.128 0.122 0.129 0.128 0.121 0.119 0.114  ||  0.126 0.033 -0.008 0.043 0.037 -0.020 -0.041 -0.083   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.914 -0.934 -0.912 -0.921 -0.803 -0.567 -0.389 4.866  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.174 -1.182 -1.082 -0.943 -0.761 -0.512 -0.115 4.648  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.120 -0.789 -0.929 -0.985 -0.711 -0.557 -0.321 4.867  || dis=0.97 || select=7/8
016/019-th : 0.021 0.030 0.032 0.046 0.064 0.163 0.226 0.418  ||  -1.321 -0.946 -0.895 -0.521 -0.201 0.736 1.061 1.678  || dis=0.19 || select=7/8
017/019-th : 0.079 0.086 0.102 0.115 0.125 0.140 0.168 0.185  ||  -0.427 -0.340 -0.167 -0.051 0.037 0.148 0.329 0.426   || dis=0.02 || select=7/8
018/019-th : 0.098 0.102 0.119 0.147 0.137 0.116 0.133 0.148  ||  -0.229 -0.188 -0.035 0.177 0.101 -0.065 0.078 0.180   || dis=0.00 || select=7/8
[epoch=592/600] FLOP : 27.21 MB, ratio : 0.6667, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:58:33] [epoch=592/600][000/098] Time 0.39 (0.39) Data 0.30 (0.30) Loss 0.525 (0.525)  Prec@1 82.03 (82.03) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:58:39] [epoch=592/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 8.263 (1.568)  Prec@1 10.71 (64.12) Prec@5 54.17 (91.50) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.12 Prec@5 91.50 Error@1 35.88 Error@5 8.50 Loss:1.568
***[2020-01-29 10:58:39]*** VALID [epoch=592/600] loss = 1.567735, accuracy@1 = 64.12, accuracy@5 = 91.50 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:58:39]*** start epoch=593/600 Time Left: [00:03:44], LR=[0.000034 ~ 0.000034], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=593, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10164543524229223, FLOP=40.81
[Search] : epoch=593/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:58:40] [epoch=593/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.358 (0.358)  Prec@1 89.45 (89.45) Prec@5 100.00 (100.00) Acls-loss 0.535 (0.535) FLOP-Loss 0.000 (0.000) Arch-Loss 0.535 (0.535)
**TRAIN** [2020-01-29 10:59:05] [epoch=593/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.556 (0.374)  Prec@1 88.10 (87.53) Prec@5 100.00 (99.45) Acls-loss 0.523 (0.511) FLOP-Loss 3.040 (0.239) Arch-Loss 6.604 (0.988)
 **TRAIN** Prec@1 87.53 Prec@5 99.45 Error@1 12.47 Error@5 0.55 Base-Loss:0.374, Arch-Loss=0.988
***[2020-01-29 10:59:05]*** TRAIN [epoch=593/600] base-loss = 0.374380, arch-loss = 0.987870, accuracy-1 = 87.53, accuracy-5 = 99.45
[epoch=593/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 26.407292)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.114 0.617 0.269  ||  -0.6490 1.0377 0.2072  || discrepancy=0.35 || select=1/3
001/003-th : 0.309 0.345 0.345  ||  0.0931 0.2042 0.2040  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.031 0.964  ||  -2.2817 -0.6104 2.8391  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.012 0.016 0.934  ||  -1.199 -0.985 -0.935 -0.890 -0.733 -0.511 -0.170 3.867  || dis=0.92 || select=7/8
001/019-th : 0.070 0.089 0.113 0.112 0.138 0.140 0.173 0.165  ||  -0.546 -0.306 -0.076 -0.085 0.126 0.146 0.352 0.307   || dis=0.01 || select=6/8
002/019-th : 0.091 0.099 0.122 0.118 0.131 0.151 0.158 0.130  ||  -0.298 -0.218 -0.012 -0.043 0.060 0.204 0.251 0.057   || dis=0.01 || select=6/8
003/019-th : 0.104 0.104 0.116 0.121 0.132 0.147 0.141 0.135  ||  -0.179 -0.177 -0.063 -0.024 0.066 0.174 0.127 0.085   || dis=0.01 || select=5/8
004/019-th : 0.092 0.102 0.107 0.108 0.128 0.125 0.174 0.166  ||  -0.287 -0.186 -0.135 -0.128 0.044 0.018 0.353 0.302   || dis=0.01 || select=6/8
005/019-th : 0.128 0.118 0.121 0.124 0.129 0.121 0.129 0.130  ||  0.024 -0.053 -0.034 -0.004 0.033 -0.035 0.033 0.037   || dis=0.00 || select=7/8
006/019-th : 0.151 0.139 0.122 0.123 0.129 0.117 0.111 0.108  ||  0.194 0.113 -0.021 -0.014 0.037 -0.060 -0.113 -0.139  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.008 0.011 0.014 0.021 0.926  ||  -1.424 -1.108 -1.071 -0.876 -0.575 -0.385 0.060 3.823  || dis=0.91 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.012 0.016 0.026 0.919  ||  -1.595 -1.452 -1.068 -0.807 -0.585 -0.304 0.193 3.746  || dis=0.89 || select=7/8
009/019-th : 0.082 0.089 0.090 0.106 0.114 0.124 0.166 0.231  ||  -0.378 -0.295 -0.279 -0.120 -0.045 0.038 0.329 0.662  || dis=0.07 || select=7/8
010/019-th : 0.088 0.095 0.105 0.115 0.125 0.152 0.153 0.166  ||  -0.330 -0.244 -0.148 -0.057 0.026 0.223 0.231 0.311   || dis=0.01 || select=7/8
011/019-th : 0.123 0.113 0.112 0.122 0.130 0.130 0.129 0.140  ||  -0.010 -0.102 -0.106 -0.017 0.045 0.042 0.036 0.118   || dis=0.01 || select=7/8
012/019-th : 0.140 0.128 0.124 0.129 0.127 0.121 0.118 0.113  ||  0.129 0.039 0.002 0.048 0.027 -0.018 -0.048 -0.090    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.908 -0.940 -0.909 -0.919 -0.802 -0.564 -0.390 4.865  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.008 0.970  ||  -1.170 -1.179 -1.078 -0.944 -0.760 -0.530 -0.114 4.652  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.116 -0.788 -0.927 -0.983 -0.707 -0.556 -0.319 4.862  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.032 0.046 0.065 0.164 0.225 0.417  ||  -1.331 -0.937 -0.894 -0.519 -0.190 0.742 1.059 1.675  || dis=0.19 || select=7/8
017/019-th : 0.079 0.086 0.103 0.115 0.125 0.140 0.166 0.185  ||  -0.422 -0.337 -0.161 -0.049 0.030 0.148 0.320 0.426   || dis=0.02 || select=7/8
018/019-th : 0.098 0.101 0.118 0.148 0.138 0.116 0.134 0.147  ||  -0.226 -0.197 -0.044 0.181 0.111 -0.062 0.079 0.177   || dis=0.00 || select=3/8
[epoch=593/600] FLOP : 26.41 MB, ratio : 0.6470, Expected-ratio : 0.7000, Discrepancy : 0.330
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:59:05] [epoch=593/600][000/098] Time 0.37 (0.37) Data 0.28 (0.28) Loss 1.927 (1.927)  Prec@1 40.62 (40.62) Prec@5 88.28 (88.28) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:59:11] [epoch=593/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 0.516 (1.400)  Prec@1 81.55 (64.15) Prec@5 98.21 (91.48) Size=[168, 3, 32, 32]
 **VALID** Prec@1 64.15 Prec@5 91.48 Error@1 35.85 Error@5 8.52 Loss:1.400
***[2020-01-29 10:59:11]*** VALID [epoch=593/600] loss = 1.399804, accuracy@1 = 64.15, accuracy@5 = 91.48 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:59:11]*** start epoch=594/600 Time Left: [00:03:12], LR=[0.000025 ~ 0.000025], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=594, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10120892710395758, FLOP=40.81
[Search] : epoch=594/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:59:12] [epoch=594/600][000/098] Time 0.65 (0.65) Data 0.36 (0.36) Base-Loss 0.691 (0.691)  Prec@1 75.39 (75.39) Prec@5 99.22 (99.22) Acls-loss 0.510 (0.510) FLOP-Loss -3.040 (-3.040) Arch-Loss -5.570 (-5.570)
**TRAIN** [2020-01-29 10:59:38] [epoch=594/600][097/098] Time 0.25 (0.27) Data 0.00 (0.00) Base-Loss 0.379 (0.342)  Prec@1 85.12 (88.56) Prec@5 100.00 (99.58) Acls-loss 0.436 (0.517) FLOP-Loss -3.041 (-0.114) Arch-Loss -5.646 (0.289)
 **TRAIN** Prec@1 88.56 Prec@5 99.58 Error@1 11.44 Error@5 0.42 Base-Loss:0.342, Arch-Loss=0.289
***[2020-01-29 10:59:38]*** TRAIN [epoch=594/600] base-loss = 0.341915, arch-loss = 0.289480, accuracy-1 = 88.56, accuracy-5 = 99.58
[epoch=594/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 30.306944)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.114 0.614 0.272  ||  -0.6527 1.0284 0.2126  || discrepancy=0.34 || select=1/3
001/003-th : 0.308 0.346 0.346  ||  0.0894 0.2065 0.2069  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.031 0.963  ||  -2.2777 -0.6092 2.8351  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.012 0.016 0.934  ||  -1.193 -0.987 -0.931 -0.886 -0.728 -0.521 -0.180 3.869  || dis=0.92 || select=7/8
001/019-th : 0.070 0.089 0.112 0.112 0.138 0.140 0.172 0.166  ||  -0.545 -0.311 -0.080 -0.080 0.125 0.143 0.348 0.314   || dis=0.01 || select=6/8
002/019-th : 0.091 0.098 0.121 0.118 0.130 0.151 0.159 0.133  ||  -0.306 -0.226 -0.020 -0.043 0.056 0.205 0.254 0.075   || dis=0.01 || select=6/8
003/019-th : 0.103 0.103 0.117 0.120 0.132 0.148 0.141 0.136  ||  -0.185 -0.182 -0.061 -0.036 0.067 0.179 0.132 0.090   || dis=0.01 || select=5/8
004/019-th : 0.092 0.101 0.107 0.108 0.126 0.124 0.175 0.167  ||  -0.291 -0.196 -0.130 -0.126 0.030 0.014 0.356 0.314   || dis=0.01 || select=6/8
005/019-th : 0.127 0.118 0.121 0.124 0.130 0.121 0.129 0.130  ||  0.021 -0.057 -0.034 -0.005 0.037 -0.033 0.034 0.039   || dis=0.00 || select=7/8
006/019-th : 0.150 0.139 0.121 0.122 0.129 0.118 0.112 0.109  ||  0.189 0.107 -0.024 -0.018 0.039 -0.056 -0.108 -0.132  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.011 0.014 0.022 0.926  ||  -1.420 -1.101 -1.077 -0.868 -0.573 -0.382 0.059 3.818  || dis=0.90 || select=7/8
008/019-th : 0.004 0.005 0.008 0.010 0.012 0.016 0.026 0.919  ||  -1.589 -1.446 -1.063 -0.803 -0.585 -0.308 0.193 3.742  || dis=0.89 || select=7/8
009/019-th : 0.081 0.089 0.090 0.105 0.114 0.122 0.165 0.232  ||  -0.381 -0.294 -0.277 -0.122 -0.044 0.027 0.328 0.668  || dis=0.07 || select=7/8
010/019-th : 0.088 0.096 0.105 0.114 0.128 0.152 0.150 0.167  ||  -0.329 -0.243 -0.146 -0.064 0.049 0.222 0.209 0.315   || dis=0.02 || select=7/8
011/019-th : 0.125 0.113 0.112 0.122 0.129 0.131 0.130 0.139  ||  0.002 -0.096 -0.107 -0.020 0.036 0.047 0.040 0.110    || dis=0.01 || select=7/8
012/019-th : 0.140 0.128 0.125 0.128 0.129 0.121 0.116 0.113  ||  0.128 0.036 0.010 0.035 0.047 -0.021 -0.058 -0.087    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.902 -0.937 -0.907 -0.921 -0.800 -0.561 -0.388 4.861  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.005 0.008 0.969  ||  -1.166 -1.176 -1.080 -0.941 -0.758 -0.528 -0.114 4.649  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.111 -0.787 -0.924 -0.981 -0.704 -0.571 -0.319 4.866  || dis=0.97 || select=7/8
016/019-th : 0.021 0.030 0.032 0.047 0.065 0.164 0.224 0.417  ||  -1.331 -0.951 -0.887 -0.510 -0.185 0.743 1.055 1.674  || dis=0.19 || select=7/8
017/019-th : 0.079 0.086 0.102 0.115 0.123 0.140 0.167 0.188  ||  -0.423 -0.345 -0.170 -0.054 0.016 0.148 0.325 0.440   || dis=0.02 || select=7/8
018/019-th : 0.098 0.100 0.118 0.149 0.138 0.115 0.134 0.149  ||  -0.230 -0.207 -0.043 0.187 0.112 -0.071 0.082 0.188   || dis=0.00 || select=7/8
[epoch=594/600] FLOP : 30.31 MB, ratio : 0.7426, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 10:59:38] [epoch=594/600][000/098] Time 0.48 (0.48) Data 0.28 (0.28) Loss 0.617 (0.617)  Prec@1 79.69 (79.69) Prec@5 98.83 (98.83) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 10:59:45] [epoch=594/600][097/098] Time 0.06 (0.07) Data 0.00 (0.00) Loss 4.787 (1.604)  Prec@1 41.67 (60.86) Prec@5 82.74 (89.99) Size=[168, 3, 32, 32]
 **VALID** Prec@1 60.86 Prec@5 89.99 Error@1 39.14 Error@5 10.01 Loss:1.604
***[2020-01-29 10:59:45]*** VALID [epoch=594/600] loss = 1.604393, accuracy@1 = 60.86, accuracy@5 = 89.99 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 10:59:45]*** start epoch=595/600 Time Left: [00:02:40], LR=[0.000017 ~ 0.000017], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=595, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10083955380988471, FLOP=40.81
[Search] : epoch=595/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 10:59:45] [epoch=595/600][000/098] Time 0.66 (0.66) Data 0.37 (0.37) Base-Loss 0.449 (0.449)  Prec@1 83.59 (83.59) Prec@5 99.22 (99.22) Acls-loss 0.433 (0.433) FLOP-Loss 3.041 (3.041) Arch-Loss 6.516 (6.516)
**TRAIN** [2020-01-29 11:00:10] [epoch=595/600][097/098] Time 0.25 (0.26) Data 0.00 (0.00) Base-Loss 0.397 (0.321)  Prec@1 85.71 (89.28) Prec@5 99.40 (99.67) Acls-loss 0.418 (0.526) FLOP-Loss -3.044 (-0.145) Arch-Loss -5.670 (0.236)
 **TRAIN** Prec@1 89.28 Prec@5 99.67 Error@1 10.72 Error@5 0.33 Base-Loss:0.321, Arch-Loss=0.236
***[2020-01-29 11:00:11]*** TRAIN [epoch=595/600] base-loss = 0.320956, arch-loss = 0.235697, accuracy-1 = 89.28, accuracy-5 = 99.67
[epoch=595/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 26.407292)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.113 0.612 0.275  ||  -0.6649 1.0232 0.2221  || discrepancy=0.34 || select=1/3
001/003-th : 0.304 0.348 0.348  ||  0.0803 0.2148 0.2146  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.031 0.963  ||  -2.2738 -0.6081 2.8312  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.011 0.016 0.935  ||  -1.189 -0.999 -0.927 -0.883 -0.728 -0.552 -0.185 3.882  || dis=0.92 || select=7/8
001/019-th : 0.071 0.088 0.113 0.113 0.138 0.140 0.171 0.167  ||  -0.540 -0.321 -0.077 -0.075 0.126 0.143 0.341 0.316   || dis=0.00 || select=6/8
002/019-th : 0.090 0.096 0.117 0.117 0.131 0.153 0.160 0.135  ||  -0.311 -0.244 -0.047 -0.046 0.060 0.221 0.261 0.093   || dis=0.01 || select=6/8
003/019-th : 0.102 0.102 0.116 0.119 0.133 0.148 0.142 0.137  ||  -0.195 -0.191 -0.065 -0.042 0.073 0.176 0.140 0.104   || dis=0.01 || select=5/8
004/019-th : 0.089 0.100 0.108 0.107 0.126 0.125 0.175 0.169  ||  -0.317 -0.199 -0.123 -0.128 0.029 0.027 0.362 0.324   || dis=0.01 || select=6/8
005/019-th : 0.127 0.118 0.119 0.124 0.131 0.121 0.130 0.131  ||  0.014 -0.055 -0.051 -0.007 0.045 -0.033 0.043 0.045   || dis=0.00 || select=4/8
006/019-th : 0.149 0.137 0.120 0.123 0.129 0.119 0.113 0.110  ||  0.178 0.098 -0.035 -0.012 0.039 -0.047 -0.097 -0.125  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.011 0.014 0.021 0.926  ||  -1.415 -1.119 -1.073 -0.866 -0.570 -0.380 0.052 3.823  || dis=0.91 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.012 0.016 0.026 0.919  ||  -1.585 -1.441 -1.078 -0.800 -0.582 -0.306 0.191 3.745  || dis=0.89 || select=7/8
009/019-th : 0.081 0.089 0.090 0.103 0.114 0.125 0.165 0.234  ||  -0.388 -0.295 -0.278 -0.141 -0.045 0.048 0.328 0.677  || dis=0.07 || select=7/8
010/019-th : 0.087 0.094 0.105 0.114 0.130 0.152 0.149 0.167  ||  -0.334 -0.255 -0.148 -0.063 0.069 0.224 0.203 0.317   || dis=0.02 || select=7/8
011/019-th : 0.124 0.113 0.112 0.121 0.129 0.132 0.130 0.139  ||  -0.004 -0.100 -0.109 -0.027 0.039 0.058 0.043 0.114   || dis=0.01 || select=7/8
012/019-th : 0.139 0.127 0.124 0.128 0.130 0.121 0.117 0.114  ||  0.120 0.028 0.004 0.037 0.052 -0.018 -0.052 -0.079    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.897 -0.934 -0.905 -0.920 -0.808 -0.559 -0.387 4.862  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.162 -1.173 -1.076 -0.938 -0.757 -0.527 -0.113 4.644  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.107 -0.785 -0.922 -0.979 -0.700 -0.570 -0.318 4.862  || dis=0.97 || select=7/8
016/019-th : 0.021 0.030 0.032 0.047 0.065 0.163 0.225 0.416  ||  -1.322 -0.947 -0.887 -0.518 -0.181 0.736 1.057 1.672  || dis=0.19 || select=7/8
017/019-th : 0.078 0.085 0.102 0.113 0.121 0.141 0.169 0.190  ||  -0.434 -0.348 -0.171 -0.066 0.003 0.156 0.336 0.450   || dis=0.02 || select=7/8
018/019-th : 0.098 0.101 0.119 0.149 0.136 0.115 0.134 0.147  ||  -0.234 -0.196 -0.032 0.188 0.097 -0.068 0.084 0.178   || dis=0.00 || select=3/8
[epoch=595/600] FLOP : 26.41 MB, ratio : 0.6470, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 11:00:11] [epoch=595/600][000/098] Time 0.37 (0.37) Data 0.29 (0.29) Loss 0.580 (0.580)  Prec@1 79.69 (79.69) Prec@5 99.22 (99.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 11:00:17] [epoch=595/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.754 (2.208)  Prec@1 44.05 (55.93) Prec@5 88.10 (87.84) Size=[168, 3, 32, 32]
 **VALID** Prec@1 55.93 Prec@5 87.84 Error@1 44.07 Error@5 12.16 Loss:2.208
***[2020-01-29 11:00:17]*** VALID [epoch=595/600] loss = 2.208128, accuracy@1 = 55.93, accuracy@5 = 87.84 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 11:00:17]*** start epoch=596/600 Time Left: [00:02:08], LR=[0.000011 ~ 0.000011], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=596, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10053732548662853, FLOP=40.81
[Search] : epoch=596/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 11:00:18] [epoch=596/600][000/098] Time 0.63 (0.63) Data 0.34 (0.34) Base-Loss 0.322 (0.322)  Prec@1 88.67 (88.67) Prec@5 100.00 (100.00) Acls-loss 0.685 (0.685) FLOP-Loss -3.044 (-3.044) Arch-Loss -5.403 (-5.403)
**TRAIN** [2020-01-29 11:00:42] [epoch=596/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.256 (0.327)  Prec@1 92.86 (88.96) Prec@5 99.40 (99.62) Acls-loss 0.424 (0.552) FLOP-Loss 3.044 (0.114) Arch-Loss 6.513 (0.780)
 **TRAIN** Prec@1 88.96 Prec@5 99.62 Error@1 11.04 Error@5 0.38 Base-Loss:0.327, Arch-Loss=0.780
***[2020-01-29 11:00:42]*** TRAIN [epoch=596/600] base-loss = 0.326812, arch-loss = 0.780360, accuracy-1 = 88.96, accuracy-5 = 99.62
[epoch=596/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 11, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 3, 3]), ('estimated_FLOP', 29.503868)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.112 0.615 0.274  ||  -0.6732 1.0317 0.2225  || discrepancy=0.34 || select=1/3
001/003-th : 0.305 0.348 0.348  ||  0.0809 0.2128 0.2134  || discrepancy=0.00 || select=2/3
002/003-th : 0.006 0.030 0.965  ||  -2.2830 -0.6354 2.8495  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.011 0.016 0.936  ||  -1.210 -0.992 -0.919 -0.879 -0.730 -0.548 -0.192 3.892  || dis=0.92 || select=7/8
001/019-th : 0.071 0.089 0.113 0.112 0.138 0.141 0.170 0.166  ||  -0.535 -0.317 -0.072 -0.085 0.125 0.149 0.337 0.311   || dis=0.00 || select=6/8
002/019-th : 0.091 0.097 0.117 0.117 0.131 0.153 0.159 0.136  ||  -0.306 -0.237 -0.055 -0.050 0.060 0.215 0.256 0.099   || dis=0.01 || select=6/8
003/019-th : 0.102 0.103 0.116 0.118 0.134 0.147 0.143 0.137  ||  -0.190 -0.185 -0.063 -0.053 0.075 0.170 0.143 0.100   || dis=0.00 || select=5/8
004/019-th : 0.087 0.097 0.108 0.108 0.131 0.126 0.173 0.171  ||  -0.336 -0.223 -0.120 -0.123 0.071 0.030 0.351 0.337   || dis=0.00 || select=6/8
005/019-th : 0.123 0.117 0.120 0.127 0.130 0.123 0.129 0.129  ||  -0.010 -0.062 -0.038 0.019 0.044 -0.011 0.037 0.037   || dis=0.00 || select=4/8
006/019-th : 0.149 0.137 0.121 0.124 0.128 0.119 0.113 0.110  ||  0.180 0.093 -0.032 -0.005 0.028 -0.046 -0.092 -0.126  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.012 0.014 0.021 0.926  ||  -1.410 -1.114 -1.068 -0.864 -0.567 -0.377 0.034 3.821  || dis=0.91 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.012 0.016 0.026 0.919  ||  -1.578 -1.435 -1.073 -0.794 -0.580 -0.315 0.169 3.745  || dis=0.89 || select=7/8
009/019-th : 0.080 0.089 0.090 0.102 0.114 0.125 0.164 0.235  ||  -0.393 -0.289 -0.277 -0.152 -0.039 0.051 0.324 0.682  || dis=0.07 || select=7/8
010/019-th : 0.088 0.094 0.105 0.113 0.131 0.151 0.149 0.168  ||  -0.324 -0.254 -0.150 -0.074 0.073 0.217 0.203 0.320   || dis=0.02 || select=7/8
011/019-th : 0.124 0.113 0.112 0.119 0.129 0.134 0.130 0.138  ||  -0.002 -0.095 -0.107 -0.045 0.039 0.075 0.043 0.105   || dis=0.00 || select=7/8
012/019-th : 0.138 0.127 0.124 0.128 0.131 0.121 0.118 0.114  ||  0.115 0.032 0.004 0.035 0.057 -0.023 -0.044 -0.082    || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.890 -0.931 -0.902 -0.918 -0.806 -0.557 -0.385 4.856  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.166 -1.170 -1.079 -0.937 -0.755 -0.525 -0.115 4.645  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.127 -0.785 -0.919 -0.976 -0.696 -0.569 -0.321 4.866  || dis=0.97 || select=7/8
016/019-th : 0.021 0.031 0.032 0.047 0.066 0.163 0.225 0.416  ||  -1.333 -0.940 -0.879 -0.516 -0.176 0.732 1.057 1.672  || dis=0.19 || select=7/8
017/019-th : 0.078 0.086 0.102 0.113 0.120 0.140 0.169 0.192  ||  -0.436 -0.341 -0.170 -0.073 -0.005 0.148 0.333 0.460  || dis=0.02 || select=7/8
018/019-th : 0.096 0.102 0.118 0.149 0.136 0.115 0.136 0.147  ||  -0.249 -0.192 -0.039 0.191 0.100 -0.066 0.099 0.177   || dis=0.00 || select=3/8
[epoch=596/600] FLOP : 29.50 MB, ratio : 0.7229, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 11:00:42] [epoch=596/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.796 (0.796)  Prec@1 78.91 (78.91) Prec@5 97.66 (97.66) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 11:00:48] [epoch=596/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.167 (1.455)  Prec@1 60.12 (63.75) Prec@5 94.64 (91.45) Size=[168, 3, 32, 32]
 **VALID** Prec@1 63.75 Prec@5 91.45 Error@1 36.25 Error@5 8.55 Loss:1.455
***[2020-01-29 11:00:48]*** VALID [epoch=596/600] loss = 1.454651, accuracy@1 = 63.75, accuracy@5 = 91.45 | Best-Valid-Acc@1=69.00, Error@1=31.00
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 11:00:48]*** start epoch=597/600 Time Left: [00:01:36], LR=[0.000006 ~ 0.000006], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=597, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10030225041993157, FLOP=40.81
[Search] : epoch=597/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 11:00:49] [epoch=597/600][000/098] Time 0.64 (0.64) Data 0.37 (0.37) Base-Loss 0.243 (0.243)  Prec@1 91.02 (91.02) Prec@5 99.61 (99.61) Acls-loss 0.489 (0.489) FLOP-Loss 3.044 (3.044) Arch-Loss 6.577 (6.577)
**TRAIN** [2020-01-29 11:01:14] [epoch=597/600][097/098] Time 0.24 (0.26) Data 0.00 (0.00) Base-Loss 0.318 (0.351)  Prec@1 88.69 (88.11) Prec@5 99.40 (99.57) Acls-loss 0.476 (0.498) FLOP-Loss -3.050 (-0.488) Arch-Loss -5.624 (-0.479)
 **TRAIN** Prec@1 88.11 Prec@5 99.57 Error@1 11.89 Error@5 0.43 Base-Loss:0.351, Arch-Loss=-0.479
***[2020-01-29 11:01:14]*** TRAIN [epoch=597/600] base-loss = 0.351377, arch-loss = -0.479079, accuracy-1 = 88.11, accuracy-5 = 99.57
[epoch=597/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 26.407292)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.109 0.612 0.279  ||  -0.7012 1.0269 0.2433  || discrepancy=0.33 || select=1/3
001/003-th : 0.296 0.352 0.352  ||  0.0596 0.2326 0.2326  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.029 0.965  ||  -2.2857 -0.6411 2.8541  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.011 0.016 0.935  ||  -1.205 -0.986 -0.924 -0.881 -0.725 -0.546 -0.180 3.888  || dis=0.92 || select=7/8
001/019-th : 0.070 0.089 0.112 0.110 0.137 0.142 0.171 0.169  ||  -0.545 -0.317 -0.081 -0.096 0.117 0.154 0.344 0.328   || dis=0.00 || select=6/8
002/019-th : 0.090 0.096 0.115 0.116 0.131 0.153 0.160 0.138  ||  -0.317 -0.247 -0.066 -0.055 0.064 0.221 0.264 0.115   || dis=0.01 || select=6/8
003/019-th : 0.101 0.100 0.115 0.116 0.136 0.148 0.145 0.138  ||  -0.203 -0.210 -0.072 -0.060 0.096 0.183 0.163 0.108   || dis=0.00 || select=5/8
004/019-th : 0.086 0.096 0.107 0.107 0.131 0.126 0.175 0.172  ||  -0.348 -0.233 -0.128 -0.128 0.073 0.039 0.364 0.345   || dis=0.00 || select=6/8
005/019-th : 0.122 0.115 0.119 0.127 0.129 0.125 0.131 0.130  ||  -0.017 -0.077 -0.045 0.018 0.038 0.002 0.052 0.046    || dis=0.00 || select=6/8
006/019-th : 0.146 0.134 0.119 0.124 0.129 0.120 0.116 0.111  ||  0.162 0.074 -0.045 -0.007 0.036 -0.035 -0.069 -0.113  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.009 0.011 0.014 0.021 0.926  ||  -1.406 -1.109 -1.093 -0.866 -0.576 -0.347 0.033 3.824  || dis=0.91 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.012 0.016 0.025 0.922  ||  -1.582 -1.429 -1.091 -0.791 -0.602 -0.314 0.155 3.768  || dis=0.90 || select=7/8
009/019-th : 0.079 0.085 0.089 0.104 0.113 0.125 0.166 0.239  ||  -0.403 -0.332 -0.284 -0.129 -0.048 0.051 0.334 0.700  || dis=0.07 || select=7/8
010/019-th : 0.088 0.094 0.104 0.113 0.130 0.152 0.150 0.170  ||  -0.329 -0.261 -0.159 -0.077 0.067 0.222 0.211 0.334   || dis=0.02 || select=7/8
011/019-th : 0.121 0.111 0.111 0.118 0.129 0.134 0.134 0.140  ||  -0.023 -0.108 -0.109 -0.048 0.038 0.079 0.074 0.121   || dis=0.01 || select=7/8
012/019-th : 0.136 0.126 0.122 0.127 0.132 0.122 0.120 0.116  ||  0.096 0.019 -0.010 0.028 0.067 -0.009 -0.029 -0.066   || dis=0.00 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.976  ||  -0.884 -0.925 -0.924 -0.916 -0.804 -0.555 -0.412 4.878  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.163 -1.169 -1.075 -0.935 -0.754 -0.524 -0.114 4.641  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.124 -0.784 -0.917 -0.975 -0.692 -0.568 -0.319 4.862  || dis=0.97 || select=7/8
016/019-th : 0.020 0.030 0.032 0.047 0.065 0.162 0.223 0.421  ||  -1.344 -0.953 -0.873 -0.513 -0.186 0.734 1.054 1.689  || dis=0.20 || select=7/8
017/019-th : 0.077 0.085 0.100 0.111 0.120 0.140 0.170 0.195  ||  -0.446 -0.351 -0.186 -0.082 -0.006 0.149 0.344 0.477  || dis=0.02 || select=7/8
018/019-th : 0.094 0.100 0.118 0.149 0.138 0.115 0.139 0.148  ||  -0.265 -0.212 -0.043 0.190 0.112 -0.069 0.123 0.185   || dis=0.00 || select=3/8
[epoch=597/600] FLOP : 26.41 MB, ratio : 0.6470, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 11:01:14] [epoch=597/600][000/098] Time 0.35 (0.35) Data 0.27 (0.27) Loss 1.804 (1.804)  Prec@1 50.78 (50.78) Prec@5 91.02 (91.02) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 11:01:20] [epoch=597/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 4.149 (1.282)  Prec@1 17.86 (69.46) Prec@5 70.24 (93.97) Size=[168, 3, 32, 32]
 **VALID** Prec@1 69.46 Prec@5 93.97 Error@1 30.54 Error@5 6.03 Loss:1.282
***[2020-01-29 11:01:20]*** VALID [epoch=597/600] loss = 1.281937, accuracy@1 = 69.46, accuracy@5 = 93.97 | Best-Valid-Acc@1=69.00, Error@1=31.00
Currently, the best validation accuracy found at 597-epoch :: acc@1=69.46, acc@5=93.97, error@1=30.54, error@5=6.03, save into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth.
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth exist, delete is at first before saving
copy the file from output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-best.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 11:01:21]*** start epoch=598/600 Time Left: [00:01:04], LR=[0.000003 ~ 0.000003], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=598, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10013433505449526, FLOP=40.81
[Search] : epoch=598/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 11:01:21] [epoch=598/600][000/098] Time 0.78 (0.78) Data 0.37 (0.37) Base-Loss 0.708 (0.708)  Prec@1 74.61 (74.61) Prec@5 98.83 (98.83) Acls-loss 0.453 (0.453) FLOP-Loss -3.050 (-3.050) Arch-Loss -5.646 (-5.646)
**TRAIN** [2020-01-29 11:01:45] [epoch=598/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.687 (0.378)  Prec@1 76.19 (87.16) Prec@5 99.40 (99.40) Acls-loss 0.409 (0.544) FLOP-Loss 0.000 (0.125) Arch-Loss 0.409 (0.794)
 **TRAIN** Prec@1 87.16 Prec@5 99.40 Error@1 12.84 Error@5 0.60 Base-Loss:0.378, Arch-Loss=0.794
***[2020-01-29 11:01:46]*** TRAIN [epoch=598/600] base-loss = 0.377988, arch-loss = 0.794254, accuracy-1 = 87.16, accuracy-5 = 99.40
[epoch=598/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 27.210368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.109 0.611 0.280  ||  -0.7004 1.0239 0.2427  || discrepancy=0.33 || select=1/3
001/003-th : 0.297 0.352 0.351  ||  0.0612 0.2317 0.2302  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.030 0.965  ||  -2.2810 -0.6374 2.8486  || discrepancy=0.93 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.011 0.016 0.935  ||  -1.200 -0.978 -0.919 -0.877 -0.720 -0.541 -0.188 3.882  || dis=0.92 || select=7/8
001/019-th : 0.071 0.088 0.112 0.110 0.138 0.142 0.171 0.168  ||  -0.544 -0.318 -0.080 -0.100 0.124 0.156 0.343 0.325   || dis=0.00 || select=6/8
002/019-th : 0.090 0.097 0.116 0.117 0.131 0.153 0.159 0.137  ||  -0.314 -0.239 -0.061 -0.048 0.064 0.219 0.257 0.108   || dis=0.01 || select=6/8
003/019-th : 0.101 0.101 0.116 0.117 0.136 0.148 0.145 0.137  ||  -0.198 -0.206 -0.067 -0.056 0.095 0.181 0.158 0.101   || dis=0.00 || select=5/8
004/019-th : 0.086 0.097 0.106 0.108 0.130 0.125 0.175 0.173  ||  -0.349 -0.228 -0.137 -0.122 0.067 0.028 0.364 0.353   || dis=0.00 || select=6/8
005/019-th : 0.123 0.116 0.120 0.127 0.128 0.125 0.131 0.130  ||  -0.014 -0.069 -0.042 0.017 0.029 0.001 0.047 0.043    || dis=0.00 || select=6/8
006/019-th : 0.146 0.134 0.119 0.124 0.129 0.120 0.117 0.111  ||  0.156 0.074 -0.044 -0.008 0.035 -0.041 -0.059 -0.112  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.008 0.011 0.014 0.020 0.929  ||  -1.427 -1.106 -1.102 -0.872 -0.572 -0.346 0.019 3.851  || dis=0.91 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.012 0.015 0.024 0.923  ||  -1.605 -1.423 -1.086 -0.786 -0.599 -0.321 0.142 3.784  || dis=0.90 || select=7/8
009/019-th : 0.079 0.085 0.089 0.104 0.113 0.125 0.166 0.238  ||  -0.403 -0.328 -0.285 -0.128 -0.048 0.055 0.334 0.695  || dis=0.07 || select=7/8
010/019-th : 0.088 0.093 0.105 0.113 0.129 0.154 0.148 0.170  ||  -0.325 -0.266 -0.151 -0.076 0.060 0.236 0.193 0.336   || dis=0.02 || select=7/8
011/019-th : 0.122 0.112 0.111 0.119 0.130 0.134 0.133 0.139  ||  -0.019 -0.102 -0.115 -0.046 0.045 0.076 0.068 0.115   || dis=0.01 || select=7/8
012/019-th : 0.136 0.125 0.123 0.127 0.131 0.122 0.120 0.115  ||  0.098 0.016 -0.002 0.030 0.061 -0.008 -0.030 -0.069   || dis=0.01 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.877 -0.922 -0.922 -0.913 -0.802 -0.551 -0.412 4.873  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.158 -1.166 -1.071 -0.931 -0.751 -0.522 -0.114 4.634  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.005 0.975  ||  -1.121 -0.782 -0.915 -0.973 -0.688 -0.566 -0.320 4.858  || dis=0.97 || select=7/8
016/019-th : 0.020 0.030 0.032 0.046 0.064 0.161 0.227 0.420  ||  -1.337 -0.959 -0.880 -0.520 -0.191 0.730 1.072 1.687  || dis=0.19 || select=7/8
017/019-th : 0.077 0.085 0.100 0.112 0.120 0.141 0.170 0.195  ||  -0.455 -0.346 -0.186 -0.079 -0.007 0.152 0.340 0.481  || dis=0.02 || select=7/8
018/019-th : 0.095 0.100 0.116 0.149 0.137 0.113 0.139 0.150  ||  -0.258 -0.206 -0.062 0.194 0.107 -0.084 0.124 0.199   || dis=0.00 || select=7/8
[epoch=598/600] FLOP : 27.21 MB, ratio : 0.6667, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 11:01:46] [epoch=598/600][000/098] Time 0.36 (0.36) Data 0.27 (0.27) Loss 0.484 (0.484)  Prec@1 86.33 (86.33) Prec@5 98.44 (98.44) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 11:01:52] [epoch=598/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.477 (1.463)  Prec@1 53.57 (63.00) Prec@5 88.69 (91.18) Size=[168, 3, 32, 32]
 **VALID** Prec@1 63.00 Prec@5 91.18 Error@1 37.00 Error@5 8.82 Loss:1.463
***[2020-01-29 11:01:52]*** VALID [epoch=598/600] loss = 1.463198, accuracy@1 = 63.00, accuracy@5 = 91.18 | Best-Valid-Acc@1=69.46, Error@1=30.54
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

***[2020-01-29 11:01:52]*** start epoch=599/600 Time Left: [00:00:32], LR=[0.000001 ~ 0.000001], scheduler=CosineAnnealingLR(warmup=0, max-epoch=600, current::epoch=599, iter=0.00, type=cosine, T-max=600, eta-min=0.0), tau=0.10003358399380448, FLOP=40.81
[Search] : epoch=599/600, FLOP-Require=28.57 MB, FLOP-WEIGHT=2.00
**TRAIN** [2020-01-29 11:01:53] [epoch=599/600][000/098] Time 0.65 (0.65) Data 0.37 (0.37) Base-Loss 0.313 (0.313)  Prec@1 91.02 (91.02) Prec@5 99.61 (99.61) Acls-loss 0.431 (0.431) FLOP-Loss 0.000 (0.000) Arch-Loss 0.431 (0.431)
**TRAIN** [2020-01-29 11:02:17] [epoch=599/600][097/098] Time 0.23 (0.25) Data 0.00 (0.00) Base-Loss 0.461 (0.334)  Prec@1 84.52 (88.83) Prec@5 98.81 (99.54) Acls-loss 0.437 (0.556) FLOP-Loss 0.000 (-0.594) Arch-Loss 0.437 (-0.631)
 **TRAIN** Prec@1 88.83 Prec@5 99.54 Error@1 11.17 Error@5 0.46 Base-Loss:0.334, Arch-Loss=-0.631
***[2020-01-29 11:02:17]*** TRAIN [epoch=599/600] base-loss = 0.333817, arch-loss = -0.631321, accuracy-1 = 88.83, accuracy-5 = 99.54
[epoch=599/600] genotype : OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 27.210368)])
for depth and width, there are 3 + 19 attention probabilities.
OrderedDict([(3, {'choices': [1, 2, 3], 'stage': 0, 'xstart': 1}), (6, {'choices': [4, 5, 6], 'stage': 1, 'xstart': 4}), (9, {'choices': [7, 8, 9], 'stage': 2, 'xstart': 7})])
000/003-th : 0.108 0.603 0.289  ||  -0.7175 0.9990 0.2651  || discrepancy=0.31 || select=1/3
001/003-th : 0.295 0.354 0.351  ||  0.0580 0.2414 0.2315  || discrepancy=0.00 || select=1/3
002/003-th : 0.006 0.029 0.965  ||  -2.2779 -0.6435 2.8478  || discrepancy=0.94 || select=2/3
-----------------------------------------------
000/019-th : 0.006 0.007 0.008 0.008 0.009 0.011 0.016 0.936  ||  -1.223 -0.972 -0.915 -0.869 -0.715 -0.540 -0.195 3.897  || dis=0.92 || select=7/8
001/019-th : 0.069 0.087 0.111 0.109 0.136 0.144 0.173 0.171  ||  -0.558 -0.336 -0.088 -0.109 0.112 0.175 0.358 0.344   || dis=0.00 || select=6/8
002/019-th : 0.089 0.095 0.114 0.116 0.131 0.155 0.162 0.140  ||  -0.328 -0.260 -0.076 -0.059 0.062 0.229 0.277 0.128   || dis=0.01 || select=6/8
003/019-th : 0.099 0.097 0.114 0.116 0.136 0.150 0.147 0.141  ||  -0.220 -0.237 -0.075 -0.064 0.095 0.198 0.172 0.132   || dis=0.00 || select=5/8
004/019-th : 0.084 0.097 0.102 0.105 0.130 0.126 0.179 0.177  ||  -0.365 -0.229 -0.171 -0.147 0.067 0.034 0.387 0.375   || dis=0.00 || select=6/8
005/019-th : 0.120 0.119 0.118 0.126 0.132 0.121 0.132 0.132  ||  -0.040 -0.047 -0.053 0.009 0.057 -0.029 0.061 0.061   || dis=0.00 || select=7/8
006/019-th : 0.142 0.131 0.117 0.124 0.130 0.122 0.120 0.114  ||  0.132 0.052 -0.063 -0.005 0.045 -0.024 -0.041 -0.090  || dis=0.01 || select=0/8
007/019-th : 0.005 0.007 0.007 0.008 0.011 0.014 0.019 0.930  ||  -1.422 -1.101 -1.100 -0.870 -0.570 -0.345 -0.015 3.858  || dis=0.91 || select=7/8
008/019-th : 0.004 0.005 0.007 0.010 0.011 0.015 0.024 0.924  ||  -1.601 -1.417 -1.091 -0.784 -0.613 -0.322 0.134 3.792  || dis=0.90 || select=7/8
009/019-th : 0.076 0.084 0.087 0.104 0.111 0.125 0.170 0.243  ||  -0.433 -0.339 -0.307 -0.123 -0.058 0.059 0.367 0.724  || dis=0.07 || select=7/8
010/019-th : 0.088 0.093 0.104 0.110 0.130 0.154 0.149 0.173  ||  -0.325 -0.269 -0.160 -0.099 0.064 0.235 0.200 0.352   || dis=0.02 || select=7/8
011/019-th : 0.120 0.110 0.110 0.118 0.130 0.136 0.134 0.142  ||  -0.036 -0.117 -0.118 -0.050 0.045 0.090 0.081 0.132   || dis=0.01 || select=7/8
012/019-th : 0.133 0.123 0.122 0.126 0.131 0.126 0.123 0.118  ||  0.073 -0.005 -0.014 0.019 0.062 0.017 -0.007 -0.048   || dis=0.00 || select=0/8
013/019-th : 0.003 0.003 0.003 0.003 0.003 0.004 0.005 0.975  ||  -0.871 -0.919 -0.921 -0.911 -0.800 -0.548 -0.411 4.868  || dis=0.97 || select=7/8
014/019-th : 0.003 0.003 0.003 0.004 0.004 0.006 0.008 0.969  ||  -1.154 -1.162 -1.067 -0.929 -0.751 -0.520 -0.133 4.637  || dis=0.96 || select=7/8
015/019-th : 0.002 0.003 0.003 0.003 0.004 0.004 0.006 0.975  ||  -1.117 -0.781 -0.913 -0.979 -0.684 -0.565 -0.319 4.857  || dis=0.97 || select=7/8
016/019-th : 0.020 0.030 0.032 0.046 0.063 0.157 0.226 0.426  ||  -1.335 -0.959 -0.888 -0.524 -0.205 0.712 1.073 1.708  || dis=0.20 || select=7/8
017/019-th : 0.075 0.083 0.099 0.111 0.117 0.141 0.170 0.203  ||  -0.474 -0.370 -0.199 -0.085 -0.028 0.158 0.346 0.522  || dis=0.03 || select=7/8
018/019-th : 0.094 0.098 0.115 0.151 0.136 0.113 0.141 0.152  ||  -0.268 -0.225 -0.071 0.207 0.101 -0.080 0.136 0.209   || dis=0.00 || select=7/8
[epoch=599/600] FLOP : 27.21 MB, ratio : 0.6667, Expected-ratio : 0.7000, Discrepancy : 0.329
------------------------------------------------------------------------------------------------------------------------------------------------------
**VALID** [2020-01-29 11:02:17] [epoch=599/600][000/098] Time 0.36 (0.36) Data 0.28 (0.28) Loss 0.689 (0.689)  Prec@1 73.44 (73.44) Prec@5 99.22 (99.22) Size=[256, 3, 32, 32]
**VALID** [2020-01-29 11:02:23] [epoch=599/600][097/098] Time 0.06 (0.06) Data 0.00 (0.00) Loss 1.094 (1.359)  Prec@1 67.26 (63.64) Prec@5 96.43 (90.64) Size=[168, 3, 32, 32]
 **VALID** Prec@1 63.64 Prec@5 90.64 Error@1 36.36 Error@5 9.36 Loss:1.359
***[2020-01-29 11:02:23]*** VALID [epoch=599/600] loss = 1.359308, accuracy@1 = 63.64, accuracy@5 = 90.64 | Best-Valid-Acc@1=69.46, Error@1=30.54
[GPU-Memory-Usage on cuda:0 is 557842432 bytes, 557842.43 KB, 557.84 MB, 0.56 GB.]
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/checkpoint/seed-5-basic.pth
Find output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth exist, delete is at first before saving
save checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth

----------------------------------------------------------------------------------------------------
save the last config int output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last.config :
OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 16, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 64]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 27.210368)])
save the last config int output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-best.config :
OrderedDict([('dataset', 'cifar'), ('arch', 'resnet'), ('depth', 20), ('module', 'ResNetBasicblock'), ('super_type', 'infer-shape'), ('zero_init_residual', False), ('class_num', 10), ('search_mode', 'shape'), ('xchannels', [3, 16, 14, 14, 12, 14, 14, 4, 32, 32, 32, 32, 32, 9, 64, 64, 64, 64, 64, 38]), ('xblocks', [2, 2, 3]), ('estimated_FLOP', 26.407292)])

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Finish training/validation in [05:21:20] with Max-GPU-Memory of 0.56 GB, and save final checkpoint into output/search-shape/cifar10-ResNet20-CIFARX-Gumbel_0.1_5-0.7/seed-5-last-info.pth
